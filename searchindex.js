Search.setIndex({"alltitles": {"": [[25, "id1"]], "(Optional) Changing the data": [[36, "optional-changing-the-data"]], "(Optional) Evaluation": [[47, "optional-evaluation"]], "(Optional) Evaluation metrics for multi-class classification": [[36, "optional-evaluation-metrics-for-multi-class-classification"]], "(Optional) Example 1: Optimization bias": [[35, "optional-example-1-optimization-bias"]], "(Optional) Example 2: Optimization bias": [[35, "optional-example-2-optimization-bias"]], "(Optional) Fancier methods": [[35, "optional-fancier-methods"]], "(Optional) Fitting in boosted regression trees.": [[38, "optional-fitting-in-boosted-regression-trees"]], "(Optional) Forward or backward selection": [[40, "optional-forward-or-backward-selection"]], "(Optional) Macro average and weighted average": [[36, "optional-macro-average-and-weighted-average"]], "(Optional) Parametric vs non parametric": [[15, "optional-parametric-vs-non-parametric"], [21, "optional-parametric-vs-non-parametric"], [31, "optional-parametric-vs-non-parametric"]], "(Optional) Passing probability distributions to random search": [[35, "optional-passing-probability-distributions-to-random-search"]], "(Optional) Prediction in boosted regression trees": [[38, "optional-prediction-in-boosted-regression-trees"]], "(Optional) Problems with feature selection": [[40, "optional-problems-with-feature-selection"]], "(Optional) Search and score": [[40, "optional-search-and-score"]], "(Optional) Searching for optimal parameters with successive halving\u00b6": [[35, "optional-searching-for-optimal-parameters-with-successive-halving"]], "(Optional) Setting up a directory structure and environment": [[49, "optional-setting-up-a-directory-structure-and-environment"]], "(Optional) Some more details": [[36, "optional-some-more-details"]], "(Supervised) machine learning: popular definition": [[12, "supervised-machine-learning-popular-definition"], [18, "supervised-machine-learning-popular-definition"], [28, "supervised-machine-learning-popular-definition"]], "(iClicker) Exercise 14.1": [[40, "id1"]], "(iClicker) Exercise 21.1": [[47, "iclicker-exercise-21-1"]], "(iClicker) Exercise 21.2": [[47, "iclicker-exercise-21-2"]], "(iClicker) Exercise 4.1": [[21, "iclicker-exercise-4-1"], [31, "iclicker-exercise-4-1"]], "(iClicker) Exercise 4.1 https://join.iclicker.com/FUYI": [[15, "iclicker-exercise-4-1-https-join-iclicker-com-fuyi"]], "(iClicker) Exercise 4.2": [[21, "iclicker-exercise-4-2"], [31, "iclicker-exercise-4-2"]], "(iClicker) Exercise 4.2 https://join.iclicker.com/FUYI": [[15, "iclicker-exercise-4-2-https-join-iclicker-com-fuyi"]], "(iClicker) Exercise 5.1": [[16, "iclicker-exercise-5-1"], [22, "iclicker-exercise-5-1"], [32, "iclicker-exercise-5-1"]], "(iClicker) Exercise 5.2": [[16, "iclicker-exercise-5-2"], [22, "iclicker-exercise-5-2"], [32, "iclicker-exercise-5-2"]], "(iClicker) Exercise 5.3": [[16, "iclicker-exercise-5-3"], [22, "iclicker-exercise-5-3"], [32, "iclicker-exercise-5-3"]], "(iClicker) Exercise 6.1": [[17, "iclicker-exercise-6-1"], [23, "iclicker-exercise-6-1"], [33, "iclicker-exercise-6-1"]], "(iClicker) Exercise 6.2": [[17, "iclicker-exercise-6-2"], [23, "iclicker-exercise-6-2"], [33, "iclicker-exercise-6-2"]], "(iClicker) Exercise 7.1": [[34, "iclicker-exercise-7-1"]], "(iClicker) Exercise 7.2": [[34, "iclicker-exercise-7-2"]], "(iClicker) Exercise 8.1": [[35, "iclicker-exercise-8-1"]], "(iClicker) Midterm poll": [[41, "iclicker-midterm-poll"]], "15.1 Select all of the following statements which are True (iClicker)": [[41, "select-all-of-the-following-statements-which-are-true-iclicker"]], "15.2 Select all of the following statements which are True (iClicker)": [[41, "id1"]], "15.3 Select all of the following statements which are True (iClicker)": [[41, "id3"]], "16.1 Select all of the following statements which are True (iClicker)": [[42, "select-all-of-the-following-statements-which-are-true-iclicker"]], "16.2 Select all of the following statements which are True (iClicker)": [[42, "id2"]], "16.3 Select all of the following statements which are True": [[42, "select-all-of-the-following-statements-which-are-true"]], "330 vs. 340": [[49, "vs-340"]], "<font color='red'>Question 1</font>": [[53, "question-1"], [54, "question-1"]], "<font color='red'>Question 2: Baseline model</font>": [[54, "question-2-baseline-model"]], "<font color='red'>Question 2</font>": [[53, "question-2"]], "<font color='red'>Question 3: Decision tree</font>": [[54, "question-3-decision-tree"]], "<font color='red'>Question 3</font>": [[53, "question-3"]], "<font color='red'>Question 4: Hyperparameter tuning</font>": [[54, "question-4-hyperparameter-tuning"]], "<font color='red'>Question 4</font>": [[53, "question-4"]], "<font color='red'>Question 5: Cross-validation</font>": [[54, "question-5-cross-validation"]], "<font color='red'>Question 6: Hyperparameters playground</font>": [[54, "question-6-hyperparameters-playground"]], "<font color='red'>Recap Questions</font>": [[53, "recap-questions"]], "<font color='red'>Recap/comprehension questions</font>": [[55, "recap-comprehension-questions"]], "A few comments on PR curve": [[36, "a-few-comments-on-pr-curve"]], "A few comments on clustering evaluation": [[42, "a-few-comments-on-clustering-evaluation"]], "AP score": [[36, "ap-score"]], "AP vs. F1-score": [[36, "ap-vs-f1-score"]], "API on the localhost": [[49, "api-on-the-localhost"]], "About this course": [[12, "about-this-course"], [18, "about-this-course"]], "About this document": [[8, "about-this-document"]], "Academic concessions": [[56, "academic-concessions"]], "Accessing homework assignments": [[7, "accessing-homework-assignments"]], "Accessing learned parameters": [[34, "accessing-learned-parameters"]], "Activity": [[12, "activity"], [18, "activity"]], "Activity (~5 mins)": [[39, "activity-5-mins"], [39, "id3"]], "Activity: Context and word meaning": [[44, "activity-context-and-word-meaning"]], "Activity: Discuss the following questions in your group": [[25, "activity-discuss-the-following-questions-in-your-group"]], "Activity: How can you measure quality of the data? (~3 mins)": [[40, "activity-how-can-you-measure-quality-of-the-data-3-mins"]], "Activity: explaining GridSearchCV (15 min)": [[48, "activity-explaining-gridsearchcv-15-min"]], "Adding/removing columns with [] and drop()": [[8, "adding-removing-columns-with-and-drop"]], "Adding/removing rows with [] and drop()": [[8, "adding-removing-rows-with-and-drop"]], "Additional submission instructions": [[7, "additional-submission-instructions"]], "Addressing class imbalance": [[36, "addressing-class-imbalance"]], "Advantages of RandomizedSearchCV": [[35, "advantages-of-randomizedsearchcv"], [35, "id1"]], "Alternative and more compact syntax: make_pipeline": [[16, "alternative-and-more-compact-syntax-make-pipeline"], [22, "alternative-and-more-compact-syntax-make-pipeline"], [32, "alternative-and-more-compact-syntax-make-pipeline"]], "Alternative methods for scaling": [[27, "alternative-methods-for-scaling"]], "Alternative terminology for examples, features, targets, and training": [[13, "alternative-terminology-for-examples-features-targets-and-training"], [19, "alternative-terminology-for-examples-features-targets-and-training"], [29, "alternative-terminology-for-examples-features-targets-and-training"]], "An effective strategy": [[38, "an-effective-strategy"]], "An example from a project": [[50, "an-example-from-a-project"]], "An example of a bootstrap samples": [[38, "an-example-of-a-bootstrap-samples"]], "An introduction to Grid Search": [[48, "an-introduction-to-grid-search"]], "Analogy-based algorithms in practice": [[15, "analogy-based-algorithms-in-practice"], [31, "analogy-based-algorithms-in-practice"]], "Analogy-based models": [[15, "analogy-based-models"], [31, "analogy-based-models"]], "Announcements": [[12, "announcements"], [13, "announcements"], [14, "announcements"], [16, "announcements"], [17, "announcements"], [34, "announcements"]], "Appendix A: Demo of feature engineering for text data": [[50, null]], "Appendix B: Multi-class, meta-strategies": [[51, null]], "Applying feature transformations": [[37, "applying-feature-transformations"], [48, "applying-feature-transformations"]], "Applying functions to a dataframe with df.apply() and df.applymap()": [[8, "applying-functions-to-a-dataframe-with-df-apply-and-df-applymap"]], "Approach 1: Only consider the examples where \u201cChurn\u201d=Yes": [[47, "approach-1-only-consider-the-examples-where-churn-yes"]], "Approach 2: Assume everyone churns right now": [[47, "approach-2-assume-everyone-churns-right-now"]], "Approach 3: Survival analysis": [[47, "approach-3-survival-analysis"]], "Approach from all angles": [[48, "approach-from-all-angles"]], "Are we doing better with class_weight=\"balanced\"?": [[36, "are-we-doing-better-with-class-weight-balanced"]], "Area under the curve (AUC)": [[36, "area-under-the-curve-auc"]], "Assessing on the test set": [[25, "assessing-on-the-test-set"]], "Assignments": [[56, "assignments"]], "Attention": [[13, null], [13, null], [15, null], [19, null], [19, null], [21, null], [29, null], [29, null], [29, null], [31, null]], "Attribution": [[48, "attribution"]], "Automated hyperparameter optimization": [[35, "automated-hyperparameter-optimization"], [35, "id3"]], "Averaging": [[38, "averaging"]], "Bad range for hyperparameters": [[35, "bad-range-for-hyperparameters"]], "Bag of words (BOW) representation": [[17, "bag-of-words-bow-representation"], [23, "bag-of-words-bow-representation"], [33, "bag-of-words-bow-representation"]], "Bag-of-words model": [[50, "bag-of-words-model"]], "Baseline": [[36, "baseline"], [39, "baseline"]], "Baseline Approaches": [[43, "baseline-approaches"]], "Baseline model": [[25, "baseline-model"]], "Baselines": [[13, "baselines"], [19, "baselines"], [29, "baselines"], [38, "baselines"]], "Baselines [video]": [[13, "baselines-video"], [19, "baselines-video"], [29, "baselines-video"]], "Basic text preprocessing [video]": [[44, "basic-text-preprocessing-video"]], "Better features usually help more than a better model.": [[40, "better-features-usually-help-more-than-a-better-model"]], "Beyond error rate in recommendation systems": [[43, "beyond-error-rate-in-recommendation-systems"]], "Bias vs variance tradeoff": [[14, "bias-vs-variance-tradeoff"], [20, "bias-vs-variance-tradeoff"], [30, "bias-vs-variance-tradeoff"]], "Big picture and datasets": [[13, "big-picture-and-datasets"], [19, "big-picture-and-datasets"], [29, "big-picture-and-datasets"]], "Big picture and motivation": [[14, "big-picture-and-motivation"], [20, "big-picture-and-motivation"], [30, "big-picture-and-motivation"]], "Books": [[1, "books"]], "Bottom-up explanations": [[48, "bottom-up-explanations"]], "Break (5 min)": [[8, "break-5-min"], [12, "break-5-min"], [13, "break-5-min"], [14, "break-5-min"], [15, "break-5-min"], [16, "break-5-min"], [17, "break-5-min"], [18, "break-5-min"], [19, "break-5-min"], [20, "break-5-min"], [21, "break-5-min"], [23, "break-5-min"], [29, "break-5-min"], [30, "break-5-min"], [31, "break-5-min"], [32, "break-5-min"], [33, "break-5-min"], [40, "break-5-min"], [44, "break-5-min"], [45, "break-5-min"], [47, "break-5-min"], [48, "break-5-min"]], "Break (~15 min)": [[49, "break-15-min"]], "Broadcasting in numpy": [[8, "broadcasting-in-numpy"]], "Building a model": [[49, "building-a-model"]], "Building a supervise machine learning model": [[12, "building-a-supervise-machine-learning-model"], [18, "building-a-supervise-machine-learning-model"], [28, "building-a-supervise-machine-learning-model"]], "Building and deploying a web app": [[49, "building-and-deploying-a-web-app"]], "Building decision trees with sklearn": [[13, "building-decision-trees-with-sklearn"], [19, "building-decision-trees-with-sklearn"], [29, "building-decision-trees-with-sklearn"]], "Building user profiles": [[43, "building-user-profiles"]], "CPSC 330 Documents": [[3, null]], "CPSC 330 Python notes": [[8, null]], "CPSC 330 grading policies": [[6, null]], "CPSC 330 vs. 340": [[12, "cpsc-330-vs-340"], [18, "cpsc-330-vs-340"]], "CPSC 330 vs. CPSC 340": [[2, null]], "Can we learn without targets?": [[41, "can-we-learn-without-targets"]], "Can we use this feature in the model?": [[16, "can-we-use-this-feature-in-the-model"], [22, "can-we-use-this-feature-in-the-model"], [32, "can-we-use-this-feature-in-the-model"]], "Cases where it\u2019s OK to break the golden rule": [[17, "cases-where-it-s-ok-to-break-the-golden-rule"], [23, "cases-where-it-s-ok-to-break-the-golden-rule"], [33, "cases-where-it-s-ok-to-break-the-golden-rule"]], "CatBoost": [[38, "catboost"]], "Categorical features": [[27, "categorical-features"], [39, "categorical-features"]], "Categorical features [video]": [[16, "categorical-features-video"], [22, "categorical-features-video"], [32, "categorical-features-video"]], "Categorical features with only two possible categories": [[17, "categorical-features-with-only-two-possible-categories"], [23, "categorical-features-with-only-two-possible-categories"], [33, "categorical-features-with-only-two-possible-categories"]], "Censoring and survival analysis": [[47, "censoring-and-survival-analysis"]], "Centre for Accessibility (CfA) Exam Accommodations": [[56, "centre-for-accessibility-cfa-exam-accommodations"]], "Changing the training procedure": [[36, "changing-the-training-procedure"]], "Characters in this course?": [[12, "characters-in-this-course"], [18, "characters-in-this-course"], [28, "characters-in-this-course"]], "Checklist for you before next class": [[12, "checklist-for-you-before-next-class"], [18, "checklist-for-you-before-next-class"]], "Choosing K [video]": [[41, "choosing-k-video"]], "Choosing n_neighbors": [[15, "choosing-n-neighbors"], [21, "choosing-n-neighbors"], [31, "choosing-n-neighbors"]], "Citing sources": [[7, "citing-sources"]], "Class imbalance in training sets": [[36, "class-imbalance-in-training-sets"]], "Class meetings": [[56, "class-meetings"]], "Classification report": [[36, "classification-report"]], "Classification vs. Regression": [[13, "classification-vs-regression"], [19, "classification-vs-regression"], [29, "classification-vs-regression"]], "Classification with KNeighborsClassifier": [[26, "classification-with-kneighborsclassifier"]], "Clustering": [[52, "clustering"]], "Clustering Activity (~5 mins)": [[41, "clustering-activity-5-mins"]], "Clustering motivation [video]": [[41, "clustering-motivation-video"]], "Clustering: Input and (possible) output": [[41, "clustering-input-and-possible-output"]], "Code of conduct": [[56, "code-of-conduct"]], "Coefficients and intercept": [[34, "coefficients-and-intercept"]], "ColumnTransformer example": [[17, "columntransformer-example"], [23, "columntransformer-example"], [33, "columntransformer-example"]], "ColumnTransformer on the California housing dataset": [[33, "columntransformer-on-the-california-housing-dataset"], [55, "columntransformer-on-the-california-housing-dataset"]], "ColumnTransformer: Transformed data": [[17, "columntransformer-transformed-data"], [23, "columntransformer-transformed-data"], [33, "columntransformer-transformed-data"]], "Coming up \u2026": [[14, "coming-up"], [20, "coming-up"], [30, "coming-up"]], "Coming up:": [[15, "coming-up"], [21, "coming-up"], [31, "coming-up"]], "Command-line git": [[5, "command-line-git"]], "Common applications": [[41, "common-applications"]], "Common preprocessing techniques": [[16, "common-preprocessing-techniques"], [22, "common-preprocessing-techniques"], [32, "common-preprocessing-techniques"]], "Communication": [[52, "communication"]], "Communications": [[12, "communications"], [18, "communications"]], "Completing the utility matrix with content-based filtering": [[43, "completing-the-utility-matrix-with-content-based-filtering"]], "Components of a linear classifier": [[34, "components-of-a-linear-classifier"]], "Concepts then labels, not the other way around": [[48, "concepts-then-labels-not-the-other-way-around"]], "Concepts we revised in this demo": [[25, "concepts-we-revised-in-this-demo"]], "Conclusion & farewell": [[49, "conclusion-farewell"]], "Confidence and predict_proba (20 min)": [[48, "confidence-and-predict-proba-20-min"]], "Confusing and perhaps misleading visualization of results": [[48, "confusing-and-perhaps-misleading-visualization-of-results"]], "Confusion matrix": [[36, "confusion-matrix"]], "Confusion matrix with cross-validation": [[36, "confusion-matrix-with-cross-validation"]], "Cons of k-NNs for supervised learning": [[15, "cons-of-k-nns-for-supervised-learning"], [21, "cons-of-k-nns-for-supervised-learning"], [31, "cons-of-k-nns-for-supervised-learning"]], "Content-based filtering": [[43, "content-based-filtering"]], "Convenient make_column_transformer syntax": [[17, "convenient-make-column-transformer-syntax"], [23, "convenient-make-column-transformer-syntax"], [33, "convenient-make-column-transformer-syntax"]], "Course Learning Objectives": [[11, null]], "Course co-ordinator": [[1, "course-co-ordinator"], [56, "course-co-ordinator"]], "Course description": [[56, "course-description"]], "Course format": [[12, "course-format"], [18, "course-format"]], "Course review / conclusion (~20 min)": [[49, "course-review-conclusion-20-min"]], "Course website": [[12, "course-website"], [18, "course-website"]], "Cox proportional hazards model": [[47, "cox-proportional-hazards-model"]], "Create X and y": [[13, "create-x-and-y"], [19, "create-x-and-y"], [29, "create-x-and-y"]], "Create a classifier object": [[13, "create-a-classifier-object"], [19, "create-a-classifier-object"], [29, "create-a-classifier-object"]], "Create a column transformer": [[17, "create-a-column-transformer"], [23, "create-a-column-transformer"], [33, "create-a-column-transformer"]], "Creating train_df and test_df": [[14, "creating-train-df-and-test-df"], [20, "creating-train-df-and-test-df"], [30, "creating-train-df-and-test-df"]], "Creating utility matrix": [[43, "creating-utility-matrix"]], "Credit": [[10, "credit"]], "Cross validation with different metrics": [[36, "cross-validation-with-different-metrics"]], "Cross-validation": [[25, "cross-validation"], [46, "cross-validation"], [46, "id4"]], "Cross-validation [video]": [[14, "cross-validation-video"], [20, "cross-validation-video"], [30, "cross-validation-video"]], "Cross-validation to the rescue!!": [[14, "cross-validation-to-the-rescue"], [20, "cross-validation-to-the-rescue"], [30, "cross-validation-to-the-rescue"]], "Cross-validation using scikit-learn": [[14, "cross-validation-using-scikit-learn"], [20, "cross-validation-using-scikit-learn"], [30, "cross-validation-using-scikit-learn"]], "Curse of dimensionality": [[15, "curse-of-dimensionality"], [21, "curse-of-dimensionality"], [31, "curse-of-dimensionality"]], "Customer churn": [[47, "customer-churn"]], "Customer segmentation": [[41, "customer-segmentation"]], "DBSCAN [video]": [[42, "dbscan-video"]], "DBSCAN introduction": [[42, "dbscan-introduction"]], "DBSCAN: failure cases": [[42, "dbscan-failure-cases"], [42, "id1"]], "Data": [[17, "data"], [23, "data"], [33, "data"], [34, "data"], [38, "data"], [39, "data"], [39, "id1"]], "Data Splitting [video]": [[14, "data-splitting-video"], [20, "data-splitting-video"], [30, "data-splitting-video"]], "Data and main approaches": [[43, "data-and-main-approaches"]], "Data and splitting": [[27, "data-and-splitting"]], "Data exploration": [[41, "data-exploration"]], "Data splitting": [[25, "data-splitting"], [54, "data-splitting"]], "Dataframe summaries": [[8, "dataframe-summaries"]], "Dataset": [[45, "dataset"], [48, "dataset"]], "Dataset [video]": [[37, "dataset-video"]], "Dataset for demonstration": [[36, "dataset-for-demonstration"]], "Dataset, splitting, and baseline": [[16, "dataset-splitting-and-baseline"], [22, "dataset-splitting-and-baseline"], [32, "dataset-splitting-and-baseline"]], "Datasets": [[7, "datasets"]], "Dealing with class imbalance [video]": [[36, "dealing-with-class-imbalance-video"]], "Dealing with unknown categories": [[17, "dealing-with-unknown-categories"], [23, "dealing-with-unknown-categories"], [33, "dealing-with-unknown-categories"]], "Debugging": [[10, "debugging"]], "Decision boundaries playground": [[26, "decision-boundaries-playground"]], "Decision boundary": [[13, "decision-boundary"], [19, "decision-boundary"], [29, "decision-boundary"]], "Decision boundary for max_depth=1": [[13, "decision-boundary-for-max-depth-1"], [19, "decision-boundary-for-max-depth-1"], [29, "decision-boundary-for-max-depth-1"]], "Decision boundary for max_depth=2": [[13, "decision-boundary-for-max-depth-2"], [19, "decision-boundary-for-max-depth-2"], [29, "decision-boundary-for-max-depth-2"]], "Decision boundary for max_depth=5": [[13, "decision-boundary-for-max-depth-5"], [19, "decision-boundary-for-max-depth-5"], [29, "decision-boundary-for-max-depth-5"]], "Decision boundary of SVMs": [[15, "decision-boundary-of-svms"], [21, "decision-boundary-of-svms"], [31, "decision-boundary-of-svms"]], "Decision boundary of logistic regression": [[34, "decision-boundary-of-logistic-regression"]], "Decision tree algorithm": [[13, "decision-tree-algorithm"], [19, "decision-tree-algorithm"], [29, "decision-tree-algorithm"]], "Decision tree feature importances": [[39, "decision-tree-feature-importances"]], "Decision tree for regression problems": [[13, "decision-tree-for-regression-problems"], [19, "decision-tree-for-regression-problems"], [29, "decision-tree-for-regression-problems"]], "Decision tree model": [[25, "decision-tree-model"]], "Decision tree with max_depth=1": [[13, "decision-tree-with-max-depth-1"], [19, "decision-tree-with-max-depth-1"], [29, "decision-tree-with-max-depth-1"]], "Decision tree with max_depth=3": [[13, "decision-tree-with-max-depth-3"], [19, "decision-tree-with-max-depth-3"], [29, "decision-tree-with-max-depth-3"]], "Decision trees [video]": [[13, "decision-trees-video"], [19, "decision-trees-video"], [29, "decision-trees-video"]], "Decision trees with continuous features": [[13, "decision-trees-with-continuous-features"], [19, "decision-trees-with-continuous-features"], [29, "decision-trees-with-continuous-features"]], "DecisionTreeClassifier baseline": [[38, "decisiontreeclassifier-baseline"]], "DecisionTreeClassifier on quiz2 grade prediction toy dataset": [[13, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"], [19, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"], [29, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"]], "Decisions involve a few key pieces": [[48, "decisions-involve-a-few-key-pieces"]], "Decreasing the threshold": [[36, "decreasing-the-threshold"]], "Deep learning": [[46, "deep-learning"]], "Deep learning software": [[45, "deep-learning-software"]], "Deliverable due dates (tentative)": [[1, "deliverable-due-dates-tentative"]], "Demo of creating a new web service": [[49, "demo-of-creating-a-new-web-service"]], "Demo of feature engineering with numeric features": [[40, "demo-of-feature-engineering-with-numeric-features"]], "Demo: A more complicated dataset": [[46, "demo-a-more-complicated-dataset"]], "Demo: Deploying moment classification model": [[49, "demo-deploying-moment-classification-model"]], "Dendrogram": [[42, "dendrogram"]], "Deploying the API on a server (not covered)": [[49, "deploying-the-api-on-a-server-not-covered"]], "Deployment (Not examinable)": [[52, "deployment-not-examinable"]], "Difference between Statistics and Machine Learning": [[49, "difference-between-statistics-and-machine-learning"]], "Different models": [[39, "different-models"]], "Different range for hyperparameters yields better results!": [[35, "different-range-for-hyperparameters-yields-better-results"]], "Different scoring functions with cross_validate": [[37, "different-scoring-functions-with-cross-validate"]], "Dimensions in ML problems": [[15, "dimensions-in-ml-problems"], [21, "dimensions-in-ml-problems"], [31, "dimensions-in-ml-problems"]], "Discuss the following questions in your group": [[25, "discuss-the-following-questions-in-your-group"]], "Discussion": [[49, "discussion"]], "Discussion question": [[44, "discussion-question"]], "Discussion questions": [[27, "discussion-questions"]], "Discussion questions:": [[48, "discussion-questions"]], "Distance between feature vectors": [[15, "distance-between-feature-vectors"], [21, "distance-between-feature-vectors"], [31, "distance-between-feature-vectors"]], "Do we actually want to use certain features for prediction?": [[17, "do-we-actually-want-to-use-certain-features-for-prediction"], [33, "do-we-actually-want-to-use-certain-features-for-prediction"]], "Do we have class imbalance?": [[38, "do-we-have-class-imbalance"], [39, "do-we-have-class-imbalance"]], "Do we have correlated features?": [[39, "do-we-have-correlated-features"]], "Document clustering": [[41, "document-clustering"]], "Domain-specific transformations": [[40, "domain-specific-transformations"]], "Dummy Classifier": [[27, "dummy-classifier"]], "Dummy classifier": [[50, "dummy-classifier"]], "Dummy model": [[26, "dummy-model"]], "DummyClassifier": [[13, "dummyclassifier"], [19, "dummyclassifier"], [29, "dummyclassifier"], [46, "dummyclassifier"], [47, "dummyclassifier"]], "DummyClassifier baseline": [[38, "dummyclassifier-baseline"]], "DummyClassifier on quiz2 grade prediction toy dataset": [[13, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"], [19, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"], [29, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"]], "DummyRegressor": [[13, "dummyregressor"], [19, "dummyregressor"], [29, "dummyregressor"], [37, "dummyregressor"]], "EDA": [[16, "eda"], [22, "eda"], [32, "eda"], [36, "eda"], [37, "eda"]], "EDA: Exploratory Data Analysis": [[54, "eda-exploratory-data-analysis"]], "Encoding text data": [[17, "encoding-text-data"], [23, "encoding-text-data"], [33, "encoding-text-data"]], "Encoding time as a number": [[46, "encoding-time-as-a-number"]], "Encoding time of day as a categorical feature": [[46, "encoding-time-of-day-as-a-categorical-feature"]], "Ensembles": [[52, "ensembles"]], "Equally good": [[48, "equally-good"]], "Ethics": [[52, "ethics"]], "Euclidean distance": [[15, "euclidean-distance"], [21, "euclidean-distance"], [31, "euclidean-distance"]], "Evaluating DBSCAN clusters": [[42, "evaluating-dbscan-clusters"]], "Evaluation": [[43, "evaluation"], [43, "id3"]], "Evaluation metrics": [[52, "evaluation-metrics"]], "Evaluation metrics for binary classification: Motivation": [[36, "evaluation-metrics-for-binary-classification-motivation"]], "Evalution metrics overview": [[36, "evalution-metrics-overview"]], "Examining the preprocessed data": [[37, "examining-the-preprocessed-data"], [48, "examining-the-preprocessed-data"]], "Example": [[34, "example"], [38, "example"]], "Example 1: Predicting whether a patient has a liver disease or not": [[12, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"], [18, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"], [28, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"]], "Example 1: What is \u201ccorrect\u201d grouping?": [[41, "example-1-what-is-correct-grouping"]], "Example 1: quiz 2 grade prediction": [[13, "example-1-quiz-2-grade-prediction"], [19, "example-1-quiz-2-grade-prediction"], [29, "example-1-quiz-2-grade-prediction"]], "Example 2: Predicting country using the longitude and latitude": [[13, "example-2-predicting-country-using-the-longitude-and-latitude"], [29, "example-2-predicting-country-using-the-longitude-and-latitude"]], "Example 2: Predicting the label of a given image": [[12, "example-2-predicting-the-label-of-a-given-image"], [18, "example-2-predicting-the-label-of-a-given-image"], [28, "example-2-predicting-the-label-of-a-given-image"]], "Example 3: Predicting housing prices": [[12, "example-3-predicting-housing-prices"], [18, "example-3-predicting-housing-prices"], [28, "example-3-predicting-housing-prices"]], "Example showing how can we interpret coefficients of scaled features.": [[39, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"]], "Example: Is \u201cRelevance\u201d clearly defined?": [[40, "example-is-relevance-clearly-defined"]], "Example: Predict whether a message is spam or not": [[12, "example-predict-whether-a-message-is-spam-or-not"], [18, "example-predict-whether-a-message-is-spam-or-not"], [28, "example-predict-whether-a-message-is-spam-or-not"]], "Example: Supervised vs unsupervised learning": [[41, "example-supervised-vs-unsupervised-learning"]], "Example: Tabular data for grade prediction": [[13, "example-tabular-data-for-grade-prediction"], [19, "example-tabular-data-for-grade-prediction"], [29, "example-tabular-data-for-grade-prediction"]], "Example: Tabular data for the housing price prediction": [[13, "example-tabular-data-for-the-housing-price-prediction"], [29, "example-tabular-data-for-the-housing-price-prediction"]], "Example: class_weight parameter of sklearn LogisticRegression": [[36, "example-class-weight-parameter-of-sklearn-logisticregression"]], "Example: k-nearest neighbours on the Spotify dataset": [[16, "example-k-nearest-neighbours-on-the-spotify-dataset"], [22, "example-k-nearest-neighbours-on-the-spotify-dataset"], [32, "example-k-nearest-neighbours-on-the-spotify-dataset"]], "Examples": [[12, "examples"], [18, "examples"], [28, "examples"]], "Exercise 17.1 Select all of the following statements which are True (iClicker)": [[43, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 17.2 Select all of the following statements which are True (iClicker)": [[43, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 2.1 Select all of the following statements which are examples of supervised machine learning": [[13, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"], [29, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"]], "Exercise 2.3": [[19, "exercise-2-3"]], "Exercise 2.4": [[13, "exercise-2-4"], [29, "exercise-2-4"]], "Exercise 8.2": [[35, "exercise-8-2"]], "Exercise: Predicting country using the longitude and latitude": [[53, "exercise-predicting-country-using-the-longitude-and-latitude"]], "Exhaustive grid search: sklearn.model_selection.GridSearchCV": [[35, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"]], "Explaining a prediction": [[39, "explaining-a-prediction"]], "Explanation 1": [[48, "explanation-1"]], "Explanation 2": [[48, "explanation-2"]], "Exploratory Data Analysis": [[25, "exploratory-data-analysis"]], "Exploratory data analysis": [[27, "exploratory-data-analysis"], [46, "exploratory-data-analysis"]], "Extracting BOW features using scikit-learn": [[17, "extracting-bow-features-using-scikit-learn"], [23, "extracting-bow-features-using-scikit-learn"], [33, "extracting-bow-features-using-scikit-learn"]], "Extracting date and time information": [[46, "extracting-date-and-time-information"]], "F1-score": [[36, "f1-score"]], "Faster method: vectorize the loop over rows": [[8, "faster-method-vectorize-the-loop-over-rows"]], "Fastest method: broadcasting": [[8, "fastest-method-broadcasting"]], "Feature crosses for one-hot encoded features": [[40, "feature-crosses-for-one-hot-encoded-features"]], "Feature engineering": [[46, "feature-engineering"]], "Feature engineering and selection": [[52, "feature-engineering-and-selection"]], "Feature engineering for date/time columns": [[46, "feature-engineering-for-date-time-columns"]], "Feature engineering: Encoding date/time as feature(s)": [[46, "feature-engineering-encoding-date-time-as-feature-s"]], "Feature engineering: Motivation": [[40, "feature-engineering-motivation"]], "Feature importances": [[39, "feature-importances"], [52, "feature-importances"]], "Feature importances in linear models": [[39, "feature-importances-in-linear-models"], [39, "id2"]], "Feature interactions and feature crosses": [[40, "feature-interactions-and-feature-crosses"]], "Feature names of transformed data": [[37, "feature-names-of-transformed-data"]], "Feature selection: Introduction and motivation": [[40, "feature-selection-introduction-and-motivation"]], "Feature transformations and the golden rule": [[16, "feature-transformations-and-the-golden-rule"], [22, "feature-transformations-and-the-golden-rule"], [32, "feature-transformations-and-the-golden-rule"]], "Feature types": [[37, "feature-types"], [37, "id1"], [48, "feature-types"]], "Feature vectors": [[15, "feature-vectors"], [31, "feature-vectors"]], "Figures": [[7, "figures"]], "Filtering a dataframe with [] and df.query()": [[8, "filtering-a-dataframe-with-and-df-query"]], "Final comments and summary": [[35, "final-comments-and-summary"], [43, "final-comments-and-summary"]], "Final comments, summary, and reflection": [[13, "final-comments-summary-and-reflection"], [19, "final-comments-summary-and-reflection"], [29, "final-comments-summary-and-reflection"], [41, "final-comments-summary-and-reflection"], [42, "final-comments-summary-and-reflection"]], "Final exam": [[56, "final-exam"]], "Final exam preparation: guiding questions": [[52, null]], "Final note": [[54, "final-note"]], "Final remarks": [[46, "final-remarks"]], "Finding the distances to a query point": [[15, "finding-the-distances-to-a-query-point"], [21, "finding-the-distances-to-a-query-point"], [31, "finding-the-distances-to-a-query-point"]], "Finding the nearest neighbour": [[15, "finding-the-nearest-neighbour"], [21, "finding-the-nearest-neighbour"], [31, "finding-the-nearest-neighbour"]], "First deliverables": [[12, "first-deliverables"], [18, "first-deliverables"]], "Forecasting further into the future": [[46, "forecasting-further-into-the-future"]], "Forecasting further into the future on a retail dataset": [[46, "forecasting-further-into-the-future-on-a-retail-dataset"]], "Formulating the problem of recommender systems": [[43, "formulating-the-problem-of-recommender-systems"]], "GB better than RF": [[48, "gb-better-than-rf"]], "Garbage in, garbage out.": [[40, "garbage-in-garbage-out"]], "General advice on finding relevant features": [[40, "general-advice-on-finding-relevant-features"]], "General guidelines": [[6, "general-guidelines"]], "General idea": [[38, "general-idea"]], "General idea of k-nearest neighbours algorithm": [[15, "general-idea-of-k-nearest-neighbours-algorithm"], [21, "general-idea-of-k-nearest-neighbours-algorithm"], [31, "general-idea-of-k-nearest-neighbours-algorithm"]], "General idea of search and score methods": [[40, "general-idea-of-search-and-score-methods"]], "General questions": [[4, "general-questions"]], "Generalization [video]": [[14, "generalization-video"], [20, "generalization-video"], [30, "generalization-video"]], "Generalization: Fundamental goal of ML": [[14, "generalization-fundamental-goal-of-ml"], [20, "generalization-fundamental-goal-of-ml"], [30, "generalization-fundamental-goal-of-ml"]], "Generalizing to more features": [[34, "generalizing-to-more-features"]], "Generalizing to unseen data": [[14, "generalizing-to-unseen-data"], [20, "generalizing-to-unseen-data"], [30, "generalizing-to-unseen-data"]], "Geometric view of tabular data and dimensions": [[15, "geometric-view-of-tabular-data-and-dimensions"], [21, "geometric-view-of-tabular-data-and-dimensions"], [31, "geometric-view-of-tabular-data-and-dimensions"]], "Git": [[10, "git"]], "GitHub Desktop": [[5, "github-desktop"]], "Global average baseline": [[43, "global-average-baseline"]], "Golden rule violation: Example 1": [[14, "golden-rule-violation-example-1"], [30, "golden-rule-violation-example-1"]], "Golden rule violation: Example 2": [[14, "golden-rule-violation-example-2"], [30, "golden-rule-violation-example-2"]], "Grades": [[18, "grades"]], "Gradient boosted trees [video]": [[38, "gradient-boosted-trees-video"]], "Gradient boosting in sklearn": [[38, "gradient-boosting-in-sklearn"]], "Grading concerns: time limit": [[6, "grading-concerns-time-limit"]], "Grading scheme": [[56, "grading-scheme"]], "Grading-related questions": [[4, "grading-related-questions"]], "Handling imbalance": [[36, "handling-imbalance"]], "Here is the workflow we\u2019ll generally follow.": [[14, "here-is-the-workflow-we-ll-generally-follow"], [20, "here-is-the-workflow-we-ll-generally-follow"], [30, "here-is-the-workflow-we-ll-generally-follow"]], "Hierarchical clustering [video]": [[42, "hierarchical-clustering-video"]], "Homework info & submission guidelines": [[7, null]], "How are we making predictions?": [[34, "how-are-we-making-predictions"]], "How can we avoid violating golden rule?": [[14, "how-can-we-avoid-violating-golden-rule"], [20, "how-can-we-avoid-violating-golden-rule"], [30, "how-can-we-avoid-violating-golden-rule"]], "How can we get feature importances for non sklearn models?": [[39, "how-can-we-get-feature-importances-for-non-sklearn-models"]], "How do they work?": [[38, "how-do-they-work"]], "How do we carry out feature selection?": [[40, "how-do-we-carry-out-feature-selection"]], "How does fit work?": [[13, "how-does-fit-work"], [13, "id2"], [19, "how-does-fit-work"], [29, "how-does-fit-work"], [29, "id2"]], "How does it work?": [[42, "how-does-it-work"], [48, "how-does-it-work"]], "How does logistic regression calculate these probabilities?": [[34, "how-does-logistic-regression-calculate-these-probabilities"]], "How does predict work?": [[13, "how-does-predict-work"], [19, "how-does-predict-work"], [29, "how-does-predict-work"]], "How to approximate generalization error?": [[14, "how-to-approximate-generalization-error"], [20, "how-to-approximate-generalization-error"], [30, "how-to-approximate-generalization-error"]], "How to ask for help": [[4, null]], "How to carry out cross-validation?": [[16, "how-to-carry-out-cross-validation"], [22, "how-to-carry-out-cross-validation"], [32, "how-to-carry-out-cross-validation"]], "How to choose n_neighbors?": [[15, "how-to-choose-n-neighbors"], [21, "how-to-choose-n-neighbors"], [31, "how-to-choose-n-neighbors"]], "How to pick a model that would generalize better?": [[14, "how-to-pick-a-model-that-would-generalize-better"], [20, "how-to-pick-a-model-that-would-generalize-better"], [30, "how-to-pick-a-model-that-would-generalize-better"]], "How to submit": [[7, "how-to-submit"]], "How would you do it properly? Enter sklearn pipelines!!": [[27, "how-would-you-do-it-properly-enter-sklearn-pipelines"]], "Hyperparameter alpha of Ridge": [[34, "hyperparameter-alpha-of-ridge"]], "Hyperparameter optimization": [[25, "hyperparameter-optimization"], [52, "hyperparameter-optimization"]], "Hyperparameter optimization motivation": [[35, "hyperparameter-optimization-motivation"]], "Hyperparameter tuning for the number of clusters": [[41, "hyperparameter-tuning-for-the-number-of-clusters"]], "Hyperparameters of SVM": [[15, "hyperparameters-of-svm"], [21, "hyperparameters-of-svm"], [31, "hyperparameters-of-svm"]], "Hyperparameters: the problem": [[35, "hyperparameters-the-problem"]], "Identify the transformations we want to apply": [[17, "identify-the-transformations-we-want-to-apply"], [23, "identify-the-transformations-we-want-to-apply"], [33, "identify-the-transformations-we-want-to-apply"]], "Image classification using KNNs and SVM RBF": [[26, "image-classification-using-knns-and-svm-rbf"]], "ImageNet": [[45, "imagenet"]], "Import": [[50, "import"]], "Importance of scaling": [[34, "importance-of-scaling"]], "Important hyperparameters": [[38, "important-hyperparameters"]], "Important hyperparameters of CountVectorizer": [[17, "important-hyperparameters-of-countvectorizer"], [23, "important-hyperparameters-of-countvectorizer"], [33, "important-hyperparameters-of-countvectorizer"]], "Important links": [[1, "important-links"]], "Important points to remember": [[41, "important-points-to-remember"]], "Imports": [[12, "imports"], [13, "imports"], [14, "imports"], [15, "imports"], [15, "id1"], [16, "imports"], [17, "imports"], [18, "imports"], [19, "imports"], [20, "imports"], [21, "imports"], [22, "imports"], [23, "imports"], [25, "imports"], [26, "imports"], [27, "imports"], [28, "imports"], [29, "imports"], [30, "imports"], [31, "imports"], [32, "imports"], [33, "imports"], [34, "imports"], [35, "imports"], [36, "imports"], [37, "imports"], [38, "imports"], [39, "imports"], [40, "imports"], [41, "imports"], [42, "imports"], [43, "imports"], [44, "imports"], [45, "imports"], [46, "imports"], [47, "imports"], [48, "imports"], [49, "imports"], [52, "imports"], [53, "imports"], [54, "imports"]], "Imports and LO": [[35, "imports-and-lo"], [37, "imports-and-lo"], [45, "imports-and-lo"], [46, "imports-and-lo"]], "Imports and LOs": [[36, "imports-and-los"], [49, "imports-and-los"]], "Imports and learning outcomes": [[41, "imports-and-learning-outcomes"]], "Imports, Announcements, LOs": [[29, "imports-announcements-los"]], "Imports, Announcements, and LO": [[23, "imports-announcements-and-lo"], [33, "imports-announcements-and-lo"], [34, "imports-announcements-and-lo"]], "Imports, LOs": [[14, "imports-los"], [16, "imports-los"], [20, "imports-los"], [22, "imports-los"], [30, "imports-los"], [32, "imports-los"], [39, "imports-los"]], "Imports, and LO": [[17, "imports-and-lo"]], "Imports, announcements, LOs": [[38, "imports-announcements-los"]], "Imports, announcements, and LOs": [[21, "imports-announcements-and-los"], [31, "imports-announcements-and-los"]], "Imputation": [[16, "imputation"], [22, "imputation"], [32, "imputation"]], "Imputation and scaling [video]": [[16, "imputation-and-scaling-video"], [22, "imputation-and-scaling-video"], [32, "imputation-and-scaling-video"]], "Incorporating ordinal feature class_attendance": [[17, "incorporating-ordinal-feature-class-attendance"], [23, "incorporating-ordinal-feature-class-attendance"], [33, "incorporating-ordinal-feature-class-attendance"]], "Incorporating text features": [[27, "incorporating-text-features"]], "Increasing the threshold": [[36, "increasing-the-threshold"]], "Indexing Dataframes": [[8, "indexing-dataframes"]], "Indexing cheatsheet": [[8, "indexing-cheatsheet"]], "Inertia": [[41, "inertia"]], "Initial analysis, EDA, preprocessing": [[49, "initial-analysis-eda-preprocessing"]], "Initialization of K-Means": [[41, "initialization-of-k-means"]], "Inject randomness in the classifier construction": [[38, "inject-randomness-in-the-classifier-construction"]], "Input data": [[12, "input-data"], [18, "input-data"], [28, "input-data"]], "Input features X and target y": [[12, "input-features-x-and-target-y"], [18, "input-features-x-and-target-y"], [28, "input-features-x-and-target-y"]], "Installing Python packages": [[10, "installing-python-packages"]], "Instructional Material": [[0, "instructional-material"]], "Instructors": [[1, "instructors"]], "Interesting to you != useful to the reader (aka it\u2019s not about you)": [[48, "interesting-to-you-useful-to-the-reader-aka-it-s-not-about-you"]], "Interim summary": [[36, "interim-summary"], [39, "interim-summary"], [40, "interim-summary"], [46, "interim-summary"]], "Interpretation of coefficients": [[34, "interpretation-of-coefficients"]], "Interpretation of coefficients in linear models": [[34, "interpretation-of-coefficients-in-linear-models"]], "Interpreting coefficients of numeric features": [[39, "interpreting-coefficients-of-numeric-features"]], "Introduction": [[42, "introduction"], [52, "introduction"]], "Introduction to NLP": [[52, "introduction-to-nlp"]], "Introduction to computer vision": [[45, "introduction-to-computer-vision"]], "Introduction to neural networks": [[45, "introduction-to-neural-networks"]], "Introduction to pandas": [[8, "introduction-to-pandas"]], "Introduction to unsupervised learning": [[41, "introduction-to-unsupervised-learning"]], "Is it possible to further improve the scores?": [[50, "is-it-possible-to-further-improve-the-scores"]], "Is stratifying a good idea?": [[36, "is-stratifying-a-good-idea"]], "Is this a realistic representation of text data?": [[17, "is-this-a-realistic-representation-of-text-data"], [23, "is-this-a-realistic-representation-of-text-data"], [33, "is-this-a-realistic-representation-of-text-data"]], "Is this misleading?": [[48, "is-this-misleading"]], "Is \u201cRelevance\u201d clearly defined?": [[40, "is-relevance-clearly-defined"], [40, "id2"], [40, "id3"], [40, "id4"], [40, "id5"], [40, "id6"], [40, "id7"]], "K-Means algorithm": [[41, "k-means-algorithm"]], "K-Means clustering [video]": [[41, "k-means-clustering-video"]], "K-Means example": [[41, "k-means-example"]], "K-Means limitations": [[42, "k-means-limitations"]], "K-Means limitations: Shape of K-Means clusters": [[42, "k-means-limitations-shape-of-k-means-clusters"]], "K-Means recap": [[42, "k-means-recap"]], "K-Means: failure case 1": [[42, "k-means-failure-case-1"]], "K-Means: failure case 2": [[42, "k-means-failure-case-2"]], "K-Means: failure case 3": [[42, "k-means-failure-case-3"]], "Kaplan-Meier survival curve": [[47, "kaplan-meier-survival-curve"]], "Key point": [[39, "key-point"]], "LDA topics in social media": [[44, "lda-topics-in-social-media"]], "LICENSE": [[0, null]], "Labeled vs. Unlabeled data": [[41, "labeled-vs-unlabeled-data"]], "Lag-based features": [[46, "lag-based-features"], [46, "id5"]], "Land acknowledgement": [[56, "land-acknowledgement"]], "Large datasets solve many of these problems": [[35, "large-datasets-solve-many-of-these-problems"]], "Late submissions": [[7, "late-submissions"]], "Learned coefficients associated with all features": [[34, "learned-coefficients-associated-with-all-features"]], "Learned model": [[25, "learned-model"]], "Learning git": [[5, "learning-git"]], "Learning objectives": [[44, "learning-objectives"], [45, "learning-objectives"], [46, "learning-objectives"], [47, "learning-objectives"], [48, "learning-objectives"], [49, "learning-objectives"]], "Learning outcomes": [[12, "learning-outcomes"], [13, "learning-outcomes"], [14, "learning-outcomes"], [15, "learning-outcomes"], [16, "learning-outcomes"], [17, "learning-outcomes"], [18, "learning-outcomes"], [19, "learning-outcomes"], [20, "learning-outcomes"], [21, "learning-outcomes"], [22, "learning-outcomes"], [23, "learning-outcomes"], [28, "learning-outcomes"], [29, "learning-outcomes"], [30, "learning-outcomes"], [31, "learning-outcomes"], [32, "learning-outcomes"], [33, "learning-outcomes"], [34, "learning-outcomes"], [35, "learning-outcomes"], [36, "learning-outcomes"], [37, "learning-outcomes"], [39, "learning-outcomes"], [40, "learning-outcomes"], [41, "learning-outcomes"], [42, "learning-outcomes"]], "Learning outcomes <a name=\"lo\"></a>": [[43, "learning-outcomes"]], "Least confident cases": [[34, "least-confident-cases"]], "Lecture 10: Regression metrics": [[37, null]], "Lecture 12: Ensembles": [[38, null]], "Lecture 13: Feature importances and model transparency": [[39, null]], "Lecture 14: Feature engineering and feature selection": [[40, null]], "Lecture 15: K-Means Clustering": [[41, null]], "Lecture 16: More Clustering": [[42, null]], "Lecture 17: Recommender Systems": [[43, null]], "Lecture 18: Introduction to natural language processing": [[44, null]], "Lecture 19: Multi-class classification and introduction to computer vision": [[45, null]], "Lecture 1: Course Introduction": [[12, null], [18, null], [28, null]], "Lecture 20: Time series": [[46, null]], "Lecture 21: Survival analysis": [[47, null]], "Lecture 22: Communication": [[48, null]], "Lecture 24: Deployment and conclusion": [[49, null]], "Lecture 2: Terminology, Baselines, Decision Trees": [[13, null], [19, null], [29, null]], "Lecture 3: ML Fundamentals Class Demo": [[25, null]], "Lecture 3: Machine Learning Fundamentals": [[14, null], [20, null], [30, null]], "Lecture 4: Class demo": [[26, null]], "Lecture 4: k-Nearest Neighbours and SVM RBFs": [[15, null], [21, null], [31, null]], "Lecture 5 and 6: Class demo": [[27, null]], "Lecture 5: Preprocessing and sklearn pipelines": [[16, null], [22, null], [32, null]], "Lecture 6: sklearn ColumnTransformer and Text Features": [[17, null], [23, null], [33, null]], "Lecture 7: Linear Models": [[34, null]], "Lecture 8: Hyperparameter Optimization and Optimization Bias": [[35, null]], "Lecture 9: Classification metrics": [[36, null]], "Lecture and homework format: Jupyter notebooks": [[12, "lecture-and-homework-format-jupyter-notebooks"], [18, "lecture-and-homework-format-jupyter-notebooks"]], "Lecture learning objectives": [[38, "lecture-learning-objectives"]], "Lecture plan and learning outcomes": [[42, "lecture-plan-and-learning-outcomes"]], "Lecture recordings": [[56, "lecture-recordings"]], "Lecture schedule (tentative)": [[1, "lecture-schedule-tentative"]], "Lecture style": [[12, "lecture-style"], [18, "lecture-style"]], "Let\u2019s do it on our housing data": [[16, "let-s-do-it-on-our-housing-data"], [22, "let-s-do-it-on-our-housing-data"], [32, "let-s-do-it-on-our-housing-data"]], "Let\u2019s examine the transformed data": [[17, "let-s-examine-the-transformed-data"], [23, "let-s-examine-the-transformed-data"], [33, "let-s-examine-the-transformed-data"]], "Let\u2019s explore SVM RBFs": [[15, "let-s-explore-svm-rbfs"], [21, "let-s-explore-svm-rbfs"], [31, "let-s-explore-svm-rbfs"]], "Let\u2019s first run our baseline model DummyRegressor": [[16, "let-s-first-run-our-baseline-model-dummyregressor"], [22, "let-s-first-run-our-baseline-model-dummyregressor"], [32, "let-s-first-run-our-baseline-model-dummyregressor"]], "Let\u2019s identify feature types": [[39, "let-s-identify-feature-types"]], "Let\u2019s look at all the scores at once": [[36, "let-s-look-at-all-the-scores-at-once"]], "Let\u2019s separate X and y": [[37, "let-s-separate-x-and-y"], [39, "let-s-separate-x-and-y"], [48, "let-s-separate-x-and-y"]], "Let\u2019s try KNN on this data": [[27, "let-s-try-knn-on-this-data"]], "Let\u2019s try a linear model: Ridge": [[37, "let-s-try-a-linear-model-ridge"]], "Let\u2019s try cross-validation with our pipeline": [[16, "let-s-try-cross-validation-with-our-pipeline"], [22, "let-s-try-cross-validation-with-our-pipeline"], [32, "let-s-try-cross-validation-with-our-pipeline"]], "License": [[1, "license"]], "LightGBM": [[38, "lightgbm"]], "Limitations of linear models": [[34, "limitations-of-linear-models"]], "Linear SVM": [[34, "linear-svm"]], "Linear models [video]": [[34, "linear-models-video"]], "Linear regression": [[34, "linear-regression"]], "Lists of resources": [[9, "lists-of-resources"]], "Loading our saved model": [[49, "loading-our-saved-model"]], "Logistic regression [video]": [[34, "logistic-regression-video"]], "Logistic regression intuition": [[34, "logistic-regression-intuition"]], "Logistic regression on the cities data": [[34, "logistic-regression-on-the-cities-data"]], "Logistic regression with flattened representation of images": [[45, "logistic-regression-with-flattened-representation-of-images"]], "LogisticRegression": [[46, "logisticregression"], [47, "logisticregression"]], "MAPE": [[37, "mape"]], "ML and decision-making (5 min)": [[48, "ml-and-decision-making-5-min"]], "ML fairness activity (~5 mins)": [[36, "ml-fairness-activity-5-mins"]], "ML fundamentals": [[52, "ml-fundamentals"]], "Mac Users": [[5, "mac-users"]], "Machine learning workflow": [[12, "machine-learning-workflow"], [28, "machine-learning-workflow"], [36, "machine-learning-workflow"]], "Magnitude of the coefficients": [[34, "magnitude-of-the-coefficients"]], "Main hyperparameter of logistic regression": [[34, "main-hyperparameter-of-logistic-regression"]], "Main hyperparameters": [[34, "main-hyperparameters"]], "Main issues in ML-related communication": [[48, "main-issues-in-ml-related-communication"]], "Manual hyperparameter optimization": [[35, "manual-hyperparameter-optimization"]], "Mean intra-cluster distance (a)": [[41, "mean-intra-cluster-distance-a"]], "Mean nearest-cluster distance (b)": [[41, "mean-nearest-cluster-distance-b"]], "Mean squared error (MSE)": [[37, "mean-squared-error-mse"]], "Meet Eva (a fictitious persona)!": [[12, "meet-eva-a-fictitious-persona"], [18, "meet-eva-a-fictitious-persona"], [28, "meet-eva-a-fictitious-persona"]], "Method 1: The Elbow method": [[41, "method-1-the-elbow-method"]], "Method 2: The Silhouette method": [[41, "method-2-the-silhouette-method"]], "Midterms": [[56, "midterms"]], "Misc": [[1, "misc"], [9, "misc"]], "Miscellaneous comments on content-based filtering": [[43, "miscellaneous-comments-on-content-based-filtering"]], "Model building": [[37, "model-building"], [49, "model-building"]], "Model complexity and training error": [[14, "model-complexity-and-training-error"], [20, "model-complexity-and-training-error"], [30, "model-complexity-and-training-error"]], "Model deployment": [[49, "model-deployment"], [49, "id1"]], "Model interpretability beyond linear models": [[39, "model-interpretability-beyond-linear-models"]], "Model predictions on unseen data": [[12, "model-predictions-on-unseen-data"], [18, "model-predictions-on-unseen-data"], [28, "model-predictions-on-unseen-data"]], "Model transparency and interpretation": [[49, "model-transparency-and-interpretation"]], "Model-based selection": [[40, "model-based-selection"]], "Modeling": [[27, "modeling"]], "More comments on tackling class imbalance": [[37, "more-comments-on-tackling-class-imbalance"]], "More details": [[20, "more-details"]], "More details on DBSCAN": [[42, "more-details-on-dbscan"]], "More on feature transformations": [[17, "more-on-feature-transformations"], [23, "more-on-feature-transformations"], [33, "more-on-feature-transformations"]], "More on k-NNs [video]": [[15, "more-on-k-nns-video"], [21, "more-on-k-nns-video"], [31, "more-on-k-nns-video"]], "More terminology [video]": [[13, "more-terminology-video"], [19, "more-terminology-video"], [29, "more-terminology-video"]], "More than one ordinal columns?": [[17, "more-than-one-ordinal-columns"], [23, "more-than-one-ordinal-columns"], [33, "more-than-one-ordinal-columns"]], "Most confident cases": [[34, "most-confident-cases"]], "Motivating example": [[34, "motivating-example"]], "Motivation": [[35, "motivation"], [46, "motivation"], [48, "motivation"]], "Motivation [video]": [[38, "motivation-video"]], "Motivation and big picture [video]": [[16, "motivation-and-big-picture-video"], [22, "motivation-and-big-picture-video"], [32, "motivation-and-big-picture-video"]], "Motivation and context": [[44, "motivation-and-context"]], "Motivation and distances [video]": [[15, "motivation-and-distances-video"], [21, "motivation-and-distances-video"], [31, "motivation-and-distances-video"]], "Movie features": [[43, "movie-features"]], "Multi-class classification": [[45, "multi-class-classification"]], "Multiclass classification and computer vision": [[52, "multiclass-classification-and-computer-vision"]], "Multiple transformations in a transformer": [[17, "multiple-transformations-in-a-transformer"], [23, "multiple-transformations-in-a-transformer"], [33, "multiple-transformations-in-a-transformer"]], "NOTE:": [[8, "note"]], "New ideas in small chunks": [[48, "new-ideas-in-small-chunks"]], "No-loop method: make them the same size, and multiply element-wise": [[8, "no-loop-method-make-them-the-same-size-and-multiply-element-wise"]], "Note": [[14, null], [14, null], [30, null], [30, null], [46, null]], "Number of trees and fundamental trade-off": [[38, "number-of-trees-and-fundamental-trade-off"]], "Numpy array shapes": [[8, "numpy-array-shapes"]], "Numpy arrays": [[8, "numpy-arrays"]], "OHE with many categories": [[17, "ohe-with-many-categories"], [33, "ohe-with-many-categories"]], "Object detection": [[45, "object-detection"]], "Observations": [[36, "observations"]], "One Vs. One approach": [[51, "one-vs-one-approach"]], "One Vs. One prediction": [[51, "one-vs-one-prediction"]], "One vs. Rest": [[51, "one-vs-rest"]], "One-hot encoding (OHE)": [[16, "one-hot-encoding-ohe"], [22, "one-hot-encoding-ohe"], [32, "one-hot-encoding-ohe"]], "One-hot encoding of the month": [[46, "one-hot-encoding-of-the-month"]], "One-hot encoding seasons": [[46, "one-hot-encoding-seasons"]], "OneHotEncoder and sparse features": [[17, "onehotencoder-and-sparse-features"], [23, "onehotencoder-and-sparse-features"], [33, "onehotencoder-and-sparse-features"]], "Online courses": [[1, "online-courses"], [9, "online-courses"]], "Operating point": [[36, "operating-point"]], "Optimization bias of hyper-parameter learning": [[35, "optimization-bias-of-hyper-parameter-learning"]], "Optimization bias of parameter learning": [[35, "optimization-bias-of-parameter-learning"]], "Optimization bias on the Spotify dataset": [[35, "optimization-bias-on-the-spotify-dataset"]], "Optimization bias/Overfitting of the validation set": [[35, "optimization-bias-overfitting-of-the-validation-set"]], "Optional readings and resources": [[35, "optional-readings-and-resources"]], "Ordinal encoding (occasionally recommended)": [[16, "ordinal-encoding-occasionally-recommended"], [22, "ordinal-encoding-occasionally-recommended"], [32, "ordinal-encoding-occasionally-recommended"]], "Ordinal features": [[27, "ordinal-features"], [39, "ordinal-features"]], "Other applications": [[41, "other-applications"]], "Other approaches / what did we not cover?": [[47, "other-approaches-what-did-we-not-cover"]], "Other commonly used preprocessing steps": [[44, "other-commonly-used-preprocessing-steps"]], "Other possible preprocessing?": [[37, "other-possible-preprocessing"]], "Other software package": [[46, "other-software-package"]], "Other tools for preprocessing": [[44, "other-tools-for-preprocessing"]], "Other typical NLP tasks": [[44, "other-typical-nlp-tasks"]], "Other useful arguments of KNeighborsClassifier": [[15, "other-useful-arguments-of-kneighborsclassifier"], [21, "other-useful-arguments-of-kneighborsclassifier"], [31, "other-useful-arguments-of-kneighborsclassifier"]], "Other ways to search": [[40, "other-ways-to-search"]], "Our typical supervised learning set up is as follows:": [[14, "our-typical-supervised-learning-set-up-is-as-follows"], [20, "our-typical-supervised-learning-set-up-is-as-follows"], [30, "our-typical-supervised-learning-set-up-is-as-follows"]], "Outline": [[53, "outline"], [54, "outline"], [55, "outline"]], "Over confident cases": [[34, "over-confident-cases"]], "Overfitting": [[14, "overfitting"], [20, "overfitting"], [30, "overfitting"]], "Overfitting of the validation data": [[35, "overfitting-of-the-validation-data"]], "Overfitting of the validation error": [[35, "overfitting-of-the-validation-error"]], "Oversampling": [[36, "oversampling"]], "Overview": [[15, "overview"], [21, "overview"], [31, "overview"]], "POSIX time feature": [[46, "posix-time-feature"]], "PR curves for logistic regression and SVC": [[36, "pr-curves-for-logistic-regression-and-svc"]], "Pandas DataFrames": [[8, "pandas-dataframes"]], "Pandas Series": [[8, "pandas-series"]], "Parameters": [[13, "parameters"], [19, "parameters"], [29, "parameters"]], "Parameters and hyperparameters: Summary": [[13, "parameters-and-hyperparameters-summary"], [19, "parameters-and-hyperparameters-summary"], [29, "parameters-and-hyperparameters-summary"]], "Parsing datetimes": [[46, "parsing-datetimes"]], "Part 1": [[52, "part-1"]], "Part 2": [[52, "part-2"]], "Piazza-specific Q&A guidelines": [[4, "piazza-specific-q-a-guidelines"]], "Pipelines": [[16, "pipelines"], [22, "pipelines"], [32, "pipelines"]], "Playground": [[15, "playground"], [31, "playground"]], "Playground (in tutorial)": [[21, "playground-in-tutorial"]], "Plotting with matplotlib": [[8, "plotting-with-matplotlib"]], "Practice exercises": [[19, "practice-exercises"], [29, "practice-exercises"]], "Precision": [[36, "precision"]], "Precision and recall: toy example": [[36, "precision-and-recall-toy-example"]], "Precision, recall, f1 score": [[36, "precision-recall-f1-score"]], "Precision-recall curve": [[36, "precision-recall-curve"], [36, "id1"]], "Precision/Recall tradeoff": [[36, "precision-recall-tradeoff"]], "Predicting on unseen data using the trained model": [[12, "predicting-on-unseen-data-using-the-trained-model"], [18, "predicting-on-unseen-data-using-the-trained-model"], [28, "predicting-on-unseen-data-using-the-trained-model"]], "Predicting probability scores [video]": [[34, "predicting-probability-scores-video"]], "Predicting with learned weights": [[34, "predicting-with-learned-weights"]], "Prediction": [[47, "prediction"]], "Prediction of linear regression": [[34, "prediction-of-linear-regression"]], "Prediction with learned parameters": [[34, "prediction-with-learned-parameters"]], "Predictions": [[45, "predictions"]], "Preferences in LogisticRegression": [[48, "preferences-in-logisticregression"]], "Preparation": [[7, "preparation"]], "Preprocessing": [[17, "preprocessing"], [23, "preprocessing"], [33, "preprocessing"], [46, "preprocessing"], [52, "preprocessing"]], "Preprocessing the targets?": [[17, "preprocessing-the-targets"], [23, "preprocessing-the-targets"], [33, "preprocessing-the-targets"]], "Prevalence of ML": [[12, "prevalence-of-ml"], [18, "prevalence-of-ml"], [28, "prevalence-of-ml"]], "Principles of effective communication": [[48, "principles-of-effective-communication"]], "Principles of good explanations (~15 min)": [[48, "principles-of-good-explanations-15-min"]], "Problem formulation": [[43, "problem-formulation"]], "Problem: Different transformations on different columns": [[16, "problem-different-transformations-on-different-columns"], [22, "problem-different-transformations-on-different-columns"], [32, "problem-different-transformations-on-different-columns"]], "Problems with exhaustive grid search": [[35, "problems-with-exhaustive-grid-search"]], "Problems with single train/validation split": [[14, "problems-with-single-train-validation-split"], [20, "problems-with-single-train-validation-split"], [30, "problems-with-single-train-validation-split"]], "Pros of k-NNs for supervised learning": [[15, "pros-of-k-nns-for-supervised-learning"], [21, "pros-of-k-nns-for-supervised-learning"], [31, "pros-of-k-nns-for-supervised-learning"]], "Pros, cons, parameters and hyperparameters of different ML models": [[52, "pros-cons-parameters-and-hyperparameters-of-different-ml-models"]], "Python and Conda": [[10, "python-and-conda"]], "Python requirements/resources": [[12, "python-requirements-resources"], [18, "python-requirements-resources"]], "Python resources": [[9, "python-resources"]], "Question": [[15, "question"], [21, "question"], [31, "question"]], "Question for you": [[42, "question-for-you"]], "Questions for class discussion": [[43, "questions-for-class-discussion"]], "Questions for class discussion (hyperparameter optimization)": [[35, "questions-for-class-discussion-hyperparameter-optimization"]], "Quick recap": [[15, "quick-recap"], [31, "quick-recap"]], "RF better than GB": [[48, "rf-better-than-gb"]], "RFE algorithm": [[40, "rfe-algorithm"]], "R^2 (not in detail)": [[37, "r-2-not-in-detail"]], "Random forest feature importances": [[39, "random-forest-feature-importances"]], "Random forests": [[38, "random-forests"]], "Random forests: number of trees (n_estimators) and the fundamental tradeoff": [[38, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"]], "RandomForestClassifier": [[38, "randomforestclassifier"], [47, "randomforestclassifier"]], "Randomized hyperparameter search": [[35, "randomized-hyperparameter-search"]], "Range of C": [[35, "range-of-c"]], "Raw scores": [[34, "raw-scores"]], "Reading from .csv": [[8, "reading-from-csv"]], "Reading from other formats": [[8, "reading-from-other-formats"]], "Reading from url": [[8, "reading-from-url"]], "Reading the data": [[13, "reading-the-data"], [19, "reading-the-data"], [29, "reading-the-data"], [45, "reading-the-data"]], "Real boundary between Canada and USA": [[13, "real-boundary-between-canada-and-usa"], [29, "real-boundary-between-canada-and-usa"], [53, "real-boundary-between-canada-and-usa"]], "Reasonable grading concerns": [[6, "reasonable-grading-concerns"]], "Recall": [[36, "recall"]], "Recap": [[47, "recap"], [48, "recap"]], "Recap and motivation [video]": [[42, "recap-and-motivation-video"]], "Recap: Supervised machine learning": [[13, "recap-supervised-machine-learning"], [19, "recap-supervised-machine-learning"], [29, "recap-supervised-machine-learning"]], "Receiver Operating Characteristic (ROC) curve": [[36, "receiver-operating-characteristic-roc-curve"]], "Recipe to approach a supervised learning problem with tabular data": [[49, "recipe-to-approach-a-supervised-learning-problem-with-tabular-data"]], "Recommended browser": [[12, "recommended-browser"], [18, "recommended-browser"]], "Recommender systems": [[52, "recommender-systems"]], "Recommender systems intro and motivation": [[43, "recommender-systems-intro-and-motivation"]], "Recommender systems problem": [[43, "recommender-systems-problem"]], "Recursive feature elimination (RFE)": [[40, "recursive-feature-elimination-rfe"]], "Reference Material": [[1, "reference-material"]], "Reference material": [[9, null]], "References": [[47, "references"]], "Registration": [[56, "registration"]], "Registration, waitlist and prerequisites": [[12, "registration-waitlist-and-prerequisites"], [18, "registration-waitlist-and-prerequisites"]], "Regression scoring functions": [[37, "regression-scoring-functions"]], "Regression with k-nearest neighbours (k-NNs)": [[15, "regression-with-k-nearest-neighbours-k-nns"], [21, "regression-with-k-nearest-neighbours-k-nns"], [31, "regression-with-k-nearest-neighbours-k-nns"]], "Relation of C and the fundamental trade-off": [[15, "relation-of-c-and-the-fundamental-trade-off"], [21, "relation-of-c-and-the-fundamental-trade-off"], [31, "relation-of-c-and-the-fundamental-trade-off"]], "Relation of gamma and the fundamental trade-off": [[15, "relation-of-gamma-and-the-fundamental-trade-off"], [21, "relation-of-gamma-and-the-fundamental-trade-off"], [31, "relation-of-gamma-and-the-fundamental-trade-off"]], "Relevant companion materials": [[9, "relevant-companion-materials"]], "Relevant papers": [[38, "relevant-papers"]], "Relevant papers and resources": [[36, "relevant-papers-and-resources"]], "Relevant resources": [[40, "relevant-resources"]], "Reminder": [[43, "reminder"]], "Renaming columns with df.rename()": [[8, "renaming-columns-with-df-rename"]], "Render set-up (I already did these):": [[49, "render-set-up-i-already-did-these"]], "Report format": [[7, "report-format"]], "Requirements (I already did these)": [[49, "requirements-i-already-did-these"]], "Resources": [[41, "resources"], [42, "resources"], [43, "resources"]], "Reuse your running examples": [[48, "reuse-your-running-examples"]], "Ridge": [[34, "ridge"]], "Ridge on the California housing dataset": [[34, "ridge-on-the-california-housing-dataset"]], "RidgeCV": [[37, "ridgecv"]], "Root mean squared error or RMSE": [[37, "root-mean-squared-error-or-rmse"]], "SHAP  (SHapley Additive exPlanations) introduction": [[39, "shap-shapley-additive-explanations-introduction"]], "SHAP plots": [[39, "shap-plots"]], "SMOTE idea": [[36, "smote-idea"]], "SMOTE: Synthetic Minority Over-sampling Technique": [[36, "smote-synthetic-minority-over-sampling-technique"]], "SVM Regressor": [[15, "svm-regressor"], [21, "svm-regressor"], [31, "svm-regressor"]], "Saving the model": [[49, "saving-the-model"]], "Saving time and scaling products": [[12, "saving-time-and-scaling-products"], [18, "saving-time-and-scaling-products"], [28, "saving-time-and-scaling-products"]], "Scaling": [[16, "scaling"], [22, "scaling"], [32, "scaling"]], "Scaling using scikit-learn\u2019s StandardScaler": [[16, "scaling-using-scikit-learn-s-standardscaler"], [22, "scaling-using-scikit-learn-s-standardscaler"], [32, "scaling-using-scikit-learn-s-standardscaler"]], "Search over multiple hyperparameters": [[15, "search-over-multiple-hyperparameters"], [21, "search-over-multiple-hyperparameters"], [31, "search-over-multiple-hyperparameters"]], "Seasonality and trends": [[46, "seasonality-and-trends"]], "Select all of the following statements which are True (iClicker)": [[12, "select-all-of-the-following-statements-which-are-true-iclicker"], [18, "select-all-of-the-following-statements-which-are-true-iclicker"], [28, "select-all-of-the-following-statements-which-are-true-iclicker"]], "Sending a request to the API": [[49, "sending-a-request-to-the-api"]], "Setting up": [[5, "setting-up"]], "Setting up a virtual environment: Conda environments": [[10, "setting-up-a-virtual-environment-conda-environments"]], "Setting up coding environment": [[10, null]], "Setting up your computer for the course": [[12, "setting-up-your-computer-for-the-course"], [18, "setting-up-your-computer-for-the-course"]], "Short posts/articles": [[9, "short-posts-articles"]], "Sigmoid vs. Softmax": [[45, "sigmoid-vs-softmax"]], "Sign of the coefficients": [[34, "sign-of-the-coefficients"]], "Silhouette distance for a sample": [[41, "silhouette-distance-for-a-sample"]], "Similarity between examples": [[15, "similarity-between-examples"], [21, "similarity-between-examples"], [31, "similarity-between-examples"]], "Simple feature engineering for our problem.": [[50, "simple-feature-engineering-for-our-problem"]], "Simple train/test split": [[14, "simple-train-test-split"], [20, "simple-train-test-split"], [30, "simple-train-test-split"]], "SimpleFeature correlations": [[39, "simplefeature-correlations"]], "Single validation set": [[25, "single-validation-set"]], "Slowest method: nested loop": [[8, "slowest-method-nested-loop"]], "Software": [[0, "software"]], "Some important hyperparameters:": [[38, "some-important-hyperparameters"]], "Some key takeaways": [[49, "some-key-takeaways"]], "Some quotes on feature engineering": [[40, "some-quotes-on-feature-engineering"]], "Some terminology related to trees": [[13, "some-terminology-related-to-trees"], [19, "some-terminology-related-to-trees"], [29, "some-terminology-related-to-trees"]], "Some ways to pick hyperparameters:": [[35, "some-ways-to-pick-hyperparameters"]], "Sorting a dataframe with df.sort_values()": [[8, "sorting-a-dataframe-with-df-sort-values"]], "Spam/non spam toy example": [[17, "spam-non-spam-toy-example"], [23, "spam-non-spam-toy-example"], [33, "spam-non-spam-toy-example"]], "Specific questions": [[4, "specific-questions"]], "Stacking": [[38, "stacking"]], "Step 1": [[55, "step-1"]], "Step 2": [[55, "step-2"]], "Step 3": [[55, "step-3"]], "Step 4": [[55, "step-4"]], "Step 5": [[55, "step-5"]], "Steps to train a classifier using sklearn": [[13, "steps-to-train-a-classifier-using-sklearn"], [19, "steps-to-train-a-classifier-using-sklearn"], [29, "steps-to-train-a-classifier-using-sklearn"]], "Stratified Splits": [[36, "stratified-splits"]], "Strengths and weaknesses": [[38, "strengths-and-weaknesses"]], "Strengths of linear models": [[34, "strengths-of-linear-models"]], "Study tips": [[52, "study-tips"]], "Submitting on Gradescope": [[7, "submitting-on-gradescope"]], "Summary": [[12, "summary"], [15, "summary"], [18, "summary"], [21, "summary"], [28, "summary"], [31, "summary"], [38, "summary"], [44, "summary"], [45, "summary"], [47, "summary"]], "Summary and reflection": [[14, "summary-and-reflection"], [20, "summary-and-reflection"], [30, "summary-and-reflection"]], "Summary of linear models": [[34, "summary-of-linear-models"]], "Summary of train, validation, test, and deployment data": [[14, "summary-of-train-validation-test-and-deployment-data"], [20, "summary-of-train-validation-test-and-deployment-data"], [30, "summary-of-train-validation-test-and-deployment-data"]], "Summary: Pros and cons": [[42, "summary-pros-and-cons"]], "Supervised approach to rating prediction": [[43, "supervised-approach-to-rating-prediction"]], "Supervised learning": [[41, "supervised-learning"]], "Supervised learning (Reminder)": [[13, "supervised-learning-reminder"], [29, "supervised-learning-reminder"]], "Supervised learning vs. Unsupervised learning": [[13, "supervised-learning-vs-unsupervised-learning"], [19, "supervised-learning-vs-unsupervised-learning"], [29, "supervised-learning-vs-unsupervised-learning"]], "Supervised machine learning": [[12, "supervised-machine-learning"], [18, "supervised-machine-learning"], [28, "supervised-machine-learning"]], "Support Vector Machines (SVMs) with RBF kernel [video]": [[15, "support-vector-machines-svms-with-rbf-kernel-video"], [21, "support-vector-machines-svms-with-rbf-kernel-video"], [31, "support-vector-machines-svms-with-rbf-kernel-video"]], "Support vectors": [[15, "support-vectors"], [21, "support-vectors"], [31, "support-vectors"]], "Survival analysis": [[52, "survival-analysis"]], "Survival plots": [[47, "survival-plots"]], "Syllabus": [[1, "syllabus"], [56, null]], "TAs": [[1, "tas"], [56, "tas"]], "Tabular data": [[13, "tabular-data"], [19, "tabular-data"], [29, "tabular-data"]], "Take-home message": [[42, "take-home-message"]], "Teaching Team": [[56, "teaching-team"]], "Terminology": [[45, "terminology"]], "Terminology [video]": [[13, "terminology-video"], [19, "terminology-video"], [29, "terminology-video"]], "Testing your git installation": [[5, "testing-your-git-installation"]], "The Netflix prize": [[38, "the-netflix-prize"]], "The __ syntax": [[35, "the-syntax"]], "The best features may be dependent on the model you use.": [[40, "the-best-features-may-be-dependent-on-the-model-you-use"]], "The golden rule <a name=\"4\"></a>": [[14, "the-golden-rule"], [20, "the-golden-rule"], [30, "the-golden-rule"]], "The random forests classifier": [[38, "the-random-forests-classifier"]], "The sigmoid function": [[34, "the-sigmoid-function"]], "The teaching team": [[1, "the-teaching-team"]], "The \u201cfundamental tradeoff\u201d of supervised learning:": [[14, "the-fundamental-tradeoff-of-supervised-learning"], [20, "the-fundamental-tradeoff-of-supervised-learning"], [30, "the-fundamental-tradeoff-of-supervised-learning"]], "The \u201cperfect\u201d spaghetti sauce": [[41, "the-perfect-spaghetti-sauce"]], "Things to watch out for": [[48, "things-to-watch-out-for"]], "Time series": [[52, "time-series"]], "Time to event and censoring": [[47, "time-to-event-and-censoring"]], "Tokenization": [[44, "tokenization"]], "Topic modeling": [[44, "topic-modeling"]], "Topic modeling motivation": [[44, "topic-modeling-motivation"]], "Topic modeling pipeline": [[44, "topic-modeling-pipeline"]], "Topic modeling toy example": [[44, "topic-modeling-toy-example"]], "Toy datasets": [[13, "toy-datasets"], [29, "toy-datasets"]], "Traditional time series approaches": [[46, "traditional-time-series-approaches"]], "Train/test split for temporal data": [[46, "train-test-split-for-temporal-data"]], "Train/test splits": [[46, "train-test-splits"]], "Train/validation/test split": [[14, "train-validation-test-split"], [20, "train-validation-test-split"], [30, "train-validation-test-split"]], "Training a supervised machine learning model with X and y": [[12, "training-a-supervised-machine-learning-model-with-x-and-y"], [18, "training-a-supervised-machine-learning-model-with-x-and-y"], [28, "training-a-supervised-machine-learning-model-with-x-and-y"]], "Training data for the motivating example": [[34, "training-data-for-the-motivating-example"]], "Training error vs. Generalization error": [[14, "training-error-vs-generalization-error"], [20, "training-error-vs-generalization-error"], [30, "training-error-vs-generalization-error"]], "Training models with transformed data": [[17, "training-models-with-transformed-data"], [23, "training-models-with-transformed-data"], [33, "training-models-with-transformed-data"]], "Training on the full corpus": [[49, "training-on-the-full-corpus"]], "Training random forests and gradient boosted trees": [[48, "training-random-forests-and-gradient-boosted-trees"]], "Transfer learning": [[45, "transfer-learning"]], "Transformations on the toy data": [[17, "transformations-on-the-toy-data"], [23, "transformations-on-the-toy-data"], [33, "transformations-on-the-toy-data"]], "Transforming the targets": [[37, "transforming-the-targets"]], "Transparency and explainability of ML models: Motivation": [[39, "transparency-and-explainability-of-ml-models-motivation"]], "Tree-based ensemble models": [[38, "tree-based-ensemble-models"]], "Tree-based models": [[38, "tree-based-models"]], "Try out this moment predictor": [[49, "try-out-this-moment-predictor"]], "Tuning alpha hyperparameter of Ridge": [[37, "tuning-alpha-hyperparameter-of-ridge"]], "Tutorial 1": [[53, null]], "Tutorial 2": [[54, null]], "Tutorial 3": [[55, null]], "Types of censoring": [[47, "types-of-censoring"]], "Types of errors": [[14, "types-of-errors"], [20, "types-of-errors"], [30, "types-of-errors"]], "Types of machine learning": [[12, "types-of-machine-learning"], [18, "types-of-machine-learning"], [28, "types-of-machine-learning"], [41, "types-of-machine-learning"]], "Types of problems involving time series": [[46, "types-of-problems-involving-time-series"]], "Types of questions we might want to answer:": [[47, "types-of-questions-we-might-want-to-answer"]], "Typical steps to build a supervised machine learning model": [[25, "typical-steps-to-build-a-supervised-machine-learning-model"]], "UBC CPSC 330: Applied Machine Learning (2024W2)": [[1, null]], "Ubuntu Users": [[5, "ubuntu-users"]], "Underfitting": [[14, "underfitting"], [20, "underfitting"], [30, "underfitting"]], "Underfitting, overfitting, the fundamental trade-off, the golden rule [video]": [[14, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"], [20, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"], [30, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"]], "Undersampling": [[36, "undersampling"]], "Understanding the problem": [[49, "understanding-the-problem"]], "Unequally spaced time points": [[46, "unequally-spaced-time-points"]], "Unsupervised learning": [[41, "unsupervised-learning"]], "Updates to assignments": [[7, "updates-to-assignments"]], "Use of AI in the course": [[56, "use-of-ai-in-the-course"]], "Use our template to create a repository": [[7, "use-our-template-to-create-a-repository"]], "Using OVR and OVO as wrappers": [[51, "using-ovr-and-ovo-as-wrappers"]], "Using SMOTE": [[36, "using-smote"]], "Using Silhouette scores to select the number of clusters": [[41, "using-silhouette-scores-to-select-the-number-of-clusters"]], "Using multiple metrics in GridSearchCV or RandomizedSearchCV": [[37, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"]], "Using pre-trained models as feature extractor": [[45, "using-pre-trained-models-as-feature-extractor"]], "Using pre-trained models out-of-the-box": [[45, "using-pre-trained-models-out-of-the-box"]], "Using regression metrics with scikit-learn": [[37, "using-regression-metrics-with-scikit-learn"]], "Viewing the transformed data as a dataframe": [[17, "viewing-the-transformed-data-as-a-dataframe"], [23, "viewing-the-transformed-data-as-a-dataframe"], [33, "viewing-the-transformed-data-as-a-dataframe"]], "Virtual environment": [[10, "virtual-environment"]], "Visualization": [[9, "visualization"]], "Visualizing the parameter grid as a heatmap": [[35, "visualizing-the-parameter-grid-as-a-heatmap"]], "Visualizing your results": [[48, "visualizing-your-results"]], "Warning": [[13, null], [19, null], [29, null]], "Warnings about feature selection": [[40, "warnings-about-feature-selection"], [40, "id8"]], "Weaknesses": [[38, "weaknesses"]], "Web app on a real server": [[49, "web-app-on-a-real-server"]], "Web app on local server": [[49, "web-app-on-local-server"]], "What all transformations we need to apply on the dataset?": [[16, "what-all-transformations-we-need-to-apply-on-the-dataset"], [32, "what-all-transformations-we-need-to-apply-on-the-dataset"]], "What and Why": [[10, "what-and-why"]], "What are git and GitHub?": [[5, null]], "What are the options?": [[16, "what-are-the-options"], [22, "what-are-the-options"], [32, "what-are-the-options"]], "What are we exactly learning?": [[34, "what-are-we-exactly-learning"]], "What did we cover?": [[43, "what-did-we-cover"], [49, "what-did-we-cover"]], "What did we learn today?": [[14, "what-did-we-learn-today"], [16, "what-did-we-learn-today"], [17, "what-did-we-learn-today"], [20, "what-did-we-learn-today"], [22, "what-did-we-learn-today"], [23, "what-did-we-learn-today"], [30, "what-did-we-learn-today"], [32, "what-did-we-learn-today"], [33, "what-did-we-learn-today"], [36, "what-did-we-learn-today"], [37, "what-did-we-learn-today"], [48, "what-did-we-learn-today"]], "What does this have to do with applied ML?": [[48, "what-does-this-have-to-do-with-applied-ml"]], "What does this mean for us, when we\u2019re trying to make claims about our data?": [[48, "what-does-this-mean-for-us-when-we-re-trying-to-make-claims-about-our-data"]], "What if we apply OHE?": [[17, "what-if-we-apply-ohe"], [23, "what-if-we-apply-ohe"], [33, "what-if-we-apply-ohe"]], "What is Natural Language Processing (NLP)?": [[44, "what-is-natural-language-processing-nlp"]], "What is a recommender system?": [[43, "what-is-a-recommender-system"]], "What is clustering?": [[41, "what-is-clustering"]], "What is deployment?": [[49, "what-is-deployment"]], "What is feature engineering?": [[40, "what-is-feature-engineering"]], "What is feature selection?": [[40, "what-is-feature-selection"]], "What is grid search?": [[48, "what-is-grid-search"]], "What is model interpretability?": [[39, "what-is-model-interpretability"]], "What is supervised machine learning (ML)?": [[12, "what-is-supervised-machine-learning-ml"], [18, "what-is-supervised-machine-learning-ml"], [28, "what-is-supervised-machine-learning-ml"]], "What is \u201cpositive\u201d and \u201cnegative\u201d?": [[36, "what-is-positive-and-negative"]], "What kind of estimators can we combine?": [[38, "what-kind-of-estimators-can-we-combine"]], "What next?": [[49, "what-next"]], "What should be the loss? (Activity: 4 mins)": [[48, "what-should-be-the-loss-activity-4-mins"]], "What to look for in these plots?": [[41, "what-to-look-for-in-these-plots"]], "What transformations do we need to apply on the dataset?": [[22, "what-transformations-do-we-need-to-apply-on-the-dataset"]], "What would I do differently?": [[49, "what-would-i-do-differently"]], "What\u2019s the problem?": [[16, "what-s-the-problem"], [22, "what-s-the-problem"], [32, "what-s-the-problem"]], "When can we use broadcasting?": [[8, "when-can-we-use-broadcasting"]], "When experimenting, show the results asap": [[48, "when-experimenting-show-the-results-asap"]], "When is it OK to do things before splitting?": [[16, "when-is-it-ok-to-do-things-before-splitting"], [22, "when-is-it-ok-to-do-things-before-splitting"], [32, "when-is-it-ok-to-do-things-before-splitting"]], "When test score is much lower than CV score": [[35, "when-test-score-is-much-lower-than-cv-score"]], "Which model should I use?": [[38, "which-model-should-i-use"]], "Which type of error is more important?": [[36, "which-type-of-error-is-more-important"]], "Why do we need a test set?": [[35, "why-do-we-need-a-test-set"]], "Why do we want this information?": [[39, "why-do-we-want-this-information"]], "Why does it matter": [[20, "why-does-it-matter"]], "Why feature selection?": [[40, "why-feature-selection"]], "Why machine learning (ML)? [video]": [[12, "why-machine-learning-ml-video"], [18, "why-machine-learning-ml-video"], [28, "why-machine-learning-ml-video"]], "Why model transparency/interpretability?": [[39, "why-model-transparency-interpretability"]], "Why neural networks?": [[45, "why-neural-networks"], [45, "id1"]], "Why not neural networks?": [[45, "why-not-neural-networks"], [45, "id2"]], "Why should I use it?": [[48, "why-should-i-use-it"]], "Why should we care about effective communication?": [[48, "why-should-we-care-about-effective-communication"]], "Why should we care about recommendation systems?": [[43, "why-should-we-care-about-recommendation-systems"]], "Why sparse matrices?": [[17, "why-sparse-matrices"], [23, "why-sparse-matrices"], [33, "why-sparse-matrices"]], "Windows": [[10, "windows"]], "Windows Users": [[5, "windows-users"]], "Word embeddings": [[44, "word-embeddings"]], "Word vectors with spaCy": [[44, "word-vectors-with-spacy"]], "Writing a traditional program to predict quiz2 grade": [[13, "writing-a-traditional-program-to-predict-quiz2-grade"], [19, "writing-a-traditional-program-to-predict-quiz2-grade"], [29, "writing-a-traditional-program-to-predict-quiz2-grade"]], "XGBoost": [[38, "xgboost"]], "[Optional] Jupyterlab and Python": [[10, "optional-jupyterlab-and-python"]], "[] notation": [[8, "notation"]], "announcements": [[15, "announcements"]], "class_weight=\"balanced\"": [[36, "class-weight-balanced"]], "cross_val_score": [[14, "cross-val-score"], [20, "cross-val-score"], [30, "cross-val-score"]], "cross_validate": [[14, "cross-validate"], [20, "cross-validate"], [30, "cross-validate"]], "fit and transform paradigm for transformers": [[16, "fit-and-transform-paradigm-for-transformers"], [22, "fit-and-transform-paradigm-for-transformers"], [32, "fit-and-transform-paradigm-for-transformers"]], "fit the classifier": [[13, "fit-the-classifier"], [19, "fit-the-classifier"], [29, "fit-the-classifier"]], "fit, predict , and score summary": [[13, "fit-predict-and-score-summary"], [19, "fit-predict-and-score-summary"], [29, "fit-predict-and-score-summary"]], "iClicker": [[56, "iclicker"]], "iClicker Exercise 10.1": [[37, "iclicker-exercise-10-1"]], "iClicker Exercise 10.2": [[37, "iclicker-exercise-10-2"]], "iClicker Exercise 12.0": [[38, "iclicker-exercise-12-0"]], "iClicker Exercise 12.1": [[38, "iclicker-exercise-12-1"]], "iClicker Exercise 14.1": [[40, "iclicker-exercise-14-1"]], "iClicker Exercise 19.1": [[45, "iclicker-exercise-19-1"]], "iClicker Exercise 2.1 Supervised vs unsupervised": [[19, "iclicker-exercise-2-1-supervised-vs-unsupervised"]], "iClicker Exercise 2.2 Classification vs regression": [[19, "iclicker-exercise-2-2-classification-vs-regression"]], "iClicker Exercise 2.2 Supervised vs unsupervised": [[13, "iclicker-exercise-2-2-supervised-vs-unsupervised"], [29, "iclicker-exercise-2-2-supervised-vs-unsupervised"]], "iClicker Exercise 2.3 Classification vs regression": [[13, "iclicker-exercise-2-3-classification-vs-regression"], [29, "iclicker-exercise-2-3-classification-vs-regression"]], "iClicker Exercise 2.4: Baselines and decision trees": [[19, "iclicker-exercise-2-4-baselines-and-decision-trees"]], "iClicker Exercise 2.5: Baselines and decision trees": [[13, "iclicker-exercise-2-5-baselines-and-decision-trees"], [29, "iclicker-exercise-2-5-baselines-and-decision-trees"]], "iClicker Exercise 3.1": [[14, "iclicker-exercise-3-1"], [20, "iclicker-exercise-3-1"], [30, "iclicker-exercise-3-1"]], "iClicker Exercise 3.2": [[14, "iclicker-exercise-3-2"], [20, "iclicker-exercise-3-2"], [30, "iclicker-exercise-3-2"]], "iClicker Exercise 9.1": [[36, "iclicker-exercise-9-1"]], "iClicker Exercise 9.2": [[36, "iclicker-exercise-9-2"]], "k-Nearest Neighbours (k-NNs) [video]": [[15, "k-nearest-neighbours-k-nns-video"], [21, "k-nearest-neighbours-k-nns-video"], [31, "k-nearest-neighbours-k-nns-video"]], "k-nearest neighbours imputation": [[43, "k-nearest-neighbours-imputation"]], "macOS": [[10, "macos"]], "n_iter": [[35, "n-iter"]], "n_jobs=-1": [[35, "n-jobs-1"]], "pandas_profiler": [[37, "pandas-profiler"]], "predict the target of given examples": [[13, "predict-the-target-of-given-examples"], [19, "predict-the-target-of-given-examples"], [29, "predict-the-target-of-given-examples"]], "predict_proba": [[34, "predict-proba"]], "random_state argument": [[14, "random-state-argument"], [20, "random-state-argument"], [30, "random-state-argument"]], "score your model": [[13, "score-your-model"], [19, "score-your-model"], [29, "score-your-model"]], "sklearn API summary: estimators": [[16, "sklearn-api-summary-estimators"], [22, "sklearn-api-summary-estimators"], [32, "sklearn-api-summary-estimators"]], "sklearn API summary: transformers": [[16, "sklearn-api-summary-transformers"], [22, "sklearn-api-summary-transformers"], [32, "sklearn-api-summary-transformers"]], "sklearn set_config": [[17, "sklearn-set-config"], [23, "sklearn-set-config"], [33, "sklearn-set-config"]], "sklearn\u2019s ColumnTransformer": [[17, "sklearn-s-columntransformer"], [23, "sklearn-s-columntransformer"], [33, "sklearn-s-columntransformer"]], "sklearn\u2019s SimpleImputer": [[27, "sklearn-s-simpleimputer"]], "sklearn\u2019s feature_importances_ and permutation_importance": [[39, "sklearn-s-feature-importances-and-permutation-importance"]], "sklearn\u2019s feature_importances_ attribute vs permutation_importance": [[39, "sklearn-s-feature-importances-attribute-vs-permutation-importance"]], "spaCy": [[50, "spacy"]], "test score vs. cross-validation score": [[14, "test-score-vs-cross-validation-score"], [20, "test-score-vs-cross-validation-score"], [30, "test-score-vs-cross-validation-score"]], "test_size, train_size arguments": [[14, "test-size-train-size-arguments"], [20, "test-size-train-size-arguments"], [30, "test-size-train-size-arguments"]], "\u201cDeployment\u201d data": [[14, "deployment-data"], [20, "deployment-data"], [30, "deployment-data"]], "\u2753\u2753 Questions for group discussion": [[36, "questions-for-group-discussion"]], "\u2753\u2753 Questions for you": [[12, "questions-for-you"], [13, "questions-for-you"], [13, "id1"], [13, "id3"], [14, "questions-for-you"], [14, "id1"], [15, "questions-for-you"], [15, "id2"], [16, "questions-for-you"], [16, "id1"], [16, "id2"], [17, "questions-for-you"], [17, "id1"], [18, "questions-for-you"], [19, "questions-for-you"], [19, "id1"], [20, "questions-for-you"], [20, "id1"], [21, "questions-for-you"], [21, "id1"], [22, "questions-for-you"], [22, "id1"], [22, "id2"], [23, "questions-for-you"], [23, "id1"], [28, "questions-for-you"], [29, "questions-for-you"], [29, "id1"], [29, "id3"], [30, "questions-for-you"], [30, "id1"], [31, "questions-for-you"], [31, "id1"], [32, "questions-for-you"], [32, "id1"], [32, "id2"], [33, "questions-for-you"], [33, "id1"], [34, "questions-for-you"], [34, "id1"], [34, "id2"], [35, "questions-for-you"], [35, "id2"], [36, "questions-for-you"], [36, "id2"], [37, "questions-for-you"], [37, "id2"], [38, "questions-for-you"], [38, "id1"], [38, "id2"], [40, "questions-for-you"], [41, "questions-for-you"], [41, "id2"], [42, "questions-for-you"], [42, "id3"], [43, "questions-for-you"], [43, "id1"], [43, "id2"], [45, "questions-for-you"], [46, "questions-for-you"], [46, "id1"], [46, "id2"], [46, "id3"], [47, "questions-for-you"], [47, "id1"], [47, "id2"], [47, "id3"], [47, "id4"], [48, "questions-for-you"], [48, "id1"], [49, "questions-for-you"], [49, "id2"]], "\ud83e\udd14 Eva\u2019s questions": [[12, "eva-s-questions"], [14, "eva-s-questions"], [18, "eva-s-questions"], [28, "eva-s-questions"], [30, "eva-s-questions"]]}, "docnames": ["LICENSE", "README", "docs/330_vs_340", "docs/README", "docs/asking_for_help", "docs/git_installation", "docs/grades", "docs/homework_instructions", "docs/python_notes", "docs/resources", "docs/setup", "learning-objectives", "lectures/201-Lecuyer-lectures/01_intro", "lectures/201-Lecuyer-lectures/02_terminology-decision-trees", "lectures/201-Lecuyer-lectures/03_ml-fundamentals", "lectures/201-Lecuyer-lectures/04_kNNs-SVM-RBF", "lectures/201-Lecuyer-lectures/05_preprocessing-pipelines", "lectures/201-Lecuyer-lectures/06_column-transformer-text-feats", "lectures/202-203-Giulia-lectures/01_intro", "lectures/202-203-Giulia-lectures/02_terminology-decision-trees", "lectures/202-203-Giulia-lectures/03_ml-fundamentals", "lectures/202-203-Giulia-lectures/04_kNNs-SVM-RBF", "lectures/202-203-Giulia-lectures/05_preprocessing-pipelines", "lectures/202-203-Giulia-lectures/06_column-transformer-text-feats", "lectures/204-Andy-lectures/README", "lectures/204-Andy-lectures/class_demos/demo_03-ml-fundamentals", "lectures/204-Andy-lectures/class_demos/demo_04-kNNs-SVMs", "lectures/204-Andy-lectures/class_demos/demo_05-06-preprocessing", "lectures/notes/01_intro", "lectures/notes/02_terminology-decision-trees", "lectures/notes/03_ml-fundamentals", "lectures/notes/04_kNNs-SVM-RBF", "lectures/notes/05_preprocessing-pipelines", "lectures/notes/06_column-transformer-text-feats", "lectures/notes/07_linear-models", "lectures/notes/08_hyperparameter-optimization", "lectures/notes/09_classification-metrics", "lectures/notes/10_regression-metrics", "lectures/notes/12_ensembles", "lectures/notes/13_feat-importances", "lectures/notes/14_feature-engineering-selection", "lectures/notes/15_K-Means", "lectures/notes/16_DBSCAN-hierarchical", "lectures/notes/17_recommender-systems", "lectures/notes/18_natural-language-processing", "lectures/notes/19_intro_to_computer-vision", "lectures/notes/20_time-series", "lectures/notes/21_survival-analysis", "lectures/notes/22_communication", "lectures/notes/24_deployment-conclusion", "lectures/notes/appendixA_feature-engineering-text-data", "lectures/notes/appendixB_multiclass-strategies", "lectures/notes/final-exam-review-guiding-question", "lectures/tutorials/01_decision_boundaries", "lectures/tutorials/02_ML_fundamentals", "lectures/tutorials/03_Preprocessing", "syllabus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["LICENSE.md", "README.md", "docs/330_vs_340.md", "docs/README.md", "docs/asking_for_help.md", "docs/git_installation.md", "docs/grades.md", "docs/homework_instructions.md", "docs/python_notes.ipynb", "docs/resources.md", "docs/setup.md", "learning-objectives.md", "lectures/201-Lecuyer-lectures/01_intro.ipynb", "lectures/201-Lecuyer-lectures/02_terminology-decision-trees.ipynb", "lectures/201-Lecuyer-lectures/03_ml-fundamentals.ipynb", "lectures/201-Lecuyer-lectures/04_kNNs-SVM-RBF.ipynb", "lectures/201-Lecuyer-lectures/05_preprocessing-pipelines.ipynb", "lectures/201-Lecuyer-lectures/06_column-transformer-text-feats.ipynb", "lectures/202-203-Giulia-lectures/01_intro.ipynb", "lectures/202-203-Giulia-lectures/02_terminology-decision-trees.ipynb", "lectures/202-203-Giulia-lectures/03_ml-fundamentals.ipynb", "lectures/202-203-Giulia-lectures/04_kNNs-SVM-RBF.ipynb", "lectures/202-203-Giulia-lectures/05_preprocessing-pipelines.ipynb", "lectures/202-203-Giulia-lectures/06_column-transformer-text-feats.ipynb", "lectures/204-Andy-lectures/README.md", "lectures/204-Andy-lectures/class_demos/demo_03-ml-fundamentals.ipynb", "lectures/204-Andy-lectures/class_demos/demo_04-kNNs-SVMs.ipynb", "lectures/204-Andy-lectures/class_demos/demo_05-06-preprocessing.ipynb", "lectures/notes/01_intro.ipynb", "lectures/notes/02_terminology-decision-trees.ipynb", "lectures/notes/03_ml-fundamentals.ipynb", "lectures/notes/04_kNNs-SVM-RBF.ipynb", "lectures/notes/05_preprocessing-pipelines.ipynb", "lectures/notes/06_column-transformer-text-feats.ipynb", "lectures/notes/07_linear-models.ipynb", "lectures/notes/08_hyperparameter-optimization.ipynb", "lectures/notes/09_classification-metrics.ipynb", "lectures/notes/10_regression-metrics.ipynb", "lectures/notes/12_ensembles.ipynb", "lectures/notes/13_feat-importances.ipynb", "lectures/notes/14_feature-engineering-selection.ipynb", "lectures/notes/15_K-Means.ipynb", "lectures/notes/16_DBSCAN-hierarchical.ipynb", "lectures/notes/17_recommender-systems.ipynb", "lectures/notes/18_natural-language-processing.ipynb", "lectures/notes/19_intro_to_computer-vision.ipynb", "lectures/notes/20_time-series.ipynb", "lectures/notes/21_survival-analysis.ipynb", "lectures/notes/22_communication.ipynb", "lectures/notes/24_deployment-conclusion.ipynb", "lectures/notes/appendixA_feature-engineering-text-data.ipynb", "lectures/notes/appendixB_multiclass-strategies.ipynb", "lectures/notes/final-exam-review-guiding-question.ipynb", "lectures/tutorials/01_decision_boundaries.ipynb", "lectures/tutorials/02_ML_fundamentals.ipynb", "lectures/tutorials/03_Preprocessing.ipynb", "syllabus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 4, 5, 7, 8, 9, 10, 13, 19, 20, 25, 26, 29, 34, 35, 38, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56], "0": [0, 1, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56], "00": [1, 12, 13, 15, 17, 18, 23, 25, 27, 28, 29, 31, 33, 34, 35, 36, 39, 42, 43, 46, 47, 48, 56], "000": [12, 14, 15, 16, 18, 20, 21, 22, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 44, 45, 47, 50], "0000": [16, 22, 32, 34, 36, 44, 50], "00000": [35, 46], "000000": [13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 46, 47], "00000000e": 39, "000000e": [27, 35], "000001": 37, "00000e": [15, 31], "000010": 37, "000011": 36, "000021": [16, 22, 32], "000036": 36, "000057": [16, 22, 32], "000065": 35, "000067": 35, "000077": 35, "000087": 34, "000089": 34, "0001": [34, 36, 37, 47, 48], "000100": [16, 22, 32, 37], "000102e": 25, "000108": 34, "000113": 36, "000114": 35, "000117": 37, "000128": 26, "000130": 34, "000136": 45, "000137": 35, "000144": 26, "000145": 35, "000146": 34, "000147": 35, "000149": [16, 22, 26, 32], "000150": 34, "000151": 35, "000154": 26, "000155": [16, 22, 32, 36], "000156": 26, "000159": 35, "000162": 26, "000163": [26, 35], "000166": [34, 35], "000175": 26, "000177": [32, 46], "000179": 26, "000180": 32, "000181": 35, "000182": 34, "000183": 34, "000187": [26, 34], "000188": 32, "000190": 46, "000192": [16, 46], "000194": 34, "000195": 32, "000197": 16, "000198": 36, "000201": 35, "000203": 16, "000206": 35, "000208": [16, 22, 32], "000210": 35, "000212": 40, "000213": 34, "000218": [22, 34], "000221": 37, "000222": 22, "000225": 16, "000226": 37, "000227": 36, "000228": 22, "000231": 32, "000232": 45, "000234": [15, 31, 35], "000235": [26, 32, 36], "000236": 26, "000240": 32, "000241": [22, 26], "000245": 35, "000247": 45, "000248": [16, 26], "000255": 34, "000256": 46, "000259": 32, "000260": 32, "000261": 16, "000265": 26, "000267": 16, "000270": 26, "000271": 46, "000273": 45, "000274": 45, "000278": 22, "000279": 22, "000281": [26, 34], "000283": [27, 34], "000285": [22, 34], "000286": 35, "000289": [16, 22, 32], "000294": 35, "000296": 26, "000304": 16, "000306": 22, "000308": 27, "000310": 26, "000312": [27, 36], "000313": 26, "000314": 27, "000316": 26, "000321": 26, "000328": 26, "000329": 26, "000332": 37, "000336": 45, "000339": 35, "000342": 22, "000348": 35, "000353": 35, "000354": 35, "000363": 45, "000366": 36, "000370": 35, "000371": 34, "000373": 37, "000374": 26, "000378": 34, "00038": 35, "000387": 26, "000397": 37, "000399": 45, "000420": 26, "000423": 26, "000428": [26, 27], "000432": 26, "000433": 37, "000434": 14, "000435": [14, 45], "000437": 45, "000438": 14, "000441": [14, 26], "000445": 14, "000448": 14, "000450": 27, "000451": 14, "000452": [27, 32], "000459": [14, 34], "000460": 26, "000463": 14, "000471": [14, 46], "000472": 45, "000475": 26, "000477": 20, "000480": [20, 26], "000489": [27, 35], "000492": 36, "000496": 20, "000498": 46, "0005": 48, "000500": 14, "000502": [20, 22], "000503": [15, 35], "000508": 35, "000511": 14, "000520": [26, 37], "000524": 14, "000528": 15, "000534": 20, "000540": 26, "000542": 26, "000545": 15, "000548": 15, "000549": 15, "000551": 20, "000558": 20, "000561": [15, 26], "000575": 46, "00058": 35, "000580": 31, "000587": 16, "000602": 15, "000607": 15, "000610": 20, "000612": 15, "000625": 15, "000626": 14, "000630": 36, "000633": 31, "000636": 14, "000637": [14, 45], "000639": 14, "000640": 15, "000642": 14, "000644": 14, "000645": 26, "000646": 14, "000647": 31, "000650": 31, "000651": 31, "000652": [14, 37], "000655": [14, 31], "000657": 14, "000661": 31, "000664": 14, "000666": 15, "000671": 31, "000675": [14, 21], "000678": 35, "000683": 15, "000685": 26, "000686": 14, "000691": 20, "000696": 20, "000697": 15, "000700": 21, "000701": [15, 20], "000707": 20, "000710": 21, "000711": 20, "000712": 20, "000713": [26, 37], "000714": 21, "000720": 20, "000722": 14, "000726": 36, "000728": 21, "000729": 27, "000736": 21, "000737": 46, "000739": 21, "000740": 26, "000742": 15, "000746": 15, "000747": 35, "000748": 32, "000752": [15, 31], "000757": 14, "000758": 45, "000765": 32, "000774": 32, "000786": 36, "000787": 31, "00079": 35, "000794": 31, "000795": 31, "000797": 31, "000800": 14, "000803": 37, "000805": 15, "000812": [14, 26], "000815": 15, "000816": 20, "000820": 15, "000823": 20, "000829": [26, 31], "000831": 31, "000832": 37, "000839": [20, 21, 26], "000842": 15, "000851": 21, "000867": 32, "000869": 46, "000870": 20, "000873": 31, "000881": 22, "000889": [27, 31], "000890": 26, "000891": 36, "000894": 22, "000902": 16, "000917": 35, "000927": 36, "000934": 26, "000936": 31, "000944": 15, "000945": 40, "000950": 21, "000952": 22, "000960": 45, "000964": 40, "000967": 21, "000969": 21, "000975": 14, "000976": 35, "000977": 31, "000982": 35, "000997": 16, "001": [12, 14, 15, 16, 18, 21, 22, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 45, 47, 48, 50], "0010": 34, "00100": 35, "001000": [35, 37], "001002": 30, "001006": 30, "001010": 30, "001011": [14, 31, 37], "001014": [16, 30], "001016": 30, "001017": 30, "001021": 14, "001026": 30, "001027": 30, "001029": 30, "001038": 30, "001043": 32, "001057": [30, 35], "001060": [16, 22, 32], "001063": 30, "001064": 45, "001068": 39, "001071": 30, "001078": 30, "001079": 22, "001082": 20, "001086": 30, "001087": 40, "001103": 30, "001109": 26, "001111": 30, "001113": 20, "001116": 21, "001126": 21, "001139": 31, "001144": 14, "001145": 15, "001146": 21, "001149": 30, "001155": 40, "001162": [35, 40], "001174": 30, "001178": 26, "001179": 15, "001200": 16, "001204": 15, "001205": 36, "001220": 34, "001224": 31, "001226": 45, "001230": 26, "001236": 35, "001239": 36, "001260": 15, "001266": 37, "001271": 15, "001272": 16, "001279": 40, "001282": 15, "001286": 36, "001294": 30, "001299": 30, "001302": 21, "001305": 30, "001307": 30, "001315": 30, "001317": 30, "001322": 30, "001323": 30, "001325": 31, "001329": 30, "001337": 30, "001338": [21, 34], "001344": 15, "001347": 35, "001352": 30, "001361": 34, "001362": 34, "001365": 31, "001371": 33, "001375": 26, "001390": 30, "001391": 30, "001392": 31, "001400": 33, "001406": 37, "001407": 30, "001412": 35, "001414": 31, "001416": 15, "001419": 26, "001421": 36, "001422": 37, "001423": 35, "001429": 30, "001433": 37, "001441": 30, "001448": 33, "001453": 30, "00146": 35, "001466": 33, "001467": 35, "001492": 35, "001495": 31, "001511": 26, "001519": 15, "001521": 21, "001541": 21, "001563": 33, "001566": [26, 37], "001580": 21, "001585": 35, "001586": 31, "001591": 33, "001594": 35, "001595": 31, "001600": 31, "001604": 33, "001606": 33, "001608": 35, "001616": 35, "001620": 35, "001629": 35, "001641": 45, "001645": 34, "001647": 33, "001679": 35, "001682": 35, "001687": 26, "001693": 40, "001699": 30, "0017": 36, "001700": 36, "001710": 34, "001715": 33, "001730": 15, "001740": 37, "001769": 35, "001773": 31, "001776": 30, "001790": 37, "001792": 35, "001805": 15, "001807": 15, "001836": 15, "001847": 40, "001850": 34, "001873": 15, "001877": 31, "001882": 26, "001883": 17, "001888": 21, "001894": 37, "001900": 31, "001920": 33, "001922": 33, "001929": 17, "001933": 37, "001949": 40, "001952": 31, "001960": 17, "0019627889": 44, "001968": 30, "001994": 40, "002": [14, 30, 34, 38, 39, 44, 47], "002003": 35, "002021": 23, "002022": 33, "002030": 31, "002035": 23, "002045": 35, "002057": [16, 22, 32, 33], "002059": 23, "002069": 23, "002070": 23, "002083": 31, "002088": 17, "002092": 17, "002096": 45, "002105": 35, "002116": 33, "002118": 31, "002123": 35, "002143": 30, "002146": 35, "002158": 40, "002159": 35, "002189": 17, "002197": 35, "002218": 17, "002221": 37, "002224": 21, "002225": 21, "002231": 17, "002238": 17, "002251": 15, "002272": 17, "002317": 23, "002321": [26, 34], "00234": 35, "002351": 17, "002355": 40, "002367": 23, "002385": 37, "002418": 26, "002441": 40, "002460": 45, "002477": 26, "002478": 23, "002512": 23, "002516": 21, "002525": 45, "002549": 23, "002561": 35, "002564": 23, "002571": 23, "002643": 26, "002646": 40, "002664": 40, "002675": 35, "002682": 45, "002690": [16, 22, 32], "002692": 35, "002704": 35, "002711": 45, "002716": 21, "002720": 21, "002746": 37, "002783": 35, "002788": 33, "002789": 33, "002802": 26, "002807": 33, "002814": 22, "002818": 17, "002835": 35, "002842": 17, "002845": 23, "002848": 26, "002858": 33, "002867": 40, "002889": 36, "0029": 47, "002902": 17, "002910": 33, "002921": 26, "002928": 16, "002934": 34, "002940": 45, "002948": 31, "002949": 21, "002962": 45, "002965": 26, "002986": 45, "002987": 26, "002999": 35, "003": [35, 38], "003013": 33, "003014": 35, "003015": [23, 35], "003027": 35, "003038": [26, 35], "003044": 26, "003052": 16, "003066": 16, "003083": 35, "003086": 33, "003088": 26, "003106": 16, "003113": 16, "003115": 33, "003124": [36, 37], "003133": 37, "003146": 33, "003148": 34, "003166": [32, 40], "003181": 32, "003183": 40, "003185": 47, "003186": 33, "003188": [32, 33], "003194": 34, "003210": 26, "003212": 32, "003218": 21, "003224": 21, "003232": 17, "003242": 45, "003257": 45, "003272": 26, "003273": 30, "003283": 45, "003284": 21, "003288": 37, "003300": [16, 22, 32], "003316": 22, "00332": 35, "003324": 32, "003365": 33, "003388": 22, "003401": 40, "003421": 35, "003423": 40, "003427": 40, "003442": 22, "003463": 26, "003472": 35, "003477": 45, "003479": [22, 35], "003483": 35, "003493": 40, "003507": 17, "003519": 23, "003528": 35, "003529": 35, "003540": 26, "003547": 37, "003561": [14, 20], "003563": 35, "003565": 23, "003586": 23, "003593": 26, "003633": 35, "003647": 45, "003663": 26, "003665": 17, "003666": [17, 22], "00369": 35, "003736": 23, "003748": 35, "003749": 17, "003757": 35, "003785": [26, 37], "003820": 23, "003877": 26, "003885": 35, "003898": 21, "003902": 17, "003904": 23, "003910": 26, "003913": 17, "003919": [26, 35], "003919287722401839": 35, "00392157": 45, "003923": 33, "003924": 40, "003933": 35, "003936": 17, "003949": 23, "003951": 17, "003968": 17, "003998": 35, "004": [15, 31, 35, 38, 39, 45], "004057": 35, "004065": 46, "004081": 17, "004082": 46, "004121": 37, "004143": 37, "004203": 23, "004262": 23, "004264": [14, 20, 30], "004293": 35, "004305": 35, "004337": 35, "00435173": 41, "004352": 41, "004358": 23, "004373": 17, "004398": 39, "004402": 35, "004461": 26, "004462": 21, "004466": 35, "004469": 26, "004496": 35, "004521": 37, "004529": 39, "004556": 35, "004574": 37, "004594": 26, "004602": 37, "00461": 35, "004713": 17, "004714": 35, "004723": 39, "004745": 23, "004761": 39, "004769": [14, 20], "004770": [16, 22, 32], "004801": [16, 22, 32, 33], "004807": 33, "004826": 37, "004829": 37, "004848": 16, "004852": 26, "004854": 37, "004884": 45, "004919": 35, "004952": 35, "004959": 35, "00496": 35, "004964": 17, "005": [12, 18, 28, 38, 39, 47, 48], "005067": 32, "005071": 23, "005074": 45, "005093": 32, "005098": 37, "005103": 16, "005114": 37, "005126": 35, "005136": 25, "005151": 35, "005157": 32, "005167": 37, "005191": 16, "005196": 35, "005204": 16, "005241": 37, "00525962": [16, 22, 32], "005269": 37, "005270": 26, "005288": 33, "005290": 16, "005309": 21, "005313": 21, "005335": 35, "005336": 37, "005373": 22, "005377": 22, "005387": 36, "005398": 22, "005423": 35, "005426": 35, "00543825": [16, 22, 32], "005440": 45, "005443": 21, "005478": 39, "00548": 35, "005508": 23, "005538": 37, "005563": 20, "005579": 37, "005593": 21, "005608": 17, "005622": 22, "005641": 37, "005674": 37, "005699": [14, 20, 30], "005708": 35, "00573": 35, "005734": 35, "005735": 35, "005767": 35, "005809": 46, "005834": 35, "005836": 32, "005868": 23, "005888": [16, 22, 32], "005963": 36, "006": [38, 39, 47], "006012": 35, "006046": 37, "006055": 35, "006067": 37, "006070": 26, "006106": 35, "006110": [15, 31, 35, 37], "006208": 26, "006236": [26, 37], "006244": 35, "006250": 26, "006435": 35, "006452": 34, "006465": 21, "006476": 37, "006505": 45, "006531": [14, 20, 30], "006545": 35, "006546893270012566": 34, "006557": 34, "006570": 22, "006578": [16, 22, 32, 33], "006649": 21, "006652": 35, "006667": [26, 35], "00667": 35, "006737": 23, "006744": 37, "006770": 26, "006805": [14, 20, 30], "006861": 35, "006904": 35, "00691": 35, "006973": 32, "006991": 17, "007": [22, 32, 38, 39, 47, 50], "007068": 40, "007116": 23, "00715": 35, "00720988e": 39, "007228": 37, "007291": 33, "007316": [14, 20, 30], "007362": 35, "007434": 39, "007438": 36, "007458": [16, 22, 32, 33], "007517": 37, "007542": 25, "007544": 35, "007563": 35, "007588": 41, "00758803": 41, "00759438": 39, "007655": 35, "007666": 36, "00767": 35, "007737": 37, "007776": 37, "007818": 35, "007926": 21, "007938": [14, 30], "007986": 37, "008": [16, 38, 39, 50], "008040": 46, "008120": 37, "008153": 35, "008167": [16, 22, 32, 33], "008286": 26, "00830586": [17, 23, 33], "008306": [17, 23, 33], "008322e": 47, "008333": 33, "008346": 37, "008377": 35, "008472": 37, "008498": 26, "008577": 45, "008581": 37, "008606": 37, "008617": 37, "008667": 35, "00871": 35, "008735": [15, 21, 31], "008785": 37, "008786": 36, "009": [33, 38, 47, 50], "009059": [14, 20, 30], "009063": 35, "009082": 35, "009090": 37, "009131": 26, "009132": 35, "009140": 37, "009260": 20, "009297": 35, "009305": 35, "009339": 37, "009422": [14, 30], "009512": 35, "009514e": 37, "009556": 36, "009664": 37, "009692": 45, "009703": 26, "009724": 40, "00pm": 1, "01": [15, 16, 21, 22, 27, 31, 32, 34, 35, 36, 37, 39, 45, 46, 47, 48, 51, 56], "010": [12, 18, 28, 34, 35, 47], "0100": 34, "01000": 35, "010000": [16, 22, 32, 35, 37], "010027": 34, "010183": [16, 22, 32, 33], "0102": [15, 31, 35], "010208": 40, "010294": [14, 20, 30], "010547": 20, "010650": [14, 20, 30], "010679": [14, 30], "010688": 40, "010715": 35, "010750": 40, "011": [12, 18, 28, 33, 45, 47], "011210": 40, "011234": 36, "011248": 37, "011252": 40, "011269e": 37, "011287": 40, "011332": 47, "011336": [15, 21, 31], "011415": 26, "011440": 37, "011617": 35, "011678": 36, "011767": 37, "011773": 38, "012": [16, 22, 32, 33, 38, 39, 45, 47, 50], "012019": [20, 30], "012030": 40, "012065": 14, "012232": 37, "012240": 40, "012247": 26, "012252": 35, "012616": 35, "012624": 37, "012758": 37, "013": 16, "013031": 37, "01311996071": 37, "013120": 39, "013157": 35, "013161": 35, "013433": [15, 21, 31], "013629": 35, "013706928443177698": 35, "013707": 35, "013863": 35, "013888": 35, "014": [16, 22, 30, 32, 38, 39, 47], "014030": 37, "014081e": 37, "01409912": 44, "014305": 37, "01432486e": 39, "014337": 26, "014481": 35, "014503": 35, "014650": 47, "014730": 33, "01473536": [15, 21, 31], "014758": 47, "014990": 26, "015": [12, 16, 18, 22, 28, 32, 33, 38, 47, 50], "015003": 35, "015039": 36, "015056": 35, "015165": 37, "015372": 35, "015639": 26, "015724": 40, "015755": 35, "015819": 35, "016263": 35, "016330": 26, "016372": 35, "01647": 35, "016525": [37, 39, 48], "016555": 34, "016587": 36, "016598": 35, "016602": 35, "016607": 35, "016660": 27, "016676": 41, "016688": [16, 22, 32, 40], "016693": 37, "016807": 34, "016815": 35, "016918": 36, "016944": [15, 21, 31], "017": [33, 45], "017185": 35, "017226": 37, "017308": 35, "017427": 35, "017561": 36, "017610": 39, "017696": 39, "017737": 39, "017741": 39, "017795": 26, "017829": 46, "017837": 35, "01784": 35, "017927": 35, "017951": 26, "017959e": 37, "017972": [16, 22, 32], "018": 38, "018014": 39, "018077": 35, "018178": [15, 21, 31], "018243": 35, "018310": [15, 21, 31], "018434": 46, "018459e": 37, "018487": 34, "0185": 34, "018505": 35, "018507e": 37, "018558": 35, "018581": 37, "018622": 27, "018653": 35, "018745": [12, 18, 28], "018789": 35, "018846": 35, "018854": 36, "019": [38, 50], "019012": 35, "019163": 35, "019293": 26, "019381838999846482": 35, "019382": 35, "019390": 36, "019396": 35, "019444": 33, "019446": 35, "019531": 36, "019556": 47, "0195598": 34, "019574": 35, "019603": 36, "019839": 35, "019963": 36, "02": [15, 16, 22, 25, 27, 31, 32, 33, 34, 35, 37, 39, 40, 46, 47, 55, 56], "020000": 26, "02000e": [15, 31], "020123": 37, "020273": 36, "020319": 36, "020403": 35, "020414": 35, "020641": 39, "020648": 37, "020653": [14, 20, 30], "020833": 43, "020862": 37, "020873": [16, 22, 32], "021": 38, "021082": 26, "021100": [16, 22, 32], "021281": 35, "021305": [15, 21, 31], "021345": 35, "021603": 45, "021721": 35, "021746": 35, "021862": 35, "021900": [15, 31, 35], "022039": 36, "022331": 39, "022433": 35, "022629": 35, "022686": 35, "022730": 26, "022848": [14, 20, 30], "022866": 36, "023": [38, 45], "023086": 47, "023105": 46, "023279": 27, "023305": 37, "023366": 40, "023511": 35, "023554": 37, "023636": 36, "023666": 35, "023810": 50, "024": 38, "024028": 35, "024122": 35, "024291": 46, "024351e": 37, "024390": 40, "02446630e": 39, "024540": [16, 22, 32], "024944": 26, "025": [32, 36], "025381": [39, 48], "025391": [16, 22, 32, 33], "025396": 35, "025460": 26, "025489": 39, "025689": 35, "025910": [15, 21, 31], "025998": [16, 22, 32, 33], "026": 47, "0261": [15, 31, 35], "026616": 26, "026620": 35, "026667": 26, "026777": 35, "02677733855112973": 35, "026793": [37, 39, 48], "026972": 37, "027070": 37, "027079": 26, "027112": 46, "027321": 40, "027484": 37, "027578": 37, "028023": 36, "02807617": 44, "028186": 26, "028337": 35, "028351": 35, "028420": 37, "028672": 40, "028772": 37, "029": 44, "029146": 36, "029164": 46, "029198": 35, "029264": 37, "029396": 26, "029409": 37, "029475": 37, "029909": [14, 30], "029950e": 37, "02d": 46, "03": [1, 16, 25, 34, 35, 37, 39, 45, 46, 47, 50, 56], "030": 39, "03017665e": 39, "030200": [16, 22, 32], "030343": 37, "030349": 37, "030408": [15, 21, 31], "03049217": [15, 21, 31], "0305": [15, 21, 31], "030618": 20, "030739733331869412": 34, "030786": 37, "030805": 37, "031": 33, "031070": 37, "031385": [15, 21, 31], "031483": 37, "031564": [16, 22, 32], "031794": 37, "031863": 37, "0319": 44, "031994": 37, "032000": 26, "032140": 37, "032324": 35, "032404": 35, "032508": 36, "032566": [17, 23, 33], "03256625": [17, 23, 33], "032656": [15, 21, 31], "032660": 26, "032836": 36, "032874": [15, 21, 31], "033165": 37, "033222": 47, "033267": 46, "033279": 39, "033305": 45, "033322": 37, "033459": [15, 21, 31], "0335": 35, "033723": 37, "033739": 37, "033780": 47, "033815": 36, "033833": 36, "0339": [16, 22, 32], "033993": 26, "034071": 36, "03411038e": 39, "034132": 37, "0344": [15, 31, 35], "034894": 39, "034977": 37, "034979e": 37, "035": 45, "0351": [16, 22, 32], "03516073": 39, "035161": 39, "035223": 37, "035230": 46, "035722": 37, "036": [14, 16, 22, 32, 38, 45], "036136": 40, "0362": [16, 22, 32], "036646": 37, "036764": 36, "036886": 38, "0370": [16, 22, 32], "0373": [16, 22, 32], "037414": 46, "037785": 36, "0378": [16, 22, 32, 47], "038102": 34, "038609": 37, "038707": 39, "038873": 26, "038948": 37, "039": 45, "039498": 34, "039739": 26, "039741": 31, "0399": [16, 22, 32], "04": [16, 22, 25, 27, 32, 33, 35, 37, 39, 46, 47, 55, 56], "040": 38, "040000": 26, "040000e": 25, "040129": 47, "040497": 36, "040563": 26, "040698e": 37, "040954": 47, "040984": 46, "041": [38, 45], "041031": 36, "04108378": 34, "041084": 34, "041129": [15, 21, 31], "041201": 36, "041488": 37, "041704": 39, "041769": 37, "042081": 39, "042382": 40, "042743": 37, "042957": [16, 22, 32, 33], "043": 35, "043257": 33, "043319": 39, "043509": 35, "0437": [13, 14, 15, 20, 21, 29, 30, 31, 53], "043890": [15, 21, 31], "044": [15, 31, 35], "044029": [16, 22, 32, 33], "044166": 34, "044253": 39, "044313": [16, 22, 32], "044409": 37, "044614": 35, "044873": [14, 20, 30], "045": [13, 25, 29, 45], "045267": 46, "045304": [15, 21, 31], "045415": 32, "045481": 46, "046": 45, "04600e": [15, 31], "046020": [15, 21, 31], "046114": 26, "046116": 35, "046193e": 37, "046216": 35, "046638": 33, "0468": 47, "0469": [16, 22, 32], "046945": 35, "04709519e": 39, "0474": 34, "047567": 37, "047577": 16, "04774884": 41, "047749": 41, "047851": 22, "048": [14, 20, 30, 33], "048378": [14, 20, 30], "04861878": 41, "048630": 46, "048860": [16, 22, 32], "048889": 37, "048940": 14, "049": [33, 45], "049097": 26, "05": [15, 16, 22, 25, 27, 31, 32, 35, 36, 37, 42, 46, 47, 48, 56], "050": [12, 18, 28, 45], "050110e": 37, "050132": [16, 22, 32, 33], "051": 45, "051269": [16, 22, 32, 33], "05137470e": 39, "051392": 45, "051472": [15, 21, 31], "051620": [16, 22, 32], "051824": 37, "051925": 35, "052": [16, 22, 32], "052349": [16, 22, 32], "052607": 36, "052790": 36, "052819": 36, "05290827e": 39, "053156": 41, "05350962": 51, "0537": 35, "053763": [14, 20, 30], "053918": 35, "054054": 36, "054461": 36, "054653": [17, 23, 33], "05465323": [17, 23, 33], "054669": [37, 39, 48], "054784": [17, 23, 33], "05478443": [17, 23, 33], "055": [16, 22, 30, 32, 33], "055100": 35, "055398": 15, "055915e": 37, "05598498": [17, 23, 33], "055985": [17, 23, 33], "056": 45, "056478": [16, 22, 32, 33], "05656664": 44, "056599": 26, "056703": 36, "057": [16, 22, 32, 45], "057003": [15, 21, 31], "057082": 37, "057254": 47, "057296": 36, "057331": 37, "057646": [15, 21, 31], "057729": 36, "057732e": 47, "057793": [16, 22, 32, 33], "057910": [16, 22, 32, 33], "058": 38, "0580": [14, 20, 30, 34], "058176": 48, "058298": 37, "059": [12, 16, 18, 22, 28, 32], "059077": 36, "0591": [16, 22, 32], "059242": [16, 22, 32, 33], "059360": 45, "059588": 35, "059863": [15, 21, 31], "06": [16, 22, 25, 32, 35, 37, 42, 44, 45, 46, 47, 51, 56], "060": 45, "060477": 37, "060543": 40, "061100": [16, 22, 32], "061206": 36, "061241": [15, 21, 31], "061312": 37, "061313": 45, "061937": [15, 21, 31], "062": [12, 15, 18, 28, 31, 35], "062043": 35, "062449": 47, "062658e": 37, "062723": [20, 30], "062792": [15, 21, 31], "062793": 44, "063004": 40, "063110": [16, 22, 32, 33], "063173": 39, "064": [35, 39], "06405": 35, "064050": 35, "064200": [15, 21, 31], "064205": 14, "064307": 40, "064452": [15, 21, 31], "065": 45, "065018": 16, "065169": 35, "065449": 37, "065463": 36, "066166": 47, "066251": [20, 30], "066512": 26, "066605": 35, "066667": [16, 22, 32], "0667579112160865": 34, "066810": 47, "066944": 35, "066960": 14, "067099": 26, "067119": 32, "067120": [20, 30], "06797961": 37, "067991": [16, 22, 32], "068": [12, 18, 28], "068214": [34, 35], "068291": 45, "068428": 26, "068498": 35, "068775": 35, "068800e": 25, "068891": 35, "069": 25, "069150": 39, "06915047": 39, "069188": 47, "0694": [15, 31, 35], "069530": [15, 21, 31], "07": [1, 27, 35, 37, 40, 46, 47], "070047": 22, "070081": 35, "070195": 35, "070850": 36, "070898": 35, "070907": [14, 20, 30], "070929": 36, "071": 45, "071330": 46, "071541": [16, 22, 32, 33], "071654": 40, "07174469222": 37, "071745": 39, "071975": 40, "072": [16, 38], "072043": 35, "072243": 39, "0723": [16, 22, 32], "072396": 35, "07245741": 37, "072595": 35, "072707": [14, 30], "072966": 16, "073016": 48, "073058": 32, "073233": 34, "073366": 32, "074": [16, 22, 32, 38], "0741": [15, 21, 31], "074141": [15, 21, 31], "07418": 35, "074327": 38, "074418": 45, "074475": 32, "074556": 16, "074719": [17, 23, 33], "07471942": [17, 23, 33], "074773": 20, "074835": 16, "074853": 48, "075000": 43, "075170": 46, "075453": 47, "075467": 47, "075668": 26, "075747": 35, "076018": 26, "076104": 37, "0762": [16, 22, 32], "076284": 41, "076358": 22, "07639": 35, "076533": 37, "076798": [15, 21, 31], "076938": 22, "077": [38, 45], "077204": 39, "077749": 44, "077761": 47, "077803": 35, "078": [34, 38], "0780": [13, 14, 20, 29, 30, 53], "078052": 36, "07808506982896266": 37, "078243": 35, "078387": 47, "078552": 35, "078740": 35, "07877994e": 51, "078880": 33, "079": 35, "079181": 22, "079282": 35, "079377": 47, "0794": [15, 31, 35], "079471e": 37, "079852e": 37, "08": [16, 22, 32, 35, 37, 40, 42, 45, 46, 47], "080": 45, "08002986030": [17, 23, 33], "080084": 35, "080165": 35, "080319": [17, 23, 33], "08031924": [17, 23, 33], "080694": 39, "080734": 30, "0808": 35, "080847": 14, "081": [12, 18, 28], "08116": 35, "081167": 47, "081292": 46, "08151507e": 39, "081837": 47, "082": 32, "082100": 35, "082251": 34, "082265e": 47, "082749": [15, 21, 31], "082835": 39, "082949": [15, 21, 31], "083": [15, 31, 35, 38], "083123": [16, 22, 32, 33], "083338": [14, 20, 30], "08338644": 44, "083545": 36, "083615": 35, "083813": [16, 22, 32, 33], "083836": 14, "084288": 35, "084490": 48, "084683": 26, "084746": [16, 22, 32, 33], "084870": 20, "085150": 46, "085415": [39, 48], "085477": 36, "085508": 37, "085546": 37, "085550": 37, "085551": 37, "085693": 35, "085698": 37, "086078": 26, "08613": 35, "08642578": 44, "086461": 40, "086517": 25, "086932": 30, "087": 33, "087128": 35, "08740234": 44, "087668": 35, "08791477": 44, "087996e": 35, "088": 45, "0880": [16, 22, 32], "088373": 14, "088543": 35, "088948": [15, 21, 31], "089136": 20, "089294": 35, "089313": 35, "089354": [14, 20], "089485": [20, 30], "089892": 20, "09": [14, 20, 25, 30, 33, 35, 37, 46, 47], "090000": 36, "09009799": 37, "090231": 39, "090376e": 37, "090453": 36, "090473": 35, "090579": 26, "09058097218": [12, 18, 28], "090785": 37, "090951": 21, "090978": 25, "091": 45, "091243": 35, "091625": 40, "091632": 26, "091819": 30, "092": 38, "092072": 35, "092123": 35, "0922": [15, 31, 35], "092204": [14, 30], "092331": 14, "09245358900622544": 35, "092454": 35, "092604": [14, 20, 30], "092660": 47, "092669": 20, "092670": 35, "092729": 35, "092930": [17, 23, 33], "093051": 35, "0931": 35, "093228": 40, "093350": 48, "093390": [15, 21, 31], "093407": 36, "09345386": [17, 23, 33], "093454": [17, 23, 33], "093624": 30, "093787": 35, "093893": 35, "094": [12, 18, 28, 44], "094290": 47, "09430199": [17, 23, 33], "094302": [17, 23, 33], "094581": [17, 23, 33], "094586": 36, "094725": 35, "094863": 35, "095018": 35, "09503409246217484": 37, "095177": 35, "095345": 35, "09573445": 35, "09619141": 44, "096426": 20, "096462": 37, "096692": [16, 22, 32], "096722": 35, "096858": 35, "096927": 36, "096960": 37, "096990": 30, "096997": 45, "097": 45, "09706504": 45, "097088": 47, "097184": 35, "097293": [16, 22, 32, 33], "097516": [16, 22, 32], "097707": 35, "097763": 35, "097938": 20, "098": [34, 45], "098019": 14, "098152": 35, "098307": 37, "098326": [15, 21, 31, 45], "098559": 35, "098629e": 35, "098663": 35, "098787": 26, "0989147678053208": 34, "098915": 34, "098950": 35, "098966": [16, 22, 32], "099": 38, "099230": 39, "099240": [16, 22, 32, 33], "099454": 35, "099558": [16, 22, 32, 33], "099685": 37, "099723": [16, 22, 32], "099729": 35, "099749": 46, "099802": 35, "099869": 35, "0x1227a36e0": 8, "0x1577111f0": 35, "0x16888d4c0": 35, "0x168921100": 35, "1": [1, 7, 8, 9, 10, 25, 26, 27, 39, 44, 46, 49, 50, 51, 56], "10": [1, 4, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56], "100": [12, 13, 15, 16, 17, 21, 22, 23, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48], "1000": [12, 14, 15, 20, 21, 30, 31, 33, 34, 35, 36, 37, 39, 40, 45, 46, 47, 48, 50, 51], "10000": [12, 13, 25, 29, 33, 34, 35, 37, 46], "100000": [12, 15, 17, 21, 23, 31, 33, 34, 35, 37, 46], "1000000": [27, 35], "100103": 46, "100105": 35, "100139": [17, 23, 33], "100146": 46, "100248": [15, 21, 31], "100275": 40, "1004": [15, 21, 31], "1005": 46, "1006": 46, "1007": 46, "1008": 46, "10083": 25, "100882": 36, "1009": 46, "10092665203438746": 37, "101": [1, 9, 41, 45, 47, 56], "1010": 46, "1012": 46, "101259": 37, "101387": 20, "1014": [26, 35, 45], "1015": [26, 45, 46], "1016": [26, 45, 46], "101688": 35, "1017": [26, 45, 46], "101772": 14, "101796": 37, "1018": [26, 45, 46], "101810": 30, "101832": 35, "101894": 36, "1019": [26, 45, 46], "102": [27, 36, 37], "1020": [25, 26, 35, 40, 45, 46], "102044": 40, "1021": [26, 45, 46], "102135": 36, "1022": [26, 45, 46], "1023": [26, 45, 46], "1024": [26, 33, 45, 46], "102435": [15, 21, 31, 37], "102474": [17, 23, 33], "10247431": [17, 23, 33], "1025": 46, "10254": 46, "1026": [34, 46], "1027": 46, "10273": 37, "10274": 36, "1028": 46, "1029": 46, "103": 47, "103023": 35, "1031": 46, "103219": 40, "103222": 45, "1034": 40, "103439": [17, 23, 33], "1039": 46, "104": [15, 16, 21, 22, 31, 32, 38, 41, 45], "1040": [16, 22, 32], "104070": 37, "1041": [37, 39, 46, 50], "10416666666666667": 43, "1042": 35, "1043": [17, 23], "1044": [12, 18, 28], "104596": 35, "104643": 37, "105": [25, 38], "1050": [13, 25, 29], "105080": 40, "105089": [17, 23, 33], "10513": 46, "1052": 27, "1053": [27, 50], "105314": 46, "1054": 27, "1055": 27, "10556679": 41, "1056": 27, "105656": 39, "1057": 27, "1058": 27, "10584063": 45, "1059": 27, "106": 27, "106000": [16, 22, 32], "106023": 37, "106112": 46, "106180": 46, "106319": 46, "106322": 46, "106424": 46, "10644531": 44, "106452": [15, 21, 31], "10645223": [15, 21, 31], "10653": 46, "106705": 46, "106764": 35, "1068": 50, "106816": 46, "1069": 50, "10693359": 44, "106996": 35, "107": 38, "1070": 40, "107050": 46, "107292": 46, "107502": 46, "1076": [25, 33], "107718": 35, "10781": [38, 39], "107917": 46, "10793260e": 45, "107947": 37, "107985": 37, "107991": 36, "108": [12, 18, 28], "1080": [12, 18, 28], "10800": [12, 18, 28], "1085": 34, "10868": 46, "108681": [15, 21, 31], "1089": 37, "10910": 46, "10931": 33, "109526": 36, "109580": 26, "1099": 37, "10_000": 47, "10th": [35, 36, 38, 39], "10x": 36, "11": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 52, 54, 56], "110": [34, 45], "1101": [17, 23, 27], "1102": 27, "1103": 27, "110316": 46, "110319": 46, "1104": [15, 21, 27, 31], "11057": 46, "1106": [27, 40], "110645": 37, "1107": 27, "1108": 27, "1109": 27, "110915e": 37, "111": [16, 22, 32, 35, 36, 37, 47], "1110": 27, "1111": 27, "111111": 16, "1112": 27, "11121453": 41, "111215": 41, "111220": 46, "1114": 27, "111438": 40, "1115": 27, "111543": 37, "1116": 27, "112": [15, 16, 21, 31], "1122": [37, 39, 50], "1123": [35, 50], "112441": 35, "112490": 35, "112527": 39, "112848": 37, "1131": 25, "11331": 50, "11336331e": 39, "113600": [16, 22, 32, 33, 55], "1138": 40, "113837": 37, "1139": [37, 39, 48], "113949e": 47, "114": [16, 22, 32], "1140": [12, 18, 28, 37, 39, 48], "114000": [16, 22, 32, 40], "114079": 35, "114214": 35, "114507": 45, "11457": [37, 39, 48], "114757": 25, "114766": 39, "114836": 40, "114966": 39, "115": 33, "1150": [12, 18, 28], "115083": [16, 22, 32], "115089": 46, "11509": 37, "115090": 46, "115091": 46, "115092": 46, "115183": 35, "115276": 47, "115401": 37, "115406": [15, 21, 31], "115428": 46, "115956": 34, "116": [16, 22, 32], "116145": 40, "116167": 34, "116443": 40, "116497": 37, "11664": 50, "11693": 37, "117": [16, 22, 27, 32, 33, 34, 40, 55], "117058": 34, "117379": 35, "117380": [16, 22, 32], "117412": 37, "117528": 40, "11758": 46, "117612": 45, "117712": 46, "117816": [16, 22, 32], "117899e": 37, "1179": [16, 22, 32], "118": [16, 22, 27, 32, 33, 34, 37, 39, 40, 48], "1180": [13, 25, 29], "118182": [16, 22, 32, 33], "118347": 37, "118450": 36, "118563": 40, "11886432": 35, "118874": 37, "118934": 36, "11898": 36, "119": [16, 22, 32, 33, 34, 40, 46, 55], "1190": [16, 22, 25, 32], "119049": 46, "11909976": 41, "119100": 41, "119121": 26, "11914062": 44, "119189": 26, "119400": [16, 22, 32], "1195": [17, 23], "119570": 40, "119911": 46, "11th": [36, 38, 39], "12": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 54, 56], "120": [15, 16, 21, 22, 27, 31, 32, 34, 37, 38, 45, 46, 51], "1204": [15, 21, 31], "120769e": 37, "121": [12, 16, 18, 22, 25, 27, 28, 32, 33, 34, 35, 38, 40, 46], "1210": 35, "121056e": 37, "121084e": 37, "121351": 39, "12138": [16, 22, 32], "1214": 37, "121438": 47, "12150684": 34, "121531": 36, "121599": 39, "121628": [15, 21, 31], "1217": 47, "12178": 40, "121846": 39, "121985": 37, "122": [12, 13, 14, 16, 18, 20, 22, 25, 27, 28, 29, 30, 32, 33, 40, 45, 53], "1220": [12, 16, 18, 22, 28, 32, 35], "1222": 35, "122307": [16, 22, 32, 33], "122331": 37, "122668": 35, "123": [4, 12, 13, 14, 15, 16, 18, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55], "123049e": 25, "123367": 37, "1235387316046016": 35, "123539": 35, "124": [16, 22, 27, 32, 44], "1240": [12, 18, 28], "1241": [37, 40], "1243": [16, 22, 32], "12436984": [17, 23, 33], "124370": [17, 23, 33], "1247": 35, "12498": 39, "124982": 40, "125": [8, 27, 37], "1250": [16, 22, 32, 33, 55], "125000": 25, "12508": [37, 39, 48], "125440e": 37, "125476": [15, 21, 31], "125523": 46, "1256": 51, "125617": 46, "125644": 37, "1258": 47, "126": [27, 40], "126238": 40, "126398": [16, 22, 32, 33], "126488": 41, "12649": [16, 22, 32], "126500": [16, 22, 32], "126563": 35, "126808": [16, 22, 32, 33], "127": [14, 16, 20, 22, 27, 30, 32, 34, 35, 49], "127086": [16, 22, 32], "127087": 47, "1271": 38, "127107": 39, "127226": 33, "127242": 37, "1273": 39, "127326": 37, "1274": 40, "127418": 37, "127439": 37, "127441": 37, "127614": 37, "12761659": 37, "12768": 25, "127878": [15, 21, 31], "1279": 37, "1280": [16, 22, 32, 35, 37], "1281": 37, "128188": [16, 22, 32, 33], "128384": 37, "128528": 37, "1287": 25, "128820": 46, "128828": 46, "128829": 46, "128830": 46, "12890625": 44, "128984": 37, "129": [15, 21, 31, 34, 40, 47], "1290": [16, 22, 32, 33], "12906": [12, 18, 28], "129257": 37, "12927": [12, 18, 28], "129300": [16, 22, 32, 33, 55], "129459": 40, "129600": 37, "129900": 36, "129904": 37, "129985": [16, 22, 32], "12th": [36, 38, 39], "13": [1, 8, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 42, 43, 44, 46, 47, 50, 52, 55], "130": [12, 13, 14, 15, 16, 18, 20, 21, 22, 28, 29, 30, 31, 32, 33, 35, 37, 39, 40, 48, 53, 55], "1300": [37, 39, 48], "1302": 36, "130395": 46, "1304": [15, 21, 31, 47, 48], "130432": 46, "1306": 49, "130690e": 37, "1307": 37, "130991": 36, "131": [16, 22, 27, 32, 38, 46, 47], "131000": 37, "13107": 46, "131275": 36, "1313": 37, "1314": [37, 39, 48], "131607": [37, 39, 48], "131773": 47, "1319796954314723": 38, "132": [16, 47], "1320": 40, "1321": [12, 18, 28], "132158": 37, "132292": 40, "13229595e": 39, "13255": 46, "132875": [16, 22, 32, 33], "132886": 46, "133": [35, 47], "133000": 37, "133210": 35, "133270": 37, "133337": 37, "133562": 47, "13392236": 45, "134": [13, 14, 20, 29, 30, 33, 34, 53], "1340": [13, 25, 29], "134061": 40, "13407": 39, "13418": 16, "134287": 36, "1346": [16, 22, 32, 37, 39, 40, 47, 50], "134615": 34, "134658": [16, 22, 32], "1347": 50, "13476562": 44, "134798": 36, "134894": 46, "135": [46, 47], "1350": 25, "135134": 46, "135197": 46, "13521135": 39, "135299": 40, "135305": [16, 22, 32, 33], "135384": 37, "13540": 25, "135422": 37, "1357": [12, 18, 25, 28], "136": [16, 22, 32, 33], "1360": [13, 25, 29], "1364": 27, "1365": 27, "1366": 27, "13665": [16, 22, 32, 33, 55], "1367": 27, "136714": 36, "1368": 27, "1369": 27, "1370": [12, 15, 18, 27, 28, 31, 35, 47], "13704": [37, 39, 48], "1371": 27, "1372": [27, 48], "1373": 27, "137339": 36, "1374": 27, "137410": 41, "1375": 27, "137500": [16, 22, 32, 33, 55], "1376": 27, "1377": 27, "1378": [27, 37], "1379": 27, "138": 50, "1380": [12, 18, 27, 28], "1381": 27, "138103": 45, "1382": 27, "1383": [27, 35], "1384": 27, "1385": 27, "138503": 40, "138528": 34, "138564": 25, "1386": 27, "1387": 27, "1388": 27, "138876": 47, "1389": [16, 22, 27, 32, 37, 39], "139": [16, 17, 22, 23, 32, 50], "1390": [12, 18, 28], "139297": 36, "139317": 36, "139322": 36, "139349": 36, "13941": 36, "139554": 36, "1396": 35, "1397": 35, "14": [1, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 42, 43, 44, 45, 46, 47, 52], "140": [16, 22, 32], "140185": 40, "140371": 26, "1404": [15, 21, 31, 47], "1405": 40, "1406": [16, 22, 32, 37, 39], "140641": 46, "140828": 25, "140953": 46, "141": [16, 22, 32, 34], "1410": 25, "141232": 46, "14159265358979323": 8, "14160": 36, "141851": 46, "142": 38, "142051e": 25, "142193": 46, "142199": 46, "1423": 36, "142398": 46, "142467": [14, 20, 30], "1427": [25, 48], "142806": 46, "142857": 33, "14289": [16, 22, 32, 33, 55], "143": [35, 36], "143693": 46, "143803": 40, "1438387200": 46, "1438398000": 46, "1438408800": 46, "1438419600": 46, "1438430400": 46, "1438441200": 46, "1438452000": 46, "1438462800": 46, "1438473600": 46, "1438484400": 46, "143975": 46, "144": [12, 18, 28, 35], "144000": [37, 39, 48], "1441": 50, "144199": 46, "144686": 39, "14471": [16, 22, 32, 33, 55], "144729": 46, "144730": 46, "144731": 46, "144732": 46, "144733": 46, "144750": [15, 21, 31], "14485": 37, "145": [26, 46], "145186": 26, "1452": 40, "145425": 37, "145454": 46, "145455": 46, "145456": 46, "145457": 46, "145458": 46, "145459": 46, "145460": 46, "1457": [16, 22, 32, 33, 47, 55], "14579": 40, "1458": [16, 22, 32, 33, 55], "145833": 43, "146": [12, 18, 26, 28, 38, 48], "1460": [37, 47], "14648438": 44, "1465": [16, 22, 32, 33, 55], "146656": 46, "1467": 40, "146767": [36, 39], "146809": 36, "146830": 36, "14690": 33, "147": [26, 39, 48], "147166": [38, 39], "14716638": 39, "1472": 27, "147226": 26, "147616": 36, "147641": 37, "147737": 45, "147893": [16, 22, 32], "147898": 36, "147917": 36, "148": [15, 26, 27, 31, 35, 39, 51], "14813": 46, "148141": 38, "148343": 37, "148349": 47, "14841": 36, "149": [26, 47], "1490": 25, "149122": 49, "14970": [16, 22, 32], "149788": 39, "149822": [16, 22, 32, 33], "14999": [16, 22, 32], "14th": [12, 13, 18], "15": [1, 8, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 50, 52, 53, 56], "150": [15, 26, 31, 35, 37, 45, 48], "1500": 27, "150000": [36, 43], "150115": 35, "15026771": 37, "150395": [15, 21, 31], "1504": [15, 21, 31], "1505": [16, 22, 32], "1509": 25, "150mb": 36, "150p": [12, 18, 28], "151357": 40, "1514": 49, "152": [27, 46], "1520": 35, "1523300141": 25, "1523300157": 25, "152401": 36, "152691": 26, "15278": 16, "152859": 36, "153": 27, "1530": [12, 18, 25, 28], "1531": [17, 23], "1534": [16, 22, 32], "15377": [16, 22, 32, 40], "154": 27, "1540": [12, 18, 28], "154076": [36, 39], "154105": 40, "15429": 46, "154386": [16, 22, 32, 33], "1545": 40, "154795": [37, 39, 48], "154842": 47, "154883": 26, "155": [12, 18, 27, 28, 35], "15500": 37, "155178e": 37, "15559528e": 39, "155624": 37, "155900": 25, "156": [16, 22, 27, 32, 35, 36], "1560": 25, "1562": 35, "156311e": 37, "1564": 35, "15661": 46, "157": [12, 18, 27, 28, 35, 45], "157008": 37, "157157": 50, "157234": 40, "15725": [16, 22, 32, 40], "157572": 26, "157712": 36, "15775": 46, "1578": 39, "15795": [36, 39], "158": 35, "1580": [12, 18, 28], "1582": 39, "158867": 46, "158982": 37, "159": 35, "1590": [15, 31, 35], "15915": 46, "159751": 26, "15992": 39, "15pm": 1, "16": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 43, 44, 46, 47, 49, 50, 52, 53], "160": [14, 15, 20, 30, 31, 34, 35, 37, 39], "1600": 25, "160000": [37, 39, 48], "160258": [14, 20, 30], "160282": 40, "1604": [15, 21, 31], "160506": 36, "160634": 45, "16063983": [17, 23, 33], "160640": [17, 23, 33], "160727": 39, "160729": 46, "161": [16, 22, 27, 32], "1610243052583638": 34, "16111330565237164": 34, "1613": [16, 22, 32], "161300e": 25, "161429": 26, "16153": 46, "16157": 46, "16160": 46, "161606": [16, 22, 32, 33], "161782": 36, "1619": 35, "161931": [37, 39, 48], "162": [12, 18, 28], "162000": 37, "162007": 50, "162214": 48, "162330": 36, "162363": 36, "162667": [36, 39], "16269": 16, "1627": 40, "162904": 47, "163": 25, "1631": 35, "163195": [16, 22, 32, 33], "163397": [16, 22, 32, 33], "1634": [16, 22, 32, 33, 35, 55], "16358": 46, "164": [40, 45], "1645": 34, "16460": 40, "164679": 36, "165": [34, 37], "1650": [15, 31, 35], "16507": [34, 40], "16508": [34, 40], "16509": [34, 40], "16510": [34, 40], "16511": [34, 40], "16512": [34, 40], "165198e": 37, "1652": [14, 20, 30, 34], "16533": 46, "165485": 39, "165617": 46, "165811": 35, "166": 20, "16630": 40, "166631": [16, 22, 32, 33], "16686": 16, "167": [14, 20, 27, 30], "167214": [15, 21, 31], "167241": 50, "167600": 40, "167620": 45, "168": [27, 37], "1680": [13, 25, 29], "168151": 45, "168196": [16, 22, 32, 33], "168244": 39, "1687": 35, "169": [14, 20, 27, 30, 34, 40], "1690": [12, 13, 18, 25, 28, 29], "169269e": 47, "169421": 35, "169693": [15, 21, 31], "169748": 34, "16991815": 8, "1699181533555938": 8, "17": [1, 4, 8, 13, 15, 16, 17, 21, 22, 23, 25, 27, 29, 31, 32, 33, 34, 35, 36, 37, 40, 44, 46, 47, 52, 55], "170": [16, 22, 32, 42], "170100": [16, 22, 32, 33, 55], "170277": [38, 39], "1704": [15, 21, 31], "17054987": 45, "170670": 37, "170931": 45, "171": [12, 18, 28, 45], "17144": 46, "171468": [37, 39, 48], "1715": 35, "171657": [14, 20, 30], "171899": 47, "1720": [16, 22, 32], "17205": 46, "1724668": 44, "172792": 36, "17290": 25, "173": [15, 31, 35], "173025": 35, "17393037": 8, "1739787032867638": 35, "173979": 35, "174": [12, 15, 18, 28, 31, 35], "174590": 36, "17476": 16, "174766": 40, "1750": [16, 22, 32, 49], "175000": [37, 39, 48], "17518": 46, "175459": 25, "176": [16, 22, 32], "176026": 26, "1766": 37, "176924": 47, "177": 40, "17730": [16, 22, 32, 40], "177709": 47, "178": [12, 18, 28, 37], "17847": 16, "178494": 37, "1788": 25, "17896": 46, "179": [38, 47], "179080": 36, "179123": [15, 21, 31], "179152": 27, "179300": [16, 22, 32], "179631": 25, "179730": 35, "17973005068132514": 35, "179802": 37, "18": [1, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 43, 46, 47, 48, 52, 55], "180": [35, 37, 45], "1800": [12, 13, 15, 18, 25, 28, 29, 31, 35], "18000": 46, "180000": [13, 25, 29], "180279e": 37, "180388": [15, 21, 31], "1804": [15, 21, 31], "18066406": 44, "180900": 40, "180926": 26, "18096": 46, "181": 47, "18113": 46, "18116": 46, "1813": 35, "182": [46, 47], "18201414": 39, "182382": 26, "18245": 46, "182639": 37, "182648": 37, "1830": 25, "18311": 46, "18313": 46, "18317085": 8, "183179": 47, "183423": [15, 21, 31], "183471e": 37, "18365": 33, "18391": [16, 22, 32, 33], "184": [46, 47], "1840": [12, 18, 25, 28], "184405": 39, "1847": [17, 23, 33], "185": [14, 20, 47], "185000": 14, "185155": 39, "185175": 47, "18533": 46, "1854": 35, "185707": [15, 31, 35], "18571": [16, 22, 32, 33], "18572": [16, 22, 32, 33], "18573": [16, 22, 32, 33], "18574": [16, 22, 32, 33], "18575": [16, 22, 32, 33], "18576": [16, 22, 32, 33], "1858": 40, "185868": 40, "185975": 39, "18597545": 39, "186": 27, "186024": [12, 18, 28], "186814": 36, "186899": 36, "187": [14, 20, 30, 34, 38], "1870": 35, "187000": [16, 22, 32], "1872": 37, "1875": [34, 44], "187503": 46, "187663": [15, 21, 31], "187700": [16, 22, 32], "188": [12, 14, 18, 20, 28, 30, 34], "1880": 35, "1886": 34, "1887": [36, 39], "189": 27, "18955": 46, "189981": 37, "19": [1, 8, 12, 13, 14, 15, 17, 18, 21, 23, 25, 28, 29, 30, 31, 33, 35, 36, 37, 40, 43, 44, 46, 47, 50, 52], "190": [14, 20, 30, 37, 40], "1900": 25, "19000e": [15, 31], "1901": [12, 18, 28], "190319": 40, "19032": 46, "1904": [15, 21, 31], "190617": [16, 22, 32, 33], "190833": 20, "191": [16, 20, 22, 30, 32], "1910": 25, "1911": 40, "191169": [37, 39], "191204": 40, "191250": [14, 20, 30], "191396": [15, 21, 31], "191700": 40, "1918": [17, 23, 33], "191k": 39, "1920": [12, 18, 28], "19213263": [17, 23, 33], "192133": [17, 23, 33], "19266": 46, "1927": 50, "1928": 50, "193": 45, "1930": [12, 18, 28], "193021": 36, "193122": 36, "193247": 40, "1933": [13, 25, 29], "193346": 39, "1934": 25, "193427": 35, "19365": 46, "193704": 46, "19380": 46, "1940": [17, 23, 33], "194002": [15, 21, 31], "194034": 46, "194040": [16, 22, 32], "19422": 39, "19433594": 44, "1944": 25, "1945": 37, "1946": [12, 18, 28, 37], "194710": 37, "1948": 25, "19485": [16, 22, 32], "194914": 26, "194985": 37, "195": [16, 22, 32], "1950": 37, "1951": [13, 25, 29], "195228": 33, "1953": [35, 37], "19536": 36, "1954": 44, "1954400510": 25, "1955": [13, 25, 29], "195564": 40, "1957": 44, "1959": [12, 18, 25, 28], "19591": 40, "1960": [13, 25, 29], "1962": 44, "1963": 35, "196385": 39, "1965": [13, 25, 29], "196599": 37, "1966": 37, "196717": 45, "196739": 46, "1968": [12, 18, 28], "196963": 26, "1970": [34, 37, 46], "197083": 14, "1971": 25, "1972": 37, "1975": 25, "197500": 20, "197649": 40, "1977": [12, 18, 28, 47], "19777": [38, 39], "19781": 46, "198": 45, "198127": 37, "1984": 37, "1985": 37, "1986": 25, "198629": 45, "198645": 47, "1987": [12, 13, 18, 25, 28, 29], "1989": [12, 18, 28], "198924": [16, 22, 32, 33], "199": [12, 15, 18, 21, 28, 31, 36], "1990": [15, 31, 34, 35], "1991": [13, 25, 29, 38], "1992": 46, "1993": 37, "199364": 36, "1994": [12, 18, 28], "199412": [26, 47], "199413": [15, 31, 35], "19966": [16, 22, 32, 33, 40], "1997": [25, 34, 35], "199771": 39, "1_000_000_000": 35, "1d": [27, 45], "1e": [35, 37], "1e3": 35, "1e4": 35, "1h": [16, 22, 32, 33, 40], "1st": [8, 36, 38, 39, 46], "1stflrsf": [37, 39, 48], "1v": 51, "1v2": 51, "1v3": 51, "2": [1, 4, 7, 8, 9, 10, 25, 26, 27, 38, 39, 40, 44, 45, 46, 49, 50, 51, 56], "20": [1, 4, 8, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 47, 50, 51, 52, 54, 55, 56], "200": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 48, 53, 54, 55], "2000": [15, 21, 27, 31, 35, 36, 37, 38, 39, 40, 45, 49, 51], "200000": [35, 46], "200000e": 25, "2003": 25, "200326e": 37, "2004": [25, 37], "200458": 26, "200475": 36, "2005": 25, "2006": [37, 39, 48], "2007": [25, 37, 39, 46, 48], "2008": [25, 37, 39, 46, 48], "200876": [17, 23, 33], "20087625": [17, 23, 33], "2009": [25, 37, 39, 46, 48], "200978": [15, 21, 31], "201": [1, 15, 21, 31, 56], "2010": [37, 39, 46], "20113": [16, 22, 32, 33, 55], "2012": [8, 16, 22, 32, 35, 56], "2013": [25, 44, 46], "201332": 42, "2014": [12, 18, 25, 28, 38, 46], "20140521t000000": 25, "20140623t000000": 25, "20141013t000000": 25, "20141015t000000": 25, "20141209t000000": 25, "2015": [25, 45, 46], "20150116t000000": 25, "20150218t000000": 25, "20150223t000000": 25, "20150225t000000": 25, "20150630": 46, "2016": [8, 45, 46], "20160101": 46, "2017": [39, 46], "201810": 36, "201862": 40, "202": [1, 15, 21, 31, 33, 56], "2020": 50, "2022": 46, "202247": 26, "2022w2": [12, 18], "2023": [1, 46], "2024": [0, 1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 54, 55], "20248": [16, 22, 32], "2024w1": [0, 10, 12, 45], "2024w2": [10, 12, 18], "2025": 1, "20274": 46, "202839": 36, "203": [1, 15, 21, 31, 56], "20310": 46, "20311": 40, "20319": 46, "203265": 39, "20334": 46, "203421": 37, "203500": [16, 22, 32], "20357847293371892": 34, "204": [1, 13, 14, 15, 20, 21, 29, 30, 31, 35, 44, 53, 56], "204167": [14, 20, 30], "2043": 47, "204302": 46, "20433": 40, "204583": [14, 20, 30], "2046": 33, "204600": [15, 31, 35], "204692": 37, "204734": 36, "20485": 46, "205": [13, 14, 15, 20, 21, 29, 30, 31, 53], "205000": [16, 22, 32, 33, 37, 39, 48, 55], "205059": 40, "20509": 46, "20514": 46, "205144": 40, "205323": 46, "205479": 34, "205597": 37, "20564": 46, "206": [13, 14, 15, 20, 21, 29, 30, 31, 35, 36, 49, 53], "206019": 26, "206041": 39, "206073": 36, "206099": 35, "20620": 46, "206292": [16, 22, 32], "20639": 40, "2064": [16, 22, 32], "20640": [34, 40], "206724": 47, "20683258": 34, "20694": 46, "20699": 25, "207": [13, 14, 15, 16, 20, 21, 22, 29, 30, 31, 32, 35, 44, 45, 53], "207039e": 37, "2071": 40, "207814e": 37, "2079": 25, "20794": 46, "208": [13, 14, 15, 20, 21, 29, 30, 31, 34, 35, 53], "209": [12, 13, 14, 15, 18, 20, 21, 28, 29, 30, 31, 35, 53], "209221": 48, "209583": 30, "209746": 36, "209903": 40, "20analysi": 47, "20assumpt": 47, "20hazard": 47, "20intro": 47, "20learn": 45, "20lifelin": 47, "20with": 47, "21": [1, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 31, 32, 33, 36, 37, 40, 41, 43, 44, 46, 50, 56], "210": 35, "210000": 14, "210001": 36, "210240": 35, "210272": 40, "210286": 26, "210417": 20, "210591": [16, 22, 32, 33], "210779": 46, "21086181023099526": 34, "211": 35, "2110": [16, 22, 32], "211250": [14, 20, 30], "211343": 40, "211544": 36, "211724": 26, "211892": [16, 22, 32, 33], "212": [1, 14, 30, 35, 56], "212385": 39, "212581": 40, "21274": 46, "212870": 37, "212975": 37, "213": [14, 35, 45, 46], "2130": [12, 18, 28], "21353": 46, "21382972": 38, "21389": 46, "213896": 25, "2139": [16, 22, 32, 33, 55], "214": [12, 18, 28, 33, 35], "21405": 46, "21436": 25, "2144": 35, "21450": 25, "214740": [16, 22, 32], "214769": 45, "214821": 46, "214852": 36, "2149": 27, "215": 35, "2150": 27, "2151": 27, "215167": 26, "2152": 27, "215245": 37, "2153": 27, "21530": 46, "2154": 27, "215412": 37, "21549": 46, "2155": 27, "2156": 27, "21571": 46, "21581": 46, "21582031": 44, "215865": 39, "21596": 46, "216": 35, "21603": 46, "21605": 46, "21608": 25, "21609": 25, "21610": 25, "21611": 25, "21612": 25, "216123": 47, "21613": [13, 25, 29], "21616484": 51, "21617": 46, "216250": 20, "216346": 39, "21634631": 39, "216585": [16, 22, 32], "216596": 46, "21668": 46, "21670": 46, "216718": 36, "216728": [16, 22, 32], "21694": 46, "21697": 46, "217": [27, 49], "2170": [13, 25, 29], "217083": 14, "217334": [17, 23, 33], "21733442": [17, 23, 33], "2173627": 44, "217500": 14, "21767954": 39, "21768": [39, 46], "217680": [38, 39], "21774": 46, "218": [17, 23, 27], "218207": [16, 22, 32, 33], "21847": 46, "21872": [37, 39, 48], "218760": 39, "218830": [16, 22, 32], "218867": 26, "219": [27, 40], "2190": [16, 22, 32], "2192": 35, "219500e": 25, "219512": 40, "219700": 40, "219714": 26, "21972656": 44, "219845e": 37, "22": [15, 16, 21, 22, 27, 31, 32, 33, 35, 36, 37, 38, 39, 40, 44, 46, 47, 50, 51, 55, 56], "220": [27, 30], "2200": 27, "22001": 39, "220392": 47, "22057": 46, "2206": 47, "22078": 46, "221": 27, "2210": [12, 18, 25, 28], "22114": 46, "221329": 37, "221348": 46, "2214": 50, "22154": 46, "221622": [16, 22, 32, 33], "22168237": 51, "221760": 26, "221900": [13, 25, 29], "222": [1, 27, 56], "22219": 46, "22221894": 37, "222222": [16, 22, 32], "22225": 46, "222307": [16, 22, 32], "222500": [20, 30], "22260": 46, "222647": [37, 39, 48], "2229": 34, "222963e": 37, "223": 27, "22305705": 38, "22320": 46, "223333": [20, 30], "223460": 47, "223750": [20, 30], "223804": 39, "224": [27, 35, 45], "22452": 46, "2246468746": 30, "224662": 37, "22471154513694713": 34, "224865": [37, 39], "225": 45, "225301e": 37, "2254": [16, 22, 32], "22550": 46, "226": 35, "226415": [16, 22, 32], "226789": 47, "2268": 38, "22697768": [17, 23, 33], "226978": [17, 23, 33], "2270": 35, "227143": [16, 22, 32], "2272": [36, 49], "227304": 46, "22741": 40, "227559": [37, 39, 48], "227836": 36, "22788": 46, "22811601": 34, "22826": 46, "228329": 36, "2285": 46, "22851562": 44, "228603": 37, "228750": [14, 20, 30], "229": 45, "229000": [16, 22, 32], "22910": 46, "229102": 39, "229167": 14, "2293467570951035": 38, "2295": 46, "229583": [14, 20, 30], "229718": 39, "23": [1, 15, 16, 21, 22, 25, 27, 31, 32, 33, 34, 35, 36, 37, 40, 44, 46, 47, 55], "230": [15, 31, 35], "2300": [12, 18, 28], "230000": 25, "23011": 39, "2305": 39, "2307": [14, 20, 30, 34], "2309": 46, "23091772": 38, "231": [1, 56], "2310": [25, 46], "2311": 46, "2312": 46, "2313": 46, "23175": 46, "231815": 39, "232": 27, "232075": 26, "232143": 33, "232751": 47, "23290": 46, "233": [13, 25, 29], "2334": 16, "234": 47, "234040": 36, "234303": 25, "234436": 47, "235": [27, 40], "235096": [16, 22, 32, 33], "235152": [15, 21, 31], "235417": 30, "235706": 40, "235833": 14, "236": [15, 27, 31, 35, 47], "2360": 25, "236096": 45, "236174": 40, "236210": 41, "23621041": 41, "23640124": 34, "236456": [16, 22, 32], "23654": [36, 39], "236960": 35, "237": [27, 36, 47], "237935": 39, "238": [27, 36, 47], "238192": [36, 39], "2388": 25, "2389": 33, "239": [27, 47], "23902": 46, "239082": 26, "23941": 46, "239944e": 37, "24": [1, 10, 12, 15, 16, 18, 21, 22, 26, 27, 28, 31, 32, 36, 37, 38, 39, 40, 44, 45, 46, 47], "240": 47, "2401": 40, "240893": 40, "241": 47, "241489": 47, "241620": 36, "24182": 46, "242015": [38, 39], "242083": 30, "242169": 36, "242381": 46, "242740": 26, "24295676": [17, 23, 33], "242957": [17, 23, 33], "242996": [16, 22, 32, 33], "243": 46, "2431": 16, "243243": 37, "2435": 40, "2436": 40, "24395": [38, 39], "24397122221206388": 46, "244": 46, "244592": [15, 21, 31], "2447": 38, "244814": 47, "245": 46, "2451": 35, "245329": 37, "245521": 36, "245635": 26, "245686": 36, "246": [46, 50], "246332": 37, "246486": 27, "246646": 35, "246646103936": 35, "246653": 35, "247": 46, "247119": 46, "247439": 41, "24743939": 41, "247690828913": 35, "247691": 35, "248": 46, "248328": 38, "248333": [20, 30], "2484": [12, 18, 28], "248457": [37, 39, 48], "248609": 37, "248664": 40, "2487200875": 25, "2488": [15, 21, 31], "248999": 47, "249": 50, "2496": [14, 20, 30, 34], "249601e": 37, "249618e": 37, "249720": [15, 21, 31], "24h": [36, 49], "24th": [12, 18], "25": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55], "2500": [8, 27, 50], "250000": [16, 22, 25, 32, 36, 37], "25031": 46, "25037": 46, "2506": [13, 14, 20, 29, 30, 53], "250900": 37, "251093": 35, "251158e": 37, "2516": 38, "25176": 46, "251769": 45, "252": 49, "252042": 40, "25214": 46, "252160": [15, 21, 31], "252859": 39, "2530": [12, 18, 28], "2533": [14, 20, 30, 34], "253312": [16, 22, 32, 33], "253432": 39, "253724": [15, 21, 31], "253914": 37, "254380": 47, "254443": 36, "255": [16, 22, 26, 32], "2550": 25, "2551": 50, "255134": 45, "2556": 38, "255751": 40, "255889": 46, "256": [12, 18, 28, 45], "25622": 46, "256263": [38, 39], "256333": [16, 22, 32], "256437": 40, "25658": 40, "256813": [15, 21, 31], "257": [13, 25, 29], "2570": [12, 13, 18, 25, 28, 29], "257024": 35, "257103": 36, "2574": 40, "257787": 27, "2580": [12, 18, 28], "258225": 46, "25823": 36, "258387": 39, "2584": 44, "258427": [15, 21, 31], "259": [37, 40], "259026": 26, "25904": 46, "2590575478171884": 34, "259085": 26, "259286": [15, 21, 31], "259500": [16, 22, 32], "259520": 26, "26": [8, 12, 15, 18, 21, 22, 27, 28, 31, 32, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 50], "2600": [16, 22, 32, 33, 55], "260258": 40, "26048": 39, "260572": 37, "26063": 46, "260890": [37, 39, 48], "261035": 37, "261953": 46, "262": [37, 39, 47, 48], "262079e": 37, "262156e": 37, "262269e": 37, "2623": 37, "262361": 40, "262500": 37, "262990": 36, "263": 37, "2630": [16, 22, 32], "263000018": 25, "263541": 47, "263600": [16, 22, 32], "26370005": 34, "263736": 47, "263742e": 37, "26376": 46, "264195": 47, "264283e": 37, "26447953": [17, 23, 33], "264480": [17, 23, 33], "265": 38, "265273": 34, "265483": 26, "266120": 46, "266135": [16, 22, 32, 33], "2670": 35, "267612e": 37, "268": 35, "2683": 36, "26831": 46, "2691": [13, 14, 20, 29, 30, 53], "26919": 40, "269880": [15, 21, 31], "269972": [37, 39, 48], "27": [1, 8, 15, 16, 17, 21, 23, 25, 27, 31, 33, 35, 36, 37, 44, 46, 47], "270093": 35, "270093376167": 35, "27021": 46, "270270": 43, "27048": 36, "2705": 35, "271037": 40, "271287": 46, "271500": 40, "271738e": 37, "2720": [13, 25, 29], "27206": 46, "27263": 39, "272667": [16, 22, 32, 33], "2730": [16, 22, 32], "27304": 25, "273382": [16, 22, 32, 33], "273606": [16, 22, 32, 33], "273890": 45, "2739": [19, 26], "273962": 40, "274": [16, 22, 32, 33, 46, 55], "274404": [16, 22, 32], "275008": 46, "27502379069": 37, "275290": 36, "275352": [15, 21, 31], "275410": 34, "2759": 39, "276": [16, 22, 32], "27610135": 44, "27638": 46, "27652": 36, "276687": 37, "27676": [36, 49], "27678": [36, 49], "276943e": 37, "27697": [36, 49], "2770": 35, "27705": [36, 49], "27715": [36, 49], "277381": [15, 21, 31], "2777": 47, "278": 50, "278441": 46, "278634": 36, "27874871715903093": 34, "278755": [17, 23, 33], "27875502": [17, 23, 33], "2788": [14, 20, 30, 34], "2794": 34, "28": [1, 15, 16, 21, 22, 31, 32, 33, 34, 35, 36, 37, 40, 41, 44, 46, 47], "280": [16, 22, 32, 40, 50], "2800": 8, "280028": 40, "280310": [16, 22, 32, 33], "2806": 35, "280618": 36, "2807": 47, "280801": 47, "281": [16, 22, 32], "28122025543": 37, "281583": 37, "2817": 39, "2820": 35, "282021e": 37, "2822": 39, "282600": 47, "283119e": 37, "28327": 46, "283421": 37, "2836": 39, "28362": 46, "283857": [15, 21, 31], "283921": [16, 22, 32], "284": [40, 46], "2845": 47, "2846": 50, "2847": 50, "285": [16, 22, 32, 33, 46, 55], "285263": 39, "28526302": 39, "285467": [37, 39, 48], "28571429": [13, 19, 29], "286": [14, 15, 20, 30, 31, 35, 46], "286000": 35, "286200": 40, "286326": 26, "286416": 33, "2865025": 51, "286821": [15, 21, 31], "287": 46, "287031": 46, "287079e": 37, "287344": [16, 22, 32, 33], "287500": 40, "28753559": 44, "288": 46, "288002": 46, "288462": 34, "28854": 46, "28868": 36, "289": 46, "2890": [15, 31, 35], "28953": 46, "289541": [37, 39, 48], "289799": [15, 21, 31], "29": [8, 15, 16, 21, 22, 25, 27, 31, 32, 36, 37, 44, 46, 47, 50], "290": [25, 46], "290002": 36, "290424": 37, "29045704": 37, "290961e": 37, "291": [25, 34, 46], "291310100": 25, "291667": 43, "292": 46, "292587": 47, "293": 46, "29324459": 45, "293663": 36, "294": [16, 22, 32, 44], "294251": [17, 23, 33], "2948": [16, 22, 32, 33, 55], "294855": 39, "295193": 26, "2953863599856862": 34, "295397": 36, "29545": 37, "2957": 27, "29572402": 44, "2958": 27, "2959": 27, "296": [16, 22, 32], "2960": 27, "2961": 27, "2962": 27, "2963": 27, "2964": 27, "296601": 40, "29691": 46, "297": 34, "29802": [36, 39], "298043": 26, "298436": 26, "298561": 47, "298612": 46, "29881": 46, "299": [25, 45], "299164": 40, "2d": [19, 27, 45], "2d454e5fd9a5": 47, "2e": 1, "2f": [14, 20, 30, 35, 43, 46], "2m7m0lw97rvf654x1cwtdfmr0000gr": 22, "2nd": 34, "2ndflrsf": [37, 39, 48], "2v": 51, "2v3": 51, "3": [1, 7, 8, 10, 15, 17, 21, 23, 26, 27, 31, 33, 34, 35, 36, 37, 38, 39, 43, 44, 45, 46, 48, 49, 51, 52, 56], "30": [1, 4, 12, 14, 15, 18, 20, 21, 27, 28, 30, 31, 34, 36, 37, 38, 39, 40, 44, 46, 47, 48, 50, 56], "300": [15, 21, 31, 42, 44, 48, 51], "3000": [27, 45], "300000": [16, 22, 32, 33, 46], "3000000": 44, "300464": 40, "300837": 36, "301": 47, "3010": 40, "301200": 35, "3014": 40, "30146": 46, "301563": 37, "30167": 46, "301784": 47, "3018": 56, "301838": 48, "3019": [13, 14, 20, 29, 30, 34, 53], "301952": 40, "302": [37, 39, 48], "302043": 26, "302131": 37, "30279": 46, "302801": 47, "302844": 47, "303": [37, 39, 48], "303000": [16, 22, 32], "303004": 40, "303030": 34, "303109": [17, 23, 33], "303694": 26, "303790": 35, "3038": 50, "3038344082": 39, "303916": [15, 21, 31], "304": [15, 21, 31], "3040": 46, "3041": 46, "3042": 46, "3043": 46, "3044": 46, "304784": 37, "305": [12, 18, 28], "30504657": 41, "305047": 41, "30530902": [15, 21, 31], "305346": [15, 21, 31], "305674": 40, "3057": [14, 20, 30, 34], "30573": 40, "306500": [15, 21, 31], "306564": 45, "307": [16, 22, 32], "307516": 45, "307521": 34, "30792853": 44, "30798381": 44, "308120": [16, 22, 32], "30815": 37, "308216": 45, "308236": 26, "308448": [15, 21, 31], "3089": 35, "308900e": 25, "309": 40, "3092": [13, 14, 20, 29, 30, 53], "309249": 45, "309859": 34, "30am": 12, "30pm": 1, "31": [1, 12, 15, 16, 18, 21, 22, 25, 28, 31, 32, 33, 34, 36, 37, 38, 39, 41, 44, 46, 47, 50, 55], "310000": [16, 22, 32], "31000e": [15, 31], "310284": 39, "31038074": 44, "310405": 36, "311": [16, 22, 32], "3110": [16, 22, 32], "311151": 47, "31127015": 39, "311310": [12, 18, 28], "311769": 40, "31196406381465247": 34, "3120": [16, 22, 32], "3125": [16, 22, 32], "312500": [16, 43], "312501": [37, 39, 48], "312696": 50, "3129": 50, "31297381": [17, 23, 33], "312974": [17, 23, 33], "31298589e": 45, "313": [33, 37], "31384": 36, "314": [16, 22, 32], "3140": [16, 22, 32], "314000": 35, "31449687e": 39, "31454": 40, "314582": 39, "314840": 40, "314929": 46, "315000": 25, "315134": 46, "315630": 36, "316164": 40, "316230": 40, "31634363": 44, "316363": [15, 21, 31], "316395e": 37, "316426": 40, "316552": [17, 23, 33], "31655231": [17, 23, 33], "316798": 40, "317": [1, 16, 22, 32, 39, 56], "317277": 40, "31767136668453344": 25, "317761": 36, "318": [16, 22, 32], "3180": 35, "3180174485124284": [16, 22, 32], "318937": [16, 22, 32, 33], "319": [13, 16, 17, 22, 23, 25, 29, 32], "31908384": 45, "319481": 26, "319559": 25, "319630": 47, "31984311": 37, "31st": 46, "32": [8, 15, 16, 21, 22, 26, 27, 31, 32, 33, 34, 35, 37, 41, 44, 46, 47, 55], "320": [16, 22, 32], "320155": 36, "320430": 37, "32064171": 38, "3209427041566191": 25, "321": 39, "321050": 25, "32127053": 37, "322": 40, "32240": [38, 39], "322465": 25, "32247597e": 39, "322755": [15, 21, 31], "323045": [16, 22, 32, 33], "32323": [12, 18, 28], "32397724e": 39, "3245": [12, 28], "324762": 26, "325000": 25, "3252": 40, "325319": 40, "32561": 36, "326": [16, 22, 32, 40], "326616": 25, "326730": 36, "326741e": 47, "326933": [15, 31, 35], "327188": 36, "3272": 47, "327283": 37, "32734": 40, "3274": 47, "327408": 36, "32791718": 44, "328": 40, "328000": 25, "328077e": 37, "328953": [15, 21, 31], "3298721": 45, "3299": [44, 50], "33": [8, 12, 15, 16, 18, 21, 22, 25, 28, 31, 32, 33, 34, 35, 36, 37, 40, 44, 46, 47], "330": [9, 10, 13, 19, 27, 28, 29, 45, 46, 48, 50, 56], "33000e": [15, 31], "330346": 47, "330_vs_340": 12, "3310": [16, 22, 32], "331588": 26, "33191802": 44, "332130": 37, "33223002": 44, "3322447": 44, "33224516": 44, "33224759": 44, "332671": 39, "3327": 46, "332710": 37, "332746": 47, "332791": 47, "332824": 37, "333": 27, "3330": [16, 22, 32], "33308783": [17, 23, 33], "333088": [17, 23, 33], "333139": 36, "333333": [13, 16, 19, 22, 26, 29, 32, 35, 43], "3333333333333333": [43, 45], "333340": [15, 21, 31], "33380649": 44, "33380754": 44, "33380761": 44, "33381373": 44, "33394593": 44, "3339473": 44, "33394769": 44, "33395626": 44, "33397112": 44, "334": 40, "33400489": 44, "33411086": 44, "33425967": 44, "33435326": 44, "33439238": 44, "33440682": 44, "334411": [15, 21, 31], "334576": 37, "33462759": 44, "334764": 26, "33476534": 44, "335": 38, "335309": 37, "3355": [16, 22, 32, 33, 55], "3356700488_183566145b": 45, "33590": 46, "336389": 39, "33641142": 39, "3364114233677307": 39, "336411423367732": 39, "336735": 35, "336826": [17, 23, 33], "33682642": [17, 23, 33], "33683087": 34, "336831": 34, "337034": 40, "33726089": 37, "33732465": 44, "337625": 26, "33782315": 44, "33797555": 44, "338": [15, 31, 35], "33888659": 8, "339": 36, "339368": 47, "339889": 47, "34": [12, 15, 16, 18, 21, 22, 27, 28, 31, 32, 33, 34, 36, 37, 40, 44, 46, 47, 55], "340": [1, 3, 13, 19, 29, 38, 40, 45, 46, 47], "34000e": [15, 31], "340988": 36, "341109": 37, "341300": 40, "341571": 47, "34161762": [37, 39], "341712": 46, "34182": 39, "3420": [16, 22, 32], "342200": 40, "342605e": 37, "3436": 46, "3437": 50, "3438": 50, "344": [16, 22, 32], "3442": 47, "34426571": 37, "34441": 37, "345": 39, "345136": [15, 21, 31], "345386e": 37, "3454": [47, 50], "3455": 50, "345831": [12, 18, 28], "346": [16, 22, 25, 32, 33, 55], "346850": 36, "34691": 46, "347523": 35, "348": [16, 22, 32, 40], "34806": 37, "348569": 48, "34900": 37, "34924955": 44, "35": [15, 16, 21, 22, 25, 31, 32, 34, 36, 37, 38, 39, 44, 46, 47, 54], "350": [12, 18, 28], "3500": [27, 54], "350000": [16, 22, 32], "351351": 43, "351366": 36, "3515": 47, "351821": 47, "351883": 48, "3520": 47, "3521": [12, 18, 28], "352100": 40, "352930": [16, 22, 32, 33], "353": [1, 45, 56], "35375221": 51, "353961": 35, "354114": [37, 39, 48], "354604": 36, "3547": 40, "354759e": 37, "35561437": 44, "356689": [38, 39], "35671794": 39, "357": [16, 22, 32], "3573886": 44, "357500": [16, 22, 32, 33], "3576": [12, 18, 28], "35771821": 44, "357823": [12, 18, 28], "358": [12, 18, 28, 35], "358032": 39, "3582": [47, 50], "358264": [37, 39, 48], "3583": 50, "358333": [15, 21, 31], "358500": 40, "358913": [17, 23, 33], "3589134": [17, 23, 33], "359": [15, 31, 35], "3590": 35, "359784": 35, "359887": 41, "359992": [15, 21, 31], "35p": [12, 18, 28], "36": [15, 16, 21, 22, 25, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 46, 47], "360": [1, 33, 56], "360000": 25, "360918": 46, "361": 47, "361718": 36, "362": [25, 47], "362009": 46, "362185e": 37, "362553": 40, "36269995": [17, 23, 33], "362700": [17, 23, 33], "363": 47, "363192": [15, 21, 31], "363913": 36, "364": [46, 47], "364352": 34, "365": 46, "36525": 39, "365420": 50, "365603": 34, "365623": [15, 21, 31], "365898": 26, "365925": 26, "366": [17, 23, 33, 46, 47], "366005": 36, "366071": 16, "3663": 47, "366626": [15, 21, 31], "36695134": 44, "367": 46, "367329e": 47, "367423": 35, "368": [46, 50], "3681": 39, "368304": 34, "3684": 47, "368922": 42, "369": 37, "369875": [15, 21, 31], "369896": 45, "37": [16, 22, 25, 27, 32, 33, 34, 37, 40, 44, 46, 47, 50, 55], "37050406": 8, "370643": 36, "370842": 25, "371": [40, 46], "3717": 39, "371722": 39, "372": [16, 22, 32], "372706": 46, "372763": [37, 39, 48], "373031": [15, 21, 31], "373275": 46, "373318": 26, "373411": 25, "373623580": 27, "373656": 46, "374": [16, 22, 32], "374584": 45, "374995": 36, "37546": 39, "376": [16, 22, 27, 32, 37], "376089": 37, "37647072": 38, "3768": 50, "3769": 50, "377032": 37, "377619": 35, "377619120792": 35, "37797291": [17, 23, 33], "377973": [17, 23, 33], "37807203": 44, "378159": 37, "378764": [15, 21, 31], "378971e": 37, "37903": 27, "37906": 36, "379416e": 37, "379875e": 37, "38": [8, 15, 16, 21, 22, 25, 31, 32, 34, 36, 37, 40, 44, 46, 47], "3803": 47, "380436": [17, 23, 33], "38043616": [17, 23, 33], "380495": [15, 21, 31], "380504": [16, 22, 32, 33], "380643": [15, 21, 31], "381190": 40, "3814": 33, "381416e": 47, "381428": [37, 39, 48], "381676": [15, 21, 31], "38192364": 41, "381924": 41, "382558": 36, "3828125": 44, "383": [16, 22, 32, 40], "384111": 50, "384127": [15, 21, 31], "384528": 26, "384613e": 35, "3851": 36, "3856": [15, 21, 31], "385639": 41, "386": 35, "386071e": 37, "386530": [39, 48], "387": 35, "388023": 36, "388169": 40, "38853": 37, "3889": 33, "389": [35, 40], "389065": 39, "389349": 40, "389736": [16, 22, 32, 33], "39": [15, 21, 31, 35, 36, 37, 41, 44, 46], "390428669205": 35, "390429": 35, "390691": 25, "390725": 37, "39095422e": 39, "391": [16, 22, 32], "3912": 47, "391304": 25, "39163": 36, "391996": 45, "392": [12, 18, 28, 47], "392082": 39, "392221": 34, "392385": 47, "392612": 37, "392893": [15, 31, 35], "393": [13, 25, 27, 29, 33], "3932": 47, "39375": 46, "394113e": 37, "394920": [16, 22, 32], "395282e": 37, "395686e": 37, "395688": 47, "395697e": 37, "396": [16, 22, 27, 32, 47], "396266": 45, "396752e": 37, "396991": [16, 22, 32, 33], "397": 47, "398": 40, "398495": 46, "398915": 26, "39896994": [17, 23, 33], "398970": [17, 23, 33], "399": [16, 22, 25, 32], "3990": [13, 14, 20, 29, 30, 53], "3991": 37, "39931": 39, "399827": 36, "39x15": 44, "3blue1brown": 45, "3d": [40, 45], "3f": [13, 14, 15, 16, 19, 20, 21, 22, 29, 30, 31, 32, 36, 37, 43, 44, 50], "3h": 46, "3m": 45, "3rd": 44, "3ssnporch": [37, 39, 48], "3v": 51, "4": [0, 1, 8, 9, 12, 16, 17, 18, 22, 23, 25, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 56], "40": [8, 12, 15, 16, 18, 21, 26, 27, 28, 31, 34, 35, 36, 37, 38, 39, 40, 42, 46, 47, 48, 54, 56], "400": [13, 16, 22, 25, 29, 32, 35, 48], "40000": [45, 46], "400000": [16, 25, 35, 46], "400047": 47, "400157": 40, "400164": 45, "400649628005": 35, "400650": 35, "400881e": 25, "401": [15, 25, 31, 35], "4011": 44, "401102": 46, "401541": 36, "401623": 37, "401729": 26, "4018": 56, "401830": 39, "401895": 35, "402": [12, 18, 28], "402101": 25, "402258": 25, "402808": 39, "404": [15, 21, 31, 40], "405": [38, 56], "405227e": 37, "405415": [15, 21, 31], "405650": 37, "406": 45, "406202": 35, "40689": 40, "407": 36, "407234": 45, "40725012": 45, "4074": 56, "407510": 36, "40756124": 38, "407862": 47, "4084": 47, "409": 56, "409430": 25, "40_000": 45, "40b5a809b05a": 47, "41": [15, 16, 21, 22, 31, 32, 36, 37, 39, 40, 41, 43, 46, 47], "410": [16, 22, 32], "410240": [36, 39], "410599": 40, "410714": 16, "411412": 37, "41150573": 37, "412": [12, 15, 18, 28, 31, 35], "41210938": 44, "412500": 40, "413050": 45, "413718": 47, "413796": 37, "413958": 36, "414": 50, "4143": 47, "414405": 26, "415": 27, "4151": 38, "4153": 40, "4158382658": [22, 32, 50], "416": 39, "4165": 38, "4169": 47, "418": 44, "418031": [15, 21, 31], "418069": 35, "41901484361": 35, "419015": 35, "419355": 34, "4195": 39, "4197": [13, 14, 20, 29, 30, 34, 53], "42": [12, 13, 14, 15, 16, 18, 20, 21, 22, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 51, 53, 54], "420": 35, "420000": [12, 18, 28], "42060": 40, "421": 45, "42104086": 39, "421215": 41, "42121526": 41, "421875": 34, "422": 37, "422222": 16, "4234": 39, "4236": 39, "4238": 36, "423852": 36, "424222": 37, "424337e": 37, "425": 38, "425365": 47, "42541681": 51, "425419": 37, "426067": [16, 22, 32], "426410": [15, 21, 31], "427": 47, "427516": 26, "4276": 49, "428": 47, "428279": 26, "429": [37, 39, 48], "429217": 36, "429634": 47, "4296875": 44, "43": [15, 21, 31, 34, 35, 36, 37, 46, 47], "430": [35, 37, 39, 47, 48], "430323": [16, 22, 32], "430571": 36, "430704": 41, "4307043": 41, "430868": 34, "431": [30, 47], "4310": [15, 16, 22, 31, 32, 35], "431104": 26, "431137": 34, "4314": 36, "432": 47, "433": 47, "433514": 46, "433814": 47, "434": [15, 31, 34, 35, 47], "43445": 40, "435": 47, "435186": [15, 21, 31], "435489": 36, "435792": 35, "436": 47, "436492": 37, "43697758253484614": 34, "4372": 41, "437367": [16, 22, 32, 33], "4375": [40, 43], "437500": 43, "437684": 46, "438": 43, "438231": 45, "438275": [17, 23, 33], "43827545": [17, 23, 33], "43833466": 37, "438592": [39, 48], "438906": 39, "439": [16, 22, 32], "4390": [15, 31, 35], "439209": 36, "439254e": 27, "439360": [16, 22, 32], "439779": 36, "44": [14, 15, 16, 20, 21, 22, 30, 31, 32, 34, 36, 37, 40, 44, 46, 47, 50], "440": [35, 46], "440897": 25, "441": 37, "441404": 45, "441445": 40, "442": 25, "442377e": 37, "442806": [15, 21, 31], "442917": 26, "4430": 47, "44311": 40, "4432": 40, "443317": [15, 21, 31], "443419": [37, 39, 48], "444297": 40, "4443": 16, "444444": [16, 22, 32], "4448": 40, "445": 35, "445111e": 37, "445124e": 37, "44586935": 38, "44586935141902073": 38, "446216": 40, "446284e": 37, "446869": 40, "447": [16, 22, 32, 39], "447461": 46, "447517": 39, "44787197": 44, "4482": [12, 18, 28], "4484": [15, 21, 31], "448757": 47, "449262": 26, "449666": [15, 21, 31], "44966612": [15, 21, 31], "45": [8, 13, 14, 15, 16, 20, 21, 29, 30, 31, 34, 36, 37, 44, 46, 47, 49, 53], "450000": 43, "450000e": 25, "450132": 46, "450739": 37, "450822": 40, "451888": 36, "452600": 40, "453367": 40, "4537": 47, "454427": [16, 22, 32, 33], "454677": 41, "45467725": 41, "454788": [39, 48], "454966": 36, "455": 33, "455026455026455": 27, "4552": 39, "45555535": 39, "455652": 25, "45587": 46, "45588": 46, "45589": 46, "45590": 46, "45591": 46, "456": 45, "456419": 40, "45653693": [17, 23, 33], "456537": [17, 23, 33], "457435": 46, "45756": 50, "458": [16, 22, 32], "458333": 43, "458524": 47, "459": [27, 37], "4591": [16, 22, 32], "459214e": 37, "459873": 47, "459937": 44, "45a": 46, "45am": 46, "46": [8, 13, 14, 15, 16, 20, 21, 22, 27, 29, 30, 31, 32, 33, 34, 36, 37, 46, 47, 50, 53, 55], "460047": 47, "46019608e": 39, "46021": 50, "46075": 50, "4608": [13, 14, 20, 29, 30, 53], "460950": 41, "461": [16, 22, 32, 35], "462060": 47, "462545": 39, "462963": 34, "46299": 50, "463": 36, "46357616": 27, "463582": 38, "464104e": 37, "465279e": 37, "46530779": [17, 23, 33], "465308": [17, 23, 33], "466246": 45, "4664": [12, 18, 28], "46666667": 27, "46729488": 37, "467379": 39, "467628": 40, "468": [15, 31, 35, 39], "468232": 46, "4687": 40, "46880": 50, "468995": 26, "469": [16, 22, 32, 36], "469383": 36, "4695": 36, "469571": 40, "47": [1, 12, 13, 14, 15, 16, 18, 20, 21, 22, 25, 28, 29, 30, 31, 32, 34, 35, 37, 40], "470": [16, 22, 32, 50], "4700": 35, "470060": 37, "470666": 37, "471000": 25, "471032": 39, "472": [17, 23, 50], "47242662": 51, "4726": 47, "472603": 37, "472790": 36, "473": 44, "473691": [15, 21, 31], "474": [27, 36], "474552": [15, 21, 31], "47491": 36, "475": 27, "475099": 39, "475540": 44, "476": [13, 19, 27, 29], "4760": 35, "47606": 40, "476092": [37, 39, 48], "476406": 39, "476412": 41, "47641249": 41, "477": [27, 35], "477291": 40, "47799": 50, "478": 27, "478060": 46, "478515": 26, "479": 27, "479109": [15, 21, 31], "479132": 40, "479773": 44, "48": [13, 14, 15, 20, 21, 29, 30, 31, 34, 36, 37, 43, 46, 47, 53, 56], "480": [27, 37], "4800": [12, 18, 28], "480249": [15, 21, 31], "4806334": 44, "48073598": 41, "4809": 35, "481": [16, 22, 27, 32], "4810": 49, "4813": [14, 20, 30, 34], "481514": 37, "481793": [16, 22, 32], "481893": 36, "481960": 36, "482": 27, "4820": 25, "4822": 47, "483": 27, "48344371": 27, "483751": [15, 21, 31], "48390": 50, "484": 27, "48407": 50, "484937": 34, "485": [27, 45], "485191": 26, "48535": 50, "4854": 39, "485722": 44, "486": [27, 39], "4861": [16, 22, 32, 33, 55], "486266": [16, 22, 32], "486664": 44, "487": [16, 22, 32], "48721": 50, "487740": 44, "4879": 50, "488": [16, 22, 27, 32], "488163": 44, "488753": 46, "489": 27, "489130": 34, "489593": 44, "49": [15, 16, 21, 31, 34, 36, 37, 40, 46, 47], "490": [27, 40, 51], "490000": [16, 22, 32], "490033": 37, "490568": 35, "490797": 44, "490930": 44, "491217": 36, "491366": [39, 48], "491379": [16, 22, 32, 40], "491968": 44, "492": [16, 22, 32, 36], "492270": [17, 23, 33], "492307": 44, "492551": 44, "493": [16, 22, 29, 30, 32], "493489": 44, "493544": [16, 22, 32], "493921": [17, 23, 33], "494": [15, 16, 22, 31, 32, 35], "4943": 35, "494309": 25, "495524": 26, "49575": 36, "496": 40, "496213": 37, "49668874": 27, "496757": 39, "497143": 44, "497386": [15, 21, 31], "497787": 37, "497949": 44, "498": [36, 49], "498133e": 37, "498164": 26, "498562": [15, 21, 31], "499900": [16, 22, 32], "4f": [15, 17, 21, 23, 31, 33, 36, 44], "4m": 45, "4th": [36, 38, 39], "4x": 56, "5": [1, 4, 25, 26, 28, 34, 35, 37, 38, 42, 43, 46, 50, 51, 52, 53, 56], "50": [1, 12, 15, 16, 17, 18, 21, 22, 23, 25, 27, 28, 31, 32, 33, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 56], "500": [12, 14, 16, 18, 22, 28, 32, 36, 38, 39, 40], "5000": [12, 13, 18, 25, 28, 29, 49], "50000": 46, "500000": [15, 16, 22, 25, 32, 33, 36, 37, 42, 46, 50], "500000e": [25, 35], "500001": [16, 22, 32], "5002": 37, "500625": [15, 21, 31], "50062e": [15, 31], "500924": [16, 22, 32, 33], "501": [16, 22, 32, 50], "501071": 45, "501191": 44, "501250": [15, 21, 31], "501304e": 37, "5014": 12, "501875": [15, 21, 31], "5024752475247525": 35, "502500": [15, 21, 31], "502985": 36, "503000": [16, 22, 32], "503090": 36, "503125": [15, 31], "503750": [15, 21, 31], "503807": 44, "504": [15, 21, 31, 40], "504231": 47, "504375": [21, 31], "504429": [17, 23, 33], "504644": 35, "50475372e": 39, "504fde4fcf8": 47, "505000": 15, "505026": 25, "505180": 44, "505335": 36, "505592e": 37, "505625": [15, 21, 31], "5057": 37, "50596432e": 51, "506023": 38, "506035e": 37, "506079e": 37, "506084e": 37, "506211": [16, 22, 32, 35], "506250": 21, "506410": 34, "506875": [15, 21, 31], "507130": 35, "507359": [16, 22, 32, 35], "507500": [15, 31], "50774": 35, "507740": [16, 22, 32], "50775": 35, "507750": 35, "507752": [16, 22, 32, 35], "507995": 34, "508": [16, 22, 32, 37], "508125": [15, 21, 31], "508133": [16, 22, 32, 35], "508371": 35, "508534": 44, "508741": 44, "508750": 21, "50884": 40, "50899": 35, "509000": [12, 18, 28], "509001": 37, "509045": 25, "509317": [16, 22, 32, 35], "5098": 44, "509859": 44, "509930": 46, "50k": [36, 38, 39], "51": [15, 16, 21, 22, 31, 32, 33, 35, 36, 37, 39, 41, 46, 47, 48, 55], "5100": 25, "510000": [13, 15, 25, 29, 31, 35], "510421": 44, "510505": 44, "5106": 50, "510625": 21, "510697e": 25, "5107": 25, "510836": 35, "5109": 39, "511": 9, "5112": [13, 25, 29], "51137414e": 39, "51143": 40, "51150": 36, "511620e": 37, "5118": 39, "511875": 21, "512": 45, "5120": [12, 18, 28], "512000": [15, 31, 35], "51226051": 41, "5123": 44, "512319": [16, 22, 32], "512408": [37, 39, 48], "512897": [15, 21, 31], "512x640": 45, "513": [16, 22, 32], "5131": 44, "513125": 15, "513333": 27, "513678": 47, "513750": 15, "514150": 44, "514155": [16, 22, 32, 33, 37], "514347": 44, "514598e": 37, "5146": 34, "514950": 27, "515000": 31, "51503393": [17, 23, 33], "515034": [17, 23, 33], "515351e": 37, "5156": [16, 22, 32, 40], "515755": 27, "515848": 40, "516199": 44, "516394": 40, "516556": 27, "516788": 26, "516858": 44, "517273": 44, "517346": 36, "518113": 44, "519000": 25, "519029": 36, "519129": 26, "52": [15, 16, 21, 22, 31, 32, 34, 36, 37, 40, 46, 47, 50], "520495": 44, "52061": 46, "520700": 44, "520782": 44, "5208": [13, 25, 29], "520857": 36, "5209": 37, "5212": 37, "521284e": 37, "521567e": 37, "521578e": 37, "521743e": 37, "521772": 44, "522": 37, "522563e": 37, "5227966": 44, "523595": 44, "523684": 44, "5238095238095238": [13, 19, 29], "52398": 40, "524": [13, 19, 29, 43], "524364": 47, "525": 27, "5253": 39, "525554": 40, "525757": [15, 21, 31], "526046": 44, "526078": [16, 22, 32, 33], "526214": 39, "526442": 26, "526596": 40, "526602": 37, "526783": 26, "5274": 47, "527500": [16, 22, 32], "528": 37, "5282": 47, "528403": [15, 21, 31], "52881619": [15, 21, 31], "529210": 36, "529388e": 37, "5294": 38, "529412": [16, 22, 32], "53": [25, 34, 37, 46], "530052": 35, "530978": 36, "531": 48, "5310": 16, "531116e": 37, "531353": 45, "5315": 35, "53187": 49, "532034": 37, "533027": 26, "533333": 16, "533454": 45, "533498": [15, 21, 31], "534114": 35, "534342": 40, "5345": 25, "535": [16, 22, 32, 40], "535014": [16, 22, 32], "53520104": [15, 21, 31], "535604": [16, 22, 32], "535622": 40, "536362": 41, "53636249": 41, "537267": [16, 22, 32], "537732": 44, "538000": [13, 25, 29], "538702": [15, 21, 31], "538816": 36, "5390": [36, 39], "5391": [16, 22, 32, 40], "539116": 46, "539258": 26, "539376": 47, "539459": 50, "539989": 25, "54": [37, 46, 47], "540": 46, "540000": [16, 22, 32], "540039": 44, "540359": 40, "541117": 37, "541347": 44, "541488": 40, "54152": 36, "541667": 33, "541795": 36, "542": 48, "54240": 36, "542624": 39, "542873": [16, 22, 32, 33], "543297": 35, "543351": 39, "543464": 44, "543678": 26, "544": 35, "544079": 26, "544462": 39, "545": 37, "546": [16, 22, 32], "5461": 37, "546150": 26, "546473": 34, "546610": [15, 21, 31], "54676006e": 39, "547": [35, 37, 39], "547090": 44, "547993": 36, "548831": 39, "549682": 36, "5498": [15, 21, 31], "549946": 44, "55": [13, 14, 15, 20, 21, 29, 30, 31, 34, 36, 37, 38, 39, 46, 47, 48, 53], "55000": 35, "550000": [16, 22, 32, 33, 35], "550004": 38, "550616": 36, "55101": 46, "5513": 35, "5514": [38, 39], "5515": 47, "551579e": 37, "551862e": 37, "551975": 37, "552": [16, 22, 32, 37], "552492": 25, "552721": 38, "553": 25, "553125": 15, "553965": 39, "553979": 36, "5540": 47, "5541306485809793": 38, "55413065": 38, "554180": 46, "554463": 44, "554621": 40, "5551": 34, "555180": 25, "555740": [15, 21, 31], "5566": [16, 22, 32, 33, 55], "556716": 27, "557197": 45, "557242": 36, "557739": 37, "558": [37, 39, 40, 48], "558564": 36, "55862988e": 39, "55873324": 45, "5588": [12, 18, 28], "558824": 36, "558889": 37, "559": [35, 37, 39, 48], "559284": 25, "56": [15, 21, 31, 33, 36, 37, 46, 47], "560": 25, "560053": 25, "560225": [16, 22, 32], "560625": 21, "560768": 37, "5609808539232339": 16, "561": [1, 15, 31, 35, 39, 40], "561467": [16, 22, 32, 33], "561602": 39, "561645e": 37, "562112": [16, 22, 32], "5623062252998352": 44, "562712": 44, "563": 1, "5630224174651539": 34, "5630921721458435": 44, "563125": 15, "5631500400": 25, "563314": [37, 39, 48], "563467": [16, 22, 32], "5644": 37, "564483": 40, "565": 40, "5650": [13, 25, 29], "565062": 47, "56521734": 8, "565625": 21, "565679": 36, "565746": 47, "565888": [16, 22, 32], "566": [16, 22, 32], "566092": [16, 22, 32], "566222": 45, "5667": 36, "567724": 45, "567856e": 37, "568": 45, "568009": [15, 21, 31], "56804591": 37, "568125": 15, "568663": 37, "5690201394302518": 39, "56902014": 39, "569375": 31, "5694": 40, "57": [15, 16, 21, 22, 25, 31, 32, 33, 36, 37, 39, 46, 47, 48, 55], "57000": 47, "570015": 37, "570449": 36, "570473": 40, "5707": 47, "570739": 40, "571": [27, 41, 51], "571431": 44, "571500": 40, "571800": 25, "571875": 21, "571901e": 37, "571969": 40, "572": 1, "572105": [15, 21, 31], "572500": 15, "572549": [16, 22, 32], "572962": 47, "573": 51, "573050": 36, "573125": 15, "573129": [37, 39, 48], "5732": [36, 49], "573542": 40, "573818": 36, "574": 25, "57415": 46, "574260": 40, "575000": 43, "575043": 25, "57510": 40, "5755444169044495": 44, "575636": 27, "575907": 40, "576": [16, 22, 32], "57640869": [17, 23, 33], "576409": [17, 23, 33], "576921": 44, "577500": 15, "578452": 26, "578523": 34, "578569": 26, "578654": 36, "5789": 37, "579091": 40, "579245": 44, "579432": 34, "579559e": 37, "579660": 38, "5798": 38, "57994": 36, "58": [13, 14, 15, 20, 21, 29, 30, 31, 34, 37, 46, 47, 53], "580": 45, "580302e": 25, "5804311633110046": 44, "580539e": 37, "580625": 15, "581": 39, "5813": 25, "58137177": [17, 23, 33], "581372": [17, 23, 33], "5814": [12, 18, 28], "581687": 40, "581787": 47, "582": [12, 18, 28, 38], "582090": 36, "5824530720710754": 44, "582469": 37, "582570": 27, "583": 25, "583125": 15, "58387198": 41, "583872": 41, "583972": 26, "584": [16, 22, 32], "584615": [16, 22, 32, 40], "585": [16, 22, 32], "585187": 27, "585513": 34, "5857": 47, "586095": [16, 22, 32, 33], "586875": 21, "587773": 36, "588": [15, 31, 35], "588125": 31, "588235": 34, "588307": [16, 22, 32], "589286": 50, "59": [1, 12, 15, 16, 18, 21, 31, 37, 46, 47, 56], "590": 25, "590243": 44, "59049": 36, "59050": 36, "590618": 40, "590625": 15, "59082668": [17, 23, 33], "590827": [17, 23, 33], "5915": 33, "592": 50, "592401": [12, 18, 28], "59243876": 38, "592507": 26, "5925410985946655": 44, "59300": 40, "5931": 37, "593370": 37, "593508": 41, "5938": [16, 22, 32], "594": [16, 22, 32], "5941": 25, "5944": 25, "594595": [15, 21, 31], "594982": 36, "594995": 36, "5950": [16, 22, 32], "595000": 21, "595427": 45, "595569e": 37, "595625": 15, "596088e": 37, "596151": 40, "596810": [15, 21, 31], "596864": 37, "596875": 21, "5970": 38, "59700": 36, "597015": 34, "59708": 36, "597326": 36, "597555": [12, 18, 28], "597924": [37, 39, 48], "598": [16, 22, 32], "598057": 27, "59810": 36, "598100": 34, "598149": [37, 39, 48], "598750": 31, "599": 50, "5993570685386658": 44, "599492": 34, "599860": [15, 21, 31], "599894": 46, "59pm": [12, 18], "5fin": 37, "5th": [36, 38, 39], "5unf": 37, "6": [1, 8, 12, 13, 14, 15, 16, 18, 20, 21, 22, 25, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 56], "60": [8, 12, 16, 18, 22, 28, 32, 36, 37, 39, 40, 41, 43, 44, 46, 47, 48], "600": [16, 22, 32, 34, 44], "60000": 46, "600000": [14, 15, 21, 30, 31, 35, 46], "600193": 36, "60023631": 37, "600288": 26, "600625": 21, "600k": 37, "601": 35, "601042": [12, 18, 28], "601504": 34, "601712": 36, "601790": 34, "602": [16, 22, 25, 32, 33, 55], "602000": [16, 22, 32], "602649": [15, 21, 31], "6028": 36, "602941": 36, "602954": 38, "603125": 21, "6031432151794434": 44, "60319915": 51, "603243": 25, "603684e": 35, "603739": 25, "603970": 47, "604": [15, 21, 31], "6040": [15, 31, 35], "604000": [13, 25, 29], "604032": 36, "60429913": 37, "604320": 34, "60455": 46, "604619": 34, "604797": 34, "6048": 46, "604807": 47, "60495488": [15, 21, 31], "605060": 36, "6051": [16, 22, 32, 33, 55], "605100": 34, "605101": 34, "605102": 34, "605263": [15, 21, 31], "605625": 31, "605696": 34, "606": [16, 22, 32], "606061": 34, "6063088774681091": 44, "606557": 34, "606567": 34, "606811": 35, "606875": 31, "606902": 34, "607062": 46, "608050": 34, "608125": 31, "6082": [16, 22, 32], "608468": 34, "608532": 45, "608565": 47, "60860": [16, 22, 32], "6086405515670776": 44, "609": [16, 22, 32], "6092": [12, 18, 28], "6093292236328125": 44, "609375": 31, "60943": 36, "60k": 37, "61": [15, 17, 21, 23, 31, 33, 34, 36, 37, 41, 46, 47], "610000": 15, "610142": 26, "61029914": 37, "610407": 36, "610931": 42, "611": 33, "611007": 45, "6111123561859131": 44, "611178": 46, "612349": [17, 23, 33], "61234944": [17, 23, 33], "6124": 47, "612500": 21, "612546": 36, "612621": 34, "612755": [15, 21, 31], "613507": 34, "613738": 35, "613738418384": 35, "614": [16, 22, 32], "61420598": [17, 23, 33], "614206": [17, 23, 33], "614567": 40, "614872": 26, "615": [16, 22, 32], "615000": 21, "6154": [16, 40], "615730": 38, "616": 35, "616099": 35, "6168": [13, 25, 29], "617342": 47, "617431": 42, "6176": 36, "617647": 36, "618": [16, 22, 32], "618000e": 25, "618012": 35, "6186580061912537": 44, "618967": 44, "619": 50, "61912405": 39, "619375": 21, "62": [15, 16, 21, 27, 31, 35, 36, 37, 46, 47], "620726": 26, "6210": 25, "622255": [16, 22, 32], "622454": 35, "622500": [15, 31], "6226": 40, "622612": 36, "622709": 34, "623000": [16, 22, 32], "62320": 46, "62352928": 38, "624049": 37, "6241": [12, 18, 28], "624375": 31, "624450e": 37, "624615": 37, "6250": [16, 22, 32], "625387": 35, "6257": 47, "626206": 37, "62657": 46, "626875": 31, "62688064": 39, "627": 47, "6273": 35, "6275": [13, 14, 20, 29, 30, 53], "627722": 39, "627966": [16, 22, 32], "628032": 40, "628139": 36, "62873917": 39, "629792e": 37, "63": [15, 21, 31, 35, 36, 37, 46, 47, 50], "6303": [16, 22, 32, 33, 55], "6306": [16, 22, 32, 40], "630625": 15, "631899": 47, "632": 50, "6320": 34, "6320979595184326": 44, "6322": 40, "632296": 26, "632353": 36, "632786": 46, "63316788": 51, "63362": 37, "633933424949646": 44, "634397": 34, "634490": 33, "634686": 36, "635": [16, 22, 32], "635200": 40, "635239": [16, 22, 32, 33], "635648": 34, "636": [12, 16, 18, 22, 28, 32, 33, 47, 55], "636364": [16, 50], "636410": 38, "636849e": 37, "637": 45, "637982": [15, 21, 31], "638169": 39, "6389": [16, 22, 32, 40], "6391518364256": 47, "6392": 40, "639754": 37, "64": [10, 15, 16, 21, 31, 34, 37, 45, 46, 47], "640": [35, 45], "6400": [16, 22, 32], "640000": [36, 50], "640266": [16, 22, 32, 33], "640625": 15, "640x480": [15, 21, 31], "641216": 46, "6414100192": 25, "641538": 47, "641873": 37, "642071": 26, "642676": 46, "642965": 36, "643": 35, "6431": 40, "643311e": 37, "643750": 15, "644106": 36, "64417243": 45, "644375": 21, "64454": 36, "644770": 42, "645519": 36, "6458": [13, 14, 20, 29, 30, 53], "645963": 35, "646050": 39, "6464": 47, "646617": 48, "647796": 40, "648": [15, 16, 22, 31, 32, 35], "6480": 38, "648195": 36, "648550": 45, "649658": 39, "64994": 46, "65": [13, 17, 23, 29, 33, 37, 47], "650": 36, "65000": 35, "650000": 35, "65000e": [15, 31], "65013704": 41, "650743": 25, "651": 25, "651250": 15, "65125032": 51, "6513": 39, "651359e": 25, "651446": 46, "651875": 21, "65243": 37, "652487": 40, "6526853": 37, "652828": 35, "652986": 40, "653": [16, 22, 32], "653205": 35, "653205232272": 35, "654": [16, 22, 32], "65424895": 37, "654375": 21, "65486": 44, "656297e": 37, "656349": [15, 21, 31], "656827": 36, "656873": 25, "657675": 40, "658047": 34, "658645": 34, "659056": 37, "66": [13, 14, 16, 20, 22, 29, 30, 32, 34, 36, 37, 45, 46, 53], "6600060120": 25, "6601256728172302": 44, "660171": [15, 21, 31], "6604": [16, 22, 32, 33, 55], "660714": 33, "661023": 44, "66214339": [15, 21, 31], "66221": 46, "6622507572174072": 44, "662450": 36, "662541e": 37, "662745": [16, 22, 32], "662879": 38, "66368": 39, "663680": [37, 39, 48], "6637": 47, "6638": 47, "663822": 39, "6639": 47, "6639009118080139": 44, "6641": 47, "6642": 47, "664207": 36, "6643": 47, "6644": 47, "6645": 47, "664625": 44, "664707": 34, "66473": 46, "665": [16, 22, 32], "665307": 44, "665351e": 37, "665625": 31, "665882": 38, "666": [16, 22, 32, 33], "666166": 46, "6666666666666666": 45, "666667": [14, 16, 22, 30, 32, 43], "666754": 45, "667450": 46, "668": 44, "668787": [15, 21, 31], "6688": [12, 18, 28], "669614": 36, "669805e": 37, "67": [13, 14, 17, 20, 23, 29, 30, 33, 34, 36, 37, 46, 47], "670344": [15, 21, 31], "6709133982658386": 44, "671272e": 25, "67186503136": 37, "6731126308441162": 44, "673277": 35, "6733067729083665": 27, "6733849048614502": 44, "6734487414360046": 44, "674": 27, "6744": 39, "674490": 35, "674721": 38, "675000": [12, 18, 28], "67501": 46, "67512181": 37, "67562658": [17, 23, 33], "675627": [17, 23, 33], "675676": 43, "675814": [15, 21, 31], "676": 48, "676250": 31, "67672595": 37, "677": [16, 22, 27, 32], "6771429181098938": 44, "6772": 47, "677268": 47, "677567": 25, "677579": [15, 21, 31], "677601": 35, "677629": [15, 21, 31], "6778583526611328": 44, "678": [15, 31, 35], "678000": 25, "678689": 34, "679240": 25, "679478": [16, 22, 32], "679877": [37, 39, 48], "68": [13, 14, 15, 17, 20, 21, 23, 29, 30, 31, 33, 36, 37, 39, 41, 42, 46, 47, 51], "680000": [12, 18, 28], "6800296306610107": 44, "680657": [16, 22, 32], "681223": [15, 21, 31], "681428": 26, "681716": 44, "683015": 38, "683171": 36, "68323": 35, "68339": 46, "684211": [15, 21, 31], "684447": [16, 22, 32], "684960": [16, 22, 32, 33], "685": 25, "685103e": 37, "68523": 46, "685786": 38, "6858": 34, "686": [16, 22, 32], "686348e": 37, "687": 37, "687055": 36, "687307": 35, "687500": [14, 30], "687504": 44, "688": 35, "6880359361853475": 34, "688043475151062": 44, "688135": 35, "688484": 25, "689338": [37, 39, 48], "69": [13, 14, 15, 17, 20, 21, 23, 29, 30, 31, 33, 37, 41, 46, 47], "690": 50, "69027185e": 39, "690402": 35, "690778": 39, "691241": 36, "691617": 44, "691640": [15, 21, 31], "691877": 35, "691924": 41, "69192445": 41, "692131": 26, "692308": [16, 22, 32], "692500": 15, "693": [16, 22, 32], "693498": 35, "693590": [17, 23, 33], "6938": [12, 18, 28, 46], "693890": 46, "693898": 46, "693936": [17, 23, 33], "69393613": [17, 23, 33], "694": 27, "69411": 40, "694155": [15, 21, 31], "694334": 38, "6950": 39, "695532": [16, 22, 32], "695783": 44, "696": 27, "696034e": 37, "6962": [16, 22, 32], "6963": 39, "696373": [16, 22, 32], "696429": 36, "696712": 46, "696859": 35, "696875": 31, "696970": 34, "69698010e": 39, "697": [16, 22, 32, 40], "697248": 36, "6973": [16, 22, 32], "698": [16, 22, 32], "698125": 15, "698167": 46, "698206": 37, "698384608345687": 35, "698385": 35, "6984": 40, "698857": 35, "699224": [15, 21, 31], "6993": 25, "699706": 45, "699901396097971": 42, "6th": [36, 38, 39], "7": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52], "70": [13, 14, 17, 20, 23, 25, 26, 29, 30, 33, 36, 37, 41, 42, 46, 47, 48], "70000": 46, "700000": 46, "700000e": 25, "700855": 36, "701128": 46, "701173": 35, "701186e": 37, "70162085e": 39, "7017": 47, "701863": 35, "702703": [15, 21, 31], "703406": 47, "704": [15, 16, 21, 22, 31, 32, 37], "704099": [17, 23, 33], "7041": 44, "7042": 47, "7043": 47, "7046136400143138": 34, "70472": 40, "704969": 35, "705000": [16, 22, 32], "705470": 44, "705511": 35, "70560276": [17, 23, 33], "705603": [17, 23, 33], "70568": 37, "705696": [15, 21, 31], "705882": [14, 20, 30, 35], "70588235": [14, 20, 30], "705898": 40, "706": 33, "706128": [15, 21, 31], "706444": 36, "706489": 25, "706783": [17, 23, 33], "70678332": [17, 23, 33], "706966": 46, "707681": [15, 21, 31], "707712": 47, "707899": 41, "70789903": 41, "70799": 35, "708": [16, 22, 32, 33, 35, 38, 55], "708075": 35, "708527": [16, 22, 32], "708978": 35, "709185": [15, 21, 31], "70978": 40, "709874": 35, "709880": 35, "709893": 46, "7099": 40, "71": [12, 13, 14, 17, 18, 20, 23, 28, 29, 30, 33, 34, 36, 37, 41, 46, 47], "710000": [16, 22, 32], "710031": 39, "710526": [15, 21, 31], "710896": 36, "71096": 40, "711": [33, 35], "711077": [16, 22, 32], "711086": 35, "711356": 25, "711717": 35, "711754": [16, 22, 32, 33], "711819": 44, "711852": 40, "71199006": 37, "712": [16, 22, 32], "712074": 35, "71219761": [17, 23, 33], "712198": [17, 23, 33], "712324": 35, "712402": 38, "7129": 35, "7129300520": 25, "713": 33, "71327467": 37, "714": 45, "714077": [16, 22, 32, 33], "714286": 35, "714375": 21, "714745": 36, "715072": 45, "71517": 35, "7153": 47, "715424": 35, "715728": 36, "715992": 45, "716157": 36, "716655": 35, "716657": 35, "716792": 36, "716985": [15, 21, 31], "717289": 35, "717391": 35, "717829": [16, 22, 32], "718242": 35, "718266": 35, "718524": 46, "71866979": 37, "718750": 31, "7188": 33, "719": [12, 16, 18, 22, 28, 32, 40], "719056": 38, "719427e": 37, "719500": [15, 21, 31], "719747": 36, "719915905190645": 25, "72": [13, 14, 15, 20, 21, 29, 30, 31, 36, 37, 46, 47, 53], "7200": 25, "720357": 46, "72036": 46, "720497": 35, "720859": [16, 22, 32], "720893": 47, "720904": 46, "7210": [13, 25, 29], "721006": 35, "721008": 35, "721250": 21, "7212512828409691": 34, "721616": 35, "721705": [16, 22, 32], "7218": [13, 14, 20, 29, 30, 53], "721818": 40, "721917": 25, "721921": [16, 22, 32], "722": [16, 22, 32], "722241": 35, "722249": 35, "722803": 25, "722873": 25, "723": [16, 22, 32], "72345029": 37, "723602": 35, "723613": [15, 21, 31], "723951": 25, "724068": 25, "7242": [13, 25, 29], "724410": 25, "724458": 35, "724539": 46, "724891": 36, "725": [34, 35], "7250894": 51, "726": [16, 22, 32, 36, 40], "726269": 26, "726412": [16, 22, 32, 33], "726441": 26, "726474": 45, "726573": 35, "726583": 35, "726634": 36, "726659": 25, "7266666666666667": 51, "726788": 37, "727014": 46, "727198": 35, "727273": [15, 16, 21, 31], "727554": 35, "7277854625841886": 47, "727821": 35, "7278214718381631": 35, "727829": 35, "727992": 26, "728": [16, 22, 32, 36], "728235": [16, 22, 32, 33], "7283": 36, "728324": 36, "728777": [15, 21, 31], "729": 35, "729109": 50, "729143": 36, "7292": 40, "729374": 25, "729814": 35, "73": [13, 14, 17, 20, 23, 29, 30, 33, 34, 35, 36, 37, 42, 46, 47], "730025": 25, "730383": 36, "730704": 25, "731498": 47, "7315": 34, "7315558717766282": 35, "731572": 34, "731583": [15, 21, 31], "73183": 44, "7328": [16, 22, 32], "732919": 35, "733102": [16, 22, 32, 33], "733333": [14, 16, 22, 30, 32, 33], "733746": 35, "734": [35, 37, 47], "734011": 35, "734048": 25, "734385": 36, "734816": 46, "734986": 25, "735": 37, "735043": 36, "735261": 35, "7352614272253524": 35, "735637": 25, "7356575131416321": 44, "735667": 36, "735879": 35, "7363681793212891": 44, "736498": 35, "736900": [16, 22, 32], "737285": 25, "7379": [13, 25, 29], "738": [16, 20, 22, 32, 37], "738564": 46, "738701": [16, 22, 32, 33], "738715": 47, "738839": 34, "738977": 35, "739264": [16, 22, 32, 40], "7395977155164125": 35, "739598": 35, "739938": 35, "74": [13, 14, 16, 17, 20, 22, 23, 29, 30, 32, 33, 34, 35, 36, 37, 42, 55], "740319": 25, "740542": [12, 18, 28], "740844": 35, "741": 47, "741037": 46, "741060": 25, "741250": 31, "741463": 35, "7418": 39, "741935": 50, "742084": 35, "742088": 35, "742703": 35, "742981": 36, "743": [15, 16, 22, 31, 32, 35, 47, 50], "743133": [15, 21, 31], "743135": 36, "743321": 35, "743323": 35, "743324": 35, "743391": [15, 21, 31], "743555": 39, "7436": [13, 14, 20, 29, 30, 53], "743917": [16, 22, 32, 33], "7440": [12, 18, 28], "744201": 36, "744565": 35, "745": 38, "745178": 35, "745925": 25, "746114": 38, "746328": [15, 21, 31], "747": [12, 18, 28], "74720920774": 37, "74798624e": 39, "748510": 36, "748725": 47, "748749e": 35, "748797": 34, "749118": 39, "75": [8, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 46, 47, 48, 55], "750": [12, 18, 28], "7500": 37, "750000": [16, 25, 37], "7503": [13, 25, 29], "7504": 50, "750401": 44, "751": 50, "752169": 25, "7524": 46, "752728": 25, "753": 27, "753286": [16, 22, 32, 33], "754": [16, 22, 32], "754165": 50, "754386": 36, "754620": 25, "754874": 40, "754938": 25, "755": [14, 47], "755000": 37, "7551": 35, "755364": [15, 21, 31], "755418": 35, "755477": [15, 21, 31], "756": 47, "7562": [12, 18, 28], "75625": 46, "757": 36, "7574257425742574": 35, "75745416": 41, "757545": 37, "757591": 46, "757932": 47, "757985": [38, 39], "758": [38, 39, 47], "758029": 26, "758062e": 37, "758259": 25, "75826": [38, 39], "758514": 35, "7588186": 45, "7588527798652649": 44, "759043": 36, "759561": 41, "75956122": 41, "7599": 34, "76": [14, 16, 20, 22, 30, 32, 34, 35, 36, 37, 39, 40, 47], "760": 47, "760262": 35, "760678": 46, "760966": 25, "76161": 35, "761945e": 37, "762": [30, 47], "7620": [12, 18, 25, 28], "762093e": 37, "76270194": 39, "763": [16, 22, 32], "763480": 25, "7639": [13, 25, 29], "764052": 40, "76470588": [14, 20, 30], "764706": [14, 15, 20, 21, 30, 31, 35], "765": 36, "765591": 36, "765601": 37, "766317e": 37, "766318": 25, "766423": 37, "766430": [15, 21, 31], "767": [37, 39, 48], "767742": 34, "767802": 35, "767819": 46, "767852": [15, 21, 31], "768": [16, 22, 32, 33, 37, 39, 48, 55], "768176": 47, "768184": 25, "768279": 48, "768512": 36, "769030": 25, "76908228": 38, "769231": [16, 22, 32], "77": [13, 14, 17, 19, 20, 23, 29, 30, 33, 34, 36, 37, 42, 46, 47, 52], "770": [13, 25, 29], "770163": 25, "7706532429048965": 38, "770833": 43, "770898": 35, "771": [16, 22, 32], "771969": [15, 21, 31], "772185": 25, "772532": 36, "7728396574320712": 25, "773017": [37, 39, 48], "773125": 21, "7736": 35, "773851": 46, "774261": 46, "774844": [17, 23, 33], "77484447": [17, 23, 33], "7750553478074826": 46, "775270": 37, "7752884548630529": 34, "775311": 39, "77536150e": 39, "7758": 35, "776": 35, "7763": [16, 22, 32, 40], "776427": 47, "77694295": 38, "77709": 35, "777600": 25, "777934": [15, 21, 31], "7781845435415525": 46, "779": [16, 22, 32, 40], "779271": 40, "78": [12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 28, 29, 30, 32, 33, 36, 37, 40, 41, 46, 47, 52], "7800": 35, "780000": 38, "780296": 37, "780298": 37, "780316": 37, "780497": 37, "78058051e": 39, "780864": 36, "781": [16, 22, 32], "781004": [15, 21, 31], "781531": 36, "7816": 37, "781975": 26, "782183": 37, "782219": [15, 21, 31], "7827": 36, "783282": 35, "783582": [15, 21, 31], "783784": 43, "783789": [15, 21, 31], "784424": 34, "784573": 40, "785": 33, "785105": 37, "785108": 37, "785134": 37, "78521263": 44, "785399": 37, "785483": 46, "785714": [16, 22, 32], "786115": 40, "78617028": 38, "786555": 37, "787": [16, 22, 32], "787574": 37, "787879": [15, 21, 31, 34], "787933": 37, "788": 30, "788374": 45, "788647472858429": 44, "7887": 39, "7891381897690047": 34, "789436": [16, 22, 32], "789657": 46, "79": [13, 14, 16, 17, 20, 22, 23, 29, 30, 32, 33, 34, 36, 37, 46, 47, 53], "790": 36, "790000": [16, 22, 32], "79041": 37, "790481e": 27, "790521": 25, "790721": 48, "790731": 34, "791017": 47, "791467": [16, 22, 32], "792": 51, "792023": [39, 48], "79250": [16, 22, 32], "792500": 15, "792577": 37, "792603": [15, 21, 31], "792828": 37, "793": 40, "793243": [16, 22, 32], "79378": 36, "7938": 33, "794": 47, "794118": [15, 21, 31], "794236": [16, 22, 32], "794820": [16, 22, 32], "795": [14, 15, 31, 35], "79500e": [15, 31], "7951": 35, "7951559890417761": 37, "795902": 46, "796": [16, 22, 32], "7964215270662811": 34, "797": [16, 22, 32], "797355": [16, 22, 32, 33], "7978563117812038": [16, 22, 32], "798": [16, 22, 32], "7982": [15, 21, 31], "7986546": 37, "799983": [15, 21, 31], "79998417": 51, "7f688092391a": 45, "7l": 22, "7pm": 40, "7th": [36, 38, 39], "8": [1, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54], "80": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 46, 47, 48, 52], "800": [12, 18, 20, 27, 28, 30, 35, 44], "800000": [35, 46], "8001": 34, "800190": [15, 21, 31], "80062924": [15, 21, 31], "800k": 48, "801219e": 37, "801666": 36, "801863": [15, 21, 31], "802502": 40, "802902": 37, "802987": [15, 21, 31], "803": [15, 16, 21, 22, 31, 32, 50], "803617": 36, "804": [15, 21, 31, 47, 50], "804818": [16, 22, 32, 33], "80482065": [17, 23, 33], "804821": [17, 23, 33], "805198": 37, "805342": 46, "805414": 26, "805970": [15, 21, 31, 34], "806": 33, "8062": [13, 25, 29], "806899": 45, "8076": 37, "807684": [15, 21, 31], "807735": 36, "8078": [12, 18, 28], "808": 47, "8080": [13, 25, 29], "808208": 36, "808958": [15, 21, 31], "809": [16, 22, 32], "8098": 47, "81": [13, 14, 15, 17, 20, 21, 23, 25, 29, 30, 31, 33, 34, 35, 36, 37, 39, 41, 46, 47, 48], "810073": [37, 39], "810098": 40, "810368": [15, 21, 31], "81071706": 35, "810811": 43, "8112": [12, 18, 28], "812272": 37, "812363": 37, "812500": [14, 30], "812593": 45, "812875": 47, "813": [16, 22, 32], "813586": 36, "815669": 36, "816200": 26, "8162831858407079": 49, "816717791411044": 47, "817": 38, "817034": 50, "817558": [16, 22, 32, 33], "8180": [16, 22, 32], "818041": 47, "818868": [16, 22, 32], "819152": [15, 21, 31], "819213": 47, "8195": 34, "819549": [15, 21, 31], "819584": [15, 21, 31], "81970188": [17, 23, 33], "819702": [17, 23, 33], "82": [13, 17, 19, 23, 29, 33, 35, 36, 42, 46, 47], "820": [15, 21, 31], "820033": 37, "820143": 34, "82025568e": 39, "820564": 37, "821040": 39, "821327": 44, "821807": 37, "8219": [16, 22, 32], "8221": 33, "8225": 50, "82273995": [17, 23, 33], "822740": [17, 23, 33], "823511": 36, "823529": [14, 15, 20, 21, 30, 31, 34], "82352941": [14, 20, 30], "823543": 40, "824849": 36, "824884": 37, "825": [16, 22, 32], "825123": 40, "8253": [15, 21, 31], "825306": 35, "825470": 47, "825697": 37, "826142": 37, "826203": 34, "826216": 37, "826513": 46, "826553": 37, "82670": 46, "826739": 37, "826758": 37, "826760": 37, "827039": 34, "827068": 34, "827130": 36, "827261": 37, "827842": 34, "827907": 35, "828": [25, 27], "8280229354283182": 37, "82804": 35, "828332": [37, 39, 48], "828358": [15, 21, 31], "828405": 46, "828682": 35, "82869879": 44, "828891": 35, "828976": 35, "829": 27, "83": [13, 14, 17, 19, 20, 23, 29, 30, 33, 35, 36, 42, 43, 44, 46, 47, 52], "830": 27, "830382": 36, "830712e": 37, "831": 27, "831135": [15, 21, 31], "831611": [37, 39], "831989": 35, "832": [16, 22, 27, 32], "832320": 34, "832370": 36, "832866": 37, "833": [15, 27, 31, 35], "83320": 46, "8334": 39, "833913": 25, "834": 27, "8340": [15, 21, 31], "834109": 35, "834356e": 37, "83437": 37, "834455": [15, 21, 31], "835": 27, "8356": 39, "835651": 35, "835749": [37, 39], "835876": 25, "83603": [37, 39], "8361313": 37, "836189": [15, 21, 31], "836735": 36, "836878e": 37, "836880e": 37, "837022e": 37, "837838": [15, 21, 31], "837848": [15, 21, 31], "838": [15, 31, 35], "83848729e": 45, "83876": 35, "8388866943476283": 34, "838951": 37, "8389756947416362": 34, "839225": 37, "84": [13, 14, 17, 19, 20, 23, 25, 29, 30, 33, 46, 47, 51, 52], "840": [16, 22, 32], "84002795": [17, 23, 33], "840028": [17, 23, 33], "840074": [14, 20, 30], "840183": 37, "840492": [37, 39, 48], "84062193": 39, "841": 37, "841208": 35, "841886": 35, "841983": 35, "842": [16, 22, 32], "842028": 36, "842064": 47, "842105": [15, 21, 31], "843": 38, "843281": 39, "843284": [15, 21, 31, 34], "843842": [16, 22, 32, 33], "843992": [37, 39], "844409": [17, 23, 33], "84440919": [17, 23, 33], "844444": 16, "844921": 41, "845": 35, "846154": [16, 22, 32, 50], "8462": 40, "846260e": 37, "846650": 37, "84679073": [15, 21, 31], "84698489": 45, "847178": 36, "847287": 35, "8475": 46, "84772": 36, "847799": 35, "847808": 36, "8478316682480326": 46, "848": [38, 39], "8481": 50, "848214": 16, "84893192": 35, "849": [38, 39], "849102e": 37, "849438e": 37, "849612": 35, "85": [13, 14, 17, 19, 20, 23, 29, 30, 33, 36, 37, 38, 39, 40, 46, 47, 52], "850": [12, 18, 28, 38, 39], "8502": 35, "850283": 46, "850503": 35, "850746": [15, 21, 31], "851460": 37, "851852": 34, "852": [47, 50], "852053": 35, "852104": 37, "852941": 34, "853125": 31, "853399": 36, "854129": 37, "854167": 43, "854500": 47, "8546143543902771": 47, "854744525547446": 47, "854749": 46, "85545875": [15, 21, 31], "85597188": [17, 23, 33], "855972": [17, 23, 33], "856": 35, "856175": [16, 22, 32], "856589": 35, "856722": 26, "857": 37, "857457": 26, "857874": 35, "858": 34, "8580": [16, 22, 32, 33, 55], "858209": [15, 21, 31, 34], "858915": 35, "859": 38, "859318": 37, "859439": 41, "85943906": 41, "859455": 47, "85969": 35, "859799": 35, "86": [13, 15, 17, 19, 23, 29, 31, 33, 34, 35, 36, 40, 46, 47], "860": [36, 39], "86000e": [15, 31], "8601643854446082": 37, "860677": 36, "861": [16, 22, 32], "86102": 46, "861157": 48, "861348": 35, "862432": 37, "862552": [16, 22, 32], "8625888648969532": 47, "86267067": [17, 23, 33], "862671": [17, 23, 33], "862997": 40, "863014": 34, "863889": 46, "863941": 37, "864": 38, "86400": 46, "8641864337292489": 47, "864205": 39, "864292": 26, "865562": 47, "8661": 50, "866110": 34, "866667": [14, 30, 36], "866980": 37, "867434": 45, "867558": 40, "868003": 37, "868281": 37, "868305": 37, "868308": 37, "869077": [17, 23, 33], "86907725": [17, 23, 33], "869094": 35, "8691": 33, "869531": [15, 21, 31], "869964": 35, "87": [13, 16, 17, 22, 23, 29, 32, 33, 36, 46, 47], "870": [38, 39], "870503": 45, "871": [35, 38], "871094": 46, "8711": 36, "871200": 25, "872": [38, 39], "872093": 35, "872603": 45, "872722908439952": 39, "8727229084399575": 39, "872961060": 37, "8729610607986": 37, "873": 38, "8731": [37, 39, 48], "873103": [15, 21, 31], "873182": 46, "873356": [15, 21, 31], "873643": 35, "873704": 37, "874062": [17, 23, 33], "87406235": [17, 23, 33], "874305": 46, "874516": 35, "874532": 37, "874767e": 37, "874962": 26, "875": 36, "8750": [16, 22, 32, 40], "875000": [14, 16, 30], "876065": 35, "876540": 47, "876566e": 25, "876574": [16, 22, 32, 33], "87681182": 44, "877046": 40, "877390": 39, "877519": 35, "877551": 36, "878183": [15, 21, 31], "87844893": 37, "87849316": 34, "879": [16, 22, 32], "87907": 35, "879938": 35, "88": [13, 14, 16, 17, 20, 22, 23, 29, 30, 32, 33, 34, 36, 40, 47, 55], "880": 40, "8801": 44, "880348": 35, "880831": 46, "881395": 35, "881720": 36, "883138": 35, "884586": 35, "885": [12, 18, 28, 33], "885044": [37, 39, 48], "885968": 47, "886047": 35, "886759": 34, "887": 38, "887017": 36, "887159": 46, "8873": 36, "887324": 36, "887343": [15, 21, 31], "887597": 35, "887701": 36, "8878117": [17, 23, 33], "887812": [17, 23, 33], "888": [35, 38, 39], "888066": 39, "888372": 35, "888513": 36, "888811": 35, "888889": [16, 22, 32, 34], "888961": 39, "889086": 37, "889147": 35, "889429": 46, "889921": 46, "89": [13, 14, 17, 19, 20, 23, 29, 30, 33, 36, 42, 46, 47, 52], "890": [27, 38], "890456": 25, "890457": 37, "890933": 47, "891001": 36, "891557": 35, "892476": 36, "892477": [15, 21, 31], "892491": [16, 22, 32], "89270": 40, "892733": 46, "892961": 40, "893000": [16, 22, 32], "893260": [17, 23, 33], "8937442459553657": 39, "894": [16, 22, 32], "894587": 48, "894960": 25, "895": 38, "895349": 35, "895541": 37, "89572": 46, "895833": 36, "895963": 34, "897010": [16, 22, 32, 33], "89706451e": 39, "897674": 35, "898": 39, "898016": 35, "898243": 26, "898703e": 37, "899": [16, 22, 32, 33, 35, 38, 55], "8994": 39, "8997": 37, "899736": 25, "899969": 46, "8m": 45, "8th": [36, 38, 39], "9": [1, 4, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 56], "90": [8, 12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 28, 29, 30, 31, 33, 36, 37, 42, 43, 46, 47, 52], "900": [17, 23, 33, 35, 36], "90000": 46, "900000": [14, 20, 30, 46], "900000e": 25, "900662": [14, 20, 30], "901085": 34, "9010852321946792": 34, "901262": 46, "90159483": 41, "901595": 41, "902343": 26, "902401": 35, "903101": 35, "903422": 26, "904": [15, 21, 31, 35], "90403853": [17, 23, 33], "904039": [17, 23, 33], "904226": [15, 21, 31], "904565": 26, "9047619047619048": [13, 19, 29], "904902": 45, "904930e": 25, "905": [15, 16, 21, 22, 31, 32], "905000": 21, "905327": 46, "906667": [14, 20, 26, 30], "90669": 40, "906865": [14, 20, 30], "907": 47, "907143": 50, "907595": 46, "908": [16, 22, 32], "908140": [16, 22, 32, 33], "908215": 37, "909091": [16, 22, 32], "90982": 40, "91": [13, 14, 16, 17, 19, 20, 22, 23, 25, 29, 30, 32, 33, 35, 36, 40, 41, 46, 52], "910": [13, 17, 23, 25, 29], "9100": 46, "910018": 37, "910174": 37, "9103": 46, "910456e": 37, "91063776": 39, "910714": 50, "9108334653214172": 25, "910843": 37, "911": 27, "911615": 37, "911846": 37, "912": [16, 22, 32], "912395": 39, "913333": [14, 20, 26, 30], "913767": 37, "913849": 37, "914003": 39, "914451894267": 37, "914585": 39, "91515735": 37, "915714e": 37, "915952": 37, "916254": [15, 21, 31], "916347": 26, "916722": 39, "917526": 36, "917837": 36, "918": [25, 38], "918124": 36, "918191": 45, "9182": 46, "919198": 39, "9196": [12, 18, 28], "92": [13, 14, 17, 19, 20, 23, 29, 30, 33, 36, 42, 45, 46, 47, 52], "920000": [14, 20, 26, 30], "9203": 35, "920305": 40, "920462": 39, "9212": 16, "92120500e": 51, "921422": 47, "921435": 26, "921438": 37, "921850": 37, "92195464": 39, "921955": 39, "922": 33, "923077": 36, "923283": [16, 22, 32, 33], "923432": 39, "924485": 40, "9245": [14, 20, 30, 34], "925272e": 37, "925288e": 37, "925593": [15, 21, 31], "925768": 36, "926657": 37, "926667": 26, "926733e": 37, "926829": 36, "928": 35, "92809": 40, "92852376": [15, 21, 31], "929": 35, "9295": 35, "93": [13, 14, 17, 19, 20, 23, 29, 30, 33, 34, 35, 41, 46, 47, 52], "930000": [16, 22, 32], "930062": 25, "930123": [15, 21, 31], "930561": [15, 21, 31], "9308647034083802": 25, "931439e": 37, "931786": 34, "931896": 25, "932": [16, 22, 32], "932070": 47, "932124": [15, 21, 31], "932143": 50, "93279": 46, "933275": 36, "933333": 26, "9336": [16, 22, 32], "934": 27, "934205": [15, 21, 31], "934269": [16, 22, 32, 33], "934783": 36, "9351": 40, "935512": 47, "935802": [15, 21, 31], "93665": 46, "937429": 48, "9375": [14, 20, 30], "937500": [14, 17, 20, 23, 30, 33], "938": 36, "938201": 25, "9383": [15, 21, 31, 34], "93869659": [17, 23, 33], "938697": [17, 23, 33], "939006": 36, "9391": 37, "939394": [15, 21, 31, 34], "939805": 25, "94": [13, 14, 16, 17, 19, 20, 22, 23, 29, 30, 32, 33, 34, 35, 36, 37, 46, 52, 55], "940000": 26, "9401": 46, "9406": [13, 14, 20, 29, 30, 53], "941": 47, "9410": 25, "941176": [14, 17, 20, 23, 30, 33], "94117647": [14, 20, 30], "942": 27, "943609": 40, "944": [12, 18, 28], "944092": 36, "944354": 33, "945000": 26, "945968": 26, "946667": 26, "946783": [15, 21, 31], "947": [16, 22, 32, 35, 50], "9471": 35, "948482": 47, "94888": 36, "949": [16, 17, 22, 23, 32], "9490": [16, 22, 32], "9492": 37, "94933723": 37, "94959681": [17, 23, 33], "949597": [17, 23, 33], "95": [13, 14, 17, 19, 20, 23, 29, 30, 33, 36, 42, 46, 47, 48], "950000": [16, 22, 32], "950088": 40, "9505": 39, "950564": 40, "9506": 39, "950696": 47, "950733": [15, 21, 31], "951294": 37, "951574": 40, "951644": 40, "951667": 26, "951669": 40, "951696": [15, 21, 31], "953": 38, "9530973451327434": 49, "953333": 26, "95511263": [15, 21, 31], "955113": [15, 21, 31], "9558": 46, "956": [16, 22, 32], "956966": 40, "957075": 40, "9573": 46, "9576": [12, 18, 28], "957886": 45, "957919": [15, 21, 31], "957987": [15, 21, 31], "9583333333333334": 45, "958393": [16, 22, 32, 40], "95886206e": 45, "959": [16, 22, 27, 32], "959139": 39, "959402e": 37, "959870": 36, "959873": 47, "96": [13, 17, 23, 29, 33, 34, 35, 36, 40, 46], "960": [17, 23, 27, 34], "960000e": 27, "961": 27, "961109802000133": 42, "961404": [16, 22, 32, 33], "961498": [37, 39, 48], "961771": 34, "961898": 34, "962": 27, "962036": 36, "963": 27, "963024": 25, "963097": 36, "96319": 46, "96320": 46, "96321": 46, "96322": 46, "96323": 46, "96325": 46, "963333": 26, "963689": 40, "964": 27, "96554": 40, "9661": 37, "966131": [16, 22, 32, 33], "9664": [13, 14, 20, 29, 30, 53], "966667": 26, "966812": 25, "967907": 36, "968": [16, 22, 32], "968233": 40, "968236": 36, "96833": 44, "968333": 26, "96834506": [15, 21, 31], "968493": 47, "968514e": 37, "96875": 45, "969048e": 37, "9691": 37, "9692602666681306": 34, "96965253": 39, "969653": 39, "97": [13, 14, 16, 17, 20, 23, 29, 30, 33, 34, 35, 39, 42, 46, 47], "970518": 36, "970683": 40, "971": 33, "97203586": [17, 23, 33], "972036": [17, 23, 33], "97217": 46, "972198": 35, "97223953": [17, 23, 33], "972240": [17, 23, 33], "972440": 36, "97253": 46, "9730": 33, "973225": 36, "973280": [17, 23, 33], "97328024": [17, 23, 33], "973294": 27, "973333": 26, "973482e": 35, "973750": [15, 31], "974": [16, 22, 32], "974183": 26, "974480": 40, "974531": 26, "9748": 34, "974801e": 37, "975104": 27, "975895": 46, "976": [16, 22, 32, 36, 38], "976667": 26, "977": [16, 22, 32, 46], "977278": 40, "9773": [13, 14, 15, 20, 21, 29, 30, 31, 53], "978": 34, "9781449369880": 46, "9781789957211": 45, "97823755": 34, "9785299": 44, "978738": 40, "979": [38, 39], "979562": 47, "98": [13, 16, 17, 22, 23, 29, 32, 33, 34, 37, 39, 41, 44, 46, 47, 48], "980": 46, "980000": 26, "98001": 25, "98007": [12, 18, 28], "98010": 25, "98024": 25, "98027": 25, "98028": [13, 25, 29], "98033": 25, "98038": 25, "98039": 25, "98045": [12, 18, 28], "98052": [12, 18, 25, 28], "98055": [12, 18, 28], "980634": 47, "98065": 25, "98072": [12, 18, 28], "98074": [13, 25, 29], "98075": [12, 18, 28], "98077": 25, "9808": 34, "980962": 26, "98102": 25, "98103": 25, "98107": [12, 18, 28], "98112": [12, 18, 28], "98115": 25, "98116": [12, 18, 28], "98117": 25, "98118": 25, "981195": 46, "98125": [13, 25, 29], "98136": [13, 25, 29], "98144": 25, "98146": 25, "98148": 25, "981643": 25, "981735": 34, "98178": [13, 25, 29], "98199": 25, "982": 33, "982184": 35, "982570": 47, "983": 45, "983333": 26, "983340": 25, "9837": [14, 20, 30, 34], "984": 35, "984653": 34, "984664": 37, "985000": 26, "985283": 35, "9854": [13, 14, 20, 29, 30, 34, 53], "985457": 47, "985816": [14, 30], "986047": 35, "9862": 50, "986207": 35, "987": [35, 45], "987062": 37, "987597": 35, "9876": [38, 39], "987681": 40, "988": 40, "9881": [13, 14, 20, 29, 30, 53], "988333": 26, "988381": 35, "988841": 35, "988901": 37, "989": [13, 19, 29], "989147": 35, "989156": 35, "989443": 47, "989922": 35, "989973": 34, "99": [13, 14, 16, 17, 20, 22, 23, 27, 29, 30, 32, 33, 35, 36, 46], "990631": 46, "990754": 46, "9912": [15, 21, 31, 34], "9915": 46, "991667": 26, "991810": 25, "991966": 47, "992": [30, 35], "992220": 25, "992254": 35, "99240562": 39, "992406": 35, "992569": 27, "9926": 33, "992857": [14, 30], "992908": 30, "993023": 35, "993029": 35, "993065": 47, "9931": [13, 14, 20, 29, 30, 53], "993333": 26, "9934531067299874": 34, "993666": 39, "993969": [37, 39, 48], "994": [12, 18, 28], "994266": 35, "994574": 35, "994764": 46, "995": [40, 45], "9950": 40, "9951": [13, 14, 20, 29, 30, 53], "99515": 46, "995434": 37, "996424": 25, "996487": 25, "996588e": 37, "996765": 39, "996788": 47, "996820": 47, "996899": 35, "99744241e": 39, "9977957422135844": 39, "998": [36, 47, 50], "9983": 36, "998302": 36, "998370": 25, "998440": 25, "99845": 35, "998451": 35, "999": [34, 50], "99907": 35, "999122": 36, "9991338290544213": 25, "999147": 36, "999172": 36, "999178": 25, "999183": 36, "999185": 36, "999192": 36, "999210": 36, "999213": 25, "999214": 36, "999221": 36, "999223": 36, "999225": 35, "999254": 36, "999298": 36, "999317": 36, "99931882": 37, "999335": 36, "999438": 25, "9994394006711425": 25, "999480": 25, "999518": 25, "999535": 35, "999539": 25, "999544": 25, "999545": 25, "999546": 25, "999558": 25, "999562": 25, "999567": 25, "999577": 46, "999622": [16, 22, 32], "9999": [12, 18], "9am": 40, "9th": [36, 38, 39], "A": [0, 1, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 47, 48, 49, 51, 52, 56], "AND": [0, 37], "AS": 0, "And": [12, 13, 18, 28, 29, 35, 37, 44, 46, 47, 48, 53, 54], "As": [4, 14, 17, 20, 21, 23, 30, 33, 35, 37, 38, 39, 43, 46, 47, 48, 49, 51, 54, 56], "At": [4, 12, 14, 18, 25, 27, 28, 30, 34, 36, 38, 40, 41, 45, 46], "BE": [0, 44], "BUT": [0, 8], "BY": [0, 1], "Be": [7, 12, 15, 18, 21, 31, 39, 48, 49, 52, 54], "Being": 45, "But": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 54, 56], "By": [11, 12, 14, 15, 17, 18, 20, 21, 23, 26, 28, 30, 31, 33, 36, 38, 41, 44, 45, 47, 48, 54], "FOR": 0, "For": [0, 1, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 56], "IN": [0, 14, 20, 30, 34], "IT": 34, "If": [4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56], "In": [1, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56], "Ines": 50, "It": [2, 4, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 54, 56], "Its": 47, "NEAR": [16, 22, 32, 33, 40, 55], "NO": 0, "NOT": [0, 8, 17, 23, 33, 34], "No": [0, 12, 13, 18, 19, 27, 28, 29, 37, 38, 39, 40, 42, 46, 47, 48, 52], "Not": [36, 37, 38, 39, 40, 41, 43, 46, 47], "OF": 0, "OR": [0, 8, 37], "Of": [9, 17, 23, 33, 35], "On": [4, 7, 12, 16, 17, 18, 22, 23, 25, 26, 27, 28, 32, 33, 35, 36, 37, 38, 39, 40, 42, 45, 47, 48, 50], "One": [5, 8, 13, 14, 17, 19, 20, 23, 27, 29, 30, 33, 34, 35, 36, 39, 41, 42, 47, 52], "Or": [15, 17, 21, 26, 31, 33, 35, 48, 54], "Such": [6, 43, 46], "THE": [0, 14, 20, 30], "TO": [0, 44], "That": [13, 14, 16, 19, 20, 22, 29, 30, 32, 34, 35, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49], "The": [0, 2, 5, 7, 8, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 36, 37, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56], "Their": 5, "Then": [13, 19, 29, 34, 38, 41, 46, 49], "There": [1, 2, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 56], "These": [4, 10, 13, 14, 15, 19, 20, 21, 29, 30, 31, 34, 36, 37, 38, 39, 40, 41, 43, 46, 48], "To": [8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 40, 42, 44, 45, 46, 48, 49, 50, 54, 56], "WITH": 0, "Will": [36, 47, 50, 52], "With": [0, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 26, 28, 29, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 43, 45, 47, 51, 54], "_": [38, 44, 45, 47, 50], "__array__": 27, "__call__": [17, 23, 33], "__class__": [34, 46], "__finalize__": 47, "__getitem__": [22, 30, 32, 50], "__name__": [34, 46], "__sklearn_tags__": 27, "__testing_word2vec": 44, "_array_api": 27, "_asarray_with_ord": 27, "_assert_all_finit": 27, "_assert_all_finite_element_wis": 27, "_astype_nansaf": 47, "_base": 27, "_california_housing_dataset": 34, "_call_func_on_transform": [17, 23, 33], "_check_i": 27, "_classif": 27, "_column_transform": [17, 23, 33], "_constructor_from_mgr": 47, "_data": 35, "_deprecate_force_all_finit": 27, "_distn_infrastructur": 35, "_encod": [17, 23, 33], "_estim": 27, "_fit": 27, "_fit_context": 27, "_get_sequential_output": [17, 23, 33], "_i": 45, "_is_numpy_namespac": 27, "_logist": 51, "_mgr": 47, "_proba": 38, "_score": [17, 23, 33], "_scorer": [17, 23, 33], "_set_output": [17, 23, 33], "_time_fit_was_cal": 47, "_transform": [17, 23, 33], "_transform_on": [17, 23, 33], "_valid": [17, 23, 33], "_validate_param": 27, "_valu": 27, "_x_subset": 14, "ab": [34, 36, 37, 39], "abbrevi": 44, "abdelrahman": [1, 56], "abil": [12, 17, 18, 23, 28, 33, 35, 39, 44, 46, 54], "abl": [8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 48, 49, 54], "about": [1, 2, 4, 7, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56], "abov": [0, 5, 8, 10, 12, 13, 14, 15, 18, 19, 20, 21, 25, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 51, 54, 56], "absenc": [17, 23, 33, 39, 43], "absolut": [11, 27, 34, 36, 37, 39, 41, 50], "abspath": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54], "academ": [1, 7, 40, 49], "accept": [5, 8, 27, 36, 37, 44, 49], "accept_large_spars": 27, "accept_spars": [17, 23, 27, 33], "access": [1, 10, 12, 14, 18, 20, 22, 30, 32, 35, 38, 41, 43, 44, 46, 48, 49, 50], "accessori": 46, "accident": [15, 16, 21, 22, 31, 32, 49], "accomod": 7, "accompani": [7, 12, 13, 18, 28, 29], "accomplish": [26, 49], "accord": [34, 36, 37, 40, 43, 47, 56], "account": [1, 7, 12, 14, 18, 30, 36, 40, 43, 47, 49, 52], "accur": [12, 14, 18, 20, 28, 30, 38, 39, 40, 43, 47, 48, 52, 53], "accuraci": [11, 13, 14, 15, 16, 19, 20, 21, 22, 25, 26, 29, 30, 31, 32, 35, 36, 38, 39, 40, 42, 45, 47, 48, 50, 52, 53, 56], "accuracy_scor": 36, "acdm": [36, 38, 39], "acf": 46, "achiev": [8, 15, 21, 31, 36, 49], "acinonyx": [12, 18, 28, 45], "acoust": [15, 16, 22, 31, 32, 35], "acquir": 11, "acquisit": 43, "across": [12, 13, 14, 16, 18, 19, 20, 22, 28, 29, 30, 32, 36, 39, 45, 56], "act": [34, 56], "action": [0, 12, 18, 28, 38, 39, 41, 43, 44, 47, 56], "activ": [4, 10, 28, 35, 50, 52, 56], "actor": [43, 44], "actual": [7, 12, 18, 23, 28, 34, 36, 38, 39, 41, 43, 44, 46, 47, 48], "ad": [17, 23, 33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 47, 50], "adapt": [0, 16, 17, 22, 23, 32, 33, 36, 38, 44, 46, 48, 50], "add": [7, 8, 10, 14, 16, 22, 32, 33, 36, 37, 38, 39, 40, 42, 44, 46, 47, 49, 50, 55], "add_pip": 50, "addit": [0, 4, 12, 18, 37, 43, 48, 56], "addition": [53, 54, 56], "address": [42, 49], "adelaid": 46, "adio": 48, "adj": [44, 50], "adject": 44, "adjust": [15, 21, 26, 31, 35, 42, 46, 54], "adm": [36, 38, 39], "admin": [1, 56], "administr": 1, "admit": [14, 30], "adopt": [6, 43], "adp": [44, 50], "adult": [36, 38, 39], "adult_df_larg": [38, 39], "adv": 44, "advanc": [11, 17, 23, 33, 35, 41, 42, 43, 44, 45, 53], "advantag": [11, 16, 17, 22, 23, 32, 33, 34, 38, 42, 43, 44, 52], "advic": 47, "advis": [12, 18, 28], "advisor": 56, "af": 39, "affect": [10, 15, 16, 21, 22, 31, 32, 34, 35, 36, 41, 46, 47, 49, 54], "affix": 44, "aft": 49, "after": [4, 6, 10, 14, 16, 17, 20, 22, 23, 30, 32, 33, 36, 37, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 56], "ag": [12, 18, 27, 28, 34, 36, 37, 38, 39, 40, 43], "again": [10, 14, 16, 19, 20, 22, 25, 26, 27, 29, 30, 32, 42, 43, 44, 45, 47, 49, 54], "against": [43, 44, 46], "agenc": [44, 50], "agent": 1, "agglomerativeclust": 42, "aggress": 44, "agnost": 39, "ago": [45, 46], "agre": 54, "agreement": [47, 56], "ahm": [1, 56], "ai": [7, 9, 36, 40, 44, 45], "aight": [12, 18, 28], "aim": [27, 52], "ain": 44, "airplan": 48, "airport": [36, 49], "aka": [34, 47], "al": [38, 44], "alain": [1, 56], "alamine_aminotransferas": [12, 18, 28], "alan": 1, "alaska": 34, "alberta": 44, "album": 35, "albumin": [12, 18, 28], "albumin_and_globulin_ratio": [12, 18, 28], "alburi": 46, "alexand": 48, "alexnet": 45, "algebra": [43, 44], "algorithm": [2, 11, 12, 14, 16, 17, 18, 22, 23, 26, 28, 30, 32, 33, 36, 37, 38, 39, 42, 44, 45, 48, 49, 53, 54, 55], "align": [8, 12, 13, 14, 18, 19, 20, 28, 29, 30], "align_kei": 47, "alison": [1, 56], "aliv": 49, "alkaline_phosphotas": [12, 18, 28], "all": [0, 1, 4, 5, 6, 7, 8, 10, 14, 15, 17, 19, 20, 21, 22, 23, 25, 26, 27, 30, 31, 33, 35, 37, 38, 39, 40, 44, 45, 46, 47, 49, 50, 51, 54, 55, 56], "all_cap": 50, "all_featur": 46, "allei": [37, 39, 48], "allen": 50, "alley_grvl": 37, "alley_miss": 37, "alley_pav": 37, "alloc": [8, 44, 45], "allow": [5, 7, 10, 14, 16, 22, 27, 30, 32, 35, 36, 40, 44, 46, 47, 49, 53, 54, 56], "allow_nan": 27, "allow_nd": 27, "allpub": [37, 39, 48], "allya": [1, 56], "almost": [34, 35, 37, 40, 42, 43, 44], "along": [7, 13, 17, 23, 29, 33, 36, 45, 46, 48, 53], "alpha": [15, 16, 21, 22, 26, 31, 32, 46, 54], "alpha_": 37, "alphabet": 34, "alphago": [12, 18, 28, 41], "alq": [37, 39, 48], "alreadi": [4, 8, 10, 11, 12, 18, 36, 37, 39, 41, 44, 46, 47, 48, 50, 53], "also": [1, 2, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56], "altar": 45, "altern": [8, 26, 35, 41, 48, 56], "although": [14, 20, 30, 38, 41, 43, 47], "alwai": [12, 13, 15, 17, 18, 19, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 50, 52, 53, 54, 56], "am": [16, 18, 22, 32, 41, 44, 48, 50, 56], "amatriain": 43, "amaz": 27, "amazon": [12, 18, 28, 41, 43, 50], "ambienc": 27, "ambigu": 44, "amer": 36, "america": [17, 33, 44], "american": [27, 41], "amirali": [1, 56], "aml": [16, 22, 32], "among": [12, 13, 18, 19, 28, 29, 35, 36, 38, 39, 43], "amongst": 50, "amount": [4, 12, 14, 18, 20, 28, 30, 34, 35, 36, 37, 39, 41, 45, 46, 47, 49], "amp": [38, 39], "amplifi": [36, 44], "amuel": [16, 22, 32], "an": [0, 1, 2, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 55, 56], "anaconda": [10, 39, 50], "anaconda3": [19, 23], "analogi": [21, 42, 44, 48], "analysi": [1, 2, 9, 11, 13, 29, 36, 37, 41, 42, 44, 48], "analyt": 46, "analyz": [11, 36, 40, 46, 47, 48], "anatinu": 45, "anca": [1, 56], "ancestor": 40, "ancestr": 56, "ancuta": [1, 56], "andrea": [1, 9], "andrew": [1, 9, 26, 35, 40, 56], "anemon": 45, "angel": [47, 50], "ani": [0, 10, 13, 14, 16, 17, 19, 20, 22, 23, 25, 27, 29, 30, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56], "anim": [26, 36, 45], "animal_fac": [26, 45], "anneal": 40, "annot": [39, 41], "announc": 7, "annoyingli": 37, "annual": 50, "anomali": [36, 37, 41], "anonym": 46, "anoth": [8, 10, 13, 15, 19, 21, 29, 31, 34, 35, 36, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 52, 53, 55], "answer": [4, 6, 7, 12, 13, 14, 18, 20, 28, 29, 30, 35, 38, 41, 43, 44, 46, 48, 51, 53, 54, 56], "anteat": 45, "anti": 47, "anymor": [37, 41, 43, 54], "anyon": [12, 48, 49], "anyth": [0, 12, 14, 17, 18, 20, 23, 27, 30, 33, 36, 43, 44, 47, 49], "anytim": 56, "anywher": [17, 23, 33], "ap": [11, 52], "ap_lr": 36, "ap_svc": 36, "apart": [15, 21, 31, 42], "apeendixa": 40, "api": [27, 36, 44, 46, 52], "app": [12, 13, 18, 19, 29, 52], "appeal": 44, "appear": [2, 7, 17, 23, 33, 38, 49, 54, 56], "append": [4, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 50, 53, 54, 55], "appendix_b": 44, "appendixb": 45, "appl": 44, "appli": [0, 2, 6, 9, 11, 12, 13, 14, 18, 19, 20, 27, 28, 29, 30, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 55], "applic": [0, 5, 12, 17, 18, 23, 28, 33, 35, 36, 37, 39, 40, 44, 47, 49, 52, 56], "appreci": [11, 41, 56], "approach": [1, 11, 14, 15, 16, 17, 21, 22, 23, 26, 27, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 44, 45, 52, 54], "appropri": [0, 4, 10, 11, 13, 14, 17, 19, 20, 23, 25, 29, 30, 33, 36, 37, 41, 42, 46, 47, 49, 52, 56], "approv": [36, 56], "approx": [15, 21, 31, 39], "approxim": [13, 19, 29, 35, 40, 49], "apr": 1, "april": 46, "apt": 5, "ar": [0, 1, 2, 4, 6, 7, 8, 9, 10, 14, 15, 17, 19, 20, 21, 23, 25, 26, 27, 30, 31, 33, 35, 37, 38, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56], "arang": [8, 14, 15, 20, 21, 25, 26, 30, 31, 34, 35, 36, 37, 54], "arbitrari": [39, 41, 42, 46], "architectur": 45, "area": [35, 37, 38, 40, 41, 48], "aren": [7, 37, 40, 41, 44, 45, 46, 50], "arena": 40, "arg": [14, 17, 20, 23, 26, 27, 30, 33], "argh": 47, "argmax": 26, "argmin": [14, 15, 20, 21, 30, 31, 36, 41], "argsort": [39, 44], "argu": [18, 41, 44], "argument": [8, 13, 17, 19, 23, 29, 33, 35, 36, 37, 39, 48, 50, 52, 55], "arima": 46, "arima_model": 46, "aris": [0, 12, 28, 44], "aristotl": [15, 21, 31], "arithmet": 8, "aroth85": 24, "around": [7, 15, 17, 21, 23, 31, 33, 36, 37, 46, 47, 53], "aroundn": [12, 28], "arr": [27, 47], "arr1": 8, "arr2": 8, "arrai": [13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51], "array_equ": 8, "array_orig": 27, "arriv": 40, "art": 48, "arthur": [12, 18, 28], "articl": [1, 13, 14, 16, 19, 22, 29, 30, 32, 36, 41, 43, 44, 45, 48], "articul": [48, 52], "artifici": [1, 44], "artist": [15, 16, 22, 31, 32, 35], "as_fram": [15, 21, 26, 31, 54], "asarrai": 27, "ascend": [8, 17, 23, 25, 33, 34, 35, 37, 38, 39, 40, 46, 47, 52], "ased": 42, "asia": [17, 33], "asid": [4, 14, 20, 30, 38, 54], "ask": [3, 7, 10, 12, 13, 14, 15, 17, 18, 19, 20, 23, 28, 29, 30, 31, 33, 36, 40, 41, 43, 44, 47, 48, 50, 53, 56], "asleep": 34, "aspartate_aminotransferas": [12, 18, 28], "aspect": [34, 39, 40, 42, 43, 47, 48, 52], "assault": 56, "assert": [7, 17, 23, 33, 36, 38, 39], "assess": [1, 6, 11, 12, 13, 14, 16, 18, 19, 20, 22, 27, 28, 29, 30, 32, 36, 39, 41, 48, 56], "assign": [1, 4, 6, 8, 10, 12, 13, 15, 16, 18, 19, 21, 22, 26, 29, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 52, 53, 55], "assist": [12, 18, 28], "assoc": [36, 38, 39], "associ": [0, 12, 14, 15, 18, 19, 20, 21, 28, 30, 31, 36, 37, 39, 40, 41, 44, 45, 46, 47, 48, 49, 52, 56], "assum": [12, 13, 17, 18, 23, 28, 29, 33, 34, 36, 37, 42, 43, 44, 46, 48, 52], "assumpt": 47, "asterisk": 35, "astyp": [8, 26, 27, 46, 47], "astype_arrai": 47, "astype_array_saf": 47, "astype_is_view": 27, "atratu": 45, "attack": [13, 19, 29], "attempt": [14, 20, 26, 30], "attend": 56, "attent": [6, 44, 49], "attic": 37, "attract": 44, "attribut": [0, 1, 12, 13, 15, 16, 18, 19, 21, 22, 28, 29, 31, 32, 34, 35, 40, 41, 44, 45], "attrit": 47, "auc": [11, 47, 49, 52], "audienc": [11, 48, 49], "audio": [45, 56], "audit": [49, 56], "auditor": 56, "augment": 36, "august": 46, "austin": 44, "australia": 46, "authent": 41, "author": [0, 44, 56], "auto": [12, 18, 28, 35, 36, 40, 41, 48], "autocorrel": 46, "autom": [13, 19, 29, 37, 44, 48], "automat": [16, 17, 22, 23, 32, 33, 37, 40, 44, 46, 47, 48], "autoregress": 34, "autumn": 46, "autumn_month": 46, "aux": [44, 50], "av": [37, 39, 44, 48], "avail": [0, 1, 7, 9, 10, 12, 14, 17, 18, 19, 20, 23, 30, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 52, 56], "avebedrm": 34, "aveoccup": 34, "averag": [11, 14, 15, 17, 20, 21, 23, 30, 31, 33, 34, 35, 37, 39, 41, 42, 44, 47, 49, 50, 52, 54], "average_precis": 36, "average_precision_scor": 36, "average_word_length": 50, "averaging_model": 38, "averaging_model_ndt": 38, "averoom": 34, "avg": [36, 43, 46], "avg_sent_emb": 44, "avocado": 48, "avoid": [7, 8, 13, 16, 22, 29, 32, 36, 37, 42, 46, 47, 48, 49, 51, 52, 54, 56], "aw": 49, "awai": [4, 6, 13, 19, 29, 34, 41, 43, 45, 47, 48, 49, 52], "awar": [17, 23, 33, 47, 48, 56], "awesom": 9, "ax": [14, 15, 20, 21, 26, 30, 31, 34, 36, 41, 42, 45, 47, 48, 54], "axi": [7, 8, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 26, 28, 29, 30, 32, 33, 34, 39, 41, 42, 44, 45, 46, 48], "axvlin": 41, "az": 50, "b": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 48], "b3": [32, 39, 50], "babe": [12, 18, 28], "babi": [40, 44], "bachelor": [36, 38, 39], "back": [8, 16, 22, 25, 26, 32, 35, 44, 52], "backdrop": 46, "background": [11, 29, 48, 49], "bad": [8, 13, 14, 15, 19, 20, 21, 27, 29, 30, 31, 33, 36, 37, 38, 39, 40, 41, 45, 46], "badgeryscreek": 46, "bag": [27, 40, 44, 45, 52], "bai": [16, 22, 32, 33, 40], "baidu": [14, 30], "bal_scor": 36, "balanc": [6, 15, 21, 27, 31, 38, 41, 43, 51], "ballarat": 46, "balltre": 27, "balust": 45, "balustrad": 45, "bambi": 43, "banist": 45, "bank": [36, 39, 46, 47], "bannist": 45, "bar": [36, 37, 39, 45, 46, 47, 48, 49], "baranski": 50, "barbu": [1, 56], "barri": 34, "base": [5, 8, 10, 11, 13, 14, 16, 17, 19, 20, 21, 22, 23, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 39, 41, 42, 44, 47, 48, 49, 50, 52, 53, 56], "base_scor": 38, "base_valu": 39, "baseblockmanag": 47, "baselin": [26, 47, 49, 52, 53, 55], "baseline_hazard_": 47, "bash": 5, "basi": [13, 15, 19, 21, 29, 31], "basic": [2, 8, 12, 13, 18, 19, 29, 35, 40, 43, 45, 47, 50], "batch": [26, 44, 45], "batch_siz": [26, 45], "batch_t": 45, "bath": [12, 18, 28], "bathroom": [12, 13, 18, 25, 28, 29, 34], "bayesian": 35, "bayesopt": 35, "bazazeh": [1, 56], "beagl": [12, 18, 28, 45], "bear": 45, "beat": [38, 47], "beauti": [43, 44, 48], "becam": 45, "becaus": [1, 7, 8, 10, 14, 15, 16, 17, 21, 22, 23, 26, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 56], "becom": [4, 14, 15, 20, 21, 30, 31, 34, 35, 36, 39, 40, 41, 44], "bed": [36, 49], "bedroom": [12, 13, 18, 19, 25, 28, 29, 34], "bedroomabvgr": [37, 39, 48], "bedrooms_per_household": [16, 22, 32, 33, 55], "beef": [27, 44], "been": [1, 4, 6, 12, 13, 16, 17, 18, 22, 23, 28, 29, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 54, 56], "befor": [1, 4, 10, 13, 14, 15, 17, 19, 20, 21, 23, 27, 28, 29, 30, 31, 33, 34, 37, 38, 41, 42, 43, 44, 45, 46, 47, 49, 53, 54], "begin": [27, 29, 34, 40, 43, 46, 47, 52], "beginn": 45, "behav": [35, 39], "behavior": [22, 30, 32, 36, 43, 49, 50], "behaviour": [17, 23, 33], "behind": [11, 12, 18, 28, 34, 56], "being": [4, 12, 14, 16, 18, 20, 22, 28, 30, 32, 36, 37, 38, 39, 42, 44, 47, 48, 54, 56], "belief": 48, "believ": [25, 35, 39, 46], "bell": 45, "belong": [13, 29, 34, 42, 53], "below": [1, 5, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56], "bench": 45, "benchmark": [25, 45], "bendigo": 46, "benefici": [17, 23, 33, 48], "benefit": [4, 15, 31, 38, 42, 44, 48, 52], "bengio": 35, "ber": 44, "bergstra": 35, "berri": 44, "bertop": 44, "best": [2, 13, 14, 15, 19, 20, 21, 22, 25, 29, 30, 31, 35, 36, 37, 38, 39, 41, 42, 43, 47, 48, 49, 53, 54], "best_alpha": 37, "best_c": 26, "best_depth": [14, 20, 25, 30], "best_estimator_": [35, 37], "best_k": 26, "best_n_neighbour": [15, 21, 31], "best_param": [35, 48], "best_paramet": 35, "best_params_": [35, 37, 48], "best_scor": 35, "best_score_": [35, 37], "best_svr": 48, "bestalpha_coeff": 37, "better": [6, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 26, 27, 28, 29, 31, 32, 33, 34, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 52, 53, 54, 55, 56], "between": [2, 8, 10, 11, 12, 14, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 30, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 54], "bewar": 44, "beyond": [14, 20, 30, 35, 40, 48], "bhatt": [1, 56], "bia": [34, 36, 39, 47, 49, 52], "bias": [11, 36, 39, 44, 47], "bicycl": [13, 19, 29, 46], "big": [7, 15, 17, 21, 23, 27, 31, 33, 35, 36, 38, 40, 41, 42, 43, 44, 45, 47, 48, 54], "bigalpha_coeff": 37, "bigger": [15, 17, 21, 31, 33, 34, 37, 39, 42, 44, 45, 46], "biggest": [37, 40], "bike": 46, "bill": 45, "billboard": 46, "billie_holidai": 44, "billion": 37, "billionth": 46, "bin": [16, 22, 27, 32, 35, 37, 40, 46, 47, 48, 50, 53], "binar": [13, 17, 19, 23, 29, 33], "binari": [13, 16, 17, 19, 22, 23, 27, 29, 32, 33, 34, 45, 47, 48, 51, 52], "binary_feat": [17, 23, 27, 33], "binary_featur": [36, 38, 39], "binary_transform": [36, 38, 39], "bincount": [36, 38], "bind": [15, 21, 26, 31, 54], "binomi": 35, "biolog": 40, "biologi": [17, 23, 33], "bit": [10, 13, 14, 16, 17, 19, 20, 22, 23, 26, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 48], "black": [15, 21, 31, 39, 41, 45, 46], "blackhawk": 44, "bldgtype": [37, 39, 48], "bldgtype_1fam": 37, "bldgtype_2fmcon": 37, "bldgtype_duplex": 37, "bldgtype_twnh": 37, "bldgtype_twnhs": 37, "blei": 44, "blend": 44, "blindli": [36, 37], "blob": [12, 51], "block": [34, 47], "blog": [44, 46], "bloomberg": [1, 9], "blq": [37, 39, 48], "blue": [13, 15, 19, 21, 29, 31, 35, 36, 39, 40, 41, 46], "bluesman": 44, "bmatrix": [40, 43], "board": 4, "boathous": 45, "bob_dylan": 44, "boggl": 38, "bold": 48, "bond": [36, 49], "bonu": 38, "book": [9, 36, 37, 43, 44, 46, 48, 56], "bool": [37, 46], "bool_t": 27, "boom": 50, "boost": [44, 49, 52], "booster": 38, "bootstrap": [10, 48], "border": [13, 29, 34, 42, 44, 51, 53], "bore": 34, "boston": 34, "both": [2, 6, 13, 14, 15, 17, 19, 20, 21, 23, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 52, 55, 56], "bother": 39, "bottom": 42, "bought": 43, "bound": [40, 47], "boundari": [14, 20, 30, 42, 44, 48, 49, 54], "bow_df": [17, 23, 33], "box": [9, 39, 52], "boxplot": 39, "boyc": [19, 29], "br": 44, "bracket": 8, "brain": [40, 45], "branch": [13, 19, 29, 42, 44, 47], "brand": 48, "break": [1, 22, 36, 52, 54], "breakdown": 18, "breakwat": 45, "breath": 52, "breathtak": 44, "breed": 52, "breiman": 38, "brief": [4, 34, 38], "briefli": [12, 18, 28, 36, 38, 40], "bring": [6, 25, 39, 42, 49, 50, 52], "british": [1, 44], "british_columbia": 44, "broad": [15, 21, 26, 31, 44, 54], "broadcast": 44, "broader": [2, 38, 44], "broadest": 44, "broadli": [13, 15, 19, 21, 29, 31, 34, 36, 38, 41, 42, 44], "broth": 27, "brownle": 40, "browser": 10, "brush": 45, "bsmtcond": [37, 39, 48], "bsmtexposur": [37, 39, 48], "bsmtfinsf1": [37, 39, 48], "bsmtfinsf2": [37, 39, 48], "bsmtfintype1": [37, 39, 48], "bsmtfintype2": [37, 39, 48], "bsmtfullbath": [37, 39, 48], "bsmthalfbath": [37, 39, 48], "bsmtqual": [37, 39, 48], "bsmtunfsf": [37, 39, 48], "btw": 39, "bubbl": [43, 45], "bucket": [40, 50], "budget": [35, 43], "bug": [4, 8], "bui": [43, 49], "build": [0, 2, 10, 11, 14, 16, 17, 20, 22, 23, 30, 32, 33, 38, 40, 41, 44, 46, 48, 51, 54], "built": [8, 12, 13, 14, 18, 19, 28, 29, 30, 34, 35, 39, 46, 48, 49], "bullshit": [1, 47], "bulwark": 45, "bunch": [8, 10, 13, 19, 25, 29, 37, 38, 45, 47, 48, 49, 54], "bundl": [7, 10], "bureau": 34, "busi": [36, 41, 47, 50], "businesswoman": 44, "bustl": 46, "butterfli": 42, "buzz": [12, 18, 28], "bypass": 56, "c": [0, 1, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 26, 27, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 54, 56], "c1": 42, "c2": 42, "c_1": 41, "c_2": 41, "c_3": 41, "c_log": [15, 21, 26, 31, 54], "c_val": 26, "c_valu": 26, "c_widget": [15, 21, 26, 31, 54], "ca": [1, 5, 9, 12, 18, 49, 50, 56], "ca_transform": [17, 23, 33], "cache_s": 48, "cal_hous": 34, "calcul": [7, 14, 15, 16, 20, 21, 22, 25, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 43, 46, 49, 50, 51, 52, 54], "calgary_flam": 44, "calibr": 49, "california": [16, 22, 32, 40], "california_h": 40, "californian": [16, 22, 32], "call": [1, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54], "callback": 38, "caller": 49, "calm": 52, "came": 46, "camera": [17, 23, 33], "campu": [40, 56], "can": [1, 4, 6, 7, 10, 12, 13, 15, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56], "canada": [5, 14, 15, 17, 20, 21, 23, 30, 31, 33, 34, 44, 48, 50, 52], "canada_usa_c": [13, 14, 15, 20, 21, 29, 30, 31, 34, 53], "canadian": [27, 44], "canadien": 44, "canberra": 46, "cancel": 56, "cancer": [12, 18, 28, 40], "candid": [25, 35, 38, 44, 54], "cannot": [0, 8, 12, 14, 15, 18, 20, 21, 30, 31, 35, 36, 38, 39, 40, 42, 46, 47, 48, 56], "canuck": 44, "canva": [1, 7, 12, 13, 18, 49], "capabl": 9, "capit": [36, 38, 39], "caption": [7, 45], "captiv": 44, "captur": [11, 14, 16, 20, 22, 30, 32, 34, 38, 40, 42, 43, 44, 46, 47, 52], "car": [12, 18, 28, 44, 45, 49], "card": [12, 13, 18, 19, 28, 29, 36, 47, 48], "care": [5, 7, 14, 16, 20, 22, 30, 32, 35, 36, 37, 39, 40, 41, 46, 47, 52], "carefulli": [1, 12, 18, 36, 37, 56], "carpentri": 5, "carri": [13, 14, 15, 17, 19, 20, 21, 23, 25, 27, 29, 30, 31, 33, 35, 36, 37, 38, 41, 43, 44, 46, 49, 50, 54], "caruana": 39, "case": [6, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22, 27, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 56], "cash": [12, 18, 28], "cast": [35, 43, 50], "castl": 45, "cat": [12, 18, 26, 28, 36, 38, 44, 45, 50, 52], "catamount": [12, 18, 28, 45], "catboost": [11, 39, 48, 52], "catboostclassifi": 38, "catboostregressor": 38, "catch": [36, 56], "categor": [13, 19, 25, 29, 35, 36, 37, 38, 40, 41, 43, 44, 47, 48, 52, 54, 55], "categori": [15, 16, 21, 22, 26, 27, 31, 32, 36, 37, 38, 39, 40, 41, 45, 48, 52], "categorical_feat": [17, 23, 27, 33, 35, 52], "categorical_featur": [33, 36, 37, 38, 39, 46, 47, 48], "categorical_transform": [33, 36, 37, 38, 39, 46, 48], "categories_": [16, 17, 22, 23, 32, 33], "cater": 41, "caus": [36, 39, 40, 43, 47, 56], "causal": [39, 40], "caution": 46, "cbar": 34, "cbtf": [1, 56], "cc": [0, 1], "cc_df": 36, "cconj": 44, "ccp_alpha": 48, "cell": [7, 8, 12, 16, 17, 18, 22, 23, 25, 26, 27, 28, 32, 33, 35, 36, 37, 38, 39, 40, 43, 45, 47, 48, 50, 53, 54], "censor": [1, 11, 48, 49, 52], "censu": [34, 36, 38, 39], "census_df": 36, "cent": 37, "center": [15, 21, 31, 41, 42, 45, 51], "centercrop": 45, "centers_idx": 41, "central": [5, 12], "centralair": [37, 39, 48], "centralair_i": 37, "centralair_n": 37, "centric": [11, 48], "centroid": [41, 42], "centroids_idx": 41, "centroids_idx_init": 41, "centuri": 44, "certain": [10, 15, 21, 31, 34, 35, 36, 39, 40, 41, 44, 47, 48], "certainli": 53, "certainti": 36, "cezannec": 45, "chaat": 44, "chain": [17, 23, 33], "challeng": [6, 11, 14, 18, 30, 40, 41, 43, 45, 46, 49, 52], "chanc": [14, 29, 30, 35, 36, 37, 40, 41, 47, 48, 49], "chang": [0, 5, 7, 8, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 35, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 53, 54, 56], "channel": [1, 10, 45], "chapter": 1, "charact": [17, 23, 33, 36, 44], "characterist": [13, 14, 19, 20, 29, 30, 34], "charg": [0, 12, 18, 28, 47], "charl": 34, "charm": 44, "chart": [39, 46, 47, 48], "chat": 56, "chatgpt": [12, 44], "che210d": 9, "cheaper": 40, "cheat": 9, "check": [1, 4, 7, 10, 12, 13, 14, 16, 18, 19, 20, 22, 28, 29, 30, 32, 34, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 54], "check_arrai": 27, "check_assumpt": 47, "check_consistent_length": 27, "check_invers": [17, 23, 33], "check_param": 27, "check_x_i": 27, "check_y_param": 27, "checklist": 52, "checkmark": 43, "checkout": 35, "cheetah": [12, 18, 28, 45], "chegini": [1, 56], "cherri": 48, "chest": [14, 20, 30], "chetah": [12, 18, 28, 45], "chi": 47, "chicago": 50, "chicken": 41, "child": [36, 39], "children": 43, "chines": [27, 44], "chn": 8, "choic": [2, 20, 35, 37, 38, 39, 41, 42, 43, 46, 50, 54, 55], "choos": [12, 28, 35, 36, 38, 42, 48, 49, 52, 54], "chop": [35, 44, 48], "choreograph": 50, "chose": [25, 48], "chosen": [14, 20, 30, 35, 36, 47, 48, 52], "chrbv": 47, "christin": 50, "christma": 50, "chrome": [12, 18], "chunki": 41, "churn": [48, 52], "ciml": 1, "cinematographi": 44, "cinereu": 45, "circl": [15, 21, 31, 36], "circumst": 7, "citat": 7, "cite": 47, "citi": [13, 14, 15, 20, 21, 29, 30, 31, 44, 46, 48, 52, 53], "citibik": 46, "cities_df": [15, 21, 31, 34], "citizen": 47, "cityscap": 46, "civ": [36, 38, 39], "clai": 39, "claim": [0, 35, 36], "clarif": 41, "clarifi": 52, "clariti": 11, "class": [1, 4, 5, 10, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 40, 41, 44, 46, 47, 48, 49, 53, 54], "class_attend": [13, 14, 19, 20, 29, 30, 52], "class_attendance_enc": [17, 23, 33], "class_attendance_level": [17, 23, 33], "class_label": 36, "class_labels_fil": [12, 18, 28], "class_nam": [13, 15, 19, 21, 26, 29, 31, 38, 45], "class_sep": 36, "class_weight": [38, 48], "classes_": [34, 36, 38, 39, 45, 51], "classic": [15, 21, 31, 45, 51], "classif": [1, 2, 11, 14, 15, 16, 17, 20, 21, 22, 23, 25, 27, 30, 31, 32, 33, 34, 37, 38, 39, 40, 43, 44, 46, 47, 48, 51, 53, 54], "classifi": [14, 15, 16, 17, 20, 21, 22, 23, 26, 30, 31, 32, 33, 35, 36, 39, 45, 48, 51, 53, 55], "classification_df": [13, 14, 19, 20, 29, 30], "classification_report": [36, 45], "classifiers_ndt": 38, "classify_imag": [12, 18, 28, 45], "classmat": [6, 54, 55, 56], "classroom": [1, 49], "clean": [2, 12, 18, 25, 27, 28, 42, 48, 56], "clean_text": 44, "cleaned_hm": [36, 49], "cleaned_restaurant_data": 27, "cleaner": [36, 39], "clear": [7, 11, 36, 41, 49, 54], "clearli": [4, 6, 7, 35, 38, 39, 46], "cleric": [36, 38, 39], "clever": 48, "clf": [12, 13, 15, 18, 19, 21, 28, 29, 31, 34, 45], "click": [1, 5, 7, 36, 43, 48, 49], "client": [43, 49], "clinic": [13, 19, 29], "clip": [12, 18, 26, 28], "clone": [5, 7, 10], "close": [2, 12, 14, 15, 20, 21, 26, 30, 31, 34, 35, 36, 41, 42, 44, 46, 50, 51, 54, 56], "close_default_lr": 36, "close_zero_svm": 36, "closer": [15, 16, 21, 22, 31, 32, 34, 43, 53, 56], "closest": [15, 16, 20, 21, 22, 31, 32, 36, 41, 42, 44, 46], "cloth": 46, "cloud": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 33, 34, 35, 36, 37, 38, 50, 56], "cloud3pm": 46, "cloud9am": 46, "clust_label": 41, "cluster": [1, 2, 11, 43, 44, 46, 49], "cluster_cent": 41, "cluster_centers_": 41, "cluster_std": [42, 45], "clutter": [13, 29], "cm": [15, 21, 26, 31, 34, 36, 39, 43, 54], "cmap": [16, 22, 32, 35, 36, 39, 45], "cmn": 37, "cmp": 47, "cnn": [45, 46], "co": [17, 23, 33, 44], "coast": 45, "cockpit": 48, "code": [4, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55], "codecademi": 9, "coef": [46, 47, 50], "coef0": 48, "coef_": [34, 37, 38, 39, 40, 43, 45, 46, 47, 50, 51], "coef_df": [34, 39], "coef_nonzero": 46, "coeff": 34, "coeff_df": 46, "coeffici": [37, 38, 40, 43, 45, 46, 47, 48, 50, 51, 52], "coefs_df": 40, "coher": 41, "col": [13, 17, 19, 23, 29, 33, 34, 43, 46, 52], "col1": 8, "col2": 8, "col3": 8, "col4": 8, "col5": 8, "col6": 8, "cold": [16, 22, 32], "colinear": 39, "collabor": [5, 11, 43, 56], "collaps": 39, "colleagu": [8, 9], "collect": [11, 12, 13, 16, 17, 18, 19, 22, 23, 27, 28, 29, 32, 33, 36, 38, 39, 40, 43, 44, 45, 46, 47, 49, 52], "colleg": [36, 38, 39], "collinear": 40, "color": [34, 39, 40, 41, 42, 46, 48], "color_continuous_scal": 40, "color_threshold": 42, "colorbar": [16, 22, 32, 34], "colour": [17, 23, 33, 34, 35, 39, 41, 42, 45], "colsample_bylevel": 38, "colsample_bynod": 38, "colsample_bytre": 38, "columbia": [1, 9, 44], "column": [7, 12, 13, 14, 15, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55], "column_nam": [17, 23, 33], "column_stack": 40, "columntranform": 55, "columntransform": [1, 16, 22, 27, 32, 35, 36, 37, 38, 39, 40, 46, 47, 48, 50], "columntransformer__countvectorizer__max_featur": 35, "columntransformercolumntransform": [17, 23, 33, 35, 37, 38, 40, 50], "columntransformerifittedcolumntransform": [17, 23, 33, 37, 48], "columntransformerinot": [17, 23, 33, 38], "com": [0, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 33, 34, 35, 36, 37, 38, 45, 46, 47, 49, 50, 56], "comat": 44, "combin": [13, 16, 19, 22, 27, 29, 32, 33, 35, 36, 40, 43, 45, 46, 47, 48, 53, 54], "come": [10, 12, 13, 16, 17, 18, 19, 22, 23, 25, 27, 28, 29, 32, 33, 36, 40, 43, 44, 45, 46, 47, 48, 53], "comedi": 43, "comfort": 5, "command": [4, 10, 36, 44, 49], "comment": [8, 9, 27], "commerci": 0, "commit": [7, 36, 56], "common": [1, 8, 11, 13, 14, 15, 19, 20, 21, 26, 29, 30, 31, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 49, 51, 54, 56], "commonli": [13, 16, 19, 22, 29, 32, 35, 36, 41, 47], "commonwealth": 44, "commun": [1, 2, 10, 11, 17, 23, 33, 35, 37, 49, 56], "commut": 8, "comp_dict": 36, "compact": [35, 40], "compani": [36, 41, 43, 44, 47, 50], "compar": [8, 11, 13, 14, 15, 16, 19, 20, 21, 22, 25, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 51, 52], "comparison": [27, 42, 45, 47, 52], "compassion": 56, "compat": [8, 39], "compatibitl": 8, "compel": 46, "compet": 50, "competit": [38, 45, 51], "complain": [6, 50], "complaint": [6, 56], "complement": 44, "complet": [1, 6, 7, 12, 16, 18, 20, 22, 27, 28, 32, 35, 38, 39, 40, 42, 44, 47, 48, 53, 54, 56], "complex": [11, 13, 15, 19, 21, 26, 27, 29, 31, 34, 35, 37, 38, 39, 40, 42, 44, 45, 46, 49, 54], "complex_warn": 27, "complexwarn": 27, "compli": 0, "complic": [4, 13, 14, 19, 26, 27, 29, 30, 35, 37, 40], "compon": [17, 23, 33, 36, 43, 46, 48, 49, 56], "components_": 44, "compos": [15, 17, 23, 26, 27, 31, 33, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 55], "composit": [17, 23, 33], "compound": [44, 45, 47, 50], "comprehend": [26, 44], "comprehens": [41, 52, 56], "compress": [17, 23, 33, 41, 44], "compris": [12, 13, 18, 19, 28, 29, 41], "comput": [1, 7, 9, 10, 11, 17, 23, 26, 28, 33, 35, 36, 38, 39, 40, 41, 42, 44, 46, 48, 49, 51, 56], "computation": 40, "compute_class_weight": 36, "computer_programm": 44, "coms4995": [16, 22, 32], "con": [41, 44, 45, 48], "concat": [12, 15, 16, 17, 18, 21, 22, 23, 28, 31, 32, 33, 34, 39], "concaten": [17, 23, 33, 44], "concav": 40, "concensu": [14, 30], "concentr": [35, 52], "concept": [1, 11, 13, 14, 19, 20, 27, 29, 30, 39, 40, 41, 46, 52, 54, 56], "conceptnet": 44, "conceptu": [38, 48], "concern": [4, 11, 17, 18, 23, 25, 33, 38, 56], "concess": [1, 7], "concis": [13, 19, 29, 49], "conclus": 48, "concord": 47, "concordance_index": 47, "concordance_index_": 47, "concret": [12, 18, 28, 48], "conda": [12, 18, 26, 28, 36, 37, 38, 39, 41, 44, 47, 50], "condens": 19, "condit": [0, 12, 13, 17, 18, 19, 23, 25, 28, 29, 33, 40, 44, 47], "condition1": [37, 39, 48], "condition1_arteri": 37, "condition1_feedr": 37, "condition1_norm": 37, "condition1_posa": 37, "condition1_posn": 37, "condition1_rra": 37, "condition1_rran": 37, "condition1_rrn": 37, "condition1_rrnn": 37, "condition2": [37, 39, 48], "condition2_arteri": 37, "condition2_feedr": 37, "condition2_norm": 37, "condition2_posa": 37, "condition2_posn": [37, 39], "condition2_rra": 37, "condition2_rran": 37, "condition2_rrnn": 37, "conditional_aft": 47, "conduct": [11, 18], "confer": 44, "confid": [12, 14, 18, 20, 28, 30, 39, 47, 49, 52, 54], "confidenti": 36, "config": 10, "config_context": 27, "configur": [35, 37, 38], "confirm": 10, "conflict": [10, 42, 56], "confound": 40, "confus": [8, 15, 17, 21, 23, 31, 33, 37, 41, 49, 54], "confusingli": [12, 18], "confusion_matrix": [36, 45, 47], "confusionmatrixdisplai": 36, "congrat": [17, 23, 33], "conjunct": 40, "connect": [0, 13, 19, 29, 42, 43, 49], "connot": 44, "conort": 40, "consciou": 56, "consecut": 46, "consequ": [7, 12, 17, 18, 28, 33, 36, 43, 48], "consid": [4, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 52, 54, 56], "consider": [2, 11, 36, 38, 41, 43, 47, 48, 49], "consist": [6, 7, 13, 14, 16, 19, 20, 22, 27, 29, 30, 32, 41, 49, 50], "const": 44, "constant": [13, 19, 29, 36, 37, 38, 39, 46, 47, 48], "constitu": 38, "constitut": [44, 56], "construct": 43, "constructor": [13, 16, 22, 29, 32], "consult": [15, 21, 26, 31, 54, 56], "consum": [12, 18, 28, 40, 41, 43, 49, 52], "consumpt": 46, "contact": [12, 18, 28, 56], "contain": [8, 10, 12, 13, 16, 17, 18, 19, 22, 23, 27, 28, 29, 32, 33, 34, 37, 43, 44, 45, 49, 50, 51], "container": 49, "content": [1, 4, 10, 11, 18, 41, 44, 45, 49, 52, 56], "contest": 6, "context": [11, 13, 16, 19, 22, 29, 32, 34, 35, 36, 38, 39, 40, 42, 43, 45, 46, 48, 52, 54], "contextu": 11, "contin": [17, 33], "conting": 42, "continu": [17, 23, 27, 33, 35, 37, 38, 40, 44, 46, 48], "contract": [0, 47], "contract_month": 47, "contract_on": 47, "contract_two": 47, "contrast": [11, 52], "contribut": [15, 21, 31, 34, 39, 45, 56], "control": [5, 8, 13, 14, 15, 17, 19, 20, 21, 23, 29, 30, 31, 33, 34, 37, 38, 45, 56], "convei": 11, "conveni": [8, 12, 18, 35, 36, 41, 44, 46, 47, 48, 49], "converg": 41, "convers": [36, 37, 39, 44, 49], "convert": [12, 16, 17, 18, 22, 23, 27, 28, 32, 33, 34, 38, 39, 40, 44, 46, 47, 56], "convinc": [17, 23, 33, 48], "convolut": [40, 45], "convolutional_neural_network": 45, "cooccurrencematrix": 44, "cook": 41, "cool": 45, "coolwarm": 34, "coordin": [18, 56], "copi": [0, 7, 8, 10, 13, 19, 27, 29, 35, 38, 39, 41, 43, 45, 46, 47, 48, 56], "copyright": 0, "cor": 39, "coral": 45, "core": [9, 11, 16, 17, 22, 23, 27, 30, 32, 33, 35, 36, 37, 40, 42, 43, 46, 47, 49, 52], "corefer": 44, "corei": 49, "corgi": [12, 18, 28, 45], "corona_nlp_test": 50, "coronapocalyps": 50, "coronaviru": 50, "corpor": [5, 50], "corpora": [17, 23, 33, 44], "corpu": [17, 23, 33, 36, 44], "corr": 39, "corr_df": 39, "correct": [7, 12, 13, 14, 15, 18, 19, 20, 21, 28, 29, 30, 31, 36, 38, 39, 47, 48, 53, 54], "correctli": [1, 10, 13, 14, 19, 20, 29, 30, 36], "correl": [46, 52], "correspond": [1, 12, 13, 14, 15, 17, 18, 19, 20, 23, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 41, 43, 46, 54, 56], "cosin": 44, "cosine_similar": 44, "cost": [8, 12, 18, 28, 45, 48, 56], "cost_rep": 8, "costco": 44, "costli": 36, "cot": 45, "cote": 45, "could": [6, 8, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 43, 44, 46, 47, 48, 49, 54, 56], "couldn": 44, "count": [8, 13, 16, 17, 19, 22, 23, 25, 27, 29, 32, 33, 36, 37, 40, 44, 45, 46, 47, 49, 50, 51, 54, 56], "counter": 36, "counti": [25, 54], "countri": [14, 15, 17, 20, 21, 30, 31, 33, 34, 36, 38, 39, 44, 56], "country_columbia": 39, "country_dominican": 39, "country_guatemala": 39, "country_hondura": 39, "country_hong": 39, "country_hungari": 39, "country_india": 39, "country_iran": 39, "country_miss": [38, 39], "country_puerto": 39, "country_scotland": 39, "country_south": 39, "country_taiwan": 39, "country_thailand": 39, "country_trinadad": [38, 39], "country_unit": [38, 39], "country_vietnam": [38, 39], "country_yugoslavia": [38, 39], "countvector": [12, 18, 27, 28, 34, 35, 36, 44, 49, 50, 52], "countvectorizercountvector": [17, 23, 33, 35, 50], "countvectorizeroriginaltweet": 50, "countvectorizersong_titl": 35, "coupl": [4, 13, 29, 35, 42, 50], "cour": 44, "cours": [2, 4, 5, 6, 7, 10, 13, 14, 17, 19, 20, 23, 25, 26, 27, 29, 30, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 50, 52, 53, 54], "coursera": [1, 9], "coursework": 56, "court": 44, "covari": [13, 19, 29, 47], "cover": [8, 11, 18, 36, 38, 41, 45, 46, 56], "coverag": 36, "covid": 50, "covid2019": 50, "cow": 48, "cox": 11, "coxph_fitt": 47, "coxphfitt": 47, "cph": [47, 48, 52], "cph_param": 47, "cpsc": [9, 10, 13, 19, 28, 29, 38, 40, 44, 45, 46, 48, 49, 50, 56], "cpsc330": [0, 1, 10, 12, 17, 18, 19, 23, 24, 26, 27, 28, 29, 30, 33, 35, 39, 44, 45, 47, 49, 50, 56], "cpsc330env": 10, "cpu": [26, 35, 45], "craft": [15, 21, 31, 36, 38, 39, 41, 54], "crash": 1, "crate": 45, "crazi": [27, 49], "creat": [8, 9, 10, 12, 15, 16, 18, 21, 22, 25, 26, 27, 28, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55], "create_lag_df": 46, "create_lag_featur": 46, "create_y_from_r": 43, "creativ": [1, 44], "credenc": 48, "credit": [0, 13, 19, 29, 36, 38, 44, 46, 47, 48], "creditcard": 36, "crime": 34, "crimin": 39, "criteria": [13, 19, 29, 42], "criterion": [42, 48], "critic": [11, 48], "cross": [13, 15, 17, 19, 23, 27, 29, 31, 33, 35, 37, 38, 39, 41, 43, 47, 48, 49, 50, 52, 55], "cross_val": 38, "cross_val_predict": [36, 38, 47], "cross_val_scor": [16, 17, 22, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 47, 48, 52, 55], "cross_valid": [15, 16, 17, 21, 22, 23, 25, 26, 27, 31, 32, 33, 34, 35, 36, 38, 39, 40, 43, 46, 47, 48, 49, 50, 52, 54, 55], "cross_validate_std": [14, 20, 30], "crowd": [38, 42], "crown": 56, "crown_princ": 44, "crucial": [12, 14, 18, 20, 28, 30, 34, 39, 41, 42, 43, 44], "crude": 44, "cs189": 9, "cs189_ch7": 9, "csr": 27, "css": 49, "csv": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55], "ct": [17, 23, 33], "cuda": [26, 45], "cui": [1, 56], "cuisin": 49, "cultiv": 11, "cultur": [45, 56], "curios": [12, 18, 28], "curiou": [12, 18, 28, 54], "curl": 49, "current": [1, 38, 44, 45, 46, 47, 48, 49, 50], "curriculum": 11, "curs": 48, "curv": [7, 8, 11, 41, 48, 52, 54], "custom": [5, 8, 12, 13, 17, 18, 19, 23, 27, 28, 29, 33, 36, 37, 43, 49, 50, 52], "custom_plot_tre": [13, 14, 19, 20, 29, 30, 38, 39], "customerid": 47, "customiz": 50, "cut": 42, "cv": [14, 17, 20, 23, 25, 26, 30, 33, 36, 37, 38, 39, 40, 46, 47, 48, 49, 52, 54], "cv_feat": 50, "cv_results_": [35, 37], "cv_score": [14, 20, 26, 30, 37], "cv_train_scor": [25, 54], "cv_valid_scor": [25, 54], "cycl": 8, "cyclic": 46, "cycling_data": 8, "cygnu": 45, "d": [4, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 49], "d3": 41, "da": [12, 18, 28], "dabeaz": 9, "dad": 40, "dai": [4, 8, 14, 27, 40, 45, 47, 48, 52, 56], "daili": [47, 52], "dall": 46, "damag": [0, 36], "dan": 44, "danceabl": [15, 16, 22, 31, 32, 35], "dark": 50, "darker": 35, "dashboard": [15, 21, 26, 31, 54], "data": [1, 2, 5, 7, 8, 9, 10, 11, 26, 42, 44, 47, 51, 52, 53, 55, 56], "data_dict": 34, "data_dir": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54], "data_to_wrap": [17, 23, 33], "data_transform": [26, 45], "data_transforms_bw": 45, "data_url": 36, "datacamp": 9, "datafram": [12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 54, 55], "dataload": [26, 45], "dataloaders_bw": 45, "datapoint": 34, "dataquest": 9, "dataset": [8, 11, 12, 14, 15, 17, 18, 20, 21, 23, 25, 26, 27, 28, 30, 31, 38, 39, 40, 41, 42, 47, 49, 50, 51, 52, 54], "dataset2": 41, "dataset_s": [26, 45], "dataviz": 48, "date": [7, 10, 12, 13, 18, 25, 28, 29, 43, 44, 47, 49, 50, 52, 54, 56], "date_rang": 46, "dates_rain": 46, "datetim": 47, "datetime64": 46, "datetimeindex": 46, "datum": 44, "daughter": [36, 49], "daum\u00e9": 1, "daunt": 43, "dave": 44, "david": [1, 44, 48], "day_nam": 46, "daylight": 46, "dayofweek": 46, "days_sinc": 46, "dbscan": [11, 49], "dc": [46, 47, 50], "dcc": 34, "dd": 46, "de": [44, 46], "deactiv": 10, "deadlin": [14, 18, 56], "deal": [0, 14, 15, 16, 20, 21, 22, 27, 30, 31, 32, 37, 44, 47, 48, 49, 52, 55], "death": 56, "debat": [8, 18, 39], "debbi": 50, "debug": [4, 39], "decad": 45, "decemb": [25, 46], "decid": [8, 13, 15, 19, 21, 29, 31, 34, 38, 39, 40, 41, 42, 44, 46, 47, 52], "decis": [1, 2, 6, 14, 16, 20, 22, 30, 32, 35, 36, 38, 40, 45, 51, 52, 53, 55, 56], "decision_boundari": 51, "decision_funct": 36, "decisiontreeclassifi": [14, 15, 16, 17, 20, 21, 22, 23, 26, 30, 31, 32, 33, 34, 35, 39, 53, 54, 55], "decisiontreeclassifierdecisiontreeclassifi": 38, "decisiontreeregressor": [13, 19, 25, 29, 37, 53, 54], "decisiontreeregressorifitteddecisiontreeregressor": 25, "deck": 9, "declar": 56, "decomposit": [42, 43, 44], "decor": 27, "decreas": [14, 20, 25, 30, 34, 35, 38, 39, 41, 54], "deduct": 7, "deem": 6, "deep": [2, 9, 35, 39, 40, 44, 47, 49], "deepen": [52, 56], "deeper": [2, 12, 18, 35, 36, 37, 39], "deepexplain": 39, "def": [14, 15, 16, 20, 21, 22, 26, 27, 30, 31, 32, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 49, 50, 54], "default": [5, 10, 12, 13, 14, 17, 18, 19, 20, 23, 26, 29, 30, 33, 34, 35, 36, 37, 38, 41, 42, 45, 46, 47, 48, 51, 56], "default_check_param": 27, "default_threshold": 36, "defaultdict": 43, "defin": [13, 15, 16, 17, 21, 22, 23, 27, 29, 31, 32, 33, 36, 38, 39, 41, 42, 43, 46, 49], "definit": [8, 15, 21, 31, 39, 41, 44, 46, 51, 52, 53], "degre": 36, "degrees_freedom": 47, "degrees_of_freedom": 47, "del": 38, "delai": [1, 10, 40], "deleg": 44, "delet": [4, 7, 16, 22, 32, 48], "delgado": 38, "delight": 44, "deliver": 7, "delv": [11, 44], "demo": [1, 18, 38, 48, 56], "demograph": [13, 19, 29, 43], "demonstr": [13, 14, 16, 19, 20, 22, 26, 27, 29, 30, 32, 34, 35, 37, 38, 41, 43, 44, 45], "denois": 12, "denomin": [37, 50], "denot": [13, 19, 29, 43], "dens": [42, 44], "densenet": [26, 45], "densenet121": [26, 45], "densenet121_weight": [26, 45], "densiti": [39, 42, 52], "dep": 44, "department": 56, "departur": 40, "depend": [2, 8, 10, 13, 14, 15, 17, 19, 20, 21, 23, 29, 30, 31, 33, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 48], "dependence_plot": 39, "dependents_no": 47, "dependents_y": 47, "deploi": [14, 20, 25, 30, 36, 43, 48, 52], "deploy": [11, 39, 46], "deprec": [22, 30, 32, 36, 37, 47, 50, 51], "deprecationwarn": [38, 47], "depth": [1, 13, 14, 19, 20, 25, 29, 30, 35, 38, 42, 53, 54], "dequ": [38, 39], "deriv": [0, 13, 19, 29, 34, 36, 43, 47, 52], "descend": [8, 42, 45, 52], "descent": 46, "descr": 34, "describ": [8, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 25, 27, 28, 29, 30, 31, 32, 34, 36, 37, 43, 44, 46, 49, 54], "descript": [1, 37, 47, 50], "desenet": 26, "deserv": 6, "design": [11, 19, 29, 39, 42, 45, 48, 56], "desir": [27, 36, 44, 47, 55], "desk": 56, "despit": [40, 44], "det": [44, 50], "detach": [26, 45], "detail": [15, 17, 21, 23, 31, 33, 38, 44, 45, 49, 56], "detect": [12, 13, 18, 19, 25, 28, 29, 36, 37, 41, 42, 46, 49], "determin": [15, 19, 21, 26, 31, 41, 42, 44, 47, 48, 54, 56], "detriment": [36, 43], "dev": [14, 30, 51], "develop": [1, 9, 11, 12, 14, 16, 17, 18, 20, 22, 23, 28, 30, 32, 33, 35, 36, 37, 38, 44, 45, 48, 49, 50, 52], "devianc": 47, "deviat": [6, 14, 16, 20, 22, 30, 32, 38, 39], "devic": [26, 27, 38, 45], "deviceprotect": 47, "deviceprotection_no": 47, "deviceprotection_y": 47, "df": [12, 13, 14, 16, 17, 18, 20, 22, 23, 25, 27, 28, 29, 30, 32, 33, 35, 36, 37, 39, 40, 45, 46, 47, 48, 49, 50, 53], "df_concat": [12, 18, 28], "df_float_1": 8, "df_float_2": 8, "df_hour_week_ohe_poli": 46, "df_locat": 46, "di": 47, "diagnos": [14, 30, 39, 52], "diagnosi": 36, "diagnost": [47, 49], "diagon": [15, 21, 31, 36, 39], "diagram": [17, 23, 33, 35, 38, 39], "dialogu": 44, "dict": [36, 43], "dict_kei": 38, "dictionari": [8, 16, 22, 32, 35, 36, 38, 39, 49], "did": [6, 12, 13, 15, 18, 19, 21, 29, 31, 39, 41, 44, 46, 50, 54, 56], "didn": [27, 35, 38, 39, 42, 44, 46, 47, 49], "die": 50, "diet": [13, 19, 29, 44], "diff": 46, "differ": [1, 2, 5, 7, 8, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 25, 27, 28, 29, 30, 31, 33, 34, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 54], "differenti": [11, 12, 13, 18, 19, 28, 29], "difficult": [4, 6, 7, 36, 40, 41, 48], "difficulti": [41, 52], "dig": [36, 37], "digit": [46, 48], "dilemma": 43, "dim": [26, 27, 45], "dimens": [8, 34, 40], "dimension": [2, 8, 19, 26, 34, 35, 36, 38, 40, 41, 44], "dine": 49, "direct": [22, 34, 39, 40, 42, 44, 50], "direct_bilirubin": [12, 18, 28], "directli": [1, 8, 17, 23, 27, 33, 37, 45, 47, 49, 56], "director": 43, "directori": [10, 13, 14, 16, 20, 22, 26, 29, 30, 32], "dirichlet": [44, 45], "disabl": 44, "disadvantag": [35, 38, 42, 43, 55], "disast": [12, 28], "discard": [40, 44], "disciplin": [36, 40], "disclos": [50, 56], "discourag": 8, "discours": 43, "discov": [40, 41], "discoveri": [12, 18, 28], "discret": [13, 19, 27, 29, 40], "discrete_scatt": [13, 14, 15, 19, 20, 21, 26, 29, 30, 31, 34, 41, 42, 45, 51, 53, 54], "discretization_feat": 40, "discrimin": 38, "discuss": [4, 14, 15, 16, 20, 21, 22, 30, 31, 32, 34, 39, 40, 41, 42, 46, 52, 54, 55, 56], "diseas": [13, 19, 29, 36, 47], "dislik": [27, 48], "displaci": [44, 50], "displai": [7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 42, 43, 45, 46, 47, 53, 54, 55], "display_heatmap": 35, "display_label": 36, "displaystyl": 44, "disput": 44, "disrespect": 4, "dissemin": 49, "dist": [15, 21, 26, 31, 41, 42], "distanc": [8, 16, 22, 26, 32, 40, 42, 43, 44], "distinct": [36, 40, 46, 48], "distinguish": [13, 15, 17, 19, 21, 23, 26, 29, 31, 33, 36, 54], "distract": 56, "distribut": [0, 10, 12, 14, 20, 25, 27, 30, 36, 39, 40, 42, 44, 45, 46, 56], "district": [16, 22, 32, 34], "districtdatalab": 41, "disturb": [12, 18, 28], "dive": 39, "divers": [11, 38, 41, 43, 46], "divid": [34, 36, 38, 39, 46, 54], "divis": [19, 39], "divorc": [38, 39], "dktal": 47, "dlwqn": 47, "dmp": 56, "do": [0, 1, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 25, 26, 28, 29, 30, 31, 34, 37, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56], "dobj": 44, "doc": [8, 9, 12, 39, 44, 45, 49, 50, 56], "doc_id": 44, "docker": 49, "doctor": [36, 38, 39], "document": [0, 1, 7, 12, 13, 14, 16, 17, 18, 20, 22, 23, 25, 26, 27, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 50, 52, 56], "document_top": 44, "documentari": 43, "doe": [5, 8, 10, 12, 14, 15, 16, 18, 21, 22, 26, 27, 28, 30, 31, 32, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 50, 52, 54, 56], "doesn": [7, 8, 12, 14, 16, 17, 20, 22, 23, 30, 32, 33, 36, 37, 38, 39, 41, 42, 43, 44, 45, 47, 48, 52], "dog": [26, 36, 45], "dolist": 49, "dollar": [4, 34, 37, 48], "dolli": 50, "domain": [0, 12, 18, 28, 39, 41, 44], "domin": [16, 22, 32, 37, 45], "domingo": [1, 14, 30, 40], "dominican_republ": 44, "don": [4, 12, 13, 14, 16, 17, 18, 20, 23, 25, 26, 27, 28, 30, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "done": [5, 10, 12, 14, 17, 18, 20, 23, 30, 33, 35, 36, 45, 46, 48, 52, 55], "dont": 50, "door": 45, "dosa": 44, "dot": [15, 21, 31, 34, 36, 38, 39, 40, 42, 44], "dot_product": 44, "doubl": 35, "down": [14, 20, 30, 36, 39, 44, 47, 48, 54, 56], "downfal": 43, "download": [5, 7, 10, 12, 13, 16, 18, 22, 25, 28, 29, 32, 34, 36, 37, 39, 44, 45, 48, 50, 54], "downright": 48, "dpi": [26, 40], "dr": 44, "draft": 1, "drag": 7, "drama": 43, "drastic": 36, "draw": [34, 35, 44, 48], "drawback": [11, 39, 43], "drawn": 38, "dream": 45, "dreampharmaceut": 44, "drink": 48, "drinker": 44, "drive": [12, 18, 28, 39], "driven": [10, 35, 36], "droit": 44, "drop": [7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 46, 47, 48, 49, 50, 52, 54, 55, 56], "drop_dupl": [15, 21, 31, 35], "drop_feat": [17, 23, 27, 33, 52], "drop_featur": [36, 37, 38, 39, 46, 47, 48, 50], "dropdrop": [17, 23, 33, 37, 38, 48, 50], "drope": [16, 22, 32], "dropna": [36, 46, 49], "dropoff": 41, "drug": [12, 18, 28, 49], "dsci": [1, 9, 39, 48, 51], "dsl": 47, "dt": [25, 54], "dt_best": 54, "dt_final": 25, "dt_pipe": 35, "dt_regr": 25, "dtype": [13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50], "dtypelik": 27, "dual": 36, "duan": [1, 56], "duck": [45, 48], "duckbil": 45, "due": [7, 12, 13, 14, 16, 17, 18, 34, 38, 40, 43, 56], "dummi": [13, 15, 16, 17, 19, 21, 22, 23, 25, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 53, 55], "dummy_clf": [13, 19, 29, 53], "dummy_regr": 25, "dummy_scor": [15, 21, 31], "dummy_valid_accuraci": [15, 21, 31], "dummyclassifi": [14, 15, 16, 17, 20, 21, 22, 23, 26, 27, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 45, 48, 49, 50, 53, 54, 55], "dummyregressor": [17, 23, 25, 33, 38, 39, 40, 48, 49, 55], "dump": 49, "dun": [12, 18, 28], "dunno": [12, 18, 28], "duplex": 37, "duplic": 8, "durat": [7, 40, 46, 47], "duration_col": 47, "duration_m": [15, 16, 22, 31, 32, 35], "dure": [1, 4, 8, 12, 13, 15, 17, 18, 19, 21, 23, 25, 28, 29, 31, 33, 34, 35, 38, 39, 40, 43, 44, 49, 52, 53, 54, 55, 56], "dwell": 37, "e": [6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52], "e737c5242822": 47, "e_": [14, 20, 30], "each": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56], "eager": 49, "earli": [39, 47, 48, 56], "earlier": [16, 22, 32, 38, 40, 46, 47], "early_stopping_round": 38, "earnest": 56, "easi": [7, 15, 16, 21, 22, 31, 32, 34, 38, 39, 40, 41, 42, 44, 48, 50], "easier": [5, 7, 36, 39, 40, 43, 48], "easiest": [39, 47], "easili": [38, 40, 46, 48, 49, 53], "east": 27, "eat_out_freq": 27, "echidna": 45, "econom": [17, 23, 33, 46], "ecosystem": 45, "eda": [14, 20, 25, 27, 30, 44, 47, 52], "edg": [13, 19, 29, 35], "edgecolor": [35, 46], "edit": [35, 44], "edu": 9, "educ": [36, 38, 39, 43], "education_level": [36, 38, 39], "effect": [15, 21, 25, 26, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 49, 52, 54, 56], "effici": 35, "effort": [4, 10, 35, 40, 41, 43, 45, 56], "egg": 41, "either": [4, 13, 14, 15, 17, 19, 20, 21, 23, 26, 29, 30, 31, 33, 36, 39, 41, 42, 44, 45, 46, 54], "elast": 47, "elbow": 42, "elect": 44, "electr": [37, 39, 48], "electrical_engin": 44, "electrical_fusea": 37, "electrical_fusef": 37, "electrical_fusep": 37, "electrical_miss": 37, "electrical_mix": 37, "electrical_sbrkr": 37, "electron": [47, 56], "eleg": [16, 22, 32, 44, 48], "elegantli": 44, "element": [0, 1, 9, 14, 17, 23, 30, 33, 44, 53], "eli5": 39, "elif": [13, 19, 29, 46, 47], "elimin": 11, "els": [13, 17, 19, 23, 26, 27, 29, 33, 36, 45, 46, 47, 50], "email": [1, 12, 13, 14, 18, 20, 28, 30, 36, 49, 56], "emb": [7, 15, 21, 31, 36, 41, 42], "embed": [1, 11, 17, 23, 33, 45, 49, 52], "emoji": 50, "emoticon": [40, 41], "emp": 39, "empathi": 44, "emphas": 11, "emphasi": [49, 56], "emploi": [26, 46, 47, 49, 52], "employ": 43, "employe": [13, 19, 29], "empti": [26, 34, 44, 45, 46], "en": [46, 47, 48, 50], "en_core_web_lr": 44, "en_core_web_md": [44, 50], "enabl": [10, 43, 44, 46], "enable_categor": 38, "enable_halving_search_cv": 35, "enc": [16, 17, 22, 23, 32, 33, 46], "enclosedporch": [37, 39, 48], "encod": [12, 14, 18, 20, 25, 27, 28, 30, 35, 36, 37, 39, 43, 47, 52, 55], "encompass": [47, 48, 52], "encount": [17, 23, 33, 35], "encourag": 10, "end": [4, 8, 11, 12, 14, 15, 18, 20, 21, 26, 28, 30, 31, 34, 35, 36, 40, 41, 42, 43, 44, 46, 47, 48, 49, 54, 56], "endors": 0, "endpoint": 47, "energi": [15, 16, 22, 31, 32, 35, 46], "engag": 56, "engin": [1, 9, 11, 17, 23, 33, 36, 37, 41, 43, 44, 47, 49], "england": 50, "english": [12, 16, 18, 22, 28, 32, 35, 36, 44, 45, 49, 50], "enhanc": 56, "enjoi": [1, 34], "enjoy_class": [17, 23, 33], "enjoy_cours": [17, 23, 33, 52], "enjoy_course_enc": [17, 23, 33], "enjoy_the_mo": [36, 49], "enough": [7, 15, 17, 21, 31, 33, 36, 37, 38, 41, 43, 52], "enrol": 56, "ensembl": [1, 11, 27, 37, 39, 40, 42, 43, 46, 47, 48, 49], "ensiti": 42, "ensur": [7, 11, 16, 22, 25, 32, 38, 46], "ensure_2d": 27, "ensure_all_finit": 27, "ensure_min_featur": 27, "ensure_min_sampl": 27, "ensure_non_neg": 27, "ent": [44, 50], "enter": [17, 23, 33, 47, 48], "enterpris": 5, "entertain": 44, "enthusiast": [12, 18, 28, 48], "entir": [4, 8, 12, 14, 18, 20, 30, 37, 45, 46, 48, 49, 50, 56], "entiti": [40, 43, 44, 50], "entitl": [17, 23, 33], "entlebuch": [12, 18, 28, 45], "entri": [15, 16, 17, 21, 22, 23, 31, 32, 33, 34, 36, 37, 40, 43, 46, 47], "entropi": [13, 19, 29, 48], "enumer": 38, "env": [10, 17, 19, 23, 26, 27, 29, 30, 33, 35, 39, 47, 50, 51], "environ": [3, 5, 8, 12, 16, 17, 18, 22, 23, 25, 26, 27, 28, 32, 33, 35, 36, 37, 38, 39, 40, 44, 45, 47, 48, 50, 56], "environemnt": 10, "environment": 52, "ep": [13, 14, 15, 20, 21, 29, 30, 31, 34, 42, 53], "epoch": 46, "epsilon": [42, 48], "equal": [8, 15, 17, 21, 31, 33, 36, 37, 38, 39, 42, 43, 46, 52, 56], "equat": [4, 12, 18, 34], "equip": [15, 21, 31, 47, 56], "equival": [8, 36, 38], "erik": 44, "err": 44, "error": [4, 6, 7, 8, 10, 11, 13, 15, 17, 19, 21, 23, 27, 29, 31, 33, 34, 38, 39, 40, 44, 47, 48, 49, 52, 54], "error_": [14, 20, 30], "erupt": [12, 28], "erythrocebu": [12, 18, 28, 45], "es": 46, "eskimo": 36, "esl": 1, "especi": [2, 15, 19, 21, 29, 31, 35, 36, 38, 40, 43, 46], "essenti": [47, 52], "establish": 25, "estat": [13, 19, 29], "estim": [14, 15, 17, 21, 23, 27, 30, 31, 33, 34, 35, 40, 41, 47, 48, 49, 52], "estimator_nam": 27, "estimators_": 38, "et": [38, 44], "etc": [1, 2, 7, 8, 13, 19, 29, 40, 44, 45, 46, 47, 48, 49, 50, 56], "ethic": [1, 11, 49], "euclidean": [41, 42, 44], "euclidean_dist": [15, 16, 21, 22, 31, 32, 41, 42, 44], "ev": 50, "eva": 43, "eva_model": 43, "eval": 45, "eval_metr": [38, 39], "eval_on_featur": 46, "evalu": [1, 8, 11, 13, 14, 19, 20, 25, 29, 30, 35, 37, 39, 41, 46, 48, 49, 54], "evapor": 46, "even": [0, 7, 11, 12, 13, 14, 18, 19, 20, 27, 29, 30, 34, 35, 36, 40, 41, 42, 43, 46, 47, 48, 50, 52, 54, 55, 56], "event": [0, 36, 37, 56], "event_col": 47, "event_observ": 47, "ever": [13, 19, 29, 51], "everi": [8, 12, 13, 14, 18, 19, 20, 29, 30, 38, 42, 46, 54], "everydai": [8, 44], "everyon": [6, 39, 48, 52], "everyth": [12, 17, 18, 23, 33, 36, 43, 46, 49], "everywher": 46, "evict": 50, "evo": 49, "evocarshar": 49, "evok": 44, "ex": [37, 39, 48], "ex1_idx": 39, "ex2_idx": 39, "exact": [4, 47], "exactli": [7, 12, 14, 18, 19, 20, 28, 30, 39, 54], "exagger": 48, "exam": [1, 6, 12, 18, 48, 49], "examin": [14, 15, 16, 20, 21, 22, 25, 26, 27, 30, 31, 32, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 51], "exampl": [0, 4, 5, 6, 7, 8, 10, 20, 26, 27, 37, 42, 43, 45, 46, 49, 51, 52, 53, 54, 56], "example1": [13, 19, 29], "example2": [13, 19, 29], "exceedingli": 54, "excel": [17, 23, 33, 34, 37, 39, 47, 52, 55], "except": [0, 1, 7, 8, 14, 20, 27, 30, 46, 47, 56], "exception": 4, "exchang": [36, 52], "excit": 43, "execut": [4, 7, 41, 49], "exercis": [1, 7, 9, 12, 18, 44, 49, 50, 54, 55, 56], "exist": [8, 36, 40, 47, 49], "exp": [34, 47, 48], "expand": [1, 13, 19, 29, 56], "expect": [1, 4, 7, 8, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 52, 54, 56], "expected_valu": 39, "expenditur": 46, "expens": [12, 18, 28, 36, 37, 40, 41, 43], "experi": [12, 18, 28, 35, 43, 44, 56], "experienc": 56, "experiment": [35, 49], "expert": [12, 13, 14, 18, 19, 20, 28, 29, 30, 35, 39, 40], "explain": [4, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52], "explan": [4, 14, 15, 21, 30, 31, 52], "explanatori": [13, 19, 29], "explicit": [36, 47], "explicitli": [8, 12, 18, 28, 49], "exploit": 6, "explor": [13, 14, 17, 20, 23, 25, 26, 29, 30, 33, 35, 36, 39, 40, 43, 44, 45, 49, 54], "exploratori": [37, 47, 49, 52], "explos": 50, "expm1": [37, 48], "expon": 35, "exponenti": 35, "export_graphviz": [13, 19, 29, 53], "exposur": 43, "express": [0, 8, 17, 23, 33, 34, 40, 44, 48], "extend": [44, 45, 51, 56], "extend_block": 47, "extens": [1, 12, 15, 18, 21, 26, 31, 36, 39, 41, 42, 44, 46, 54, 56], "extent": [41, 44], "extercond": [37, 39, 48], "exterior": 39, "exterior1st": [37, 39, 48], "exterior1st_asbshng": 37, "exterior1st_asphshn": 37, "exterior1st_brkcomm": 37, "exterior1st_brkfac": 37, "exterior1st_cblock": 37, "exterior1st_cemntbd": 37, "exterior1st_hdboard": 37, "exterior1st_imstucc": [37, 39], "exterior1st_metalsd": 37, "exterior1st_plywood": 37, "exterior1st_ston": 37, "exterior1st_stucco": 37, "exterior1st_vinylsd": 37, "exterior1st_wd": 37, "exterior1st_wdsh": 37, "exterior2nd": [37, 39, 48], "exterior2nd_asbshng": 37, "exterior2nd_asphshn": 37, "exterior2nd_brk": 37, "exterior2nd_brkfac": 37, "exterior2nd_cblock": 37, "exterior2nd_cmentbd": 37, "exterior2nd_hdboard": 37, "exterior2nd_imstucc": 37, "exterior2nd_metalsd": 37, "exterior2nd_oth": 37, "exterior2nd_plywood": [37, 48], "exterior2nd_ston": [37, 48], "exterior2nd_stucco": [37, 48], "exterior2nd_vinylsd": [37, 48], "exterior2nd_wd": [37, 48], "external_tool": 49, "exterqu": [37, 39, 48], "extra": [4, 41, 46, 49, 56], "extract": [26, 40, 41, 43, 44, 45, 50, 56], "extractor": 52, "extrapol": [46, 47], "extratreesclassifi": 38, "extrem": [6, 17, 33, 36, 38, 39, 43, 47, 50], "ey": 50, "f": [8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 36, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 54], "f1": [11, 37, 52], "f1_score": 36, "fa": [37, 39, 48], "fac": 50, "face": [12, 13, 15, 18, 26, 28, 29, 31, 43, 45], "facebook": [43, 44, 56], "facial": [15, 31], "facil": 56, "facilit": [8, 56], "fact": [12, 28, 35, 36, 38, 45, 46, 47, 48], "factor": [13, 19, 29, 35, 39, 40, 42, 43, 47], "fail": [1, 7, 8, 10, 14, 16, 17, 20, 22, 23, 30, 32, 33, 40, 42, 44, 47, 48], "failur": [7, 12, 18, 28, 47, 56], "fair": [6, 14, 16, 20, 22, 30, 32, 37, 39, 41, 49, 52, 56], "fairli": [14, 20, 30, 35, 36, 39, 49], "fake": [15, 21, 31], "fall": [15, 21, 31, 41, 44, 46], "fals": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 52], "famili": [12, 18, 28, 35, 36, 37, 38, 39, 41, 49, 56], "familiar": [8, 10, 11, 13, 16, 19, 22, 29, 32, 48, 54, 56], "famou": [1, 9, 44, 45], "fanci": [4, 12, 18, 28, 35], "fancier": 40, "far": [13, 15, 16, 17, 21, 22, 23, 29, 31, 32, 33, 34, 36, 39, 40, 41, 42, 44, 45, 46, 47, 51, 52, 54], "farm": 36, "farthest": [13, 19, 29], "fashion": [19, 38, 44], "fast": [14, 15, 20, 30, 31, 34, 38, 39, 44, 47, 49, 56], "faster": [12, 18, 28, 35, 38, 40, 45], "fastest": 38, "fasttext": 44, "favour": 49, "favourit": 44, "fc": 34, "fcluster": 42, "feat": [27, 35, 46, 50], "feat1": 41, "feat2": 41, "feat_nam": [27, 46, 50], "feat_vec": 43, "featur": [1, 11, 14, 20, 25, 26, 30, 36, 38, 41, 42, 44, 47, 49, 51, 54, 55, 56], "feature_extract": [12, 17, 18, 23, 27, 28, 33, 34, 35, 36, 44, 49, 50], "feature_import": 25, "feature_importances_": [25, 40], "feature_nam": [13, 14, 19, 20, 25, 29, 30, 34, 38, 39, 40, 44], "feature_names_in_": 25, "feature_names_out": [17, 23, 33], "feature_select": 40, "feature_typ": 38, "features_lag": 46, "features_nonzero": 46, "features_poli": 46, "feb": [1, 16], "februari": [25, 46], "feder": [36, 39, 44, 46], "feed": [26, 27], "feedback": [19, 29, 52], "feel": [5, 6, 14, 20, 30, 41, 49, 52], "feli": [12, 18, 28, 45], "fell": 34, "femal": [36, 38, 39, 47], "female_cm": 36, "female_pr": 36, "fenc": [37, 39, 45, 48], "fernandez": 38, "fetch_california_h": 34, "few": [1, 8, 12, 18, 27, 28, 34, 37, 38, 40, 43, 44, 45, 46, 47, 49, 53], "fewer": [10, 38, 40, 42], "feynman": 48, "fiber": 47, "fiction": 50, "field": [2, 4, 11, 12, 17, 18, 23, 28, 33, 44, 45, 46, 49], "fig": [14, 15, 20, 21, 26, 30, 31, 34, 36, 40, 41, 42, 45, 54], "figsiz": [13, 14, 15, 16, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 34, 36, 39, 40, 41, 42, 45, 46, 47, 48, 54], "figur": [4, 8, 10, 12, 13, 15, 18, 19, 21, 26, 28, 29, 31, 35, 37, 39, 40, 41, 42, 45, 46, 47, 48, 54], "file": [0, 1, 4, 5, 7, 8, 10, 12, 13, 17, 18, 23, 27, 29, 33, 36, 39, 45, 47, 49], "file_nam": 26, "filenam": 45, "fill": [15, 21, 25, 26, 27, 31, 34, 35, 43, 49, 54, 56], "fill_diagon": [15, 21, 31], "fill_valu": [36, 37, 38, 39, 46, 48], "film": [44, 50], "filter": [4, 11, 12, 14, 18, 20, 28, 30, 41, 46, 52], "filterwarn": [15, 18, 20, 21, 31, 47], "final": [1, 6, 7, 12, 14, 16, 18, 20, 22, 25, 30, 32, 38, 40, 48, 49, 53, 55], "final_estim": 38, "final_estimator_": 38, "financ": [45, 46], "find": [1, 7, 8, 12, 13, 16, 18, 19, 22, 26, 27, 28, 29, 32, 35, 37, 38, 39, 41, 42, 43, 44, 48, 50, 51, 56], "fine": [7, 16, 17, 22, 23, 32, 33, 36, 43, 45, 46, 49], "finish": [12, 18, 28, 37], "fira": [0, 1], "firasm": 36, "firefox": [12, 18], "fireplac": [37, 39, 48], "fireplacequ": [37, 39, 48], "first": [1, 4, 8, 13, 15, 17, 19, 21, 23, 27, 29, 31, 33, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 56], "first_dai": 46, "first_day_retail": 46, "first_pass_isfinit": 27, "firth": 44, "fish": [36, 39], "fist": 46, "fit": [0, 12, 14, 15, 17, 18, 20, 21, 23, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 56], "fit_intercept": 36, "fit_method": 27, "fit_predict": 42, "fit_resampl": 36, "fit_tim": [14, 15, 16, 17, 20, 21, 22, 23, 26, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 47, 50], "fit_transform": [16, 17, 22, 23, 32, 33, 36, 38, 39, 40, 42, 43, 44, 46, 52], "fittedcolumntransform": [17, 23, 33, 38], "fittedpipelin": [33, 35, 37], "fittedvotingclassifi": 38, "fitter": 47, "five": 35, "fix": [16, 17, 22, 23, 27, 32, 33, 38, 47, 49, 51, 54, 56], "flag": 47, "flagstaff": 50, "flaki": 36, "flashcard": 52, "flask": 49, "flat": 42, "flatten": [26, 38, 39, 42, 46], "flatten_train": 45, "flatten_transform": 45, "flatten_valid": 45, "flaw": [14, 16, 20, 22, 30, 32], "flawless": 34, "flexibl": [7, 12, 28, 40, 45, 52, 56], "flibbertigibbet": 44, "flickr_cat_000002": 45, "flight": 40, "flip": [1, 14, 30, 36, 37, 49], "flip_i": 36, "float": [8, 27, 37, 40, 47, 50], "float32": [44, 45], "float64": [13, 15, 16, 17, 21, 22, 23, 26, 27, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 43, 46, 47], "floatlogslid": [15, 21, 31, 54], "floatslid": [15, 21, 26, 31, 36, 41, 42, 54], "floor": [12, 13, 18, 25, 28, 29, 56], "flower": [15, 21, 26, 31, 36, 49, 54], "fmt": 35, "fn": 36, "fnlwgt": [36, 38, 39], "focu": [1, 11, 12, 16, 17, 18, 22, 23, 27, 28, 32, 33, 34, 39, 42, 43, 44, 46, 52, 54, 55, 56], "focus": [12, 28, 34, 41, 44, 52], "fold": [14, 16, 17, 20, 22, 23, 30, 32, 33, 35, 36, 37, 38, 49, 54], "folder": [5, 6, 22, 30, 32, 39, 49, 50], "folk": [47, 49, 56], "follow": [0, 5, 6, 7, 8, 10, 15, 16, 17, 19, 21, 22, 23, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56], "font": [12, 13, 14, 18, 19, 20, 28, 29, 30, 41, 42, 43, 46, 47, 48], "font_scal": 39, "fontsiz": [13, 14, 15, 19, 20, 21, 25, 26, 29, 30, 31, 36, 38, 39, 41, 45, 48, 53, 54], "food": [27, 41, 44, 45, 56], "food_typ": 27, "foot": [37, 39], "footag": 34, "footstal": 45, "forc": [36, 39, 54], "force_all_finit": 27, "force_plot": 39, "force_writ": 27, "forecast": [11, 13, 19, 29, 47, 48, 52], "forest": [11, 36, 37, 45, 46, 47, 49, 52], "forev": 46, "forg": [10, 36, 37, 38, 39, 44, 47, 50], "forget": [13, 15, 16, 17, 19, 23, 29, 33, 38], "form": [1, 12, 17, 18, 21, 23, 33, 36, 40, 42, 43, 44, 47, 48, 49, 52], "formal": 56, "format": [0, 1, 13, 19, 25, 27, 29, 36, 42, 44, 46, 47], "former": 47, "formul": [4, 35], "formula": [34, 37, 45, 51], "forum": [12, 18], "forward": [47, 49], "found": [1, 7, 14, 17, 20, 23, 24, 25, 27, 30, 33, 35, 37, 41, 43, 44, 50, 52, 56], "foundat": [1, 9, 11, 36, 37, 39, 48], "foundation_brktil": 37, "foundation_cblock": 37, "foundation_pconc": 37, "foundation_slab": 37, "foundation_ston": 37, "foundation_wood": 37, "fountain": 45, "four": [13, 14, 19, 29, 30, 40, 42, 49, 52], "fourth": 42, "foxhound": [12, 18, 28, 45], "foyer": 37, "fp": 36, "fpr": 36, "fpr_lr": 36, "fpr_svc": 36, "frac": [13, 19, 29, 34, 36, 37, 41, 44, 45], "fractal": 40, "fraction": [17, 23, 33, 36, 43], "fragment": 54, "frame": [16, 17, 22, 23, 32, 33, 36, 37, 40, 46, 47, 48, 49], "framework": [29, 35], "fraud": [13, 19, 29, 36, 37, 41, 46], "fraudul": [13, 19, 29, 36, 48], "frederick": [1, 56], "free": [0, 5, 17, 23, 33, 37, 44, 47, 49], "freedom": [0, 50], "french": [16, 22, 32, 44], "freq": 46, "frequenc": [17, 23, 33, 44, 46, 47, 52], "frequent": [13, 16, 19, 22, 29, 32, 43, 44, 47], "fresh": [43, 44], "fri": [12, 46], "fridai": [14, 18, 56], "friend": [13, 14, 19, 29, 30, 36, 39, 42, 43, 49, 52, 56], "from": [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56], "from_block": 47, "from_estim": 36, "front": 56, "fruit": 44, "frustrat": [4, 6, 35], "full": [25, 35, 38, 45, 46, 47, 56], "fullbath": [37, 39, 48], "fulli": 42, "fun": [36, 44, 45], "func": [8, 17, 23, 33, 34, 37, 48], "function": [2, 12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 26, 28, 29, 30, 31, 33, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 54], "functiontransform": [17, 23, 27, 33, 47], "fund": 50, "fundament": [1, 2, 9, 11, 16, 22, 32, 34, 35, 37, 40, 45, 47, 56], "funni": [12, 28, 38, 50], "furnish": 0, "furnitur": 52, "further": [25, 36, 38, 40, 41, 44, 45, 47, 49, 54, 56], "furthermor": 48, "fusion": 27, "futur": [11, 14, 18, 20, 22, 30, 32, 35, 37, 47, 50, 52], "futurewarn": [22, 30, 32, 37, 39, 50, 51], "fuyi": [12, 13, 14, 16, 17, 56], "fyi": 47, "g": [6, 7, 8, 11, 12, 13, 16, 17, 18, 19, 22, 23, 25, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52], "g26r0dcx4b35vf3nk31216hc0000gr": [32, 39, 50], "gain": [6, 11, 13, 19, 29, 36, 38, 39], "game": [13, 19, 29, 39, 44], "gamma": [26, 34, 35, 38, 48, 54], "gamma_log": [15, 21, 26, 31, 54], "gamma_widget": [15, 21, 26, 31, 54], "gap": [14, 20, 25, 30, 46, 47, 48, 52, 54], "garagearea": [37, 39, 48], "garagecar": [37, 39, 48], "garagecond": [37, 39, 48], "garagefinish": [37, 39, 48], "garagefinish_fin": 37, "garagefinish_miss": 37, "garagefinish_rfn": 37, "garagefinish_unf": 37, "garagequ": [37, 39, 48], "garagetyp": [37, 39, 48], "garagetype_2typ": 37, "garagetype_attchd": 37, "garagetype_bas": 37, "garagetype_builtin": 37, "garagetype_carport": 37, "garagetype_detchd": 37, "garagetype_miss": 37, "garageyrblt": [37, 39, 48], "garlic": 41, "gaurav": [1, 56], "gauss": 44, "gaussian": 42, "gaussianmixtur": 42, "gave": [43, 46], "gbr": 8, "gca": [41, 42, 47], "gd": [12, 18, 28, 37, 39, 48], "gdprv": [37, 39, 48], "gdwo": [37, 39, 48], "gelbart": [0, 1, 19, 29, 44], "gender": [12, 17, 18, 28, 33, 36, 44, 46, 47], "gender_femal": 47, "gender_mal": 47, "gener": [7, 9, 12, 13, 16, 17, 19, 22, 23, 25, 27, 29, 32, 33, 35, 36, 37, 39, 42, 44, 45, 46, 47, 48, 49, 51, 52, 54, 56], "genet": 40, "genom": 40, "genr": 43, "gensim": 44, "gentl": 11, "geog": [1, 56], "geograph": [34, 49], "geometr": [13, 29], "georg": 44, "geq": 34, "ger": 8, "german": 44, "get": [1, 4, 5, 6, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56], "get_avg_word_length": 50, "get_cmap": [16, 22, 32], "get_depth": [25, 54], "get_dummi": [16, 22, 32], "get_featur": [26, 45], "get_feature_names_out": [16, 17, 22, 23, 27, 32, 33, 36, 37, 38, 39, 40, 44, 46, 47, 48, 50], "get_length_in_word": 50, "get_lr_data_per_us": 43, "get_param": 26, "get_permutation_import": 39, "get_relative_length": 50, "get_season": 46, "get_senti": 50, "get_stat": 43, "get_tag": 27, "get_user_profil": 43, "getattr": 47, "ghassemi": [1, 56], "gif": [41, 42], "gift": 50, "gigaword": 44, "gini": [13, 19, 29, 39, 48], "git": [3, 8, 12, 18], "github": [0, 1, 7, 9, 10, 12, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 32, 33, 35, 36, 37, 38, 39, 40, 45, 48, 49, 50], "githubusercont": 8, "gitlf": 36, "giulia": [0, 1, 56], "give": [0, 12, 13, 14, 17, 18, 19, 20, 22, 23, 25, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 53, 54], "given": [0, 14, 15, 16, 17, 20, 21, 22, 23, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54], "gladwel": 41, "glass": 48, "glob": [12, 18, 26, 28, 45], "global": [16, 22, 32, 36, 38, 41, 44, 52], "global_skip_valid": 27, "glove": [11, 44], "glq": [37, 39, 48], "gmail": [12, 18, 28, 41], "go": [1, 5, 7, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54], "goal": [2, 11, 15, 16, 21, 22, 31, 32, 35, 36, 41, 42, 43, 44, 49, 50], "goe": [2, 12, 14, 15, 17, 18, 20, 21, 23, 30, 31, 33, 36, 38, 39, 42, 43, 45, 48, 49], "gold": 8, "goldcoast": 46, "golden": [15, 25, 31, 49, 52, 54], "good": [9, 10, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 27, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 54, 55], "good_serv": 27, "goodarzvand": [1, 56], "googl": [1, 4, 12, 13, 18, 19, 28, 29, 38, 39, 40, 41, 44, 48, 50], "google_news_vector": 44, "got": [15, 21, 31, 34, 35, 36, 37, 45], "gotten": 47, "gov": [36, 38, 39], "govern": [44, 56], "gpe": 44, "gpt": [43, 44], "gpu": [38, 44, 45], "grad": [36, 38, 39], "grade": [1, 3, 7, 12, 14, 16, 17, 20, 23, 25, 28, 30, 33, 35, 48, 52, 54, 55], "grader": 6, "grades_df": 52, "gradescop": [1, 6, 12, 13, 18, 56], "gradient": [49, 52], "gradientboostingclassifi": 38, "gradientboostingregressor": [38, 48], "gradientexplain": 39, "grading_concern": 6, "graduat": 45, "grai": 45, "grain": [34, 39], "gram": 44, "grammat": 44, "grandma": 40, "grandmoth": [36, 49], "grant": 0, "grant_macewan": 44, "granular": 42, "graph": [1, 26, 45, 46], "graphic": 45, "graphic_design": 44, "graphviz": [13, 19, 29, 53], "grasp": [11, 52], "grayscal": 45, "great": [12, 15, 17, 18, 20, 21, 23, 28, 29, 31, 33, 34, 39, 40, 44, 45, 46, 48, 50], "greater": [10, 40, 41], "greater_is_bett": 37, "greedili": 42, "green": [15, 21, 31, 35, 41, 48, 51], "grei": 56, "grid": [34, 37, 46, 47, 52], "grid_result": 48, "grid_search": [35, 48], "gridsearchcv": [15, 21, 31, 38, 39], "gridsearchcvifittedgridsearchcv": 35, "grinberg": 49, "grip": 44, "grlivarea": [37, 39, 48], "groak": 44, "groceri": [45, 50], "groin": 45, "ground": [14, 20, 30, 40, 42, 43, 56], "ground_truth_categori": [36, 49], "group": [7, 11, 13, 15, 16, 17, 19, 21, 26, 29, 31, 33, 34, 38, 40, 52, 54, 55], "groupbi": 46, "grow": [35, 38, 40], "grow_polici": 38, "growth": [46, 47], "groyn": 45, "grv": 37, "gsc": 48, "gt": [17, 23, 33, 34, 35, 36, 37, 38], "gtl": 39, "gtoti": [19, 23], "guarante": [35, 36, 38, 41, 45], "guenon": 45, "guess": [15, 16, 21, 22, 31, 32, 44, 50], "guid": [1, 7, 9, 12, 18, 40, 45, 49, 56], "guidanc": 39, "guidelin": [16, 39, 40, 49], "guido": 1, "h": [25, 36, 38, 39, 41, 44, 45, 47, 49, 50], "ha": [1, 2, 5, 6, 13, 14, 16, 17, 19, 20, 22, 23, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 54, 56], "hab": 44, "habit": [17, 23, 33, 48, 49], "hacki": [45, 51], "had": [12, 16, 17, 18, 22, 23, 28, 32, 33, 34, 36, 43, 44, 45, 46, 47, 49], "hadn": [44, 47], "haidilao": 27, "hal": 1, "half": [1, 6, 12, 13, 18, 19, 29, 34, 40, 42], "halfbath": [37, 39, 48], "halvingrandomsearchcv": 35, "halvingrandomsearchcvifittedhalvingrandomsearchcv": 35, "ham": [12, 18, 28], "hand": [4, 9, 11, 27, 36, 43, 56], "handi": 36, "handl": [11, 25, 27, 38, 39, 42, 47, 49, 51, 52, 54], "handle_unknow": [17, 23, 33], "handle_unknown": [16, 17, 22, 23, 27, 32, 33, 35, 36, 37, 38, 39, 46, 47, 48, 52], "handler": [36, 39], "handrail": 45, "handwritten": [36, 48], "hang": 36, "happen": [4, 6, 12, 15, 17, 21, 23, 27, 28, 31, 33, 35, 38, 39, 40, 43, 46, 47, 48, 52, 56], "happi": [25, 27, 36, 41, 47], "happier": [49, 56], "happydb": [36, 49], "hard": [8, 12, 14, 15, 16, 18, 20, 21, 22, 28, 30, 31, 32, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 50, 52], "hardi": [1, 56], "hardli": 43, "hardwar": 45, "harmon": 36, "harri": [1, 44, 56], "has_emoji": 50, "has_nan_error": 27, "hasn": [4, 43, 44, 47], "hassl": [8, 39, 46], "hat": [34, 37, 38], "have": [0, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56], "haven": [14, 20, 27, 30, 44, 47, 48, 49, 52], "haylei": [19, 29], "hazard": 11, "hc_truncation_toy_demo": 42, "hdbscan": 42, "he": [14, 17, 20, 23, 30, 33, 44], "head": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50, 52, 55], "header": 49, "headlin": [44, 48], "health": 44, "healthcar": 39, "healthi": [44, 48], "heard": [14, 20, 30], "heart": [13, 19, 29, 50], "hearti": 27, "heat": [35, 37, 39, 48], "heating_floor": 37, "heating_gasa": 37, "heating_gasw": 37, "heating_grav": 37, "heating_othw": [37, 39], "heating_wal": 37, "heatingqc": [37, 39, 48], "heatmap": 39, "heavi": [38, 50], "heavili": [43, 45, 46], "heeren": 44, "height": [13, 14, 19, 20, 26, 29, 30, 36, 44, 50, 53], "hell": 50, "help": [3, 7, 10, 12, 14, 16, 18, 20, 22, 27, 28, 30, 32, 33, 35, 36, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 53, 54, 55, 56], "henc": [5, 36, 37, 39, 41], "her": [12, 18, 28, 43, 44], "here": [1, 4, 5, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56], "herebi": 0, "herself": [44, 50], "herta": [15, 31], "hesist": 48, "hesit": 48, "heurist": [13, 19, 29, 35], "hi": [44, 54], "hidden": [40, 44, 45, 48], "hide": [8, 45], "hier_label": 42, "hier_labels1": 42, "hier_labels2": 42, "hierarch": [11, 52], "hierarchi": [13, 19, 29, 42], "high": [6, 11, 14, 15, 19, 20, 21, 27, 30, 31, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49], "high_corr": 39, "higher": [13, 14, 15, 19, 20, 21, 29, 30, 31, 34, 36, 37, 38, 39, 40, 41, 43, 47, 48, 49, 54], "highest": [38, 39, 43, 44, 45, 48, 51, 54], "highland": 50, "highli": [1, 10, 16, 22, 32, 39, 43], "highlight": [4, 45, 48, 52], "highwai": 34, "him": 44, "himself": 44, "hinder": 56, "hindi": [16, 22, 32], "hint": [39, 54], "hist": [16, 22, 27, 32, 35, 37, 40, 47], "histgradientboostingclassifi": [27, 38], "histgradientboostingregressor": 38, "histogram": 47, "histor": 52, "histori": [34, 43, 46, 56], "hit": [12, 18, 28, 35], "hitter": 50, "hl": [37, 39, 48], "hmid": [36, 49], "hmmm": 47, "hockei": 44, "hold": [27, 48, 49], "holder": 0, "holdout": 36, "holi": 48, "holidai": [43, 56], "home": [13, 19, 26, 29, 34, 36, 45, 49], "homemak": 44, "homepag": 1, "homework": [1, 3, 4, 6, 8, 10, 15, 31, 34, 35, 44, 49, 52, 56], "honest": 48, "honour": 56, "hood": [14, 20, 27, 30, 49], "hope": [14, 20, 30, 48, 49], "hopefulli": 49, "hopeless": 40, "hopelessli": [15, 21, 31], "horizont": [13, 17, 19, 23, 27, 29, 33], "host": [5, 47, 49], "hot": [14, 17, 20, 23, 27, 30, 33, 39, 52], "hound": [12, 18, 28, 45], "hour": [1, 4, 10, 12, 36, 38, 39, 40, 43, 46, 49, 52, 56], "hourli": [47, 52], "hous": [19, 25, 37, 39, 40, 47, 48, 54], "houseag": 34, "household": [16, 22, 32, 33, 34, 40, 55], "housestyl": [37, 39, 48], "housestyle_1": 37, "housestyle_1stori": 37, "housestyle_2": 37, "housestyle_2stori": 37, "housestyle_sfoy": 37, "housestyle_slvl": 37, "housewif": 44, "housing_df": [13, 16, 22, 25, 29, 32, 33, 40, 54, 55], "housing_median_ag": [16, 22, 32, 33, 40, 55], "houston": 50, "how": [0, 3, 8, 10, 11, 12, 17, 18, 23, 25, 26, 28, 33, 35, 36, 37, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56], "howard": 41, "howev": [2, 8, 16, 17, 22, 23, 26, 32, 33, 36, 37, 39, 41, 43, 46, 47, 49, 51, 54], "hsjcy": 47, "hstack": 46, "html": [7, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 47, 48, 49, 50, 53, 55], "htrz": 56, "http": [0, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 45, 46, 47, 48, 49, 50, 56], "hug": 43, "huge": [17, 23, 33, 37, 44, 45, 46, 47], "human": [0, 12, 15, 16, 17, 18, 22, 23, 28, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45], "humidity3pm": 46, "humidity3pm_lag1": 46, "humidity9am": 46, "hummu": [41, 44], "humour": [1, 44], "hundr": 34, "hurrican": [12, 28], "husband": [36, 38, 39], "hussar": [12, 18, 28, 45], "hw": [12, 16, 28], "hw1": [1, 4, 13, 14, 16, 17, 53], "hw2": [1, 14, 15, 16, 22, 31, 32], "hw3": [1, 16, 17], "hw4": 1, "hw5": 1, "hw6": 1, "hw6a": 7, "hw6b": 7, "hw7": 1, "hw8": 1, "hw9": 1, "hybrid": 43, "hyper": 48, "hyperband": 35, "hyperopt": 35, "hyperparamet": [1, 14, 20, 26, 30, 36, 42, 43, 44, 45, 48, 49], "hyperparameter_": 48, "hyperparamt": [14, 20, 30, 35, 47], "hyperparlan": 34, "hyperplan": 34, "hypothesi": [44, 47, 49], "hypothet": [34, 41], "i": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 19, 21, 25, 26, 27, 29, 31, 34, 37, 42, 45, 46, 47, 51, 52, 53, 54, 55, 56], "i1": 38, "i2": 38, "ia": 50, "ibm": 50, "ic": 44, "icc": [1, 56], "iclick": 1, "id": [12, 13, 18, 25, 28, 29, 37, 39, 43, 48, 54], "idea": [8, 13, 14, 16, 19, 20, 22, 25, 26, 27, 29, 30, 32, 35, 39, 41, 42, 43, 44, 45, 46, 47, 49, 52, 54], "ideal": [4, 16, 27, 36, 38, 40, 43, 47, 49], "ident": [26, 44, 45], "identif": [12, 18, 28, 50], "identifi": [11, 13, 14, 15, 16, 19, 20, 22, 25, 29, 30, 31, 32, 35, 36, 37, 41, 42, 44, 45, 46, 48, 49, 52], "idf": [17, 23, 33], "idli": 44, "idx": [26, 45], "idxmax": [15, 21, 25, 31], "if_binari": [17, 23, 27, 33, 36, 38, 39, 52, 55], "ifram": [14, 20, 30, 36], "igloo": 44, "ignor": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 44, 46, 47, 48, 52], "ignore_index": 8, "ii": 36, "iii": 1, "ij": [34, 43], "ik": 38, "ill": 56, "illus": 36, "illustr": [42, 46], "iloc": [8, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 29, 30, 31, 32, 33, 38, 39, 44, 46, 50, 53], "im": 50, "imag": [7, 11, 14, 20, 22, 30, 36, 39, 40, 41, 42, 46, 48, 52], "image_dataset": [26, 45], "image_datasets_bw": 45, "image_fil": 26, "image_s": [26, 45], "imagefold": [26, 45], "imagenet": 51, "imagenet1k_v1": [26, 45], "imagenet_class": [12, 18, 28, 45], "imagin": [12, 13, 14, 16, 18, 19, 20, 22, 28, 29, 30, 32, 34, 36, 39, 40, 41, 44, 47, 48, 49, 52, 53], "imaginari": [14, 20, 30, 44], "imbal": [41, 47], "imbalanc": [36, 37, 51], "imblearn": 36, "img": [12, 18, 26, 28, 45], "img_classifi": [12, 18, 28], "img_ind": 26, "img_path": [12, 18, 28], "img_t": 45, "immedi": [39, 43, 56], "imp": [16, 22, 32, 33, 46], "impact": [7, 11, 17, 23, 33, 34, 38, 39, 42, 46, 48, 54, 56], "implement": [2, 4, 12, 16, 18, 22, 28, 32, 36, 37, 38, 40, 42, 43, 44, 47, 48, 49, 51], "impli": [0, 47], "implic": [11, 16, 22, 32, 49, 52], "implicit": 44, "import": [8, 11, 51, 55, 56], "importance_typ": 38, "importances_mean": 39, "impos": [16, 22, 32], "imposs": 41, "impress": 39, "improv": [11, 25, 27, 35, 36, 37, 38, 40, 41, 42, 43, 46, 47, 48, 49, 52, 56], "impur": [13, 19, 25, 29, 38], "imput": [14, 17, 20, 23, 27, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 46, 47, 48, 49, 52, 55], "imread": 45, "imshow": [12, 18, 26, 28, 45], "inabl": 18, "inbox": [14, 20, 30], "inc": [39, 44], "incept": [43, 45], "inception": 45, "incl": 37, "includ": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 18, 19, 22, 23, 26, 29, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 54, 55, 56], "include_bia": [40, 46], "incom": [14, 20, 30, 34, 36, 38, 39], "incomplet": 47, "inconsist": [17, 23, 33], "incorpor": [35, 37, 40, 47, 49, 52], "incorrect": [47, 48], "incorrectli": [12, 18, 28, 36], "increament": 49, "increas": [8, 14, 15, 17, 20, 21, 23, 25, 30, 31, 33, 34, 38, 39, 40, 41, 42, 45, 54], "increasingli": [12, 18, 28], "incred": 45, "increment": 49, "inde": 39, "independ": [8, 9, 13, 18, 19, 29, 35, 37, 38, 40, 46, 56], "index": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 50, 54], "index_col": [8, 15, 16, 22, 31, 32, 35, 36, 43, 49], "india": 44, "indian": [27, 36], "indian_liver_pati": [12, 18, 28], "indic": [0, 17, 23, 27, 33, 41, 43, 44, 45, 46, 47], "indirectli": 48, "individu": [27, 38, 39, 41, 43, 44, 47, 49, 56], "industri": [38, 40, 44, 45], "inequ": 36, "inertia_": 41, "inertia_valu": 41, "inf": [15, 21, 31, 47], "infeas": 35, "infer": [13, 29, 44, 45, 46, 49, 53], "infin": [15, 21, 31, 48], "infinit": 35, "inflamm": 9, "inflat": 39, "inflect": [41, 44], "influenc": [13, 14, 19, 20, 29, 30, 35, 39, 41, 43, 47, 54], "info": [1, 3, 8, 16, 17, 22, 23, 32, 33, 36, 37, 40, 44, 46, 47, 54], "infom": 44, "infor_m": 44, "inform": [1, 4, 7, 10, 12, 13, 16, 17, 19, 22, 23, 26, 29, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 54, 56], "informa_t": 44, "informaion": 44, "informaiton": 44, "informationabout": 44, "informationon": 44, "inhabit": 56, "inher": [19, 36, 46, 47], "initi": [26, 42, 45], "initj": 39, "inject": [40, 43, 52], "ink": 48, "inland": [16, 22, 32, 33, 40, 55], "inlin": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 53, 54], "inner": [17, 23, 33, 35, 44], "inplac": [8, 12, 13, 18, 28, 29, 35], "input": [8, 13, 16, 19, 22, 26, 27, 29, 32, 34, 38, 39, 42, 44, 45, 46, 49, 50, 52], "input_img": 45, "input_nam": 27, "input_tag": 27, "inputs_bw": 45, "insid": [9, 17, 23, 33, 36], "insight": [2, 11, 15, 21, 31, 36, 39, 41], "inspct": 36, "inspect": [39, 42], "inspir": [13, 29, 36, 38], "instal": [12, 15, 18, 26, 27, 28, 31, 36, 37, 38, 39, 41, 44, 45, 47, 49, 50], "instanc": [12, 13, 14, 17, 18, 19, 20, 23, 26, 27, 28, 29, 30, 33, 34, 36, 41, 42, 43, 44, 45, 46, 51], "instanti": [25, 35, 54], "instead": [5, 8, 10, 13, 14, 16, 17, 19, 22, 23, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 51, 54], "institut": [44, 50], "instruct": [3, 4, 5, 10, 12, 15, 16, 18, 31, 48, 49, 56], "instructor": [4, 6, 12, 18, 28, 48, 49, 56], "instrument": [15, 16, 22, 31, 32, 35], "int": [16, 17, 22, 23, 32, 33, 36, 38, 39, 44, 46, 50], "int32": [15, 21, 31, 41, 42, 46], "int64": [13, 15, 16, 17, 19, 23, 25, 27, 29, 31, 33, 36, 37, 43, 44, 46, 47, 49, 50], "integ": [8, 16, 22, 30, 32, 35, 38, 39, 46, 50], "integr": [11, 49], "intellig": [1, 44], "intelligen": 44, "intend": [0, 48, 56], "intens": 44, "inter": 50, "interact": [9, 12, 15, 18, 21, 26, 31, 35, 36, 39, 41, 42, 43, 46, 49, 50, 54], "interaction_constraint": 38, "interaction_onli": [40, 46], "interactive_plot": [15, 21, 26, 31, 54], "intercept": [39, 45, 51], "intercept_": [34, 38, 45, 51], "intercept_sc": 36, "interest": [2, 12, 14, 18, 20, 27, 28, 30, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 54], "interfac": [38, 49], "intermedi": [42, 45], "intern": [0, 1, 13, 19, 29, 45, 46, 47], "internet": [47, 48, 49], "internetservic": 47, "internetservice_dsl": 47, "internetservice_fib": 47, "internetservice_no": 47, "internship": [12, 18, 28], "interpret": [1, 10, 11, 15, 16, 21, 22, 25, 31, 32, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48], "interv": [11, 46, 47, 52], "interweb": 49, "intrins": 46, "intro": [1, 44, 45], "introduc": [17, 23, 33, 36, 47], "introduct": [1, 9, 10, 11, 25, 46, 47, 54], "intslid": [15, 21, 26, 31, 54], "intuit": [11, 15, 16, 17, 21, 22, 23, 31, 32, 33, 35, 37, 39, 41, 42, 47, 50], "invalid": 35, "inventori": 52, "invers": [34, 37], "inverse_func": [37, 48], "investig": [15, 21, 26, 31, 39, 54], "involv": [2, 4, 35, 37, 38, 42, 44, 45], "io": [9, 16, 22, 24, 32, 45, 47, 50], "ipykernel_13054": 50, "ipykernel_19402": 39, "ipykernel_32469": 32, "ipykernel_6214": 27, "ipykernel_70329": 22, "ipykernel_79734": 30, "ipynb": [7, 8, 12, 18], "ipython": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 36, 44, 53, 55], "ipywidget": [15, 21, 31, 54], "ir1": [37, 39, 48], "ir2": [37, 39, 48], "iri": [15, 21, 26, 31, 54], "iris_df": [15, 21, 26, 31, 54], "irregular": 11, "irregularli": 52, "irrelev": [15, 21, 31, 40, 44], "irrelevant_po": 44, "irrespect": [14, 20, 30, 34, 56], "is_avail": [26, 45], "is_classifi": 27, "is_leap_year": 46, "is_stop": 44, "is_year_end": 46, "isinst": [27, 47], "island": [16, 22, 32, 33], "isn": [14, 15, 21, 30, 31, 36, 37, 38, 44, 48], "isnul": [16, 22, 27, 32], "isol": [10, 36, 37, 39, 48], "issu": [4, 6, 7, 12, 18, 25, 38, 43, 47, 52, 56], "issubclass": 47, "isupp": 50, "itali": 44, "italian": 27, "item": [12, 18, 26, 28, 38, 39, 41, 43, 44, 45, 47, 52], "item_inverse_mapp": 43, "item_kei": 43, "item_mapp": 43, "iter": [26, 35, 40, 41, 42, 45, 49], "iterable_with_config": [17, 23, 33], "iterrow": 43, "its": [8, 11, 12, 14, 15, 17, 18, 21, 22, 23, 26, 27, 28, 30, 31, 33, 34, 36, 39, 41, 42, 44, 45, 46, 47, 50, 51, 54, 56], "itself": [7, 36, 38, 42, 44], "j": [8, 34, 39, 40, 41, 43, 45], "jackin": 35, "jackpot": [17, 23, 33], "jaguar": [12, 18, 28, 45], "jalebi": 44, "jam": 35, "jame": [44, 47, 50], "jan": [1, 12, 13, 16], "januari": [12, 18, 46], "japan": 44, "jargon": [13, 19, 29], "jason": [1, 40], "javascript": 39, "jazz_musician": 44, "jellyfish": 45, "jennif": 50, "jerri": 43, "jet": [16, 22, 32], "jetti": 45, "jieba": 44, "jim": 43, "jmlr": 35, "joan_baez": 44, "job": [17, 23, 33, 46, 47], "joblib": [17, 23, 33, 49], "joei": 27, "john": 38, "johnny_cash": 44, "join": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 56], "jointli": 46, "joke": [12, 18, 28, 43], "jolen": 50, "joni_mitchel": 44, "journal": 44, "journei": [1, 42, 56], "jpg": [26, 45], "json": 49, "ju": [12, 18, 28], "jubatu": [12, 18, 28, 45], "judg": 40, "judgment": 48, "juic": 44, "juli": 46, "june": 46, "jupyt": [1, 7, 8, 9, 10, 16, 17, 22, 23, 25, 26, 27, 28, 32, 33, 35, 36, 37, 38, 39, 40, 45, 48, 49, 50], "jupyter_notebook": 47, "jupyterlab": 39, "jurafski": 44, "jurisdict": 44, "just": [4, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 50, 52, 54, 56], "justic": [39, 44], "k": [1, 7, 11, 14, 20, 26, 27, 30, 34, 36, 37, 38, 40, 44, 45, 47, 49, 50, 51, 54], "k_neighbor": 36, "k_valu": [15, 21, 31], "kaggl": [13, 16, 22, 26, 29, 32, 36, 37, 38, 39, 40, 45, 48], "kaggler": 40, "kangaroo": 45, "kaplan": 11, "kaplanmeierfitt": 47, "kazmi": [1, 56], "kb": [17, 23, 33, 37, 47], "kbinsdiscret": 40, "kbinsdiscretizer__latitude_0": 40, "kbinsdiscretizer__latitude_1": 40, "kbinsdiscretizer__latitude_2": 40, "kbinsdiscretizer__latitude_3": 40, "kbinsdiscretizer__latitude_4": 40, "kbinsdiscretizer__latitude_5": 40, "kbinsdiscretizer__latitude_6": 40, "kbinsdiscretizer__latitude_7": 40, "kbinsdiscretizer__latitude_8": 40, "kbinsdiscretizer__latitude_9": 40, "kbinsdiscretizer__longitude_11": 40, "kbinsdiscretizer__longitude_12": 40, "kbinsdiscretizer__longitude_13": 40, "kbinsdiscretizer__longitude_14": 40, "kbinsdiscretizer__longitude_15": 40, "kbinsdiscretizer__longitude_16": 40, "kbinsdiscretizer__longitude_17": 40, "kbinsdiscretizer__longitude_18": 40, "kbinsdiscretizer__longitude_19": 40, "kbinsdiscretizerkbinsdiscret": 40, "kc_house_data": [12, 13, 18, 25, 28, 29, 54], "kdtree": 27, "keep": [1, 14, 15, 16, 17, 20, 21, 22, 23, 25, 30, 31, 32, 33, 36, 38, 39, 40, 41, 43, 44, 47, 49, 54, 55, 56], "keep_empty_featur": 43, "kei": [9, 11, 13, 15, 16, 19, 21, 22, 29, 30, 31, 32, 35, 36, 37, 38, 43, 44, 47, 50], "kelbowvisu": 41, "kellei": 34, "kept": [14, 20, 30], "kera": 39, "kernel": [1, 7, 16, 22, 26, 32, 34, 35, 39, 40, 48, 54], "kernelexplain": 39, "keyword": [4, 35, 50], "kfold": 36, "kick": 44, "kilian": 39, "kill": 47, "kimia": [1, 56], "kind": [0, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 28, 29, 30, 32, 33, 34, 36, 37, 39, 41, 42, 43, 45, 46, 47, 49, 51], "king": [25, 43, 44, 54], "kitchenabvgr": [37, 39, 48], "kitchenqu": [37, 39, 48], "kiwi": 44, "kk": 41, "km": [47, 48, 52], "km_label": 41, "kmean": [41, 42, 52], "kmf": 47, "kmqfw": 47, "kneighbor": 26, "kneighborregressor": [16, 22, 32], "kneighborsclassifi": [16, 17, 22, 23, 27, 32, 33, 34, 40, 54, 55], "kneighborsclassifierifittedkneighborsclassifi": 27, "kneighborsregressor": [16, 17, 22, 23, 32, 33, 34, 55], "kneighborsregressorkneighborsregressor": [16, 22, 32, 33], "knew": 41, "knn": [2, 14, 15, 16, 20, 21, 22, 30, 31, 32, 33, 34, 39, 40, 43, 45, 49, 51, 52], "knn1": [15, 21, 31], "knn100": [15, 21, 31], "knn_pipe": 33, "knn_scale": [16, 22, 32], "knn_unscal": [16, 22, 32], "knn_valid_accuraci": [15, 21, 31], "knnimput": 43, "knob": [13, 19, 29, 48], "know": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56], "knowledg": [8, 12, 13, 17, 18, 19, 23, 29, 33, 35, 40, 41, 44, 48, 52], "knowleg": 52, "known": [26, 43, 44, 47], "koala": 45, "kolhatkar": [0, 1, 19, 44], "kr9rkqfj4w78h49djkz8yy9r0000gp": 30, "ksatr": 47, "kvarada": [10, 29, 30, 33, 35, 39, 44, 45, 47, 50, 51], "kvarada01": 10, "kwantlen": 44, "kwarg": [14, 16, 17, 20, 22, 23, 27, 30, 32, 33, 47, 50], "l": 10, "l1": 47, "l123": 4, "l17": 4, "l1_ratio": 36, "l2": [36, 44, 47], "l9": 4, "la": 48, "lab": [10, 12, 13, 14, 18, 20, 29, 30, 41, 43], "lab1": [13, 14, 17, 19, 20, 23, 29, 30, 33, 52], "lab2": [13, 14, 17, 19, 20, 23, 29, 30, 33, 52], "lab3": [13, 14, 17, 19, 20, 23, 29, 30, 33, 52], "lab4": [13, 14, 17, 19, 20, 23, 29, 30, 33, 52], "label": [7, 8, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 50, 55], "label_": [44, 50], "label_encod": [38, 39], "label_n_clust": 42, "labelencod": [38, 39], "labels": [36, 41], "labels_": [41, 42], "lack": [14, 20, 30, 43, 48], "lag": [47, 52], "lag_df": 46, "lakehead_univers": 44, "lakeshor": 45, "lakesid": 45, "lamb": 27, "lambda": [8, 13, 19, 29, 34, 42, 45, 46, 47, 50], "land": 47, "landcontour": [37, 39, 48], "landcontour_bnk": 37, "landcontour_hl": 37, "landcontour_low": 37, "landcontour_lvl": 37, "landmark": 52, "landown": 50, "landscap": [41, 44], "landslop": [37, 39, 48], "landslope_gtl": [37, 39], "landslope_mod": [37, 39], "landslope_sev": [37, 39], "langara_colleg": 44, "languag": [2, 9, 16, 17, 22, 23, 32, 33, 43, 45, 49, 50], "language_enc": [16, 22, 32], "language_english": [16, 22, 32], "language_french": [16, 22, 32], "language_hindi": [16, 22, 32], "language_mandarin": [16, 22, 32], "language_spanish": [16, 22, 32], "language_vietnames": [16, 22, 32], "laptop": [12, 18, 28, 49], "lar": [12, 18, 28], "larg": [12, 14, 15, 16, 18, 20, 21, 22, 25, 28, 30, 31, 32, 34, 36, 37, 41, 42, 44, 45, 49, 52, 54], "larger": [13, 14, 15, 16, 20, 21, 22, 29, 30, 31, 32, 34, 35, 37, 38, 39, 41, 42, 47], "largest": 37, "larvatu": [12, 18, 28, 45], "last": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 26, 27, 29, 30, 31, 32, 33, 36, 39, 43, 45, 46, 47, 48, 49, 54, 56], "last_row": 8, "lastp": 42, "lat": [12, 13, 18, 25, 28, 29], "late": [18, 36, 56], "latent": [43, 44, 45], "latentdirichletalloc": 44, "later": [10, 13, 17, 19, 23, 29, 33, 36, 45, 46, 49, 54], "latest": [17, 23, 33, 39, 47], "latex": [4, 7, 12, 18], "latin": [12, 18, 28, 36], "latitud": [14, 15, 16, 20, 21, 22, 30, 31, 32, 33, 34, 40, 55], "latitude_0": 40, "latitude_1": 40, "latitude_10": 40, "latitude_11": 40, "latitude_12": 40, "latitude_13": 40, "latitude_14": 40, "latitude_15": 40, "latitude_16": 40, "latitude_17": 40, "latitude_18": 40, "latitude_19": 40, "latitude_2": 40, "latitude_3": 40, "latitude_4": 40, "latitude_5": 40, "latitude_6": 40, "latitude_7": 40, "latitude_8": 40, "latitude_9": 40, "latter": 37, "launch": [12, 18], "lauvagrand": 50, "law": [27, 44], "lawsuit": 44, "layer": [26, 45], "layout": [15, 21, 26, 31, 54], "lazi": [15, 21, 31], "lbfg": 36, "lda": 45, "ldot": 35, "lead": [1, 8, 14, 20, 30, 34, 37, 42, 43, 44, 47, 48], "leaf": [13, 19, 29, 42, 44], "leagu": 44, "leak": [16, 22, 32, 47, 52], "leakag": 52, "leaner": [14, 20, 30], "learn": [2, 9, 10, 27, 50, 51, 52, 53, 54, 55, 56], "learner": [14, 15, 20, 21, 30, 31, 38], "learning_method": 44, "learning_r": 38, "learnxinyminut": 9, "least": [1, 4, 14, 15, 20, 21, 30, 31, 36, 37, 39, 40, 41, 42, 48], "least_confident_i": 34, "least_confident_x": 34, "leav": [7, 13, 19, 29, 42, 45, 47, 48, 51], "lectur": [5, 7, 8, 10, 24, 52], "lecun": 39, "lecuy": 1, "lee": 39, "left": [7, 12, 18, 28, 35, 36, 37, 41, 42, 44, 46, 47, 48, 56], "legal": [0, 44], "legend": [7, 8, 15, 21, 31, 34, 36, 37, 40, 41, 45, 46, 47, 48, 51], "legendari": 50, "leisur": [36, 49], "lemma": 44, "lemma_": 44, "lemmat": 44, "lemon": 41, "len": [12, 14, 16, 20, 22, 26, 30, 32, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 48, 50], "length": [13, 14, 15, 19, 20, 21, 25, 26, 29, 30, 31, 34, 37, 39, 41, 42, 44, 46, 47, 50, 54], "leo": 38, "leopard": [12, 18, 28, 45], "leq": [40, 41], "less": [1, 5, 6, 12, 15, 17, 18, 21, 23, 28, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 52, 54], "lesson": [9, 16, 22, 32, 50], "lesssim": [14, 20, 30], "let": [12, 13, 14, 18, 19, 20, 25, 26, 28, 29, 30, 34, 35, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56], "letter": [34, 50], "lev": 37, "level": [11, 15, 21, 31, 34, 36, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49], "leverag": [39, 43], "lewi": 50, "lexic": 44, "lexicon": 50, "lgbm": [11, 38, 39, 52], "lgbmclassifi": [12, 18, 28, 38, 39], "lgbmclassifierifittedlgbmclassifi": [12, 18, 28, 39], "lgbmclassifierlgbmclassifi": 38, "lgbmregressor": [12, 18, 28, 38], "li": [1, 34, 56], "liabil": 0, "liabl": 0, "liao": [12, 18, 28], "lib": [17, 19, 23, 26, 27, 29, 30, 33, 35, 39, 47, 51], "librari": [4, 8, 10, 14, 20, 25, 27, 30, 36, 39, 40, 44, 45, 46, 48, 50, 54], "licensor": 0, "life": [13, 27, 29, 34, 41, 43, 48, 49, 53, 56], "lifelin": [11, 47], "lifetim": 47, "lighter": 35, "lightgbm": [12, 18, 28, 39, 49], "lightweight": 44, "like": [1, 2, 4, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56], "likelihood": 47, "likewis": 7, "lime": 39, "limit": [0, 12, 13, 14, 17, 18, 20, 23, 28, 29, 30, 33, 38, 39, 48, 49, 50, 52, 53, 56], "linalg": 44, "line": [4, 8, 10, 12, 13, 17, 18, 19, 23, 27, 29, 33, 34, 35, 36, 37, 41, 44, 45, 46, 47, 48, 54], "line2d": 8, "linear": [1, 35, 36, 38, 40, 42, 43, 45, 46, 47, 48, 49, 51, 52], "linear_model": [12, 18, 28, 34, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 51], "linear_svc": 34, "linearli": [34, 40, 46], "linearregress": [34, 37, 40, 47], "linestyl": [41, 46], "linewidth": [46, 48], "linger": [15, 31], "lingual": 44, "linguist": [17, 23, 33], "link": [0, 4, 5, 7, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 33, 34, 35, 36, 37, 38, 42, 47, 48, 49, 56], "linkag": 42, "linkage_arrai": 42, "linkage_typ": 42, "linkedin": 43, "linspac": [34, 35, 37, 40, 48], "lion": 43, "list": [4, 7, 8, 10, 14, 15, 16, 17, 20, 22, 23, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 56], "listedcolormap": 34, "literatur": 38, "littl": [8, 36, 45, 48, 49], "live": [1, 10, 12, 15, 16, 17, 18, 22, 23, 31, 32, 33, 35, 41, 47, 48, 49], "liver": [13, 19, 29], "livestream": 56, "ll": [1, 6, 7, 10, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 56], "llazx": 47, "lo": 50, "load": [8, 12, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 48, 50, 54, 55], "load_breast_canc": 40, "load_citibik": 46, "load_digit": 48, "load_iri": [15, 21, 26, 31, 54], "loan": 36, "loc": [8, 15, 21, 31, 34, 36, 39, 43, 46, 47, 48], "local": [5, 7, 10, 26, 27, 36, 38, 39, 40, 45, 50], "locat": [8, 17, 23, 26, 33, 41, 43, 44, 46, 50, 56], "location_katherin": 46, "location_mountginini": 46, "location_townsvil": 46, "location_witchcliff": 46, "location_wollongong": 46, "lock": [14, 20, 30], "log": [12, 13, 15, 21, 26, 27, 31, 37, 38, 47, 48, 49, 54], "log10": 37, "log1p": [37, 48], "log2": 47, "log_likelihood_ratio_test": 47, "log_loss": 48, "logarithm": [15, 21, 26, 31, 54], "logic": 40, "logical_xor": 40, "login": 43, "logisit": 45, "logist": [38, 39, 46, 47, 48, 49, 50, 51, 52], "logisticregress": [12, 18, 28, 34, 37, 38, 39, 40, 44, 45, 49, 50, 51], "logisticregressionifittedlogisticregress": 45, "logisticregressionlogisticregress": [36, 38, 45, 50], "logloss": 39, "lognorm": 35, "logspac": [26, 35], "loguniform": 35, "lol": [17, 23, 33], "london": 50, "lone": 42, "long": [0, 12, 13, 18, 19, 25, 28, 29, 34, 36, 38, 42, 43, 47, 49, 52, 56], "longer": [7, 35, 36, 45, 47, 48, 49], "longest": [13, 19, 29], "longitud": [14, 15, 16, 20, 21, 22, 30, 31, 32, 33, 34, 40, 55], "longitude_0": 40, "longitude_1": 40, "longitude_10": 40, "longitude_11": 40, "longitude_12": 40, "longitude_13": 40, "longitude_14": 40, "longitude_15": 40, "longitude_16": 40, "longitude_17": 40, "longitude_18": 40, "longitude_19": 40, "longitude_2": 40, "longitude_3": 40, "longitude_4": 40, "longitude_5": 40, "longitude_6": 40, "longitude_7": 40, "longitude_8": 40, "longitude_9": 40, "look": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54], "lookatm": [12, 18, 28], "loop": [35, 38, 46, 51, 52], "loos": [42, 49], "lose": [6, 17, 23, 33], "loss": [2, 36, 37, 38, 39, 44, 47], "lot": [5, 9, 12, 13, 15, 17, 18, 19, 20, 21, 23, 27, 28, 29, 31, 33, 34, 35, 36, 37, 39, 40, 42, 45, 46, 47, 48, 49, 56], "lotarea": [37, 39, 48], "lotconfig": [37, 39, 48], "lotconfig_corn": 37, "lotconfig_culdsac": 37, "lotconfig_fr2": 37, "lotconfig_fr3": 37, "lotconfig_insid": 37, "lotfrontag": [37, 39, 48], "lotshap": [37, 39, 48], "lotshape_ir1": [37, 48], "lotshape_ir2": [37, 48], "lotshape_ir3": [37, 48], "lotshape_reg": [37, 48], "loud": [15, 16, 22, 27, 31, 32, 35, 52], "loui": 46, "lourenzutti": 35, "love": [49, 50], "low": [6, 14, 15, 20, 21, 27, 30, 31, 35, 36, 37, 39, 40, 41, 42, 47, 48, 49], "lower": [14, 15, 20, 21, 30, 31, 36, 37, 39, 41, 43, 44, 47, 48], "lowerbound_peopl": 27, "lowercas": [16, 17, 22, 23, 32, 33], "lowest": [54, 56], "lowqualfinsf": [37, 39, 48], "lr": [34, 36, 37, 39, 45, 46, 47, 50, 51], "lr_1": 40, "lr_2": 40, "lr_3": 40, "lr_coef": [39, 46, 47], "lr_coefs_landslop": 39, "lr_flatten_pip": 45, "lr_item": 43, "lr_pipe": [37, 39, 46], "lr_pred": [36, 37], "lr_scale": 39, "lr_schedul": 45, "lr_x": 43, "lr_y": 43, "ls15hb": [12, 18, 28], "lstm": 46, "lt": [14, 16, 17, 20, 22, 23, 30, 32, 33, 35, 36, 37, 38, 39, 40, 47], "ltorgo": 34, "luck": 49, "lucki": [15, 21, 31, 35], "lundberg": 39, "luster": 42, "lvert": 44, "lvl": [37, 39, 48], "lwq": [37, 39, 48], "lynx": [12, 18, 28, 45], "l\u00e9cuyer": [44, 56], "m": [10, 12, 14, 18, 20, 25, 26, 27, 28, 30, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "m_neighbor": 36, "ma": [35, 44], "macaqu": [12, 18, 28, 45], "macbook": 10, "mach": 44, "machin": [2, 9, 10, 11, 16, 17, 22, 23, 26, 27, 32, 33, 35, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 50, 52, 54, 56], "machine_learn": 48, "mackworth": 1, "made": [0, 6, 7, 8, 12, 13, 18, 19, 28, 29, 36, 38, 39, 43, 44, 45, 46, 48, 49], "magazin": 44, "magnitud": [22, 35, 37, 39, 44, 46], "maguir": 43, "mahsa": [1, 56], "mai": [0, 1, 7, 8, 10, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 49, 53, 54, 55, 56], "mail": 47, "main": [8, 10, 12, 13, 15, 17, 18, 19, 21, 23, 25, 29, 31, 33, 38, 41, 42, 52, 56], "mainland": 34, "mainli": 56, "maintain": [38, 43, 48, 52], "mainten": 38, "maissan": [1, 56], "maj1": [37, 39, 48], "maj2": [37, 39, 48], "major": [2, 14, 15, 16, 17, 20, 21, 22, 23, 30, 31, 32, 33, 44, 52, 53], "major_biologi": [17, 23, 33], "major_comput": [17, 23, 33], "major_econom": [17, 23, 33], "major_linguist": [17, 23, 33], "major_mathemat": [17, 23, 33], "major_mechan": [17, 23, 33], "major_phys": [17, 23, 33], "major_psychologi": [17, 23, 33], "make": [2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56], "make_blob": [15, 21, 31, 41, 42, 45, 51], "make_circl": 42, "make_classif": [15, 21, 31, 36], "make_column_transform": [27, 35, 36, 37, 38, 39, 40, 46, 47, 48, 50, 55], "make_forg": [15, 21, 31], "make_grid": [26, 45], "make_imb_pipelin": 36, "make_moon": 42, "make_num_tree_plot": 38, "make_pipelin": [12, 17, 18, 23, 27, 28, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 49, 50, 55], "make_scor": [37, 40], "maker": 48, "malcolm": [41, 43], "malcom": 41, "male": [36, 38, 39, 47], "male_cm": 36, "male_pr": 36, "mall": 50, "mamba": [26, 27], "man": [43, 44], "manag": [5, 11, 46, 47, 48, 52], "mandarin": [16, 22, 32], "mango": 44, "mani": [1, 2, 5, 8, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 56], "manipul": 48, "manner": [0, 38], "manual": [10, 12, 17, 18, 19, 23, 26, 28, 33, 36, 40, 41, 42, 44], "manual_se": 26, "manufactur": 45, "map": [1, 13, 14, 17, 19, 20, 23, 29, 30, 33, 35, 43], "mape": [49, 52], "mape_scor": 37, "maple_leaf": 44, "mapper": 43, "mar": 1, "march": 46, "marit": [36, 38, 39], "mark": [6, 7, 18, 35, 36, 42, 56], "markdown": [12, 18], "marker": [15, 21, 31, 34, 41], "markers": [34, 36], "market": [12, 18, 28, 41, 45, 46, 48, 49], "markov": 44, "marri": [36, 38, 39], "martin": 44, "mask": 35, "massiv": [17, 23, 33, 35], "master": [8, 35, 36, 38, 39, 44], "masvnrarea": [37, 39, 48], "masvnrtyp": [37, 39, 48], "masvnrtype_brkcmn": 37, "masvnrtype_brkfac": 37, "masvnrtype_miss": 37, "masvnrtype_ston": 37, "match": [17, 23, 33, 34, 36, 38, 39, 46], "materi": [8, 10, 12, 13, 14, 15, 18, 21, 28, 29, 30, 31, 41, 44, 47, 49, 52, 56], "matern": 40, "math": [2, 41, 43, 47], "mathcal": [15, 31], "mathemat": [2, 17, 23, 33, 38, 49, 52], "mathematician": 44, "mathia": [1, 17, 56], "matlab": 8, "matplotlib": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 52, 53, 54, 55], "matplotlibdeprecationwarn": 39, "matric": [12, 15, 18, 21, 31, 36, 43], "matrix": [17, 23, 27, 33, 42, 44, 49, 52], "matter": [16, 17, 22, 23, 32, 33, 36, 38, 42, 48, 52, 56], "max": [8, 14, 16, 20, 22, 25, 27, 30, 32, 34, 35, 36, 37, 38, 41, 42, 46], "max_bin": 38, "max_cat_threshold": 38, "max_cat_to_onehot": 38, "max_clust": 42, "max_colwidth": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 42, 43, 53, 54, 55], "max_delta_step": 38, "max_depth": [14, 15, 20, 21, 25, 26, 30, 31, 35, 38, 39, 48, 53, 54], "max_depth_widget": [15, 21, 26, 31, 54], "max_df": [17, 23, 33], "max_displai": 39, "max_featur": [12, 17, 18, 23, 28, 33, 35, 38, 48], "max_it": [12, 18, 28, 36, 38, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51], "max_leaf_nod": [13, 19, 29, 48], "max_leav": 38, "max_opt": [15, 21, 31, 36, 41, 42], "max_row": 47, "max_sampl": 48, "maxabsscal": 27, "maxclust": 42, "maxent": 51, "maxim": [12, 18, 28, 36, 37, 41], "maximum": [13, 16, 19, 22, 27, 29, 32, 37, 38, 41, 42, 54], "maxosx": 10, "maxtemp": 46, "may": 1, "mayb": [36, 39, 46, 48, 56], "maybe_coerce_valu": 47, "mb": [16, 22, 32, 33, 36, 40, 46, 47], "mcld": 56, "mcml": [1, 56], "md": [10, 12, 13, 29, 44], "me": [8, 12, 18, 28, 35, 44, 48, 49, 50], "mean": [5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 43, 45, 46, 47, 49, 50, 51, 52, 54, 56], "mean_absolute_error": 49, "mean_absolute_percentage_error": 37, "mean_cv_error": [14, 20, 30], "mean_cv_scor": [15, 21, 26, 31, 34, 35], "mean_fit_tim": [35, 37], "mean_scor": [14, 16, 20, 22, 30, 32, 35, 50], "mean_score_tim": [35, 37], "mean_squared_error": [37, 40], "mean_std_cross_val_scor": [14, 16, 20, 22, 30, 32, 33, 38, 39, 47, 50], "mean_test_neg_mean_squared_error": 37, "mean_test_scor": [35, 37], "mean_train_error": [14, 20, 30], "mean_train_neg_mean_squared_error": 37, "mean_train_scor": [15, 21, 26, 31, 34, 35, 37], "meaning": [11, 15, 17, 21, 23, 26, 31, 33, 36, 39, 41, 44, 55], "meaningless": 42, "measur": [0, 12, 13, 14, 15, 18, 19, 20, 21, 28, 29, 30, 31, 36, 37, 39, 41, 42, 43, 44, 46, 47, 48, 49, 52, 54], "meat": 27, "mechan": [17, 23, 33, 52], "mechanical_engin": 44, "medal": 8, "media": 48, "median": [13, 16, 19, 22, 27, 29, 32, 33, 34, 37, 39, 40, 46, 47, 48], "median_house_valu": [16, 22, 32, 33, 40, 55], "median_incom": [16, 22, 32, 33, 40, 55], "mediat": 48, "medic": [36, 41, 56], "medinc": 34, "medit": [36, 49], "medium": [0, 15, 21, 27, 31, 47, 52], "meet": 44, "meier": 11, "melbourneairport": 46, "member": [34, 38, 56], "membership": [17, 23, 33, 41, 42], "memori": [8, 16, 17, 22, 23, 27, 32, 33, 36, 37, 38, 40, 45, 46, 47, 52], "mental": 48, "mention": [0, 4, 34, 47, 48], "menu": [10, 49], "merchant": 0, "merg": [0, 5, 10, 42], "meshgrid": 40, "mess": [43, 47], "messag": [4, 6, 10, 14, 17, 20, 23, 27, 30, 33], "messi": [40, 44], "met": 56, "meta": 38, "metacademi": 1, "method": [2, 11, 13, 15, 16, 19, 21, 22, 25, 26, 29, 31, 32, 34, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52], "methodologi": [16, 22, 32, 46], "metric": [1, 11, 15, 17, 21, 23, 27, 31, 33, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49], "mexican": 27, "mexico": 36, "mglearn": [13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 26, 29, 30, 31, 32, 33, 34, 35, 36, 41, 44, 45, 46, 51, 53, 54], "mi": [12, 18, 28, 35, 36, 48], "microsoft": 50, "midnight": 46, "midterm": [1, 6, 12, 18], "might": [1, 6, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 52, 54, 56], "mightn": 44, "miguel": 49, "mike": [0, 1, 9, 19, 29, 49], "mikolov": 44, "milk": 44, "mill": 38, "millennia": 56, "million": 45, "min": [1, 22, 25, 27, 34, 37, 42, 46], "min1": [37, 39, 48], "min2": [37, 39, 48], "min_child_weight": 38, "min_df": [17, 23, 33], "min_impurity_decreas": 48, "min_impurity_split": 48, "min_sampl": 42, "min_samples_leaf": [13, 19, 29, 48], "min_samples_split": [13, 19, 29, 48], "min_token_len": 44, "min_token_length": 44, "min_weight_fraction_leaf": 48, "mind": [14, 16, 17, 20, 22, 30, 32, 33, 38, 39, 43, 47, 48, 49, 52, 56], "mine": 1, "minibatchkmean": 42, "miniconda": 10, "miniconda3": [10, 17, 50], "miniforge3": [29, 30, 33, 35, 39, 47, 51], "minim": [5, 13, 19, 29, 37, 41, 42, 48], "minimum": [8, 14, 16, 20, 22, 30, 32, 42, 44], "minmaxscal": [16, 17, 22, 23, 27, 32, 33, 48], "minor": [6, 47], "mintemp": 46, "minut": [4, 12, 13, 18, 19, 29, 40, 47, 52], "miracl": 50, "miscalcul": 1, "miscfeatur": [37, 39, 48], "miscfeature_gar2": 37, "miscfeature_miss": 37, "miscfeature_othr": 37, "miscfeature_sh": 37, "miscfeature_tenc": 37, "misconduct": 56, "miscval": [37, 39, 48], "mishaal": [1, 56], "mislead": [14, 20, 30, 36], "miss": [10, 15, 16, 17, 21, 22, 23, 25, 27, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 46, 47, 48, 52, 54, 56], "mistak": [16, 22, 32, 38, 47, 48, 54], "mit": [0, 1], "mitig": [11, 43], "mitlp": 47, "mitt": 44, "mitten": 44, "mix": [12, 18, 37, 48, 49], "mixtur": [42, 44, 45], "ml": [1, 2, 9, 11, 13, 16, 19, 22, 29, 32, 38, 42, 44, 45, 49], "ml_experi": [13, 14, 17, 19, 20, 23, 29, 30, 33, 52], "mlpclassifi": 45, "mlpregressor": 45, "mm": 46, "mmsto": [12, 18, 28], "mn": [37, 39, 48], "mnprv": [37, 39, 48], "mnww": [37, 39, 48], "mo": 44, "mobil": [17, 23, 33, 45], "mobilenet": 45, "mod": [37, 39, 48], "mode": [15, 16, 22, 31, 32, 35], "model": [1, 2, 11, 21, 35, 36, 41, 42, 43, 46, 48, 51, 53], "model_nam": 43, "model_select": [12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 43, 45, 46, 47, 48, 49, 54, 55], "modern": [1, 15, 21, 31, 44, 48], "modif": 47, "modifi": [0, 10, 36, 47, 49, 56], "modul": [9, 14, 19, 20, 26, 27, 29, 30, 36, 50], "moe": 35, "mole": 45, "mom": 40, "moment": [36, 56], "moment_predictor": 49, "mon": 46, "monarch": 44, "monarchi": 44, "mondai": [1, 46, 56], "monei": [8, 47], "monitor": 44, "monkei": [12, 18, 28, 45], "monotone_constraint": 38, "montani": 50, "month": [14, 17, 23, 30, 33, 37, 47], "month_nam": [25, 46], "monthli": 47, "monthlycharg": 47, "montreal": [44, 50], "moon": 42, "moosvi": [0, 1, 44], "moral": [0, 41], "more": [1, 2, 5, 6, 7, 8, 10, 12, 14, 18, 26, 27, 30, 35, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56], "morn": [12, 18, 28], "morpholog": 44, "moskowitz": 41, "mosold": [37, 39, 48], "mosold_1": 37, "mosold_10": 37, "mosold_11": 37, "mosold_12": 37, "mosold_2": 37, "mosold_3": 37, "mosold_4": 37, "mosold_5": 37, "mosold_6": 37, "mosold_7": 37, "mosold_8": 37, "mosold_9": 37, "most": [7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 56], "most_confident_i": 34, "most_confident_x": 34, "most_frequ": [13, 15, 16, 19, 21, 22, 29, 31, 32, 36, 37, 39, 48, 53], "most_similar": 44, "mostli": [8, 17, 23, 33, 46], "motiv": [12, 17, 18, 23, 28, 33], "mountginini": 46, "move": [7, 34, 39, 40, 53, 56], "movi": [34, 44, 50], "movie_feats_df": 43, "movie_id": 43, "movie_nam": 43, "movies_rated_by_pat": 43, "movies_to_pr": 43, "movieto": 50, "mpimg": 45, "mri": 52, "mrtssm448usn": 46, "mse": [13, 19, 29, 43, 49, 52], "msg": [17, 23, 33, 47], "msg_dtype": 27, "msg_err": 27, "mssubclass": [37, 39, 48], "mssubclass_120": 37, "mssubclass_160": 37, "mssubclass_180": 37, "mssubclass_190": 37, "mssubclass_20": 37, "mssubclass_30": 37, "mssubclass_40": 37, "mssubclass_45": 37, "mssubclass_50": 37, "mssubclass_60": 37, "mssubclass_70": 37, "mssubclass_75": 37, "mssubclass_80": 37, "mssubclass_85": 37, "mssubclass_90": 37, "mszone": [37, 39, 48], "mszoning_c": [37, 39], "mszoning_fv": 37, "mszoning_rh": 37, "mszoning_rl": 37, "mszoning_rm": 37, "much": [4, 5, 8, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 29, 30, 31, 32, 33, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 54, 56], "mueller": 1, "multi": [37, 39, 41, 44, 46, 49], "multi_class": [36, 51], "multi_output": 27, "multi_strategi": 38, "multiclass": [45, 49, 51], "multicoliniar": 39, "multicultur": 44, "multilevel": 37, "multimod": 41, "multinomi": 51, "multipl": [7, 8, 14, 20, 25, 30, 34, 35, 38, 39, 44, 45, 46, 47], "multiplelin": 47, "multiplelines_no": 47, "multiplelines_y": 47, "multipli": [34, 35, 36, 38, 40, 47], "music": [27, 43, 50], "musqueam": 56, "must": [0, 6, 7, 8, 12, 13, 14, 16, 18, 19, 22, 29, 30, 32, 39, 42, 44, 47], "mustn": 44, "mutual": 42, "my": [6, 10, 12, 18, 28, 35, 36, 41, 44, 48, 49, 50, 56], "my_heatmap": 35, "my_map": 37, "mypreprocessor": 44, "myself": [29, 44, 48], "m\u00fcller": 9, "n": [1, 13, 15, 19, 21, 26, 27, 29, 31, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 48, 50, 51, 54], "n_bin": 40, "n_class": [15, 21, 31, 36], "n_cluster": [41, 42], "n_clusters_per_class": 36, "n_compon": 44, "n_constitu": 38, "n_estim": [40, 46, 47, 48], "n_estimators_valu": 48, "n_exampl": 41, "n_feat": [15, 21, 31], "n_featur": [15, 21, 31, 36, 41], "n_features_to_select": 40, "n_imag": 26, "n_inform": 36, "n_init": 41, "n_job": [17, 23, 33, 36, 37, 38, 48], "n_neighbor": [26, 43, 54], "n_neighbors_selector": [15, 21, 31], "n_neighbors_widget": [15, 21, 26, 31, 54], "n_peopl": 27, "n_redund": 36, "n_rental": 46, "n_rentalsin3hour": 46, "n_rentalsin6hour": 46, "n_repeat": 39, "n_resourc": 35, "n_sampl": [15, 21, 31, 36, 41, 42, 45, 51], "n_split": 46, "n_threshold": 36, "n_topic": 44, "n_train": 46, "n_word": [44, 50], "na": [37, 39, 48], "nafter": 44, "nah": [17, 23, 33], "naiv": 42, "name": [1, 4, 5, 6, 7, 8, 10, 13, 15, 16, 17, 19, 21, 22, 23, 25, 26, 27, 29, 31, 32, 33, 35, 36, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 50, 54, 56], "named_estimators_": 38, "named_step": [34, 36, 37, 38, 39, 40, 46, 48, 50], "named_transformers_": [17, 23, 33, 36, 37, 38, 39, 40, 46, 47, 48, 50], "namespac": 27, "nan": [16, 17, 22, 23, 27, 32, 33, 36, 37, 38, 39, 40, 43, 46, 47, 48, 50, 52], "nanmean": 43, "nanosecond": 46, "narr": 44, "narrow": [12, 18, 43, 48], "nasali": [12, 18, 28, 45], "nation": 56, "nativ": [27, 36, 38, 39, 45, 51], "natur": [2, 11, 12, 17, 23, 27, 28, 33, 36, 38, 40, 45, 49, 51], "navig": [7, 10, 49], "nbsp": [12, 18, 28, 32, 33, 35, 36, 37, 38, 39, 40, 45, 48, 50], "nbviewer": [12, 16, 17, 18, 22, 23, 25, 26, 27, 28, 32, 33, 35, 36, 37, 38, 39, 40, 45, 48, 50], "nc": 1, "ncol": 34, "ndarrai": [8, 17, 23, 27, 33], "ndate": 50, "ndframe": [40, 47], "ndim": [8, 27], "ne": 46, "nearbi": [15, 21, 31, 41], "nearest": [26, 27, 36, 42, 54], "nearestneighbor": 26, "nearestneighborsifittednearestneighbor": 26, "nearli": 25, "necessari": [0, 7, 13, 27, 29, 35, 52, 55], "necessarili": [14, 20, 30, 37, 38, 43, 49], "necvq": 47, "need": [5, 7, 8, 10, 12, 13, 15, 17, 18, 19, 21, 23, 25, 26, 27, 28, 29, 31, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 55, 56], "needn": 44, "neg": [13, 14, 15, 19, 20, 21, 29, 30, 31, 34, 37, 38, 39, 44, 46, 47, 50, 54], "neg_mean_absolute_percentage_error": 37, "neg_mean_squared_error": [37, 48], "neg_root_mean_square_error": 37, "neg_root_mean_squared_error": 37, "neigh": [15, 21, 26, 31], "neighbor": [15, 16, 17, 21, 22, 23, 26, 27, 31, 32, 33, 34, 36, 40, 42, 54, 55], "neighborhood": [34, 37, 39, 48], "neighborhood_blmngtn": 37, "neighborhood_bluest": 37, "neighborhood_brdal": 37, "neighborhood_brksid": 37, "neighborhood_clearcr": 37, "neighborhood_collgcr": 37, "neighborhood_crawfor": 37, "neighborhood_edward": 37, "neighborhood_gilbert": 37, "neighborhood_idotrr": 37, "neighborhood_meadowv": 37, "neighborhood_mitchel": 37, "neighborhood_nam": 37, "neighborhood_noridg": [37, 39], "neighborhood_npkvil": 37, "neighborhood_nridght": [37, 39], "neighborhood_nwam": 37, "neighborhood_oldtown": [37, 39], "neighborhood_sawy": [37, 39], "neighborhood_sawyerw": [37, 39], "neighborhood_somerst": [37, 39], "neighborhood_stonebr": [37, 39], "neighborhood_swisu": [37, 39], "neighborhood_timb": [37, 39], "neighborhood_veenk": [37, 39], "neighborsbas": 27, "neighbour": [14, 26, 30, 39, 41, 42, 44, 54], "neighbourhood": [34, 40, 42, 55], "neither": [14, 17, 20, 23, 30, 33, 43], "neo": [1, 56], "neq": [39, 43], "ner": 44, "nervou": [13, 19, 29], "nest": [35, 52], "net": [45, 47], "netflix": [43, 50], "network": [1, 11, 12, 17, 18, 23, 28, 33, 38, 40, 41, 43, 44, 46, 49], "neu": 50, "neural": [1, 11, 40, 46], "neutral": 50, "never": [36, 38, 39, 43, 45, 47], "nevertheless": 56, "new": [1, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 52, 55], "new_cent": 41, "new_column": [37, 39, 46, 47, 48], "new_data": 47, "new_df": 46, "new_exampl": [13, 19, 29, 41], "new_feature_nam": 46, "new_valu": 47, "newaxi": 8, "newcastl": 50, "newer": 37, "newli": [16, 22, 32, 37, 40, 42], "newsgroup": 44, "newswir": 44, "next": [1, 10, 13, 14, 15, 16, 19, 21, 22, 26, 27, 29, 30, 31, 32, 33, 36, 37, 38, 44, 45, 46, 48, 55, 56], "nfeat": [15, 21, 31], "nfeats_accuraci": [15, 21, 31], "ng": [1, 9, 35, 40], "ngram": 40, "ngram_rang": [17, 23, 33], "nhl": 44, "nhqxu": 47, "nice": [4, 12, 18, 35, 36, 38, 39, 42, 45, 47, 48, 49], "nicki": 35, "night": [36, 46, 49], "nightmar": 48, "niki": [1, 56], "nlemma": 44, "nlp": [17, 23, 33, 45, 50], "nltk": [44, 50], "nltk_data": [44, 50], "nmax": 48, "nn": [1, 16, 22, 26, 32, 45, 54], "nne": 46, "nnw": 46, "nnz": [17, 23, 33], "no_grad": [26, 45], "no_val_x": 27, "nobodi": [12, 28], "node": [13, 19, 29, 38, 42, 45, 53], "nois": [42, 52, 54], "noise_cat": 27, "noise_level": 27, "non": [1, 8, 12, 13, 14, 16, 18, 19, 20, 22, 28, 29, 30, 32, 34, 35, 36, 37, 38, 40, 42, 43, 45, 46, 47, 49, 52, 56], "noncommerci": 1, "none": [1, 14, 16, 17, 20, 22, 23, 27, 30, 32, 33, 34, 35, 36, 38, 40, 42, 46, 47, 48], "noninfring": 0, "nonzero": [17, 23, 33], "noodl": 27, "noqa": 35, "nor": [7, 14, 17, 20, 23, 30, 33, 44], "norg": [44, 50], "norm": [27, 35, 44], "normal": [6, 22, 26, 27, 36, 37, 38, 39, 41, 42, 44, 45, 46, 48, 50], "north": 44, "north_america": 27, "norvig": 1, "notat": [15, 31], "note": [0, 1, 3, 7, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 43, 49, 51, 52, 56], "notebook": [5, 7, 9, 10, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 45, 48, 50, 55], "notic": [0, 17, 23, 27, 33, 34, 36, 37, 40], "notion": [15, 21, 31, 35, 41, 43], "notna": 46, "noun": [44, 50], "nov": 46, "novel": 52, "novemb": 46, "novic": 9, "now": [8, 10, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 53, 54, 55], "np": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55], "nperson": 50, "npie": 8, "npo": 44, "npr": [40, 44, 52], "npt": 27, "nsubj": 44, "ntest": [15, 21, 26, 31, 35, 54], "ntoken": 44, "ntree": 38, "null": [16, 17, 22, 23, 32, 33, 36, 37, 40, 46, 47], "null_distribut": 47, "num": [36, 38, 39], "num_output_channel": 45, "num_parallel_tre": 38, "num_sent": [36, 49], "num_work": [26, 45], "number": [1, 4, 6, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 47, 49, 52, 54, 56], "number_test": 35, "numberbatch": 44, "numer": [2, 13, 16, 17, 19, 22, 23, 26, 27, 29, 32, 33, 34, 36, 37, 38, 43, 44, 46, 47, 48, 54, 55], "numeric_feat": [17, 23, 27, 33, 35, 40, 52], "numeric_featur": [33, 36, 37, 38, 39, 46, 47, 48, 50], "numeric_looking_column": 37, "numeric_transform": [33, 36, 37, 38, 39, 46, 48], "numpi": [9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55], "numpy_dtyp": 47, "nuniqu": 25, "nutrit": 44, "nw": 46, "nwith": [15, 21, 31], "ny": 50, "nyt": 48, "o": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55], "obelisk": 45, "object": [14, 16, 17, 20, 22, 23, 25, 27, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 50, 52, 53, 54], "observ": [12, 13, 14, 15, 18, 19, 20, 21, 26, 28, 29, 30, 31, 38, 39, 41, 42, 46, 47, 54], "obtain": [0, 26, 34, 41, 42, 43, 47, 54], "obviou": [42, 44], "occasion": 36, "occup": [36, 38, 39], "occupation_farm": 39, "occupation_miss": 39, "occupation_priv": 39, "occupi": 56, "occur": [8, 13, 14, 17, 19, 20, 23, 29, 30, 33, 44, 47], "occurr": [44, 47], "ocean": [16, 22, 32, 33, 40, 55], "ocean_proxim": [16, 22, 32, 33, 40, 55], "ocean_proximity_": [16, 22, 32, 33], "ocean_proximity_inland": [16, 22, 32, 33], "ocean_proximity_island": [16, 22, 32, 33], "ocean_proximity_near": [16, 22, 32, 33], "oct": 34, "octob": [25, 46], "oe": [17, 23, 33, 52], "oe_encod": 52, "off": [11, 26, 34, 35, 36, 37, 40, 41, 44, 45, 47, 48, 52], "offens": 4, "offer": [8, 38, 43, 44, 47, 56], "offic": [1, 4, 10, 12, 52, 56], "offici": [44, 56], "offlin": 43, "offset": 34, "often": [8, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54], "ogunrind": [12, 18, 28], "oh": [27, 39, 40, 45, 46, 47, 49, 52, 56], "ohe_column": [37, 39, 48], "ohe_enc": [17, 23, 33], "ohe_encod": 52, "ohe_feat": 27, "ohe_feature_nam": [39, 46], "ohehotencod": [17, 23, 33], "ois": 42, "ok": [12, 15, 18, 21, 28, 31, 37, 46, 47, 49, 52], "okai": [41, 49], "ola": 44, "old": [9, 38, 39], "old_cent": 41, "older": 37, "olymp": 8, "omit": 39, "omw": 44, "onc": [6, 7, 8, 10, 13, 14, 16, 17, 19, 20, 22, 23, 26, 29, 30, 32, 33, 35, 40, 42, 43, 44, 45, 49, 56], "onca": [12, 18, 28, 45], "one": [6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 56], "one_c": [15, 21, 31], "one_ex_preprocess": 39, "one_ex_preprocessed_perturb": 39, "one_exampl": 39, "one_example_perturb": 39, "onehot": [17, 23, 33, 40], "onehotencod": [16, 22, 27, 32, 34, 35, 36, 37, 38, 39, 40, 46, 47, 48, 52, 55], "onehotencoder__major_biologi": [17, 23, 33], "onehotencoder__major_comput": [17, 23, 33], "onehotencoder__major_econom": [17, 23, 33], "onehotencoder__major_linguist": [17, 23, 33], "onehotencoder__major_mathemat": [17, 23, 33], "onehotencoder__major_mechan": [17, 23, 33], "onehotencoder__major_phys": [17, 23, 33], "onehotencoder__major_psychologi": [17, 23, 33], "onehotencoderonehotencod": [17, 23, 33, 35, 37, 38, 48], "ones": [8, 12, 15, 16, 18, 21, 22, 25, 26, 28, 31, 32, 38, 39, 41, 43, 44, 54], "onevsoneclassifi": 51, "onevsrestclassifi": 51, "onli": [2, 4, 8, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 54, 55, 56], "onlin": [3, 5, 7, 10, 19, 29, 44, 56], "onlinebackup": 47, "onlinebackup_no": 47, "onlinebackup_y": 47, "onlinesecur": 47, "onlinesecurity_no": 47, "onlinesecurity_y": 47, "onrend": 49, "ontario": 44, "ontonot": 44, "oob_scor": 48, "op": 36, "open": [5, 6, 10, 12, 18, 28, 45, 49, 56], "openporchsf": [37, 39, 48], "oper": [4, 8, 10, 17, 23, 33, 40, 44, 49], "operand": 8, "opinion": 38, "opportun": [25, 43], "oppos": [37, 38], "opposit": [8, 37, 38, 39], "opt": [10, 26, 27, 38], "optic": 47, "optim": [1, 2, 13, 14, 15, 19, 20, 21, 26, 29, 30, 31, 33, 36, 38, 39, 40, 41, 42, 45, 47, 48, 49], "optimist": 35, "option": [1, 7, 8, 13, 18, 19, 29, 37, 41, 44, 48], "orang": 34, "orch": 56, "order": [5, 7, 8, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 48, 49, 52], "ordering_ordinal_oth": [37, 39, 48], "ordering_ordinal_reg": [37, 39, 48], "ordin": [37, 52, 55], "ordinal_feat": [17, 23, 27, 33], "ordinal_featur": [36, 38, 39], "ordinal_features_oth": [37, 39, 48], "ordinal_features_reg": [37, 39, 48], "ordinal_transform": [27, 36, 38, 39], "ordinal_transformer_oth": [37, 39, 48], "ordinal_transformer_reg": [37, 39, 48], "ordinalencod": [16, 17, 22, 23, 27, 32, 33, 36, 37, 38, 39, 40, 46, 47, 48, 52, 55], "ordinalencoderordinalencod": [17, 23, 33, 37, 38, 48], "ordinari": 37, "oreilli": [45, 46], "org": [9, 12, 14, 16, 17, 18, 20, 22, 23, 25, 26, 27, 28, 30, 32, 33, 35, 36, 37, 38, 39, 40, 44, 45, 48, 50], "organ": [12, 13, 16, 18, 19, 22, 28, 29, 32, 44, 48, 49], "orgin": 8, "orig_featur": 46, "orig_pr": 39, "orig_scor": 36, "origin": [12, 16, 17, 18, 22, 23, 32, 33, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 50, 54, 56], "original_hm": [36, 49], "originaltweet": 50, "ornithorhynchu": 45, "oscar": 34, "ostblom": 44, "other": [0, 1, 4, 5, 6, 7, 10, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 38, 39, 42, 43, 45, 49, 50, 51, 52, 54, 56], "otherwis": [0, 7, 17, 23, 33], "ounc": [12, 18, 28, 45], "our": [5, 6, 8, 10, 12, 13, 15, 17, 18, 19, 21, 23, 25, 26, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 56], "ourselv": [13, 19, 29, 36, 44, 45, 46], "out": [0, 1, 4, 7, 8, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 25, 27, 28, 29, 30, 31, 33, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 50, 52, 54, 56], "out_col": [14, 16, 20, 22, 30, 32, 50], "out_step": 36, "outer": 50, "outlier": [27, 37, 42, 49, 52], "outlook": 47, "output": [7, 8, 10, 12, 13, 14, 17, 18, 19, 20, 23, 27, 28, 29, 30, 33, 34, 36, 38, 39, 44, 45, 46, 48, 49, 52, 56], "outsid": [7, 36, 38, 39, 43, 44, 46, 47], "over": [14, 30, 35, 37, 44, 45, 46, 47, 48, 49, 52, 56], "over_confident_i": 34, "over_confident_x": 34, "over_sampl": 36, "overal": [10, 27, 36, 39, 41, 44, 45, 48, 52, 56], "overallcond": [37, 39, 48], "overallqu": [37, 39, 48], "overconfid": [39, 40, 49], "overcrowd": 56, "overfit": [1, 11, 15, 21, 25, 26, 31, 34, 37, 38, 40, 45, 49, 54], "overflow": 7, "overhead": [17, 23, 33], "overlap": [2, 14, 20, 30, 41, 49], "overli": [15, 21, 26, 31, 35, 54], "overload": [43, 47], "overpredict": 37, "oversample_pip": 36, "overshadow": 44, "overst": 48, "overus": 38, "overview": [41, 42, 43, 44], "overwhelm": 41, "overzeal": 6, "own": [4, 5, 8, 12, 14, 16, 18, 22, 30, 32, 36, 37, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51], "p": [34, 35, 42, 44, 47, 49], "p_i": 41, "p_value_threshold": 47, "pace": [34, 41, 44, 56], "packag": [5, 8, 11, 17, 19, 23, 26, 27, 29, 30, 33, 35, 36, 39, 41, 42, 43, 44, 45, 47, 49, 50, 51], "pad": [26, 45], "page": [1, 4, 7, 12, 16, 17, 18, 22, 23, 25, 26, 27, 28, 32, 33, 35, 36, 37, 38, 39, 40, 44, 45, 48, 50, 56], "pai": [39, 49], "pain": [4, 45, 46, 48], "pair": [42, 44, 51], "pairwis": [15, 21, 31, 42], "panda": [9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55], "pane": [15, 21, 26, 31, 54], "panel": [15, 21, 26, 31, 36, 39, 41, 42, 54], "panic": 50, "panther": [12, 18, 28, 45], "panthera": [12, 18, 28, 45], "paper": [7, 39, 40, 44, 45, 47, 49, 50], "paperlessbil": 47, "paperlessbilling_no": 47, "paperlessbilling_y": 47, "paradigm": [12, 13, 18, 19, 28, 29, 41, 44], "paradox": 43, "paragraph": 44, "paraleg": 44, "parallel": [17, 23, 33, 35, 38], "param": [15, 17, 21, 23, 26, 31, 33, 35, 37, 54], "param_columntransformer__countvectorizer__max_featur": 35, "param_dist": 35, "param_distribut": 35, "param_grid": [14, 15, 20, 21, 30, 31, 35, 37, 48], "param_grid1": 35, "param_grid2": 35, "param_grid3": 35, "param_grid4": 35, "param_ridge__alpha": 37, "param_svc__c": 35, "param_svc__gamma": 35, "paramet": [15, 16, 17, 21, 22, 23, 26, 27, 31, 32, 33, 37, 38, 39, 41, 42, 44, 46, 47, 48, 50, 53, 54], "parametr": 42, "params_": 47, "params_str": 35, "paramter": [15, 21, 31], "pardu": [12, 18, 28, 45], "parent": 42, "park": [40, 45, 49, 50], "pars": 44, "parse_d": [8, 46], "parser": 44, "part": [1, 4, 9, 10, 16, 17, 22, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 46, 48, 49, 50, 56], "part1": 43, "part2": 43, "parti": 44, "partial": [4, 47, 48], "particip": 56, "particular": [0, 9, 10, 16, 17, 22, 23, 32, 33, 35, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 54], "particularli": [38, 43, 56], "partit": [17, 23, 33, 41, 42], "partner": [47, 56], "partner_no": 47, "partner_y": 47, "parton": 50, "pass": [8, 14, 15, 16, 17, 20, 21, 22, 23, 26, 27, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 44, 45, 54, 56], "passthrough": [17, 23, 33, 35, 47, 50], "passthrough__ml_experi": [17, 23, 33], "passthrough_feat": [17, 23, 33, 35, 52], "passthrough_featur": [47, 50], "passthroughpassthrough": [17, 23, 33, 35, 50], "past": [13, 14, 19, 20, 29, 30, 38, 46, 47, 48, 52], "pat": 43, "pat_i": 43, "pat_model": 43, "pat_x": 43, "pata": [12, 18, 28, 45], "path": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55], "patial": 42, "patient": [13, 19, 29, 49], "patio": 45, "patric": 39, "patrick": [1, 56], "pattern": [12, 13, 14, 17, 18, 19, 20, 23, 25, 28, 29, 30, 33, 35, 40, 41, 44, 46, 48, 54], "pav_bhaji": 44, "pave": [37, 39, 48], "paveddr": [37, 39, 48], "paveddrive_i": 37, "paveddrive_n": 37, "paveddrive_p": 37, "paymentmethod": 47, "paymentmethod_bank": 47, "paymentmethod_credit": 47, "paymentmethod_electron": 47, "paymentmethod_mail": 47, "pca": [36, 42, 43], "pcarter": 9, "pd": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55], "pdf": [7, 9], "peac": 44, "pedest": 45, "pedro": [1, 14, 30, 40], "peer": [49, 52, 56], "pembrok": [12, 18, 28, 45], "penal": [6, 47], "penalti": [36, 44, 56], "peopl": [4, 13, 14, 16, 19, 20, 22, 29, 30, 32, 34, 36, 38, 41, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 56], "per": [8, 34, 36, 37, 38, 39, 43, 45, 46, 48, 51, 52], "perceiv": 6, "percent": 37, "percent_error": 37, "percentag": [13, 19, 29, 36, 43, 48], "perfect": [6, 13, 14, 19, 20, 25, 29, 30, 36, 37, 39, 43, 47, 50], "perfectli": [2, 43, 44], "perform": [11, 13, 14, 15, 16, 19, 20, 21, 22, 25, 26, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 52, 53, 55], "performac": [14, 20, 30], "perhap": [37, 46, 51], "perimet": 40, "period": [44, 46, 47, 50, 56], "perm_sorted_idx": 39, "perman": 8, "permiss": [0, 56], "permit": [0, 16, 22, 32, 36, 56], "permut": 39, "persist": 43, "person": [0, 1, 4, 6, 12, 18, 28, 36, 41, 44, 45, 46, 47, 49, 50, 56], "perspect": [38, 43], "pertain": 5, "perthairport": 46, "perturb": [27, 39, 42], "perturbed_pr": 39, "pete_seeg": 44, "peter": 1, "ph": 44, "pharma": 49, "phascolarcto": 45, "phase": [14, 20, 30], "phd": 44, "phdei": 47, "phenomenon": [43, 47, 54], "philippin": 50, "philosoph": 44, "phone": [12, 18, 28, 47, 56], "phoneservic": 47, "phoneservice_no": 47, "phoneservice_y": 47, "photo": [50, 52], "photograph": 56, "phrase": 44, "physic": [17, 23, 33, 46], "pi": 8, "piazza": [1, 6, 7, 12, 13, 18], "pick": [13, 19, 25, 29, 34, 36, 38, 39, 40, 41, 42, 45, 48, 49, 51, 53, 54], "pictur": [38, 39, 42, 44, 46, 48], "pie": 8, "piec": [34, 47], "pil": [12, 18, 26, 28, 45], "pin": [7, 45], "pineappl": 44, "pip": [10, 39, 44, 45, 49, 50], "pipe": [16, 17, 22, 23, 32, 33, 34, 35, 36, 38, 44, 45, 50], "pipe_bestalpha": 37, "pipe_bigalpha": 37, "pipe_catboost": 38, "pipe_dt": [38, 39], "pipe_forward": 40, "pipe_knn": 27, "pipe_lgbm": [38, 39], "pipe_lr": [36, 38, 39, 49], "pipe_lr_all_feat": 40, "pipe_lr_balanc": 36, "pipe_lr_model_bas": 40, "pipe_lr_weight": 36, "pipe_ohe_knn": 27, "pipe_ordinal_knn": 27, "pipe_rf": [38, 39], "pipe_rf_demo": 38, "pipe_ridg": [34, 37], "pipe_sklearn_gb": 38, "pipe_sklearn_histgb": 38, "pipe_smallalpha": 37, "pipe_svc": 36, "pipe_svm": 35, "pipe_xgb": [38, 39], "pipe_xor": 40, "pipelin": [1, 2, 11, 12, 14, 17, 18, 20, 23, 28, 30, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 49, 50, 55], "pipeline__lab1": [17, 23, 33], "pipeline__lab2": [17, 23, 33], "pipeline__lab3": [17, 23, 33], "pipeline__lab4": [17, 23, 33], "pipeline__quiz1": [17, 23, 33], "pipeline__rooms_per_household": 40, "pipeline__university_year": [17, 23, 33], "pipelineifittedpipelin": [16, 17, 22, 23, 32, 33, 35, 36, 40, 45, 50], "pipelineinot": [33, 35, 37], "pipelinepipelin": 35, "pitch": 48, "pitfal": [46, 48], "pixel": 39, "pizza": 44, "pkg": 10, "pla": 44, "place": [5, 44, 46, 56], "plagiar": 56, "plai": [13, 15, 19, 21, 29, 31, 35, 39, 42, 44, 53, 54], "plain": 41, "plan": [10, 12, 18, 28, 37, 40, 47, 49, 50, 55, 56], "plane": [19, 34], "plant": 52, "plastic": 44, "platform": 4, "platypu": 45, "player": [39, 44, 45], "pleas": [1, 4, 7, 10, 12, 16, 17, 18, 22, 23, 25, 26, 27, 28, 32, 33, 35, 36, 37, 38, 39, 40, 45, 48, 49, 50, 56], "plinth": 45, "plot": [7, 13, 14, 15, 16, 19, 20, 21, 22, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 40, 42, 43, 44, 45, 46, 48, 49, 54], "plot_2d_scor": 34, "plot_2d_separ": [15, 21, 26, 31, 34, 54], "plot_confusion_matrix": 36, "plot_confusion_matrix_exampl": 36, "plot_cross_valid": [14, 20, 30, 46], "plot_dbscan": 42, "plot_dbscan_with_label": 42, "plot_dendrogram_clust": 42, "plot_elbow": 41, "plot_example_dist": 41, "plot_fruit_tre": [13, 29], "plot_grid_search_overview": 35, "plot_improper_process": 27, "plot_k_means_dbscan_comparison": 42, "plot_km_initi": 41, "plot_km_it": 41, "plot_km_iter": 41, "plot_kmean": 42, "plot_knn_clf": [15, 21, 31], "plot_knn_decision_boundari": [15, 21, 31], "plot_knn_regress": [15, 21, 31], "plot_lda_w_vector": 44, "plot_linkage_criteria": 42, "plot_logistic_regress": 34, "plot_logistic_regression_graph": 45, "plot_loss_diagram": 48, "plot_multiclass_lr_ovr": 51, "plot_original_clust": 42, "plot_partial_effects_on_outcom": 47, "plot_proper_process": 27, "plot_result": [15, 21, 26, 31, 54], "plot_sample_img": 26, "plot_scal": [16, 22, 32], "plot_silhouette_dist": 41, "plot_single_hidden_layer_graph": 45, "plot_support_vector": [15, 21, 31], "plot_survival_funct": 47, "plot_svc_c": [15, 21, 31], "plot_svc_gamma": [15, 21, 31], "plot_time_spacing_distribut": 46, "plot_train_test_point": [15, 21, 31], "plot_tre": 25, "plot_tree_decision_boundari": [14, 20, 30], "plot_tree_decision_boundary_and_tre": [13, 14, 19, 20, 29, 30, 53], "plot_two_hidden_layer_graph": 45, "plot_typ": 39, "plot_x_dendrogram": 42, "plotli": [40, 44], "plotting_funct": [13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 45, 48, 51, 53, 54, 55], "plotting_functions_unsup": [41, 42, 43, 44], "plt": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 51, 52, 53, 54, 55], "plu": [34, 45], "plural": [17, 23, 33], "pm": [1, 12, 16, 18, 46, 56], "pmltt": 1, "pn": [15, 21, 26, 31, 36, 41, 42, 54], "po": [22, 30, 32, 34, 37, 39, 44, 48, 50], "pobox": [12, 18, 28], "poet": 44, "point": [1, 4, 11, 12, 13, 14, 16, 17, 18, 19, 22, 23, 25, 27, 28, 29, 30, 32, 33, 34, 35, 37, 40, 42, 47, 48, 49, 51, 52, 54, 56], "point_ind": 41, "point_index": 41, "polarity_scor": 50, "pole": 45, "polici": [3, 4, 7, 18, 56], "polit": [43, 44, 45], "poly_transform": 46, "polynomialfeatur": [40, 46], "pomegran": 45, "pool": 1, "poolarea": [37, 39, 48], "poolqc": [37, 39, 48], "poor": [17, 23, 33, 37, 40, 52, 55], "poorli": [15, 21, 31, 37, 42, 46], "pope": 44, "popul": [16, 22, 32, 33, 34, 40, 46, 55], "popular": [8, 11, 14, 15, 16, 17, 21, 22, 23, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 48, 50], "population_per_household": [16, 22, 32, 33, 55], "port": 49, "porter": 44, "porterstemm": 44, "portion": [0, 14, 16, 20, 22, 30, 32, 35, 37, 39, 48, 56], "portug": [36, 39], "pos_": [44, 50], "pos_label": 37, "posit": [13, 14, 15, 20, 21, 22, 29, 30, 31, 32, 34, 37, 38, 39, 44, 46, 47, 50], "posix": 47, "possess": 48, "possibl": [4, 5, 6, 8, 12, 13, 14, 16, 18, 19, 20, 22, 25, 27, 28, 29, 30, 32, 35, 36, 38, 39, 40, 42, 43, 44, 45, 47, 48, 52, 54, 55, 56], "possibli": [7, 44], "post": [1, 4, 6, 7, 8, 12, 17, 18, 44, 46, 49, 56], "postprocess": 45, "potenti": [11, 15, 16, 21, 22, 25, 31, 32, 41, 44, 48, 49], "powder": 44, "power": [8, 14, 20, 27, 30, 38, 43, 44, 45, 48], "pplicat": 42, "pr": 52, "practic": [0, 1, 6, 9, 12, 14, 16, 20, 22, 30, 32, 40, 45, 48, 49, 52, 55, 56], "practition": 48, "prairielearn": [1, 12, 17, 18, 56], "pre": [1, 10, 12, 18, 26, 28, 38, 40, 44, 48, 49, 50, 52], "precipit": 49, "precis": [11, 37, 48, 49, 52], "precision_lr": 36, "precision_recall_curv": 36, "precision_scor": 36, "precision_svc": 36, "precisionrecallcurvedisplai": 36, "precisionrecalldisplai": 36, "pred": [36, 37, 43, 46, 47], "pred_df": [12, 18, 28, 43], "pred_dict": [12, 18, 28], "pred_g": 43, "pred_lin_reg": 43, "pred_train": 37, "pred_x": 43, "prediciton": 47, "predict": [2, 11, 14, 15, 16, 20, 21, 22, 23, 25, 27, 30, 31, 32, 35, 36, 37, 40, 41, 42, 44, 46, 48, 49, 50, 52, 54, 55], "predict_expect": 47, "predict_for_usr": 43, "predict_proba": [36, 38, 39, 45, 51], "predict_survival_funct": 47, "predicted_categori": [36, 49], "predicted_n_rent": 46, "predicted_quiz2": [13, 19, 29], "predicted_sal": 46, "predicted_target": [12, 18, 28], "predictor": [13, 19, 29, 52], "prefer": [12, 18, 28, 38, 41, 43], "prefer_skip_nested_valid": 27, "prefix": 8, "preliminari": [16, 22, 32, 40], "prepar": [16, 22, 32, 40, 45], "prepend": 10, "preprocess": [1, 11, 14, 15, 20, 21, 25, 26, 27, 30, 31, 34, 35, 36, 38, 39, 40, 42, 43, 45, 47, 54, 55], "preprocess_featur": 46, "preprocessing_fin": 47, "preprocessing_notenur": 47, "preprocessor": [27, 33, 35, 36, 37, 38, 39, 46, 47, 48, 50, 55], "preprocessor1": 40, "preprocessor2": 40, "preprocessor3": 40, "prereq": 49, "prerequisit": [2, 47, 56], "preschool": [36, 38, 39], "presenc": [17, 23, 33, 39, 47], "present": [7, 14, 20, 26, 30, 36, 43, 44, 45, 46, 47, 48, 49, 52, 54], "preserv": [36, 41], "pressure3pm": 46, "pressure9am": 46, "pretend": [13, 14, 20, 29, 30, 46], "pretrain": [44, 45, 50], "pretti": [13, 19, 27, 29, 33, 34, 36, 38, 41, 44, 46, 47], "prevent": [35, 44, 47, 56], "previou": [12, 13, 18, 19, 25, 29, 37, 38, 41, 42, 46, 47, 48, 52], "previous": [43, 45, 46], "price": [8, 16, 19, 22, 25, 27, 32, 34, 37, 39, 40, 47, 48, 54], "primari": [8, 15, 21, 31], "primarili": [12, 13, 18, 19, 29, 39, 45, 49], "prime": [12, 18, 28], "princ": 44, "princess": 44, "principl": [9, 11, 13, 29, 52], "print": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 54], "print_top": 44, "prior": [41, 46, 52], "priorit": [40, 52], "privaci": [0, 11, 41, 49], "privat": [7, 36, 38, 39], "privileg": 6, "prize": [17, 23, 33], "pro": [41, 45, 48], "prob": [34, 38], "proba": 45, "probabilist": [2, 44], "probabl": [12, 15, 16, 18, 21, 22, 27, 28, 31, 32, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 52], "problem": [1, 4, 6, 11, 12, 17, 18, 23, 25, 27, 28, 33, 34, 36, 37, 38, 39, 41, 42, 44, 45, 47, 48, 51, 52, 54, 56], "problemat": [36, 39, 47], "probosci": [12, 18, 28, 45], "proce": [26, 56], "procedur": 38, "proceed": [14, 30], "process": [2, 5, 7, 11, 13, 15, 16, 17, 19, 21, 22, 23, 25, 26, 29, 31, 32, 33, 35, 40, 41, 42, 45, 48, 49, 50, 54], "procfil": 49, "prod": [17, 23, 33, 35], "produc": [2, 7, 19, 27, 37, 39, 42, 47, 48, 52, 54], "product": [5, 35, 43, 44, 48, 50], "prof": [36, 38, 39], "profession": [43, 49], "profil": 37, "profile_df": 43, "profilereport": 37, "profit": 48, "program": [0, 4, 9, 10, 12, 18, 28, 44, 56], "programm": 44, "progress": 41, "project": [10, 16, 22, 32, 38, 40, 45, 48, 49, 52, 56], "promin": 44, "promis": [12, 18, 25, 28, 44, 46, 49], "promot": 47, "prompt": [10, 12, 56], "pron": [44, 50], "prone": 35, "proper": [45, 53], "properli": [7, 12, 18, 47, 48], "properti": [13, 19, 29, 37, 39, 40], "prophet": 46, "propn": [44, 50], "proport": [11, 13, 14, 17, 19, 20, 23, 29, 30, 33, 34, 36, 37, 38, 39, 48], "proportional_hazard_test": 47, "prostitut": 44, "protocol": 49, "prototyp": [49, 52], "prove": 36, "provid": [0, 5, 7, 10, 11, 13, 14, 17, 19, 20, 23, 26, 29, 30, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 48, 52, 56], "provinc": [17, 23, 33, 44], "provinci": 44, "proxi": [14, 20, 30], "proxim": [34, 44, 56], "prune": 40, "psychologi": [17, 23, 33, 52], "pt": [34, 35, 45], "public": [0, 4, 7, 44, 50], "publish": [0, 1, 34, 44], "puck": 44, "pud": 37, "pull": [10, 34, 44], "punct": [44, 50], "punctuat": [17, 23, 33, 44], "punish": 48, "punkt": 50, "punkt_tab": 50, "purchas": [12, 18, 26, 28, 43, 49], "pure": [13, 19, 29, 46], "purpos": [0, 13, 14, 16, 19, 20, 22, 29, 30, 32, 43, 44, 46, 49, 52, 53, 54, 56], "pursuit": 48, "push": [7, 39], "put": [7, 8, 10, 13, 14, 16, 17, 20, 22, 23, 26, 27, 29, 30, 32, 33, 40, 41, 42, 43, 49], "px": [40, 44], "py": [13, 17, 19, 22, 23, 26, 27, 29, 30, 32, 33, 35, 38, 39, 41, 42, 47, 49, 50, 51], "pybo": 35, "pydata": 40, "pyplot": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 52, 53, 54, 55], "pysurviv": 47, "python": [1, 3, 4, 11, 28, 35, 37, 43, 44, 45, 46, 47, 48, 49, 50, 56], "python3": [9, 17, 19, 23, 26, 27, 29, 30, 33, 35, 39, 47, 51], "pythonwarn": 37, "pytorch": [12, 18, 28, 45], "pyviz": 36, "q": 1, "qualit": 27, "qualiti": [36, 39, 41, 42, 48], "quantifi": 36, "quantil": 27, "quantit": 27, "quebecoi": 27, "queen": 44, "queen_consort": 44, "queri": [16, 22, 26, 32, 36, 38, 41, 43, 44, 46, 47, 56], "query_img": 26, "query_point": [15, 21, 31], "quest": 40, "question": [1, 6, 7, 56], "queuepredictor": 49, "quick": [4, 12, 18, 44, 49, 56], "quickli": [13, 15, 16, 19, 21, 22, 29, 31, 32, 35, 42, 47, 52, 56], "quickstart": 9, "quirk": [14, 20, 30], "quit": [6, 12, 13, 16, 19, 22, 26, 28, 29, 32, 35, 36, 37, 39, 40, 42, 44, 45, 46, 47, 48, 50], "quiz": [1, 12, 16, 18, 44, 56], "quiz1": [13, 14, 17, 19, 20, 23, 29, 30, 33, 52], "quiz2": [14, 17, 20, 23, 30, 33, 52], "quizz": [13, 15, 17, 19, 29], "r": [11, 13, 17, 19, 23, 29, 33, 34, 36, 46, 48], "r1": 38, "r2": [25, 37, 38, 52, 54], "r2_score": [37, 40], "r4": 38, "race": [17, 33, 36, 38, 39, 56], "radial": [15, 21, 31], "radiu": [40, 42], "rail": 45, "rain": 46, "rain_df": 46, "rain_df_modifi": 46, "rainfal": 46, "rainfall_lag1": 46, "rainfall_lag2": 46, "rainfall_lag3": 46, "raintodai": 46, "raintoday_miss": 46, "raintoday_no": 46, "raintoday_y": 46, "raintomorrow": 46, "rais": [6, 17, 18, 23, 27, 33, 36, 46, 47], "rand": [8, 38], "randint": 35, "randn": [34, 40], "random": [6, 8, 11, 14, 15, 20, 21, 26, 30, 31, 34, 36, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52], "random_forest_data": 38, "random_search": 35, "random_st": [12, 15, 16, 18, 21, 22, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55], "randomforestclassifi": [39, 40, 46, 48], "randomforestclassifierrandomforestclassifi": 38, "randomforestregressor": [37, 38, 39, 40, 46, 47, 48, 49], "randomhorizontalflip": 45, "randomizedsearchcv": [15, 21, 31, 38, 39, 48], "randomizedsearchcvifittedrandomizedsearchcv": 35, "randomli": [14, 20, 30, 34, 35, 36, 38, 47], "randomoversampl": 36, "randomresizedcrop": 45, "randomst": [40, 42], "randomundersampl": 36, "rang": [4, 8, 11, 14, 15, 16, 17, 20, 21, 22, 23, 27, 30, 31, 32, 33, 34, 38, 41, 43, 44, 45, 46, 47, 48, 50], "rangeindex": [17, 23, 33, 40, 46, 47], "rank": [36, 40, 43, 44, 47], "rank_test_mape_scor": 37, "rank_test_neg_mean_squared_error": 37, "rank_test_scor": [35, 37], "ranking_": 40, "rare": [17, 33, 36, 37, 41, 44, 52], "rate": [12, 18, 28, 34, 36, 38, 41, 47, 48, 52], "rated_item": 43, "rather": [12, 17, 18, 23, 27, 28, 33, 35, 36, 37, 38, 39, 41, 44, 45, 56], "ratings_df": 43, "ratio": [36, 38, 44, 47], "ravel": [26, 36, 52], "raw": [8, 17, 23, 33, 36, 39, 40, 44, 45, 48, 51], "raw_model_output": 34, "raw_scor": 39, "rbf": [1, 14, 16, 20, 22, 30, 32, 34, 35, 38, 39, 40, 48, 49, 52, 54], "rcparam": [12, 13, 14, 18, 19, 20, 28, 29, 30, 36, 41, 42, 43, 45, 46, 47, 48, 53], "re": [4, 7, 8, 10, 12, 13, 14, 17, 18, 19, 20, 23, 28, 29, 30, 33, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 47, 49, 52, 53], "reach": [1, 6, 41, 56], "read": [1, 4, 7, 12, 15, 16, 17, 18, 21, 22, 23, 26, 31, 32, 33, 36, 37, 38, 39, 44, 46, 48, 49], "read_csv": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 46, 47, 48, 49, 50, 52, 53, 54, 55], "read_excel": 8, "read_html": 8, "read_img_dataset": 26, "read_json": 8, "readabl": [0, 8], "reader": 11, "readi": [7, 12, 14, 15, 16, 20, 21, 22, 30, 31, 32, 34], "readlin": 45, "readm": 47, "readthedoc": 47, "real": [14, 15, 16, 17, 19, 20, 21, 22, 23, 27, 30, 31, 32, 33, 34, 36, 39, 41, 42, 43, 44, 45, 48, 50, 52], "realdonaldtrump": 50, "realist": [16, 22, 32, 46, 49], "realiti": [14, 20, 30, 37, 47], "realiz": 48, "realli": [8, 14, 20, 30, 34, 35, 38, 40, 42, 43, 45, 46, 47, 49], "reason": [0, 2, 4, 8, 11, 14, 16, 20, 22, 30, 32, 35, 36, 37, 39, 41, 43, 44, 46, 47, 48, 49, 52, 56], "rec": [37, 39, 48], "recal": [11, 13, 14, 15, 16, 17, 20, 22, 23, 27, 29, 30, 31, 32, 33, 34, 37, 41, 46, 49, 52], "recall_lr": 36, "recall_scor": 36, "recall_svc": 36, "receiv": [6, 7, 17, 18, 23, 33, 42, 45, 46, 49], "recent": [8, 10, 12, 17, 18, 23, 27, 28, 33, 40, 43, 44, 46, 47], "recip": [14, 20, 30], "recogn": [11, 14, 20, 30, 42, 46, 48, 56], "recognit": [12, 13, 15, 18, 28, 29, 31, 36, 44, 56], "recommend": [1, 2, 4, 8, 10, 11, 14, 15, 20, 26, 28, 30, 31, 35, 36, 41, 44, 45, 48, 49], "record": [13, 19, 29, 47], "rectangular": 41, "recurr": 46, "recurs": 11, "red": [13, 15, 19, 21, 29, 31, 36, 39, 40, 41, 46], "redbon": 35, "redefin": 47, "redistribut": 0, "reduc": [7, 8, 12, 15, 18, 21, 28, 31, 35, 36, 37, 38, 39, 40, 43, 44, 45, 51, 54, 56], "reduct": [2, 36, 38, 40, 41], "redund": [34, 39], "ref": [36, 47], "refer": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 29, 30, 31, 32, 33, 34, 36, 39, 41, 43, 44, 45, 54, 56], "referenc": 56, "referenti": 44, "refin": [15, 21, 26, 31, 54], "refit": 37, "reflect": [15, 21, 31, 37, 39, 44, 54, 56], "reflection_period": [36, 49], "reg": [13, 19, 29, 38], "reg_model": [13, 19, 29], "regard": 56, "regardless": 7, "regex": 44, "regim": 49, "region": [13, 19, 29, 36, 42, 46, 49, 51], "region_data": 46, "regist": [12, 18, 49, 56], "registered_nurs": 44, "regrad": [6, 18], "regress": [1, 2, 11, 12, 16, 17, 18, 22, 23, 25, 28, 32, 33, 39, 40, 43, 46, 47, 48, 49, 50, 51, 52, 54], "regression_df": [13, 19, 29], "regressor": [13, 16, 17, 19, 22, 23, 25, 27, 29, 32, 33, 37, 46], "regular": [15, 17, 21, 23, 31, 33, 34, 38, 44, 46, 47, 48, 52], "regulatori": 39, "reinforc": [12, 18, 28, 41], "reject": 36, "rel": [20, 27, 34, 39, 42, 44, 50, 51], "rel_char_len": 50, "relabel": 41, "relat": [2, 6, 10, 12, 18, 28, 34, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 50, 56], "relationship": [11, 36, 38, 39, 40, 44, 46, 48, 50, 52, 53, 54, 56], "relationship_husband": 39, "relationship_own": 39, "releas": [1, 7, 14, 15, 16, 17], "relev": [1, 4, 8, 11, 13, 15, 16, 19, 21, 22, 29, 31, 32, 35, 39, 46, 56], "reli": [14, 15, 20, 21, 26, 30, 31, 40, 42, 43, 46, 54], "reliabl": [12, 18, 20, 28, 41], "religi": 44, "remain": [5, 37, 40, 43, 46, 48], "remaind": 6, "rememb": [7, 15, 17, 18, 21, 23, 31, 33, 35, 36, 39, 40, 42, 45, 46, 47, 53, 54], "remind": 53, "remix": 0, "remov": [7, 16, 22, 26, 32, 36, 38, 39, 40, 44, 45, 47, 51], "renam": [12, 18, 28, 36, 39, 46, 49], "render": [4, 7, 12, 16, 17, 18, 22, 23, 25, 26, 27, 28, 32, 33, 35, 36, 37, 38, 39, 40, 41, 44, 45, 48, 50], "rent": 46, "rental": [46, 49], "rentals_df": 46, "rentals_lag5": 46, "rentals_lag5_i": 46, "rentals_lag5_x": 46, "rentals_model": 46, "repair": [36, 38, 39], "repeat": [8, 40, 41, 42, 45, 49], "repeatedli": 6, "rephras": 48, "replac": [12, 16, 18, 22, 27, 28, 32, 36, 38, 39, 43, 47], "replic": 49, "repo": [1, 36, 49], "report": [6, 13, 19, 29, 35, 37, 40, 46, 50], "repositori": [0, 1, 5, 10, 12, 18, 26, 27, 34, 36, 49, 56], "repres": [13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 29, 30, 31, 32, 33, 34, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52], "represent": [12, 13, 16, 18, 19, 22, 25, 26, 27, 28, 29, 32, 35, 36, 37, 38, 39, 40, 41, 42, 44, 48, 49, 50, 52], "reproduc": [4, 14, 20, 30, 35, 38, 49, 56], "republ": 39, "request": [6, 18, 44, 56], "requir": [5, 7, 15, 16, 21, 22, 26, 27, 31, 32, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 52, 54, 56], "rerun": [12, 16, 17, 18, 22, 23, 25, 26, 27, 28, 32, 33, 35, 36, 37, 38, 39, 40, 45, 48, 50], "res_mean": [14, 20, 30], "resampl": 36, "research": [12, 14, 18, 20, 28, 30, 35, 43, 44, 49], "reserv": [46, 56], "reset": 27, "reset_index": [12, 18, 28], "reshap": [8, 27, 34, 35, 45, 46], "resid": 34, "residu": 38, "resiz": [26, 45], "resnet": 45, "resolut": 44, "resolv": 56, "resort": 34, "resourc": [1, 3, 5, 29, 38, 39, 44, 45, 49, 52], "respect": [34, 35, 36, 38, 39], "respons": [4, 7, 13, 19, 29, 41, 44, 48, 56], "rest": [34, 35, 45, 47, 49, 52], "restart": [7, 10], "restaur": [27, 43, 49], "restaurant_df": 27, "restaurant_nam": 27, "restrict": [0, 37, 38, 44], "resubmit": 18, "result": [1, 2, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 49, 50, 54, 56], "result_block": 47, "result_img": 45, "results_df": [14, 15, 20, 21, 25, 26, 30, 31, 34, 54], "results_dict": [14, 15, 16, 20, 21, 22, 26, 30, 31, 32, 33, 35], "results_single_valid_df": [25, 54], "retail": [50, 52], "retail_df": 46, "retail_df_test": 46, "retail_df_train": 46, "retail_lag_5": 46, "retail_model": 46, "retail_test_5": 46, "retail_test_5_pr": 46, "retail_train_5": 46, "retail_train_5_d": 46, "retail_train_5_i": 46, "retail_train_5_x": 46, "retent": 47, "retrain": [35, 49], "return": [5, 8, 10, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 26, 27, 29, 30, 31, 32, 33, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 54], "return_gener": [17, 23, 33], "return_predict": 49, "return_train_scor": [14, 15, 16, 17, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 47, 50, 54], "reus": [36, 56], "revenu": 43, "revers": [17, 23, 33, 37], "review": [1, 4, 34, 41, 48, 50, 52, 56], "revisit": [36, 52], "revok": 0, "reward": [12, 17, 18, 23, 28, 33, 41], "rf": [46, 47], "rf_imp_df": 39, "rfe_cv": 40, "rfe_pip": 40, "rfecv": 40, "rgb": [12, 18, 28], "rhode_island": 44, "rich": [39, 44, 47, 48, 52], "richard": 48, "rico": 39, "rid": [10, 17, 23, 27, 33, 38, 39, 44, 47], "ridg": [39, 40, 43, 46, 47, 48, 49], "ridge__alpha": 37, "ridge_pr": 37, "ridge_tun": 37, "ridgecv": 40, "ridgecv_pip": 37, "ridgeridg": [37, 40], "right": [0, 1, 11, 12, 18, 25, 27, 28, 34, 35, 36, 37, 40, 41, 42, 43, 44, 48, 49, 52], "rightarrow": [13, 15, 21, 29, 31, 34, 36, 37, 38, 41, 42, 43, 44, 48, 49, 52], "rindfleischetikettierungs\u00fcberwachungsaufgaben\u00fcbertragungsgesetz": 44, "rise": [40, 44], "risk": [1, 36, 40, 48, 54], "riti": [18, 19, 20, 21, 22, 23, 56], "river": 34, "rl": [37, 39, 48], "rmse": [43, 52], "rng": [40, 42], "rnn": 46, "ro": 36, "roast": 41, "robot": [43, 44], "robust": [12, 14, 15, 16, 18, 20, 21, 22, 27, 28, 30, 31, 32, 35, 38, 42, 54], "robustscal": 27, "roc": [11, 49, 52], "roc_auc": 36, "roc_auc_scor": 36, "roc_curv": 36, "roc_lr": 36, "roc_svc": 36, "roccurvedisplai": 36, "rodolfo": 35, "rodr\u00edguez": 44, "roger": 40, "role": [34, 35, 39, 45], "roman": 43, "romanc": 43, "romant": 43, "ronald": 34, "roof": 39, "roofmatl": [37, 39, 48], "roofmatl_clytil": [37, 39], "roofmatl_compshg": [37, 39], "roofmatl_membran": 37, "roofmatl_met": 37, "roofmatl_rol": 37, "roofmatl_tar": 37, "roofmatl_wdshak": 37, "roofmatl_wdshngl": [37, 39], "roofstyl": [37, 39, 48], "roofstyle_flat": 37, "roofstyle_g": 37, "roofstyle_gambrel": 37, "roofstyle_hip": 37, "roofstyle_mansard": 37, "roofstyle_sh": 37, "room": [12, 13, 18, 19, 28, 29, 34, 37, 40, 49, 50, 56], "rooms_per_household": [16, 22, 32, 33, 40, 55], "rooms_per_household_0": 40, "rooms_per_household_1": 40, "rooms_per_household_10": 40, "rooms_per_household_11": 40, "rooms_per_household_12": 40, "rooms_per_household_13": 40, "rooms_per_household_14": 40, "rooms_per_household_15": 40, "rooms_per_household_16": 40, "rooms_per_household_17": 40, "rooms_per_household_18": 40, "rooms_per_household_19": 40, "rooms_per_household_2": 40, "rooms_per_household_3": 40, "rooms_per_household_4": 40, "rooms_per_household_5": 40, "rooms_per_household_6": 40, "rooms_per_household_7": 40, "rooms_per_household_8": 40, "rooms_per_household_9": 40, "root": [10, 13, 15, 19, 21, 26, 29, 31, 43, 45, 52], "rose": 44, "rostin": [1, 56], "rotat": 46, "roth": [1, 56], "rough": 4, "roughli": [5, 14, 30, 44, 49, 52], "round": [8, 15, 16, 21, 22, 26, 31, 32, 35, 36, 38, 42, 45, 54], "rout": [5, 13, 19, 29, 46], "row": [13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 56], "rry": 44, "rsh": 35, "ru": [8, 36], "rubric": [18, 34], "rule": [1, 8, 12, 13, 15, 18, 19, 25, 28, 29, 31, 34, 36, 38, 44, 49, 52, 54], "run": [1, 4, 5, 7, 10, 12, 14, 15, 17, 18, 20, 23, 26, 28, 30, 31, 33, 35, 36, 37, 39, 41, 42, 44, 45, 49, 50, 51, 53, 54], "runtimewarn": 35, "ruscorpora": 44, "rush": 40, "russel": 1, "rv": 35, "rv_continuous_frozen": 35, "rv_discrete_frozen": 35, "rvert_2": 44, "s1": [8, 44], "s19": [16, 22, 32], "s2": [8, 44], "s_lag": 46, "sa": 1, "sabr": 44, "sabrina": 1, "sadli": 44, "safe": [16, 22, 32], "safeti": 45, "sai": [8, 13, 15, 16, 17, 19, 21, 22, 23, 29, 31, 32, 33, 36, 37, 38, 39, 44, 46, 48, 52], "said": [14, 16, 20, 22, 30, 32, 34, 39, 42, 43, 44, 48], "sal": [37, 39, 48], "sale": [8, 25, 36, 37, 46, 48, 54], "salecondit": [37, 39, 48], "salecondition_abnorml": 37, "salecondition_adjland": 37, "salecondition_alloca": 37, "salecondition_famili": 37, "salecondition_norm": 37, "salecondition_parti": 37, "salepric": [37, 39, 48], "sales_data": 46, "salesforc": 50, "saleswoman": 44, "saletyp": [37, 39, 48], "saletype_cod": 37, "saletype_con": 37, "saletype_conld": 37, "saletype_conli": 37, "saletype_conlw": 37, "saletype_cwd": 37, "saletype_new": 37, "saletype_oth": 37, "saletype_wd": 37, "salt": [34, 39], "sam": 43, "same": [6, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54], "samosa": 44, "sampl": [12, 13, 15, 16, 19, 20, 21, 22, 26, 27, 29, 31, 32, 34, 35, 39, 42, 45, 46, 47, 48, 49, 53, 54], "sample_df": [36, 49], "sample_text": 50, "sampling_strategi": 36, "samuel": [12, 18, 28], "sand": 45, "sandbar": 45, "saniti": [13, 19, 29, 47], "sarah": 1, "sat": 46, "satisfactori": 41, "satisfi": 41, "satur": 48, "saturdai": 46, "sauc": 27, "save": [7, 8, 17, 23, 33, 35, 39, 44, 45, 46, 48, 50, 55], "saw": [16, 22, 32, 34, 35, 36, 42, 52], "sb": 40, "scalabl": [12, 18, 28, 42], "scalar": 8, "scale": [14, 15, 17, 20, 21, 23, 25, 26, 30, 31, 33, 35, 36, 37, 38, 40, 42, 45, 47, 48, 49, 52, 54, 55], "scale_pos_weight": 38, "scaler": [16, 22, 27, 32, 39, 40], "scan": 52, "scari": 49, "scatter": [16, 22, 32, 37, 39, 40], "scatter_3d": 40, "scatterplot": [40, 49], "scc": 44, "scenario": [11, 14, 17, 20, 23, 30, 33, 38, 39, 40, 42, 46, 47, 49, 52], "schafer": 49, "schedul": [47, 52, 56], "schmidt": 35, "school": [12, 18, 28, 36, 38, 39, 43], "schoolteach": 44, "scienc": [1, 2, 9, 10, 11, 17, 23, 33, 41, 46, 48, 52, 54], "scientif": [43, 44], "scientist": [1, 9, 42], "scikit": [9, 10, 11, 13, 15, 19, 21, 27, 29, 31, 34, 35, 36, 38, 41, 42, 45, 46, 48, 50, 51], "scipi": [10, 35, 42, 44], "scm": 5, "scope": [12, 18, 44, 46], "score": [11, 12, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 31, 32, 33, 38, 39, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 56], "score_func": 37, "score_gb_test": 48, "score_gb_train": 48, "score_lr_print_coeff": 46, "score_param": [17, 23, 33], "score_rf_test": 48, "score_rf_train": 48, "score_tim": [14, 15, 16, 17, 20, 21, 22, 23, 26, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 47, 50], "scorer": [17, 23, 33, 37], "scores_dict": 34, "scores_imag": 34, "scoring_method": 47, "scoring_metr": [38, 39, 50], "scotland": 44, "scott": 48, "scratch": [2, 45, 49], "screen": 7, "screennam": 50, "screenplai": 44, "screenporch": [37, 39, 48], "screenshot": 48, "script": 10, "scroog": 50, "sdng": [37, 48], "se": [46, 47], "sea": 45, "seaborn": [39, 40, 41, 42, 43], "seacoast": 45, "search": [4, 5, 10, 37, 44, 52], "search_multi": 37, "seashor": 45, "season_autumn": 46, "season_fal": 46, "season_summ": 46, "season_wint": 46, "seat": [45, 56], "seattl": 50, "seawal": 45, "second": [4, 6, 13, 18, 19, 29, 34, 38, 39, 42, 45, 46, 48], "secondari": [12, 18, 28], "secpompeo": 50, "section": [1, 7, 10, 14, 19, 29, 30, 40, 56], "secur": [39, 49, 56], "see": [1, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 48, 49, 52, 53, 54, 56], "seed": [26, 34, 35, 41, 42, 49], "seem": [13, 15, 16, 17, 19, 21, 22, 23, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 46, 47, 50, 51, 54], "seemingli": 36, "seen": [8, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 28, 30, 31, 32, 33, 34, 40, 42, 43, 47, 52, 54], "segment": [11, 36, 44, 45, 47, 49, 52], "segmentspher": 49, "select": [1, 5, 6, 10, 11, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38, 45, 46, 47, 48, 49], "select_dtyp": 37, "select_knn": 40, "select_rf": 40, "select_svc": 40, "selectfrommodel": 40, "self": [12, 17, 18, 23, 27, 28, 33, 47, 56], "sell": [0, 8, 13, 19, 29, 48], "semant": [11, 41, 42, 44], "semest": [12, 18, 56], "semi": [1, 12, 44], "semicolon": 8, "semilogx": 37, "send": [4, 12, 18, 28], "senior": 47, "seniorcitizen": 47, "sens": [6, 14, 17, 20, 23, 30, 33, 34, 36, 37, 39, 40, 41, 43, 44, 46, 47, 49, 51], "sensibl": [7, 49], "sensit": [14, 16, 20, 22, 30, 32, 35, 36, 37, 41, 47], "sent": [12, 18, 28, 44], "sent_token": 44, "sentenc": [44, 48], "sentiment": [13, 29, 34, 44, 50], "sentimentintensityanalyz": 50, "sepal": [15, 21, 26, 31, 54], "separ": [13, 14, 16, 17, 19, 20, 22, 23, 27, 29, 30, 32, 33, 34, 36, 40, 41, 43, 44, 46, 51, 52, 53, 54, 55], "septemb": 46, "sequenc": [14, 17, 20, 23, 30, 33, 45, 46], "sequenti": [13, 19, 29, 38, 46, 47, 52], "sequentialfeatureselector": 40, "ser": [22, 30, 32, 47, 50], "seri": [1, 2, 11, 14, 16, 17, 20, 22, 23, 30, 32, 33, 36, 40, 45, 47, 49, 50], "serial": 38, "seriou": [6, 36, 43, 44, 47, 49, 56], "serv": [5, 11, 13, 19, 29, 39, 56], "server": 5, "servic": [27, 38, 39, 43, 47, 50], "session": [12, 13, 41, 52, 56], "set": [1, 7, 8, 9, 13, 15, 16, 17, 19, 21, 22, 23, 26, 28, 29, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 54, 55], "set_config": [35, 38], "set_index": [14, 15, 20, 21, 26, 30, 31, 35, 36, 37], "set_opt": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 42, 43, 53, 54, 55], "set_properti": [12, 18, 28], "set_se": 26, "set_titl": [15, 21, 26, 31, 34, 36, 45, 54], "set_xlabel": [15, 21, 26, 31, 34, 41, 54], "set_ylabel": [15, 21, 26, 31, 34, 41, 54], "setup": [3, 7, 10, 12, 18, 53], "sev": [37, 39, 48], "sever": [10, 16, 22, 32, 34, 41, 42, 44, 45, 46, 51, 56], "sex": [36, 38, 39, 40], "sexual": 56, "sfu": 44, "shall": [0, 44], "shallow": 38, "shan": 44, "shap": 49, "shape": [13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54], "shape_df": [14, 20, 30], "shape_dict": [14, 20, 30], "share": [0, 27, 40, 49, 56], "sharealik": 1, "sharex": [16, 22, 32], "she": [12, 18, 28, 43, 44, 50], "shed": [37, 39, 48], "sheet": [9, 49, 52], "shelf": [38, 44], "shell": [5, 9, 12, 18], "shelv": 50, "shift": 46, "shipyard": 27, "shit": 50, "shng": [37, 48], "shop": 43, "short": [1, 10, 14, 30, 35, 38, 44, 56], "shorter": 47, "shorthand": [16, 22, 32], "shortli": 49, "shot": 40, "should": [5, 7, 8, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 39, 40, 41, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56], "shouldn": [36, 38, 44, 54], "show": [4, 7, 10, 12, 14, 16, 17, 18, 20, 22, 23, 25, 26, 27, 28, 30, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 49, 50, 52, 54], "show_nearest_neighbor": 26, "show_plot": 47, "showcas": 44, "shown": [7, 10, 12, 13, 15, 18, 19, 21, 28, 29, 31, 36, 38, 41, 42, 46, 48], "shrink": [35, 40, 48], "shuffl": [14, 20, 26, 30, 45, 46], "si": [12, 18, 28], "sibl": 40, "sick": [41, 50], "sid": 50, "side": [6, 45, 48], "sift": 43, "sigma": 45, "sign": [4, 37, 39, 45, 54, 56], "signal": [14, 20, 30, 44], "signific": [11, 16, 22, 27, 32, 45, 48], "significantli": [17, 23, 33, 36, 43], "sigoptsearchcv": 35, "silhouett": 42, "silhouettevisu": [41, 42], "sim": 39, "sim_word": 44, "simard": 39, "similar": [1, 10, 13, 14, 17, 18, 19, 20, 23, 26, 29, 30, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 47, 48, 51], "similarity_": 44, "similarli": [39, 41, 47], "simon_fras": 44, "simp": 46, "simpl": [1, 13, 15, 16, 19, 21, 22, 29, 31, 32, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 52, 53], "simplefilt": [38, 39], "simpleimput": [16, 17, 22, 23, 32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 47, 48, 52, 55], "simpleimputersimpleimput": [16, 17, 22, 23, 32, 33, 37, 38, 40, 48], "simpler": [25, 34, 35, 49, 54], "simplest": [17, 23, 33], "simpli": [16, 22, 32, 40, 41, 44], "simplic": [13, 17, 19, 23, 29, 33, 43], "simplist": [15, 21, 26, 31, 39, 54], "simul": 40, "sin": 8, "sinc": [5, 12, 18, 26, 34, 37, 39, 40, 41, 43, 45, 46, 47, 48, 51, 52, 53], "singer_songwriter_bob_dylan": 44, "singl": [8, 15, 16, 21, 22, 26, 31, 32, 34, 35, 36, 38, 39, 42, 46, 47, 52, 53, 54], "sit": 56, "sitarist_ravi_shankar": 44, "site": [5, 12, 17, 19, 23, 26, 27, 29, 30, 33, 35, 39, 47, 51, 56], "situat": [6, 12, 18, 28, 36, 38, 41, 45, 47, 56], "six": [14, 30, 38, 46, 49], "size": [12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 26, 28, 29, 30, 31, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 56], "skeleton": 48, "skeptic": 48, "skew": 37, "skill": [11, 38, 49], "skin": 50, "skip_check_arrai": 27, "skip_parameter_valid": 27, "skipna": 47, "sklearn": [1, 12, 14, 15, 18, 20, 21, 25, 26, 28, 30, 31, 34, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "sklearn_gb": 38, "sklearn_histgb": 38, "sktime": 46, "skyblu": 46, "skyscrap": 46, "sl": 44, "slice": 8, "slide": [1, 9, 16, 22, 24, 32, 45, 56], "slightli": [17, 23, 26, 27, 33, 34, 36, 38, 47], "slipper": 48, "slope": 34, "sloppi": [16, 22, 32], "slot": 56, "slow": [15, 21, 31, 38, 40, 45], "slower": [38, 41], "sm": [12, 17, 18, 23, 28, 33], "smac": 35, "small": [10, 14, 15, 17, 20, 21, 23, 26, 27, 30, 31, 33, 35, 37, 38, 39, 40, 41, 43, 45, 47, 52, 54], "small_citi": [15, 21, 31], "small_train_df": [15, 21, 31], "smallalpha_coeff": 37, "smaller": [15, 16, 17, 21, 22, 23, 25, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 54], "smallest": [34, 37, 41, 42], "smart": [41, 48, 50], "smile": 50, "smooth": [15, 21, 31, 54], "smoothli": 10, "smote_pip": 36, "sms_df": [12, 18, 28], "sn": [39, 41, 42], "snake": [34, 45], "snake_length": 34, "snakes_df": 34, "snbf": 38, "snippet": [7, 12, 18], "snow": [12, 18, 28, 45], "snp": 40, "so": [0, 1, 4, 5, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56], "social": [41, 42, 43, 46], "societ": 11, "societi": [36, 44], "sofist": 54, "soft": [27, 34, 38], "softmax": 52, "softwar": [1, 5, 10, 47], "solar": 43, "sold": [8, 37], "sole": [36, 42], "solidifi": 52, "solut": [12, 14, 18, 19, 20, 28, 29, 30, 38, 41, 47, 48, 49, 52, 56], "solv": [4, 12, 13, 15, 18, 19, 20, 21, 28, 29, 31, 40, 44, 48, 49, 54, 56], "solver": 36, "some": [4, 6, 7, 8, 10, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56], "someon": [12, 13, 14, 18, 19, 20, 28, 29, 30, 40, 47, 48], "someth": [4, 7, 10, 13, 17, 19, 23, 29, 33, 36, 37, 38, 39, 41, 46, 47, 48, 49, 52, 56], "sometim": [6, 13, 14, 17, 19, 20, 23, 29, 30, 33, 34, 35, 38, 39, 44, 48, 49], "somewhat": 37, "somewher": [12, 18, 28, 37], "song": [15, 16, 22, 31, 32, 43, 50], "song_titl": [15, 16, 22, 31, 32, 35], "soon": [12, 15, 16, 18, 21, 22, 28, 31, 32, 46, 49], "sopha": [12, 18, 28], "sophist": [35, 39, 44], "sort": [1, 5, 13, 14, 16, 20, 22, 29, 30, 32, 39, 43, 44, 45, 46, 49], "sort_index": [8, 35, 37, 46], "sort_valu": [16, 17, 22, 23, 25, 32, 33, 34, 35, 37, 38, 39, 40, 46, 47, 50], "sound": [39, 40], "soundtrack": 44, "sourc": [10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 27, 28, 29, 30, 31, 32, 33, 35, 38, 39, 40, 41, 42, 43, 44, 45, 50, 53, 56], "south": [17, 33], "space": [15, 19, 21, 31, 34, 35, 40, 41, 42, 44, 50, 56], "spaci": 40, "spacymoji": 50, "spam": [14, 20, 30, 36, 41], "spam_predict": [12, 18, 28], "span": [44, 46], "spanish": [16, 22, 32], "spars": [12, 15, 18, 21, 27, 31, 34, 38, 43, 44, 52], "sparse_output": [16, 17, 22, 23, 27, 32, 33, 36, 37, 38, 39, 46, 47, 48, 52], "spatial": 34, "speak": [5, 49], "spearmint": 35, "speci": [15, 21, 26, 31, 52, 54], "special": [11, 12, 17, 18, 23, 28, 33, 43, 44, 45, 46, 47, 54], "specialti": [36, 38, 39], "specif": [8, 11, 13, 14, 19, 20, 27, 29, 30, 35, 36, 39, 41, 43, 44, 45, 46, 47, 48, 49, 52, 54], "specifi": [8, 13, 14, 17, 19, 20, 23, 26, 29, 30, 33, 35, 36, 41, 42, 45, 48, 49], "spectrogram": 40, "speech": [40, 44, 50], "speechi": [15, 16, 22, 31, 32, 35], "speed": [8, 13, 19, 29, 38, 45, 49], "spell": [12, 18, 28], "spend": [12, 16, 18, 22, 27, 28, 32, 40, 48, 50, 56], "spent": [6, 16, 22, 32, 40], "spheric": [42, 52], "spici": 41, "spini": 45, "spit": 45, "split": [11, 13, 15, 17, 19, 21, 23, 29, 31, 33, 34, 35, 37, 38, 40, 43, 44, 47, 49, 50, 52], "split0_test_r2": 37, "split0_test_scor": 35, "split0_train_neg_mean_squared_error": 37, "split0_train_scor": 35, "split1_test_r2": 37, "split1_test_scor": 35, "split1_train_neg_mean_squared_error": 37, "split1_train_scor": 35, "split2_test_r2": 37, "split2_test_scor": 35, "split2_train_neg_mean_squared_error": 37, "split2_train_scor": 35, "split3_test_r2": 37, "split3_test_scor": 35, "split3_train_neg_mean_squared_error": 37, "split3_train_scor": 35, "split4_test_scor": 35, "split4_train_neg_mean_squared_error": 37, "split4_train_scor": 35, "spoken": [17, 23, 33], "sport": [44, 45, 46], "spot": [36, 37, 49, 54], "spotifi": [15, 31, 43], "spotify_df": [15, 16, 22, 31, 32, 35], "spotlight": [5, 10], "spous": [36, 38, 39], "spread": 42, "spring_month": 46, "sqft": 39, "sqft_abov": [12, 13, 18, 25, 28, 29], "sqft_basement": [12, 13, 18, 25, 28, 29], "sqft_live": [12, 13, 18, 25, 28, 29], "sqft_living15": [12, 13, 18, 25, 28, 29], "sqft_lot": [12, 13, 18, 25, 28, 29], "sqft_lot15": [12, 13, 18, 25, 28, 29], "sqrt": [15, 21, 31, 37, 39, 43, 44], "squar": [8, 11, 13, 15, 19, 21, 29, 31, 34, 39, 43, 47, 48, 50, 52], "squash": [34, 45], "squeez": [8, 47], "src": [20, 30, 36], "sse": 46, "ssw": 46, "st": [46, 50], "stabil": 10, "stabl": [14, 20, 27, 30, 36, 38, 54], "stack": [7, 11, 27, 49, 52], "stacking_model": 38, "stacking_model_tre": 38, "stackingclassifi": 38, "stackingregressor": 38, "staff": 6, "stai": [12, 18, 36, 47], "stakehold": [11, 48, 49], "stale": 41, "stand": [15, 21, 31, 35, 44, 49], "standard": [4, 6, 14, 16, 20, 22, 30, 32, 35, 38, 39, 40, 44, 49], "standardscal": [17, 23, 27, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 50, 52, 55], "standardscalerstandardscal": [16, 17, 22, 23, 32, 33, 35, 36, 37, 38, 40, 45, 48, 50], "stanford": 44, "star": [15, 21, 31, 41, 43, 50], "start": [7, 8, 10, 13, 14, 15, 19, 20, 21, 26, 27, 29, 30, 31, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55], "startswith": 39, "starttim": 46, "stat": [35, 47], "state": [6, 8, 14, 20, 30, 36, 38, 39, 43, 44, 49, 50], "statement": [7, 14, 15, 16, 17, 19, 20, 21, 22, 23, 30, 31, 32, 33, 34, 35, 36, 37, 40, 45, 47, 48], "static": [12, 18, 49], "station": 46, "statist": [1, 9, 11, 13, 19, 29, 34, 39, 43, 44, 47], "statistician": [15, 21, 31], "statlib": 34, "statsmodel": [46, 47], "statu": [36, 38, 39], "status_marri": 39, "status_nev": 39, "std": [14, 15, 16, 20, 21, 22, 25, 26, 27, 30, 31, 32, 36, 37, 45, 46, 50, 51], "std_cv_error": [14, 20, 30], "std_cv_score": [15, 21, 26, 31], "std_fit_tim": [35, 37], "std_score": [14, 16, 20, 22, 30, 32, 50], "std_score_tim": [35, 37], "std_test_neg_mean_squared_error": 37, "std_test_scor": [14, 20, 30, 35], "std_train_error": [14, 20, 30], "std_train_neg_mean_squared_error": 37, "std_train_scor": [14, 15, 20, 21, 26, 30, 31, 35], "stdki": 47, "stem": 44, "step": [7, 12, 14, 15, 16, 17, 20, 21, 22, 23, 26, 28, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56], "stereotyp": 44, "stick": [13, 46], "still": [4, 10, 19, 35, 36, 37, 38, 40, 41, 46, 47, 50, 54, 55], "stipul": 48, "stochast": [40, 41], "stock": [12, 18, 28, 46], "stop": [8, 25, 27, 41, 44, 45, 47, 54], "stop_word": [35, 36, 44, 49, 50], "stopword": 44, "storag": [15, 31], "store": [7, 8, 15, 16, 17, 21, 22, 23, 31, 32, 33, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 49, 50], "stori": [37, 38, 50], "storylin": 44, "str": [26, 35, 39, 44, 46, 47, 50], "straight": [47, 49], "straightforward": 39, "strain": 7, "strang": [39, 47], "strata": 47, "strategi": [13, 15, 16, 17, 19, 21, 22, 23, 27, 29, 31, 32, 33, 36, 37, 39, 41, 43, 46, 47, 48, 49, 52, 53], "stratif": 47, "stratifi": 47, "stratifiedkfold": [14, 20, 30, 36], "stream": 47, "streamingmovi": 47, "streamingmovies_no": 47, "streamingmovies_y": 47, "streamingtv": 47, "streamingtv_no": 47, "streamingtv_y": 47, "street": [37, 39, 48], "street_grvl": 37, "street_pav": 37, "strength": [44, 52], "stress": 41, "strftime": [46, 47], "string": [8, 10, 15, 21, 27, 31, 36, 37, 38, 39, 44, 46, 47, 54], "strip": [39, 45], "strong": [38, 47, 52], "stronger": 38, "strongli": 38, "structur": [8, 41, 44, 45], "struggl": [41, 46], "stuart": [1, 38], "stuck": [4, 8], "student": [1, 4, 5, 6, 7, 11, 12, 13, 18, 19, 28, 29, 34, 36, 37, 39, 40, 41, 42, 43, 45, 49, 50, 56], "studi": [12, 17, 18, 23, 28, 33, 40, 44, 47], "stuff": [15, 21, 26, 31, 45, 47], "stump": [13, 14, 15, 19, 20, 21, 25, 29, 30, 31, 38, 53], "stupid": 50, "style": [28, 37, 40, 41, 43, 44, 45, 49, 50], "sub": [35, 41, 44, 47, 49, 52], "subdirectori": [39, 49], "subgroup": 47, "subject": [0, 1, 47, 56], "sublicens": 0, "submiss": [3, 56], "submit": [1, 8, 16, 18, 49, 56], "subplot": [14, 15, 20, 21, 26, 30, 31, 34, 36, 41, 45, 47, 48, 54], "subplot_kw": [14, 20, 26, 30], "subprocess": 37, "subscrib": 47, "subscript": [46, 47], "subset": [13, 14, 19, 20, 26, 29, 30, 35, 38, 45, 46, 51, 54], "substanti": 0, "substitut": 0, "subtl": 44, "subtleti": [14, 20, 30, 37], "subtract": [15, 18, 21, 31, 36, 39], "suburb": 50, "subword": 44, "succe": [40, 56], "success": [5, 8, 10, 12, 18, 28, 36, 38, 43, 44, 45, 46, 49], "successfulli": [10, 12, 18, 28, 50], "sudo": 5, "suei": 35, "suffer": 35, "suffici": [7, 44], "suggest": [0, 1, 13, 19, 29, 43, 47, 49], "suicid": 44, "suit": [22, 43], "suitabl": [10, 11, 12, 18, 25, 28, 41, 43, 49, 52], "sultan": 44, "sum": [8, 15, 16, 17, 21, 22, 23, 31, 32, 33, 34, 38, 39, 41, 45, 50], "sum_": [15, 21, 31, 37, 41, 44, 45], "sum_i": [39, 44], "sum_prob_ex1_class_0": 38, "sum_prob_ex1_class_1": 38, "summar": [1, 12, 18, 28, 34, 36, 37, 41, 44, 49], "summari": [0, 51, 52, 54], "summary_plot": 39, "summat": [38, 48], "summer": [43, 46], "summer_month": 46, "sun": [44, 46], "sundai": 46, "sundial": 45, "sunshin": 46, "sunstrum": [1, 56], "super": [17, 23, 33, 52], "superfici": [15, 21, 31], "superior": 11, "supermarket": 50, "supervis": [11, 16, 17, 22, 23, 27, 32, 33, 35, 36, 37, 40, 42, 44, 46, 47, 52, 56], "suppli": 56, "support": [10, 13, 16, 19, 22, 26, 27, 29, 32, 36, 38, 39, 40, 42, 44, 48, 50, 51, 54, 56], "support_": [15, 21, 31, 40], "suppos": [12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 48, 52, 53], "suppress": 8, "suprem": 44, "supr\u00eam": 44, "sure": [4, 7, 8, 10, 13, 14, 15, 16, 17, 21, 23, 30, 31, 33, 36, 37, 38, 39, 42, 45, 46, 48, 49, 54, 56], "surfac": 19, "surgeri": 47, "surpris": [39, 43], "surprisingli": [17, 23, 33, 34], "surround": [4, 11, 48], "survei": [27, 41], "surviv": [1, 2, 11, 48, 49], "survival_function_": 47, "suscept": [42, 49], "suspect": 35, "svc": [15, 16, 17, 21, 22, 23, 26, 27, 31, 32, 33, 34, 35, 38, 39, 40, 45, 54, 55], "svc__c": 35, "svc__gamma": 35, "svc_pipe": 35, "svc_pred": 36, "svcsvc": [17, 23, 33, 35, 36], "svm": [1, 14, 16, 17, 20, 22, 23, 27, 30, 32, 33, 35, 38, 39, 40, 45, 46, 48, 49, 51, 52, 54, 55], "svm_estim": 36, "svr": [15, 21, 31, 33, 39, 48], "svr_c_pipe": 33, "svr_pipe": 33, "sw": 46, "swai": [12, 28], "swamp": [15, 21, 31], "swan": 45, "swcarpentri": 9, "sweep": 36, "sweet": 50, "switch": [13, 39, 41, 46, 47, 48], "swng": [1, 56], "sy": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 52, 53, 54, 55], "sydnei": 46, "syllabu": [3, 7, 12, 13, 15, 16, 17, 18], "symbol": [19, 29], "symmetri": 40, "sync": 5, "synonym": 44, "synopsi": 44, "syntact": 44, "syntax": [4, 8, 12, 18, 28, 40, 47], "synthet": [40, 51], "system": [1, 2, 4, 5, 6, 10, 11, 12, 14, 15, 17, 18, 20, 26, 28, 30, 31, 33, 36, 39, 41, 46, 48, 49], "systemat": [13, 19, 29, 33, 35, 39, 44], "t": [1, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54], "t2a": 56, "t2b": 56, "t2c": 56, "t2d": 56, "t2e": 56, "t2f": 56, "t2g": 56, "t2h": 56, "t2i": 56, "t2j": 56, "t2k": 56, "ta": [7, 12, 18, 28, 37, 39, 48, 49, 53, 54, 55], "tab": [12, 18], "tabbi": [12, 18, 28, 45], "tabl": [7, 27], "tabular": [8, 12, 18, 26, 28, 45, 46], "tackl": [14, 16, 20, 22, 30, 32, 36, 42, 54], "taco": 40, "tag": [4, 44, 50], "tail": [8, 46], "tailor": [11, 41, 48, 49], "take": [2, 4, 5, 6, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56], "taken": [46, 51, 56], "talk": [13, 14, 16, 19, 20, 22, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 56], "tall": 44, "target": [14, 15, 16, 20, 21, 22, 26, 27, 30, 31, 32, 34, 35, 36, 38, 39, 40, 43, 45, 46, 47, 48, 49, 52, 54, 55], "target_column": [38, 39, 47], "target_nam": 36, "target_names_toi": 36, "target_tag": 27, "tariff": 44, "task": [11, 16, 17, 22, 23, 25, 26, 32, 33, 34, 35, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 52], "tast": [27, 41, 43], "tasti": 27, "taught": [17, 23, 33, 44, 56], "tax": 48, "tba": 1, "teach": [4, 12, 16, 18, 22, 28, 32, 44, 52], "team": [4, 8, 12, 18, 28, 38, 39, 44], "tech": [15, 31, 36, 39], "technic": [48, 49, 56], "techniqu": [1, 11, 12, 15, 21, 31, 35, 40, 43, 45, 47, 49, 51, 52], "technolog": 0, "technologi": 44, "techsupport": 47, "techsupport_no": 47, "techsupport_y": 47, "ted": 41, "tediou": 42, "telco": 47, "telecom": 47, "telephon": 44, "tell": [14, 15, 16, 20, 22, 30, 31, 32, 34, 36, 39, 40, 43, 44, 46, 47, 48, 49, 54], "temp3pm": 46, "temp9am": 46, "temperatur": [13, 19, 29], "templat": 49, "tempo": [15, 16, 22, 31, 32, 35], "tempor": [47, 52], "tend": [14, 15, 20, 21, 30, 31, 34, 38, 40, 43, 46, 47, 56], "tendenc": [14, 20, 30], "tensor": [26, 45], "tensorflow": [10, 39, 45], "tent": 12, "tenur": [47, 48, 52], "tenure_lm": 47, "tenure_predict": 47, "term": [0, 2, 13, 15, 17, 19, 21, 23, 29, 31, 33, 34, 36, 39, 40, 43, 44, 47, 48, 49, 52], "termin": [5, 10, 13, 29, 41, 49], "terminologi": [14, 30, 36, 52, 53], "terrac": 45, "terribl": [37, 43], "territori": 56, "tesoro": 35, "test": [1, 7, 8, 10, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 42, 47, 48, 49, 51, 52, 54, 56], "test_accuraci": 36, "test_average_precis": 36, "test_df": [12, 16, 18, 22, 28, 32, 33, 34, 36, 37, 38, 39, 40, 46, 47, 48, 49, 50, 55], "test_df_churn": 47, "test_df_nan": [36, 38, 39], "test_df_sort": 46, "test_df_surv": 47, "test_exampl": 38, "test_f1": 36, "test_format": [15, 21, 31], "test_g50k": 38, "test_idx": 26, "test_imag": [12, 18, 28, 45], "test_l50k": 38, "test_mape_scor": 37, "test_nam": 47, "test_neg_mean_squared_error": 37, "test_neg_root_mean_square_error": 37, "test_point": [15, 21, 31, 51], "test_precis": 36, "test_r2": 37, "test_recal": 36, "test_roc_auc": 36, "test_scor": [14, 15, 16, 17, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 47, 50, 54], "test_shap_valu": 39, "test_siz": [12, 15, 16, 18, 21, 22, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 46, 48, 49, 50, 51, 54, 55], "test_sklearn": 37, "test_statist": 47, "test_x": 47, "testabl": 18, "text": [1, 7, 11, 12, 13, 18, 19, 22, 28, 29, 34, 35, 36, 37, 38, 39, 40, 43, 45, 48, 49, 52], "text_feat": 35, "text_featur": 50, "text_pp": 44, "textbook": [3, 9, 48], "textrm": [14, 20, 30], "textual": 11, "textur": 40, "tf": [17, 23, 33], "tfidfvector": 34, "th": [12, 18, 34, 43], "thai": 27, "than": [6, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 51, 53, 54, 56], "thank": [12, 18, 28, 44, 54], "thankfulli": 46, "thei": [1, 7, 8, 13, 14, 15, 18, 19, 20, 21, 27, 29, 30, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 56], "theirs": 44, "them": [1, 2, 4, 7, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 56], "theme": 44, "themselv": [41, 42, 44], "theoret": [16, 22, 32, 36, 38, 52], "theori": 39, "thepopbreak": 50, "therefor": [18, 54], "thermostat": [13, 19, 29], "thi": [0, 1, 2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 19, 20, 21, 26, 29, 30, 31, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56], "thick": [27, 41], "thing": [1, 5, 7, 8, 12, 13, 14, 15, 18, 19, 20, 21, 29, 30, 31, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 54], "think": [4, 12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 27, 28, 29, 30, 31, 33, 34, 36, 37, 39, 40, 41, 43, 45, 46, 47, 48, 49, 52, 53, 54], "third": 42, "thk": [12, 18, 28], "thorough": 10, "thoroughli": 52, "those": [5, 8, 10, 11, 12, 16, 18, 22, 32, 37, 38, 39, 43, 44, 47, 48, 49, 56], "though": [14, 17, 19, 20, 23, 27, 30, 33, 34, 41, 42, 43, 49, 50], "thought": [4, 15, 21, 31, 39, 47, 52], "thousand": [34, 42, 43], "thrasher": 44, "threahold": 40, "threaten": 50, "three": [8, 13, 16, 22, 26, 29, 32, 34, 36, 38, 39, 40, 41, 42, 44, 45, 46, 51, 52, 56], "thresh": 8, "threshold": [13, 19, 29, 34, 38, 40, 42, 44, 47], "thresholds_lr": 36, "thresholds_svc": 36, "through": [1, 7, 10, 12, 13, 18, 19, 29, 36, 37, 40, 42, 43, 44, 45, 48, 56], "throughout": [14, 20, 30, 48], "throught": [18, 56], "throw": [17, 23, 33, 45, 47, 48, 52], "thu": [1, 6, 12, 35, 46, 47, 56], "thumb": [13, 19, 29, 50], "thursdai": [12, 56], "ti": [17, 23, 33], "tianyu": [1, 56], "tick": 46, "tick_label": 39, "tick_param": 41, "tiffin": 44, "tiger": [12, 18, 28, 45], "tight": [15, 21, 26, 31, 42, 54], "tight_layout": [45, 48], "tightrop": [15, 21, 26, 31, 54], "tile": 39, "till": [15, 21, 31, 44, 47], "timber": 44, "time": [1, 2, 4, 8, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 53, 54, 56], "time_diff": 46, "time_signatur": [15, 16, 22, 31, 32, 35], "timedelta": 46, "timeit": [8, 51], "timelin": 48, "timeseri": [45, 46], "timeseriessplit": [46, 47, 52], "timestamp": 46, "timezon": [1, 47], "tinder": 43, "tini": [7, 14, 20, 30, 36, 42], "tip": 44, "tire": 50, "titan": 43, "titi": [12, 18, 28], "titl": [7, 14, 15, 20, 21, 25, 26, 30, 31, 34, 37, 40, 42, 45, 46, 47, 48, 54], "tldr": [12, 18], "tmp": 27, "tn": 36, "to_datetim": [25, 46], "to_html": [12, 13, 14, 18, 20, 28, 29, 30], "to_notebook_ifram": 37, "to_numpi": [15, 21, 31, 43, 46], "to_str": [12, 18, 28, 45], "toarrai": [17, 23, 33, 39, 46], "tobago": [38, 39], "todai": [13, 19, 29, 43, 45, 46, 47, 49, 52], "todens": [39, 40], "togeth": [5, 8, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 27, 29, 31, 32, 33, 41, 44, 54], "toi": [8, 14, 15, 20, 21, 30, 31, 40, 41, 42, 43, 46, 52], "toilet": [45, 50], "token": [7, 18, 50, 56], "token_pattern": [17, 23, 33], "tol": [36, 40, 48], "told": [5, 56], "tolist": [12, 13, 14, 17, 18, 19, 20, 23, 25, 26, 27, 28, 29, 30, 33, 34, 36, 37, 38, 39, 40, 41, 43, 46, 47, 50], "tomasbeuzen": 8, "tomorrow": [13, 16, 17, 19, 29, 46, 47, 52], "ton": 35, "tone": 50, "too": [6, 7, 14, 15, 17, 20, 21, 22, 23, 26, 30, 31, 33, 35, 37, 38, 39, 44, 46, 47, 48, 49, 54, 56], "took": 46, "tool": [1, 7, 8, 10, 11, 17, 23, 33, 34, 36, 37, 39, 42, 43, 45, 46, 47, 49, 52, 56], "toolbox": [15, 21, 31, 38, 44], "toolkit": 44, "top": [13, 17, 19, 23, 29, 33, 35, 36, 42, 46, 48, 49], "topi": 44, "topic": [1, 2, 8, 11, 13, 19, 29, 36, 37, 41, 43, 45, 49, 52, 56], "topic2vec": 44, "topics_per_chunk": 44, "topn": [12, 18, 28, 45], "torch": [26, 45], "torchvis": [12, 18, 26, 28, 45], "toronto": [44, 48, 50], "tort": 0, "total": [1, 8, 13, 16, 17, 19, 22, 23, 29, 32, 33, 36, 37, 38, 39, 40, 44, 46, 47, 48], "total_bedroom": [16, 22, 32, 33, 40, 55], "total_bilirubin": [12, 18, 28], "total_protien": [12, 18, 28], "total_room": [16, 22, 32, 33, 40, 55], "total_second": 46, "totalbsmtsf": [37, 39, 48], "totalcharg": 47, "totem": 45, "totensor": [26, 45], "toti": [0, 1, 44, 56], "totrmsabvgrd": [37, 39, 48], "touch": 49, "toward": [34, 39, 44, 56], "towardsdatasci": [45, 47], "town": 50, "townsvil": 46, "toy_clust": 44, "toy_clust_df": 41, "toy_df": [17, 23, 33, 44], "toy_lda_data": 44, "toy_movie_feat": 43, "toy_rat": 43, "toy_spam": [17, 23, 33], "toy_x": 44, "tp": 36, "tpot": 35, "tpr": 36, "tpr_lr": 36, "tpr_svc": 36, "tr_score": [25, 54], "traceback": [4, 8, 17, 23, 27, 33, 47], "track": [1, 17, 23, 33, 49, 56], "trade": [11, 34, 36, 40, 41, 52], "tradeoff": [15, 16, 21, 22, 25, 31, 32, 34, 37, 40, 41, 45], "tradit": [12, 18, 28, 43, 45, 47, 56], "tradition": 56, "trail": 8, "train": [7, 15, 16, 21, 22, 25, 26, 27, 31, 32, 35, 37, 38, 39, 40, 41, 43, 44, 47, 50, 51, 52, 53, 54, 55], "train_accuraci": 36, "train_dataload": 45, "train_df": [12, 16, 18, 22, 28, 32, 33, 34, 36, 37, 38, 39, 40, 46, 47, 48, 49, 50, 55], "train_df_churn": 47, "train_df_nan": [36, 38, 39], "train_df_ord": 46, "train_df_sort": 46, "train_df_surv": 47, "train_df_surv_not_churn": 47, "train_dir": 26, "train_f1": 36, "train_flatten": 45, "train_for_usr": 43, "train_load": 45, "train_mape_scor": 37, "train_mat": 43, "train_mat_imp": 43, "train_neg_mean_squared_error": 37, "train_neg_root_mean_square_error": 37, "train_precis": 36, "train_r2": 37, "train_recal": 36, "train_scor": [14, 15, 16, 17, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 47, 50, 54], "train_shap_valu": 39, "train_sklearn": 37, "train_test_split": [12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 46, 47, 48, 49, 50, 51, 54, 55], "train_x": 43, "transact": [13, 19, 29, 36, 46, 48], "transfer": [47, 49], "transfer_learning_tutori": 45, "transform": [0, 15, 21, 26, 27, 31, 35, 36, 38, 39, 42, 44, 45, 46, 47, 49, 50, 52, 54, 55], "transformed_exampl": 38, "transformed_oh": [16, 22, 32], "transformedtargetregressor": [37, 40, 48, 52], "transformedtargetregressortransformedtargetregressor": 37, "translat": [1, 9, 12, 18, 28], "transpar": [36, 52], "transpos": [26, 40, 45], "trasform": [16, 22, 32], "trash": 53, "traumat": 56, "treat": [8, 16, 17, 22, 23, 30, 32, 33, 36, 37, 43, 46, 47, 48, 50, 52], "treati": 56, "treatment": [17, 23, 33], "tree": [1, 2, 14, 15, 16, 17, 20, 21, 22, 23, 26, 30, 31, 32, 33, 34, 35, 37, 40, 42, 45, 46, 47, 49, 51, 52, 53, 55], "tree1": 38, "tree2": 38, "tree3": 38, "tree_numeric_transform": 39, "treeexplain": 39, "trend": [11, 47, 52], "tri": [19, 38, 39, 48, 51], "trial": [35, 47], "triangl": [15, 21, 31, 41], "trick": [5, 37], "tricki": [17, 23, 33, 35, 39, 43], "trigger": [15, 21, 31], "trigram": 44, "trivial": 42, "troubl": 10, "true": [8, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 54], "truli": [37, 44], "truncat": 42, "truncate_mod": 42, "truncation_mod": 42, "trust": [12, 16, 17, 18, 22, 23, 25, 26, 27, 28, 32, 33, 35, 36, 37, 38, 39, 40, 43, 45, 48, 50], "trustworthi": 42, "truth": [38, 40, 41, 42, 43, 46], "try": [1, 4, 5, 8, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 25, 26, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 52, 53, 54, 56], "tsa": 46, "tscv": 46, "tslearn": 46, "tsunami": [12, 28], "ttr": 37, "ttr_pipe": 37, "tue": [1, 12, 13, 46, 56], "tuesdai": [1, 12, 18, 40, 46, 56], "tuggeranong": 46, "tumor": 52, "tune": [14, 20, 25, 30, 35, 38, 42, 43, 45, 48, 49], "turn": [4, 14, 20, 26, 30, 44, 45, 47, 55, 56], "tusker": 45, "tutori": [1, 4, 5, 9, 10, 12, 18, 43, 45, 49, 52, 56], "tweak": [15, 21, 26, 31, 54], "tweet": [44, 50], "tweetat": 50, "twice": [8, 14, 17, 23, 30, 33, 34], "twinx": 48, "twist": 44, "twitter": 44, "twitter_allowed_char": 50, "two": [4, 6, 7, 8, 9, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 27, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 55, 56], "two_citi": [15, 21, 31], "two_song": [16, 22, 32], "two_songs_subset": [16, 22, 32], "tx": [34, 50], "tx_i": 48, "txt": [12, 18, 28, 45, 49], "typ": [37, 39, 48], "type": [4, 8, 10, 11, 13, 15, 16, 17, 19, 22, 23, 27, 29, 31, 32, 33, 35, 38, 40, 42, 43, 44, 45, 49, 52, 54, 55], "typeerror": 47, "typic": [2, 7, 12, 13, 15, 16, 18, 19, 21, 22, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 41, 43, 46, 48, 49], "u": [4, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 53, 54, 55], "u6": [13, 19, 29], "u_1": [15, 21, 31], "u_2": [15, 21, 31], "u_i": [15, 21, 31], "u_n": [15, 21, 31], "ubc": [0, 4, 5, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 54, 55, 56], "ubc_img": 45, "ubc_okanagan": 44, "ubco": 44, "ubyssei": 44, "ucsb": 9, "ud036": 9, "udac": 9, "ufunc": 37, "ufv": 44, "uint8": 26, "ultim": [4, 14, 20, 30, 48], "ultralyt": 45, "uluru": 46, "umbrella": 43, "un": [37, 47], "unabl": [12, 16, 17, 18, 22, 23, 25, 26, 27, 28, 32, 33, 35, 36, 37, 38, 39, 40, 42, 45, 47, 48, 50, 56], "unambigu": 44, "unassign": [41, 42], "unbias": 36, "unced": 56, "uncertain": 34, "uncertainti": [34, 36, 48, 49], "unchang": 39, "uncia": [12, 18, 28, 45], "uncomfort": 43, "uncorrel": 39, "under": [0, 1, 7, 13, 14, 20, 27, 29, 30, 37, 44, 45, 47, 49], "under_sampl": 36, "underestim": 47, "underfit": [15, 21, 25, 26, 31, 34, 35, 45, 54], "underli": [2, 39, 40, 41], "underneath": 7, "underpredict": 37, "undersample_pip": 36, "understand": [0, 1, 4, 7, 11, 12, 13, 14, 15, 17, 18, 21, 23, 25, 26, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 56], "understood": 36, "unemploi": 47, "unexpect": [17, 23, 33, 34, 35, 44], "unexplain": 37, "unf": [37, 39, 48], "unfinish": 37, "unfortun": [6, 35, 39, 41, 42], "uniform": [35, 36, 42], "unimport": [35, 39], "uninstal": 10, "uninterpret": 39, "unintuit": 8, "union": 8, "uniqu": [16, 17, 22, 23, 32, 33, 36, 37, 38, 39, 43, 44, 46, 47], "unit": [27, 34, 36, 37, 38, 39, 44, 45, 47, 50], "unitless": 37, "univers": [1, 9, 44], "university_year": [17, 23, 33, 52], "unix": [5, 46], "unknown": [6, 44, 52], "unlabel": [12, 14, 18, 20, 28, 30, 42], "unless": [7, 18, 56], "unlik": [8, 12, 14, 15, 17, 18, 20, 21, 23, 30, 31, 33, 37, 39, 41, 42], "unlimit": 46, "unlucki": [14, 20, 30], "unmarri": [38, 39], "unnam": [12, 18, 28], "uno": 27, "unoffici": 56, "unqualifi": 36, "unreason": [6, 18, 37], "unrecogniz": [12, 18], "unreli": [14, 20, 30], "unrespond": [12, 18], "unscal": [16, 22, 32], "unseen": [13, 29, 40, 41, 45, 49, 54], "unsqueez": 45, "unstructur": 44, "unsupervis": [12, 18, 28, 43, 44, 45, 49, 56], "unsur": [7, 48], "until": [4, 13, 14, 19, 20, 29, 30, 35, 40, 41, 42, 44, 47, 48, 49], "unus": 54, "unusu": 27, "unwieldi": [13, 16, 19, 22, 29, 32], "unzip": [39, 50], "uoft": 44, "up": [7, 8, 13, 16, 17, 19, 22, 23, 25, 27, 28, 29, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 52, 53, 56], "uparrow": 42, "upcom": 41, "updat": [10, 15, 16, 17, 21, 22, 23, 26, 31, 32, 33, 38, 41, 54], "update_cent": 41, "update_plot": [15, 21, 26, 31, 54], "update_z": 41, "upei": 44, "upgrad": 44, "upload": 7, "upon": [0, 13, 14, 17, 19, 20, 23, 29, 30, 33, 36, 38, 39, 40, 41, 42, 44], "upper": [36, 47], "upperbound_pric": 27, "uppercas": 50, "upto": 46, "ur": [12, 18, 28], "urgent": [17, 23, 33, 44], "url": [4, 14, 20, 30, 36, 47, 49], "us": [0, 1, 2, 4, 5, 10, 11, 25, 27, 34, 35, 39, 42, 43, 46, 47, 49, 50, 52, 54, 55], "usa": [8, 14, 15, 20, 21, 30, 31, 34, 44], "usabl": 49, "usag": [16, 17, 22, 23, 32, 33, 36, 37, 40, 44, 46, 47], "usec_": 47, "useless": [35, 39, 40], "user": [10, 12, 16, 17, 18, 19, 22, 23, 26, 28, 29, 30, 32, 33, 35, 38, 39, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52], "user_id": 43, "user_inverse_mapp": 43, "user_kei": 43, "user_mapp": 43, "user_nam": 43, "usernam": 50, "userwarn": [17, 19, 23, 26, 29, 30, 33, 38, 39], "usf": [17, 23, 33], "using_copy_on_writ": [27, 47], "using_cow": 47, "usual": [1, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 56], "utc": [46, 47], "utcnow": 47, "util": [5, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 45, 47, 48, 52, 53, 54, 55], "utilities_allpub": 37, "utilities_nosewa": 37, "utility_mat": 43, "uvic": 44, "v": [1, 3, 7, 17, 23, 25, 26, 33, 34, 42, 44, 46, 47, 48, 52], "v1": [12, 18, 28, 36], "v10": 36, "v11": 36, "v12": 36, "v13": 36, "v14": 36, "v15": 36, "v16": 36, "v17": 36, "v18": 36, "v19": 36, "v2": [12, 18, 28, 36], "v20": 36, "v21": 36, "v22": 36, "v23": 36, "v24": 36, "v25": 36, "v26": 36, "v27": 36, "v28": 36, "v3": 36, "v4": 36, "v5": 36, "v6": 36, "v7": 36, "v8": 36, "v9": 36, "v_1": [15, 21, 31], "v_2": [15, 21, 31], "v_i": [15, 21, 31], "v_n": [15, 21, 31], "vacat": 34, "vaccin": [48, 50], "vada_pav": 44, "vader": 50, "vader_lexicon": 50, "vader_senti": 50, "vain": 35, "val": [43, 47], "valenc": [15, 16, 22, 31, 32, 35, 50], "valid": [1, 15, 17, 19, 21, 23, 26, 27, 29, 31, 33, 37, 38, 39, 40, 41, 43, 45, 47, 48, 49, 50, 52, 55], "valid_dataload": 45, "valid_dir": 26, "valid_flatten": 45, "valid_load": 45, "valid_mat": 43, "valid_sample_df": 38, "valid_sample_i": 38, "valid_sample_x": 38, "valid_scor": [25, 54], "valid_x": 43, "validate_data": 27, "validate_separ": 27, "valu": [7, 8, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "valuabl": [11, 40, 42, 56], "value_count": [13, 17, 19, 23, 25, 27, 29, 33, 36, 38, 39, 46, 47, 49, 50], "value_throttl": [15, 21, 26, 31, 54], "valueerror": [8, 16, 17, 22, 23, 27, 32, 33, 47], "values_format": 36, "vancouv": [44, 48], "vancouver_canuck": 44, "vanilla": 34, "var": [22, 30, 32, 39, 50], "var_": 39, "varada": [0, 1, 19], "vari": [11, 13, 19, 29, 35, 38, 42, 47, 54], "variabl": [7, 8, 13, 16, 17, 19, 22, 23, 25, 29, 32, 33, 34, 35, 37, 39, 40, 46, 47, 48, 54], "varianc": [37, 39, 42, 46, 54], "variant": [39, 42], "variat": [14, 20, 30, 34, 36, 37, 40], "varieti": [12, 18, 28, 38, 44], "variou": [11, 12, 15, 18, 21, 26, 28, 31, 37, 39, 45, 46, 47, 48, 49, 52, 54], "vault": [14, 20, 30], "ve": [7, 8, 12, 14, 15, 18, 20, 21, 25, 26, 28, 30, 31, 36, 37, 39, 43, 44, 45, 46, 48, 49, 51], "vec": [17, 23, 33, 44, 45], "vec1": 44, "vec1_i": 44, "vec2": 44, "vec2_i": 44, "vec8": [17, 23, 33], "vec8_binari": [17, 23, 33], "vec_binari": [17, 23, 33], "vecom": 35, "vector": [13, 19, 22, 26, 29, 34, 36, 43, 45, 48, 54], "verb": [44, 50], "verbos": [12, 18, 28, 36, 38, 39, 48], "veri": [2, 4, 5, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 54, 56], "versa": [37, 54], "version": [1, 4, 5, 7, 8, 10, 12, 19, 22, 27, 30, 32, 34, 35, 37, 39, 42, 44, 46, 47, 50, 51], "versu": 9, "vert": 39, "vertic": [13, 19, 29, 36, 46], "vgg": 45, "vgg16": [26, 45], "vgg16_weight": 45, "via": [4, 7, 10, 12, 18, 36, 40, 56], "vibe": 27, "vice": [37, 54], "video": [1, 7, 8, 9, 10, 25, 43, 45, 47, 48, 49, 54, 56], "vietnames": [16, 22, 32], "view": [6, 7, 10, 12, 13, 18, 25, 28, 29, 39, 42, 45, 46, 47, 48], "viewpoint": 43, "vif": 39, "vikski": 44, "violat": [16, 17, 22, 23, 32, 33, 47, 49, 56], "virginia": 45, "viridi": 35, "vision": [1, 49, 51], "visit": [8, 56], "visual": [1, 11, 13, 14, 15, 17, 19, 20, 21, 23, 25, 29, 30, 31, 33, 34, 36, 37, 38, 39, 41, 42, 45, 46, 47, 50, 52, 55], "viu": 44, "viz": 48, "voc": [36, 38, 39], "vocab": 44, "vocabulari": [17, 23, 33, 34, 44], "vocabulary_": [17, 23, 33], "voic": [12, 18, 28], "volcano": [12, 28], "volum": 49, "vote": [15, 16, 21, 22, 31, 32, 38, 51], "voting_ndt": 38, "votingclassifi": 38, "votingclassifierinot": 38, "votingregressor": 38, "vyfj": [28, 29, 33, 34, 35, 36, 37, 38], "w": [10, 17, 23, 33, 34, 37, 41, 44, 46, 48, 49], "w_0": 34, "w_1": 34, "w_1x_1": 34, "w_2x_2": 34, "w_3x_3": 34, "w_4x_4": 34, "w_d": 34, "w_dx_d": 34, "w_j": 34, "wa": [4, 5, 10, 14, 16, 17, 18, 19, 20, 22, 26, 27, 29, 30, 32, 34, 36, 38, 39, 43, 44, 45, 47, 48, 50, 51, 53, 54, 56], "wa_fn": 47, "wai": [0, 2, 6, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 54, 56], "wait": [4, 12, 15, 17, 18, 19, 21, 23, 28, 29, 31, 33, 47, 49, 56], "waitlist": [13, 56], "walk": [15, 21, 26, 31, 36, 49, 54], "walker": [12, 18, 28, 45], "wallabi": 45, "wang": [1, 56], "want": [4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 55, 56], "war": 43, "ward": 42, "warm": [16, 22, 32], "warm_start": [36, 48], "warn": [6, 12, 15, 17, 18, 20, 21, 23, 26, 30, 31, 33, 37, 38, 39, 47, 51], "warranti": 0, "washington": 50, "washroom": 56, "wasn": 44, "wast": [4, 17, 23, 33, 48], "watch": [1, 10, 12, 15, 18, 31, 34, 43, 44, 52], "watchfil": 26, "water": 48, "waterfal": 39, "waterfront": [12, 13, 18, 25, 28, 29], "wavelet": 40, "wb": 49, "wd": [37, 39, 48], "we": [1, 4, 5, 6, 7, 10, 12, 13, 15, 18, 19, 21, 26, 27, 28, 29, 31, 42, 44, 45, 46, 50, 51, 52, 53, 54, 55, 56], "weak": 52, "weather": [13, 19, 29, 46, 49], "weatherau": 46, "web": [5, 12, 18, 44, 52], "web_api": 49, "web_appl": 49, "weblog": 44, "websit": [4, 10], "wed": 46, "wednesdai": [46, 56], "week": [1, 6, 14, 15, 16, 17, 18, 21, 22, 23, 30, 31, 32, 33, 36, 37, 38, 39, 43, 44, 46, 48, 56], "weekdai": 46, "weekend": [8, 46, 48], "weekli": [12, 50], "weight": [15, 18, 21, 26, 31, 38, 40, 43, 44, 45, 56], "weighted_averag": 36, "weinberg": 39, "weird": 37, "welcom": [53, 56], "well": [4, 5, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 48, 49, 52, 56], "wellyanto": [1, 56], "welsh": [12, 18, 28, 45], "went": [37, 50], "were": [0, 6, 12, 18, 27, 33, 34, 36, 37, 44, 45, 46, 47, 48, 56], "weren": 44, "what": [7, 8, 9, 13, 15, 19, 21, 25, 26, 27, 29, 31, 35, 42, 45, 46, 50, 51, 52, 53, 54, 55, 56], "whatev": 40, "when": [4, 6, 7, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 55, 56], "wher": 50, "where": [0, 1, 7, 10, 13, 14, 15, 19, 20, 21, 22, 26, 27, 29, 30, 31, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 48, 49, 52, 54], "wherea": [2, 13, 19, 27, 29, 34, 35, 37, 39, 42, 48], "whether": [0, 4, 7, 8, 13, 14, 16, 17, 19, 20, 22, 23, 27, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 46, 47, 49, 50, 53, 56], "which": [4, 6, 8, 10, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 34, 35, 37, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56], "whichev": 38, "while": [14, 19, 20, 22, 29, 30, 34, 35, 36, 38, 39, 41, 43, 44, 47, 50], "white": [36, 38, 39, 42, 44], "whitespac": [44, 47], "who": [4, 5, 6, 12, 18, 28, 36, 39, 41, 42, 44, 46, 47, 48, 49, 50, 52, 56], "whole": [14, 20, 30, 35, 37, 39, 43, 49], "whom": [0, 44, 50], "whose": 4, "why": [8, 14, 15, 19, 21, 25, 27, 30, 31, 36, 37, 38, 41, 42, 44, 46, 47, 52, 53, 54, 55], "wid": [36, 49], "wide": [10, 34, 35, 38, 40, 43, 45, 48], "wider": [15, 21, 26, 31, 54], "widespread": 44, "widget": [15, 21, 26, 31, 36, 41, 42, 54], "width": [13, 14, 15, 19, 20, 21, 26, 29, 30, 31, 36, 44, 53, 54], "wife": [12, 28, 36, 38, 39], "wiki": [44, 48], "wiki_df": 44, "wiki_dict": 44, "wikipedia": [44, 45, 48], "wikipedia2vec": 44, "wild": [12, 14, 18, 20, 26, 28, 30, 45], "willing": 36, "win": [15, 17, 21, 23, 31, 33, 38, 39, 40, 43, 51], "wind": [13, 19, 29], "winddir3pm": 46, "winddir3pm_miss": 46, "winddir3pm_ss": 46, "winddir3pm_ssw": 46, "winddir3pm_sw": 46, "winddir3pm_w": 46, "winddir3pm_wnw": 46, "winddir3pm_wsw": 46, "winddir9am": 46, "windgustdir": 46, "windgustspe": 46, "window": 47, "windsor": 50, "windspeed3pm": 46, "windspeed9am": 46, "wine_1": 8, "winter": 46, "winter_month": 46, "wire": 43, "wisdom": 38, "wish": [12, 13, 18, 19, 28, 29, 41, 48, 56], "within": [13, 16, 19, 22, 26, 29, 32, 34, 38, 40, 41, 42, 47, 49, 52], "without": [0, 7, 12, 13, 18, 19, 28, 29, 36, 38, 39, 40, 43, 45, 46, 47, 48, 49, 56], "wnw": 46, "wolv": 42, "woman": 44, "wombat": 45, "won": [5, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 29, 30, 31, 33, 34, 40, 43, 44, 45, 46, 47, 49, 50], "wonder": [12, 14, 18, 28, 30], "wooddecksf": [37, 39, 48], "word": [11, 12, 18, 25, 27, 28, 34, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 52, 56], "word1": 44, "word2": 44, "word2vec": [11, 44, 45], "word3": 44, "word_pair": 44, "word_token": [44, 50], "wordnet": 44, "wordnetlemmat": 44, "work": [0, 4, 5, 7, 8, 10, 12, 15, 16, 17, 18, 21, 22, 23, 27, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 49, 50, 52, 56], "workclass": [36, 38, 39], "workclass_feder": [38, 39], "workclass_loc": [38, 39], "workclass_miss": 39, "workclass_nev": [38, 39], "workclass_priv": [38, 39], "workclass_self": 39, "workclass_st": 39, "workclass_without": 39, "workflow": [13, 19, 29, 49, 56], "worksheet": 49, "world": [15, 16, 17, 20, 21, 22, 23, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 52], "worm": 45, "worri": [12, 18, 28, 41, 42, 43], "wors": [13, 19, 29, 35, 37, 38, 47, 53], "worst": [36, 40, 41], "worth": [13, 15, 19, 21, 29, 31, 36, 37], "worthi": 34, "would": [4, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54, 55, 56], "wouldn": [17, 23, 33, 35, 44, 47], "wow": 39, "wrangl": 27, "wrap": [17, 23, 33], "wrapper": [27, 40], "write": [4, 7, 11, 12, 18, 28, 35, 39, 40, 41, 44, 48, 49, 50, 54, 56], "written": [7, 17, 23, 33, 39, 46, 48], "wrong": [10, 14, 20, 27, 30, 34, 37, 40, 41, 47, 48], "wrote": [44, 46], "wsw": 46, "wtf": 49, "www": [9, 34], "x": [4, 8, 10, 14, 15, 16, 17, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 34, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54], "x0": 40, "x0_male": 36, "x1": [40, 43], "x1x2": 40, "x2": [40, 42, 43], "x27": [16, 17, 22, 23, 32, 33, 35, 36, 37, 38, 40, 45, 48, 50], "x_": 34, "x_1": [34, 40, 41], "x_1x_2": 40, "x_2": [34, 40, 41], "x_anim_train": 26, "x_anim_valid": 26, "x_binari": [13, 19, 29], "x_citi": [15, 21, 31], "x_count": [17, 23, 33], "x_d": 34, "x_femal": 36, "x_hour": 46, "x_hour_week": 46, "x_hour_week_onehot": 46, "x_hour_week_onehot_poli": 46, "x_hour_week_onehot_poly_lag": 46, "x_i": [34, 43], "x_imp_ohe_train": [16, 22, 32], "x_init": 41, "x_int": [17, 23, 33], "x_label": [13, 14, 15, 19, 20, 21, 29, 30, 31, 53], "x_lag_featur": 46, "x_lag_features_imp": 46, "x_male": 36, "x_mask": [17, 23, 33], "x_multi": 51, "x_n": 40, "x_orig": 42, "x_re": 36, "x_small_citi": [15, 21, 31], "x_spotifi": [15, 31, 35], "x_subset": [13, 14, 19, 20, 29, 30], "x_test": [12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 50, 51, 54, 55], "x_test_big": 35, "x_test_cat": 27, "x_test_cat_oh": 27, "x_test_enc": [39, 46, 47, 48], "x_test_happi": [36, 49], "x_test_imp": [16, 22, 32], "x_test_multi": 51, "x_test_num": 27, "x_test_num_imp": 27, "x_test_num_imp_sc": 27, "x_test_pr": 46, "x_test_predict": [16, 22, 32], "x_test_scal": [16, 22, 32], "x_test_transform": [16, 22, 32], "x_toi": [15, 16, 17, 21, 22, 23, 31, 32, 33, 46], "x_toy_oh": [16, 22, 32], "x_toy_ord": [16, 17, 22, 23, 32, 33], "x_tr": [25, 54], "x_train": [12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 46, 47, 48, 50, 51, 54, 55], "x_train_big": 36, "x_train_cat": 27, "x_train_cat_oh": 27, "x_train_enc": [36, 37, 39, 46, 47, 48], "x_train_happi": [36, 49], "x_train_hous": 40, "x_train_imp": [16, 22, 32], "x_train_imp_sc": [16, 22, 32], "x_train_multi": 51, "x_train_num": 27, "x_train_num_imp": 27, "x_train_num_imp_sc": 27, "x_train_oversampl": 36, "x_train_perm": 39, "x_train_pp": 33, "x_train_predict": [16, 22, 32], "x_train_scal": [16, 22, 32, 40], "x_train_subsampl": 36, "x_train_tini": 35, "x_train_transform": [16, 22, 32], "x_train_usr": 43, "x_transform": [17, 23, 33], "x_valid": [25, 26, 36, 43, 54], "x_vari": 42, "x_xor": 40, "xanni": 35, "xavier": [40, 43], "xcode": 5, "xgbclassifi": [38, 39], "xgbclassifierxgbclassifi": 38, "xgboost": 39, "xgbregressor": [12, 18, 28, 38], "xlabel": [8, 13, 14, 15, 19, 20, 21, 26, 29, 30, 31, 34, 35, 36, 37, 39, 42, 45, 46, 47, 48, 51, 53], "xlim": 47, "xor": [34, 40], "xp": 27, "xt": [17, 23, 33], "xtick": [14, 20, 26, 30, 36, 46], "xticklabel": 35, "xticks_rot": 36, "xwm\u0259\u03b8kw\u0259y": 56, "xx": [40, 41], "y": [8, 14, 15, 16, 17, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54], "y_": 43, "y_citi": [15, 21, 31], "y_femal": 36, "y_hat": [34, 38], "y_i": [37, 38, 40, 43], "y_init": 41, "y_label": [13, 14, 15, 19, 20, 21, 29, 30, 31, 53], "y_male": 36, "y_mat": 43, "y_multi": 51, "y_numer": 27, "y_pred": [36, 46], "y_pred_lower_threshold": 36, "y_pred_toi": 36, "y_pred_train": 46, "y_re": 36, "y_small_citi": [15, 21, 31], "y_spotifi": 35, "y_test": [12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 50, 51, 54, 55], "y_test_big": 35, "y_test_happi": [36, 49], "y_test_multi": 51, "y_test_num": [38, 39], "y_toi": [15, 21, 31, 46], "y_tr": [25, 54], "y_train": [12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 46, 47, 48, 50, 51, 54, 55], "y_train_big": 36, "y_train_happi": [36, 49], "y_train_hous": 40, "y_train_multi": 51, "y_train_num": [38, 39], "y_train_ord": 46, "y_train_oversampl": 36, "y_train_subsampl": 36, "y_train_tini": 35, "y_train_usr": 43, "y_true": 48, "y_true_toi": 36, "y_valid": [25, 26, 36, 43, 45, 54], "y_vari": 42, "y_xor": 40, "yale": 44, "yan": [1, 56], "yann": 39, "ycxmx": 47, "ye": [4, 12, 13, 16, 17, 18, 19, 22, 23, 27, 28, 29, 32, 33, 39, 41, 42, 43, 45, 46, 48, 49, 50, 52], "year": [12, 13, 18, 19, 29, 43, 44, 45, 46, 47], "yearbuilt": [37, 39, 48], "yearremodadd": [37, 39, 48], "yellow": 35, "yellowbrick": [41, 42], "yesterdai": 46, "yet": [1, 10, 11, 27, 34, 39, 43, 46, 47, 54], "yifei": [1, 56], "ylabel": [8, 13, 14, 15, 19, 20, 21, 25, 26, 29, 30, 31, 34, 35, 36, 37, 42, 45, 46, 47, 48, 51, 53, 54], "ylim": [47, 48], "yml": 10, "yolo": 45, "yolo8": 45, "yolo_input": 45, "yolo_result": 45, "yolo_test": 45, "yolov8n": 45, "york": [46, 50], "you": [0, 1, 4, 5, 6, 7, 8, 10, 25, 26, 39, 44, 50, 51, 52, 53, 54, 55, 56], "your": [0, 1, 2, 4, 6, 7, 8, 10, 14, 15, 16, 17, 20, 21, 22, 23, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56], "your_miniconda_path": 50, "your_nam": 10, "yourself": [4, 11, 17, 23, 33, 36, 43, 44, 48, 56], "yourselv": 44, "youtub": [1, 12, 18, 43, 44, 48, 56], "yr_built": [12, 13, 18, 25, 28, 29], "yr_renov": [12, 13, 18, 25, 28, 29], "yrpxn": 47, "yrsold": [37, 39, 48], "ytick": [14, 20, 26, 30, 36], "yticklabel": 35, "yy": [40, 46], "yyyi": 46, "z": [8, 26, 34, 40, 41, 42, 43, 45, 47], "z_i": 45, "z_j": 45, "z_km": 41, "z_train": [26, 45], "z_valid": [26, 45], "zachari": 47, "zarei": [1, 56], "zefeng": [1, 56], "zeng": [1, 56], "zero": [8, 14, 17, 20, 23, 30, 33, 35, 43, 44, 48], "zero_divis": 36, "zhiyanov": [1, 56], "zip": [15, 21, 26, 31, 34, 43, 50, 54], "zipcod": [12, 13, 18, 25, 28, 29, 54], "zone": 46, "zoom": 7, "\u0259m": 56, "\u03bc": 51}, "titles": ["LICENSE", "UBC CPSC 330: Applied Machine Learning (2024W2)", "CPSC 330 vs. CPSC 340", "CPSC 330 Documents", "How to ask for help", "What are git and GitHub?", "CPSC 330 grading policies", "Homework info &amp; submission guidelines", "CPSC 330 Python notes", "Reference material", "Setting up coding environment", "Course Learning Objectives", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "&lt;no title&gt;", "Lecture 3: ML Fundamentals Class Demo", "Lecture 4: Class demo", "Lecture 5 and 6: Class demo", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 12: Ensembles", "Lecture 13: Feature importances and model transparency", "Lecture 14: Feature engineering and feature selection", "Lecture 15: K-Means Clustering", "Lecture 16: More Clustering", "Lecture 17: Recommender Systems", "Lecture 18: Introduction to natural language processing", "Lecture 19: Multi-class classification and introduction to computer vision", "Lecture 20: Time series", "Lecture 21: Survival analysis", "Lecture 22: Communication", "Lecture 24: Deployment and conclusion", "Appendix A: Demo of feature engineering for text data", "Appendix B: Multi-class, meta-strategies", "Final exam preparation: guiding questions", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Syllabus"], "titleterms": {"": [12, 14, 15, 16, 17, 18, 21, 22, 23, 27, 28, 30, 31, 32, 33, 36, 37, 39, 46, 48], "0": 38, "1": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 45, 47, 48, 52, 53, 54, 55], "10": 37, "12": 38, "13": 39, "14": 40, "15": [41, 48, 49], "16": 42, "17": 43, "18": 44, "19": 45, "2": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 42, 43, 47, 48, 52, 53, 54, 55], "20": [46, 48, 49], "2024w2": 1, "21": 47, "22": 48, "24": 49, "3": [12, 13, 14, 16, 18, 19, 20, 22, 25, 28, 29, 30, 32, 40, 41, 42, 47, 53, 54, 55], "330": [1, 2, 3, 6, 8, 12, 18, 49], "340": [2, 12, 18, 49], "4": [13, 14, 15, 19, 20, 21, 26, 29, 30, 31, 48, 53, 54, 55], "5": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 29, 30, 31, 32, 33, 36, 39, 40, 41, 44, 45, 47, 48, 54, 55], "6": [17, 23, 27, 33, 54], "7": 34, "8": 35, "9": 36, "A": [4, 36, 42, 46, 50], "No": 8, "Not": 52, "One": [16, 22, 32, 46, 51], "The": [1, 14, 20, 30, 34, 35, 38, 40, 41], "__": 35, "about": [8, 12, 18, 40, 43, 48], "academ": 56, "access": [7, 34, 56], "accommod": 56, "acknowledg": 56, "activ": [12, 18, 25, 36, 39, 40, 41, 44, 48], "actual": [17, 33], "ad": 8, "addit": [7, 39], "address": 36, "advantag": 35, "advic": 40, "ai": 56, "aka": 48, "algorithm": [13, 15, 19, 21, 29, 31, 40, 41], "all": [12, 13, 16, 18, 28, 29, 32, 34, 36, 41, 42, 43, 48], "alpha": [34, 37], "alreadi": 49, "altern": [13, 16, 19, 22, 27, 29, 32], "an": [38, 48, 50], "analogi": [15, 31], "analysi": [25, 27, 46, 47, 49, 52, 54], "angl": 48, "announc": [12, 13, 14, 15, 16, 17, 21, 23, 29, 31, 33, 34, 38], "answer": 47, "ap": 36, "api": [16, 22, 32, 49], "app": 49, "appendix": [50, 51], "appli": [1, 8, 16, 17, 22, 23, 32, 33, 37, 48], "applic": 41, "applymap": 8, "approach": [43, 46, 47, 48, 49, 51], "approxim": [14, 20, 30], "ar": [5, 12, 13, 16, 18, 22, 28, 29, 32, 34, 36, 41, 42, 43], "area": 36, "argument": [14, 15, 20, 21, 30, 31], "around": 48, "arrai": 8, "articl": 9, "asap": 48, "ask": 4, "assess": 25, "assign": [7, 56], "associ": 34, "assum": 47, "attent": [13, 15, 19, 21, 29, 31], "attribut": [39, 48], "auc": 36, "autom": 35, "averag": [36, 38, 43], "avoid": [14, 20, 30], "b": [41, 51], "backward": 40, "bad": 35, "bag": [17, 23, 33, 50], "balanc": 36, "base": [15, 31, 38, 40, 43, 46], "baselin": [13, 16, 19, 22, 25, 29, 32, 36, 38, 39, 43, 54], "basic": 44, "befor": [12, 16, 18, 22, 32], "best": 40, "better": [14, 20, 30, 35, 36, 40, 48], "between": [13, 15, 21, 29, 31, 49, 53], "beyond": [39, 43], "bia": [14, 20, 30, 35], "big": [13, 14, 16, 19, 20, 22, 29, 30, 32], "binari": 36, "book": 1, "boost": [38, 48], "bootstrap": 38, "bottom": 48, "boundari": [13, 15, 19, 21, 26, 29, 31, 34, 53], "bow": [17, 23, 33], "box": 45, "break": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 29, 30, 31, 32, 33, 40, 44, 45, 47, 48, 49], "broadcast": 8, "browser": [12, 18], "build": [12, 13, 18, 19, 25, 28, 29, 37, 43, 49], "c": [15, 21, 31, 35], "calcul": 34, "california": [33, 34, 55], "can": [8, 14, 16, 20, 22, 30, 32, 38, 39, 40, 41], "canada": [13, 29, 53], "care": [43, 48], "carri": [16, 22, 32, 40], "case": [17, 23, 33, 34, 42], "catboost": 38, "categor": [16, 17, 22, 23, 27, 32, 33, 39, 46], "categori": [17, 23, 33], "censor": 47, "centr": 56, "certain": [17, 33], "cfa": 56, "chang": 36, "charact": [12, 18, 28], "characterist": 36, "cheatsheet": 8, "checklist": [12, 18], "choos": [15, 21, 31, 41], "chunk": 48, "churn": 47, "cite": 7, "citi": 34, "claim": 48, "class": [12, 18, 25, 26, 27, 35, 36, 37, 38, 39, 43, 45, 51, 56], "class_attend": [17, 23, 33], "class_weight": 36, "classif": [13, 19, 26, 29, 36, 45, 49, 52], "classifi": [13, 19, 27, 29, 34, 38, 50], "clearli": 40, "cluster": [41, 42, 52], "co": [1, 56], "code": [10, 56], "coeffici": [34, 39], "color": [53, 54, 55], "column": [8, 16, 17, 22, 23, 32, 33, 46], "columntransform": [17, 23, 33, 55], "com": 15, "combin": 38, "come": [14, 15, 20, 21, 30, 31], "command": 5, "comment": [13, 19, 29, 35, 36, 37, 41, 42, 43], "common": [16, 22, 32, 41], "commonli": 44, "commun": [12, 18, 48, 52], "compact": [16, 22, 32], "companion": 9, "complet": 43, "complex": [14, 20, 30], "complic": 46, "compon": 34, "comprehens": 55, "comput": [12, 18, 45, 52], "con": [15, 21, 31, 42, 52], "concept": [25, 48], "concern": 6, "concess": 56, "conclus": 49, "conda": 10, "conduct": 56, "confid": [34, 48], "confus": [36, 48], "consid": 47, "construct": 38, "content": 43, "context": 44, "continu": [13, 19, 29], "conveni": [17, 23, 33], "corpu": 49, "correct": 41, "correl": 39, "countri": [13, 29, 53], "countvector": [17, 23, 33], "cours": [1, 9, 11, 12, 18, 28, 49, 56], "cover": [43, 47, 49], "cox": 47, "cpsc": [1, 2, 3, 6, 8, 12, 18], "creat": [7, 13, 14, 17, 19, 20, 23, 29, 30, 33, 43, 49], "credit": 10, "cross": [14, 16, 20, 22, 25, 30, 32, 36, 40, 46, 54], "cross_val_scor": [14, 20, 30], "cross_valid": [14, 20, 30, 37], "csv": 8, "curs": [15, 21, 31], "curv": [36, 47], "custom": [41, 47], "cv": 35, "dai": 46, "data": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 48, 49, 50, 54], "datafram": [8, 17, 23, 33], "dataset": [7, 13, 16, 19, 22, 29, 32, 33, 34, 35, 36, 37, 45, 46, 48, 55], "date": [1, 46], "datetim": 46, "dbscan": 42, "deal": [17, 23, 33, 36], "debug": 10, "decis": [13, 15, 19, 21, 25, 26, 29, 31, 34, 39, 48, 54], "decisiontreeclassifi": [13, 19, 29, 38], "decreas": 36, "deep": [45, 46], "defin": 40, "definit": [12, 18, 28], "deliver": [1, 12, 18], "demo": [25, 26, 27, 40, 46, 49, 50], "demonstr": 36, "dendrogram": 42, "depend": 40, "deploi": 49, "deploy": [14, 20, 30, 49, 52], "descript": 56, "desktop": 5, "detail": [20, 36, 37, 42], "detect": 45, "df": 8, "did": [14, 16, 17, 20, 22, 23, 30, 32, 33, 36, 37, 43, 47, 48, 49], "differ": [16, 22, 32, 35, 36, 37, 39, 49, 52], "dimens": [15, 21, 31], "dimension": [15, 21, 31], "directori": 49, "discuss": [25, 27, 35, 36, 43, 44, 48, 49], "diseas": [12, 18, 28], "distanc": [15, 21, 31, 41], "distribut": 35, "do": [16, 17, 22, 27, 32, 33, 35, 36, 38, 39, 40, 48, 49], "document": [3, 8, 41], "doe": [13, 19, 20, 29, 34, 42, 48], "domain": 40, "drop": 8, "due": 1, "dummi": [26, 27, 50], "dummyclassifi": [13, 19, 29, 38, 46, 47], "dummyregressor": [13, 16, 19, 22, 29, 32, 37], "eda": [16, 22, 32, 36, 37, 49, 54], "effect": [38, 48], "elbow": 41, "element": 8, "elimin": 40, "embed": 44, "encod": [16, 17, 22, 23, 32, 33, 40, 46], "engin": [40, 46, 50, 52], "ensembl": [38, 52], "enter": 27, "environ": [10, 49], "equal": 48, "error": [14, 20, 30, 35, 36, 37, 43], "estim": [16, 22, 32, 38], "ethic": 52, "euclidean": [15, 21, 31], "eva": [12, 14, 18, 28, 30], "evalu": [36, 42, 43, 47, 52], "evalut": 36, "event": 47, "everyon": 47, "exactli": 34, "exam": [52, 56], "examin": [17, 23, 33, 37, 48, 52], "exampl": [12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 44, 47, 48, 50], "exercis": [13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 43, 45, 47, 53], "exhaust": 35, "experi": 48, "explain": [39, 48], "explan": [39, 48], "explor": [15, 21, 31, 41], "exploratori": [25, 27, 46, 54], "extract": [17, 23, 33, 46], "extractor": 45, "f1": 36, "failur": 42, "fair": 36, "fancier": 35, "farewel": 49, "faster": 8, "fastest": 8, "featur": [12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 27, 28, 29, 31, 32, 33, 34, 37, 39, 40, 43, 45, 46, 48, 50, 52], "feature_importances_": 39, "few": [36, 42, 48], "fictiti": [12, 18, 28], "figur": 7, "filter": [8, 43], "final": [13, 19, 29, 35, 41, 42, 43, 46, 52, 54, 56], "find": [15, 21, 31, 40], "first": [12, 16, 18, 22, 32], "fit": [13, 16, 19, 22, 29, 32, 38], "flatten": 45, "follow": [12, 13, 14, 18, 20, 25, 28, 29, 30, 41, 42, 43], "font": [53, 54, 55], "forecast": 46, "forest": [38, 39, 48], "format": [7, 8, 12, 18], "formul": 43, "forward": 40, "from": [8, 48, 50], "full": 49, "function": [8, 34, 37], "fundament": [14, 15, 20, 21, 25, 30, 31, 38, 52], "further": [46, 50], "futur": 46, "fuyi": 15, "gamma": [15, 21, 31], "garbag": 40, "gb": 48, "gener": [4, 6, 14, 15, 20, 21, 30, 31, 34, 38, 40], "geometr": [15, 21, 31], "get": 39, "git": [5, 10], "github": 5, "given": [12, 13, 18, 19, 28, 29], "global": 43, "goal": [14, 20, 30], "golden": [14, 16, 17, 20, 22, 23, 30, 32, 33], "good": [36, 48], "grade": [4, 6, 13, 18, 19, 29, 56], "gradescop": 7, "gradient": [38, 48], "grid": [35, 48], "gridsearchcv": [35, 37, 48], "group": [25, 36, 41], "guid": 52, "guidelin": [4, 6, 7], "ha": [12, 18, 28], "halv": 35, "handl": 36, "have": [38, 39, 48], "hazard": 47, "heatmap": 35, "help": [4, 40], "here": [14, 20, 30], "hierarch": 42, "home": 42, "homework": [7, 12, 18], "hot": [16, 22, 32, 40, 46], "hous": [12, 13, 16, 18, 22, 28, 29, 32, 33, 34, 55], "how": [4, 7, 13, 14, 15, 16, 19, 20, 21, 22, 27, 29, 30, 31, 32, 34, 38, 39, 40, 42, 48], "http": 15, "hyper": 35, "hyperparamet": [13, 15, 17, 19, 21, 23, 25, 29, 31, 33, 34, 35, 37, 38, 41, 52, 54], "i": [12, 14, 16, 17, 18, 20, 22, 23, 28, 30, 32, 33, 35, 36, 38, 39, 40, 41, 43, 44, 48, 49, 50], "iclick": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 45, 47, 56], "idea": [15, 21, 31, 36, 38, 40, 48], "identifi": [17, 23, 33, 39], "imag": [12, 18, 26, 28, 45], "imagenet": 45, "imbal": [36, 37, 38, 39], "import": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54], "improv": 50, "imput": [16, 22, 32, 43], "incorpor": [17, 23, 27, 33], "increas": 36, "index": 8, "inertia": 41, "info": 7, "inform": [39, 46], "initi": [41, 49], "inject": 38, "input": [12, 18, 28, 41], "instal": [5, 10], "instruct": [0, 7], "instructor": 1, "interact": 40, "intercept": 34, "interest": 48, "interim": [36, 39, 40, 46], "interpret": [34, 39, 49], "intra": 41, "intro": 43, "introduct": [8, 12, 18, 28, 39, 40, 41, 42, 44, 45, 48, 52], "intuit": 34, "involv": [46, 48], "issu": 48, "join": 15, "jupyt": [12, 18], "jupyterlab": 10, "k": [15, 16, 21, 22, 31, 32, 41, 42, 43], "kaplan": 47, "kei": [39, 48, 49], "kernel": [15, 21, 31], "kind": 38, "kneighborsclassifi": [15, 21, 26, 31], "knn": [26, 27], "label": [12, 18, 28, 41, 48], "lag": 46, "land": 56, "languag": 44, "larg": 35, "late": 7, "latitud": [13, 29, 53], "lda": 44, "learn": [1, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], "least": 34, "lectur": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 56], "let": [15, 16, 17, 21, 22, 23, 27, 31, 32, 33, 36, 37, 39, 48], "licens": [0, 1], "lightgbm": 38, "limit": [6, 34, 42], "line": 5, "linear": [34, 37, 39], "link": 1, "list": 9, "liver": [12, 18, 28], "ll": [14, 20, 30], "lo": [14, 16, 17, 20, 21, 22, 23, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 45, 46, 49], "load": 49, "local": 49, "localhost": 49, "logist": [34, 36, 45], "logisticregress": [36, 46, 47, 48], "longitud": [13, 29, 53], "look": [36, 41], "loop": 8, "loss": 48, "lower": 35, "mac": 5, "machin": [1, 12, 13, 14, 15, 18, 19, 20, 21, 25, 28, 29, 30, 31, 36, 41, 49], "maco": 10, "macro": 36, "magnitud": 34, "mai": 40, "main": [34, 43, 48], "make": [8, 34, 48], "make_column_transform": [17, 23, 33], "make_pipelin": [16, 22, 32], "mani": [17, 33, 35], "manual": 35, "mape": 37, "materi": [0, 1, 9], "matplotlib": 8, "matric": [17, 23, 33], "matrix": [36, 43], "matter": 20, "max_depth": [13, 19, 29], "mean": [37, 41, 42, 44, 48], "measur": 40, "media": 44, "meet": [12, 18, 28, 56], "meier": 47, "messag": [12, 18, 28, 42], "meta": 51, "method": [8, 27, 35, 40, 41], "metric": [36, 37, 52], "midterm": [41, 56], "might": 47, "min": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 29, 30, 31, 32, 33, 36, 39, 40, 41, 44, 45, 47, 48, 49], "minor": 36, "misc": [1, 9], "miscellan": 43, "mislead": 48, "ml": [12, 14, 15, 18, 20, 21, 25, 28, 30, 31, 36, 39, 48, 52], "model": [12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 44, 45, 47, 49, 50, 52, 54], "model_select": 35, "moment": 49, "month": 46, "more": [13, 15, 16, 17, 19, 20, 21, 22, 23, 29, 31, 32, 33, 34, 36, 37, 40, 42, 46], "most": 34, "motiv": [14, 15, 16, 20, 21, 22, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 48], "movi": 43, "mse": 37, "much": 35, "multi": [36, 45, 51], "multiclass": 52, "multipl": [15, 17, 21, 23, 31, 33, 37], "multipli": 8, "n_estim": 38, "n_iter": 35, "n_job": 35, "n_neighbor": [15, 21, 31], "name": [14, 20, 30, 37, 43], "natur": 44, "nearest": [15, 16, 21, 22, 31, 32, 41, 43], "need": [16, 22, 32, 35], "neg": 36, "neighbour": [15, 16, 21, 22, 31, 32, 43], "nest": 8, "netflix": 38, "network": 45, "neural": 45, "new": [48, 49], "next": [12, 18, 49], "nlp": [44, 52], "nn": [15, 21, 31], "non": [15, 17, 21, 23, 31, 33, 39], "notat": 8, "note": [8, 14, 30, 46, 54], "notebook": [12, 18], "now": 47, "number": [38, 41, 46], "numer": [39, 40], "numpi": 8, "object": [11, 13, 19, 29, 38, 44, 45, 46, 47, 48, 49], "observ": 36, "occasion": [16, 22, 32], "off": [14, 15, 20, 21, 30, 31, 38], "oh": [16, 17, 22, 23, 32, 33], "ok": [16, 17, 22, 23, 32, 33], "onc": 36, "one": [17, 23, 33, 40], "onehotencod": [17, 23, 33], "onli": [17, 23, 33, 47], "onlin": [1, 9], "oper": 36, "optim": [25, 35, 52], "option": [10, 15, 16, 21, 22, 31, 32, 35, 36, 38, 40, 47, 49], "ordin": [1, 16, 17, 22, 23, 27, 32, 33, 39, 56], "other": [8, 15, 21, 31, 37, 40, 41, 44, 46, 47, 48], "our": [7, 14, 16, 20, 22, 30, 32, 48, 49, 50], "out": [16, 22, 32, 40, 45, 48, 49], "outcom": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43], "outlin": [53, 54, 55], "output": 41, "over": [8, 15, 21, 31, 34, 36], "overfit": [14, 20, 30, 35], "oversampl": 36, "overview": [15, 21, 31, 36], "ovo": 51, "ovr": 51, "packag": [10, 46], "panda": 8, "pandas_profil": 37, "paper": [36, 38], "paradigm": [16, 22, 32], "paramet": [13, 19, 29, 34, 35, 36, 52], "parametr": [15, 21, 31], "pars": 46, "part": 52, "pass": 35, "patient": [12, 18, 28], "perfect": 41, "perhap": 48, "permutation_import": 39, "persona": [12, 18, 28], "piazza": 4, "pick": [14, 20, 30, 35], "pictur": [13, 14, 16, 19, 20, 22, 29, 30, 32], "piec": 48, "pipelin": [16, 22, 27, 32, 44], "plan": 42, "playground": [15, 21, 26, 31, 54], "plot": [8, 39, 41, 47], "point": [15, 21, 31, 36, 39, 41, 46], "polici": 6, "poll": 41, "popular": [12, 18, 28], "posit": 36, "posix": 46, "possibl": [17, 23, 33, 37, 41, 50], "post": 9, "pr": 36, "practic": [15, 19, 29, 31], "pre": 45, "precis": 36, "predict": [12, 13, 17, 18, 19, 28, 29, 33, 34, 38, 39, 43, 45, 47, 51, 53], "predict_proba": [34, 48], "predictor": 49, "prefer": 48, "prepar": [7, 52], "preprocess": [16, 17, 22, 23, 32, 33, 37, 44, 46, 48, 49, 52], "prerequisit": [12, 18], "preval": [12, 18, 28], "price": [12, 13, 18, 28, 29], "principl": 48, "prize": 38, "pro": [15, 21, 31, 42, 52], "probabl": [34, 35], "problem": [13, 14, 15, 16, 19, 20, 21, 22, 29, 30, 31, 32, 35, 40, 43, 46, 49, 50], "procedur": 36, "process": 44, "product": [12, 18, 28], "profil": 43, "program": [13, 19, 29], "project": 50, "properli": 27, "proport": 47, "python": [8, 9, 10, 12, 18], "q": 4, "qualiti": 40, "queri": [8, 15, 21, 31], "question": [4, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55], "quick": [15, 31], "quiz": [13, 19, 29], "quiz2": [13, 19, 29], "quot": 40, "r": 37, "random": [35, 38, 39, 48], "random_st": [14, 20, 30], "randomforestclassifi": [38, 47], "randomizedsearchcv": [35, 37], "rang": 35, "rate": 43, "raw": 34, "rbf": [15, 21, 26, 31], "re": 48, "read": [8, 13, 19, 29, 35, 45], "reader": 48, "real": [13, 29, 49, 53], "realist": [17, 23, 33], "reason": 6, "recal": 36, "recap": [13, 15, 19, 29, 31, 42, 47, 48, 53, 55], "receiv": 36, "recip": 49, "recommend": [12, 16, 18, 22, 32, 43, 52], "record": 56, "recurs": 40, "red": [53, 54, 55], "refer": [1, 9, 47], "reflect": [13, 14, 19, 20, 29, 30, 41, 42], "registr": [12, 18, 56], "regress": [13, 15, 19, 21, 29, 31, 34, 36, 37, 38, 45], "regressor": [15, 21, 31], "relat": [4, 13, 15, 19, 21, 29, 31, 48], "relev": [9, 36, 38, 40], "remark": 46, "rememb": 41, "remind": [13, 29, 43], "remov": 8, "renam": 8, "render": 49, "report": [7, 36], "repositori": 7, "represent": [17, 23, 33, 45], "request": 49, "requir": [12, 18, 49], "rescu": [14, 20, 30], "resourc": [9, 12, 18, 35, 36, 40, 41, 42, 43], "rest": 51, "result": [35, 48], "retail": 46, "reus": 48, "review": 49, "revis": 25, "rf": 48, "rfe": 40, "ridg": [34, 37], "ridgecv": 37, "right": 47, "rmse": 37, "roc": 36, "root": 37, "row": 8, "rule": [14, 16, 17, 20, 22, 23, 30, 32, 33], "run": [16, 22, 32, 48], "same": 8, "sampl": [36, 38, 41], "sauc": 41, "save": [12, 18, 28, 49], "scale": [12, 16, 18, 22, 27, 28, 32, 34, 39], "schedul": 1, "scheme": 56, "scikit": [14, 16, 17, 20, 22, 23, 30, 32, 33, 37], "score": [13, 14, 19, 20, 29, 30, 34, 35, 36, 37, 40, 41, 50], "search": [15, 21, 31, 35, 40, 48], "season": 46, "segment": 41, "select": [12, 13, 18, 28, 29, 40, 41, 42, 43, 52], "send": 49, "separ": [37, 39, 48], "seri": [8, 46, 52], "server": 49, "servic": 49, "set": [5, 10, 12, 14, 18, 20, 25, 30, 35, 36, 49], "set_config": [17, 23, 33], "shap": 39, "shape": [8, 42], "shaplei": 39, "short": 9, "should": [38, 43, 48], "show": [39, 48], "sigmoid": [34, 45], "sign": 34, "silhouett": 41, "similar": [15, 21, 31], "simpl": [14, 20, 30, 50], "simplefeatur": 39, "simpleimput": 27, "singl": [14, 20, 25, 30], "size": 8, "sklearn": [13, 16, 17, 19, 22, 23, 27, 29, 32, 33, 35, 36, 38, 39], "slowest": 8, "small": 48, "smote": 36, "social": 44, "softmax": 45, "softwar": [0, 45, 46], "solv": 35, "some": [13, 19, 29, 35, 36, 38, 40, 49], "sort": 8, "sort_valu": 8, "sourc": 7, "space": 46, "spaci": [44, 50], "spaghetti": 41, "spam": [12, 17, 18, 23, 28, 33], "spars": [17, 23, 33], "specif": [4, 40], "split": [14, 16, 20, 22, 25, 27, 30, 32, 36, 46, 54], "spotifi": [16, 22, 32, 35], "squar": 37, "stack": 38, "standardscal": [16, 22, 32], "statement": [12, 13, 18, 28, 29, 41, 42, 43], "statist": 49, "step": [13, 19, 25, 29, 44, 55], "strategi": [38, 51], "stratifi": 36, "strength": [34, 38], "structur": 49, "studi": 52, "style": [12, 18], "submiss": 7, "submit": 7, "success": 35, "summari": [8, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47], "supervis": [12, 13, 14, 15, 18, 19, 20, 21, 25, 28, 29, 30, 31, 41, 43, 49], "support": [15, 21, 31], "surviv": [47, 52], "svc": 36, "svm": [15, 21, 26, 31, 34], "syllabu": [1, 56], "syntax": [16, 17, 22, 23, 32, 33, 35], "synthet": 36, "system": [43, 52], "ta": [1, 56], "tabular": [13, 15, 19, 21, 29, 31, 49], "tackl": 37, "take": 42, "takeawai": 49, "target": [12, 13, 17, 18, 19, 23, 28, 29, 33, 37, 41], "task": 44, "teach": [1, 56], "team": [1, 56], "techniqu": [16, 22, 32, 36], "templat": 7, "tempor": 46, "tent": 1, "terminologi": [13, 19, 29, 45], "test": [5, 14, 20, 25, 30, 35, 46], "test_df": [14, 20, 30], "test_siz": [14, 20, 30], "text": [17, 23, 27, 33, 44, 50], "than": [17, 23, 33, 35, 40, 48], "thei": 38, "them": 8, "thi": [8, 12, 16, 17, 18, 22, 23, 25, 27, 28, 32, 33, 39, 48, 49], "thing": [16, 22, 32, 48], "threshold": 36, "time": [6, 12, 18, 28, 46, 47, 52], "tip": 52, "todai": [14, 16, 17, 20, 22, 23, 30, 32, 33, 36, 37, 48], "toi": [13, 17, 19, 23, 29, 33, 36, 44], "token": 44, "tool": 44, "topic": 44, "trade": [14, 15, 20, 21, 30, 31, 38], "tradeoff": [14, 20, 30, 36, 38], "tradit": [13, 19, 29, 46], "train": [12, 13, 14, 17, 18, 19, 20, 23, 28, 29, 30, 33, 34, 36, 45, 46, 48, 49], "train_df": [14, 20, 30], "train_siz": [14, 20, 30], "transfer": 45, "transform": [16, 17, 22, 23, 32, 33, 37, 40, 48], "transpar": [39, 49], "tree": [13, 19, 25, 29, 38, 39, 48, 54], "trend": 46, "true": [12, 18, 28, 41, 42, 43], "try": [16, 22, 27, 32, 37, 48, 49], "tune": [37, 41, 54], "tutori": [21, 53, 54, 55], "two": [17, 23, 33], "type": [12, 14, 18, 20, 28, 30, 36, 37, 39, 41, 46, 47, 48], "typic": [14, 20, 25, 30, 44], "u": 48, "ubc": 1, "ubuntu": 5, "under": 36, "underfit": [14, 20, 30], "undersampl": 36, "understand": 49, "unequ": 46, "unknown": [17, 23, 33], "unlabel": 41, "unseen": [12, 14, 18, 20, 28, 30], "unsupervis": [13, 19, 29, 41], "up": [5, 10, 12, 14, 15, 18, 20, 21, 30, 31, 48, 49], "updat": 7, "url": 8, "us": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 28, 29, 30, 31, 32, 33, 36, 37, 38, 40, 41, 44, 45, 48, 51, 53, 56], "usa": [13, 29, 53], "user": [5, 43], "usual": 40, "util": 43, "v": [2, 12, 13, 14, 15, 18, 19, 20, 21, 29, 30, 31, 36, 39, 41, 45, 49, 51], "valid": [14, 16, 20, 22, 25, 30, 32, 35, 36, 46, 54], "varianc": [14, 20, 30], "vector": [8, 15, 21, 31, 44], "video": [12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 28, 29, 30, 31, 32, 34, 36, 37, 38, 41, 42, 44], "view": [15, 17, 21, 23, 31, 33], "violat": [14, 20, 30], "virtual": 10, "vision": [45, 52], "visual": [9, 35, 48], "wai": [35, 40, 48], "waitlist": [12, 18], "want": [17, 23, 33, 39, 47], "warn": [13, 19, 29, 40], "watch": 48, "we": [8, 14, 16, 17, 20, 22, 23, 25, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48, 49], "weak": 38, "web": 49, "websit": [12, 18], "weight": [34, 36], "what": [5, 10, 12, 14, 16, 17, 18, 20, 22, 23, 28, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 47, 48, 49], "when": [8, 16, 22, 32, 35, 48], "where": [17, 23, 33, 47], "whether": [12, 18, 28], "which": [12, 13, 18, 28, 29, 36, 38, 41, 42, 43], "why": [10, 12, 17, 18, 20, 23, 28, 33, 35, 39, 40, 43, 45, 48], "window": [5, 10], "wise": 8, "without": 41, "word": [17, 23, 33, 44, 50], "work": [13, 19, 29, 38, 42, 48], "workflow": [12, 14, 20, 28, 30, 36], "would": [14, 20, 27, 30, 49], "wrapper": 51, "write": [13, 19, 29], "x": [12, 13, 18, 19, 28, 29, 37, 39, 48], "xgboost": 38, "y": [12, 13, 18, 19, 28, 29, 37, 39, 48], "ye": 47, "yield": 35, "you": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49], "your": [5, 12, 13, 18, 19, 25, 29, 48]}})