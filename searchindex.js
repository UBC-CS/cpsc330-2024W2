Search.setIndex({"alltitles": {"": [[26, "id1"]], "(Optional) Changing the data": [[38, "optional-changing-the-data"]], "(Optional) Evaluation": [[49, "optional-evaluation"]], "(Optional) Evaluation metrics for multi-class classification": [[38, "optional-evaluation-metrics-for-multi-class-classification"]], "(Optional) Example 1: Optimization bias": [[37, "optional-example-1-optimization-bias"]], "(Optional) Example 2: Optimization bias": [[37, "optional-example-2-optimization-bias"]], "(Optional) Fancier methods": [[37, "optional-fancier-methods"]], "(Optional) Fitting in boosted regression trees.": [[40, "optional-fitting-in-boosted-regression-trees"]], "(Optional) Forward or backward selection": [[42, "optional-forward-or-backward-selection"]], "(Optional) Macro average and weighted average": [[38, "optional-macro-average-and-weighted-average"]], "(Optional) Parametric vs non parametric": [[15, "optional-parametric-vs-non-parametric"], [22, "optional-parametric-vs-non-parametric"], [33, "optional-parametric-vs-non-parametric"]], "(Optional) Passing probability distributions to random search": [[37, "optional-passing-probability-distributions-to-random-search"]], "(Optional) Prediction in boosted regression trees": [[40, "optional-prediction-in-boosted-regression-trees"]], "(Optional) Problems with feature selection": [[42, "optional-problems-with-feature-selection"]], "(Optional) Search and score": [[42, "optional-search-and-score"]], "(Optional) Searching for optimal parameters with successive halving\u00b6": [[37, "optional-searching-for-optimal-parameters-with-successive-halving"]], "(Optional) Setting up a directory structure and environment": [[51, "optional-setting-up-a-directory-structure-and-environment"]], "(Optional) Some more details": [[38, "optional-some-more-details"]], "(Supervised) machine learning: popular definition": [[12, "supervised-machine-learning-popular-definition"], [19, "supervised-machine-learning-popular-definition"], [30, "supervised-machine-learning-popular-definition"]], "(iClicker) Exercise 14.1": [[42, "id1"]], "(iClicker) Exercise 21.1": [[49, "iclicker-exercise-21-1"]], "(iClicker) Exercise 21.2": [[49, "iclicker-exercise-21-2"]], "(iClicker) Exercise 4.1": [[22, "iclicker-exercise-4-1"], [33, "iclicker-exercise-4-1"]], "(iClicker) Exercise 4.1 https://join.iclicker.com/FUYI": [[15, "iclicker-exercise-4-1-https-join-iclicker-com-fuyi"]], "(iClicker) Exercise 4.2": [[22, "iclicker-exercise-4-2"], [33, "iclicker-exercise-4-2"]], "(iClicker) Exercise 4.2 https://join.iclicker.com/FUYI": [[15, "iclicker-exercise-4-2-https-join-iclicker-com-fuyi"]], "(iClicker) Exercise 5.1": [[16, "iclicker-exercise-5-1"], [23, "iclicker-exercise-5-1"], [34, "iclicker-exercise-5-1"]], "(iClicker) Exercise 5.2": [[16, "iclicker-exercise-5-2"], [23, "iclicker-exercise-5-2"], [34, "iclicker-exercise-5-2"]], "(iClicker) Exercise 5.3": [[16, "iclicker-exercise-5-3"], [23, "iclicker-exercise-5-3"], [34, "iclicker-exercise-5-3"]], "(iClicker) Exercise 6.1": [[17, "iclicker-exercise-6-1"], [24, "iclicker-exercise-6-1"], [35, "iclicker-exercise-6-1"]], "(iClicker) Exercise 6.2": [[17, "iclicker-exercise-6-2"], [24, "iclicker-exercise-6-2"], [35, "iclicker-exercise-6-2"]], "(iClicker) Exercise 7.1": [[18, "iclicker-exercise-7-1"], [36, "iclicker-exercise-7-1"]], "(iClicker) Exercise 7.2": [[18, "iclicker-exercise-7-2"], [36, "iclicker-exercise-7-2"]], "(iClicker) Exercise 8.1": [[37, "iclicker-exercise-8-1"]], "(iClicker) Midterm poll": [[43, "iclicker-midterm-poll"]], "15.1 Select all of the following statements which are True (iClicker)": [[43, "select-all-of-the-following-statements-which-are-true-iclicker"]], "15.2 Select all of the following statements which are True (iClicker)": [[43, "id1"]], "15.3 Select all of the following statements which are True (iClicker)": [[43, "id3"]], "16.1 Select all of the following statements which are True (iClicker)": [[44, "select-all-of-the-following-statements-which-are-true-iclicker"]], "16.2 Select all of the following statements which are True (iClicker)": [[44, "id2"]], "16.3 Select all of the following statements which are True": [[44, "select-all-of-the-following-statements-which-are-true"]], "330 vs. 340": [[51, "vs-340"]], "<font color='red'>Question 1</font>": [[55, "question-1"], [56, "question-1"]], "<font color='red'>Question 2: Baseline model</font>": [[56, "question-2-baseline-model"]], "<font color='red'>Question 2</font>": [[55, "question-2"]], "<font color='red'>Question 3: Decision tree</font>": [[56, "question-3-decision-tree"]], "<font color='red'>Question 3</font>": [[55, "question-3"]], "<font color='red'>Question 4: Hyperparameter tuning</font>": [[56, "question-4-hyperparameter-tuning"]], "<font color='red'>Question 4</font>": [[55, "question-4"]], "<font color='red'>Question 5: Cross-validation</font>": [[56, "question-5-cross-validation"]], "<font color='red'>Question 6: Hyperparameters playground</font>": [[56, "question-6-hyperparameters-playground"]], "<font color='red'>Recap Questions</font>": [[55, "recap-questions"]], "<font color='red'>Recap/comprehension questions</font>": [[57, "recap-comprehension-questions"]], "A few comments on PR curve": [[38, "a-few-comments-on-pr-curve"]], "A few comments on clustering evaluation": [[44, "a-few-comments-on-clustering-evaluation"]], "AP score": [[38, "ap-score"]], "AP vs. F1-score": [[38, "ap-vs-f1-score"]], "API on the localhost": [[51, "api-on-the-localhost"]], "About this course": [[12, "about-this-course"], [19, "about-this-course"]], "About this document": [[8, "about-this-document"]], "Academic concessions": [[58, "academic-concessions"]], "Accessing homework assignments": [[7, "accessing-homework-assignments"]], "Accessing learned parameters": [[18, "accessing-learned-parameters"], [36, "accessing-learned-parameters"]], "Activity": [[12, "activity"], [19, "activity"]], "Activity (~5 mins)": [[41, "activity-5-mins"], [41, "id3"]], "Activity: Context and word meaning": [[46, "activity-context-and-word-meaning"]], "Activity: Discuss the following questions in your group": [[26, "activity-discuss-the-following-questions-in-your-group"]], "Activity: How can you measure quality of the data? (~3 mins)": [[42, "activity-how-can-you-measure-quality-of-the-data-3-mins"]], "Activity: explaining GridSearchCV (15 min)": [[50, "activity-explaining-gridsearchcv-15-min"]], "Adding/removing columns with [] and drop()": [[8, "adding-removing-columns-with-and-drop"]], "Adding/removing rows with [] and drop()": [[8, "adding-removing-rows-with-and-drop"]], "Additional submission instructions": [[7, "additional-submission-instructions"]], "Addressing class imbalance": [[38, "addressing-class-imbalance"]], "Advantages of RandomizedSearchCV": [[37, "advantages-of-randomizedsearchcv"], [37, "id1"]], "Alternative and more compact syntax: make_pipeline": [[16, "alternative-and-more-compact-syntax-make-pipeline"], [23, "alternative-and-more-compact-syntax-make-pipeline"], [34, "alternative-and-more-compact-syntax-make-pipeline"]], "Alternative methods for scaling": [[28, "alternative-methods-for-scaling"]], "Alternative terminology for examples, features, targets, and training": [[13, "alternative-terminology-for-examples-features-targets-and-training"], [20, "alternative-terminology-for-examples-features-targets-and-training"], [31, "alternative-terminology-for-examples-features-targets-and-training"]], "An effective strategy": [[40, "an-effective-strategy"]], "An example from a project": [[52, "an-example-from-a-project"]], "An example of a bootstrap samples": [[40, "an-example-of-a-bootstrap-samples"]], "An introduction to Grid Search": [[50, "an-introduction-to-grid-search"]], "Analogy-based algorithms in practice": [[15, "analogy-based-algorithms-in-practice"], [33, "analogy-based-algorithms-in-practice"]], "Analogy-based models": [[15, "analogy-based-models"], [33, "analogy-based-models"]], "Announcements": [[12, "announcements"], [13, "announcements"], [14, "announcements"], [16, "announcements"], [17, "announcements"], [18, "announcements"], [36, "announcements"]], "Appendix A: Demo of feature engineering for text data": [[52, null]], "Appendix B: Multi-class, meta-strategies": [[53, null]], "Applying feature transformations": [[39, "applying-feature-transformations"], [50, "applying-feature-transformations"]], "Applying functions to a dataframe with df.apply() and df.applymap()": [[8, "applying-functions-to-a-dataframe-with-df-apply-and-df-applymap"]], "Approach 1: Only consider the examples where \u201cChurn\u201d=Yes": [[49, "approach-1-only-consider-the-examples-where-churn-yes"]], "Approach 2: Assume everyone churns right now": [[49, "approach-2-assume-everyone-churns-right-now"]], "Approach 3: Survival analysis": [[49, "approach-3-survival-analysis"]], "Approach from all angles": [[50, "approach-from-all-angles"]], "Are we doing better with class_weight=\"balanced\"?": [[38, "are-we-doing-better-with-class-weight-balanced"]], "Area under the curve (AUC)": [[38, "area-under-the-curve-auc"]], "Assessing on the test set": [[26, "assessing-on-the-test-set"]], "Assignments": [[58, "assignments"]], "Attention": [[13, null], [13, null], [15, null], [20, null], [20, null], [22, null], [31, null], [31, null], [31, null], [33, null]], "Attribution": [[50, "attribution"]], "Automated hyperparameter optimization": [[37, "automated-hyperparameter-optimization"], [37, "id3"]], "Averaging": [[40, "averaging"]], "Bad range for hyperparameters": [[37, "bad-range-for-hyperparameters"]], "Bag of words (BOW) representation": [[17, "bag-of-words-bow-representation"], [24, "bag-of-words-bow-representation"], [35, "bag-of-words-bow-representation"]], "Bag-of-words model": [[52, "bag-of-words-model"]], "Baseline": [[38, "baseline"], [41, "baseline"]], "Baseline Approaches": [[45, "baseline-approaches"]], "Baseline model": [[26, "baseline-model"]], "Baselines": [[13, "baselines"], [20, "baselines"], [31, "baselines"], [40, "baselines"]], "Baselines [video]": [[13, "baselines-video"], [20, "baselines-video"], [31, "baselines-video"]], "Basic text preprocessing [video]": [[46, "basic-text-preprocessing-video"]], "Better features usually help more than a better model.": [[42, "better-features-usually-help-more-than-a-better-model"]], "Beyond error rate in recommendation systems": [[45, "beyond-error-rate-in-recommendation-systems"]], "Bias vs variance tradeoff": [[14, "bias-vs-variance-tradeoff"], [21, "bias-vs-variance-tradeoff"], [32, "bias-vs-variance-tradeoff"]], "Big picture and datasets": [[13, "big-picture-and-datasets"], [20, "big-picture-and-datasets"], [31, "big-picture-and-datasets"]], "Big picture and motivation": [[14, "big-picture-and-motivation"], [21, "big-picture-and-motivation"], [32, "big-picture-and-motivation"]], "Books": [[1, "books"]], "Bottom-up explanations": [[50, "bottom-up-explanations"]], "Break (5 min)": [[8, "break-5-min"], [12, "break-5-min"], [13, "break-5-min"], [14, "break-5-min"], [15, "break-5-min"], [16, "break-5-min"], [17, "break-5-min"], [19, "break-5-min"], [20, "break-5-min"], [21, "break-5-min"], [22, "break-5-min"], [24, "break-5-min"], [31, "break-5-min"], [32, "break-5-min"], [33, "break-5-min"], [34, "break-5-min"], [35, "break-5-min"], [42, "break-5-min"], [46, "break-5-min"], [47, "break-5-min"], [49, "break-5-min"], [50, "break-5-min"]], "Break (~15 min)": [[51, "break-15-min"]], "Broadcasting in numpy": [[8, "broadcasting-in-numpy"]], "Building a model": [[51, "building-a-model"]], "Building a supervise machine learning model": [[12, "building-a-supervise-machine-learning-model"], [19, "building-a-supervise-machine-learning-model"], [30, "building-a-supervise-machine-learning-model"]], "Building and deploying a web app": [[51, "building-and-deploying-a-web-app"]], "Building decision trees with sklearn": [[13, "building-decision-trees-with-sklearn"], [20, "building-decision-trees-with-sklearn"], [31, "building-decision-trees-with-sklearn"]], "Building user profiles": [[45, "building-user-profiles"]], "CPSC 330 Documents": [[3, null]], "CPSC 330 Python notes": [[8, null]], "CPSC 330 grading policies": [[6, null]], "CPSC 330 vs. 340": [[12, "cpsc-330-vs-340"], [19, "cpsc-330-vs-340"]], "CPSC 330 vs. CPSC 340": [[2, null]], "Can we learn without targets?": [[43, "can-we-learn-without-targets"]], "Can we use this feature in the model?": [[16, "can-we-use-this-feature-in-the-model"], [23, "can-we-use-this-feature-in-the-model"], [34, "can-we-use-this-feature-in-the-model"]], "Cases where it\u2019s OK to break the golden rule": [[17, "cases-where-it-s-ok-to-break-the-golden-rule"], [24, "cases-where-it-s-ok-to-break-the-golden-rule"], [35, "cases-where-it-s-ok-to-break-the-golden-rule"]], "CatBoost": [[40, "catboost"]], "Categorical features": [[28, "categorical-features"], [41, "categorical-features"]], "Categorical features [video]": [[16, "categorical-features-video"], [23, "categorical-features-video"], [34, "categorical-features-video"]], "Categorical features with only two possible categories": [[17, "categorical-features-with-only-two-possible-categories"], [24, "categorical-features-with-only-two-possible-categories"], [35, "categorical-features-with-only-two-possible-categories"]], "Censoring and survival analysis": [[49, "censoring-and-survival-analysis"]], "Centre for Accessibility (CfA) Exam Accommodations": [[58, "centre-for-accessibility-cfa-exam-accommodations"]], "Changing the training procedure": [[38, "changing-the-training-procedure"]], "Characters in this course?": [[12, "characters-in-this-course"], [19, "characters-in-this-course"], [30, "characters-in-this-course"]], "Checklist for you before next class": [[12, "checklist-for-you-before-next-class"], [19, "checklist-for-you-before-next-class"]], "Choosing K [video]": [[43, "choosing-k-video"]], "Choosing n_neighbors": [[15, "choosing-n-neighbors"], [22, "choosing-n-neighbors"], [33, "choosing-n-neighbors"]], "Citing sources": [[7, "citing-sources"]], "Class imbalance in training sets": [[38, "class-imbalance-in-training-sets"]], "Class meetings": [[58, "class-meetings"]], "Classification report": [[38, "classification-report"]], "Classification vs. Regression": [[13, "classification-vs-regression"], [20, "classification-vs-regression"], [31, "classification-vs-regression"]], "Classification with KNeighborsClassifier": [[27, "classification-with-kneighborsclassifier"]], "Clustering": [[54, "clustering"]], "Clustering Activity (~5 mins)": [[43, "clustering-activity-5-mins"]], "Clustering motivation [video]": [[43, "clustering-motivation-video"]], "Clustering: Input and (possible) output": [[43, "clustering-input-and-possible-output"]], "Code of conduct": [[58, "code-of-conduct"]], "Coefficients and intercept": [[18, "coefficients-and-intercept"], [36, "coefficients-and-intercept"]], "ColumnTransformer example": [[17, "columntransformer-example"], [24, "columntransformer-example"], [35, "columntransformer-example"]], "ColumnTransformer on the California housing dataset": [[35, "columntransformer-on-the-california-housing-dataset"], [57, "columntransformer-on-the-california-housing-dataset"]], "ColumnTransformer: Transformed data": [[17, "columntransformer-transformed-data"], [24, "columntransformer-transformed-data"], [35, "columntransformer-transformed-data"]], "Coming up \u2026": [[14, "coming-up"], [21, "coming-up"], [32, "coming-up"]], "Coming up:": [[15, "coming-up"], [22, "coming-up"], [33, "coming-up"]], "Command-line git": [[5, "command-line-git"]], "Common applications": [[43, "common-applications"]], "Common preprocessing techniques": [[16, "common-preprocessing-techniques"], [23, "common-preprocessing-techniques"], [34, "common-preprocessing-techniques"]], "Communication": [[54, "communication"]], "Communications": [[12, "communications"], [19, "communications"]], "Completing the utility matrix with content-based filtering": [[45, "completing-the-utility-matrix-with-content-based-filtering"]], "Components of a linear classifier": [[18, "components-of-a-linear-classifier"], [36, "components-of-a-linear-classifier"]], "Concepts then labels, not the other way around": [[50, "concepts-then-labels-not-the-other-way-around"]], "Concepts we revised in this demo": [[26, "concepts-we-revised-in-this-demo"]], "Conclusion & farewell": [[51, "conclusion-farewell"]], "Confidence and predict_proba (20 min)": [[50, "confidence-and-predict-proba-20-min"]], "Confusing and perhaps misleading visualization of results": [[50, "confusing-and-perhaps-misleading-visualization-of-results"]], "Confusion matrix": [[38, "confusion-matrix"]], "Confusion matrix with cross-validation": [[38, "confusion-matrix-with-cross-validation"]], "Cons of k-NNs for supervised learning": [[15, "cons-of-k-nns-for-supervised-learning"], [22, "cons-of-k-nns-for-supervised-learning"], [33, "cons-of-k-nns-for-supervised-learning"]], "Content-based filtering": [[45, "content-based-filtering"]], "Convenient make_column_transformer syntax": [[17, "convenient-make-column-transformer-syntax"], [24, "convenient-make-column-transformer-syntax"], [35, "convenient-make-column-transformer-syntax"]], "Course Learning Objectives": [[11, null]], "Course co-ordinator": [[1, "course-co-ordinator"], [58, "course-co-ordinator"]], "Course description": [[58, "course-description"]], "Course format": [[12, "course-format"], [19, "course-format"]], "Course review / conclusion (~20 min)": [[51, "course-review-conclusion-20-min"]], "Course website": [[12, "course-website"], [19, "course-website"]], "Cox proportional hazards model": [[49, "cox-proportional-hazards-model"]], "Create X and y": [[13, "create-x-and-y"], [20, "create-x-and-y"], [31, "create-x-and-y"]], "Create a classifier object": [[13, "create-a-classifier-object"], [20, "create-a-classifier-object"], [31, "create-a-classifier-object"]], "Create a column transformer": [[17, "create-a-column-transformer"], [24, "create-a-column-transformer"], [35, "create-a-column-transformer"]], "Creating train_df and test_df": [[14, "creating-train-df-and-test-df"], [21, "creating-train-df-and-test-df"], [32, "creating-train-df-and-test-df"]], "Creating utility matrix": [[45, "creating-utility-matrix"]], "Credit": [[10, "credit"]], "Cross validation with different metrics": [[38, "cross-validation-with-different-metrics"]], "Cross-validation": [[26, "cross-validation"], [48, "cross-validation"], [48, "id4"]], "Cross-validation [video]": [[14, "cross-validation-video"], [21, "cross-validation-video"], [32, "cross-validation-video"]], "Cross-validation to the rescue!!": [[14, "cross-validation-to-the-rescue"], [21, "cross-validation-to-the-rescue"], [32, "cross-validation-to-the-rescue"]], "Cross-validation using scikit-learn": [[14, "cross-validation-using-scikit-learn"], [21, "cross-validation-using-scikit-learn"], [32, "cross-validation-using-scikit-learn"]], "Curse of dimensionality": [[15, "curse-of-dimensionality"], [22, "curse-of-dimensionality"], [33, "curse-of-dimensionality"]], "Customer churn": [[49, "customer-churn"]], "Customer segmentation": [[43, "customer-segmentation"]], "DBSCAN [video]": [[44, "dbscan-video"]], "DBSCAN introduction": [[44, "dbscan-introduction"]], "DBSCAN: failure cases": [[44, "dbscan-failure-cases"], [44, "id1"]], "Data": [[17, "data"], [18, "data"], [24, "data"], [35, "data"], [36, "data"], [40, "data"], [41, "data"], [41, "id1"]], "Data Splitting [video]": [[14, "data-splitting-video"], [21, "data-splitting-video"], [32, "data-splitting-video"]], "Data and main approaches": [[45, "data-and-main-approaches"]], "Data and splitting": [[28, "data-and-splitting"]], "Data exploration": [[43, "data-exploration"]], "Data splitting": [[26, "data-splitting"], [56, "data-splitting"]], "Dataframe summaries": [[8, "dataframe-summaries"]], "Dataset": [[47, "dataset"], [50, "dataset"]], "Dataset [video]": [[39, "dataset-video"]], "Dataset for demonstration": [[38, "dataset-for-demonstration"]], "Dataset, splitting, and baseline": [[16, "dataset-splitting-and-baseline"], [23, "dataset-splitting-and-baseline"], [34, "dataset-splitting-and-baseline"]], "Datasets": [[7, "datasets"]], "Dealing with class imbalance [video]": [[38, "dealing-with-class-imbalance-video"]], "Dealing with unknown categories": [[17, "dealing-with-unknown-categories"], [24, "dealing-with-unknown-categories"], [35, "dealing-with-unknown-categories"]], "Debugging": [[10, "debugging"]], "Decision boundaries playground": [[27, "decision-boundaries-playground"]], "Decision boundary": [[13, "decision-boundary"], [20, "decision-boundary"], [31, "decision-boundary"]], "Decision boundary for max_depth=1": [[13, "decision-boundary-for-max-depth-1"], [20, "decision-boundary-for-max-depth-1"], [31, "decision-boundary-for-max-depth-1"]], "Decision boundary for max_depth=2": [[13, "decision-boundary-for-max-depth-2"], [20, "decision-boundary-for-max-depth-2"], [31, "decision-boundary-for-max-depth-2"]], "Decision boundary for max_depth=5": [[13, "decision-boundary-for-max-depth-5"], [20, "decision-boundary-for-max-depth-5"], [31, "decision-boundary-for-max-depth-5"]], "Decision boundary of SVMs": [[15, "decision-boundary-of-svms"], [22, "decision-boundary-of-svms"], [33, "decision-boundary-of-svms"]], "Decision boundary of logistic regression": [[18, "decision-boundary-of-logistic-regression"], [36, "decision-boundary-of-logistic-regression"]], "Decision tree algorithm": [[13, "decision-tree-algorithm"], [20, "decision-tree-algorithm"], [31, "decision-tree-algorithm"]], "Decision tree feature importances": [[41, "decision-tree-feature-importances"]], "Decision tree for regression problems": [[13, "decision-tree-for-regression-problems"], [20, "decision-tree-for-regression-problems"], [31, "decision-tree-for-regression-problems"]], "Decision tree model": [[26, "decision-tree-model"]], "Decision tree with max_depth=1": [[13, "decision-tree-with-max-depth-1"], [20, "decision-tree-with-max-depth-1"], [31, "decision-tree-with-max-depth-1"]], "Decision tree with max_depth=3": [[13, "decision-tree-with-max-depth-3"], [20, "decision-tree-with-max-depth-3"], [31, "decision-tree-with-max-depth-3"]], "Decision trees [video]": [[13, "decision-trees-video"], [20, "decision-trees-video"], [31, "decision-trees-video"]], "Decision trees with continuous features": [[13, "decision-trees-with-continuous-features"], [20, "decision-trees-with-continuous-features"], [31, "decision-trees-with-continuous-features"]], "DecisionTreeClassifier baseline": [[40, "decisiontreeclassifier-baseline"]], "DecisionTreeClassifier on quiz2 grade prediction toy dataset": [[13, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"], [20, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"], [31, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"]], "Decisions involve a few key pieces": [[50, "decisions-involve-a-few-key-pieces"]], "Decreasing the threshold": [[38, "decreasing-the-threshold"]], "Deep learning": [[48, "deep-learning"]], "Deep learning software": [[47, "deep-learning-software"]], "Deliverable due dates (tentative)": [[1, "deliverable-due-dates-tentative"]], "Demo of creating a new web service": [[51, "demo-of-creating-a-new-web-service"]], "Demo of feature engineering with numeric features": [[42, "demo-of-feature-engineering-with-numeric-features"]], "Demo: A more complicated dataset": [[48, "demo-a-more-complicated-dataset"]], "Demo: Deploying moment classification model": [[51, "demo-deploying-moment-classification-model"]], "Demo: Model interpretation of linear classifiers": [[29, "demo-model-interpretation-of-linear-classifiers"]], "Dendrogram": [[44, "dendrogram"]], "Deploying the API on a server (not covered)": [[51, "deploying-the-api-on-a-server-not-covered"]], "Deployment (Not examinable)": [[54, "deployment-not-examinable"]], "Difference between Statistics and Machine Learning": [[51, "difference-between-statistics-and-machine-learning"]], "Different models": [[41, "different-models"]], "Different range for hyperparameters yields better results!": [[37, "different-range-for-hyperparameters-yields-better-results"]], "Different scoring functions with cross_validate": [[39, "different-scoring-functions-with-cross-validate"]], "Dimensions in ML problems": [[15, "dimensions-in-ml-problems"], [22, "dimensions-in-ml-problems"], [33, "dimensions-in-ml-problems"]], "Discuss the following questions in your group": [[26, "discuss-the-following-questions-in-your-group"]], "Discussion": [[51, "discussion"]], "Discussion question": [[46, "discussion-question"]], "Discussion questions": [[28, "discussion-questions"]], "Discussion questions:": [[50, "discussion-questions"]], "Distance between feature vectors": [[15, "distance-between-feature-vectors"], [22, "distance-between-feature-vectors"], [33, "distance-between-feature-vectors"]], "Do we actually want to use certain features for prediction?": [[17, "do-we-actually-want-to-use-certain-features-for-prediction"], [35, "do-we-actually-want-to-use-certain-features-for-prediction"]], "Do we have class imbalance?": [[40, "do-we-have-class-imbalance"], [41, "do-we-have-class-imbalance"]], "Do we have correlated features?": [[41, "do-we-have-correlated-features"]], "Document clustering": [[43, "document-clustering"]], "Domain-specific transformations": [[42, "domain-specific-transformations"]], "Dummy Classifier": [[28, "dummy-classifier"]], "Dummy classifier": [[52, "dummy-classifier"]], "Dummy model": [[27, "dummy-model"]], "DummyClassifier": [[13, "dummyclassifier"], [20, "dummyclassifier"], [31, "dummyclassifier"], [48, "dummyclassifier"], [49, "dummyclassifier"]], "DummyClassifier baseline": [[40, "dummyclassifier-baseline"]], "DummyClassifier on quiz2 grade prediction toy dataset": [[13, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"], [20, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"], [31, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"]], "DummyRegressor": [[13, "dummyregressor"], [20, "dummyregressor"], [31, "dummyregressor"], [39, "dummyregressor"]], "EDA": [[16, "eda"], [23, "eda"], [34, "eda"], [38, "eda"], [39, "eda"]], "EDA: Exploratory Data Analysis": [[56, "eda-exploratory-data-analysis"]], "Encoding text data": [[17, "encoding-text-data"], [24, "encoding-text-data"], [35, "encoding-text-data"]], "Encoding time as a number": [[48, "encoding-time-as-a-number"]], "Encoding time of day as a categorical feature": [[48, "encoding-time-of-day-as-a-categorical-feature"]], "Ensembles": [[54, "ensembles"]], "Equally good": [[50, "equally-good"]], "Ethics": [[54, "ethics"]], "Euclidean distance": [[15, "euclidean-distance"], [22, "euclidean-distance"], [33, "euclidean-distance"]], "Evaluating DBSCAN clusters": [[44, "evaluating-dbscan-clusters"]], "Evaluation": [[45, "evaluation"], [45, "id3"]], "Evaluation metrics": [[54, "evaluation-metrics"]], "Evaluation metrics for binary classification: Motivation": [[38, "evaluation-metrics-for-binary-classification-motivation"]], "Evalution metrics overview": [[38, "evalution-metrics-overview"]], "Examining learned coefficients": [[29, "examining-learned-coefficients"]], "Examining the preprocessed data": [[39, "examining-the-preprocessed-data"], [50, "examining-the-preprocessed-data"]], "Examining the vocabulary": [[29, "examining-the-vocabulary"]], "Example": [[18, "example"], [36, "example"], [40, "example"]], "Example 1: Predicting whether a patient has a liver disease or not": [[12, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"], [19, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"], [30, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"]], "Example 1: What is \u201ccorrect\u201d grouping?": [[43, "example-1-what-is-correct-grouping"]], "Example 1: quiz 2 grade prediction": [[13, "example-1-quiz-2-grade-prediction"], [20, "example-1-quiz-2-grade-prediction"], [31, "example-1-quiz-2-grade-prediction"]], "Example 2: Predicting country using the longitude and latitude": [[13, "example-2-predicting-country-using-the-longitude-and-latitude"], [31, "example-2-predicting-country-using-the-longitude-and-latitude"]], "Example 2: Predicting the label of a given image": [[12, "example-2-predicting-the-label-of-a-given-image"], [19, "example-2-predicting-the-label-of-a-given-image"], [30, "example-2-predicting-the-label-of-a-given-image"]], "Example 3: Predicting housing prices": [[12, "example-3-predicting-housing-prices"], [19, "example-3-predicting-housing-prices"], [30, "example-3-predicting-housing-prices"]], "Example showing how can we interpret coefficients of scaled features.": [[41, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"]], "Example: Is \u201cRelevance\u201d clearly defined?": [[42, "example-is-relevance-clearly-defined"]], "Example: Predict whether a message is spam or not": [[12, "example-predict-whether-a-message-is-spam-or-not"], [19, "example-predict-whether-a-message-is-spam-or-not"], [30, "example-predict-whether-a-message-is-spam-or-not"]], "Example: Supervised vs unsupervised learning": [[43, "example-supervised-vs-unsupervised-learning"]], "Example: Tabular data for grade prediction": [[13, "example-tabular-data-for-grade-prediction"], [20, "example-tabular-data-for-grade-prediction"], [31, "example-tabular-data-for-grade-prediction"]], "Example: Tabular data for the housing price prediction": [[13, "example-tabular-data-for-the-housing-price-prediction"], [31, "example-tabular-data-for-the-housing-price-prediction"]], "Example: class_weight parameter of sklearn LogisticRegression": [[38, "example-class-weight-parameter-of-sklearn-logisticregression"]], "Example: k-nearest neighbours on the Spotify dataset": [[16, "example-k-nearest-neighbours-on-the-spotify-dataset"], [23, "example-k-nearest-neighbours-on-the-spotify-dataset"], [34, "example-k-nearest-neighbours-on-the-spotify-dataset"]], "Examples": [[12, "examples"], [19, "examples"], [30, "examples"]], "Exercise 17.1 Select all of the following statements which are True (iClicker)": [[45, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 17.2 Select all of the following statements which are True (iClicker)": [[45, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 2.1 Select all of the following statements which are examples of supervised machine learning": [[13, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"], [31, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"]], "Exercise 2.3": [[20, "exercise-2-3"]], "Exercise 2.4": [[13, "exercise-2-4"], [31, "exercise-2-4"]], "Exercise 8.2": [[37, "exercise-8-2"]], "Exercise: Predicting country using the longitude and latitude": [[55, "exercise-predicting-country-using-the-longitude-and-latitude"]], "Exhaustive grid search: sklearn.model_selection.GridSearchCV": [[37, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"]], "Explaining a prediction": [[41, "explaining-a-prediction"]], "Explanation 1": [[50, "explanation-1"]], "Explanation 2": [[50, "explanation-2"]], "Exploratory Data Analysis": [[26, "exploratory-data-analysis"]], "Exploratory data analysis": [[28, "exploratory-data-analysis"], [48, "exploratory-data-analysis"]], "Extracting BOW features using scikit-learn": [[17, "extracting-bow-features-using-scikit-learn"], [24, "extracting-bow-features-using-scikit-learn"], [35, "extracting-bow-features-using-scikit-learn"]], "Extracting date and time information": [[48, "extracting-date-and-time-information"]], "F1-score": [[38, "f1-score"]], "Faster method: vectorize the loop over rows": [[8, "faster-method-vectorize-the-loop-over-rows"]], "Fastest method: broadcasting": [[8, "fastest-method-broadcasting"]], "Feature crosses for one-hot encoded features": [[42, "feature-crosses-for-one-hot-encoded-features"]], "Feature engineering": [[48, "feature-engineering"]], "Feature engineering and selection": [[54, "feature-engineering-and-selection"]], "Feature engineering for date/time columns": [[48, "feature-engineering-for-date-time-columns"]], "Feature engineering: Encoding date/time as feature(s)": [[48, "feature-engineering-encoding-date-time-as-feature-s"]], "Feature engineering: Motivation": [[42, "feature-engineering-motivation"]], "Feature importances": [[41, "feature-importances"], [54, "feature-importances"]], "Feature importances in linear models": [[41, "feature-importances-in-linear-models"], [41, "id2"]], "Feature interactions and feature crosses": [[42, "feature-interactions-and-feature-crosses"]], "Feature names of transformed data": [[39, "feature-names-of-transformed-data"]], "Feature selection: Introduction and motivation": [[42, "feature-selection-introduction-and-motivation"]], "Feature transformations and the golden rule": [[16, "feature-transformations-and-the-golden-rule"], [23, "feature-transformations-and-the-golden-rule"], [34, "feature-transformations-and-the-golden-rule"]], "Feature types": [[39, "feature-types"], [39, "id1"], [50, "feature-types"]], "Feature vectors": [[15, "feature-vectors"], [33, "feature-vectors"]], "Figures": [[7, "figures"]], "Filtering a dataframe with [] and df.query()": [[8, "filtering-a-dataframe-with-and-df-query"]], "Final comments and summary": [[37, "final-comments-and-summary"], [45, "final-comments-and-summary"]], "Final comments, summary, and reflection": [[13, "final-comments-summary-and-reflection"], [20, "final-comments-summary-and-reflection"], [31, "final-comments-summary-and-reflection"], [43, "final-comments-summary-and-reflection"], [44, "final-comments-summary-and-reflection"]], "Final exam": [[58, "final-exam"]], "Final exam preparation: guiding questions": [[54, null]], "Final note": [[56, "final-note"]], "Final remarks": [[48, "final-remarks"]], "Finding the distances to a query point": [[15, "finding-the-distances-to-a-query-point"], [22, "finding-the-distances-to-a-query-point"], [33, "finding-the-distances-to-a-query-point"]], "Finding the nearest neighbour": [[15, "finding-the-nearest-neighbour"], [22, "finding-the-nearest-neighbour"], [33, "finding-the-nearest-neighbour"]], "First deliverables": [[12, "first-deliverables"], [19, "first-deliverables"]], "Forecasting further into the future": [[48, "forecasting-further-into-the-future"]], "Forecasting further into the future on a retail dataset": [[48, "forecasting-further-into-the-future-on-a-retail-dataset"]], "Formulating the problem of recommender systems": [[45, "formulating-the-problem-of-recommender-systems"]], "GB better than RF": [[50, "gb-better-than-rf"]], "Garbage in, garbage out.": [[42, "garbage-in-garbage-out"]], "General advice on finding relevant features": [[42, "general-advice-on-finding-relevant-features"]], "General guidelines": [[6, "general-guidelines"]], "General idea": [[40, "general-idea"]], "General idea of k-nearest neighbours algorithm": [[15, "general-idea-of-k-nearest-neighbours-algorithm"], [22, "general-idea-of-k-nearest-neighbours-algorithm"], [33, "general-idea-of-k-nearest-neighbours-algorithm"]], "General idea of search and score methods": [[42, "general-idea-of-search-and-score-methods"]], "General questions": [[4, "general-questions"]], "Generalization [video]": [[14, "generalization-video"], [21, "generalization-video"], [32, "generalization-video"]], "Generalization: Fundamental goal of ML": [[14, "generalization-fundamental-goal-of-ml"], [21, "generalization-fundamental-goal-of-ml"], [32, "generalization-fundamental-goal-of-ml"]], "Generalizing to more features": [[18, "generalizing-to-more-features"], [36, "generalizing-to-more-features"]], "Generalizing to unseen data": [[14, "generalizing-to-unseen-data"], [21, "generalizing-to-unseen-data"], [32, "generalizing-to-unseen-data"]], "Geometric view of tabular data and dimensions": [[15, "geometric-view-of-tabular-data-and-dimensions"], [22, "geometric-view-of-tabular-data-and-dimensions"], [33, "geometric-view-of-tabular-data-and-dimensions"]], "Git": [[10, "git"]], "GitHub Desktop": [[5, "github-desktop"]], "Global average baseline": [[45, "global-average-baseline"]], "Golden rule violation: Example 1": [[14, "golden-rule-violation-example-1"], [32, "golden-rule-violation-example-1"]], "Golden rule violation: Example 2": [[14, "golden-rule-violation-example-2"], [32, "golden-rule-violation-example-2"]], "Grades": [[19, "grades"]], "Gradient boosted trees [video]": [[40, "gradient-boosted-trees-video"]], "Gradient boosting in sklearn": [[40, "gradient-boosting-in-sklearn"]], "Grading concerns: time limit": [[6, "grading-concerns-time-limit"]], "Grading scheme": [[58, "grading-scheme"]], "Grading-related questions": [[4, "grading-related-questions"]], "Handling imbalance": [[38, "handling-imbalance"]], "Here is the workflow we\u2019ll generally follow.": [[14, "here-is-the-workflow-we-ll-generally-follow"], [21, "here-is-the-workflow-we-ll-generally-follow"], [32, "here-is-the-workflow-we-ll-generally-follow"]], "Hierarchical clustering [video]": [[44, "hierarchical-clustering-video"]], "Homework info & submission guidelines": [[7, null]], "How are we making predictions?": [[18, "how-are-we-making-predictions"], [36, "how-are-we-making-predictions"]], "How can we avoid violating golden rule?": [[14, "how-can-we-avoid-violating-golden-rule"], [21, "how-can-we-avoid-violating-golden-rule"], [32, "how-can-we-avoid-violating-golden-rule"]], "How can we get feature importances for non sklearn models?": [[41, "how-can-we-get-feature-importances-for-non-sklearn-models"]], "How do they work?": [[40, "how-do-they-work"]], "How do we carry out feature selection?": [[42, "how-do-we-carry-out-feature-selection"]], "How does fit work?": [[13, "how-does-fit-work"], [13, "id2"], [20, "how-does-fit-work"], [31, "how-does-fit-work"], [31, "id2"]], "How does it work?": [[44, "how-does-it-work"], [50, "how-does-it-work"]], "How does logistic regression calculate these probabilities?": [[18, "how-does-logistic-regression-calculate-these-probabilities"], [36, "how-does-logistic-regression-calculate-these-probabilities"]], "How does predict work?": [[13, "how-does-predict-work"], [20, "how-does-predict-work"], [31, "how-does-predict-work"]], "How to approximate generalization error?": [[14, "how-to-approximate-generalization-error"], [21, "how-to-approximate-generalization-error"], [32, "how-to-approximate-generalization-error"]], "How to ask for help": [[4, null]], "How to carry out cross-validation?": [[16, "how-to-carry-out-cross-validation"], [23, "how-to-carry-out-cross-validation"], [34, "how-to-carry-out-cross-validation"]], "How to choose n_neighbors?": [[15, "how-to-choose-n-neighbors"], [22, "how-to-choose-n-neighbors"], [33, "how-to-choose-n-neighbors"]], "How to pick a model that would generalize better?": [[14, "how-to-pick-a-model-that-would-generalize-better"], [21, "how-to-pick-a-model-that-would-generalize-better"], [32, "how-to-pick-a-model-that-would-generalize-better"]], "How to submit": [[7, "how-to-submit"]], "How would you do it properly? Enter sklearn pipelines!!": [[28, "how-would-you-do-it-properly-enter-sklearn-pipelines"]], "Hyperparameter alpha of Ridge": [[18, "hyperparameter-alpha-of-ridge"], [36, "hyperparameter-alpha-of-ridge"]], "Hyperparameter optimization": [[26, "hyperparameter-optimization"], [54, "hyperparameter-optimization"]], "Hyperparameter optimization motivation": [[37, "hyperparameter-optimization-motivation"]], "Hyperparameter tuning for the number of clusters": [[43, "hyperparameter-tuning-for-the-number-of-clusters"]], "Hyperparameters of SVM": [[15, "hyperparameters-of-svm"], [22, "hyperparameters-of-svm"], [33, "hyperparameters-of-svm"]], "Hyperparameters: the problem": [[37, "hyperparameters-the-problem"]], "Identify the transformations we want to apply": [[17, "identify-the-transformations-we-want-to-apply"], [24, "identify-the-transformations-we-want-to-apply"], [35, "identify-the-transformations-we-want-to-apply"]], "Image classification using KNNs and SVM RBF": [[27, "image-classification-using-knns-and-svm-rbf"]], "ImageNet": [[47, "imagenet"]], "Import": [[52, "import"]], "Importance of scaling": [[18, "importance-of-scaling"], [36, "importance-of-scaling"]], "Important hyperparameters": [[40, "important-hyperparameters"]], "Important hyperparameters of CountVectorizer": [[17, "important-hyperparameters-of-countvectorizer"], [24, "important-hyperparameters-of-countvectorizer"], [35, "important-hyperparameters-of-countvectorizer"]], "Important links": [[1, "important-links"]], "Important points to remember": [[43, "important-points-to-remember"]], "Imports": [[12, "imports"], [13, "imports"], [14, "imports"], [15, "imports"], [15, "id1"], [16, "imports"], [17, "imports"], [18, "imports"], [19, "imports"], [20, "imports"], [21, "imports"], [22, "imports"], [23, "imports"], [24, "imports"], [26, "imports"], [27, "imports"], [28, "imports"], [29, "imports"], [30, "imports"], [31, "imports"], [32, "imports"], [33, "imports"], [34, "imports"], [35, "imports"], [36, "imports"], [37, "imports"], [38, "imports"], [39, "imports"], [40, "imports"], [41, "imports"], [42, "imports"], [43, "imports"], [44, "imports"], [45, "imports"], [46, "imports"], [47, "imports"], [48, "imports"], [49, "imports"], [50, "imports"], [51, "imports"], [54, "imports"], [55, "imports"], [56, "imports"]], "Imports and LO": [[37, "imports-and-lo"], [39, "imports-and-lo"], [47, "imports-and-lo"], [48, "imports-and-lo"]], "Imports and LOs": [[38, "imports-and-los"], [51, "imports-and-los"]], "Imports and learning outcomes": [[43, "imports-and-learning-outcomes"]], "Imports, Announcements, LOs": [[31, "imports-announcements-los"]], "Imports, Announcements, and LO": [[24, "imports-announcements-and-lo"], [35, "imports-announcements-and-lo"], [36, "imports-announcements-and-lo"]], "Imports, LOs": [[14, "imports-los"], [16, "imports-los"], [21, "imports-los"], [23, "imports-los"], [32, "imports-los"], [34, "imports-los"], [41, "imports-los"]], "Imports, and LO": [[17, "imports-and-lo"], [18, "imports-and-lo"]], "Imports, announcements, LOs": [[40, "imports-announcements-los"]], "Imports, announcements, and LOs": [[22, "imports-announcements-and-los"], [33, "imports-announcements-and-los"]], "Imputation": [[16, "imputation"], [23, "imputation"], [34, "imputation"]], "Imputation and scaling [video]": [[16, "imputation-and-scaling-video"], [23, "imputation-and-scaling-video"], [34, "imputation-and-scaling-video"]], "Incorporating ordinal feature class_attendance": [[17, "incorporating-ordinal-feature-class-attendance"], [24, "incorporating-ordinal-feature-class-attendance"], [35, "incorporating-ordinal-feature-class-attendance"]], "Incorporating text features": [[28, "incorporating-text-features"]], "Increasing the threshold": [[38, "increasing-the-threshold"]], "Indexing Dataframes": [[8, "indexing-dataframes"]], "Indexing cheatsheet": [[8, "indexing-cheatsheet"]], "Inertia": [[43, "inertia"]], "Initial analysis, EDA, preprocessing": [[51, "initial-analysis-eda-preprocessing"]], "Initialization of K-Means": [[43, "initialization-of-k-means"]], "Inject randomness in the classifier construction": [[40, "inject-randomness-in-the-classifier-construction"]], "Input data": [[12, "input-data"], [19, "input-data"], [30, "input-data"]], "Input features X and target y": [[12, "input-features-x-and-target-y"], [19, "input-features-x-and-target-y"], [30, "input-features-x-and-target-y"]], "Installing Python packages": [[10, "installing-python-packages"]], "Instructional Material": [[0, "instructional-material"]], "Instructors": [[1, "instructors"]], "Interesting to you != useful to the reader (aka it\u2019s not about you)": [[50, "interesting-to-you-useful-to-the-reader-aka-it-s-not-about-you"]], "Interim summary": [[38, "interim-summary"], [41, "interim-summary"], [42, "interim-summary"], [48, "interim-summary"]], "Interpretation of coefficients": [[18, "interpretation-of-coefficients"], [36, "interpretation-of-coefficients"]], "Interpretation of coefficients in linear models": [[18, "interpretation-of-coefficients-in-linear-models"], [36, "interpretation-of-coefficients-in-linear-models"]], "Interpreting coefficients of numeric features": [[41, "interpreting-coefficients-of-numeric-features"]], "Introduction": [[44, "introduction"], [54, "introduction"]], "Introduction to NLP": [[54, "introduction-to-nlp"]], "Introduction to computer vision": [[47, "introduction-to-computer-vision"]], "Introduction to neural networks": [[47, "introduction-to-neural-networks"]], "Introduction to pandas": [[8, "introduction-to-pandas"]], "Introduction to unsupervised learning": [[43, "introduction-to-unsupervised-learning"]], "Is it possible to further improve the scores?": [[52, "is-it-possible-to-further-improve-the-scores"]], "Is stratifying a good idea?": [[38, "is-stratifying-a-good-idea"]], "Is this a realistic representation of text data?": [[17, "is-this-a-realistic-representation-of-text-data"], [24, "is-this-a-realistic-representation-of-text-data"], [35, "is-this-a-realistic-representation-of-text-data"]], "Is this misleading?": [[50, "is-this-misleading"]], "Is \u201cRelevance\u201d clearly defined?": [[42, "is-relevance-clearly-defined"], [42, "id2"], [42, "id3"], [42, "id4"], [42, "id5"], [42, "id6"], [42, "id7"]], "K-Means algorithm": [[43, "k-means-algorithm"]], "K-Means clustering [video]": [[43, "k-means-clustering-video"]], "K-Means example": [[43, "k-means-example"]], "K-Means limitations": [[44, "k-means-limitations"]], "K-Means limitations: Shape of K-Means clusters": [[44, "k-means-limitations-shape-of-k-means-clusters"]], "K-Means recap": [[44, "k-means-recap"]], "K-Means: failure case 1": [[44, "k-means-failure-case-1"]], "K-Means: failure case 2": [[44, "k-means-failure-case-2"]], "K-Means: failure case 3": [[44, "k-means-failure-case-3"]], "Kaplan-Meier survival curve": [[49, "kaplan-meier-survival-curve"]], "Key point": [[41, "key-point"]], "LDA topics in social media": [[46, "lda-topics-in-social-media"]], "LICENSE": [[0, null]], "Labeled vs. Unlabeled data": [[43, "labeled-vs-unlabeled-data"]], "Lag-based features": [[48, "lag-based-features"], [48, "id5"]], "Land acknowledgement": [[58, "land-acknowledgement"]], "Large datasets solve many of these problems": [[37, "large-datasets-solve-many-of-these-problems"]], "Late submissions": [[7, "late-submissions"]], "Learned coefficients associated with all features": [[18, "learned-coefficients-associated-with-all-features"], [36, "learned-coefficients-associated-with-all-features"]], "Learned model": [[26, "learned-model"]], "Learning git": [[5, "learning-git"]], "Learning objectives": [[46, "learning-objectives"], [47, "learning-objectives"], [48, "learning-objectives"], [49, "learning-objectives"], [50, "learning-objectives"], [51, "learning-objectives"]], "Learning outcomes": [[12, "learning-outcomes"], [13, "learning-outcomes"], [14, "learning-outcomes"], [15, "learning-outcomes"], [16, "learning-outcomes"], [17, "learning-outcomes"], [18, "learning-outcomes"], [19, "learning-outcomes"], [20, "learning-outcomes"], [21, "learning-outcomes"], [22, "learning-outcomes"], [23, "learning-outcomes"], [24, "learning-outcomes"], [30, "learning-outcomes"], [31, "learning-outcomes"], [32, "learning-outcomes"], [33, "learning-outcomes"], [34, "learning-outcomes"], [35, "learning-outcomes"], [36, "learning-outcomes"], [37, "learning-outcomes"], [38, "learning-outcomes"], [39, "learning-outcomes"], [41, "learning-outcomes"], [42, "learning-outcomes"], [43, "learning-outcomes"], [44, "learning-outcomes"]], "Learning outcomes <a name=\"lo\"></a>": [[45, "learning-outcomes"]], "Least confident cases": [[18, "least-confident-cases"], [36, "least-confident-cases"]], "Lecture 10: Regression metrics": [[39, null]], "Lecture 12: Ensembles": [[40, null]], "Lecture 13: Feature importances and model transparency": [[41, null]], "Lecture 14: Feature engineering and feature selection": [[42, null]], "Lecture 15: K-Means Clustering": [[43, null]], "Lecture 16: More Clustering": [[44, null]], "Lecture 17: Recommender Systems": [[45, null]], "Lecture 18: Introduction to natural language processing": [[46, null]], "Lecture 19: Multi-class classification and introduction to computer vision": [[47, null]], "Lecture 1: Course Introduction": [[12, null], [19, null], [30, null]], "Lecture 20: Time series": [[48, null]], "Lecture 21: Survival analysis": [[49, null]], "Lecture 22: Communication": [[50, null]], "Lecture 24: Deployment and conclusion": [[51, null]], "Lecture 2: Terminology, Baselines, Decision Trees": [[13, null], [20, null], [31, null]], "Lecture 3: ML Fundamentals Class Demo": [[26, null]], "Lecture 3: Machine Learning Fundamentals": [[14, null], [21, null], [32, null]], "Lecture 4: Class demo": [[27, null]], "Lecture 4: k-Nearest Neighbours and SVM RBFs": [[15, null], [22, null], [33, null]], "Lecture 5 and 6: Class demo": [[28, null]], "Lecture 5: Preprocessing and sklearn pipelines": [[16, null], [23, null], [34, null]], "Lecture 6: sklearn ColumnTransformer and Text Features": [[17, null], [24, null], [35, null]], "Lecture 7: Linear Models": [[18, null], [36, null]], "Lecture 8: Hyperparameter Optimization and Optimization Bias": [[37, null]], "Lecture 9: Classification metrics": [[38, null]], "Lecture and homework format: Jupyter notebooks": [[12, "lecture-and-homework-format-jupyter-notebooks"], [19, "lecture-and-homework-format-jupyter-notebooks"]], "Lecture learning objectives": [[40, "lecture-learning-objectives"]], "Lecture plan and learning outcomes": [[44, "lecture-plan-and-learning-outcomes"]], "Lecture recordings": [[58, "lecture-recordings"]], "Lecture schedule (tentative)": [[1, "lecture-schedule-tentative"]], "Lecture style": [[12, "lecture-style"], [19, "lecture-style"]], "Lectures 7: Class demo": [[29, null]], "Let\u2019s do it on our housing data": [[16, "let-s-do-it-on-our-housing-data"], [23, "let-s-do-it-on-our-housing-data"], [34, "let-s-do-it-on-our-housing-data"]], "Let\u2019s examine the transformed data": [[17, "let-s-examine-the-transformed-data"], [24, "let-s-examine-the-transformed-data"], [35, "let-s-examine-the-transformed-data"]], "Let\u2019s explore SVM RBFs": [[15, "let-s-explore-svm-rbfs"], [22, "let-s-explore-svm-rbfs"], [33, "let-s-explore-svm-rbfs"]], "Let\u2019s first run our baseline model DummyRegressor": [[16, "let-s-first-run-our-baseline-model-dummyregressor"], [23, "let-s-first-run-our-baseline-model-dummyregressor"], [34, "let-s-first-run-our-baseline-model-dummyregressor"]], "Let\u2019s identify feature types": [[41, "let-s-identify-feature-types"]], "Let\u2019s look at all the scores at once": [[38, "let-s-look-at-all-the-scores-at-once"]], "Let\u2019s separate X and y": [[39, "let-s-separate-x-and-y"], [41, "let-s-separate-x-and-y"], [50, "let-s-separate-x-and-y"]], "Let\u2019s try KNN on this data": [[28, "let-s-try-knn-on-this-data"]], "Let\u2019s try a linear model: Ridge": [[39, "let-s-try-a-linear-model-ridge"]], "Let\u2019s try cross-validation with our pipeline": [[16, "let-s-try-cross-validation-with-our-pipeline"], [23, "let-s-try-cross-validation-with-our-pipeline"], [34, "let-s-try-cross-validation-with-our-pipeline"]], "License": [[1, "license"]], "LightGBM": [[40, "lightgbm"]], "Limitations of linear models": [[18, "limitations-of-linear-models"], [36, "limitations-of-linear-models"]], "Linear SVM": [[18, "linear-svm"], [36, "linear-svm"]], "Linear models [video]": [[18, "linear-models-video"], [36, "linear-models-video"]], "Linear regression": [[18, "linear-regression"], [36, "linear-regression"]], "Lists of resources": [[9, "lists-of-resources"]], "Loading our saved model": [[51, "loading-our-saved-model"]], "Logistic regression [video]": [[18, "logistic-regression-video"], [36, "logistic-regression-video"]], "Logistic regression intuition": [[18, "logistic-regression-intuition"], [36, "logistic-regression-intuition"]], "Logistic regression on the cities data": [[18, "logistic-regression-on-the-cities-data"], [36, "logistic-regression-on-the-cities-data"]], "Logistic regression with flattened representation of images": [[47, "logistic-regression-with-flattened-representation-of-images"]], "LogisticRegression": [[48, "logisticregression"], [49, "logisticregression"]], "MAPE": [[39, "mape"]], "ML and decision-making (5 min)": [[50, "ml-and-decision-making-5-min"]], "ML fairness activity (~5 mins)": [[38, "ml-fairness-activity-5-mins"]], "ML fundamentals": [[54, "ml-fundamentals"]], "Mac Users": [[5, "mac-users"]], "Machine learning workflow": [[12, "machine-learning-workflow"], [30, "machine-learning-workflow"], [38, "machine-learning-workflow"]], "Magnitude of the coefficients": [[18, "magnitude-of-the-coefficients"], [36, "magnitude-of-the-coefficients"]], "Main hyperparameter of logistic regression": [[18, "main-hyperparameter-of-logistic-regression"], [36, "main-hyperparameter-of-logistic-regression"]], "Main hyperparameters": [[18, "main-hyperparameters"], [36, "main-hyperparameters"]], "Main issues in ML-related communication": [[50, "main-issues-in-ml-related-communication"]], "Manual hyperparameter optimization": [[37, "manual-hyperparameter-optimization"]], "Mean intra-cluster distance (a)": [[43, "mean-intra-cluster-distance-a"]], "Mean nearest-cluster distance (b)": [[43, "mean-nearest-cluster-distance-b"]], "Mean squared error (MSE)": [[39, "mean-squared-error-mse"]], "Meet Eva (a fictitious persona)!": [[12, "meet-eva-a-fictitious-persona"], [19, "meet-eva-a-fictitious-persona"], [30, "meet-eva-a-fictitious-persona"]], "Method 1: The Elbow method": [[43, "method-1-the-elbow-method"]], "Method 2: The Silhouette method": [[43, "method-2-the-silhouette-method"]], "Midterms": [[58, "midterms"]], "Misc": [[1, "misc"], [9, "misc"]], "Miscellaneous comments on content-based filtering": [[45, "miscellaneous-comments-on-content-based-filtering"]], "Model building": [[39, "model-building"], [51, "model-building"]], "Model building on the dataset": [[29, "model-building-on-the-dataset"]], "Model complexity and training error": [[14, "model-complexity-and-training-error"], [21, "model-complexity-and-training-error"], [32, "model-complexity-and-training-error"]], "Model deployment": [[51, "model-deployment"], [51, "id1"]], "Model interpretability beyond linear models": [[41, "model-interpretability-beyond-linear-models"]], "Model predictions on unseen data": [[12, "model-predictions-on-unseen-data"], [19, "model-predictions-on-unseen-data"], [30, "model-predictions-on-unseen-data"]], "Model transparency and interpretation": [[51, "model-transparency-and-interpretation"]], "Model-based selection": [[42, "model-based-selection"]], "Modeling": [[28, "modeling"]], "More comments on tackling class imbalance": [[39, "more-comments-on-tackling-class-imbalance"]], "More details": [[21, "more-details"]], "More details on DBSCAN": [[44, "more-details-on-dbscan"]], "More on feature transformations": [[17, "more-on-feature-transformations"], [24, "more-on-feature-transformations"], [35, "more-on-feature-transformations"]], "More on k-NNs [video]": [[15, "more-on-k-nns-video"], [22, "more-on-k-nns-video"], [33, "more-on-k-nns-video"]], "More terminology [video]": [[13, "more-terminology-video"], [20, "more-terminology-video"], [31, "more-terminology-video"]], "More than one ordinal columns?": [[17, "more-than-one-ordinal-columns"], [24, "more-than-one-ordinal-columns"], [35, "more-than-one-ordinal-columns"]], "Most confident cases": [[18, "most-confident-cases"], [36, "most-confident-cases"]], "Most negative review": [[29, "most-negative-review"]], "Most positive review": [[29, "most-positive-review"]], "Motivating example": [[18, "motivating-example"], [36, "motivating-example"]], "Motivation": [[37, "motivation"], [48, "motivation"], [50, "motivation"]], "Motivation [video]": [[40, "motivation-video"]], "Motivation and big picture [video]": [[16, "motivation-and-big-picture-video"], [23, "motivation-and-big-picture-video"], [34, "motivation-and-big-picture-video"]], "Motivation and context": [[46, "motivation-and-context"]], "Motivation and distances [video]": [[15, "motivation-and-distances-video"], [22, "motivation-and-distances-video"], [33, "motivation-and-distances-video"]], "Movie features": [[45, "movie-features"]], "Multi-class classification": [[47, "multi-class-classification"]], "Multiclass classification and computer vision": [[54, "multiclass-classification-and-computer-vision"]], "Multiple transformations in a transformer": [[17, "multiple-transformations-in-a-transformer"], [24, "multiple-transformations-in-a-transformer"], [35, "multiple-transformations-in-a-transformer"]], "NOTE:": [[8, "note"]], "New ideas in small chunks": [[50, "new-ideas-in-small-chunks"]], "No-loop method: make them the same size, and multiply element-wise": [[8, "no-loop-method-make-them-the-same-size-and-multiply-element-wise"]], "Note": [[14, null], [14, null], [32, null], [32, null], [48, null]], "Number of trees and fundamental trade-off": [[40, "number-of-trees-and-fundamental-trade-off"]], "Numpy array shapes": [[8, "numpy-array-shapes"]], "Numpy arrays": [[8, "numpy-arrays"]], "OHE with many categories": [[17, "ohe-with-many-categories"], [35, "ohe-with-many-categories"]], "Object detection": [[47, "object-detection"]], "Observations": [[38, "observations"]], "One Vs. One approach": [[53, "one-vs-one-approach"]], "One Vs. One prediction": [[53, "one-vs-one-prediction"]], "One vs. Rest": [[53, "one-vs-rest"]], "One-hot encoding (OHE)": [[16, "one-hot-encoding-ohe"], [23, "one-hot-encoding-ohe"], [34, "one-hot-encoding-ohe"]], "One-hot encoding of the month": [[48, "one-hot-encoding-of-the-month"]], "One-hot encoding seasons": [[48, "one-hot-encoding-seasons"]], "OneHotEncoder and sparse features": [[17, "onehotencoder-and-sparse-features"], [24, "onehotencoder-and-sparse-features"], [35, "onehotencoder-and-sparse-features"]], "Online courses": [[1, "online-courses"], [9, "online-courses"]], "Operating point": [[38, "operating-point"]], "Optimization bias of hyper-parameter learning": [[37, "optimization-bias-of-hyper-parameter-learning"]], "Optimization bias of parameter learning": [[37, "optimization-bias-of-parameter-learning"]], "Optimization bias on the Spotify dataset": [[37, "optimization-bias-on-the-spotify-dataset"]], "Optimization bias/Overfitting of the validation set": [[37, "optimization-bias-overfitting-of-the-validation-set"]], "Optional readings and resources": [[37, "optional-readings-and-resources"]], "Ordinal encoding (occasionally recommended)": [[16, "ordinal-encoding-occasionally-recommended"], [23, "ordinal-encoding-occasionally-recommended"], [34, "ordinal-encoding-occasionally-recommended"]], "Ordinal features": [[28, "ordinal-features"], [41, "ordinal-features"]], "Other applications": [[43, "other-applications"]], "Other approaches / what did we not cover?": [[49, "other-approaches-what-did-we-not-cover"]], "Other commonly used preprocessing steps": [[46, "other-commonly-used-preprocessing-steps"]], "Other possible preprocessing?": [[39, "other-possible-preprocessing"]], "Other software package": [[48, "other-software-package"]], "Other tools for preprocessing": [[46, "other-tools-for-preprocessing"]], "Other typical NLP tasks": [[46, "other-typical-nlp-tasks"]], "Other useful arguments of KNeighborsClassifier": [[15, "other-useful-arguments-of-kneighborsclassifier"], [22, "other-useful-arguments-of-kneighborsclassifier"], [33, "other-useful-arguments-of-kneighborsclassifier"]], "Other ways to search": [[42, "other-ways-to-search"]], "Our typical supervised learning set up is as follows:": [[14, "our-typical-supervised-learning-set-up-is-as-follows"], [21, "our-typical-supervised-learning-set-up-is-as-follows"], [32, "our-typical-supervised-learning-set-up-is-as-follows"]], "Outline": [[55, "outline"], [56, "outline"], [57, "outline"]], "Over confident cases": [[18, "over-confident-cases"], [36, "over-confident-cases"]], "Overfitting": [[14, "overfitting"], [21, "overfitting"], [32, "overfitting"]], "Overfitting of the validation data": [[37, "overfitting-of-the-validation-data"]], "Overfitting of the validation error": [[37, "overfitting-of-the-validation-error"]], "Oversampling": [[38, "oversampling"]], "Overview": [[15, "overview"], [22, "overview"], [33, "overview"]], "POSIX time feature": [[48, "posix-time-feature"]], "PR curves for logistic regression and SVC": [[38, "pr-curves-for-logistic-regression-and-svc"]], "Pandas DataFrames": [[8, "pandas-dataframes"]], "Pandas Series": [[8, "pandas-series"]], "Parameters": [[13, "parameters"], [20, "parameters"], [31, "parameters"]], "Parameters and hyperparameters: Summary": [[13, "parameters-and-hyperparameters-summary"], [20, "parameters-and-hyperparameters-summary"], [31, "parameters-and-hyperparameters-summary"]], "Parsing datetimes": [[48, "parsing-datetimes"]], "Part 1": [[54, "part-1"]], "Part 2": [[54, "part-2"]], "Piazza-specific Q&A guidelines": [[4, "piazza-specific-q-a-guidelines"]], "Pipelines": [[16, "pipelines"], [23, "pipelines"], [34, "pipelines"]], "Playground": [[15, "playground"], [33, "playground"]], "Playground (in tutorial)": [[22, "playground-in-tutorial"]], "Plotting with matplotlib": [[8, "plotting-with-matplotlib"]], "Practice exercises": [[20, "practice-exercises"], [31, "practice-exercises"]], "Precision": [[38, "precision"]], "Precision and recall: toy example": [[38, "precision-and-recall-toy-example"]], "Precision, recall, f1 score": [[38, "precision-recall-f1-score"]], "Precision-recall curve": [[38, "precision-recall-curve"], [38, "id1"]], "Precision/Recall tradeoff": [[38, "precision-recall-tradeoff"]], "Predicting on unseen data using the trained model": [[12, "predicting-on-unseen-data-using-the-trained-model"], [19, "predicting-on-unseen-data-using-the-trained-model"], [30, "predicting-on-unseen-data-using-the-trained-model"]], "Predicting probability scores [video]": [[18, "predicting-probability-scores-video"], [36, "predicting-probability-scores-video"]], "Predicting with learned weights": [[18, "predicting-with-learned-weights"], [36, "predicting-with-learned-weights"]], "Prediction": [[49, "prediction"]], "Prediction of linear regression": [[18, "prediction-of-linear-regression"], [36, "prediction-of-linear-regression"]], "Prediction with learned parameters": [[18, "prediction-with-learned-parameters"], [36, "prediction-with-learned-parameters"]], "Predictions": [[47, "predictions"]], "Preferences in LogisticRegression": [[50, "preferences-in-logisticregression"]], "Preparation": [[7, "preparation"]], "Preprocessing": [[17, "preprocessing"], [24, "preprocessing"], [35, "preprocessing"], [48, "preprocessing"], [54, "preprocessing"]], "Preprocessing the targets?": [[17, "preprocessing-the-targets"], [24, "preprocessing-the-targets"], [35, "preprocessing-the-targets"]], "Prevalence of ML": [[12, "prevalence-of-ml"], [19, "prevalence-of-ml"], [30, "prevalence-of-ml"]], "Principles of effective communication": [[50, "principles-of-effective-communication"]], "Principles of good explanations (~15 min)": [[50, "principles-of-good-explanations-15-min"]], "Problem formulation": [[45, "problem-formulation"]], "Problem: Different transformations on different columns": [[16, "problem-different-transformations-on-different-columns"], [23, "problem-different-transformations-on-different-columns"], [34, "problem-different-transformations-on-different-columns"]], "Problems with exhaustive grid search": [[37, "problems-with-exhaustive-grid-search"]], "Problems with single train/validation split": [[14, "problems-with-single-train-validation-split"], [21, "problems-with-single-train-validation-split"], [32, "problems-with-single-train-validation-split"]], "Pros of k-NNs for supervised learning": [[15, "pros-of-k-nns-for-supervised-learning"], [22, "pros-of-k-nns-for-supervised-learning"], [33, "pros-of-k-nns-for-supervised-learning"]], "Pros, cons, parameters and hyperparameters of different ML models": [[54, "pros-cons-parameters-and-hyperparameters-of-different-ml-models"]], "Python and Conda": [[10, "python-and-conda"]], "Python requirements/resources": [[12, "python-requirements-resources"], [19, "python-requirements-resources"]], "Python resources": [[9, "python-resources"]], "Question": [[15, "question"], [22, "question"], [33, "question"]], "Question for you": [[44, "question-for-you"]], "Question for you to ponder on": [[29, "question-for-you-to-ponder-on"]], "Questions for class discussion": [[45, "questions-for-class-discussion"]], "Questions for class discussion (hyperparameter optimization)": [[37, "questions-for-class-discussion-hyperparameter-optimization"]], "Quick recap": [[15, "quick-recap"], [33, "quick-recap"]], "RF better than GB": [[50, "rf-better-than-gb"]], "RFE algorithm": [[42, "rfe-algorithm"]], "R^2 (not in detail)": [[39, "r-2-not-in-detail"]], "Random forest feature importances": [[41, "random-forest-feature-importances"]], "Random forests": [[40, "random-forests"]], "Random forests: number of trees (n_estimators) and the fundamental tradeoff": [[40, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"]], "RandomForestClassifier": [[40, "randomforestclassifier"], [49, "randomforestclassifier"]], "Randomized hyperparameter search": [[37, "randomized-hyperparameter-search"]], "Range of C": [[37, "range-of-c"]], "Raw scores": [[18, "raw-scores"], [36, "raw-scores"]], "Reading from .csv": [[8, "reading-from-csv"]], "Reading from other formats": [[8, "reading-from-other-formats"]], "Reading from url": [[8, "reading-from-url"]], "Reading the data": [[13, "reading-the-data"], [20, "reading-the-data"], [31, "reading-the-data"], [47, "reading-the-data"]], "Real boundary between Canada and USA": [[13, "real-boundary-between-canada-and-usa"], [31, "real-boundary-between-canada-and-usa"], [55, "real-boundary-between-canada-and-usa"]], "Reasonable grading concerns": [[6, "reasonable-grading-concerns"]], "Recall": [[38, "recall"]], "Recap": [[49, "recap"], [50, "recap"]], "Recap and motivation [video]": [[44, "recap-and-motivation-video"]], "Recap: Supervised machine learning": [[13, "recap-supervised-machine-learning"], [20, "recap-supervised-machine-learning"], [31, "recap-supervised-machine-learning"]], "Receiver Operating Characteristic (ROC) curve": [[38, "receiver-operating-characteristic-roc-curve"]], "Recipe to approach a supervised learning problem with tabular data": [[51, "recipe-to-approach-a-supervised-learning-problem-with-tabular-data"]], "Recommended browser": [[12, "recommended-browser"], [19, "recommended-browser"]], "Recommender systems": [[54, "recommender-systems"]], "Recommender systems intro and motivation": [[45, "recommender-systems-intro-and-motivation"]], "Recommender systems problem": [[45, "recommender-systems-problem"]], "Recursive feature elimination (RFE)": [[42, "recursive-feature-elimination-rfe"]], "Reference Material": [[1, "reference-material"]], "Reference material": [[9, null]], "References": [[49, "references"]], "Registration": [[58, "registration"]], "Registration, waitlist and prerequisites": [[12, "registration-waitlist-and-prerequisites"], [19, "registration-waitlist-and-prerequisites"]], "Regression scoring functions": [[39, "regression-scoring-functions"]], "Regression with k-nearest neighbours (k-NNs)": [[15, "regression-with-k-nearest-neighbours-k-nns"], [22, "regression-with-k-nearest-neighbours-k-nns"], [33, "regression-with-k-nearest-neighbours-k-nns"]], "Relation of C and the fundamental trade-off": [[15, "relation-of-c-and-the-fundamental-trade-off"], [22, "relation-of-c-and-the-fundamental-trade-off"], [33, "relation-of-c-and-the-fundamental-trade-off"]], "Relation of gamma and the fundamental trade-off": [[15, "relation-of-gamma-and-the-fundamental-trade-off"], [22, "relation-of-gamma-and-the-fundamental-trade-off"], [33, "relation-of-gamma-and-the-fundamental-trade-off"]], "Relevant companion materials": [[9, "relevant-companion-materials"]], "Relevant papers": [[40, "relevant-papers"]], "Relevant papers and resources": [[38, "relevant-papers-and-resources"]], "Relevant resources": [[42, "relevant-resources"]], "Reminder": [[45, "reminder"]], "Renaming columns with df.rename()": [[8, "renaming-columns-with-df-rename"]], "Render set-up (I already did these):": [[51, "render-set-up-i-already-did-these"]], "Report format": [[7, "report-format"]], "Requirements (I already did these)": [[51, "requirements-i-already-did-these"]], "Resources": [[43, "resources"], [44, "resources"], [45, "resources"]], "Reuse your running examples": [[50, "reuse-your-running-examples"]], "Ridge": [[18, "ridge"], [36, "ridge"]], "Ridge on the California housing dataset": [[18, "ridge-on-the-california-housing-dataset"], [36, "ridge-on-the-california-housing-dataset"]], "RidgeCV": [[39, "ridgecv"]], "Root mean squared error or RMSE": [[39, "root-mean-squared-error-or-rmse"]], "SHAP  (SHapley Additive exPlanations) introduction": [[41, "shap-shapley-additive-explanations-introduction"]], "SHAP plots": [[41, "shap-plots"]], "SMOTE idea": [[38, "smote-idea"]], "SMOTE: Synthetic Minority Over-sampling Technique": [[38, "smote-synthetic-minority-over-sampling-technique"]], "SVM Regressor": [[15, "svm-regressor"], [22, "svm-regressor"], [33, "svm-regressor"]], "Saving the model": [[51, "saving-the-model"]], "Saving time and scaling products": [[12, "saving-time-and-scaling-products"], [19, "saving-time-and-scaling-products"], [30, "saving-time-and-scaling-products"]], "Scaling": [[16, "scaling"], [23, "scaling"], [34, "scaling"]], "Scaling using scikit-learn\u2019s StandardScaler": [[16, "scaling-using-scikit-learn-s-standardscaler"], [23, "scaling-using-scikit-learn-s-standardscaler"], [34, "scaling-using-scikit-learn-s-standardscaler"]], "Search over multiple hyperparameters": [[15, "search-over-multiple-hyperparameters"], [22, "search-over-multiple-hyperparameters"], [33, "search-over-multiple-hyperparameters"]], "Seasonality and trends": [[48, "seasonality-and-trends"]], "Select all of the following statements which are True (iClicker)": [[12, "select-all-of-the-following-statements-which-are-true-iclicker"], [19, "select-all-of-the-following-statements-which-are-true-iclicker"], [30, "select-all-of-the-following-statements-which-are-true-iclicker"]], "Sending a request to the API": [[51, "sending-a-request-to-the-api"]], "Setting up": [[5, "setting-up"]], "Setting up a virtual environment: Conda environments": [[10, "setting-up-a-virtual-environment-conda-environments"]], "Setting up coding environment": [[10, null]], "Setting up your computer for the course": [[12, "setting-up-your-computer-for-the-course"], [19, "setting-up-your-computer-for-the-course"]], "Short posts/articles": [[9, "short-posts-articles"]], "Sigmoid vs. Softmax": [[47, "sigmoid-vs-softmax"]], "Sign of the coefficients": [[18, "sign-of-the-coefficients"], [36, "sign-of-the-coefficients"]], "Silhouette distance for a sample": [[43, "silhouette-distance-for-a-sample"]], "Similarity between examples": [[15, "similarity-between-examples"], [22, "similarity-between-examples"], [33, "similarity-between-examples"]], "Simple feature engineering for our problem.": [[52, "simple-feature-engineering-for-our-problem"]], "Simple train/test split": [[14, "simple-train-test-split"], [21, "simple-train-test-split"], [32, "simple-train-test-split"]], "SimpleFeature correlations": [[41, "simplefeature-correlations"]], "Single validation set": [[26, "single-validation-set"]], "Slowest method: nested loop": [[8, "slowest-method-nested-loop"]], "Software": [[0, "software"]], "Some important hyperparameters:": [[40, "some-important-hyperparameters"]], "Some key takeaways": [[51, "some-key-takeaways"]], "Some quotes on feature engineering": [[42, "some-quotes-on-feature-engineering"]], "Some terminology related to trees": [[13, "some-terminology-related-to-trees"], [20, "some-terminology-related-to-trees"], [31, "some-terminology-related-to-trees"]], "Some ways to pick hyperparameters:": [[37, "some-ways-to-pick-hyperparameters"]], "Sorting a dataframe with df.sort_values()": [[8, "sorting-a-dataframe-with-df-sort-values"]], "Spam/non spam toy example": [[17, "spam-non-spam-toy-example"], [24, "spam-non-spam-toy-example"], [35, "spam-non-spam-toy-example"]], "Specific questions": [[4, "specific-questions"]], "Stacking": [[40, "stacking"]], "Step 1": [[57, "step-1"]], "Step 2": [[57, "step-2"]], "Step 3": [[57, "step-3"]], "Step 4": [[57, "step-4"]], "Step 5": [[57, "step-5"]], "Steps to train a classifier using sklearn": [[13, "steps-to-train-a-classifier-using-sklearn"], [20, "steps-to-train-a-classifier-using-sklearn"], [31, "steps-to-train-a-classifier-using-sklearn"]], "Stratified Splits": [[38, "stratified-splits"]], "Strengths and weaknesses": [[40, "strengths-and-weaknesses"]], "Strengths of linear models": [[18, "strengths-of-linear-models"], [36, "strengths-of-linear-models"]], "Study tips": [[54, "study-tips"]], "Submitting on Gradescope": [[7, "submitting-on-gradescope"]], "Summary": [[12, "summary"], [15, "summary"], [19, "summary"], [22, "summary"], [30, "summary"], [33, "summary"], [40, "summary"], [46, "summary"], [47, "summary"], [49, "summary"]], "Summary and reflection": [[14, "summary-and-reflection"], [21, "summary-and-reflection"], [32, "summary-and-reflection"]], "Summary of linear models": [[18, "summary-of-linear-models"], [36, "summary-of-linear-models"]], "Summary of train, validation, test, and deployment data": [[14, "summary-of-train-validation-test-and-deployment-data"], [21, "summary-of-train-validation-test-and-deployment-data"], [32, "summary-of-train-validation-test-and-deployment-data"]], "Summary: Pros and cons": [[44, "summary-pros-and-cons"]], "Supervised approach to rating prediction": [[45, "supervised-approach-to-rating-prediction"]], "Supervised learning": [[43, "supervised-learning"]], "Supervised learning (Reminder)": [[13, "supervised-learning-reminder"], [31, "supervised-learning-reminder"]], "Supervised learning vs. Unsupervised learning": [[13, "supervised-learning-vs-unsupervised-learning"], [20, "supervised-learning-vs-unsupervised-learning"], [31, "supervised-learning-vs-unsupervised-learning"]], "Supervised machine learning": [[12, "supervised-machine-learning"], [19, "supervised-machine-learning"], [30, "supervised-machine-learning"]], "Support Vector Machines (SVMs) with RBF kernel [video]": [[15, "support-vector-machines-svms-with-rbf-kernel-video"], [22, "support-vector-machines-svms-with-rbf-kernel-video"], [33, "support-vector-machines-svms-with-rbf-kernel-video"]], "Support vectors": [[15, "support-vectors"], [22, "support-vectors"], [33, "support-vectors"]], "Survival analysis": [[54, "survival-analysis"]], "Survival plots": [[49, "survival-plots"]], "Syllabus": [[1, "syllabus"], [58, null]], "TAs": [[1, "tas"], [58, "tas"]], "Tabular data": [[13, "tabular-data"], [20, "tabular-data"], [31, "tabular-data"]], "Take-home message": [[44, "take-home-message"]], "Teaching Team": [[58, "teaching-team"]], "Terminology": [[47, "terminology"]], "Terminology [video]": [[13, "terminology-video"], [20, "terminology-video"], [31, "terminology-video"]], "Testing your git installation": [[5, "testing-your-git-installation"]], "The Netflix prize": [[40, "the-netflix-prize"]], "The __ syntax": [[37, "the-syntax"]], "The best features may be dependent on the model you use.": [[42, "the-best-features-may-be-dependent-on-the-model-you-use"]], "The golden rule <a name=\"4\"></a>": [[14, "the-golden-rule"], [21, "the-golden-rule"], [32, "the-golden-rule"]], "The random forests classifier": [[40, "the-random-forests-classifier"]], "The sigmoid function": [[18, "the-sigmoid-function"], [36, "the-sigmoid-function"]], "The teaching team": [[1, "the-teaching-team"]], "The \u201cfundamental tradeoff\u201d of supervised learning:": [[14, "the-fundamental-tradeoff-of-supervised-learning"], [21, "the-fundamental-tradeoff-of-supervised-learning"], [32, "the-fundamental-tradeoff-of-supervised-learning"]], "The \u201cperfect\u201d spaghetti sauce": [[43, "the-perfect-spaghetti-sauce"]], "Things to watch out for": [[50, "things-to-watch-out-for"]], "Time series": [[54, "time-series"]], "Time to event and censoring": [[49, "time-to-event-and-censoring"]], "Tokenization": [[46, "tokenization"]], "Topic modeling": [[46, "topic-modeling"]], "Topic modeling motivation": [[46, "topic-modeling-motivation"]], "Topic modeling pipeline": [[46, "topic-modeling-pipeline"]], "Topic modeling toy example": [[46, "topic-modeling-toy-example"]], "Toy datasets": [[13, "toy-datasets"], [31, "toy-datasets"]], "Traditional time series approaches": [[48, "traditional-time-series-approaches"]], "Train/test split for temporal data": [[48, "train-test-split-for-temporal-data"]], "Train/test splits": [[48, "train-test-splits"]], "Train/validation/test split": [[14, "train-validation-test-split"], [21, "train-validation-test-split"], [32, "train-validation-test-split"]], "Training a supervised machine learning model with X and y": [[12, "training-a-supervised-machine-learning-model-with-x-and-y"], [19, "training-a-supervised-machine-learning-model-with-x-and-y"], [30, "training-a-supervised-machine-learning-model-with-x-and-y"]], "Training data for the motivating example": [[18, "training-data-for-the-motivating-example"], [36, "training-data-for-the-motivating-example"]], "Training error vs. Generalization error": [[14, "training-error-vs-generalization-error"], [21, "training-error-vs-generalization-error"], [32, "training-error-vs-generalization-error"]], "Training models with transformed data": [[17, "training-models-with-transformed-data"], [24, "training-models-with-transformed-data"], [35, "training-models-with-transformed-data"]], "Training on the full corpus": [[51, "training-on-the-full-corpus"]], "Training random forests and gradient boosted trees": [[50, "training-random-forests-and-gradient-boosted-trees"]], "Transfer learning": [[47, "transfer-learning"]], "Transformations on the toy data": [[17, "transformations-on-the-toy-data"], [24, "transformations-on-the-toy-data"], [35, "transformations-on-the-toy-data"]], "Transforming the targets": [[39, "transforming-the-targets"]], "Transparency and explainability of ML models: Motivation": [[41, "transparency-and-explainability-of-ml-models-motivation"]], "Tree-based ensemble models": [[40, "tree-based-ensemble-models"]], "Tree-based models": [[40, "tree-based-models"]], "Try out this moment predictor": [[51, "try-out-this-moment-predictor"]], "Tuning alpha hyperparameter of Ridge": [[39, "tuning-alpha-hyperparameter-of-ridge"]], "Tutorial 1": [[55, null]], "Tutorial 2": [[56, null]], "Tutorial 3": [[57, null]], "Types of censoring": [[49, "types-of-censoring"]], "Types of errors": [[14, "types-of-errors"], [21, "types-of-errors"], [32, "types-of-errors"]], "Types of machine learning": [[12, "types-of-machine-learning"], [19, "types-of-machine-learning"], [30, "types-of-machine-learning"], [43, "types-of-machine-learning"]], "Types of problems involving time series": [[48, "types-of-problems-involving-time-series"]], "Types of questions we might want to answer:": [[49, "types-of-questions-we-might-want-to-answer"]], "Typical steps to build a supervised machine learning model": [[26, "typical-steps-to-build-a-supervised-machine-learning-model"]], "UBC CPSC 330: Applied Machine Learning (2024W2)": [[1, null]], "Ubuntu Users": [[5, "ubuntu-users"]], "Underfitting": [[14, "underfitting"], [21, "underfitting"], [32, "underfitting"]], "Underfitting, overfitting, the fundamental trade-off, the golden rule [video]": [[14, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"], [21, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"], [32, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"]], "Undersampling": [[38, "undersampling"]], "Understanding the problem": [[51, "understanding-the-problem"]], "Unequally spaced time points": [[48, "unequally-spaced-time-points"]], "Unsupervised learning": [[43, "unsupervised-learning"]], "Updates to assignments": [[7, "updates-to-assignments"]], "Use of AI in the course": [[58, "use-of-ai-in-the-course"]], "Use our template to create a repository": [[7, "use-our-template-to-create-a-repository"]], "Using OVR and OVO as wrappers": [[53, "using-ovr-and-ovo-as-wrappers"]], "Using SMOTE": [[38, "using-smote"]], "Using Silhouette scores to select the number of clusters": [[43, "using-silhouette-scores-to-select-the-number-of-clusters"]], "Using multiple metrics in GridSearchCV or RandomizedSearchCV": [[39, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"]], "Using pre-trained models as feature extractor": [[47, "using-pre-trained-models-as-feature-extractor"]], "Using pre-trained models out-of-the-box": [[47, "using-pre-trained-models-out-of-the-box"]], "Using regression metrics with scikit-learn": [[39, "using-regression-metrics-with-scikit-learn"]], "Viewing the transformed data as a dataframe": [[17, "viewing-the-transformed-data-as-a-dataframe"], [24, "viewing-the-transformed-data-as-a-dataframe"], [35, "viewing-the-transformed-data-as-a-dataframe"]], "Virtual environment": [[10, "virtual-environment"]], "Visualization": [[9, "visualization"]], "Visualizing the parameter grid as a heatmap": [[37, "visualizing-the-parameter-grid-as-a-heatmap"]], "Visualizing your results": [[50, "visualizing-your-results"]], "Warning": [[13, null], [20, null], [31, null]], "Warnings about feature selection": [[42, "warnings-about-feature-selection"], [42, "id8"]], "Weaknesses": [[40, "weaknesses"]], "Web app on a real server": [[51, "web-app-on-a-real-server"]], "Web app on local server": [[51, "web-app-on-local-server"]], "What all transformations we need to apply on the dataset?": [[16, "what-all-transformations-we-need-to-apply-on-the-dataset"], [34, "what-all-transformations-we-need-to-apply-on-the-dataset"]], "What and Why": [[10, "what-and-why"]], "What are git and GitHub?": [[5, null]], "What are the options?": [[16, "what-are-the-options"], [23, "what-are-the-options"], [34, "what-are-the-options"]], "What are we exactly learning?": [[18, "what-are-we-exactly-learning"], [36, "what-are-we-exactly-learning"]], "What did we cover?": [[45, "what-did-we-cover"], [51, "what-did-we-cover"]], "What did we learn today?": [[14, "what-did-we-learn-today"], [16, "what-did-we-learn-today"], [17, "what-did-we-learn-today"], [21, "what-did-we-learn-today"], [23, "what-did-we-learn-today"], [24, "what-did-we-learn-today"], [32, "what-did-we-learn-today"], [34, "what-did-we-learn-today"], [35, "what-did-we-learn-today"], [38, "what-did-we-learn-today"], [39, "what-did-we-learn-today"], [50, "what-did-we-learn-today"]], "What does this have to do with applied ML?": [[50, "what-does-this-have-to-do-with-applied-ml"]], "What does this mean for us, when we\u2019re trying to make claims about our data?": [[50, "what-does-this-mean-for-us-when-we-re-trying-to-make-claims-about-our-data"]], "What if we apply OHE?": [[17, "what-if-we-apply-ohe"], [24, "what-if-we-apply-ohe"], [35, "what-if-we-apply-ohe"]], "What is Natural Language Processing (NLP)?": [[46, "what-is-natural-language-processing-nlp"]], "What is a recommender system?": [[45, "what-is-a-recommender-system"]], "What is clustering?": [[43, "what-is-clustering"]], "What is deployment?": [[51, "what-is-deployment"]], "What is feature engineering?": [[42, "what-is-feature-engineering"]], "What is feature selection?": [[42, "what-is-feature-selection"]], "What is grid search?": [[50, "what-is-grid-search"]], "What is model interpretability?": [[41, "what-is-model-interpretability"]], "What is supervised machine learning (ML)?": [[12, "what-is-supervised-machine-learning-ml"], [19, "what-is-supervised-machine-learning-ml"], [30, "what-is-supervised-machine-learning-ml"]], "What is \u201cpositive\u201d and \u201cnegative\u201d?": [[38, "what-is-positive-and-negative"]], "What kind of estimators can we combine?": [[40, "what-kind-of-estimators-can-we-combine"]], "What next?": [[51, "what-next"]], "What should be the loss? (Activity: 4 mins)": [[50, "what-should-be-the-loss-activity-4-mins"]], "What to look for in these plots?": [[43, "what-to-look-for-in-these-plots"]], "What transformations do we need to apply on the dataset?": [[23, "what-transformations-do-we-need-to-apply-on-the-dataset"]], "What would I do differently?": [[51, "what-would-i-do-differently"]], "What\u2019s the problem?": [[16, "what-s-the-problem"], [23, "what-s-the-problem"], [34, "what-s-the-problem"]], "When can we use broadcasting?": [[8, "when-can-we-use-broadcasting"]], "When experimenting, show the results asap": [[50, "when-experimenting-show-the-results-asap"]], "When is it OK to do things before splitting?": [[16, "when-is-it-ok-to-do-things-before-splitting"], [23, "when-is-it-ok-to-do-things-before-splitting"], [34, "when-is-it-ok-to-do-things-before-splitting"]], "When test score is much lower than CV score": [[37, "when-test-score-is-much-lower-than-cv-score"]], "Which model should I use?": [[40, "which-model-should-i-use"]], "Which type of error is more important?": [[38, "which-type-of-error-is-more-important"]], "Why do we need a test set?": [[37, "why-do-we-need-a-test-set"]], "Why do we want this information?": [[41, "why-do-we-want-this-information"]], "Why does it matter": [[21, "why-does-it-matter"]], "Why feature selection?": [[42, "why-feature-selection"]], "Why machine learning (ML)? [video]": [[12, "why-machine-learning-ml-video"], [19, "why-machine-learning-ml-video"], [30, "why-machine-learning-ml-video"]], "Why model transparency/interpretability?": [[41, "why-model-transparency-interpretability"]], "Why neural networks?": [[47, "why-neural-networks"], [47, "id1"]], "Why not neural networks?": [[47, "why-not-neural-networks"], [47, "id2"]], "Why should I use it?": [[50, "why-should-i-use-it"]], "Why should we care about effective communication?": [[50, "why-should-we-care-about-effective-communication"]], "Why should we care about recommendation systems?": [[45, "why-should-we-care-about-recommendation-systems"]], "Why sparse matrices?": [[17, "why-sparse-matrices"], [24, "why-sparse-matrices"], [35, "why-sparse-matrices"]], "Windows": [[10, "windows"]], "Windows Users": [[5, "windows-users"]], "Word embeddings": [[46, "word-embeddings"]], "Word vectors with spaCy": [[46, "word-vectors-with-spacy"]], "Writing a traditional program to predict quiz2 grade": [[13, "writing-a-traditional-program-to-predict-quiz2-grade"], [20, "writing-a-traditional-program-to-predict-quiz2-grade"], [31, "writing-a-traditional-program-to-predict-quiz2-grade"]], "XGBoost": [[40, "xgboost"]], "[Optional] Jupyterlab and Python": [[10, "optional-jupyterlab-and-python"]], "[] notation": [[8, "notation"]], "announcements": [[15, "announcements"]], "class_weight=\"balanced\"": [[38, "class-weight-balanced"]], "cross_val_score": [[14, "cross-val-score"], [21, "cross-val-score"], [32, "cross-val-score"]], "cross_validate": [[14, "cross-validate"], [21, "cross-validate"], [32, "cross-validate"]], "fit and transform paradigm for transformers": [[16, "fit-and-transform-paradigm-for-transformers"], [23, "fit-and-transform-paradigm-for-transformers"], [34, "fit-and-transform-paradigm-for-transformers"]], "fit the classifier": [[13, "fit-the-classifier"], [20, "fit-the-classifier"], [31, "fit-the-classifier"]], "fit, predict , and score summary": [[13, "fit-predict-and-score-summary"], [20, "fit-predict-and-score-summary"], [31, "fit-predict-and-score-summary"]], "iClicker": [[58, "iclicker"]], "iClicker Exercise 10.1": [[39, "iclicker-exercise-10-1"]], "iClicker Exercise 10.2": [[39, "iclicker-exercise-10-2"]], "iClicker Exercise 12.0": [[40, "iclicker-exercise-12-0"]], "iClicker Exercise 12.1": [[40, "iclicker-exercise-12-1"]], "iClicker Exercise 14.1": [[42, "iclicker-exercise-14-1"]], "iClicker Exercise 19.1": [[47, "iclicker-exercise-19-1"]], "iClicker Exercise 2.1 Supervised vs unsupervised": [[20, "iclicker-exercise-2-1-supervised-vs-unsupervised"]], "iClicker Exercise 2.2 Classification vs regression": [[20, "iclicker-exercise-2-2-classification-vs-regression"]], "iClicker Exercise 2.2 Supervised vs unsupervised": [[13, "iclicker-exercise-2-2-supervised-vs-unsupervised"], [31, "iclicker-exercise-2-2-supervised-vs-unsupervised"]], "iClicker Exercise 2.3 Classification vs regression": [[13, "iclicker-exercise-2-3-classification-vs-regression"], [31, "iclicker-exercise-2-3-classification-vs-regression"]], "iClicker Exercise 2.4: Baselines and decision trees": [[20, "iclicker-exercise-2-4-baselines-and-decision-trees"]], "iClicker Exercise 2.5: Baselines and decision trees": [[13, "iclicker-exercise-2-5-baselines-and-decision-trees"], [31, "iclicker-exercise-2-5-baselines-and-decision-trees"]], "iClicker Exercise 3.1": [[14, "iclicker-exercise-3-1"], [21, "iclicker-exercise-3-1"], [32, "iclicker-exercise-3-1"]], "iClicker Exercise 3.2": [[14, "iclicker-exercise-3-2"], [21, "iclicker-exercise-3-2"], [32, "iclicker-exercise-3-2"]], "iClicker Exercise 9.1": [[38, "iclicker-exercise-9-1"]], "iClicker Exercise 9.2": [[38, "iclicker-exercise-9-2"]], "k-Nearest Neighbours (k-NNs) [video]": [[15, "k-nearest-neighbours-k-nns-video"], [22, "k-nearest-neighbours-k-nns-video"], [33, "k-nearest-neighbours-k-nns-video"]], "k-nearest neighbours imputation": [[45, "k-nearest-neighbours-imputation"]], "macOS": [[10, "macos"]], "n_iter": [[37, "n-iter"]], "n_jobs=-1": [[37, "n-jobs-1"]], "pandas_profiler": [[39, "pandas-profiler"]], "predict the target of given examples": [[13, "predict-the-target-of-given-examples"], [20, "predict-the-target-of-given-examples"], [31, "predict-the-target-of-given-examples"]], "predict_proba": [[18, "predict-proba"], [36, "predict-proba"]], "random_state argument": [[14, "random-state-argument"], [21, "random-state-argument"], [32, "random-state-argument"]], "score your model": [[13, "score-your-model"], [20, "score-your-model"], [31, "score-your-model"]], "sklearn API summary: estimators": [[16, "sklearn-api-summary-estimators"], [23, "sklearn-api-summary-estimators"], [34, "sklearn-api-summary-estimators"]], "sklearn API summary: transformers": [[16, "sklearn-api-summary-transformers"], [23, "sklearn-api-summary-transformers"], [34, "sklearn-api-summary-transformers"]], "sklearn set_config": [[17, "sklearn-set-config"], [24, "sklearn-set-config"], [35, "sklearn-set-config"]], "sklearn\u2019s ColumnTransformer": [[17, "sklearn-s-columntransformer"], [24, "sklearn-s-columntransformer"], [35, "sklearn-s-columntransformer"]], "sklearn\u2019s SimpleImputer": [[28, "sklearn-s-simpleimputer"]], "sklearn\u2019s feature_importances_ and permutation_importance": [[41, "sklearn-s-feature-importances-and-permutation-importance"]], "sklearn\u2019s feature_importances_ attribute vs permutation_importance": [[41, "sklearn-s-feature-importances-attribute-vs-permutation-importance"]], "spaCy": [[52, "spacy"]], "test score vs. cross-validation score": [[14, "test-score-vs-cross-validation-score"], [21, "test-score-vs-cross-validation-score"], [32, "test-score-vs-cross-validation-score"]], "test_size, train_size arguments": [[14, "test-size-train-size-arguments"], [21, "test-size-train-size-arguments"], [32, "test-size-train-size-arguments"]], "\u201cDeployment\u201d data": [[14, "deployment-data"], [21, "deployment-data"], [32, "deployment-data"]], "\u2753\u2753 Questions for group discussion": [[38, "questions-for-group-discussion"]], "\u2753\u2753 Questions for you": [[12, "questions-for-you"], [13, "questions-for-you"], [13, "id1"], [13, "id3"], [14, "questions-for-you"], [14, "id1"], [15, "questions-for-you"], [15, "id2"], [16, "questions-for-you"], [16, "id1"], [16, "id2"], [17, "questions-for-you"], [17, "id1"], [18, "questions-for-you"], [18, "id1"], [18, "id2"], [19, "questions-for-you"], [20, "questions-for-you"], [20, "id1"], [21, "questions-for-you"], [21, "id1"], [22, "questions-for-you"], [22, "id1"], [23, "questions-for-you"], [23, "id1"], [23, "id2"], [24, "questions-for-you"], [24, "id1"], [29, "questions-for-you"], [30, "questions-for-you"], [31, "questions-for-you"], [31, "id1"], [31, "id3"], [32, "questions-for-you"], [32, "id1"], [33, "questions-for-you"], [33, "id1"], [34, "questions-for-you"], [34, "id1"], [34, "id2"], [35, "questions-for-you"], [35, "id1"], [36, "questions-for-you"], [36, "id1"], [36, "id2"], [37, "questions-for-you"], [37, "id2"], [38, "questions-for-you"], [38, "id2"], [39, "questions-for-you"], [39, "id2"], [40, "questions-for-you"], [40, "id1"], [40, "id2"], [42, "questions-for-you"], [43, "questions-for-you"], [43, "id2"], [44, "questions-for-you"], [44, "id3"], [45, "questions-for-you"], [45, "id1"], [45, "id2"], [47, "questions-for-you"], [48, "questions-for-you"], [48, "id1"], [48, "id2"], [48, "id3"], [49, "questions-for-you"], [49, "id1"], [49, "id2"], [49, "id3"], [49, "id4"], [50, "questions-for-you"], [50, "id1"], [51, "questions-for-you"], [51, "id2"]], "\ud83e\udd14 Eva\u2019s questions": [[12, "eva-s-questions"], [14, "eva-s-questions"], [19, "eva-s-questions"], [30, "eva-s-questions"], [32, "eva-s-questions"]]}, "docnames": ["LICENSE", "README", "docs/330_vs_340", "docs/README", "docs/asking_for_help", "docs/git_installation", "docs/grades", "docs/homework_instructions", "docs/python_notes", "docs/resources", "docs/setup", "learning-objectives", "lectures/201-Lecuyer-lectures/01_intro", "lectures/201-Lecuyer-lectures/02_terminology-decision-trees", "lectures/201-Lecuyer-lectures/03_ml-fundamentals", "lectures/201-Lecuyer-lectures/04_kNNs-SVM-RBF", "lectures/201-Lecuyer-lectures/05_preprocessing-pipelines", "lectures/201-Lecuyer-lectures/06_column-transformer-text-feats", "lectures/201-Lecuyer-lectures/07_linear-models", "lectures/202-203-Giulia-lectures/01_intro", "lectures/202-203-Giulia-lectures/02_terminology-decision-trees", "lectures/202-203-Giulia-lectures/03_ml-fundamentals", "lectures/202-203-Giulia-lectures/04_kNNs-SVM-RBF", "lectures/202-203-Giulia-lectures/05_preprocessing-pipelines", "lectures/202-203-Giulia-lectures/06_column-transformer-text-feats", "lectures/204-Andy-lectures/README", "lectures/204-Andy-lectures/class_demos/demo_03-ml-fundamentals", "lectures/204-Andy-lectures/class_demos/demo_04-kNNs-SVMs", "lectures/204-Andy-lectures/class_demos/demo_05-06-preprocessing", "lectures/204-Andy-lectures/class_demos/demo_07-linear-models_clean", "lectures/notes/01_intro", "lectures/notes/02_terminology-decision-trees", "lectures/notes/03_ml-fundamentals", "lectures/notes/04_kNNs-SVM-RBF", "lectures/notes/05_preprocessing-pipelines", "lectures/notes/06_column-transformer-text-feats", "lectures/notes/07_linear-models", "lectures/notes/08_hyperparameter-optimization", "lectures/notes/09_classification-metrics", "lectures/notes/10_regression-metrics", "lectures/notes/12_ensembles", "lectures/notes/13_feat-importances", "lectures/notes/14_feature-engineering-selection", "lectures/notes/15_K-Means", "lectures/notes/16_DBSCAN-hierarchical", "lectures/notes/17_recommender-systems", "lectures/notes/18_natural-language-processing", "lectures/notes/19_intro_to_computer-vision", "lectures/notes/20_time-series", "lectures/notes/21_survival-analysis", "lectures/notes/22_communication", "lectures/notes/24_deployment-conclusion", "lectures/notes/appendixA_feature-engineering-text-data", "lectures/notes/appendixB_multiclass-strategies", "lectures/notes/final-exam-review-guiding-question", "lectures/tutorials/01_decision_boundaries", "lectures/tutorials/02_ML_fundamentals", "lectures/tutorials/03_Preprocessing", "syllabus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["LICENSE.md", "README.md", "docs/330_vs_340.md", "docs/README.md", "docs/asking_for_help.md", "docs/git_installation.md", "docs/grades.md", "docs/homework_instructions.md", "docs/python_notes.ipynb", "docs/resources.md", "docs/setup.md", "learning-objectives.md", "lectures/201-Lecuyer-lectures/01_intro.ipynb", "lectures/201-Lecuyer-lectures/02_terminology-decision-trees.ipynb", "lectures/201-Lecuyer-lectures/03_ml-fundamentals.ipynb", "lectures/201-Lecuyer-lectures/04_kNNs-SVM-RBF.ipynb", "lectures/201-Lecuyer-lectures/05_preprocessing-pipelines.ipynb", "lectures/201-Lecuyer-lectures/06_column-transformer-text-feats.ipynb", "lectures/201-Lecuyer-lectures/07_linear-models.ipynb", "lectures/202-203-Giulia-lectures/01_intro.ipynb", "lectures/202-203-Giulia-lectures/02_terminology-decision-trees.ipynb", "lectures/202-203-Giulia-lectures/03_ml-fundamentals.ipynb", "lectures/202-203-Giulia-lectures/04_kNNs-SVM-RBF.ipynb", "lectures/202-203-Giulia-lectures/05_preprocessing-pipelines.ipynb", "lectures/202-203-Giulia-lectures/06_column-transformer-text-feats.ipynb", "lectures/204-Andy-lectures/README.md", "lectures/204-Andy-lectures/class_demos/demo_03-ml-fundamentals.ipynb", "lectures/204-Andy-lectures/class_demos/demo_04-kNNs-SVMs.ipynb", "lectures/204-Andy-lectures/class_demos/demo_05-06-preprocessing.ipynb", "lectures/204-Andy-lectures/class_demos/demo_07-linear-models_clean.ipynb", "lectures/notes/01_intro.ipynb", "lectures/notes/02_terminology-decision-trees.ipynb", "lectures/notes/03_ml-fundamentals.ipynb", "lectures/notes/04_kNNs-SVM-RBF.ipynb", "lectures/notes/05_preprocessing-pipelines.ipynb", "lectures/notes/06_column-transformer-text-feats.ipynb", "lectures/notes/07_linear-models.ipynb", "lectures/notes/08_hyperparameter-optimization.ipynb", "lectures/notes/09_classification-metrics.ipynb", "lectures/notes/10_regression-metrics.ipynb", "lectures/notes/12_ensembles.ipynb", "lectures/notes/13_feat-importances.ipynb", "lectures/notes/14_feature-engineering-selection.ipynb", "lectures/notes/15_K-Means.ipynb", "lectures/notes/16_DBSCAN-hierarchical.ipynb", "lectures/notes/17_recommender-systems.ipynb", "lectures/notes/18_natural-language-processing.ipynb", "lectures/notes/19_intro_to_computer-vision.ipynb", "lectures/notes/20_time-series.ipynb", "lectures/notes/21_survival-analysis.ipynb", "lectures/notes/22_communication.ipynb", "lectures/notes/24_deployment-conclusion.ipynb", "lectures/notes/appendixA_feature-engineering-text-data.ipynb", "lectures/notes/appendixB_multiclass-strategies.ipynb", "lectures/notes/final-exam-review-guiding-question.ipynb", "lectures/tutorials/01_decision_boundaries.ipynb", "lectures/tutorials/02_ML_fundamentals.ipynb", "lectures/tutorials/03_Preprocessing.ipynb", "syllabus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 4, 5, 7, 8, 9, 10, 13, 18, 20, 21, 26, 27, 29, 31, 36, 37, 40, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58], "0": [0, 1, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], "00": [1, 12, 13, 15, 17, 18, 19, 24, 26, 28, 30, 31, 33, 35, 36, 37, 38, 41, 44, 45, 48, 49, 50, 58], "000": [12, 14, 15, 16, 18, 19, 21, 22, 23, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 46, 47, 49, 52], "0000": [16, 18, 23, 34, 36, 38, 46, 52], "00000": [37, 48], "000000": [13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 26, 27, 28, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 48, 49], "00000000e": 41, "000000e": [28, 37], "000001": 39, "00000e": [15, 33], "000010": 39, "000011": 38, "000021": [16, 23, 34], "000036": 38, "000057": [16, 23, 34], "000065": 37, "000067": 37, "000077": 37, "000087": 36, "000089": 36, "0001": [18, 36, 38, 39, 49, 50], "000100": [16, 23, 34, 39], "000101": 18, "000102": 18, "000102e": 26, "000108": 36, "000113": 38, "000114": 37, "000116": 18, "000117": 39, "000128": 27, "000130": 36, "000136": 47, "000137": 37, "000140": 18, "000142": 18, "000144": 27, "000145": 37, "000146": 36, "000147": 37, "000149": [16, 23, 27, 34], "000150": 36, "000151": 37, "000153": 18, "000154": 27, "000155": [16, 23, 34, 38], "000156": 27, "000159": 37, "000162": 27, "000163": [27, 37], "000166": [18, 36, 37], "000175": 27, "000177": [34, 48], "000179": 27, "000180": 34, "000181": 37, "000182": 36, "000183": 36, "000187": [27, 36], "000188": 34, "000190": 48, "000192": [16, 48], "000194": 36, "000195": 34, "000196": 18, "000197": 16, "000198": 38, "000201": 37, "000203": 16, "000206": 37, "000208": [16, 23, 34], "000210": 37, "000212": 42, "000213": 36, "000218": [23, 36], "000221": 39, "000222": 23, "000225": 16, "000226": 39, "000227": 38, "000228": 23, "000231": 34, "000232": 47, "000234": [15, 33, 37], "000235": [27, 34, 38], "000236": 27, "000239": 18, "000240": [18, 34], "000241": [23, 27], "000245": 37, "000247": 47, "000248": [16, 27], "000255": 36, "000256": [18, 48], "000259": 34, "000260": 34, "000261": 16, "000265": 27, "000267": 16, "000270": 27, "000271": 48, "000273": 47, "000274": 47, "000278": [18, 23], "000279": 23, "000280": 18, "000281": [27, 36], "000283": 36, "000285": [23, 36], "000286": 37, "000289": [16, 23, 34], "000294": 37, "000296": 27, "000304": 16, "000306": 23, "000310": 27, "000312": [28, 38], "000313": 27, "000316": 27, "000318": 18, "000321": 27, "000328": 27, "000329": 27, "000332": [28, 39], "000336": 47, "000339": [28, 37], "000342": 23, "000348": 37, "000351": 18, "000353": [18, 37], "000354": 37, "000363": 47, "000366": 38, "000370": 37, "000371": 36, "000373": 39, "000374": 27, "000378": 36, "00038": 37, "000387": 27, "000397": [18, 39], "000399": 47, "000402": 18, "000412": 18, "000415": 28, "000416": 18, "000420": 27, "000423": 27, "000428": 27, "000432": [27, 28], "000433": 39, "000434": 14, "000435": [14, 47], "000437": 47, "000438": 14, "000441": [14, 27], "000445": 14, "000448": 14, "000450": 28, "000451": 14, "000452": 34, "000459": [14, 36], "000460": 27, "000463": 14, "000471": [14, 48], "000472": 47, "000475": 27, "000477": 21, "000480": [21, 27], "000489": 37, "000492": 38, "000496": 21, "000498": 48, "0005": 50, "000500": 14, "000502": [21, 23], "000503": [15, 37], "000507": 28, "000508": 37, "000511": 14, "000520": [27, 39], "000524": 14, "000528": 15, "000534": 21, "000540": 27, "000542": 27, "000545": 15, "000548": 15, "000549": 15, "000551": 21, "000556": 28, "000558": [21, 28], "000561": [15, 27], "000575": 48, "00058": 37, "000580": 33, "000587": 16, "000602": 15, "000607": 15, "000610": 21, "000612": 15, "000625": 15, "000626": 14, "000630": 38, "000633": 33, "000636": 14, "000637": [14, 47], "000639": 14, "000640": 15, "000642": 14, "000644": 14, "000645": 27, "000646": 14, "000647": 33, "000650": 33, "000651": 33, "000652": [14, 39], "000655": [14, 33], "000657": 14, "000661": 33, "000664": 14, "000666": 15, "000671": 33, "000675": [14, 22], "000678": 37, "000683": 15, "000685": 27, "000686": 14, "000691": 21, "000696": 21, "000697": 15, "000700": 22, "000701": [15, 21], "000707": 21, "000710": 22, "000711": 21, "000712": 21, "000713": [27, 39], "000714": 22, "000720": 21, "000722": 14, "000726": 38, "000728": 22, "000736": 22, "000737": 48, "000739": 22, "000740": 27, "000742": 15, "000746": 15, "000747": 37, "000748": 34, "000752": [15, 33], "000757": 14, "000758": 47, "000765": 34, "000774": 34, "000786": 38, "000787": 33, "000789": 28, "00079": 37, "000794": 33, "000795": 33, "000797": 33, "000800": 14, "000803": 39, "000805": 15, "000812": [14, 27], "000815": 15, "000816": 21, "000820": 15, "000823": 21, "000829": [27, 33], "000831": 33, "000832": 39, "000839": [21, 22, 27], "000842": 15, "000851": 22, "000867": 34, "000869": 48, "000870": 21, "000873": 33, "000881": 23, "000889": 33, "000890": 27, "000891": 38, "000894": 23, "000902": 16, "000917": 37, "000927": 38, "000934": 27, "000936": 33, "000944": 15, "000945": 42, "000950": 22, "000952": 23, "000960": 47, "000964": 42, "000967": 22, "000969": 22, "000975": 14, "000976": 37, "000977": 33, "000982": 37, "000997": 16, "001": [12, 14, 15, 16, 18, 19, 22, 23, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 47, 49, 50, 52], "0010": [18, 36], "00100": 37, "001000": [37, 39], "001002": 32, "001006": 32, "001010": 32, "001011": [14, 33, 39], "001014": [16, 32], "001016": 32, "001017": 32, "001021": 14, "001026": 32, "001027": 32, "001029": 32, "001038": 32, "001043": 34, "001057": [32, 37], "001060": [16, 23, 34], "001063": 32, "001064": 47, "001068": 41, "001071": 32, "001078": 32, "001079": 23, "001082": 21, "001086": 32, "001087": 42, "001103": 32, "001109": 27, "001111": 32, "001113": 21, "001116": 22, "001126": 22, "001139": 33, "001144": 14, "001145": 15, "001146": 22, "001149": 32, "001155": 42, "001162": [37, 42], "001174": 32, "001178": 27, "001179": 15, "001200": 16, "001204": 15, "001205": 38, "001220": 36, "001224": 33, "001226": 47, "001230": 27, "001236": 37, "001239": 38, "001260": 15, "001266": 39, "001271": 15, "001272": 16, "001279": 42, "001282": 15, "001286": 38, "001294": 32, "001299": 32, "001302": 22, "001305": 32, "001307": 32, "001315": 32, "001317": 32, "001322": 32, "001323": 32, "001325": 33, "001329": 32, "001337": 32, "001338": [22, 36], "001344": 15, "001347": 37, "001352": 32, "001361": 36, "001362": 36, "001365": 33, "001371": 35, "001375": 27, "001390": 32, "001391": 32, "001392": 33, "001400": 35, "001406": 39, "001407": 32, "001412": 37, "001414": 33, "001416": 15, "001419": 27, "001421": 38, "001422": 39, "001423": 37, "001429": 32, "001433": 39, "001441": 32, "001448": 35, "001453": 32, "00146": 37, "001466": 35, "001467": 37, "001492": 37, "001495": 33, "001511": 27, "001519": 15, "001521": 22, "001541": 22, "001563": 35, "001566": [27, 39], "001580": 22, "001585": 37, "001586": 33, "001591": 35, "001594": 37, "001595": 33, "001600": 33, "001604": 35, "001606": 35, "001608": 37, "001616": 37, "001620": 37, "001629": 37, "001641": 47, "001645": 36, "001647": 35, "001679": 37, "001682": 37, "001687": 27, "001693": 42, "001699": 32, "0017": 38, "001700": 38, "001710": 36, "001715": 35, "001730": 15, "001740": [18, 39], "001762": 18, "001769": 37, "001773": 33, "001776": 32, "001790": 39, "001792": 37, "001805": 15, "001807": 15, "001836": 15, "001847": 42, "001850": 36, "001873": 15, "001877": 33, "001882": 27, "001883": 17, "001888": 22, "001894": 39, "001900": 33, "001920": 35, "001922": 35, "001929": 17, "001933": 39, "001949": 42, "001952": 33, "001960": 17, "0019627889": 46, "001968": 32, "001994": 42, "002": [14, 18, 32, 36, 40, 41, 46, 49], "002003": 37, "002021": 24, "002022": 35, "002030": 33, "002035": 24, "002045": 37, "002057": [16, 23, 34, 35], "002059": 24, "002069": 24, "002070": 24, "002083": 33, "002088": 17, "002092": 17, "002096": 47, "002105": 37, "002114": 18, "002116": 35, "002118": 33, "002121": 18, "002123": 37, "002143": 32, "002146": 37, "002158": 42, "002159": 37, "002189": 17, "002197": 37, "002218": 17, "002221": 39, "002224": 22, "002225": 22, "002231": 17, "002238": 17, "002251": 15, "002272": 17, "002317": 24, "002321": [27, 36], "00234": 37, "002351": 17, "002355": 42, "002367": 24, "002385": 39, "002418": 27, "002441": 42, "002460": 47, "002477": 27, "002478": 24, "002481": 18, "002512": 24, "002516": 22, "002525": 47, "002549": 24, "002561": 37, "002564": 24, "002571": 24, "002643": 27, "002646": 42, "002664": 42, "002675": 37, "002682": 47, "002690": [16, 23, 34], "002692": 37, "002703": 18, "002704": 37, "002711": 47, "002716": 22, "002720": 22, "002746": 39, "002761": 18, "002783": 37, "002788": 35, "002789": 35, "002802": 27, "002807": 35, "002814": 23, "002818": 17, "002835": 37, "002842": 17, "002845": 24, "002848": 27, "002858": 35, "002867": 42, "002889": 38, "0029": 49, "002902": 17, "002910": 35, "002921": 27, "002928": 16, "002934": 36, "002940": 47, "002948": 33, "002949": 22, "002962": 47, "002965": 27, "002986": 47, "002987": 27, "002999": 37, "003": [37, 40], "003013": 35, "003014": 37, "003015": [24, 37], "003026": 18, "003027": 37, "003038": [27, 37], "003044": 27, "003052": 16, "003066": 16, "003083": 37, "003086": 35, "003088": 27, "003103": 18, "003106": 16, "003113": 16, "003115": 35, "003124": [38, 39], "003133": 39, "003146": 35, "003148": 36, "003166": [34, 42], "003181": 34, "003183": 42, "003185": 49, "003186": 35, "003188": [34, 35], "003194": [18, 36], "003210": 27, "003212": 34, "003218": 22, "003224": 22, "003232": 17, "003242": 47, "003257": 47, "003272": 27, "003273": 32, "003283": 47, "003284": 22, "003288": 39, "003300": [16, 23, 34], "003316": 23, "00332": 37, "003324": 34, "003365": 35, "003388": 23, "003401": 42, "003421": 37, "003423": 42, "003427": 42, "003442": 23, "003463": 27, "003472": 37, "003477": 47, "003479": [23, 37], "003483": 37, "003493": 42, "003507": 17, "003519": 24, "003528": 37, "003529": 37, "003540": 27, "003547": 39, "003561": [14, 21], "003563": 37, "003565": 24, "003586": 24, "003593": 27, "003633": 37, "003647": 47, "003663": 27, "003665": 17, "003666": [17, 23], "00369": 37, "003736": 24, "003748": 37, "003749": 17, "003757": 37, "003785": [27, 39], "003820": 24, "003877": 27, "003885": 37, "003898": 22, "003902": 17, "003904": 24, "003910": 27, "003913": 17, "003919": [27, 37], "003919287722401839": 37, "00392157": 47, "003923": 35, "003924": 42, "003933": 37, "003936": 17, "003949": 24, "003951": 17, "003968": 17, "003998": 37, "004": [15, 33, 37, 40, 41, 47], "004057": 37, "004065": 48, "004081": 17, "004082": 48, "004121": 39, "004143": 39, "004203": 24, "004262": 24, "004264": [14, 21, 32], "004293": 37, "004305": 37, "004337": 37, "00435173": 43, "004352": 43, "004358": 24, "004373": 17, "004398": 41, "004402": 37, "004438": 18, "004461": 27, "004462": 22, "004466": 37, "004469": 27, "004496": 37, "004521": 39, "004529": 41, "004556": 37, "004574": 39, "004594": 27, "004602": 39, "00461": 37, "004713": 17, "004714": 37, "004723": 41, "004745": 24, "004761": 41, "004769": [14, 21], "004770": [16, 23, 34], "004801": [16, 23, 34, 35], "004807": 35, "004826": 39, "004829": 39, "004848": 16, "004852": 27, "004854": 39, "004884": 47, "004919": 37, "004952": 37, "004959": 37, "00496": 37, "004964": 17, "005": [12, 19, 30, 40, 41, 49, 50], "005067": 34, "005071": 24, "005074": 47, "005093": 34, "005098": 39, "005103": 16, "005114": 39, "005126": 37, "005136": 26, "005151": 37, "005157": 34, "005167": 39, "005191": 16, "005196": 37, "005204": 16, "005241": 39, "00525962": [16, 23, 34], "005269": 39, "005270": 27, "005288": 35, "005290": 16, "005309": 22, "005313": 22, "005335": 37, "005336": 39, "005373": 23, "005377": 23, "005387": 38, "005398": 23, "005423": 37, "005426": 37, "00543825": [16, 23, 34], "005440": 47, "005443": 22, "005478": 41, "00548": 37, "005508": 24, "005538": 39, "005563": 21, "005579": 39, "005593": 22, "005608": 17, "005622": 23, "005641": 39, "005674": 39, "005699": [14, 21, 32], "005708": 37, "00573": 37, "005734": 37, "005735": 37, "005767": 37, "005809": 48, "005834": 37, "005836": 34, "005868": 24, "005888": [16, 23, 34], "005963": 38, "006": [40, 41, 49], "006012": 37, "006046": 39, "006055": 37, "006067": 39, "006070": 27, "006106": 37, "006110": [15, 33, 37, 39], "006208": 27, "006236": [27, 39], "006244": 37, "006250": 27, "006435": 37, "006452": [18, 36], "006465": 22, "006476": 39, "006505": 47, "006531": [14, 21, 32], "006545": 37, "006546893270012566": [18, 36], "006557": [18, 36], "006570": 23, "006578": [16, 23, 34, 35], "006649": 22, "006652": 37, "006667": [27, 37], "00667": 37, "006737": 24, "006744": 39, "006770": 27, "006805": [14, 21, 32], "006861": 37, "006904": 37, "00691": 37, "006973": 34, "006991": 17, "007": [23, 34, 40, 41, 49, 52], "007068": 42, "007116": 24, "00715": 37, "00720988e": 41, "007228": 39, "007291": 35, "007316": [14, 21, 32], "007362": 37, "007434": 41, "007438": 38, "007458": [16, 23, 34, 35], "007517": 39, "007542": 26, "007544": 37, "007563": 37, "007588": 43, "00758803": 43, "00759438": 41, "007655": 37, "007666": 38, "00767": 37, "007737": 39, "007776": 39, "007794": 28, "007818": 37, "007926": 22, "007938": [14, 32], "007986": 39, "008": [16, 40, 41, 52], "008040": 48, "008120": 39, "008153": 37, "008167": [16, 23, 34, 35], "008286": 27, "00830586": [17, 24, 35], "008306": [17, 24, 35], "008322e": 49, "008333": 35, "008346": 39, "008377": 37, "008472": 39, "008498": 27, "008577": 47, "008581": 39, "008606": 39, "008617": 39, "008667": 37, "00871": 37, "008735": [15, 22, 33], "008785": 39, "008786": 38, "009": [35, 40, 49, 52], "009059": [14, 21, 32], "009063": 37, "009082": 37, "009090": 39, "009131": 27, "009132": 37, "009140": 39, "009260": 21, "009297": 37, "009305": 37, "009339": 39, "009422": [14, 32], "009512": 37, "009514e": 39, "009556": 38, "009664": 39, "009692": 47, "009703": 27, "009724": 42, "00pm": 1, "01": [15, 16, 18, 22, 23, 28, 33, 34, 36, 37, 38, 39, 41, 47, 48, 49, 50, 53, 58], "010": [12, 18, 19, 30, 36, 37, 49], "0100": [18, 36], "01000": 37, "010000": [16, 23, 34, 37, 39], "010027": [18, 36], "010183": [16, 23, 34, 35], "0102": [15, 33, 37], "010208": 42, "010294": [14, 21, 32], "010547": 21, "010650": [14, 21, 32], "010679": [14, 32], "010688": 42, "010715": 37, "010750": 42, "011": [12, 19, 30, 35, 47, 49], "011210": 42, "011234": 38, "011248": 39, "011252": 42, "011269e": 39, "011287": 42, "011332": 49, "011336": [15, 22, 33], "011415": 27, "011440": 39, "011617": 37, "011678": 38, "011767": 39, "011773": 40, "012": [16, 23, 34, 35, 40, 41, 47, 49, 52], "012019": [21, 32], "012030": 42, "012065": 14, "012232": 39, "012240": 42, "012247": 27, "012252": 37, "012616": 37, "012624": 39, "012758": 39, "013": 16, "013031": 39, "01311996071": 39, "013120": 41, "013157": 37, "013161": 37, "013433": [15, 22, 33], "013629": 37, "013706928443177698": 37, "013707": 37, "013863": 37, "013888": 37, "014": [16, 23, 32, 34, 40, 41, 49], "014030": 39, "014081e": 39, "01409912": 46, "014305": 39, "01432486e": 41, "014337": 27, "014481": 37, "014503": 37, "014650": 49, "014730": 35, "01473536": [15, 22, 33], "014758": 49, "014990": 27, "015": [12, 16, 19, 23, 30, 34, 35, 40, 49, 52], "015003": 37, "015039": 38, "015056": 37, "015165": 39, "015372": 37, "015639": 27, "015724": 42, "015755": 37, "015819": 37, "016263": 37, "016330": 27, "016372": 37, "01647": 37, "016525": [39, 41, 50], "016555": [18, 36], "016587": 38, "016598": 37, "016602": 37, "016607": 37, "016660": 28, "016676": 43, "016688": [16, 23, 34, 42], "016693": 39, "016807": [18, 36], "016815": 37, "016918": 38, "016944": [15, 22, 33], "017": [35, 47], "017185": 37, "017226": 39, "017308": 37, "017427": 37, "017561": 38, "017610": 41, "017696": 41, "017737": 41, "017741": 41, "017795": 27, "017829": 48, "017837": 37, "01784": 37, "017927": 37, "017951": 27, "017959e": 39, "017972": [16, 23, 34], "018": 40, "018014": 41, "018077": 37, "018178": [15, 22, 33], "018243": 37, "018310": [15, 22, 33], "018434": 48, "018459e": 39, "018487": [18, 36], "0185": [18, 36], "018505": 37, "018507e": 39, "018558": 37, "018581": 39, "018622": 28, "018653": 37, "018745": [12, 19, 30], "018789": 37, "018846": 37, "018854": 38, "019": [40, 52], "019012": 37, "019163": 37, "019293": 27, "019381838999846482": 37, "019382": 37, "019390": 38, "019396": 37, "019444": 35, "019446": 37, "019531": 38, "019556": 49, "0195598": [18, 36], "019574": 37, "019603": 38, "019839": 37, "019963": 38, "02": [15, 16, 18, 23, 26, 28, 33, 34, 35, 36, 37, 39, 41, 42, 48, 49, 57, 58], "020000": 27, "02000e": [15, 33], "020123": 39, "020273": 38, "020319": 38, "020403": 37, "020414": 37, "020641": 41, "020648": 39, "020653": [14, 21, 32], "020833": 45, "020862": 39, "020873": [16, 23, 34], "021": 40, "021082": 27, "021100": [16, 23, 34], "021281": 37, "021305": [15, 22, 33], "021345": 37, "021603": 47, "021721": 37, "021746": 37, "021862": 37, "021900": [15, 33, 37], "022039": 38, "022331": 41, "022433": 37, "022629": 37, "022686": 37, "022730": 27, "022848": [14, 21, 32], "022866": 38, "023": [40, 47], "023086": 49, "023105": 48, "023279": 28, "023305": 39, "023366": 42, "023511": 37, "023554": 39, "023636": 38, "023666": 37, "023810": 52, "024": 40, "024028": 37, "024122": 37, "024291": 48, "024351e": 39, "024390": 42, "02446630e": 41, "024540": [16, 23, 34], "024944": 27, "025": [34, 38], "025381": [41, 50], "025391": [16, 23, 34, 35], "025396": 37, "025460": 27, "025489": 41, "025689": 37, "025910": [15, 22, 33], "025998": [16, 23, 34, 35], "026": 49, "0261": [15, 33, 37], "026616": 27, "026620": 37, "026667": 27, "026777": 37, "02677733855112973": 37, "026793": [39, 41, 50], "026972": 39, "027070": 39, "027079": 27, "027112": 48, "027321": 42, "027484": 39, "027578": 39, "028023": 38, "02807617": 46, "028186": 27, "028337": 37, "028351": 37, "028420": 39, "028672": 42, "028772": 39, "029": 46, "029146": 38, "029164": 48, "029198": 37, "029264": 39, "029396": 27, "029409": 39, "029475": 39, "029909": [14, 32], "029950e": 39, "02d": 48, "03": [1, 16, 18, 26, 36, 37, 39, 41, 47, 48, 49, 52, 58], "030": 41, "03017665e": 41, "030200": [16, 23, 34], "030343": 39, "030349": 39, "030408": [15, 22, 33], "03049217": [15, 22, 33], "0305": [15, 22, 33], "030618": 21, "030739733331869412": [18, 36], "030786": 39, "030805": 39, "031": 35, "031070": 39, "031385": [15, 22, 33], "031483": 39, "031564": [16, 23, 34], "031794": 39, "031863": 39, "0319": 46, "031994": 39, "032000": 27, "032140": 39, "032324": 37, "032404": 37, "032508": 38, "032566": [17, 24, 35], "03256625": [17, 24, 35], "032656": [15, 22, 33], "032660": 27, "032836": 38, "032874": [15, 22, 33], "033165": 39, "033222": 49, "033267": 48, "033279": 41, "033305": 47, "033322": 39, "033459": [15, 22, 33], "0335": 37, "033723": 39, "033739": 39, "033780": 49, "033815": 38, "033833": 38, "0339": [16, 23, 34], "033993": 27, "034071": 38, "03411038e": 41, "034132": 39, "0344": [15, 33, 37], "034894": 41, "034977": 39, "034979e": 39, "035": 47, "0351": [16, 23, 34], "03516073": 41, "035161": 41, "035223": 39, "035230": 48, "035722": 39, "036": [14, 16, 23, 34, 40, 47], "036136": 42, "0362": [16, 23, 34], "036646": 39, "036764": 38, "036886": 40, "0370": [16, 23, 34], "0373": [16, 23, 34], "037414": 48, "037785": 38, "0378": [16, 23, 34, 49], "038102": [18, 36], "038609": 39, "038707": 41, "038873": 27, "038948": 39, "039": 47, "039498": [18, 36], "039739": 27, "039741": 33, "0399": [16, 23, 34], "04": [16, 23, 26, 28, 34, 35, 37, 39, 41, 48, 49, 57, 58], "040": 40, "040000": 27, "040000e": 26, "040129": 49, "040497": 38, "040563": 27, "040698e": 39, "040954": 49, "040984": 48, "041": [40, 47], "041031": 38, "04108378": [18, 36], "041084": [18, 36], "041129": [15, 22, 33], "041201": 38, "041488": 39, "041704": 41, "041769": 39, "042081": 41, "042382": 42, "042743": 39, "042957": [16, 23, 34, 35], "043": 37, "043257": 35, "043319": 41, "043509": 37, "0437": [13, 14, 15, 21, 22, 31, 32, 33, 55], "043890": [15, 22, 33], "044": [15, 33, 37], "044029": [16, 23, 34, 35], "044166": [18, 36], "044253": 41, "044313": [16, 23, 34], "044409": 39, "044614": 37, "044873": [14, 21, 32], "045": [13, 26, 31, 47], "045267": 48, "045304": [15, 22, 33], "045415": 34, "045481": 48, "046": 47, "04600e": [15, 33], "046020": [15, 22, 33], "046114": 27, "046116": 37, "046193e": 39, "046216": 37, "046638": 35, "0468": 49, "0469": [16, 23, 34], "046945": 37, "04709519e": 41, "0474": [18, 36], "047567": 39, "047577": 16, "04774884": 43, "047749": 43, "047851": 23, "048": [14, 21, 32, 35], "048378": [14, 21, 32], "04861878": 43, "048630": 48, "048860": [16, 23, 34], "048889": 39, "048940": 14, "049": [35, 47], "049097": 27, "05": [15, 16, 23, 26, 28, 33, 34, 37, 38, 39, 44, 48, 49, 50, 58], "050": [12, 19, 30, 47], "050110e": 39, "050132": [16, 23, 34, 35], "051": 47, "051269": [16, 23, 34, 35], "05137470e": 41, "051392": 47, "051472": [15, 22, 33], "051620": [16, 23, 34], "051824": 39, "051925": 37, "052": [16, 23, 34], "052349": [16, 23, 34], "052607": 38, "052790": 38, "052819": 38, "05290827e": 41, "053156": 43, "05350962": 53, "0537": 37, "053763": [14, 21, 32], "053918": 37, "054054": 38, "054225": 28, "054461": 38, "054653": [17, 24, 35], "05465323": [17, 24, 35], "054669": [39, 41, 50], "054784": [17, 24, 35], "05478443": [17, 24, 35], "055": [16, 23, 32, 34, 35], "055100": 37, "055398": 15, "055915e": 39, "05598498": [17, 24, 35], "055985": [17, 24, 35], "056": 47, "056478": [16, 23, 34, 35], "05656664": 46, "056599": 27, "056703": 38, "057": [16, 23, 34, 47], "057003": [15, 22, 33], "057082": 39, "057254": 49, "057296": 38, "057331": 39, "057646": [15, 22, 33], "057729": 38, "057732e": 49, "057793": [16, 23, 34, 35], "057910": [16, 23, 34, 35], "058": 40, "0580": [14, 18, 21, 32, 36], "058176": 50, "058298": 39, "059": [12, 16, 19, 23, 30, 34], "059077": 38, "0591": [16, 23, 34], "059242": [16, 23, 34, 35], "059360": 47, "059588": 37, "059863": [15, 22, 33], "06": [16, 23, 26, 34, 37, 39, 44, 46, 47, 48, 49, 53, 58], "060": 47, "060477": 39, "060543": 42, "061100": [16, 23, 34], "061206": 38, "061241": [15, 22, 33], "061312": 39, "061313": 47, "061937": [15, 22, 33], "062": [12, 15, 19, 30, 33, 37], "062043": 37, "062449": 49, "062658e": 39, "062723": [21, 32], "062792": [15, 22, 33], "062793": 46, "063004": 42, "063110": [16, 23, 34, 35], "063173": 41, "064": [37, 41], "06405": 37, "064050": 37, "064200": [15, 22, 33], "064205": 14, "064307": 42, "064452": [15, 22, 33], "065": 47, "065018": 16, "065169": 37, "065449": 39, "065463": 38, "066166": 49, "066251": [21, 32], "066512": 27, "066605": 37, "066667": [16, 23, 34], "0667579112160865": [18, 36], "066810": 49, "066944": 37, "066960": 14, "067099": 27, "067119": 34, "067120": [21, 32], "06797961": 39, "067991": [16, 23, 34], "068": [12, 19, 30], "068214": [18, 36, 37], "068291": 47, "068428": 27, "068498": 37, "068775": 37, "068800e": 26, "068891": 37, "069": 26, "069150": 41, "06915047": 41, "069188": 49, "0694": [15, 33, 37], "069530": [15, 22, 33], "07": [1, 28, 37, 39, 42, 48, 49], "070047": 23, "070081": 37, "070195": 37, "070850": 38, "070898": 37, "070907": [14, 21, 32], "070929": 38, "071": 47, "071330": 48, "071541": [16, 23, 34, 35], "071654": 42, "07174469222": 39, "071745": 41, "071975": 42, "072": [16, 40], "072043": 37, "072243": 41, "0723": [16, 23, 34], "072396": 37, "07245741": 39, "072595": 37, "072707": [14, 32], "072966": 16, "073016": 50, "073058": 34, "073233": [18, 36], "073366": 34, "074": [16, 23, 34, 40], "0741": [15, 22, 33], "074141": [15, 22, 33], "07418": 37, "074327": 40, "074418": 47, "074475": 34, "074556": 16, "074719": [17, 24, 35], "07471942": [17, 24, 35], "074773": 21, "074835": 16, "074853": 50, "075000": 45, "075170": 48, "075453": 49, "075467": 49, "075668": 27, "075747": 37, "076018": 27, "076104": 39, "0762": [16, 23, 34], "076284": 43, "076358": 23, "07639": 37, "076533": 39, "076798": [15, 22, 33], "076938": 23, "077": [40, 47], "077204": 41, "077749": 46, "077761": 49, "077803": 37, "078": [18, 36, 40], "0780": [13, 14, 21, 31, 32, 55], "078052": 38, "07808506982896266": 39, "078243": 37, "078387": 49, "078552": 37, "078740": 37, "07877994e": 53, "078880": 35, "079": 37, "079181": 23, "079282": 37, "079377": 49, "0794": [15, 33, 37], "079471e": 39, "079852e": 39, "08": [16, 23, 34, 37, 39, 42, 44, 47, 48, 49], "080": 47, "08002986030": [17, 24, 35], "080084": 37, "080165": 37, "080319": [17, 24, 35], "08031924": [17, 24, 35], "080694": 41, "080734": 32, "0808": 37, "080847": 14, "081": [12, 19, 30], "08116": 37, "081167": 49, "081292": 48, "08151507e": 41, "081837": 49, "082": 34, "082100": 37, "082251": [18, 36], "082265e": 49, "082749": [15, 22, 33], "082835": 41, "082949": [15, 22, 33], "083": [15, 33, 37, 40], "083123": [16, 23, 34, 35], "083338": [14, 21, 32], "08338644": 46, "083545": 38, "083615": 37, "083813": [16, 23, 34, 35], "083836": 14, "084288": 37, "084490": 50, "084683": 27, "084746": [16, 23, 34, 35], "084870": 21, "085150": 48, "085415": [41, 50], "085477": 38, "085508": 39, "085546": 39, "085550": 39, "085551": 39, "085693": 37, "085698": 39, "086078": 27, "08613": 37, "08642578": 46, "086461": 42, "086517": 26, "086932": 32, "087": 35, "087128": 37, "08740234": 46, "087668": 37, "08791477": 46, "087996e": 37, "088": 47, "0880": [16, 23, 34], "088373": 14, "088543": 37, "088948": [15, 22, 33], "089136": 21, "089294": 37, "089313": 37, "089354": [14, 21], "089485": [21, 32], "089892": 21, "09": [14, 21, 26, 32, 35, 37, 39, 48, 49], "090000": 38, "09009799": 39, "090231": 41, "090376e": 39, "090453": 38, "090473": 37, "090579": 27, "09058097218": [12, 19, 30], "090785": 39, "090951": 22, "090978": 26, "091": 47, "091243": 37, "091625": 42, "091632": 27, "091819": 32, "092": 40, "092072": 37, "092123": 37, "0922": [15, 33, 37], "092204": [14, 32], "092331": 14, "09245358900622544": 37, "092454": 37, "092604": [14, 21, 32], "092660": 49, "092669": 21, "092670": 37, "092729": 37, "092930": [17, 24, 35], "093051": 37, "0931": 37, "093228": 42, "093350": 50, "093390": [15, 22, 33], "093407": 38, "09345386": [17, 24, 35], "093454": [17, 24, 35], "093624": 32, "093787": 37, "093893": 37, "094": [12, 19, 30, 46], "094290": 49, "09430199": [17, 24, 35], "094302": [17, 24, 35], "094581": [17, 24, 35], "094586": 38, "094725": 37, "094863": 37, "095018": 37, "09503409246217484": 39, "095177": 37, "095345": 37, "09573445": 37, "09619141": 46, "096426": 21, "096462": 39, "096692": [16, 23, 34], "096722": 37, "096858": 37, "096927": 38, "096960": 39, "096990": 32, "096997": 47, "097": 47, "09706504": 47, "097088": 49, "097184": 37, "097293": [16, 23, 34, 35], "097516": [16, 23, 34], "097707": 37, "097763": 37, "097938": 21, "098": [18, 36, 47], "098019": 14, "098152": 37, "098307": 39, "098326": [15, 22, 33, 47], "098559": 37, "098629e": 37, "098663": 37, "098787": 27, "09891476780532049": 18, "0989147678053208": 36, "098915": [18, 36], "098950": 37, "098966": [16, 23, 34], "099": 40, "099230": 41, "099240": [16, 23, 34, 35], "099454": 37, "099558": [16, 23, 34, 35], "099685": 39, "099723": [16, 23, 34], "099729": 37, "099749": 48, "099802": 37, "099869": 37, "0x1227a36e0": 8, "0x1577111f0": 37, "0x16888d4c0": 37, "0x168921100": 37, "1": [1, 7, 8, 9, 10, 26, 27, 28, 29, 41, 46, 48, 51, 52, 53, 58], "10": [1, 4, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58], "100": [12, 13, 15, 16, 17, 18, 22, 23, 24, 26, 27, 28, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50], "1000": [12, 14, 15, 18, 21, 22, 32, 33, 35, 36, 37, 38, 39, 41, 42, 47, 48, 49, 50, 52, 53], "10000": [12, 13, 18, 26, 29, 31, 35, 36, 37, 39, 48], "100000": [12, 15, 17, 18, 22, 24, 33, 35, 36, 37, 39, 48], "1000000": [28, 37], "100103": 48, "100105": 37, "100139": [17, 24, 35], "100146": 48, "100248": [15, 22, 33], "100275": 42, "1004": [15, 22, 33], "1005": 48, "1006": 48, "1007": 48, "1008": 48, "10083": 26, "100882": 38, "1009": 48, "10092665203438746": 39, "101": [1, 9, 43, 47, 49, 58], "1010": 48, "1012": 48, "101259": 39, "101387": 21, "1014": [27, 37, 47], "1015": [27, 47, 48], "1016": [27, 47, 48], "101688": 37, "1017": [27, 47, 48], "101772": 14, "101796": 39, "1018": [27, 47, 48], "101810": 32, "101832": 37, "101894": 38, "1019": [27, 47, 48], "102": [28, 38, 39], "1020": [26, 27, 37, 42, 47, 48], "102044": 42, "1021": [27, 47, 48], "102135": 38, "1022": [27, 47, 48], "1023": [27, 47, 48], "1024": [27, 35, 47, 48], "102435": [15, 22, 33, 39], "102474": [17, 24, 35], "10247431": [17, 24, 35], "1025": 48, "10254": 48, "1026": [18, 36, 48], "1027": 48, "10273": 39, "10274": 38, "1028": 48, "1029": 48, "103": 49, "103023": 37, "1031": 48, "103219": 42, "103222": 47, "1034": 42, "103439": [17, 24, 35], "103619": 28, "10361902": 28, "1039": 48, "104": [15, 16, 22, 23, 33, 34, 40, 43, 47], "1040": [16, 23, 34], "104070": 39, "1041": [39, 41, 48, 52], "10416666666666667": 45, "1042": 37, "1043": [17, 24], "1044": [12, 19, 30], "104596": 37, "104643": 39, "105": [26, 40], "1050": [13, 26, 31], "105080": 42, "105089": [17, 24, 35], "10513": 48, "1052": 28, "1053": [28, 52], "105314": 48, "1054": 28, "1055": 28, "10556679": 43, "1056": 28, "105656": 41, "1057": 28, "1058": 28, "10584063": 47, "1059": 28, "106": 28, "106000": [16, 23, 34], "106023": 39, "106112": 48, "106180": 48, "106319": 48, "106322": 48, "106424": 48, "10644531": 46, "106452": [15, 22, 33], "10645223": [15, 22, 33], "10653": 48, "106705": 48, "106764": 37, "1068": 52, "106816": 48, "1069": 52, "10693359": 46, "106996": 37, "107": 40, "1070": 42, "107050": 48, "107292": 48, "107502": 48, "1076": [26, 35], "107718": 37, "10781": [40, 41], "107917": 48, "10793260e": 47, "107947": 39, "107985": 39, "107991": 38, "108": [12, 19, 30], "1080": [12, 19, 30], "10800": [12, 19, 30], "1085": [18, 36], "10868": 48, "108681": [15, 22, 33], "1089": 39, "10910": 48, "10931": 35, "109526": 38, "109580": 27, "1099": 39, "10_000": 49, "10th": [37, 38, 40, 41], "10x": 38, "11": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 52, 54, 56, 58], "110": [18, 36, 47], "1101": [17, 24, 28], "1102": 28, "1103": 28, "110316": 48, "110319": 48, "1104": [15, 22, 28, 33], "11057": 48, "1106": [28, 42], "110645": 39, "1107": 28, "1108": 28, "1109": 28, "110915e": 39, "111": [16, 23, 34, 37, 38, 39, 49], "1110": 28, "1111": 28, "111111": 16, "1112": 28, "11121453": 43, "111215": 43, "111220": 48, "1114": 28, "111438": 42, "1115": 28, "111543": 39, "1116": 28, "112": [15, 16, 22, 33], "1122": [39, 41, 52], "1123": [37, 52], "112441": 37, "112490": 37, "112527": 41, "112848": 39, "1131": 26, "11331": 52, "11336331e": 41, "113600": [16, 23, 34, 35, 57], "1138": 42, "113837": 39, "1139": [39, 41, 50], "113949e": 49, "114": [16, 23, 34], "1140": [12, 19, 30, 39, 41, 50], "114000": [16, 23, 34, 42], "114079": 37, "114214": 37, "114507": 47, "11457": [39, 41, 50], "114757": 26, "114766": 41, "114836": 42, "114966": 41, "115": 35, "1150": [12, 19, 30], "115083": [16, 23, 34], "115089": 48, "11509": 39, "115090": 48, "115091": 48, "115092": 48, "115183": 37, "115276": 49, "115401": 39, "115406": [15, 22, 33], "115428": 48, "115956": [18, 36], "116": [16, 23, 34], "116145": 42, "116167": [18, 36], "116443": 42, "116497": 39, "11664": 52, "11693": 39, "117": [16, 18, 23, 28, 34, 35, 36, 42, 57], "117058": [18, 36], "117379": 37, "117380": [16, 23, 34], "117412": 39, "117528": 42, "11758": 48, "117612": 47, "117712": 48, "117816": [16, 23, 34], "117899e": 39, "1179": [16, 23, 34], "118": [16, 18, 23, 28, 34, 35, 36, 39, 41, 42, 50], "1180": [13, 26, 31], "118182": [16, 23, 34, 35], "118347": 39, "118450": 38, "118563": 42, "11886432": 37, "118874": 39, "118934": 38, "11898": 38, "119": [16, 18, 23, 34, 35, 36, 42, 48, 57], "1190": [16, 23, 26, 34], "119049": 48, "11909976": 43, "119100": 43, "119121": 27, "11914062": 46, "119189": 27, "119400": [16, 23, 34], "1195": [17, 24], "119570": 42, "119911": 48, "11th": [38, 40, 41], "12": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 56, 58], "120": [15, 16, 18, 22, 23, 28, 33, 34, 36, 39, 40, 47, 48, 53], "1204": [15, 22, 33], "120769e": 39, "121": [12, 16, 18, 19, 23, 26, 28, 30, 34, 35, 36, 37, 40, 42, 48], "1210": 37, "121056e": 39, "121084e": 39, "121351": 41, "12138": [16, 23, 34], "1214": 39, "121438": 49, "12150684": [18, 36], "121531": 38, "121599": 41, "121628": [15, 22, 33], "1217": 49, "12178": 42, "121846": 41, "121985": 39, "122": [12, 13, 14, 16, 19, 21, 23, 26, 28, 30, 31, 32, 34, 35, 42, 47, 55], "1220": [12, 16, 19, 23, 30, 34, 37], "1222": 37, "122307": [16, 23, 34, 35], "122331": 39, "122668": 37, "123": [4, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57], "123049e": 26, "123367": 39, "1235387316046016": 37, "123539": 37, "124": [16, 23, 28, 34, 46], "1240": [12, 19, 30], "1241": [39, 42], "1243": [16, 23, 34], "12436984": [17, 24, 35], "124370": [17, 24, 35], "1247": 37, "12498": 41, "124982": 42, "125": [8, 28, 39], "1250": [16, 23, 34, 35, 57], "125000": 26, "12508": [39, 41, 50], "125440e": 39, "125476": [15, 22, 33], "125523": 48, "1256": 53, "125617": 48, "125644": 39, "1258": 49, "126": [28, 42], "126238": 42, "126398": [16, 23, 34, 35], "126488": 43, "12649": [16, 23, 34], "126500": [16, 23, 34], "126563": 37, "126808": [16, 23, 34, 35], "127": [14, 16, 18, 21, 23, 28, 32, 34, 36, 37, 51], "127086": [16, 23, 34], "127087": 49, "1271": 40, "127107": 41, "127226": 35, "127242": 39, "1273": 41, "127326": 39, "1274": 42, "127418": 39, "127439": 39, "127441": 39, "127614": 39, "12761659": 39, "12768": 26, "127878": [15, 22, 33], "1279": 39, "1280": [16, 23, 34, 37, 39], "1281": 39, "128188": [16, 23, 34, 35], "128384": 39, "128528": 39, "1287": 26, "128820": 48, "128828": 48, "128829": 48, "128830": 48, "12890625": 46, "128984": 39, "129": [15, 18, 22, 33, 36, 42, 49], "1290": [16, 23, 34, 35], "12906": [12, 19, 30], "129257": 39, "12927": [12, 19, 30], "129300": [16, 23, 34, 35, 57], "129459": 42, "129600": 39, "129900": 38, "129904": 39, "129985": [16, 23, 34], "12th": [38, 40, 41], "13": [1, 8, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 26, 27, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49, 52, 54, 57], "130": [12, 13, 14, 15, 16, 19, 21, 22, 23, 30, 31, 32, 33, 34, 35, 37, 39, 41, 42, 50, 55, 57], "1300": [39, 41, 50], "1302": 38, "130395": 48, "1304": [15, 22, 33, 49, 50], "130432": 48, "1306": 51, "130690e": 39, "1307": 39, "130991": 38, "131": [16, 23, 28, 34, 40, 48, 49], "131000": 39, "13107": 48, "131275": 38, "1313": 39, "1314": [39, 41, 50], "131607": [39, 41, 50], "131773": 49, "1319796954314723": 40, "132": [16, 49], "1320": 42, "1321": [12, 19, 30], "132158": 39, "132292": 42, "13229595e": 41, "13255": 48, "132875": [16, 23, 34, 35], "132886": 48, "133": [37, 49], "133000": 39, "133210": 37, "133270": 39, "133337": 39, "133562": 49, "13392236": 47, "134": [13, 14, 18, 21, 31, 32, 35, 36, 55], "1340": [13, 26, 31], "134061": 42, "13407": 41, "13418": 16, "134287": 38, "1346": [16, 23, 34, 39, 41, 42, 49, 52], "134615": [18, 36], "134658": [16, 23, 34], "1347": 52, "13476562": 46, "134798": 38, "134894": 48, "135": [48, 49], "1350": 26, "135134": 48, "135197": 48, "13521135": 41, "135299": 42, "135305": [16, 23, 34, 35], "135384": 39, "13540": 26, "135422": 39, "1357": [12, 19, 26, 30], "136": [16, 23, 34, 35], "1360": [13, 26, 31], "1364": 28, "1365": 28, "1366": 28, "13665": [16, 23, 34, 35, 57], "1367": 28, "136714": 38, "1368": 28, "1369": 28, "1370": [12, 15, 19, 28, 30, 33, 37, 49], "13704": [39, 41, 50], "1371": 28, "1372": [28, 50], "1373": 28, "137339": 38, "1374": 28, "137410": 43, "1375": 28, "137500": [16, 23, 34, 35, 57], "1376": 28, "1377": 28, "1378": [28, 39], "1379": 28, "138": 52, "1380": [12, 19, 28, 30], "1381": 28, "138103": 47, "1382": 28, "1383": [28, 37], "1384": 28, "1385": 28, "138503": 42, "138528": [18, 36], "138564": 26, "1386": 28, "1387": 28, "1388": 28, "138876": 49, "1389": [16, 23, 28, 34, 39, 41], "139": [16, 17, 23, 24, 34, 52], "1390": [12, 19, 30], "139297": 38, "139317": 38, "139322": 38, "139349": 38, "13941": 38, "139554": 38, "1396": 37, "1397": 37, "14": [1, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 44, 45, 46, 47, 48, 49, 54], "140": [16, 23, 34], "140185": 42, "140371": 27, "1404": [15, 22, 33, 49], "1405": 42, "1406": [16, 23, 34, 39, 41], "140641": 48, "140828": 26, "140953": 48, "141": [16, 18, 23, 34, 36], "1410": 26, "141232": 48, "14159265358979323": 8, "14160": 38, "141851": 48, "142": 40, "142051e": 26, "142193": 48, "142199": 48, "1423": 38, "142398": 48, "142467": [14, 21, 32], "1427": [26, 50], "142806": 48, "142857": 35, "14289": [16, 23, 34, 35, 57], "143": [37, 38], "143693": 48, "143803": 42, "1438387200": 48, "1438398000": 48, "1438408800": 48, "1438419600": 48, "1438430400": 48, "1438441200": 48, "1438452000": 48, "1438462800": 48, "1438473600": 48, "1438484400": 48, "143975": 48, "144": [12, 19, 30, 37], "144000": [39, 41, 50], "1441": 52, "144199": 48, "144686": 41, "14471": [16, 23, 34, 35, 57], "144729": 48, "144730": 48, "144731": 48, "144732": 48, "144733": 48, "144750": [15, 22, 33], "14485": 39, "145": [27, 48], "145186": 27, "1452": 42, "145425": 39, "145454": 48, "145455": 48, "145456": 48, "145457": 48, "145458": 48, "145459": 48, "145460": 48, "1457": [16, 23, 34, 35, 49, 57], "14579": 42, "1458": [16, 23, 34, 35, 57], "145833": 45, "146": [12, 19, 27, 30, 40, 50], "1460": [39, 49], "14648438": 46, "1465": [16, 23, 34, 35, 57], "146656": 48, "1467": 42, "146767": [38, 41], "146809": 38, "146830": 38, "14690": 35, "147": [27, 41, 50], "147166": [40, 41], "14716638": 41, "1472": 28, "147226": 27, "147616": 38, "147641": 39, "147737": 47, "147893": [16, 23, 34], "147898": 38, "147917": 38, "148": [15, 27, 28, 33, 37, 41, 53], "14813": 48, "148141": 40, "148343": 39, "148349": 49, "14841": 38, "149": [27, 49], "1490": 26, "149122": 51, "14970": [16, 23, 34], "149788": 41, "149822": [16, 23, 34, 35], "14999": [16, 23, 34], "14th": [12, 13, 19], "15": [1, 8, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 26, 27, 28, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 52, 54, 55, 58], "150": [15, 27, 33, 37, 39, 47, 50], "1500": 28, "150000": [38, 45], "150115": 37, "15026771": 39, "150395": [15, 22, 33], "1504": [15, 22, 33], "1505": [16, 23, 34], "1509": 26, "150mb": 38, "150p": [12, 19, 30], "151357": 42, "1514": 51, "152": [28, 48], "1520": 37, "1523300141": 26, "1523300157": 26, "152401": 38, "152691": 27, "15278": 16, "152859": 38, "153": 28, "1530": [12, 19, 26, 30], "1531": [17, 24], "1534": [16, 23, 34], "15377": [16, 23, 34, 42], "154": 28, "1540": [12, 19, 30], "154076": [38, 41], "154105": 42, "15429": 48, "154386": [16, 23, 34, 35], "1545": 42, "154795": [39, 41, 50], "154842": 49, "154883": 27, "155": [12, 19, 28, 30, 37], "15500": 39, "155178e": 39, "15559528e": 41, "155624": 39, "155900": 26, "156": [16, 23, 28, 34, 37, 38], "1560": 26, "1562": 37, "156311e": 39, "1564": 37, "15661": 48, "157": [12, 19, 28, 30, 37, 47], "157008": 39, "157157": 52, "157234": 42, "15725": [16, 23, 34, 42], "157572": 27, "157712": 38, "15775": 48, "1578": 41, "15795": [38, 41], "158": 37, "1580": [12, 19, 30], "1582": 41, "158867": 48, "158982": 39, "159": 37, "1590": [15, 33, 37], "15915": 48, "159751": 27, "15992": 41, "15pm": 1, "16": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 45, 46, 48, 49, 51, 52, 54, 55], "160": [14, 15, 18, 21, 32, 33, 36, 37, 39, 41], "1600": 26, "160000": [39, 41, 50], "160258": [14, 21, 32], "160282": 42, "1604": [15, 22, 33], "160506": 38, "160634": 47, "16063983": [17, 24, 35], "160640": [17, 24, 35], "160727": 41, "160729": 48, "161": [16, 23, 28, 34], "1610243052583633": 18, "1610243052583638": 36, "16111330565237114": 18, "16111330565237164": 36, "1613": [16, 23, 34], "161300e": 26, "161429": 27, "16153": 48, "16157": 48, "16160": 48, "161606": [16, 23, 34, 35], "161782": 38, "1619": 37, "161931": [39, 41, 50], "162": [12, 19, 30], "162000": 39, "162007": 52, "162214": 50, "162330": 38, "162363": 38, "162667": [38, 41], "16269": 16, "1627": 42, "162904": 49, "163": 26, "1631": 37, "163195": [16, 23, 34, 35], "163397": [16, 23, 34, 35], "1634": [16, 23, 34, 35, 37, 57], "16358": 48, "164": [42, 47], "1645": [18, 36], "16460": 42, "164679": 38, "165": [18, 36, 39], "1650": [15, 33, 37], "16507": [18, 36, 42], "16508": [18, 36, 42], "16509": [18, 36, 42], "16510": [18, 36, 42], "16511": [18, 36, 42], "16512": [18, 36, 42], "165198e": 39, "1652": [14, 18, 21, 32, 36], "16533": 48, "165485": 41, "165617": 48, "165811": 37, "166": 21, "16630": 42, "166631": [16, 23, 34, 35], "16686": 16, "167": [14, 21, 28, 32], "167214": [15, 22, 33], "167241": 52, "167600": 42, "167620": 47, "168": [28, 39], "1680": [13, 26, 31], "168151": 47, "168196": [16, 23, 34, 35], "168244": 41, "1687": 37, "169": [14, 18, 21, 28, 32, 36, 42], "1690": [12, 13, 19, 26, 30, 31], "169269e": 49, "169421": 37, "169693": [15, 22, 33], "169748": [18, 36], "16991815": 8, "1699181533555938": 8, "17": [1, 4, 8, 13, 15, 16, 17, 18, 22, 23, 24, 26, 28, 31, 33, 34, 35, 36, 37, 38, 39, 42, 46, 48, 49, 54, 57], "170": [16, 23, 34, 44], "170100": [16, 23, 34, 35, 57], "170277": [40, 41], "1704": [15, 22, 33], "17054987": 47, "170670": 39, "170931": 47, "171": [12, 19, 30, 47], "17144": 48, "171468": [39, 41, 50], "1715": 37, "171657": [14, 21, 32], "171899": 49, "1720": [16, 23, 34], "17205": 48, "1724668": 46, "172792": 38, "17290": 26, "173": [15, 33, 37], "173025": 37, "17393037": 8, "1739787032867638": 37, "173979": 37, "174": [12, 15, 19, 30, 33, 37], "174590": 38, "17476": 16, "174766": 42, "1750": [16, 23, 34, 51], "175000": [39, 41, 50], "17518": 48, "175459": 26, "176": [16, 23, 34], "176026": 27, "1766": 39, "176924": 49, "177": 42, "17730": [16, 23, 34, 42], "177709": 49, "178": [12, 19, 30, 39], "17847": 16, "178494": 39, "1788": 26, "17896": 48, "179": [40, 49], "179080": 38, "179123": [15, 22, 33], "179152": 28, "179300": [16, 23, 34], "179631": 26, "179730": 37, "17973005068132514": 37, "179802": 39, "18": [1, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 45, 48, 49, 50, 54, 57], "180": [37, 39, 47], "1800": [12, 13, 15, 19, 26, 30, 31, 33, 37], "18000": 48, "180000": [13, 26, 31], "180279e": 39, "180388": [15, 22, 33], "1804": [15, 22, 33], "18066406": 46, "180900": 42, "180926": 27, "18096": 48, "181": 49, "18113": 48, "18116": 48, "1813": 37, "182": [48, 49], "18201414": 41, "182382": 27, "18245": 48, "182639": 39, "182648": 39, "1830": 26, "18311": 48, "18313": 48, "18317085": 8, "183179": 49, "183423": [15, 22, 33], "183471e": 39, "18365": 35, "18391": [16, 23, 34, 35], "184": [48, 49], "1840": [12, 19, 26, 30], "184405": 41, "1847": [17, 24, 35], "185": [14, 21, 49], "185000": 14, "185155": 41, "185175": 49, "18533": 48, "1854": 37, "185707": [15, 33, 37], "18571": [16, 23, 34, 35], "18572": [16, 23, 34, 35], "18573": [16, 23, 34, 35], "18574": [16, 23, 34, 35], "18575": [16, 23, 34, 35], "18576": [16, 23, 34, 35], "1858": 42, "185868": 42, "185975": 41, "18597545": 41, "186": 28, "186024": [12, 19, 30], "186814": 38, "186899": 38, "187": [14, 18, 21, 32, 36, 40], "1870": 37, "187000": [16, 23, 34], "1872": 39, "1875": [18, 36, 46], "187503": 48, "187663": [15, 22, 33], "187700": [16, 23, 34], "188": [12, 14, 18, 19, 21, 30, 32, 36], "1880": 37, "1886": [18, 36], "1887": [38, 41], "189": 28, "18955": 48, "189981": 39, "19": [1, 8, 12, 13, 14, 15, 17, 19, 22, 24, 26, 30, 31, 32, 33, 35, 37, 38, 39, 42, 45, 46, 48, 49, 52, 54], "190": [14, 21, 32, 39, 42], "1900": 26, "19000e": [15, 33], "1901": [12, 19, 30], "190319": 42, "19032": 48, "1904": [15, 22, 33], "190617": [16, 23, 34, 35], "190833": 21, "191": [16, 21, 23, 32, 34], "1910": 26, "1911": 42, "191169": [39, 41], "191204": 42, "191250": [14, 21, 32], "191396": [15, 22, 33], "191700": 42, "1918": [17, 24, 35], "191k": 41, "1920": [12, 19, 30], "19213263": [17, 24, 35], "192133": [17, 24, 35], "19266": 48, "1927": 52, "1928": 52, "193": 47, "1930": [12, 19, 30], "193021": 38, "193122": 38, "193247": 42, "1933": [13, 26, 31], "193346": 41, "1934": 26, "193427": 37, "19365": 48, "193704": 48, "19380": 48, "1940": [17, 24, 35], "194002": [15, 22, 33], "194034": 48, "194040": [16, 23, 34], "19422": 41, "19433594": 46, "1944": 26, "1945": 39, "1946": [12, 19, 30, 39], "194710": 39, "1948": 26, "19485": [16, 23, 34], "194914": 27, "194985": 39, "195": [16, 23, 34], "1950": 39, "1951": [13, 26, 31], "195228": 35, "1953": [37, 39], "19536": 38, "1954": 46, "1954400510": 26, "1955": [13, 26, 31], "195564": 42, "1957": 46, "1959": [12, 19, 26, 30], "19591": 42, "1960": [13, 26, 31], "1962": 46, "1963": 37, "196385": 41, "1965": [13, 26, 31], "196599": 39, "1966": 39, "196717": 47, "196739": 48, "1968": [12, 19, 30], "196963": 27, "1970": [18, 36, 39, 48], "197083": 14, "1971": 26, "1972": 39, "1975": 26, "197500": 21, "197649": 42, "1977": [12, 19, 30, 49], "19777": [40, 41], "19781": 48, "197884": 28, "198": 47, "198127": 39, "1984": 39, "1985": 39, "1986": 26, "198629": 47, "198645": 49, "1987": [12, 13, 19, 26, 30, 31], "1989": [12, 19, 30], "198924": [16, 23, 34, 35], "199": [12, 15, 19, 22, 30, 33, 38], "1990": [15, 18, 33, 36, 37], "1991": [13, 26, 31, 40], "1992": 48, "1993": 39, "199364": 38, "1994": [12, 19, 30], "199412": [27, 49], "199413": [15, 33, 37], "19966": [16, 23, 34, 35, 42], "1997": [18, 26, 36, 37], "199771": 41, "1_000_000_000": 37, "1d": [28, 47], "1e": [37, 39], "1e3": 37, "1e4": 37, "1h": [16, 23, 34, 35, 42], "1st": [8, 38, 40, 41, 48], "1stflrsf": [39, 41, 50], "1v": 53, "1v2": 53, "1v3": 53, "2": [1, 4, 7, 8, 9, 10, 26, 27, 28, 40, 41, 42, 46, 47, 48, 51, 52, 53, 58], "20": [1, 4, 8, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 49, 52, 53, 54, 56, 57, 58], "200": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 46, 47, 50, 55, 56, 57], "2000": [15, 22, 28, 33, 37, 38, 39, 40, 41, 42, 47, 51, 53], "200000": [37, 48], "200000e": 26, "2003": 26, "200326e": 39, "2004": [26, 39], "200458": 27, "200475": 38, "2005": 26, "2006": [39, 41, 50], "2007": [26, 39, 41, 48, 50], "2008": [26, 39, 41, 48, 50], "200876": [17, 24, 35], "20087625": [17, 24, 35], "2009": [26, 39, 41, 48, 50], "200978": [15, 22, 33], "201": [1, 15, 22, 33, 58], "2010": [39, 41, 48], "20113": [16, 23, 34, 35, 57], "2012": [8, 16, 23, 34, 37, 58], "2013": [26, 46, 48], "201332": 44, "2014": [12, 19, 26, 30, 40, 48], "20140521t000000": 26, "20140623t000000": 26, "20141013t000000": 26, "20141015t000000": 26, "20141209t000000": 26, "2015": [26, 47, 48], "20150116t000000": 26, "20150218t000000": 26, "20150223t000000": 26, "20150225t000000": 26, "20150630": 48, "2016": [8, 47, 48], "20160101": 48, "2017": [41, 48], "201810": 38, "201862": 42, "202": [1, 15, 22, 33, 35, 58], "2020": 52, "2022": 48, "202247": 27, "2022w2": [12, 19], "2023": [1, 48], "2024": [0, 1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57], "20248": [16, 23, 34], "2024w1": [0, 10, 12, 47], "2024w2": [10, 12, 19], "2025": 1, "20274": 48, "20277493": 28, "202775": 28, "202839": 38, "203": [1, 15, 22, 33, 58], "20310": 48, "20311": 42, "20319": 48, "203265": 41, "20334": 48, "203421": 39, "203500": [16, 23, 34], "20357847293371834": 18, "20357847293371892": 36, "204": [1, 13, 14, 15, 21, 22, 31, 32, 33, 37, 46, 55, 58], "204167": [14, 21, 32], "2043": 49, "204302": 48, "20433": 42, "204583": [14, 21, 32], "2046": 35, "204600": [15, 33, 37], "204692": 39, "204734": 38, "20485": 48, "205": [13, 14, 15, 21, 22, 28, 31, 32, 33, 55], "205000": [16, 23, 34, 35, 39, 41, 50, 57], "205059": 42, "20509": 48, "20514": 48, "205144": 42, "205323": 48, "205479": [18, 36], "205597": 39, "20564": 48, "206": [13, 14, 15, 21, 22, 31, 32, 33, 37, 38, 51, 55], "206019": 27, "206041": 41, "206073": 38, "206099": 37, "20620": 48, "206292": [16, 23, 34], "20639": 42, "2064": [16, 23, 34], "20640": [18, 36, 42], "206724": 49, "20683258": [18, 36], "20694": 48, "20699": 26, "207": [13, 14, 15, 16, 21, 22, 23, 31, 32, 33, 34, 37, 46, 47, 55], "207039e": 39, "2071": 42, "207814e": 39, "2079": 26, "20794": 48, "208": [13, 14, 15, 18, 21, 22, 31, 32, 33, 36, 37, 55], "209": [12, 13, 14, 15, 19, 21, 22, 30, 31, 32, 33, 37, 55], "209221": 50, "209583": 32, "209746": 38, "209903": 42, "20analysi": 49, "20assumpt": 49, "20hazard": 49, "20intro": 49, "20learn": 47, "20lifelin": 49, "20with": 49, "21": [1, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 28, 30, 31, 33, 34, 35, 38, 39, 42, 43, 45, 46, 48, 52, 58], "210": 37, "210000": 14, "210001": 38, "210240": 37, "210272": 42, "210286": 27, "210417": 21, "210591": [16, 23, 34, 35], "210779": 48, "21086181023099465": 18, "21086181023099526": 36, "211": 37, "2110": [16, 23, 34], "211250": [14, 21, 32], "211343": 42, "211544": 38, "211724": 27, "211892": [16, 23, 34, 35], "212": [1, 14, 32, 37, 58], "212385": 41, "212581": 42, "21274": 48, "212870": 39, "212975": 39, "213": [14, 37, 47, 48], "2130": [12, 19, 30], "21353": 48, "21382972": 40, "21389": 48, "213896": 26, "2139": [16, 23, 34, 35, 57], "214": [12, 19, 30, 35, 37], "21405": 48, "21436": 26, "2144": 37, "21450": 26, "214740": [16, 23, 34], "214769": 47, "214821": 48, "214852": 38, "2149": 28, "215": 37, "2150": 28, "2151": 28, "215167": 27, "2152": 28, "215245": 39, "2153": 28, "21530": 48, "2154": 28, "215412": 39, "21549": 48, "2155": 28, "2156": 28, "21571": 48, "21581": 48, "21582031": 46, "215865": 41, "21596": 48, "216": 37, "21603": 48, "21605": 48, "21608": 26, "21609": 26, "21610": 26, "21611": 26, "21612": 26, "216123": 49, "21613": [13, 26, 31], "21616484": 53, "21617": 48, "216250": 21, "216346": 41, "21634631": 41, "216585": [16, 23, 34], "216596": 48, "21668": 48, "21670": 48, "216718": 38, "216728": [16, 23, 34], "21694": 48, "21697": 48, "217": [28, 51], "2170": [13, 26, 31], "217083": 14, "217334": [17, 24, 35], "21733442": [17, 24, 35], "2173627": 46, "217500": 14, "21767954": 41, "21768": [41, 48], "217680": [40, 41], "21774": 48, "218": [17, 24, 28], "218207": [16, 23, 34, 35], "21847": 48, "21872": [39, 41, 50], "218760": 41, "218830": [16, 23, 34], "218867": 27, "219": [28, 42], "2190": [16, 23, 34], "2192": 37, "219500e": 26, "219512": 42, "219700": 42, "219714": 27, "21972656": 46, "219845e": 39, "22": [15, 16, 22, 23, 28, 33, 34, 35, 37, 38, 39, 40, 41, 42, 46, 48, 49, 52, 53, 57, 58], "220": [28, 32], "2200": 28, "22001": 41, "220392": 49, "22057": 48, "2206": 49, "22078": 48, "221": 28, "2210": [12, 19, 26, 30], "22114": 48, "221329": 39, "221348": 48, "2214": 52, "22154": 48, "221622": [16, 23, 34, 35], "22168237": 53, "221760": 27, "221900": [13, 26, 31], "222": [1, 28, 58], "22219": 48, "22221894": 39, "222222": [16, 23, 34], "22225": 48, "222307": [16, 23, 34], "222500": [21, 32], "22260": 48, "222647": [39, 41, 50], "2229": [18, 36], "222963e": 39, "223": 28, "22305705": 40, "22320": 48, "223333": [21, 32], "223460": 49, "223750": [21, 32], "223804": 41, "224": [28, 37, 47], "22452": 48, "2246468746": 32, "224662": 39, "22471154513694652": 18, "22471154513694713": 36, "224865": [39, 41], "225": 47, "225301e": 39, "2254": [16, 23, 34], "22550": 48, "226": 37, "226415": [16, 23, 34], "226789": 49, "2268": 40, "22697768": [17, 24, 35], "226978": [17, 24, 35], "2270": 37, "227143": [16, 23, 34], "2272": [38, 51], "227304": 48, "22741": 42, "227559": [39, 41, 50], "227836": 38, "22788": 48, "22811601": [18, 36], "22826": 48, "228329": 38, "2285": 48, "22851562": 46, "228603": 39, "228750": [14, 21, 32], "229": 47, "229000": [16, 23, 34], "22910": 48, "229102": 41, "229167": 14, "2293467570951035": 40, "2295": 48, "229583": [14, 21, 32], "229718": 41, "23": [1, 15, 16, 18, 22, 23, 26, 28, 33, 34, 35, 36, 37, 38, 39, 42, 46, 48, 49, 57], "230": [15, 33, 37], "2300": [12, 19, 30], "230000": 26, "23011": 41, "2305": 41, "2307": [14, 18, 21, 32, 36], "2309": 48, "23091772": 40, "231": [1, 58], "2310": [26, 48], "2311": 48, "2312": 48, "2313": 48, "23175": 48, "231815": 41, "232": 28, "232075": 27, "232143": 35, "232751": 49, "23290": 48, "233": [13, 26, 31], "2334": 16, "234": 49, "234040": 38, "234303": 26, "234436": 49, "235": [28, 42], "235096": [16, 23, 34, 35], "235152": [15, 22, 33], "235417": 32, "235706": 42, "235833": 14, "236": [15, 28, 33, 37, 49], "2360": 26, "236096": 47, "236174": 42, "236210": 43, "23621041": 43, "23640124": [18, 36], "236456": [16, 23, 34], "23654": [38, 41], "236960": 37, "237": [28, 38, 49], "237935": 41, "238": [28, 38, 49], "238192": [38, 41], "2388": 26, "2389": 35, "239": [28, 49], "23902": 48, "239082": 27, "23941": 48, "239944e": 39, "24": [1, 10, 12, 15, 16, 19, 22, 23, 27, 28, 30, 33, 34, 38, 39, 40, 41, 42, 46, 47, 48, 49], "240": 49, "2401": 42, "240893": 42, "241": 49, "241489": 49, "241620": 38, "24182": 48, "242015": [40, 41], "242083": 32, "242169": 38, "242381": 48, "242740": 27, "24295676": [17, 24, 35], "242957": [17, 24, 35], "242996": [16, 23, 34, 35], "243": 48, "2431": 16, "243243": 39, "2435": 42, "2436": 42, "24395": [40, 41], "24397122221206388": 48, "244": 48, "244592": [15, 22, 33], "2447": 40, "244814": 49, "245": 48, "2451": 37, "245329": 39, "245521": 38, "245635": 27, "245686": 38, "246": [48, 52], "246332": 39, "246486": 28, "246646": 37, "246646103936": 37, "246653": 37, "247": 48, "247119": 48, "247439": 43, "24743939": 43, "247690828913": 37, "247691": 37, "248": 48, "248328": 40, "248333": [21, 32], "2484": [12, 19, 30], "248457": [39, 41, 50], "248609": 39, "248664": 42, "2487200875": 26, "2488": [15, 22, 33], "248999": 49, "249": 52, "2496": [14, 18, 21, 32, 36], "249601e": 39, "249618e": 39, "249720": [15, 22, 33], "24h": [38, 51], "24th": [12, 19], "25": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57], "2500": [8, 28, 52], "250000": [16, 23, 26, 34, 38, 39], "25031": 48, "25037": 48, "250588": 28, "2506": [13, 14, 21, 31, 32, 55], "250900": 39, "251093": 37, "251158e": 39, "2516": 40, "25176": 48, "251769": 47, "252": 51, "252042": 42, "25214": 48, "252160": [15, 22, 33], "252859": 41, "2530": [12, 19, 30], "2533": [14, 18, 21, 32, 36], "253312": [16, 23, 34, 35], "253432": 41, "253724": [15, 22, 33], "253914": 39, "254380": 49, "254443": 38, "25498295": 28, "254983": 28, "255": [16, 23, 27, 34], "2550": 26, "2551": 52, "255134": 47, "2556": 40, "255751": 42, "255889": 48, "256": [12, 19, 30, 47], "25622": 48, "256263": [40, 41], "256333": [16, 23, 34], "256437": 42, "25658": 42, "256813": [15, 22, 33], "257": [13, 26, 31], "2570": [12, 13, 19, 26, 30, 31], "257024": 37, "257103": 38, "2574": 42, "257787": 28, "2580": [12, 19, 30], "258225": 48, "25823": 38, "258387": 41, "2584": 46, "258427": [15, 22, 33], "259": [39, 42], "259026": 27, "25904": 48, "2590575478171884": [18, 36], "259085": 27, "259286": [15, 22, 33], "259500": [16, 23, 34], "259520": 27, "26": [8, 12, 15, 19, 22, 23, 28, 30, 33, 34, 37, 38, 39, 40, 41, 42, 43, 46, 48, 49, 52], "2600": [16, 23, 34, 35, 57], "260258": 42, "26048": 41, "260572": 39, "26063": 48, "260890": [39, 41, 50], "261035": 39, "261953": 48, "262": [39, 41, 49, 50], "262079e": 39, "262156e": 39, "262269e": 39, "2623": 39, "262361": 42, "262500": 39, "262990": 38, "263": 39, "2630": [16, 23, 34], "263000018": 26, "263541": 49, "263600": [16, 23, 34], "26370005": [18, 36], "263736": 49, "263742e": 39, "26376": 48, "264195": 49, "264283e": 39, "26447953": [17, 24, 35], "264480": [17, 24, 35], "265": 40, "265273": [18, 36], "265483": 27, "266120": 48, "266135": [16, 23, 34, 35], "2670": 37, "267612e": 39, "268": 37, "2683": 38, "26831": 48, "2691": [13, 14, 21, 31, 32, 55], "26919": 42, "269880": [15, 22, 33], "269972": [39, 41, 50], "27": [1, 8, 15, 16, 17, 22, 24, 26, 28, 33, 35, 37, 38, 39, 46, 48, 49], "270093": 37, "270093376167": 37, "27021": 48, "270270": 45, "27048": 38, "2705": 37, "271037": 42, "271287": 48, "271500": 42, "271738e": 39, "2720": [13, 26, 31], "27206": 48, "27263": 41, "272667": [16, 23, 34, 35], "2730": [16, 23, 34], "27304": 26, "273382": [16, 23, 34, 35], "273606": [16, 23, 34, 35], "273890": 47, "2739": [20, 27], "273962": 42, "274": [16, 23, 34, 35, 48, 57], "274404": [16, 23, 34], "275008": 48, "27502379069": 39, "275290": 38, "275352": [15, 22, 33], "275410": [18, 36], "2759": 41, "276": [16, 23, 34], "27610135": 46, "27638": 48, "27652": 38, "276687": 39, "27676": [38, 51], "27678": [38, 51], "276943e": 39, "27697": [38, 51], "2770": 37, "27705": [38, 51], "27715": [38, 51], "277381": [15, 22, 33], "2777": 49, "278": 52, "278441": 48, "278634": 38, "27874871715903093": 36, "27874871715903127": 18, "278755": [17, 24, 35], "27875502": [17, 24, 35], "2788": [14, 18, 21, 32, 36], "2794": [18, 36], "28": [1, 15, 16, 18, 22, 23, 33, 34, 35, 36, 37, 38, 39, 42, 43, 46, 48, 49], "280": [16, 23, 34, 42, 52], "2800": 8, "280028": 42, "280310": [16, 23, 34, 35], "2806": 37, "280618": 38, "2807": 49, "280801": 49, "281": [16, 23, 34], "28122025543": 39, "281583": 39, "2817": 41, "2820": 37, "282021e": 39, "2822": 41, "282600": 49, "283119e": 39, "28327": 48, "283421": 39, "2836": 41, "28362": 48, "283857": [15, 22, 33], "283921": [16, 23, 34], "284": [42, 48], "2845": 49, "2846": 52, "2847": 52, "285": [16, 23, 34, 35, 48, 57], "285263": 41, "28526302": 41, "285467": [39, 41, 50], "28571429": [13, 20, 31], "286": [14, 15, 21, 32, 33, 37, 48], "286000": 37, "286200": 42, "286326": 27, "286416": 35, "2865025": 53, "286821": [15, 22, 33], "287": 48, "287031": 48, "287079e": 39, "287344": [16, 23, 34, 35], "287500": 42, "28753559": 46, "288": 48, "288002": 48, "288462": [18, 36], "28854": 48, "28868": 38, "289": 48, "2890": [15, 33, 37], "28953": 48, "289541": [39, 41, 50], "289799": [15, 22, 33], "29": [8, 15, 16, 22, 23, 26, 28, 33, 34, 38, 39, 46, 48, 49, 52], "290": [26, 48], "290002": 38, "290424": 39, "29045704": 39, "290961e": 39, "291": [18, 26, 36, 48], "291310100": 26, "291667": 45, "292": 48, "292587": 49, "293": 48, "29324459": 47, "293663": 38, "294": [16, 23, 34, 46], "294251": [17, 24, 35], "2948": [16, 23, 34, 35, 57], "294855": 41, "295193": 27, "2953863599856858": 18, "2953863599856862": 36, "295397": 38, "29545": 39, "2957": 28, "29572402": 46, "2958": 28, "2959": 28, "296": [16, 23, 34], "2960": 28, "2961": 28, "2962": 28, "2963": 28, "2964": 28, "296601": 42, "29691": 48, "297": [18, 36], "29802": [38, 41], "298043": 27, "298436": 27, "298561": 49, "298612": 48, "29881": 48, "299": [26, 47], "299164": 42, "2d": [20, 28, 47], "2d454e5fd9a5": 49, "2e": 1, "2f": [14, 21, 29, 32, 37, 45, 48], "2m7m0lw97rvf654x1cwtdfmr0000gr": 23, "2nd": 36, "2ndflrsf": [39, 41, 50], "2v": 53, "2v3": 53, "3": [1, 7, 8, 10, 15, 17, 18, 22, 24, 27, 28, 29, 33, 35, 36, 37, 38, 39, 40, 41, 45, 46, 47, 48, 50, 51, 53, 54, 58], "30": [1, 4, 12, 14, 15, 18, 19, 21, 22, 28, 30, 32, 33, 36, 38, 39, 40, 41, 42, 46, 48, 49, 50, 52, 58], "300": [15, 22, 33, 44, 46, 50, 53], "3000": [28, 47], "300000": [16, 23, 34, 35, 48], "3000000": 46, "300464": 42, "300837": 38, "301": 49, "3010": 42, "301200": 37, "3014": 42, "30146": 48, "301563": 39, "30167": 48, "301784": 49, "3018": 58, "301838": 50, "3019": [13, 14, 18, 21, 31, 32, 36, 55], "301952": 42, "302": [39, 41, 50], "302043": 27, "302131": 39, "30279": 48, "302801": 49, "302844": 49, "303": [39, 41, 50], "303000": [16, 23, 34], "303004": 42, "303030": [18, 36], "303109": [17, 24, 35], "303694": 27, "303790": 37, "3038": 52, "3038344082": 41, "303916": [15, 22, 33], "304": [15, 22, 33], "3040": 48, "3041": 48, "3042": 48, "3043": 48, "3044": 48, "304784": 39, "305": [12, 19, 30], "30504657": 43, "305047": 43, "30530902": [15, 22, 33], "305346": [15, 22, 33], "305674": 42, "3057": [14, 18, 21, 32, 36], "30573": 42, "306500": [15, 22, 33], "306564": 47, "307": [16, 23, 34], "307516": 47, "307521": [18, 36], "30792853": 46, "30798381": 46, "308120": [16, 23, 34], "30815": 39, "308216": 47, "308236": 27, "308448": [15, 22, 33], "3089": 37, "308900e": 26, "309": 42, "3092": [13, 14, 21, 31, 32, 55], "309249": 47, "309859": [18, 36], "30am": 12, "30pm": 1, "31": [1, 12, 15, 16, 18, 19, 22, 23, 26, 30, 33, 34, 35, 36, 38, 39, 40, 41, 43, 46, 48, 49, 52, 57], "310000": [16, 23, 34], "31000e": [15, 33], "310284": 41, "31029469": 28, "310295": 28, "31038074": 46, "310405": 38, "311": [16, 23, 34], "3110": [16, 23, 34], "311151": 49, "31127015": 41, "311310": [12, 19, 30], "311769": 42, "3119640638146517": 18, "31196406381465247": 36, "3120": [16, 23, 34], "3125": [16, 23, 34], "312500": [16, 45], "312501": [39, 41, 50], "312696": 52, "3129": 52, "31297381": [17, 24, 35], "312974": [17, 24, 35], "31298589e": 47, "313": [35, 39], "31384": 38, "314": [16, 23, 34], "3140": [16, 23, 34], "314000": 37, "31449687e": 41, "31454": 42, "314582": 41, "314840": 42, "314929": 48, "315000": 26, "315134": 48, "315630": 38, "316164": 42, "316230": 42, "31634363": 46, "316363": [15, 22, 33], "316395e": 39, "316426": 42, "316552": [17, 24, 35], "31655231": [17, 24, 35], "316798": 42, "317": [1, 16, 23, 34, 41, 58], "317277": 42, "31767136668453344": 26, "317761": 38, "318": [16, 23, 34], "3180": 37, "3180174485124284": [16, 23, 34], "318937": [16, 23, 34, 35], "319": [13, 16, 17, 23, 24, 26, 31, 34], "31908384": 47, "319481": 27, "319559": 26, "319630": 49, "31984311": 39, "31st": 48, "32": [8, 15, 16, 18, 22, 23, 27, 28, 33, 34, 35, 36, 37, 39, 43, 46, 48, 49, 57], "320": [16, 23, 34], "320155": 38, "320430": 39, "32064171": 40, "3209427041566191": 26, "321": 41, "321050": 26, "32127053": 39, "322": 42, "32240": [40, 41], "322465": 26, "32247597e": 41, "322755": [15, 22, 33], "323045": [16, 23, 34, 35], "32323": [12, 19, 30], "32397724e": 41, "3245": [12, 30], "324762": 27, "325000": 26, "3252": 42, "325319": 42, "32561": 38, "326": [16, 23, 34, 42], "326616": 26, "326730": 38, "326741e": 49, "326933": [15, 33, 37], "327188": 38, "3272": 49, "327283": 39, "32734": 42, "3274": 49, "327408": 38, "32791718": 46, "328": 42, "328000": 26, "328077e": 39, "328953": [15, 22, 33], "3298721": 47, "3299": [46, 52], "33": [8, 12, 15, 16, 18, 19, 22, 23, 26, 30, 33, 34, 35, 36, 37, 38, 39, 42, 46, 48, 49], "330": [9, 10, 13, 20, 28, 30, 31, 47, 48, 50, 52, 58], "33000e": [15, 33], "330346": 49, "330_vs_340": 12, "3310": [16, 23, 34], "331588": 27, "33191802": 46, "332130": 39, "33223002": 46, "3322447": 46, "33224516": 46, "33224759": 46, "332671": 41, "3327": 48, "332710": 39, "332746": 49, "332791": 49, "332824": 39, "333": 28, "3330": [16, 23, 34], "33308783": [17, 24, 35], "333088": [17, 24, 35], "333139": 38, "333333": [13, 16, 20, 23, 27, 31, 34, 37, 45], "3333333333333333": [45, 47], "333340": [15, 22, 33], "33380649": 46, "33380754": 46, "33380761": 46, "33381373": 46, "33394593": 46, "3339473": 46, "33394769": 46, "33395626": 46, "33397112": 46, "334": 42, "33400489": 46, "33411086": 46, "33425967": 46, "33435326": 46, "33439238": 46, "33440682": 46, "334411": [15, 22, 33], "334576": 39, "33462759": 46, "334764": 27, "33476534": 46, "335": 40, "335309": 39, "3355": [16, 23, 34, 35, 57], "3356700488_183566145b": 47, "33590": 48, "336389": 41, "33641142": 41, "3364114233677307": 41, "336411423367732": 41, "33643394": 28, "336434": 28, "336735": 37, "336826": [17, 24, 35], "33682642": [17, 24, 35], "33683087": [18, 36], "336831": [18, 36], "337034": 42, "33726089": 39, "33732465": 46, "337625": 27, "33782315": 46, "33797555": 46, "338": [15, 33, 37], "33888659": 8, "339": 38, "339368": 49, "339889": 49, "34": [12, 15, 16, 18, 19, 22, 23, 28, 30, 33, 34, 35, 36, 38, 39, 42, 46, 48, 49, 57], "340": [1, 3, 13, 20, 31, 40, 42, 47, 48, 49], "34000e": [15, 33], "340988": 38, "341109": 39, "341300": 42, "341571": 49, "34161762": [39, 41], "341712": 48, "34182": 41, "3420": [16, 23, 34], "342200": 42, "342605e": 39, "3436": 48, "3437": 52, "3438": 52, "344": [16, 23, 34], "3442": 49, "34426571": 39, "34441": 39, "345": 41, "345136": [15, 22, 33], "345386e": 39, "3454": [49, 52], "3455": 52, "345831": [12, 19, 30], "346": [16, 23, 26, 34, 35, 57], "346850": 38, "34691": 48, "347523": 37, "348": [16, 23, 34, 42], "34806": 39, "348569": 50, "34900": 39, "34924955": 46, "35": [15, 16, 18, 22, 23, 26, 33, 34, 36, 38, 39, 40, 41, 46, 48, 49, 56], "350": [12, 19, 30], "3500": [28, 56], "350000": [16, 23, 34], "351351": 45, "351366": 38, "3515": 49, "351821": 49, "351883": 50, "3520": 49, "3521": [12, 19, 30], "352100": 42, "352930": [16, 23, 34, 35], "353": [1, 47, 58], "35375221": 53, "353961": 37, "354114": [39, 41, 50], "354604": 38, "3547": 42, "354759e": 39, "35561437": 46, "356689": [40, 41], "35671794": 41, "357": [16, 23, 34], "3573886": 46, "357500": [16, 23, 34, 35], "3576": [12, 19, 30], "35771821": 46, "357823": [12, 19, 30], "358": [12, 19, 30, 37], "358032": 41, "3582": [49, 52], "358264": [39, 41, 50], "3583": 52, "358333": [15, 22, 33], "358500": 42, "358913": [17, 24, 35], "3589134": [17, 24, 35], "359": [15, 33, 37], "3590": 37, "359784": 37, "359887": 43, "359992": [15, 22, 33], "35p": [12, 19, 30], "36": [15, 16, 18, 22, 23, 26, 28, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 48, 49], "360": [1, 35, 58], "360000": 26, "360918": 48, "361": 49, "361718": 38, "362": [26, 49], "362009": 48, "362185e": 39, "362553": 42, "36269995": [17, 24, 35], "362700": [17, 24, 35], "363": 49, "363192": [15, 22, 33], "363913": 38, "364": [48, 49], "364352": [18, 36], "365": 48, "36525": 41, "365420": 52, "365603": [18, 36], "365623": [15, 22, 33], "365898": 27, "365925": 27, "366": [17, 24, 35, 48, 49], "366005": 38, "366071": 16, "3663": 49, "366626": [15, 22, 33], "36695134": 46, "367": 48, "367329e": 49, "367423": 37, "368": [48, 52], "3681": 41, "368304": [18, 36], "3684": 49, "368406": 28, "368922": 44, "369": 39, "369875": [15, 22, 33], "369896": 47, "37": [16, 18, 23, 26, 28, 34, 35, 36, 39, 42, 46, 48, 49, 52, 57], "37050406": 8, "370643": 38, "370842": 26, "371": [42, 48], "3717": 41, "371722": 41, "372": [16, 23, 34], "372706": 48, "372763": [39, 41, 50], "373031": [15, 22, 33], "373275": 48, "373318": 27, "373411": 26, "373623580": 28, "373656": 48, "374": [16, 23, 34], "374584": 47, "374995": 38, "37546": 41, "376": [16, 23, 28, 34, 39], "376089": 39, "37647072": 40, "3768": 52, "3769": 52, "377032": 39, "377619": 37, "377619120792": 37, "37797291": [17, 24, 35], "377973": [17, 24, 35], "37807203": 46, "378159": 39, "378764": [15, 22, 33], "378971e": 39, "37903": 28, "37906": 38, "379416e": 39, "379875e": 39, "38": [8, 15, 16, 18, 22, 23, 26, 33, 34, 36, 38, 39, 42, 46, 48, 49], "3803": 49, "380436": [17, 24, 35], "38043616": [17, 24, 35], "380495": [15, 22, 33], "380504": [16, 23, 34, 35], "380643": [15, 22, 33], "381190": 42, "3814": 35, "381416e": 49, "381428": [39, 41, 50], "381676": [15, 22, 33], "38192364": 43, "381924": 43, "382558": 38, "3828125": 46, "383": [16, 23, 34, 42], "384111": 52, "384127": [15, 22, 33], "384528": 27, "384613e": 37, "3851": 38, "3856": [15, 22, 33], "385639": 43, "386": 37, "386071e": 39, "386530": [41, 50], "387": 37, "388023": 38, "388169": 42, "38853": 39, "3889": 35, "389": [37, 42], "389065": 41, "389349": 42, "389736": [16, 23, 34, 35], "39": [15, 22, 33, 37, 38, 39, 43, 46, 48], "390428669205": 37, "390429": 37, "390691": 26, "390725": 39, "39095422e": 41, "391": [16, 23, 34], "3912": 49, "391304": 26, "39163": 38, "391996": 47, "392": [12, 19, 30, 49], "392082": 41, "392221": [18, 36], "392385": 49, "392612": 39, "392893": [15, 33, 37], "393": [13, 26, 28, 31, 35], "3932": 49, "39375": 48, "394113e": 39, "394920": [16, 23, 34], "395282e": 39, "395686e": 39, "395688": 49, "395697e": 39, "396": [16, 23, 28, 34, 49], "396266": 47, "396752e": 39, "396991": [16, 23, 34, 35], "397": 49, "398": 42, "398495": 48, "398915": 27, "39896994": [17, 24, 35], "398970": [17, 24, 35], "399": [16, 23, 26, 34], "3990": [13, 14, 21, 31, 32, 55], "3991": 39, "39931": 41, "399827": 38, "39x15": 46, "3blue1brown": 47, "3d": [42, 47], "3f": [13, 14, 15, 16, 20, 21, 22, 23, 29, 31, 32, 33, 34, 38, 39, 45, 46, 52], "3h": 48, "3m": 47, "3rd": 46, "3ssnporch": [39, 41, 50], "3v": 53, "4": [0, 1, 8, 9, 12, 16, 17, 18, 19, 23, 24, 26, 28, 30, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 58], "40": [8, 12, 15, 16, 18, 19, 22, 27, 28, 30, 33, 36, 37, 38, 39, 40, 41, 42, 44, 48, 49, 50, 56, 58], "400": [13, 16, 23, 26, 31, 34, 37, 50], "40000": [47, 48], "400000": [16, 26, 37, 48], "400047": 49, "400157": 42, "400164": 47, "400649628005": 37, "400650": 37, "400881e": 26, "401": [15, 26, 33, 37], "4011": 46, "401102": 48, "401541": 38, "401623": 39, "401729": 27, "4018": 58, "401830": 41, "401895": 37, "402": [12, 19, 30], "402101": 26, "402258": 26, "402808": 41, "404": [15, 22, 33, 42], "405": [40, 58], "405227e": 39, "405415": [15, 22, 33], "405650": 39, "406": 47, "406202": 37, "40689": 42, "407": 38, "407234": 47, "40725012": 47, "4074": 58, "407510": 38, "40756124": 40, "407862": 49, "4084": 49, "409": 58, "409430": 26, "40_000": 47, "40b5a809b05a": 49, "41": [15, 16, 22, 23, 33, 34, 38, 39, 41, 42, 43, 45, 48, 49], "410": [16, 23, 34], "410240": [38, 41], "410599": 42, "410714": 16, "411412": 39, "41150573": 39, "412": [12, 15, 19, 30, 33, 37], "41210938": 46, "412500": 42, "413050": 47, "413718": 49, "413796": 39, "413958": 38, "414": 52, "4143": 49, "414405": 27, "415": 28, "4151": 40, "4153": 42, "4158382658": [23, 34, 52], "416": 41, "4165": 40, "4169": 49, "418": 46, "418031": [15, 22, 33], "418069": 37, "41901484361": 37, "419015": 37, "419355": [18, 36], "4195": 41, "4197": [13, 14, 18, 21, 31, 32, 36, 55], "42": [12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 27, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 53, 55, 56], "420": 37, "420000": [12, 19, 30], "42060": 42, "421": 47, "42104086": 41, "421215": 43, "42121526": 43, "421875": [18, 36], "422": 39, "422222": 16, "4234": 41, "4236": 41, "4238": 38, "423852": 38, "424222": 39, "424337e": 39, "425": 40, "425365": 49, "42541681": 53, "425419": 39, "426067": [16, 23, 34], "426410": [15, 22, 33], "427": 49, "427516": 27, "4276": 51, "428": 49, "428279": 27, "429": [39, 41, 50], "429217": 38, "429634": 49, "4296875": 46, "43": [15, 18, 22, 33, 36, 37, 38, 39, 48, 49], "430": [37, 39, 41, 49, 50], "430323": [16, 23, 34], "430571": 38, "430704": 43, "4307043": 43, "430868": [18, 36], "431": [32, 49], "4310": [15, 16, 23, 33, 34, 37], "431104": 27, "431137": [18, 36], "4314": 38, "432": 49, "433": 49, "433514": 48, "433814": 49, "434": [15, 18, 33, 36, 37, 49], "43445": 42, "435": 49, "435186": [15, 22, 33], "435489": 38, "435792": 37, "436": 49, "436492": 39, "43697758253484525": 18, "43697758253484614": 36, "4372": 43, "437367": [16, 23, 34, 35], "4375": [42, 45], "437500": 45, "437684": 48, "438": 45, "438231": 47, "438275": [17, 24, 35], "43827545": [17, 24, 35], "43833466": 39, "438592": [41, 50], "438906": 41, "439": [16, 23, 34], "4390": [15, 33, 37], "439209": 38, "439254e": 28, "439360": [16, 23, 34], "439779": 38, "44": [14, 15, 16, 18, 21, 22, 23, 32, 33, 34, 36, 38, 39, 42, 46, 48, 49, 52], "440": [37, 48], "440897": 26, "441": 39, "441404": 47, "441445": 42, "442": 26, "442377e": 39, "442806": [15, 22, 33], "442917": 27, "4430": 49, "44311": 42, "4432": 42, "443317": [15, 22, 33], "443419": [39, 41, 50], "444297": 42, "4443": 16, "444444": [16, 23, 34], "4448": 42, "445": 37, "445111e": 39, "445124e": 39, "44586935": 40, "44586935141902073": 40, "446216": 42, "446284e": 39, "446869": 42, "447": [16, 23, 34, 41], "447461": 48, "447517": 41, "44787197": 46, "4482": [12, 19, 30], "4484": [15, 22, 33], "448757": 49, "449262": 27, "449666": [15, 22, 33], "44966612": [15, 22, 33], "45": [8, 13, 14, 15, 16, 18, 21, 22, 31, 32, 33, 36, 38, 39, 46, 48, 49, 51, 55], "450000": 45, "450000e": 26, "450132": 48, "450739": 39, "450822": 42, "451888": 38, "452600": 42, "453367": 42, "4537": 49, "454427": [16, 23, 34, 35], "454677": 43, "45467725": 43, "454788": [41, 50], "454966": 38, "455": 35, "455026455026455": 28, "4552": 41, "45555535": 41, "455652": 26, "45587": 48, "45588": 48, "45589": 48, "45590": 48, "45591": 48, "456": 47, "456419": 42, "45653693": [17, 24, 35], "456537": [17, 24, 35], "457435": 48, "45756": 52, "458": [16, 23, 34], "458333": 45, "458524": 49, "459": [28, 39], "4591": [16, 23, 34], "459214e": 39, "459873": 49, "459937": 46, "45a": 48, "45am": 48, "46": [8, 13, 14, 15, 16, 18, 21, 22, 23, 28, 31, 32, 33, 34, 35, 36, 38, 39, 48, 49, 52, 55, 57], "460047": 49, "46019608e": 41, "46021": 52, "46075": 52, "4608": [13, 14, 21, 31, 32, 55], "460950": 43, "461": [16, 23, 34, 37], "462060": 49, "462545": 41, "462963": [18, 36], "46299": 52, "463": 38, "46357616": 28, "463582": 40, "464104e": 39, "465279e": 39, "46530779": [17, 24, 35], "465308": [17, 24, 35], "466246": 47, "4664": [12, 19, 30], "46666667": 28, "46729488": 39, "467379": 41, "467628": 42, "468": [15, 33, 37, 41], "468232": 48, "4687": 42, "46880": 52, "468995": 27, "469": [16, 23, 34, 38], "469383": 38, "4695": 38, "469571": 42, "47": [1, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 26, 30, 31, 32, 33, 34, 36, 37, 39, 42], "470": [16, 23, 34, 52], "4700": 37, "470060": 39, "470666": 39, "471000": 26, "471032": 41, "472": [17, 24, 52], "47242662": 53, "4726": 49, "472603": 39, "472790": 38, "473": 46, "473691": [15, 22, 33], "474": [28, 38], "474552": [15, 22, 33], "47491": 38, "475": 28, "475099": 41, "475540": 46, "476": [13, 20, 28, 31], "4760": 37, "47606": 42, "476092": [39, 41, 50], "476406": 41, "476412": 43, "47641249": 43, "477": [28, 37], "477291": 42, "47799": 52, "478": 28, "478060": 48, "47810154525386317": 28, "478515": 27, "479": 28, "479109": [15, 22, 33], "479132": 42, "479773": 46, "48": [13, 14, 15, 18, 21, 22, 31, 32, 33, 36, 38, 39, 45, 48, 49, 55, 58], "480": [28, 39], "4800": [12, 19, 30], "480249": [15, 22, 33], "4806334": 46, "48073598": 43, "4809": 37, "481": [16, 23, 28, 34], "4810": 51, "4813": [14, 18, 21, 32, 36], "481514": 39, "481793": [16, 23, 34], "481893": 38, "481960": 38, "482": 28, "4820": 26, "4822": 49, "483": 28, "48344371": 28, "483751": [15, 22, 33], "48390": 52, "484": 28, "48407": 52, "484937": [18, 36], "485": [28, 47], "485191": 27, "48535": 52, "4854": 41, "485722": 46, "486": [28, 41], "4861": [16, 23, 34, 35, 57], "486266": [16, 23, 34], "486664": 46, "487": [16, 23, 34], "48721": 52, "487740": 46, "4879": 52, "488": [16, 23, 28, 34], "488163": 46, "488753": 48, "489": 28, "489130": [18, 36], "489593": 46, "49": [15, 16, 18, 22, 33, 36, 38, 39, 42, 48, 49], "490": [28, 42, 53], "490000": [16, 23, 34], "490033": 39, "490568": 37, "490797": 46, "490930": 46, "491217": 38, "491366": [41, 50], "491379": [16, 23, 34, 42], "491968": 46, "492": [16, 23, 34, 38], "492270": [17, 24, 35], "492307": 46, "492551": 46, "493": [16, 23, 31, 32, 34], "493489": 46, "493544": [16, 23, 34], "493921": [17, 24, 35], "494": [15, 16, 23, 33, 34, 37], "4943": 37, "494309": 26, "495524": 27, "49575": 38, "496": 42, "496213": 39, "49668874": 28, "496757": 41, "497143": 46, "497386": [15, 22, 33], "497787": 39, "497949": 46, "498": [38, 51], "498133e": 39, "498164": 27, "498562": [15, 22, 33], "499900": [16, 23, 34], "4f": [15, 17, 22, 24, 29, 33, 35, 38, 46], "4m": 47, "4th": [38, 40, 41], "4x": 58, "5": [1, 4, 18, 26, 27, 30, 36, 37, 39, 40, 44, 45, 48, 52, 53, 54, 55, 58], "50": [1, 12, 15, 16, 17, 19, 22, 23, 24, 26, 28, 30, 33, 34, 35, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 58], "500": [12, 14, 16, 19, 23, 29, 30, 34, 38, 40, 41, 42], "5000": [12, 13, 19, 26, 30, 31, 51], "50000": 48, "500000": [15, 16, 23, 26, 34, 35, 38, 39, 44, 48, 52], "500000e": [26, 37], "500001": [16, 23, 34], "5002": 39, "500625": [15, 22, 33], "50062e": [15, 33], "500924": [16, 23, 34, 35], "501": [16, 23, 34, 52], "501071": 47, "501191": 46, "501250": [15, 22, 33], "501304e": 39, "5014": 12, "501875": [15, 22, 33], "5024752475247525": 37, "502500": [15, 22, 33], "502985": 38, "503000": [16, 23, 34], "503090": 38, "503125": [15, 33], "503750": [15, 22, 33], "503807": 46, "504": [15, 22, 33, 42], "504231": 49, "504375": [22, 33], "504429": [17, 24, 35], "504644": 37, "50475372e": 41, "504fde4fcf8": 49, "505000": 15, "505026": 26, "505180": 46, "505335": 38, "505592e": 39, "505625": [15, 22, 33], "5057": 39, "50596432e": 53, "506023": 40, "506035e": 39, "506079e": 39, "506084e": 39, "506211": [16, 23, 34, 37], "506250": 22, "506410": [18, 36], "50666667": 28, "506875": [15, 22, 33], "507130": 37, "507359": [16, 23, 34, 37], "507500": [15, 33], "50774": 37, "507740": [16, 23, 34], "50775": 37, "507750": 37, "507752": [16, 23, 34, 37], "507995": [18, 36], "508": [16, 23, 34, 39], "508125": [15, 22, 33], "508133": [16, 23, 34, 37], "508371": 37, "508534": 46, "508741": 46, "508750": 22, "50884": 42, "50899": 37, "509000": [12, 19, 30], "509001": 39, "509045": 26, "509317": [16, 23, 34, 37], "5098": 46, "509859": 46, "509930": 48, "50k": [38, 40, 41], "51": [15, 16, 22, 23, 33, 34, 35, 37, 38, 39, 41, 43, 48, 49, 50, 57], "5100": 26, "510000": [13, 15, 26, 31, 33, 37], "510421": 46, "510505": 46, "5106": 52, "510625": 22, "510697e": 26, "5107": 26, "510836": 37, "5109": 41, "511": 9, "5112": [13, 26, 31], "51137414e": 41, "51143": 42, "51150": 38, "511620e": 39, "5118": 41, "511875": 22, "512": 47, "5120": [12, 19, 30], "512000": [15, 33, 37], "51226051": 43, "5123": 46, "512319": [16, 23, 34], "512408": [39, 41, 50], "512897": [15, 22, 33], "512x640": 47, "513": [16, 23, 34], "5131": 46, "513125": 15, "513333": 28, "513678": 49, "513750": 15, "514150": 46, "514155": [16, 23, 34, 35, 39], "514347": 46, "514598e": 39, "5146": [18, 36], "514950": 28, "515000": 33, "51503393": [17, 24, 35], "515034": [17, 24, 35], "515351e": 39, "5156": [16, 23, 34, 42], "515755": 28, "515848": 42, "516199": 46, "516394": 42, "516556": 28, "516788": 27, "516858": 46, "517273": 46, "517346": 38, "518113": 46, "519000": 26, "519029": 38, "519129": 27, "52": [15, 16, 18, 22, 23, 33, 34, 36, 38, 39, 42, 48, 49, 52], "520495": 46, "52061": 48, "520700": 46, "520782": 46, "5208": [13, 26, 31], "520857": 38, "5209": 39, "5212": 39, "521284e": 39, "521567e": 39, "521578e": 39, "521743e": 39, "521772": 46, "522": 39, "522563e": 39, "5227966": 46, "523595": 46, "523684": 46, "5238095238095238": [13, 20, 31], "52398": 42, "524": [13, 20, 31, 45], "524364": 49, "525": 28, "5253": 41, "525554": 42, "525757": [15, 22, 33], "526046": 46, "526078": [16, 23, 34, 35], "526214": 41, "526442": 27, "526596": 42, "526602": 39, "526783": 27, "5274": 49, "527500": [16, 23, 34], "528": 39, "5282": 49, "528403": [15, 22, 33], "52881619": [15, 22, 33], "529210": 38, "529388e": 39, "5294": 40, "529412": [16, 23, 34], "52980132": 28, "53": [18, 26, 36, 39, 48], "530052": 37, "530978": 38, "531": 50, "5310": 16, "531116e": 39, "531353": 47, "5315": 37, "53187": 51, "532034": 39, "533027": 27, "533333": 16, "533454": 47, "533498": [15, 22, 33], "534114": 37, "534342": 42, "5345": 26, "535": [16, 23, 34, 42], "535014": [16, 23, 34], "53520104": [15, 22, 33], "535604": [16, 23, 34], "535622": 42, "536362": 43, "53636249": 43, "537267": [16, 23, 34], "537732": 46, "538000": [13, 26, 31], "538702": [15, 22, 33], "538816": 38, "5390": [38, 41], "5391": [16, 23, 34, 42], "539116": 48, "539258": 27, "539376": 49, "539459": 52, "539989": 26, "54": [39, 48, 49], "540": 48, "540000": [16, 23, 34], "540039": 46, "540359": 42, "541117": 39, "541347": 46, "541488": 42, "54152": 38, "541667": 35, "541795": 38, "542": 50, "54240": 38, "542624": 41, "542873": [16, 23, 34, 35], "543297": 37, "543351": 41, "543464": 46, "543678": 27, "544": 37, "544079": 27, "544462": 41, "545": 39, "546": [16, 23, 34], "5461": 39, "546150": 27, "546473": [18, 36], "546610": [15, 22, 33], "54676006e": 41, "547": [37, 39, 41], "547090": 46, "5471258278145695": 28, "547993": 38, "548831": 41, "54966887": 28, "549682": 38, "5498": [15, 22, 33], "549946": 46, "55": [13, 14, 15, 18, 21, 22, 31, 32, 33, 36, 38, 39, 40, 41, 48, 49, 50, 55], "55000": 37, "550000": [16, 23, 34, 35, 37], "550004": 40, "550616": 38, "55101": 48, "5513": 37, "5514": [40, 41], "5515": 49, "551579e": 39, "551862e": 39, "551975": 39, "552": [16, 23, 34, 39], "552492": 26, "552721": 40, "553": 26, "553125": 15, "553965": 41, "553979": 38, "5540": 49, "5541306485809793": 40, "55413065": 40, "554180": 48, "554463": 46, "554621": 42, "5551": [18, 36], "555180": 26, "555740": [15, 22, 33], "5566": [16, 23, 34, 35, 57], "556716": 28, "557197": 47, "557242": 38, "557739": 39, "558": [39, 41, 42, 50], "558564": 38, "55862988e": 41, "55873324": 47, "5588": [12, 19, 30], "558824": 38, "558889": 39, "559": [37, 39, 41, 50], "559284": 26, "56": [15, 22, 33, 35, 38, 39, 48, 49], "560": 26, "560053": 26, "560225": [16, 23, 34], "560625": 22, "560768": 39, "5609808539232339": 16, "561": [1, 15, 33, 37, 41, 42], "561467": [16, 23, 34, 35], "561602": 41, "561645e": 39, "562112": [16, 23, 34], "5623062252998352": 46, "562712": 46, "563": 1, "5630224174651539": 36, "5630224174651548": 18, "5630921721458435": 46, "563125": 15, "5631500400": 26, "563314": [39, 41, 50], "563467": [16, 23, 34], "5644": 39, "564483": 42, "565": 42, "5650": [13, 26, 31], "565062": 49, "56521734": 8, "565625": 22, "565679": 38, "565746": 49, "565888": [16, 23, 34], "566": [16, 23, 34], "566092": [16, 23, 34], "566222": 47, "5667": 38, "567724": 47, "567856e": 39, "568": 47, "568009": [15, 22, 33], "56804591": 39, "568125": 15, "568663": 39, "5690201394302518": 41, "56902014": 41, "569375": 33, "5694": 42, "57": [15, 16, 22, 23, 26, 33, 34, 35, 38, 39, 41, 48, 49, 50, 57], "57000": 49, "570015": 39, "570449": 38, "570473": 42, "5707": 49, "570739": 42, "571": [28, 43, 53], "571431": 46, "571500": 42, "571800": 26, "571875": 22, "571901e": 39, "571969": 42, "572": 1, "572105": [15, 22, 33], "572500": 15, "572549": [16, 23, 34], "572962": 49, "573": 53, "573050": 38, "573125": 15, "573129": [39, 41, 50], "5732": [38, 51], "57333333": 28, "573542": 42, "573818": 38, "574": 26, "57415": 48, "574260": 42, "575000": 45, "575043": 26, "575046357615894": 28, "57510": 42, "5755444169044495": 46, "575636": 28, "575907": 42, "576": [16, 23, 34], "57615894": 28, "57640869": [17, 24, 35], "576409": [17, 24, 35], "576921": 46, "577500": 15, "578452": 27, "578523": [18, 36], "578569": 27, "578654": 38, "5789": 39, "579091": 42, "579245": 46, "579432": [18, 36], "579559e": 39, "579660": 40, "5798": 40, "57994": 38, "58": [13, 14, 15, 18, 21, 22, 31, 32, 33, 36, 39, 48, 49, 55], "580": 47, "580302e": 26, "5804311633110046": 46, "580539e": 39, "580625": 15, "581": 41, "5813": 26, "58137177": [17, 24, 35], "581372": [17, 24, 35], "5814": [12, 19, 30], "581687": 42, "581787": 49, "582": [12, 19, 30, 40], "582090": 38, "5824530720710754": 46, "582469": 39, "582570": 28, "583": 26, "583125": 15, "58387198": 43, "583872": 43, "583972": 27, "584": [16, 23, 34], "584615": [16, 23, 34, 42], "585": [16, 23, 34], "585187": 28, "585513": [18, 36], "5857": 49, "586095": [16, 23, 34, 35], "586875": 22, "587773": 38, "588": [15, 33, 37], "588125": 33, "588235": [18, 36], "588307": [16, 23, 34], "589286": 52, "59": [1, 12, 15, 16, 18, 19, 22, 33, 39, 48, 49, 58], "590": 26, "590243": 46, "59049": 38, "59050": 38, "590618": 42, "590625": 15, "59082668": [17, 24, 35], "590827": [17, 24, 35], "5915": 35, "592": 52, "592401": [12, 19, 30], "59243876": 40, "592507": 27, "5925410985946655": 46, "59300": 42, "5931": 39, "593370": 39, "593508": 43, "5938": [16, 23, 34], "594": [16, 23, 34], "5941": 26, "5944": 26, "594595": [15, 22, 33], "594982": 38, "594995": 38, "5950": [16, 23, 34], "595000": 22, "595427": 47, "595569e": 39, "595625": 15, "596088e": 39, "596151": 42, "596810": [15, 22, 33], "596864": 39, "596875": 22, "5970": 40, "59700": 38, "597015": [18, 36], "59708": 38, "597326": 38, "597555": [12, 19, 30], "597924": [39, 41, 50], "598": [16, 23, 34], "598057": 28, "59810": 38, "598100": [18, 36], "598149": [39, 41, 50], "598750": 33, "599": 52, "5993570685386658": 46, "599492": [18, 36], "599860": [15, 22, 33], "599894": 48, "59pm": [12, 19], "5fin": 39, "5th": [38, 40, 41], "5unf": 39, "6": [1, 8, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 58], "60": [8, 12, 16, 19, 23, 30, 34, 38, 39, 41, 42, 43, 45, 46, 48, 49, 50], "600": [16, 18, 23, 34, 36, 46], "60000": 48, "600000": [14, 15, 22, 32, 33, 37, 48], "600193": 38, "60023631": 39, "600288": 27, "600625": 22, "600k": 39, "601": 37, "601042": [12, 19, 30], "601504": [18, 36], "601712": 38, "601790": [18, 36], "602": [16, 23, 26, 34, 35, 57], "602000": [16, 23, 34], "602649": [15, 22, 33], "6028": 38, "602941": 38, "602954": 40, "603125": 22, "6031432151794434": 46, "60319915": 53, "603243": 26, "603684e": 37, "603739": 26, "603970": 49, "604": [15, 22, 33], "6040": [15, 33, 37], "604000": [13, 26, 31], "604032": 38, "60429913": 39, "604320": [18, 36], "60455": 48, "604619": [18, 36], "604797": [18, 36], "6048": 48, "604807": 49, "60495488": [15, 22, 33], "605060": 38, "6051": [16, 23, 34, 35, 57], "605100": [18, 36], "605101": [18, 36], "605102": [18, 36], "605263": [15, 22, 33], "605625": 33, "605696": [18, 36], "606": [16, 23, 34], "606061": [18, 36], "6063088774681091": 46, "606557": [18, 36], "606567": [18, 36], "606811": 37, "606875": 33, "606902": [18, 36], "607062": 48, "608050": [18, 36], "608125": 33, "6082": [16, 23, 34], "608468": [18, 36], "608532": 47, "608565": 49, "60860": [16, 23, 34], "6086405515670776": 46, "609": [16, 23, 34], "6092": [12, 19, 30], "6093292236328125": 46, "609375": 33, "60943": 38, "60k": 39, "61": [15, 17, 18, 22, 24, 33, 35, 36, 38, 39, 43, 48, 49], "610000": 15, "610142": 27, "61029914": 39, "610407": 38, "610931": 44, "611": 35, "611007": 47, "6111123561859131": 46, "611178": 48, "612349": [17, 24, 35], "61234944": [17, 24, 35], "6124": 49, "612500": 22, "612546": 38, "612621": [18, 36], "612755": [15, 22, 33], "613231": 28, "613507": [18, 36], "613738": 37, "613738418384": 37, "614": [16, 23, 34], "61420598": [17, 24, 35], "614206": [17, 24, 35], "614567": 42, "614872": 27, "615": [16, 23, 34], "615000": 22, "6154": [16, 42], "615730": 40, "616": 37, "616099": 37, "6168": [13, 26, 31], "617342": 49, "617431": 44, "6176": 38, "617647": 38, "618": [16, 23, 34], "618000e": 26, "618012": 37, "6186580061912537": 46, "618967": 46, "619": 52, "61912405": 41, "619375": 22, "62": [15, 16, 22, 28, 33, 37, 38, 39, 48, 49], "620726": 27, "6210": 26, "622255": [16, 23, 34], "622454": 37, "622500": [15, 33], "6226": 42, "622612": 38, "622709": [18, 36], "623000": [16, 23, 34], "62320": 48, "62352928": 40, "624049": 39, "6241": [12, 19, 30], "624375": 33, "624450e": 39, "624615": 39, "6250": [16, 23, 34], "625387": 37, "6257": 49, "626206": 39, "62657": 48, "626875": 33, "62688064": 41, "627": 49, "6273": 37, "6275": [13, 14, 21, 31, 32, 55], "627722": 41, "627966": [16, 23, 34], "628032": 42, "628139": 38, "62873917": 41, "629792e": 39, "63": [15, 22, 33, 37, 38, 39, 48, 49, 52], "6303": [16, 23, 34, 35, 57], "6306": [16, 23, 34, 42], "630625": 15, "631899": 49, "632": 52, "6320": [18, 36], "6320979595184326": 46, "6322": 42, "632296": 27, "632353": 38, "632786": 48, "63316788": 53, "63362": 39, "633933424949646": 46, "634397": [18, 36], "634490": 35, "634686": 38, "635": [16, 23, 34], "635200": 42, "635239": [16, 23, 34, 35], "635648": [18, 36], "636": [12, 16, 19, 23, 30, 34, 35, 49, 57], "636364": [16, 52], "636410": 40, "636849e": 39, "637": 47, "637982": [15, 22, 33], "638169": 41, "6389": [16, 23, 34, 42], "6391518364256": 49, "6392": 42, "639754": 39, "64": [10, 15, 16, 18, 22, 33, 36, 39, 47, 48, 49], "640": [37, 47], "6400": [16, 23, 34], "640000": [38, 52], "640266": [16, 23, 34, 35], "640625": 15, "640x480": [15, 22, 33], "641216": 48, "6414100192": 26, "641538": 49, "641873": 39, "642071": 27, "642676": 48, "642965": 38, "643": 37, "6431": 42, "643311e": 39, "643315": 28, "643750": 15, "644106": 38, "64417243": 47, "644375": 22, "64454": 38, "644770": 44, "6453951434878586": 28, "645519": 38, "6458": [13, 14, 21, 31, 32, 55], "645963": 37, "646050": 41, "6464": 49, "646617": 50, "647796": 42, "648": [15, 16, 23, 33, 34, 37], "6480": 40, "648195": 38, "648550": 47, "649658": 41, "64994": 48, "65": [13, 17, 24, 31, 35, 39, 49], "650": 38, "65000": 37, "650000": 37, "65000e": [15, 33], "65013704": 43, "650743": 26, "6507517": 28, "650752": 28, "651": 26, "651250": 15, "65125032": 53, "6513": 41, "651359e": 26, "651446": 48, "651875": 22, "65243": 39, "652487": 42, "6526853": 39, "652828": 37, "652986": 42, "653": [16, 23, 34], "653205": 37, "653205232272": 37, "654": [16, 23, 34], "65424895": 39, "654375": 22, "65486": 46, "656297e": 39, "656349": [15, 22, 33], "656827": 38, "656873": 26, "657675": 42, "658047": [18, 36], "658645": [18, 36], "659056": 39, "66": [13, 14, 16, 18, 21, 23, 31, 32, 34, 36, 38, 39, 47, 48, 55], "6600060120": 26, "6601256728172302": 46, "660171": [15, 22, 33], "6604": [16, 23, 34, 35, 57], "660714": 35, "661023": 46, "66214339": [15, 22, 33], "66221": 48, "6622507572174072": 46, "662450": 38, "662541e": 39, "662745": [16, 23, 34], "662879": 40, "66368": 41, "663680": [39, 41, 50], "6637": 49, "6638": 49, "663822": 41, "6639": 49, "6639009118080139": 46, "6641": 49, "6642": 49, "664207": 38, "6643": 49, "6644": 49, "6645": 49, "664625": 46, "664707": [18, 36], "66473": 48, "665": [16, 23, 34], "665307": 46, "665351e": 39, "665625": 33, "665882": 40, "666": [16, 23, 34, 35], "666166": 48, "6666666666666666": 47, "666667": [14, 16, 23, 32, 34, 45], "666754": 47, "667450": 48, "668": 46, "668787": [15, 22, 33], "6688": [12, 19, 30], "66941678": 28, "669417": 28, "669614": 38, "669805e": 39, "67": [13, 14, 17, 18, 21, 24, 31, 32, 35, 36, 38, 39, 48, 49], "670344": [15, 22, 33], "6709133982658386": 46, "671272e": 26, "67186503136": 39, "6731126308441162": 46, "673277": 37, "6733067729083665": 28, "6733849048614502": 46, "6734487414360046": 46, "674": 28, "6744": 41, "674490": 37, "674721": 40, "675000": [12, 19, 30], "67501": 48, "67512181": 39, "67562658": [17, 24, 35], "675627": [17, 24, 35], "675676": 45, "675814": [15, 22, 33], "6759470198675496": 28, "676": 50, "676250": 33, "67672595": 39, "677": [16, 23, 28, 34], "6771429181098938": 46, "6772": 49, "677268": 49, "677567": 26, "677579": [15, 22, 33], "677601": 37, "677629": [15, 22, 33], "6778583526611328": 46, "678": [15, 33, 37], "678000": 26, "678689": [18, 36], "679240": 26, "679478": [16, 23, 34], "679877": [39, 41, 50], "68": [13, 14, 15, 17, 21, 22, 24, 31, 32, 33, 35, 38, 39, 41, 43, 44, 48, 49, 53], "680000": [12, 19, 30], "6800296306610107": 46, "680657": [16, 23, 34], "681223": [15, 22, 33], "681428": 27, "681716": 46, "683015": 40, "683171": 38, "68323": 37, "68339": 48, "684211": [15, 22, 33], "684447": [16, 23, 34], "684960": [16, 23, 34, 35], "685": 26, "685006": 28, "685103e": 39, "68523": 48, "685786": 40, "6858": [18, 36], "686": [16, 23, 34], "686348e": 39, "687": 39, "687055": 38, "687307": 37, "687500": [14, 32], "687504": 46, "688": 37, "6880359361853475": 36, "6880359361853483": 18, "688043475151062": 46, "688135": 37, "688484": 26, "689338": [39, 41, 50], "69": [13, 14, 15, 17, 21, 22, 24, 31, 32, 33, 35, 39, 43, 48, 49], "690": 52, "69027185e": 41, "690402": 37, "690778": 41, "691241": 38, "691617": 46, "691640": [15, 22, 33], "691877": 37, "691924": 43, "69192445": 43, "692131": 27, "692308": [16, 23, 34], "692500": 15, "693": [16, 23, 34], "6932538631346579": 28, "693498": 37, "693590": [17, 24, 35], "6938": [12, 19, 30, 48], "693890": 48, "693898": 48, "693936": [17, 24, 35], "69393613": [17, 24, 35], "694": 28, "69411": 42, "694155": [15, 22, 33], "694334": 40, "6950": 41, "695532": [16, 23, 34], "695783": 46, "696": 28, "696034e": 39, "6962": [16, 23, 34], "6963": 41, "696373": [16, 23, 34], "696429": 38, "696712": 48, "696859": 37, "696875": 33, "696970": [18, 36], "69698010e": 41, "697": [16, 23, 34, 42], "697248": 38, "6973": [16, 23, 34], "698": [16, 23, 34], "698125": 15, "698167": 48, "698206": 39, "698384608345687": 37, "698385": 37, "6984": 42, "698857": 37, "699224": [15, 22, 33], "6993": 26, "699706": 47, "699901396097971": 44, "6th": [38, 40, 41], "7": [1, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54], "70": [13, 14, 17, 21, 24, 26, 27, 31, 32, 35, 38, 39, 43, 44, 48, 49, 50], "70000": 48, "700000": 48, "700000e": 26, "700855": 38, "701128": 48, "701173": 37, "701186e": 39, "70162085e": 41, "7017": 49, "701863": 37, "702703": [15, 22, 33], "703406": 49, "704": [15, 16, 22, 23, 33, 34, 39], "704099": [17, 24, 35], "7041": 46, "7042": 49, "7043": 49, "7046136400143138": 36, "7046136400143141": 18, "70472": 42, "704969": 37, "705000": [16, 23, 34], "705470": 46, "705511": 37, "70560276": [17, 24, 35], "705603": [17, 24, 35], "70568": 39, "705696": [15, 22, 33], "705882": [14, 21, 32, 37], "70588235": [14, 21, 32], "705898": 42, "706": 35, "706128": [15, 22, 33], "706444": 38, "706489": 26, "706783": [17, 24, 35], "70678332": [17, 24, 35], "706966": 48, "707681": [15, 22, 33], "707712": 49, "707850": 28, "707899": 43, "70789903": 43, "70799": 37, "708": [16, 23, 34, 35, 37, 40, 57], "708075": 37, "708527": [16, 23, 34], "708978": 37, "709185": [15, 22, 33], "70978": 42, "709874": 37, "709880": 37, "709893": 48, "7099": 42, "71": [12, 13, 14, 17, 18, 19, 21, 24, 30, 31, 32, 35, 36, 38, 39, 43, 48, 49], "710000": [16, 23, 34], "710031": 41, "710526": [15, 22, 33], "710896": 38, "71096": 42, "711": [35, 37], "711077": [16, 23, 34], "711086": 37, "711356": 26, "711717": 37, "711754": [16, 23, 34, 35], "711819": 46, "711852": 42, "71199006": 39, "712": [16, 23, 34], "712074": 37, "71219761": [17, 24, 35], "712198": [17, 24, 35], "712324": 37, "712402": 40, "7129": 37, "7129300520": 26, "713": 35, "71327467": 39, "714": 47, "714077": [16, 23, 34, 35], "714286": 37, "714375": 22, "714745": 38, "715072": 47, "71517": 37, "7153": 49, "715424": 37, "715728": 38, "715845": 28, "715992": 47, "716157": 38, "716655": 37, "716657": 37, "716792": 38, "716985": [15, 22, 33], "717289": 37, "717391": 37, "717829": [16, 23, 34], "718242": 37, "718266": 37, "718524": 48, "71866979": 39, "718750": 33, "7188": 35, "719": [12, 16, 19, 23, 30, 34, 42], "719056": 40, "719427e": 39, "719500": [15, 22, 33], "719747": 38, "719915905190645": 26, "72": [13, 14, 15, 21, 22, 31, 32, 33, 38, 39, 48, 49, 55], "7200": 26, "720357": 48, "72036": 48, "720497": 37, "720859": [16, 23, 34], "720893": 49, "720904": 48, "7210": [13, 26, 31], "721006": 37, "721008": 37, "721250": 22, "7212512828409687": 18, "7212512828409691": 36, "721616": 37, "721705": [16, 23, 34], "7218": [13, 14, 21, 31, 32, 55], "721818": 42, "721917": 26, "721921": [16, 23, 34], "722": [16, 23, 34], "722241": 37, "722249": 37, "722803": 26, "722873": 26, "723": [16, 23, 34], "72345029": 39, "723602": 37, "723613": [15, 22, 33], "723951": 26, "724068": 26, "7242": [13, 26, 31], "724410": 26, "724458": 37, "724539": 48, "724891": 38, "725": [18, 36, 37], "7250894": 53, "726": [16, 23, 34, 38, 42], "726269": 27, "726412": [16, 23, 34, 35], "726441": 27, "726474": 47, "726573": 37, "726583": 37, "726634": 38, "726659": 26, "7266666666666667": 53, "726788": 39, "727014": 48, "727198": 37, "727273": [15, 16, 22, 33], "727554": 37, "7277854625841886": 49, "727821": 37, "7278214718381631": 37, "727829": 37, "727992": 27, "728": [16, 23, 34, 38], "728235": [16, 23, 34, 35], "7283": 38, "728324": 38, "728777": [15, 22, 33], "729": 37, "729109": 52, "729143": 38, "7292": 42, "729374": 26, "729814": 37, "73": [13, 14, 17, 18, 21, 24, 31, 32, 35, 36, 37, 38, 39, 44, 48, 49], "730025": 26, "730383": 38, "730704": 26, "731498": 49, "7315": [18, 36], "7315558717766282": 37, "731572": [18, 36], "731583": [15, 22, 33], "73183": 46, "7328": [16, 23, 34], "732919": 37, "733102": [16, 23, 34, 35], "733333": [14, 16, 23, 32, 34, 35], "733746": 37, "734": [37, 39, 49], "734011": 37, "734048": 26, "734385": 38, "734816": 48, "734986": 26, "735": 39, "735043": 38, "735261": 37, "7352614272253524": 37, "735637": 26, "7356575131416321": 46, "735667": 38, "735879": 37, "7363681793212891": 46, "736498": 37, "736900": [16, 23, 34], "737285": 26, "7379": [13, 26, 31], "738": [16, 21, 23, 34, 39], "738564": 48, "738701": [16, 23, 34, 35], "738715": 49, "738839": [18, 36], "738977": 37, "739264": [16, 23, 34, 42], "7395977155164125": 37, "739598": 37, "739938": 37, "74": [13, 14, 16, 17, 18, 21, 23, 24, 31, 32, 34, 35, 36, 37, 38, 39, 44, 57], "740319": 26, "740542": [12, 19, 30], "740844": 37, "741": 49, "741037": 48, "741060": 26, "741250": 33, "741463": 37, "7418": 41, "741935": 52, "742084": 37, "742088": 37, "742703": 37, "742981": 38, "743": [15, 16, 23, 33, 34, 37, 49, 52], "743133": [15, 22, 33], "743135": 38, "743321": 37, "743323": 37, "743324": 37, "743391": [15, 22, 33], "743555": 41, "7436": [13, 14, 21, 31, 32, 55], "743917": [16, 23, 34, 35], "7440": [12, 19, 30], "744201": 38, "744565": 37, "745": 40, "745178": 37, "745925": 26, "746114": 40, "746328": [15, 22, 33], "747": [12, 19, 30], "74720920774": 39, "74798624e": 41, "748": 28, "748510": 38, "748725": 49, "748749e": 37, "748797": [18, 36], "749": 28, "749118": 41, "75": [8, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 24, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 48, 49, 50, 57], "750": [12, 19, 28, 30], "7500": 39, "750000": [16, 26, 39], "7503": [13, 26, 31], "7504": 52, "750401": 46, "751": [28, 52], "752": 28, "752169": 26, "7524": 48, "752728": 26, "753": 28, "753286": [16, 23, 34, 35], "754": [16, 23, 34], "754165": 52, "754386": 38, "754620": 26, "754874": 42, "754938": 26, "755": [14, 49], "755000": 39, "7551": 37, "755364": [15, 22, 33], "755418": 37, "755477": [15, 22, 33], "756": 49, "7562": [12, 19, 30], "75625": 48, "757": 38, "7574257425742574": 37, "75745416": 43, "757545": 39, "757591": 48, "757932": 49, "757985": [40, 41], "758": [40, 41, 49], "758029": 27, "758062e": 39, "758259": 26, "75826": [40, 41], "758514": 37, "7588186": 47, "7588527798652649": 46, "759043": 38, "759561": 43, "75956122": 43, "7599": [18, 36], "76": [14, 16, 18, 21, 23, 32, 34, 36, 37, 38, 39, 41, 42, 49], "760": 49, "760262": 37, "760678": 48, "760966": 26, "76161": 37, "761945e": 39, "762": [32, 49], "7620": [12, 19, 26, 30], "762093e": 39, "76270194": 41, "763": [16, 23, 34], "763480": 26, "7639": [13, 26, 31], "764052": 42, "76470588": [14, 21, 32], "764706": [14, 15, 21, 22, 32, 33, 37], "765": 38, "765591": 38, "765601": 39, "766317e": 39, "766318": 26, "766423": 39, "766430": [15, 22, 33], "767": [39, 41, 50], "767742": [18, 36], "767802": 37, "767819": 48, "767852": [15, 22, 33], "768": [16, 23, 34, 35, 39, 41, 50, 57], "768176": 49, "768184": 26, "768279": 50, "768512": 38, "769030": 26, "76908228": 40, "769231": [16, 23, 34], "77": [13, 14, 17, 18, 20, 21, 24, 31, 32, 35, 36, 38, 39, 44, 48, 49, 54], "770": [13, 26, 31], "770163": 26, "7706532429048965": 40, "770833": 45, "770898": 37, "771": [16, 23, 34], "771969": [15, 22, 33], "772185": 26, "772532": 38, "7728396574320712": 26, "773017": [39, 41, 50], "773125": 22, "7736": 37, "773851": 48, "774261": 48, "774844": [17, 24, 35], "77484447": [17, 24, 35], "7750553478074826": 48, "775270": 39, "7752884548630529": 36, "7752884548630534": 18, "775311": 41, "77536150e": 41, "7758": 37, "776": 37, "7763": [16, 23, 34, 42], "776427": 49, "77694295": 40, "77709": 37, "777600": 26, "777934": [15, 22, 33], "7781845435415525": 48, "779": [16, 23, 34, 42], "779271": 42, "78": [12, 13, 14, 16, 17, 19, 20, 21, 23, 24, 30, 31, 32, 34, 35, 38, 39, 42, 43, 48, 49, 54], "7800": 37, "780000": 40, "780296": 39, "780298": 39, "780316": 39, "780497": 39, "78058051e": 41, "780864": 38, "781": [16, 23, 34], "781004": [15, 22, 33], "781531": 38, "7816": 39, "781975": 27, "782183": 39, "782219": [15, 22, 33], "7827": 38, "783282": 37, "783582": [15, 22, 33], "783784": 45, "783789": [15, 22, 33], "784424": [18, 36], "784573": 42, "785": 35, "785105": 39, "785108": 39, "785134": 39, "78521263": 46, "785399": 39, "785483": 48, "785714": [16, 23, 34], "786115": 42, "78617028": 40, "786555": 39, "787": [16, 23, 34], "787574": 39, "787879": [15, 18, 22, 33, 36], "787933": 39, "788": 32, "788374": 47, "788647472858429": 46, "7887": 41, "7891381897690047": 36, "7891381897690053": 18, "789436": [16, 23, 34], "789657": 48, "79": [13, 14, 16, 17, 18, 21, 23, 24, 31, 32, 34, 35, 36, 38, 39, 48, 49, 55], "790": 38, "790000": [16, 23, 34], "79041": 39, "790481e": 28, "790521": 26, "790721": 50, "790731": [18, 36], "791017": 49, "791467": [16, 23, 34], "792": 53, "792023": [41, 50], "79250": [16, 23, 34], "792500": 15, "792577": 39, "792603": [15, 22, 33], "792828": 39, "793": 42, "793243": [16, 23, 34], "79378": 38, "7938": 35, "794": 49, "794118": [15, 22, 33], "794236": [16, 23, 34], "794820": [16, 23, 34], "795": [14, 15, 33, 37], "79500e": [15, 33], "7951": 37, "7951559890417761": 39, "795902": 48, "796": [16, 23, 34], "7964215270662811": 36, "7964215270662817": 18, "797": [16, 23, 34], "797355": [16, 23, 34, 35], "7978563117812038": [16, 23, 34], "798": [16, 23, 34], "7982": [15, 22, 33], "7986546": 39, "799983": [15, 22, 33], "79998417": 53, "7f688092391a": 47, "7l": 23, "7pm": 42, "7th": [38, 40, 41], "8": [1, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 56], "80": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 48, 49, 50, 54], "800": [12, 19, 21, 28, 30, 32, 37, 46], "800000": [37, 48], "8001": [18, 36], "800190": [15, 22, 33], "80062924": [15, 22, 33], "800k": 50, "801219e": 39, "801666": 38, "801863": [15, 22, 33], "802502": 42, "802902": 39, "802987": [15, 22, 33], "803": [15, 16, 22, 23, 33, 34, 52], "803617": 38, "804": [15, 22, 33, 49, 52], "804818": [16, 23, 34, 35], "80482065": [17, 24, 35], "804821": [17, 24, 35], "805198": 39, "805342": 48, "805414": 27, "805970": [15, 18, 22, 33, 36], "806": 35, "8062": [13, 26, 31], "806899": 47, "8076": 39, "807684": [15, 22, 33], "807735": 38, "8078": [12, 19, 30], "808": 49, "8080": [13, 26, 31], "808208": 38, "808958": [15, 22, 33], "809": [16, 23, 34], "8098": 49, "81": [13, 14, 15, 17, 18, 21, 22, 24, 26, 31, 32, 33, 35, 36, 37, 38, 39, 41, 43, 48, 49, 50], "810073": [39, 41], "810098": 42, "810368": [15, 22, 33], "81071706": 37, "810811": 45, "8112": [12, 19, 30], "812272": 39, "812363": 39, "812500": [14, 32], "812593": 47, "812875": 49, "813": [16, 23, 34], "813586": 38, "815669": 38, "816200": 27, "8162831858407079": 51, "816717791411044": 49, "817": 40, "817034": 52, "817558": [16, 23, 34, 35], "8180": [16, 23, 34], "818041": 49, "818868": [16, 23, 34], "819152": [15, 22, 33], "819213": 49, "8195": [18, 36], "819549": [15, 22, 33], "819584": [15, 22, 33], "81970188": [17, 24, 35], "819702": [17, 24, 35], "82": [13, 17, 20, 24, 31, 35, 37, 38, 44, 48, 49], "820": [15, 22, 33], "820033": 39, "820143": [18, 36], "82025568e": 41, "820564": 39, "821040": 41, "821327": 46, "821807": 39, "8219": [16, 23, 34], "8221": 35, "8225": 52, "82273995": [17, 24, 35], "822740": [17, 24, 35], "823364": 28, "82336432": 28, "823511": 38, "823529": [14, 15, 18, 21, 22, 32, 33, 36], "82352941": [14, 21, 32], "823543": 42, "824849": 38, "824884": 39, "825": [16, 23, 34], "825123": 42, "8253": [15, 22, 33], "825306": 37, "825470": 49, "825697": 39, "826142": 39, "826203": [18, 36], "826216": 39, "826513": 48, "826553": 39, "82670": 48, "826739": 39, "826758": 39, "826760": 39, "827039": [18, 36], "827068": [18, 36], "827130": 38, "827261": 39, "827842": [18, 36], "827907": 37, "828": [26, 28], "8280229354283182": 39, "82804": 37, "828332": [39, 41, 50], "828358": [15, 22, 33], "828405": 48, "828682": 37, "82869879": 46, "828891": 37, "828976": 37, "829": 28, "83": [13, 14, 17, 20, 21, 24, 31, 32, 35, 37, 38, 44, 45, 46, 48, 49, 54], "830": 28, "830382": 38, "830712e": 39, "831": 28, "831135": [15, 22, 33], "831611": [39, 41], "831989": 37, "832": [16, 23, 28, 34], "832320": [18, 36], "832370": 38, "832866": 39, "833": [15, 28, 33, 37], "83320": 48, "8334": 41, "833913": 26, "834": 28, "8340": [15, 22, 33], "834109": 37, "834356e": 39, "83437": 39, "834455": [15, 22, 33], "835": 28, "8356": 41, "835651": 37, "835749": [39, 41], "835876": 26, "83603": [39, 41], "8361313": 39, "836189": [15, 22, 33], "836735": 38, "836878e": 39, "836880e": 39, "837022e": 39, "837838": [15, 22, 33], "837848": [15, 22, 33], "838": [15, 33, 37], "83848729e": 47, "83876": 37, "8388866943476283": 36, "8388866943476289": 18, "838951": 39, "8389756947416362": 36, "8389756947416367": 18, "839225": 39, "84": [13, 14, 17, 20, 21, 24, 26, 31, 32, 35, 48, 49, 53, 54], "840": [16, 23, 34], "84002795": [17, 24, 35], "840028": [17, 24, 35], "840074": [14, 21, 32], "840183": 39, "840492": [39, 41, 50], "84062193": 41, "841": 39, "841208": 37, "841886": 37, "841983": 37, "842": [16, 23, 34], "842028": 38, "842064": 49, "842105": [15, 22, 33], "843": 40, "843281": 41, "843284": [15, 18, 22, 33, 36], "843842": [16, 23, 34, 35], "843992": [39, 41], "844409": [17, 24, 35], "84440919": [17, 24, 35], "844444": 16, "844921": 43, "845": 37, "846154": [16, 23, 34, 52], "8462": 42, "846260e": 39, "846650": 39, "84679073": [15, 22, 33], "84698489": 47, "847178": 38, "847287": 37, "8475": 48, "84772": 38, "847799": 37, "847808": 38, "8478316682480326": 48, "848": [40, 41], "8481": 52, "848214": 16, "84893192": 37, "849": [40, 41], "849102e": 39, "849438e": 39, "849612": 37, "85": [13, 14, 17, 20, 21, 24, 31, 32, 35, 38, 39, 40, 41, 42, 48, 49, 54], "850": [12, 19, 30, 40, 41], "8502": 37, "850283": 48, "850503": 37, "850746": [15, 22, 33], "851460": 39, "851852": [18, 36], "852": [49, 52], "852053": 37, "852104": 39, "852941": [18, 36], "853125": 33, "853399": 38, "854129": 39, "854167": 45, "854500": 49, "8546143543902771": 49, "854744525547446": 49, "854749": 48, "85545875": [15, 22, 33], "85597188": [17, 24, 35], "855972": [17, 24, 35], "856": 37, "856175": [16, 23, 34], "856589": 37, "856722": 27, "857": 39, "857457": 27, "857874": 37, "858": [18, 36], "8580": [16, 23, 34, 35, 57], "858209": [15, 18, 22, 33, 36], "858915": 37, "859": 40, "859318": 39, "859439": 43, "85943906": 43, "859455": 49, "85969": 37, "859799": 37, "86": [13, 15, 17, 18, 20, 24, 31, 33, 35, 36, 37, 38, 42, 48, 49], "860": [38, 41], "86000e": [15, 33], "8601643854446082": 39, "860677": 38, "861": [16, 23, 34], "86102": 48, "861157": 50, "861348": 37, "862432": 39, "862552": [16, 23, 34], "8625888648969532": 49, "86267067": [17, 24, 35], "862671": [17, 24, 35], "862997": 42, "863014": [18, 36], "863889": 48, "863941": 39, "864": 40, "86400": 48, "8641864337292489": 49, "864205": 41, "864292": 27, "865562": 49, "8661": 52, "866110": [18, 36], "866667": [14, 32, 38], "866980": 39, "867434": 47, "867558": 42, "868003": 39, "868281": 39, "868305": 39, "868308": 39, "869077": [17, 24, 35], "86907725": [17, 24, 35], "869094": 37, "8691": 35, "869531": [15, 22, 33], "869964": 37, "87": [13, 16, 17, 23, 24, 31, 34, 35, 38, 48, 49], "870": [40, 41], "870503": 47, "871": [37, 40], "871094": 48, "8711": 38, "871200": 26, "872": [40, 41], "872093": 37, "872603": 47, "872722908439952": 41, "8727229084399575": 41, "872961060": 39, "8729610607986": 39, "873": 40, "8731": [39, 41, 50], "873103": [15, 22, 33], "873182": 48, "873356": [15, 22, 33], "873643": 37, "873704": 39, "874062": [17, 24, 35], "87406235": [17, 24, 35], "874305": 48, "874516": 37, "874532": 39, "874767e": 39, "874962": 27, "875": 38, "8750": [16, 23, 34, 42], "875000": [14, 16, 32], "876065": 37, "876540": 49, "876566e": 26, "876574": [16, 23, 34, 35], "87681182": 46, "877046": 42, "877390": 41, "877519": 37, "877551": 38, "878183": [15, 22, 33], "87844893": 39, "87849316": [18, 36], "879": [16, 23, 34], "87907": 37, "879938": 37, "88": [13, 14, 16, 17, 18, 21, 23, 24, 31, 32, 34, 35, 36, 38, 42, 49, 57], "880": 42, "8801": 46, "880348": 37, "880831": 48, "881395": 37, "881720": 38, "883138": 37, "884586": 37, "885": [12, 19, 30, 35], "885044": [39, 41, 50], "8859": 29, "885968": 49, "886047": 37, "886759": [18, 36], "887": 40, "887017": 38, "887159": 48, "8873": 38, "887324": 38, "887343": [15, 22, 33], "887597": 37, "887701": 38, "8878117": [17, 24, 35], "887812": [17, 24, 35], "888": [37, 40, 41], "888066": 41, "888372": 37, "888513": 38, "888811": 37, "888889": [16, 18, 23, 34, 36], "888961": 41, "889086": 39, "889147": 37, "889429": 48, "889921": 48, "89": [13, 14, 17, 20, 21, 24, 31, 32, 35, 38, 44, 48, 49, 54], "890": [28, 40], "890456": 26, "890457": 39, "890933": 49, "891001": 38, "891557": 37, "892476": 38, "892477": [15, 22, 33], "892491": [16, 23, 34], "89270": 42, "892733": 48, "892961": 42, "893000": [16, 23, 34], "893260": [17, 24, 35], "8937442459553657": 41, "894": [16, 23, 34], "894587": 50, "894960": 26, "895": 40, "89515383": 28, "895154": 28, "895349": 37, "895541": 39, "89572": 48, "895833": 38, "895963": [18, 36], "897010": [16, 23, 34, 35], "89706451e": 41, "897674": 37, "898": 41, "898016": 37, "898243": 27, "898703e": 39, "899": [16, 23, 34, 35, 37, 40, 57], "8994": 41, "8997": 39, "899736": 26, "899969": 48, "8m": 47, "8th": [38, 40, 41], "9": [1, 4, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 58], "90": [8, 12, 13, 14, 15, 17, 19, 20, 21, 22, 24, 30, 31, 32, 33, 35, 38, 39, 44, 45, 48, 49, 54], "900": [17, 24, 35, 37, 38], "90000": 48, "900000": [14, 21, 32, 48], "900000e": 26, "900662": [14, 21, 32], "901085": [18, 36], "9010852321946792": 36, "9010852321946795": 18, "901262": 48, "90159483": 43, "901595": 43, "902343": 27, "902401": 37, "903101": 37, "903422": 27, "904": [15, 22, 33, 37], "90403853": [17, 24, 35], "904039": [17, 24, 35], "904226": [15, 22, 33], "904565": 27, "9047619047619048": [13, 20, 31], "904902": 47, "904930e": 26, "905": [15, 16, 22, 23, 33, 34], "905000": 22, "905327": 48, "906667": [14, 21, 27, 32], "90669": 42, "906865": [14, 21, 32], "907": 49, "907143": 52, "907595": 48, "908": [16, 23, 34], "908140": [16, 23, 34, 35], "908215": 39, "909091": [16, 23, 34], "90982": 42, "91": [13, 14, 16, 17, 20, 21, 23, 24, 26, 31, 32, 34, 35, 37, 38, 42, 43, 48, 54], "910": [13, 17, 24, 26, 31], "9100": 48, "910018": 39, "910174": 39, "9103": 48, "910456e": 39, "91063776": 41, "910714": 52, "9108334653214172": 26, "910843": 39, "911": 28, "911615": 39, "911846": 39, "912": [16, 23, 34], "912395": 41, "913333": [14, 21, 27, 32], "913767": 39, "913849": 39, "914003": 41, "914451894267": 39, "914585": 41, "91515735": 39, "915714e": 39, "915952": 39, "916254": [15, 22, 33], "916347": 27, "916722": 41, "917526": 38, "917837": 38, "918": [26, 40], "918124": 38, "918191": 47, "9182": 48, "918224": 28, "919198": 41, "9196": [12, 19, 30], "92": [13, 14, 17, 20, 21, 24, 31, 32, 35, 38, 44, 47, 48, 49, 54], "920000": [14, 21, 27, 32], "9203": 37, "920305": 42, "920462": 41, "9212": 16, "92120500e": 53, "921422": 49, "921435": 27, "921438": 39, "921850": 39, "92195464": 41, "921955": 41, "922": 35, "923077": 38, "923283": [16, 23, 34, 35], "923432": 41, "924485": 42, "9245": [14, 18, 21, 32, 36], "925272e": 39, "925288e": 39, "925593": [15, 22, 33], "925768": 38, "926657": 39, "926667": 27, "926733e": 39, "926829": 38, "928": 37, "92809": 42, "92852376": [15, 22, 33], "929": 37, "9295": 37, "93": [13, 14, 17, 18, 20, 21, 24, 31, 32, 35, 36, 37, 43, 48, 49, 54], "930000": [16, 23, 34], "930062": 26, "930123": [15, 22, 33], "930561": [15, 22, 33], "9308647034083802": 26, "931439e": 39, "931786": [18, 36], "931896": 26, "932": [16, 23, 34], "932070": 49, "932124": [15, 22, 33], "932143": 52, "93279": 48, "933275": 38, "933333": 27, "9336": [16, 23, 34], "934": 28, "934205": [15, 22, 33], "934269": [16, 23, 34, 35], "934783": 38, "9351": 42, "935512": 49, "935802": [15, 22, 33], "93665": 48, "937429": 50, "9375": [14, 21, 32], "937500": [14, 17, 21, 24, 32, 35], "938": 38, "938201": 26, "9383": [15, 18, 22, 33, 36], "93869659": [17, 24, 35], "938697": [17, 24, 35], "939006": 38, "9391": 39, "939394": [15, 18, 22, 33, 36], "939805": 26, "94": [13, 14, 16, 17, 18, 20, 21, 23, 24, 31, 32, 34, 35, 36, 37, 38, 39, 48, 54, 57], "940000": 27, "9401": 48, "9406": [13, 14, 21, 31, 32, 55], "941": 49, "9410": 26, "941176": [14, 17, 21, 24, 32, 35], "94117647": [14, 21, 32], "942": 28, "943609": 42, "944": [12, 19, 30], "944092": 38, "944354": 35, "945000": 27, "945968": 27, "946667": 27, "946783": [15, 22, 33], "947": [16, 23, 34, 37, 52], "9471": 37, "948482": 49, "94888": 38, "949": [16, 17, 23, 24, 34], "9490": [16, 23, 34], "9492": 39, "94933723": 39, "94959681": [17, 24, 35], "949597": [17, 24, 35], "95": [13, 14, 17, 20, 21, 24, 31, 32, 35, 38, 44, 48, 49, 50], "950000": [16, 23, 34], "950088": 42, "9505": 41, "950564": 42, "9506": 41, "950696": 49, "950733": [15, 22, 33], "951294": 39, "951574": 42, "951644": 42, "951667": 27, "951669": 42, "951696": [15, 22, 33], "953": 40, "9530973451327434": 51, "953333": 27, "95511263": [15, 22, 33], "955113": [15, 22, 33], "9558": 48, "956": [16, 23, 34], "956966": 42, "957075": 42, "9573": 48, "9576": [12, 19, 30], "957886": 47, "957919": [15, 22, 33], "957987": [15, 22, 33], "9583333333333334": 47, "958393": [16, 23, 34, 42], "95886206e": 47, "959": [16, 23, 28, 34], "959139": 41, "959402e": 39, "959870": 38, "959873": 49, "96": [13, 17, 18, 24, 31, 35, 36, 37, 38, 42, 48], "960": [17, 18, 24, 28, 36], "960000e": 28, "961": 28, "961109802000133": 44, "961404": [16, 23, 34, 35], "961498": [39, 41, 50], "961771": [18, 36], "961898": [18, 36], "962": 28, "962036": 38, "963": 28, "963024": 26, "963097": 38, "96319": 48, "96320": 48, "96321": 48, "96322": 48, "96323": 48, "96325": 48, "963333": 27, "963689": 42, "964": 28, "96554": 42, "9661": 39, "966131": [16, 23, 34, 35], "9664": [13, 14, 21, 31, 32, 55], "966667": 27, "966812": 26, "967907": 38, "968": [16, 23, 34], "968233": 42, "968236": 38, "96833": 46, "968333": 27, "96834506": [15, 22, 33], "968493": 49, "968514e": 39, "96875": 47, "969048e": 39, "9691": 39, "9692602666681306": [18, 36], "96965253": 41, "969653": 41, "97": [13, 14, 16, 17, 18, 21, 24, 31, 32, 35, 36, 37, 41, 44, 48, 49], "970518": 38, "970683": 42, "971": 35, "97203586": [17, 24, 35], "972036": [17, 24, 35], "97217": 48, "972198": 37, "97223953": [17, 24, 35], "972240": [17, 24, 35], "972379": 28, "97237936": 28, "972440": 38, "97253": 48, "9730": 35, "973225": 38, "973280": [17, 24, 35], "97328024": [17, 24, 35], "973294": 28, "973333": 27, "973482e": 37, "973750": [15, 33], "974": [16, 23, 34], "974183": 27, "974480": 42, "974531": 27, "9748": [18, 36], "974801e": 39, "975104": 28, "975895": 48, "976": [16, 23, 34, 38, 40], "976667": 27, "977": [16, 23, 34, 48], "977278": 42, "9773": [13, 14, 15, 21, 22, 31, 32, 33, 55], "978": [18, 36], "9781449369880": 48, "9781789957211": 47, "97823755": [18, 36], "9785299": 46, "978738": 42, "979": [40, 41], "979562": 49, "98": [13, 16, 17, 18, 23, 24, 31, 34, 35, 36, 39, 41, 43, 46, 48, 49, 50], "980": 48, "980000": 27, "98001": 26, "98007": [12, 19, 30], "98010": 26, "98024": 26, "98027": 26, "98028": [13, 26, 31], "98033": 26, "98038": 26, "98039": 26, "98045": [12, 19, 30], "98052": [12, 19, 26, 30], "98055": [12, 19, 30], "980634": 49, "98065": 26, "98072": [12, 19, 30], "98074": [13, 26, 31], "98075": [12, 19, 30], "98077": 26, "9808": [18, 36], "980962": 27, "98102": 26, "98103": 26, "98107": [12, 19, 30], "98112": [12, 19, 30], "98115": 26, "98116": [12, 19, 30], "98117": 26, "98118": 26, "981195": 48, "98125": [13, 26, 31], "98136": [13, 26, 31], "98144": 26, "98146": 26, "98148": 26, "981643": 26, "981735": [18, 36], "98178": [13, 26, 31], "98199": 26, "982": 35, "982184": 37, "982570": 49, "983": 47, "983333": 27, "983340": 26, "9837": [14, 18, 21, 32, 36], "984": 37, "984653": [18, 36], "984664": 39, "985000": 27, "985283": 37, "9854": [13, 14, 18, 21, 31, 32, 36, 55], "985457": 49, "985816": [14, 32], "986047": 37, "9862": 52, "986207": 37, "987": [37, 47], "987062": 39, "987597": 37, "9876": [40, 41], "987681": 42, "988": 42, "9881": [13, 14, 21, 31, 32, 55], "988333": 27, "988381": 37, "988841": 37, "988901": 39, "989": [13, 20, 31], "989147": 37, "989156": 37, "989443": 49, "989922": 37, "989973": [18, 36], "99": [13, 14, 16, 17, 21, 23, 24, 28, 31, 32, 34, 35, 37, 38, 48], "990631": 48, "990754": 48, "9912": [15, 18, 22, 33, 36], "9915": 48, "991667": 27, "991810": 26, "991966": 49, "992": [32, 37], "992220": 26, "992254": 37, "99240562": 41, "992406": 37, "992569": 28, "9926": 35, "992857": [14, 32], "992908": 32, "993023": 37, "993029": 37, "993065": 49, "9931": [13, 14, 21, 31, 32, 55], "993333": 27, "9934531067299874": [18, 36], "993666": 41, "993969": [39, 41, 50], "994": [12, 19, 30], "994266": 37, "994574": 37, "994764": 48, "995": [42, 47], "9950": 42, "9951": [13, 14, 21, 31, 32, 55], "99515": 48, "995434": 39, "996424": 26, "996487": 26, "996588e": 39, "996765": 41, "996788": 49, "996820": 49, "996899": 37, "99744241e": 41, "9977957422135844": 41, "998": [38, 49, 52], "9983": 38, "998302": 38, "998370": 26, "998440": 26, "99845": 37, "998451": 37, "999": [18, 36, 52], "99907": 37, "999122": 38, "9991338290544213": 26, "999147": 38, "999172": 38, "999178": 26, "999183": 38, "999185": 38, "999192": 38, "999210": 38, "999213": 26, "999214": 38, "999221": 38, "999223": 38, "999225": 37, "999254": 38, "999298": 38, "999317": 38, "99931882": 39, "999335": 38, "999438": 26, "9994394006711425": 26, "999480": 26, "999518": 26, "999535": 37, "999539": 26, "999544": 26, "999545": 26, "999546": 26, "999558": 26, "999562": 26, "999567": 26, "999577": 48, "999622": [16, 23, 34], "9999": [12, 19], "9am": 42, "9th": [38, 40, 41], "A": [0, 1, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 51, 53, 54, 58], "AND": [0, 39], "AS": 0, "And": [12, 13, 19, 30, 31, 37, 39, 46, 48, 49, 50, 55, 56], "As": [4, 14, 17, 21, 22, 24, 32, 35, 37, 39, 40, 41, 45, 48, 49, 50, 51, 53, 56, 58], "At": [4, 12, 14, 18, 19, 26, 28, 30, 32, 36, 38, 40, 42, 43, 47, 48], "BE": [0, 46], "BUT": [0, 8], "BY": [0, 1], "Be": [7, 12, 15, 19, 22, 33, 41, 50, 51, 54, 56], "Being": 47, "But": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 56, 58], "By": [11, 12, 14, 15, 17, 19, 21, 22, 24, 27, 30, 32, 33, 35, 38, 40, 43, 46, 47, 49, 50, 56], "FOR": 0, "For": [0, 1, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 58], "IN": [0, 14, 18, 21, 32, 36], "IT": [18, 36], "If": [4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], "In": [1, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58], "Ines": 52, "It": [2, 4, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 56, 58], "Its": 49, "NEAR": [16, 23, 34, 35, 42, 57], "NO": 0, "NOT": [0, 8, 17, 18, 24, 35, 36], "No": [0, 12, 13, 19, 20, 28, 30, 31, 39, 40, 41, 42, 44, 48, 49, 50, 54], "Not": [38, 39, 40, 41, 42, 43, 45, 48, 49], "OF": 0, "OR": [0, 8, 39], "Of": [9, 17, 24, 35, 37], "On": [4, 7, 12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 34, 35, 37, 38, 39, 40, 41, 42, 44, 47, 49, 50, 52], "One": [5, 8, 13, 14, 17, 18, 20, 21, 24, 28, 29, 31, 32, 35, 36, 37, 38, 41, 43, 44, 49, 54], "Or": [15, 17, 22, 27, 33, 35, 37, 50, 56], "Such": [6, 45, 48], "THE": [0, 14, 21, 32], "TO": [0, 46], "That": [13, 14, 16, 18, 20, 21, 23, 31, 32, 34, 36, 37, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51], "The": [0, 2, 5, 7, 8, 11, 12, 13, 15, 16, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 38, 39, 41, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58], "Their": 5, "Then": [13, 18, 20, 31, 36, 40, 43, 48, 51], "There": [1, 2, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 28, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 58], "These": [4, 10, 13, 14, 15, 18, 20, 21, 22, 31, 32, 33, 36, 38, 39, 40, 41, 42, 43, 45, 48, 50], "To": [8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 39, 40, 42, 44, 46, 47, 48, 50, 51, 52, 56, 58], "WITH": 0, "Will": [38, 49, 52, 54], "With": [0, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 27, 30, 31, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 47, 49, 53, 56], "_": [40, 46, 47, 49, 52], "__array__": 28, "__call__": [17, 24, 35], "__class__": [18, 36, 48], "__finalize__": 49, "__getitem__": [23, 32, 34, 52], "__name__": [18, 36, 48], "__sklearn_tags__": 28, "__testing_word2vec": 46, "_array_api": 28, "_asarray_with_ord": 28, "_assert_all_finit": 28, "_assert_all_finite_element_wis": 28, "_astype_nansaf": 49, "_base": 28, "_california_housing_dataset": [18, 36], "_call_func_on_transform": [17, 24, 35], "_check_i": 28, "_classif": 28, "_column_transform": [17, 24, 35], "_constructor_from_mgr": 49, "_data": 37, "_deprecate_force_all_finit": 28, "_distn_infrastructur": 37, "_encod": [17, 24, 35], "_estim": 28, "_fit": 28, "_fit_context": 28, "_get_sequential_output": [17, 24, 35], "_i": 47, "_is_numpy_namespac": 28, "_logist": 53, "_mgr": 49, "_proba": 40, "_score": [17, 24, 35], "_scorer": [17, 24, 35], "_set_output": [17, 24, 35], "_time_fit_was_cal": 49, "_transform": [17, 24, 35], "_transform_on": [17, 24, 35], "_valid": [17, 24, 35], "_validate_param": 28, "_valu": 28, "_x_subset": 14, "ab": [18, 36, 38, 39, 41], "abbrevi": 46, "abdelrahman": [1, 58], "abil": [12, 17, 19, 24, 29, 30, 35, 37, 41, 46, 48, 56], "abl": [8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 50, 51, 56], "about": [1, 2, 4, 7, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58], "abov": [0, 5, 8, 10, 12, 13, 14, 15, 18, 19, 20, 21, 22, 26, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 50, 53, 56, 58], "absenc": [17, 24, 35, 41, 45], "absolut": [11, 18, 28, 36, 38, 39, 41, 43, 52], "abspath": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56], "academ": [1, 7, 42, 51], "accept": [5, 8, 28, 38, 39, 46, 51], "accept_large_spars": 28, "accept_spars": [17, 24, 28, 35], "access": [1, 10, 12, 14, 19, 21, 23, 32, 34, 37, 40, 43, 45, 46, 48, 50, 51, 52], "accessori": 48, "accident": [15, 16, 22, 23, 33, 34, 51], "accomod": 7, "accompani": [7, 12, 13, 19, 30, 31], "accomplish": [27, 51], "accord": [18, 36, 38, 39, 42, 45, 49, 58], "account": [1, 7, 12, 14, 19, 32, 38, 42, 45, 49, 51, 54], "accur": [12, 14, 19, 21, 30, 32, 40, 41, 42, 45, 49, 50, 54, 55], "accuraci": [11, 13, 14, 15, 16, 20, 21, 22, 23, 26, 27, 31, 32, 33, 34, 37, 38, 40, 41, 42, 44, 47, 49, 50, 52, 54, 55, 58], "accuracy_scor": 38, "acdm": [38, 40, 41], "acf": 48, "achiev": [8, 15, 22, 33, 38, 51], "acinonyx": [12, 19, 30, 47], "acoust": [15, 16, 23, 33, 34, 37], "acquir": 11, "acquisit": 45, "across": [12, 13, 14, 16, 19, 20, 21, 23, 30, 31, 32, 34, 38, 41, 47, 58], "act": [18, 29, 36, 58], "action": [0, 12, 19, 30, 40, 41, 43, 45, 46, 49, 58], "activ": [4, 10, 30, 37, 52, 54, 58], "actor": [45, 46], "actual": [7, 12, 18, 19, 24, 29, 30, 36, 38, 40, 41, 43, 45, 46, 48, 49, 50], "ad": [17, 18, 24, 35, 36, 37, 38, 40, 41, 42, 44, 46, 47, 49, 52], "adapt": [0, 16, 17, 23, 24, 34, 35, 38, 40, 46, 48, 50, 52], "add": [7, 8, 10, 14, 16, 23, 34, 35, 38, 39, 40, 41, 42, 44, 46, 48, 49, 51, 52, 57], "add_pip": 52, "addit": [0, 4, 12, 19, 39, 45, 50, 58], "addition": [55, 56, 58], "address": [44, 51], "adelaid": 48, "adio": 50, "adj": [46, 52], "adject": 46, "adjust": [15, 22, 27, 33, 37, 44, 48, 56], "adm": [38, 40, 41], "admin": [1, 58], "administr": 1, "admit": [14, 32], "adopt": [6, 45], "adp": [46, 52], "adult": [38, 40, 41], "adult_df_larg": [40, 41], "adv": 46, "advanc": [11, 17, 24, 35, 37, 43, 44, 45, 46, 47, 55], "advantag": [11, 16, 17, 18, 23, 24, 29, 34, 35, 36, 40, 44, 45, 46, 54], "advic": 49, "advis": [12, 19, 30], "advisor": 58, "af": 41, "affect": [10, 15, 16, 18, 22, 23, 33, 34, 36, 37, 38, 43, 48, 49, 51, 56], "affix": 46, "aft": 51, "after": [4, 6, 10, 14, 16, 17, 21, 23, 24, 28, 32, 34, 35, 38, 39, 41, 43, 44, 46, 47, 48, 49, 50, 51, 52, 54, 58], "ag": [12, 18, 19, 28, 30, 36, 38, 39, 40, 41, 42, 45], "again": [10, 14, 16, 20, 21, 23, 26, 27, 28, 31, 32, 34, 44, 45, 46, 47, 49, 51, 56], "against": [45, 46, 48], "agenc": [46, 52], "agent": 1, "agglomerativeclust": 44, "aggress": 46, "agnost": 41, "ago": [47, 48], "agre": 56, "agreement": [49, 58], "ahm": [1, 58], "ai": [7, 9, 38, 42, 46, 47], "aight": [12, 19, 30], "aim": [28, 54], "ain": 46, "airplan": 50, "airport": [38, 51], "aka": [18, 36, 49], "al": [40, 46], "alain": [1, 58], "alamine_aminotransferas": [12, 19, 30], "alan": 1, "alaska": [18, 36], "alberta": 46, "album": 37, "albumin": [12, 19, 30], "albumin_and_globulin_ratio": [12, 19, 30], "alburi": 48, "alexand": 50, "alexnet": 47, "algebra": [45, 46], "algorithm": [2, 11, 12, 14, 16, 17, 19, 23, 24, 27, 30, 32, 34, 35, 38, 39, 40, 41, 44, 46, 47, 50, 51, 55, 56, 57], "align": [8, 12, 13, 14, 19, 20, 21, 30, 31, 32], "align_kei": 49, "alison": [1, 58], "aliv": 51, "alkaline_phosphotas": [12, 19, 30], "all": [0, 1, 4, 5, 6, 7, 8, 10, 14, 15, 17, 20, 21, 22, 23, 24, 26, 27, 28, 32, 33, 35, 37, 39, 40, 41, 42, 46, 47, 48, 49, 51, 52, 53, 56, 57, 58], "all_cap": 52, "all_featur": 48, "allei": [39, 41, 50], "allen": 52, "alley_grvl": 39, "alley_miss": 39, "alley_pav": 39, "alloc": [8, 46, 47], "allow": [5, 7, 10, 14, 16, 23, 28, 32, 34, 37, 38, 42, 46, 48, 49, 51, 55, 56, 58], "allow_nan": 28, "allow_nd": 28, "allpub": [39, 41, 50], "allya": [1, 58], "almost": [18, 36, 37, 39, 42, 44, 45, 46], "along": [7, 13, 17, 24, 31, 35, 38, 47, 48, 50, 55], "alpha": [15, 16, 22, 23, 27, 33, 34, 48, 56], "alpha_": 39, "alphabet": [18, 36], "alphago": [12, 19, 30, 43], "alq": [39, 41, 50], "alreadi": [4, 8, 10, 11, 12, 19, 38, 39, 41, 43, 46, 48, 49, 50, 52, 55], "also": [1, 2, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], "altar": 47, "altern": [8, 27, 37, 43, 50, 58], "although": [14, 21, 32, 40, 43, 45, 49], "alwai": [12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 26, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 45, 52, 54, 55, 56, 58], "am": [16, 19, 23, 29, 34, 43, 46, 50, 52, 58], "amatriain": 45, "amaz": 28, "amazon": [12, 19, 30, 43, 45, 52], "ambienc": 28, "ambigu": 46, "amer": 38, "america": [17, 35, 46], "american": [28, 43], "amirali": [1, 58], "aml": [16, 23, 34], "among": [12, 13, 19, 20, 30, 31, 37, 38, 40, 41, 45], "amongst": 52, "amount": [4, 12, 14, 18, 19, 21, 30, 32, 36, 37, 38, 39, 41, 43, 47, 48, 49, 51], "amp": [40, 41], "amplifi": [38, 46], "amuel": [16, 23, 34], "an": [0, 1, 2, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 57, 58], "anaconda": [10, 41, 52], "anaconda3": [20, 24], "analogi": [22, 44, 46, 50], "analysi": [1, 2, 9, 11, 13, 31, 38, 39, 43, 44, 46, 50], "analyt": 48, "analyz": [11, 38, 42, 48, 49, 50], "anatinu": 47, "anca": [1, 58], "ancestor": 42, "ancestr": 58, "ancuta": [1, 58], "andrea": [1, 9], "andrew": [1, 9, 27, 37, 42, 58], "anemon": 47, "angel": [49, 52], "ani": [0, 10, 13, 14, 16, 17, 18, 20, 21, 23, 24, 26, 28, 31, 32, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58], "anim": [27, 38, 47], "animal_fac": [27, 47], "anneal": 42, "annot": [41, 43], "announc": 7, "annoyingli": 39, "annual": 52, "anomali": [38, 39, 43], "anonym": 48, "anoth": [8, 10, 13, 15, 18, 20, 22, 31, 33, 36, 37, 38, 40, 41, 43, 44, 45, 47, 48, 49, 50, 51, 54, 55, 57], "answer": [4, 6, 7, 12, 13, 14, 19, 21, 29, 30, 31, 32, 37, 40, 43, 45, 46, 48, 50, 53, 55, 56, 58], "anteat": 47, "anti": 49, "anymor": [39, 43, 45, 56], "anyon": [12, 50, 51], "anyth": [0, 12, 14, 17, 19, 21, 24, 28, 32, 35, 38, 45, 46, 49, 51], "anytim": 58, "anywher": [17, 24, 35], "ap": [11, 54], "ap_lr": 38, "ap_svc": 38, "apart": [15, 22, 33, 44], "apeendixa": 42, "api": [28, 38, 46, 48, 54], "app": [12, 13, 19, 20, 31, 54], "appeal": 46, "appear": [2, 7, 17, 24, 35, 40, 51, 56, 58], "append": [4, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 55, 56, 57], "appendix_b": 46, "appendixb": 47, "appl": 46, "appli": [0, 2, 6, 9, 11, 12, 13, 14, 18, 19, 20, 21, 28, 29, 30, 31, 32, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 57], "applic": [0, 5, 12, 17, 19, 24, 30, 35, 37, 38, 39, 41, 42, 46, 49, 51, 54, 58], "appreci": [11, 43, 58], "approach": [1, 11, 14, 15, 16, 17, 18, 22, 23, 24, 27, 28, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 46, 47, 54, 56], "appropri": [0, 4, 10, 11, 13, 14, 17, 20, 21, 24, 26, 31, 32, 35, 38, 39, 43, 44, 48, 49, 51, 54, 58], "approv": [38, 58], "approx": [15, 22, 33, 41], "approxim": [13, 20, 31, 37, 42, 51], "apr": 1, "april": 48, "apt": 5, "ar": [0, 1, 2, 4, 6, 7, 8, 9, 10, 14, 15, 17, 20, 21, 22, 24, 26, 27, 28, 29, 32, 33, 35, 37, 39, 40, 41, 42, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], "arang": [8, 14, 15, 18, 21, 22, 26, 27, 29, 32, 33, 36, 37, 38, 39, 56], "arbitrari": [41, 43, 44, 48], "architectur": 47, "area": [37, 39, 40, 42, 43, 50], "aren": [7, 39, 42, 43, 46, 47, 48, 52], "arena": 42, "arg": [14, 17, 21, 24, 27, 28, 32, 35], "argh": 49, "argmax": 27, "argmin": [14, 15, 21, 22, 32, 33, 38, 43], "argsort": [41, 46], "argu": [19, 43, 46], "argument": [8, 13, 17, 20, 24, 31, 35, 37, 38, 39, 41, 50, 52, 54, 57], "arima": 48, "arima_model": 48, "aris": [0, 12, 30, 46], "aristotl": [15, 22, 33], "arithmet": 8, "aroth85": 25, "around": [7, 15, 17, 22, 24, 33, 35, 38, 39, 48, 49, 55], "aroundn": [12, 30], "arr": [28, 49], "arr1": 8, "arr2": 8, "arrai": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53], "array_equ": 8, "array_orig": 28, "arriv": 42, "art": 50, "arthur": [12, 19, 30], "articl": [1, 13, 14, 16, 20, 23, 31, 32, 34, 38, 43, 45, 46, 47, 50], "articul": [50, 54], "artifici": [1, 46], "artist": [15, 16, 23, 33, 34, 37], "as_fram": [15, 22, 27, 33, 56], "asarrai": 28, "ascend": [8, 17, 18, 24, 26, 29, 35, 36, 37, 39, 40, 41, 42, 48, 49, 54], "ased": 44, "asia": [17, 35], "asid": [4, 14, 21, 32, 40, 56], "ask": [3, 7, 10, 12, 13, 14, 15, 17, 19, 20, 21, 24, 30, 31, 32, 33, 35, 38, 42, 43, 45, 46, 49, 50, 52, 55, 58], "asleep": [18, 36], "aspartate_aminotransferas": [12, 19, 30], "aspect": [18, 36, 41, 42, 44, 45, 49, 50, 54], "assault": 58, "assert": [7, 17, 24, 35, 38, 40, 41], "assess": [1, 6, 11, 12, 13, 14, 16, 19, 20, 21, 23, 28, 30, 31, 32, 34, 38, 41, 43, 50, 58], "assign": [1, 4, 6, 8, 10, 12, 13, 15, 16, 18, 19, 20, 22, 23, 27, 31, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 55, 57], "assist": [12, 19, 30], "assoc": [38, 40, 41], "associ": [0, 12, 14, 15, 19, 20, 21, 22, 29, 30, 32, 33, 38, 39, 41, 42, 43, 46, 47, 48, 49, 50, 51, 54, 58], "assum": [12, 13, 17, 18, 19, 24, 30, 31, 35, 36, 38, 39, 44, 45, 46, 48, 50, 54], "assumpt": 49, "asterisk": 37, "astyp": [8, 27, 28, 29, 48, 49], "astype_arrai": 49, "astype_array_saf": 49, "astype_is_view": 28, "atratu": 47, "attack": [13, 20, 31], "attempt": [14, 21, 27, 32], "attend": 58, "attent": [6, 46, 51], "attic": 39, "attract": 46, "attribut": [0, 1, 12, 13, 15, 16, 18, 19, 20, 22, 23, 29, 30, 31, 33, 34, 36, 37, 42, 43, 46, 47], "attrit": 49, "auc": [11, 49, 51, 54], "audienc": [11, 50, 51], "audio": [47, 58], "audit": [51, 58], "auditor": 58, "augment": 38, "august": 48, "austin": 46, "australia": 48, "authent": 43, "author": [0, 46, 58], "auto": [12, 19, 30, 37, 38, 42, 43, 50], "autocorrel": 48, "autom": [13, 20, 31, 39, 46, 50], "automat": [16, 17, 23, 24, 34, 35, 39, 42, 46, 48, 49, 50], "autoregress": [18, 36], "autumn": 48, "autumn_month": 48, "aux": [46, 52], "av": [39, 41, 46, 50], "avail": [0, 1, 7, 9, 10, 12, 14, 17, 19, 20, 21, 24, 32, 35, 37, 38, 39, 44, 45, 46, 47, 48, 49, 54, 58], "avebedrm": [18, 36], "aveoccup": [18, 36], "averag": [11, 14, 15, 17, 18, 21, 22, 24, 32, 33, 35, 36, 37, 39, 41, 43, 44, 46, 49, 51, 52, 54, 56], "average_precis": 38, "average_precision_scor": 38, "average_word_length": 52, "averaging_model": 40, "averaging_model_ndt": 40, "averoom": [18, 36], "avg": [38, 45, 48], "avg_sent_emb": 46, "avocado": 50, "avoid": [7, 8, 13, 16, 23, 29, 31, 34, 38, 39, 44, 48, 49, 50, 51, 53, 54, 56, 58], "aw": [28, 51], "awai": [4, 6, 13, 18, 20, 31, 36, 43, 45, 47, 49, 50, 51, 54], "awar": [17, 24, 35, 49, 50, 58], "awesom": 9, "ax": [14, 15, 18, 21, 22, 27, 32, 33, 36, 38, 43, 44, 47, 49, 50, 56], "axi": [7, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 27, 30, 31, 32, 34, 35, 36, 41, 43, 44, 46, 47, 48, 50], "axvlin": 43, "az": 52, "b": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50], "b3": [34, 41, 52], "babe": [12, 19, 30], "babi": [42, 46], "bachelor": [38, 40, 41], "back": [8, 16, 23, 26, 27, 34, 37, 46, 54], "backdrop": 48, "background": [11, 31, 50, 51], "bad": [8, 13, 14, 15, 20, 21, 22, 28, 31, 32, 33, 35, 38, 39, 40, 41, 42, 43, 47, 48], "badgeryscreek": 48, "bag": [28, 29, 42, 46, 47, 54], "bai": [16, 23, 34, 35, 42], "baidu": [14, 32], "bal_scor": 38, "balanc": [6, 15, 22, 28, 29, 33, 40, 43, 45, 53], "ballarat": 48, "balltre": 28, "balust": 47, "balustrad": 47, "bambi": 45, "banist": 47, "bank": [38, 41, 48, 49], "bannist": 47, "bar": [38, 39, 41, 47, 48, 49, 50, 51], "baranski": 52, "barbu": [1, 58], "barri": [18, 36], "base": [5, 8, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 27, 28, 31, 32, 34, 35, 36, 37, 38, 39, 41, 43, 44, 46, 49, 50, 51, 52, 54, 55, 58], "base_scor": 40, "base_valu": 41, "baseblockmanag": 49, "baselin": [27, 49, 51, 54, 55, 57], "baseline_hazard_": 49, "bash": 5, "basi": [13, 15, 20, 22, 31, 33], "basic": [2, 8, 12, 13, 19, 20, 31, 37, 42, 45, 47, 49, 52], "batch": [27, 46, 47], "batch_siz": [27, 47], "batch_t": 47, "bath": [12, 19, 30], "bathroom": [12, 13, 18, 19, 26, 30, 31, 36], "bayesian": 37, "bayesopt": 37, "bazazeh": [1, 58], "beagl": [12, 19, 30, 47], "bear": 47, "beat": [40, 49], "beauti": [45, 46, 50], "becam": 47, "becaus": [1, 7, 8, 10, 14, 15, 16, 17, 18, 22, 23, 24, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 58], "becom": [4, 14, 15, 18, 21, 22, 32, 33, 36, 37, 38, 41, 42, 43, 46], "bed": [38, 51], "bedroom": [12, 13, 18, 19, 20, 26, 30, 31, 36], "bedroomabvgr": [39, 41, 50], "bedrooms_per_household": [16, 23, 34, 35, 57], "beef": [28, 46], "been": [1, 4, 6, 12, 13, 16, 17, 18, 19, 23, 24, 30, 31, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 56, 58], "befor": [1, 4, 10, 13, 14, 15, 17, 18, 20, 21, 22, 24, 28, 30, 31, 32, 33, 35, 36, 39, 40, 43, 44, 45, 46, 47, 48, 49, 51, 55, 56], "begin": [18, 28, 31, 36, 42, 45, 48, 49, 54], "beginn": 47, "behav": [37, 41], "behavior": [23, 32, 34, 38, 45, 51, 52], "behaviour": [17, 24, 35], "behind": [11, 12, 18, 19, 30, 36, 58], "being": [4, 12, 14, 16, 19, 21, 23, 30, 32, 34, 38, 39, 40, 41, 44, 46, 49, 50, 56, 58], "belief": 50, "believ": [26, 37, 41, 48], "bell": 47, "belong": [13, 18, 31, 36, 44, 55], "below": [1, 5, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58], "bench": 47, "benchmark": [26, 47], "bendigo": 48, "benefici": [17, 24, 35, 50], "benefit": [4, 15, 33, 40, 44, 46, 50, 54], "bengio": 37, "ber": 46, "bergstra": 37, "berri": 46, "bertop": 46, "best": [2, 13, 14, 15, 20, 21, 22, 23, 26, 29, 31, 32, 33, 37, 38, 39, 40, 41, 43, 44, 45, 49, 50, 51, 55, 56], "best_alpha": 39, "best_c": 27, "best_depth": [14, 21, 26, 32], "best_estimator_": [37, 39], "best_k": 27, "best_n_neighbour": [15, 22, 33], "best_param": [37, 50], "best_paramet": 37, "best_params_": [37, 39, 50], "best_scor": 37, "best_score_": [37, 39], "best_svr": 50, "bestalpha_coeff": 39, "better": [6, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 27, 28, 30, 31, 33, 34, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 54, 55, 56, 57, 58], "between": [2, 8, 10, 11, 12, 14, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 32, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 54, 56], "bewar": 46, "beyond": [14, 21, 32, 37, 42, 50], "bhatt": [1, 58], "bia": [18, 36, 38, 41, 49, 51, 54], "bias": [11, 38, 41, 46, 49], "bicycl": [13, 20, 31, 48], "big": [7, 15, 17, 22, 24, 28, 29, 33, 35, 37, 38, 40, 42, 43, 44, 45, 46, 47, 49, 50, 56], "bigalpha_coeff": 39, "bigger": [15, 17, 18, 22, 33, 35, 36, 39, 41, 44, 46, 47, 48], "biggest": [39, 42], "bike": 48, "bill": 47, "billboard": 48, "billie_holidai": 46, "billion": 39, "billionth": 48, "bin": [16, 23, 28, 34, 37, 39, 42, 48, 49, 50, 52, 55], "binar": [13, 17, 20, 24, 31, 35], "binari": [13, 16, 17, 18, 20, 23, 24, 28, 31, 34, 35, 36, 47, 49, 50, 53, 54], "binary_feat": [17, 24, 28, 35], "binary_featur": [38, 40, 41], "binary_transform": [28, 38, 40, 41], "bincount": [38, 40], "bind": [15, 22, 27, 33, 56], "binomi": 37, "biolog": 42, "biologi": [17, 24, 35], "bit": [10, 13, 14, 16, 17, 18, 20, 21, 23, 24, 27, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48, 49, 50], "black": [15, 22, 33, 41, 43, 47, 48], "blackhawk": 46, "bldgtype": [39, 41, 50], "bldgtype_1fam": 39, "bldgtype_2fmcon": 39, "bldgtype_duplex": 39, "bldgtype_twnh": 39, "bldgtype_twnhs": 39, "blei": 46, "blend": 46, "blindli": [38, 39], "blob": [12, 53], "block": [18, 36, 49], "blog": [46, 48], "bloomberg": [1, 9], "blq": [39, 41, 50], "blue": [13, 15, 20, 22, 31, 33, 37, 38, 41, 42, 43, 48], "bluesman": 46, "bmatrix": [42, 45], "board": 4, "boathous": 47, "bob_dylan": 46, "boggl": 40, "bold": 50, "bond": [38, 51], "bonu": 40, "book": [9, 38, 39, 45, 46, 48, 50, 58], "bool": [29, 39, 48], "bool_t": 28, "boom": 52, "boost": [46, 51, 54], "booster": 40, "bootstrap": [10, 50], "border": [13, 18, 31, 36, 44, 46, 53, 55], "bore": [18, 29, 36], "boston": [18, 36], "both": [2, 6, 13, 14, 15, 17, 18, 20, 21, 22, 24, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 54, 57, 58], "bother": 41, "bottom": 44, "bought": 45, "bound": [42, 49], "boundari": [14, 21, 32, 44, 46, 50, 51, 56], "bow": 29, "bow_df": [17, 24, 35], "box": [9, 41, 54], "boxplot": 41, "boyc": [20, 31], "br": [29, 46], "bracket": 8, "brain": [42, 47], "branch": [13, 20, 31, 44, 46, 49], "brand": 50, "break": [1, 23, 29, 38, 54, 56], "breakdown": 19, "breakwat": 47, "breath": 54, "breathtak": 46, "breed": 54, "breiman": 40, "brief": [4, 18, 36, 40], "briefli": [12, 19, 30, 38, 40, 42], "bring": [6, 26, 41, 44, 51, 52, 54], "british": [1, 46], "british_columbia": 46, "broad": [15, 22, 27, 33, 46, 56], "broadcast": 46, "broader": [2, 40, 46], "broadest": 46, "broadli": [13, 15, 18, 20, 22, 31, 33, 36, 38, 40, 43, 44, 46], "broth": 28, "brownle": 42, "browser": 10, "brush": 47, "bsmtcond": [39, 41, 50], "bsmtexposur": [39, 41, 50], "bsmtfinsf1": [39, 41, 50], "bsmtfinsf2": [39, 41, 50], "bsmtfintype1": [39, 41, 50], "bsmtfintype2": [39, 41, 50], "bsmtfullbath": [39, 41, 50], "bsmthalfbath": [39, 41, 50], "bsmtqual": [39, 41, 50], "bsmtunfsf": [39, 41, 50], "btw": 41, "bubbl": [45, 47], "bucket": [42, 52], "budget": [37, 45], "bug": [4, 8], "bui": [45, 51], "build": [0, 2, 10, 11, 14, 16, 17, 21, 23, 24, 28, 32, 34, 35, 40, 42, 43, 46, 48, 50, 53, 56], "built": [8, 12, 13, 14, 18, 19, 20, 30, 31, 32, 36, 37, 41, 48, 50, 51], "bullshit": [1, 49], "bulwark": 47, "bunch": [8, 10, 13, 20, 26, 31, 39, 40, 47, 49, 50, 51, 56], "bundl": [7, 10], "bureau": [18, 36], "busi": [38, 43, 49, 52], "businesswoman": 46, "bustl": 48, "butterfli": 44, "buzz": [12, 19, 30], "bypass": 58, "c": [0, 1, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 56, 58], "c1": 44, "c2": 44, "c_1": 43, "c_2": 43, "c_3": 43, "c_log": [15, 22, 27, 33, 56], "c_val": 27, "c_valu": 27, "c_widget": [15, 22, 27, 33, 56], "ca": [1, 5, 9, 12, 19, 51, 52, 58], "ca_transform": [17, 24, 35], "cache_s": 50, "cal_hous": [18, 36], "calcul": [7, 14, 15, 16, 21, 22, 23, 26, 32, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 48, 51, 52, 53, 54, 56], "calgary_flam": 46, "calibr": 51, "california": [16, 23, 34, 42], "california_h": 42, "californian": [16, 23, 34], "call": [1, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56], "callback": 40, "caller": 51, "calm": 54, "came": 48, "camera": [17, 24, 35], "campu": [42, 58], "can": [1, 4, 6, 7, 10, 12, 13, 15, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 36, 37, 38, 39, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58], "canada": [5, 14, 15, 17, 18, 21, 22, 24, 32, 33, 35, 36, 46, 50, 52, 54], "canada_usa_c": [13, 14, 15, 18, 21, 22, 31, 32, 33, 36, 55], "canadian": [28, 46], "canadien": 46, "canberra": 48, "cancel": 58, "cancer": [12, 19, 30, 42], "candid": [26, 37, 40, 46, 56], "cannot": [0, 8, 12, 14, 15, 19, 21, 22, 32, 33, 37, 38, 40, 41, 42, 44, 48, 49, 50, 58], "canuck": 46, "canva": [1, 7, 12, 13, 19, 51], "capabl": 9, "capit": [38, 40, 41], "caption": [7, 47], "captiv": 46, "captur": [11, 14, 16, 18, 21, 23, 32, 34, 36, 40, 42, 44, 45, 46, 48, 49, 54], "car": [12, 19, 30, 46, 47, 51], "card": [12, 13, 19, 20, 30, 31, 38, 49, 50], "care": [5, 7, 14, 16, 21, 23, 32, 34, 37, 38, 39, 41, 42, 43, 48, 49, 54], "carefulli": [1, 12, 19, 38, 39, 58], "carpentri": 5, "carri": [13, 14, 15, 17, 20, 21, 22, 24, 26, 28, 31, 32, 33, 35, 37, 38, 39, 40, 43, 45, 46, 48, 51, 52, 56], "caruana": 41, "case": [6, 10, 11, 13, 14, 15, 16, 20, 21, 22, 23, 28, 29, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51, 53, 54, 58], "cash": [12, 19, 30], "cast": [37, 45, 52], "castl": 47, "cat": [12, 19, 27, 30, 38, 40, 46, 47, 52, 54], "catamount": [12, 19, 30, 47], "catboost": [11, 41, 50, 54], "catboostclassifi": 40, "catboostregressor": 40, "catch": [38, 58], "categor": [13, 20, 26, 31, 37, 38, 39, 40, 42, 43, 45, 46, 49, 50, 54, 56, 57], "categori": [15, 16, 22, 23, 27, 28, 33, 34, 38, 39, 40, 41, 42, 43, 47, 50, 54], "categorical_feat": [17, 24, 28, 35, 37, 54], "categorical_featur": [35, 38, 39, 40, 41, 48, 49, 50], "categorical_transform": [28, 35, 38, 39, 40, 41, 48, 50], "categories_": [16, 17, 23, 24, 34, 35], "cater": 43, "caus": [38, 41, 42, 45, 49, 58], "causal": [41, 42], "caution": 48, "cbar": [18, 36], "cbtf": [1, 58], "cc": [0, 1], "cc_df": 38, "cconj": 46, "ccp_alpha": 50, "cell": [7, 8, 12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 34, 35, 37, 38, 39, 40, 41, 42, 45, 47, 49, 50, 52, 55, 56], "censor": [1, 11, 50, 51, 54], "censu": [18, 36, 38, 40, 41], "census_df": 38, "cent": 39, "center": [15, 22, 33, 43, 44, 47, 53], "centercrop": 47, "centers_idx": 43, "central": [5, 12], "centralair": [39, 41, 50], "centralair_i": 39, "centralair_n": 39, "centric": [11, 50], "centroid": [43, 44], "centroids_idx": 43, "centroids_idx_init": 43, "centuri": 46, "certain": [10, 15, 18, 22, 29, 33, 36, 37, 38, 41, 42, 43, 46, 49, 50], "certainli": 55, "certainti": 38, "cezannec": 47, "chaat": 46, "chain": [17, 24, 35], "challeng": [6, 11, 14, 19, 32, 42, 43, 45, 47, 48, 51, 54], "chambar": 28, "chanc": [14, 31, 32, 37, 38, 39, 42, 43, 49, 50, 51], "chang": [0, 5, 7, 8, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 27, 31, 32, 33, 34, 37, 39, 40, 41, 43, 44, 45, 47, 48, 49, 50, 55, 56, 58], "channel": [1, 10, 47], "chapter": 1, "charact": [17, 24, 35, 38, 46], "characterist": [13, 14, 18, 20, 21, 31, 32, 36], "charg": [0, 12, 19, 30, 49], "charl": [18, 36], "charm": 46, "chart": [41, 48, 49, 50], "chat": 58, "chatgpt": [12, 46], "che210d": 9, "cheaper": 42, "cheat": 9, "check": [1, 4, 7, 10, 12, 13, 14, 16, 18, 19, 20, 21, 23, 30, 31, 32, 34, 36, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 56], "check_arrai": 28, "check_assumpt": 49, "check_consistent_length": 28, "check_invers": [17, 24, 35], "check_param": 28, "check_x_i": 28, "check_y_param": 28, "checklist": 54, "checkmark": 45, "checkout": 37, "cheetah": [12, 19, 30, 47], "chegini": [1, 58], "cherri": 50, "chest": [14, 21, 32], "chetah": [12, 19, 30, 47], "chi": 49, "chicago": 52, "chicken": 43, "child": [38, 41], "children": 45, "chines": [28, 46], "chn": 8, "choic": [2, 21, 37, 39, 40, 41, 43, 44, 45, 48, 52, 56, 57], "choos": [12, 30, 37, 38, 40, 44, 50, 51, 54, 56], "chop": [37, 46, 50], "choreograph": 52, "chose": [26, 50], "chosen": [14, 21, 32, 37, 38, 49, 50, 54], "chrbv": 49, "christin": 52, "christma": 52, "chrome": [12, 19], "chunki": 43, "churn": [50, 54], "ciml": 1, "cinematographi": 46, "cinereu": 47, "circl": [15, 22, 33, 38], "circumst": 7, "citat": 7, "cite": 49, "citi": [13, 14, 15, 21, 22, 31, 32, 33, 46, 48, 50, 54, 55], "citibik": 48, "cities_df": [15, 18, 22, 33, 36], "citizen": 49, "cityscap": 48, "civ": [38, 40, 41], "clai": 41, "claim": [0, 37, 38], "clarif": 43, "clarifi": 54, "clariti": 11, "class": [1, 4, 5, 10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 42, 43, 46, 48, 49, 50, 51, 55, 56], "class_attend": [13, 14, 20, 21, 31, 32, 54], "class_attendance_enc": [17, 24, 35], "class_attendance_level": [17, 24, 35], "class_label": 38, "class_labels_fil": [12, 19, 30], "class_nam": [13, 15, 20, 22, 27, 31, 33, 40, 47], "class_sep": 38, "class_weight": [40, 50], "classes_": [18, 29, 36, 38, 40, 41, 47, 53], "classic": [15, 22, 33, 47, 53], "classif": [1, 2, 11, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 28, 32, 33, 34, 35, 36, 39, 40, 41, 42, 45, 46, 48, 49, 50, 53, 55, 56], "classifi": [14, 15, 16, 17, 21, 22, 23, 24, 27, 32, 33, 34, 35, 37, 38, 41, 47, 50, 53, 55, 57], "classification_df": [13, 14, 20, 21, 31, 32], "classification_report": [38, 47], "classifiers_ndt": 40, "classify_imag": [12, 19, 30, 47], "classmat": [6, 56, 57, 58], "classroom": [1, 51], "clean": [2, 12, 19, 26, 28, 29, 30, 44, 50, 58], "clean_text": 46, "cleaned_hm": [38, 51], "cleaned_restaurant_data": 28, "cleaner": [38, 41], "clear": [7, 11, 38, 43, 51, 56], "clearli": [4, 6, 7, 37, 40, 41, 48], "cleric": [38, 40, 41], "clever": 50, "clf": [12, 13, 15, 18, 19, 20, 22, 30, 31, 33, 36, 47], "click": [1, 5, 7, 38, 45, 50, 51], "client": [45, 51], "clinic": [13, 20, 31], "clip": [12, 19, 27, 30], "clone": [5, 7, 10], "close": [2, 12, 14, 15, 18, 21, 22, 27, 32, 33, 36, 37, 38, 43, 44, 46, 48, 52, 53, 56, 58], "close_default_lr": 38, "close_zero_svm": 38, "closer": [15, 16, 18, 22, 23, 33, 34, 36, 45, 55, 58], "closest": [15, 16, 21, 22, 23, 33, 34, 38, 43, 44, 46, 48], "cloth": 48, "cloud": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 35, 36, 37, 38, 39, 40, 52, 58], "cloud3pm": 48, "cloud9am": 48, "clust_label": 43, "cluster": [1, 2, 11, 45, 46, 48, 51], "cluster_cent": 43, "cluster_centers_": 43, "cluster_std": [44, 47], "clutter": [13, 31], "cm": [15, 18, 22, 27, 33, 36, 38, 41, 45, 56], "cmap": [16, 23, 34, 37, 38, 41, 47], "cmn": 39, "cmp": 49, "cnn": [47, 48], "co": [17, 24, 35, 46], "coast": 47, "cockpit": 50, "code": [4, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57], "codecademi": 9, "coef": [48, 49, 52], "coef0": 50, "coef_": [18, 29, 36, 39, 40, 41, 42, 45, 47, 48, 49, 52, 53], "coef_df": [18, 36, 41], "coef_nonzero": 48, "coeff": [18, 29, 36], "coeff_df": 48, "coeffici": [39, 40, 42, 45, 47, 48, 49, 50, 52, 53, 54], "coefs_df": 42, "coher": 43, "col": [13, 17, 18, 20, 24, 31, 35, 36, 45, 48, 54], "col1": 8, "col2": 8, "col3": 8, "col4": 8, "col5": 8, "col6": 8, "cold": [16, 23, 34], "colinear": 41, "collabor": [5, 11, 45, 58], "collaps": 41, "colleagu": [8, 9], "collect": [11, 12, 13, 16, 17, 19, 20, 23, 24, 28, 30, 31, 34, 35, 38, 40, 41, 42, 45, 46, 47, 48, 49, 51, 54], "colleg": [38, 40, 41], "collinear": 42, "color": [18, 36, 41, 42, 43, 44, 48, 50], "color_continuous_scal": 42, "color_threshold": 44, "colorbar": [16, 18, 23, 34, 36], "colour": [17, 18, 24, 35, 36, 37, 41, 43, 44, 47], "colsample_bylevel": 40, "colsample_bynod": 40, "colsample_bytre": 40, "columbia": [1, 9, 46], "column": [7, 12, 13, 14, 15, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 54, 55, 56, 57], "column_nam": [17, 24, 35], "column_stack": 42, "columntranform": 57, "columntransform": [1, 16, 23, 28, 34, 37, 38, 39, 40, 41, 42, 48, 49, 50, 52], "columntransformer__countvectorizer__max_featur": 37, "columntransformercolumntransform": [17, 24, 35, 37, 39, 40, 42, 52], "columntransformerifittedcolumntransform": [17, 24, 28, 35, 39, 50], "columntransformerinot": [17, 24, 35, 40], "com": [0, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 35, 36, 37, 38, 39, 40, 47, 48, 49, 51, 52, 58], "comat": 46, "combin": [13, 16, 20, 23, 28, 31, 34, 35, 37, 38, 42, 45, 47, 48, 49, 50, 55, 56], "come": [10, 12, 13, 16, 17, 19, 20, 23, 24, 26, 28, 30, 31, 34, 35, 38, 42, 45, 46, 47, 48, 49, 50, 55], "comedi": 45, "comfi": 28, "comfort": 5, "command": [4, 10, 38, 46, 51], "comment": [8, 9, 28], "commerci": 0, "commit": [7, 38, 58], "common": [1, 8, 11, 13, 14, 15, 20, 21, 22, 27, 31, 32, 33, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 51, 53, 56, 58], "commonli": [13, 16, 20, 23, 31, 34, 37, 38, 43, 49], "commonwealth": 46, "commun": [1, 2, 10, 11, 17, 24, 35, 37, 39, 51, 58], "commut": 8, "comp_dict": 38, "compact": [37, 42], "compani": [38, 43, 45, 46, 49, 52], "compar": [8, 11, 13, 14, 15, 16, 18, 20, 21, 22, 23, 26, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 53, 54], "comparison": [28, 44, 47, 49, 54], "compassion": 58, "compat": [8, 41], "compatibitl": 8, "compel": 48, "compet": 52, "competit": [40, 47, 53], "complain": [6, 52], "complaint": [6, 58], "complement": 46, "complet": [1, 6, 7, 12, 16, 19, 21, 23, 28, 30, 34, 37, 40, 41, 42, 44, 46, 49, 50, 55, 56, 58], "complex": [11, 13, 15, 18, 20, 22, 27, 28, 31, 33, 36, 37, 39, 40, 41, 42, 44, 46, 47, 48, 51, 56], "complex_warn": 28, "complexwarn": 28, "compli": 0, "complic": [4, 13, 14, 20, 27, 28, 31, 32, 37, 39, 42], "compon": [17, 24, 35, 38, 45, 48, 50, 51, 58], "components_": 46, "compos": [15, 17, 24, 27, 28, 33, 35, 37, 38, 39, 40, 41, 42, 47, 48, 49, 50, 57], "composit": [17, 24, 35], "compound": [46, 47, 49, 52], "comprehend": [27, 46], "comprehens": [43, 54, 58], "compress": [17, 24, 35, 43, 46], "compris": [12, 13, 19, 20, 30, 31, 43], "comput": [1, 7, 9, 10, 11, 17, 24, 27, 30, 35, 37, 38, 40, 41, 42, 43, 44, 46, 48, 50, 51, 53, 58], "computation": 42, "compute_class_weight": 38, "computer_programm": 46, "coms4995": [16, 23, 34], "con": [43, 46, 47, 50], "concat": [12, 15, 16, 17, 18, 19, 22, 23, 24, 30, 33, 34, 35, 36, 41], "concaten": [17, 24, 35, 46], "concav": 42, "concensu": [14, 32], "concentr": [37, 54], "concept": [1, 11, 13, 14, 20, 21, 28, 31, 32, 41, 42, 43, 48, 54, 56, 58], "conceptnet": 46, "conceptu": [40, 50], "concern": [4, 11, 17, 19, 24, 26, 35, 40, 58], "concess": [1, 7], "concis": [13, 20, 31, 51], "conclus": 50, "concord": 49, "concordance_index": 49, "concordance_index_": 49, "concret": [12, 19, 30, 50], "conda": [12, 19, 27, 30, 38, 39, 40, 41, 43, 46, 49, 52], "condens": 20, "condit": [0, 12, 13, 17, 19, 20, 24, 26, 30, 31, 35, 42, 46, 49], "condition1": [39, 41, 50], "condition1_arteri": 39, "condition1_feedr": 39, "condition1_norm": 39, "condition1_posa": 39, "condition1_posn": 39, "condition1_rra": 39, "condition1_rran": 39, "condition1_rrn": 39, "condition1_rrnn": 39, "condition2": [39, 41, 50], "condition2_arteri": 39, "condition2_feedr": 39, "condition2_norm": 39, "condition2_posa": 39, "condition2_posn": [39, 41], "condition2_rra": 39, "condition2_rran": 39, "condition2_rrnn": 39, "conditional_aft": 49, "conduct": [11, 19], "confer": 46, "confid": [12, 14, 19, 21, 29, 30, 32, 41, 49, 51, 54, 56], "confidenti": 38, "config": 10, "config_context": 28, "configur": [37, 39, 40], "confirm": 10, "conflict": [10, 44, 58], "confound": 42, "confus": [8, 15, 17, 22, 24, 33, 35, 39, 43, 51, 56], "confusingli": [12, 19], "confusion_matrix": [38, 47, 49], "confusionmatrixdisplai": 38, "congrat": [17, 24, 35], "conjunct": 42, "connect": [0, 13, 20, 31, 44, 45, 51], "connot": 46, "conort": 42, "consciou": 58, "consecut": 48, "consequ": [7, 12, 17, 19, 30, 35, 38, 45, 50], "consid": [4, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 54, 56, 58], "consider": [2, 11, 38, 40, 43, 45, 49, 50, 51], "consist": [6, 7, 13, 14, 16, 20, 21, 23, 28, 31, 32, 34, 43, 51, 52], "const": 46, "constant": [13, 20, 28, 31, 38, 39, 40, 41, 48, 49, 50], "constitu": 40, "constitut": [46, 58], "construct": 45, "constructor": [13, 16, 23, 31, 34], "consult": [15, 22, 27, 33, 56, 58], "consum": [12, 19, 30, 42, 43, 45, 51, 54], "consumpt": 48, "contact": [12, 19, 30, 58], "contain": [8, 10, 12, 13, 16, 17, 18, 19, 20, 23, 24, 28, 30, 31, 34, 35, 36, 39, 45, 46, 47, 51, 52, 53], "container": 51, "content": [1, 4, 10, 11, 19, 43, 46, 47, 51, 54, 58], "contest": 6, "context": [11, 13, 16, 18, 20, 23, 31, 34, 36, 37, 38, 40, 41, 42, 44, 45, 47, 48, 50, 54, 56], "contextu": 11, "contin": [17, 35], "conting": 44, "continu": [17, 24, 28, 35, 37, 39, 40, 42, 46, 48, 50], "contract": [0, 49], "contract_month": 49, "contract_on": 49, "contract_two": 49, "contrast": [11, 54], "contribut": [15, 18, 22, 33, 36, 41, 47, 58], "control": [5, 8, 13, 14, 15, 17, 18, 20, 21, 22, 24, 31, 32, 33, 35, 36, 39, 40, 47, 58], "convei": 11, "conveni": [8, 12, 19, 37, 38, 43, 46, 48, 49, 50, 51], "converg": 43, "convers": [38, 39, 41, 46, 51], "convert": [12, 16, 17, 18, 19, 23, 24, 28, 30, 34, 35, 36, 40, 41, 42, 46, 48, 49, 58], "convinc": [17, 24, 35, 50], "convolut": [42, 47], "convolutional_neural_network": 47, "cooccurrencematrix": 46, "cook": 43, "cool": 47, "coolwarm": [18, 36], "coordin": [19, 58], "copi": [0, 7, 8, 10, 13, 20, 28, 31, 37, 40, 41, 43, 45, 47, 48, 49, 50, 58], "copyright": 0, "cor": 41, "coral": 47, "core": [9, 11, 16, 17, 23, 24, 28, 32, 34, 35, 37, 38, 39, 42, 44, 45, 48, 49, 51, 54], "corefer": 46, "corei": 51, "corgi": [12, 19, 30, 47], "corona_nlp_test": 52, "coronapocalyps": 52, "coronaviru": 52, "corpor": [5, 52], "corpora": [17, 24, 35, 46], "corpu": [17, 24, 35, 38, 46], "corr": 41, "corr_df": 41, "correct": [7, 12, 13, 14, 15, 19, 20, 21, 22, 30, 31, 32, 33, 38, 40, 41, 49, 50, 55, 56], "correctli": [1, 10, 13, 14, 20, 21, 31, 32, 38], "correl": [48, 54], "correspond": [1, 12, 13, 14, 15, 17, 18, 19, 20, 21, 24, 27, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 43, 45, 48, 56, 58], "cosin": 46, "cosine_similar": 46, "cost": [8, 12, 19, 30, 47, 50, 58], "cost_rep": 8, "costco": 46, "costli": 38, "cot": 47, "cote": 47, "could": [6, 8, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 45, 46, 48, 49, 50, 51, 56, 58], "couldn": 46, "count": [8, 13, 16, 17, 20, 23, 24, 26, 28, 31, 34, 35, 38, 39, 42, 46, 47, 48, 49, 51, 52, 53, 56, 58], "counter": 38, "counti": [26, 56], "countri": [14, 15, 17, 18, 21, 22, 32, 33, 35, 36, 38, 40, 41, 46, 58], "country_columbia": 41, "country_dominican": 41, "country_guatemala": 41, "country_hondura": 41, "country_hong": 41, "country_hungari": 41, "country_india": 41, "country_iran": 41, "country_miss": [40, 41], "country_puerto": 41, "country_scotland": 41, "country_south": 41, "country_taiwan": 41, "country_thailand": 41, "country_trinadad": [40, 41], "country_unit": [40, 41], "country_vietnam": [40, 41], "country_yugoslavia": [40, 41], "countvector": [12, 18, 19, 28, 29, 30, 36, 37, 38, 46, 51, 52, 54], "countvectorizercountvector": [17, 24, 35, 37, 52], "countvectorizeroriginaltweet": 52, "countvectorizersong_titl": 37, "coupl": [4, 13, 31, 37, 44, 52], "cour": 46, "cours": [2, 4, 5, 6, 7, 10, 13, 14, 17, 18, 20, 21, 24, 26, 27, 28, 31, 32, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 52, 54, 55, 56], "coursera": [1, 9], "coursework": 58, "court": 46, "covari": [13, 20, 31, 49], "cover": [8, 11, 19, 38, 40, 43, 47, 48, 58], "coverag": 38, "covid": 52, "covid2019": 52, "cow": 50, "cox": 11, "coxph_fitt": 49, "coxphfitt": 49, "cph": [49, 50, 54], "cph_param": 49, "cpsc": [9, 10, 13, 20, 30, 31, 40, 42, 46, 47, 48, 50, 51, 52, 58], "cpsc330": [0, 1, 10, 12, 17, 19, 20, 24, 25, 27, 28, 30, 31, 32, 35, 37, 41, 46, 47, 49, 51, 52, 58], "cpsc330env": 10, "cpu": [27, 37, 47], "craft": [15, 22, 33, 38, 40, 41, 43, 56], "crash": 1, "crate": 47, "crazi": [28, 51], "creat": [8, 9, 10, 12, 15, 16, 18, 19, 22, 23, 26, 27, 28, 29, 30, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57], "create_lag_df": 48, "create_lag_featur": 48, "create_y_from_r": 45, "creativ": [1, 46], "credenc": 50, "credit": [0, 13, 20, 31, 38, 40, 46, 48, 49, 50], "creditcard": 38, "crime": [18, 36], "crimin": 41, "criteria": [13, 20, 31, 44], "criterion": [44, 50], "critic": [11, 50], "cross": [13, 15, 17, 20, 24, 28, 31, 33, 35, 37, 39, 40, 41, 43, 45, 49, 50, 51, 52, 54, 57], "cross_val": 40, "cross_val_predict": [38, 40, 49], "cross_val_scor": [16, 17, 18, 23, 24, 28, 29, 34, 35, 36, 37, 38, 39, 40, 41, 42, 48, 49, 50, 54, 57], "cross_valid": [15, 16, 17, 18, 22, 23, 24, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38, 40, 41, 42, 45, 48, 49, 50, 51, 52, 54, 56, 57], "cross_validate_std": [14, 21, 32], "crowd": [40, 44], "crown": 58, "crown_princ": 46, "crucial": [12, 14, 18, 19, 21, 30, 32, 36, 41, 43, 44, 45, 46], "crude": 46, "cs189": 9, "cs189_ch7": 9, "csr": 28, "css": 51, "csv": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57], "ct": [17, 24, 35], "cuda": [27, 47], "cui": [1, 58], "cuisin": 51, "cultiv": 11, "cultur": [47, 58], "curios": [12, 19, 30], "curiou": [12, 19, 30, 56], "curl": 51, "current": [1, 40, 46, 47, 48, 49, 50, 51, 52], "curriculum": 11, "curs": 50, "curv": [7, 8, 11, 43, 50, 54, 56], "custom": [5, 8, 12, 13, 17, 19, 20, 24, 28, 30, 31, 35, 38, 39, 45, 51, 52, 54], "custom_plot_tre": [13, 14, 20, 21, 31, 32, 40, 41], "customerid": 49, "customiz": 52, "cut": 44, "cv": [14, 17, 21, 24, 26, 27, 32, 35, 38, 39, 40, 41, 42, 48, 49, 50, 51, 54, 56], "cv_feat": 52, "cv_results_": [37, 39], "cv_score": [14, 21, 27, 32, 39], "cv_train_scor": [26, 56], "cv_valid_scor": [26, 56], "cycl": 8, "cyclic": 48, "cycling_data": 8, "cygnu": 47, "d": [4, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 51], "d3": 43, "da": [12, 19, 30], "dabeaz": 9, "dad": 42, "dai": [4, 8, 14, 28, 42, 47, 49, 50, 54, 58], "daili": [49, 54], "dall": 48, "damag": [0, 38], "dan": 46, "danceabl": [15, 16, 23, 33, 34, 37], "dark": 52, "darker": 37, "dashboard": [15, 22, 27, 33, 56], "data": [1, 2, 5, 7, 8, 9, 10, 11, 27, 29, 44, 46, 49, 53, 54, 55, 57, 58], "data_dict": [18, 36], "data_dir": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56], "data_to_wrap": [17, 24, 35], "data_transform": [27, 47], "data_transforms_bw": 47, "data_url": 38, "datacamp": 9, "datafram": [12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 56, 57], "dataload": [27, 47], "dataloaders_bw": 47, "datapoint": [18, 36], "dataquest": 9, "dataset": [8, 11, 12, 14, 15, 17, 19, 21, 22, 24, 26, 27, 28, 30, 32, 33, 40, 41, 42, 43, 44, 49, 51, 52, 53, 54, 56], "dataset2": 43, "dataset_s": [27, 47], "dataviz": 50, "date": [7, 10, 12, 13, 19, 26, 30, 31, 45, 46, 49, 51, 52, 54, 56, 58], "date_rang": 48, "dates_rain": 48, "datetim": 49, "datetime64": 48, "datetimeindex": 48, "datum": 46, "daughter": [38, 51], "daum\u00e9": 1, "daunt": 45, "dave": 46, "david": [1, 46, 50], "day_nam": 48, "daylight": 48, "dayofweek": 48, "days_sinc": 48, "dbscan": [11, 51], "dc": [48, 49, 52], "dcc": [18, 36], "dd": 48, "de": [46, 48], "deactiv": 10, "deadlin": [14, 19, 58], "deal": [0, 14, 15, 16, 21, 22, 23, 28, 32, 33, 34, 39, 46, 49, 50, 51, 54, 57], "death": 58, "debat": [8, 19, 41], "debbi": 52, "debug": [4, 41], "decad": 47, "decemb": [26, 48], "decid": [8, 13, 15, 18, 20, 22, 31, 33, 36, 40, 41, 42, 43, 44, 46, 48, 49, 54], "decis": [1, 2, 6, 14, 16, 21, 23, 29, 32, 34, 37, 38, 40, 42, 47, 53, 54, 55, 57, 58], "decision_boundari": 53, "decision_funct": 38, "decisiontreeclassifi": [14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 32, 33, 34, 35, 36, 37, 41, 55, 56, 57], "decisiontreeclassifierdecisiontreeclassifi": 40, "decisiontreeregressor": [13, 20, 26, 31, 39, 55, 56], "decisiontreeregressorifitteddecisiontreeregressor": 26, "deck": 9, "declar": 58, "decomposit": [44, 45, 46], "decor": 28, "decreas": [14, 18, 21, 26, 32, 36, 37, 40, 41, 43, 56], "deduct": 7, "deem": 6, "deep": [2, 9, 37, 41, 42, 46, 49, 51], "deepen": [54, 58], "deeper": [2, 12, 19, 37, 38, 39, 41], "deepexplain": 41, "def": [14, 15, 16, 21, 22, 23, 27, 28, 29, 32, 33, 34, 37, 38, 39, 41, 43, 44, 45, 46, 47, 48, 51, 52, 56], "default": [5, 10, 12, 13, 14, 17, 18, 19, 20, 21, 24, 27, 31, 32, 35, 36, 37, 38, 39, 40, 43, 44, 47, 48, 49, 50, 53, 58], "default_check_param": 28, "default_threshold": 38, "defaultdict": 45, "defin": [13, 15, 16, 17, 22, 23, 24, 28, 31, 33, 34, 35, 38, 40, 41, 43, 44, 45, 48, 51], "definit": [8, 15, 22, 33, 41, 43, 46, 48, 53, 54, 55], "degre": 38, "degrees_freedom": 49, "degrees_of_freedom": 49, "del": 40, "delai": [1, 10, 42], "deleg": 46, "delet": [4, 7, 16, 23, 34, 50], "delgado": 40, "delight": 46, "deliver": 7, "delv": [11, 46], "demo": [1, 19, 40, 50, 58], "demograph": [13, 20, 31, 45], "demonstr": [13, 14, 16, 18, 20, 21, 23, 27, 28, 29, 31, 32, 34, 36, 37, 39, 40, 43, 45, 46, 47], "denois": 12, "denomin": [39, 52], "denot": [13, 20, 31, 45], "dens": [44, 46], "densenet": [27, 47], "densenet121": [27, 47], "densenet121_weight": [27, 47], "densiti": [41, 44, 54], "dep": 46, "department": 58, "departur": 42, "depend": [2, 8, 10, 13, 14, 15, 17, 20, 21, 22, 24, 31, 32, 33, 35, 37, 38, 39, 40, 41, 43, 44, 46, 48, 49, 50], "dependence_plot": 41, "dependents_no": 49, "dependents_y": 49, "deploi": [14, 21, 26, 32, 38, 45, 50, 54], "deploy": [11, 41, 48], "deprec": [23, 32, 34, 38, 39, 49, 52, 53], "deprecationwarn": [40, 49], "depth": [1, 13, 14, 20, 21, 26, 31, 32, 37, 40, 44, 55, 56], "dequ": [40, 41], "deriv": [0, 13, 18, 20, 31, 36, 38, 45, 49, 54], "descend": [8, 29, 44, 47, 54], "descent": 48, "descr": [18, 36], "describ": [8, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 26, 28, 30, 31, 32, 33, 34, 36, 38, 39, 45, 46, 48, 51, 56], "descript": [1, 39, 49, 52], "desenet": 27, "deserv": 6, "design": [11, 20, 31, 41, 44, 47, 50, 58], "desir": [28, 38, 46, 49, 57], "desk": 58, "despit": [42, 46], "det": [46, 52], "detach": [27, 47], "detail": [15, 17, 22, 24, 33, 35, 40, 46, 47, 51, 58], "detect": [12, 13, 19, 20, 26, 30, 31, 38, 39, 43, 44, 48, 51], "determin": [15, 20, 22, 27, 33, 43, 44, 46, 49, 50, 56, 58], "detriment": [38, 45], "dev": [14, 32, 53], "develop": [1, 9, 11, 12, 14, 16, 17, 19, 21, 23, 24, 30, 32, 34, 35, 37, 38, 39, 40, 46, 47, 50, 51, 52, 54], "devianc": 49, "deviat": [6, 14, 16, 21, 23, 32, 34, 40, 41], "devic": [27, 28, 40, 47], "deviceprotect": 49, "deviceprotection_no": 49, "deviceprotection_y": 49, "df": [12, 13, 14, 16, 17, 19, 21, 23, 24, 26, 28, 30, 31, 32, 34, 35, 37, 38, 39, 41, 42, 47, 48, 49, 50, 51, 52, 55], "df_concat": [12, 19, 30], "df_float_1": 8, "df_float_2": 8, "df_hour_week_ohe_poli": 48, "df_locat": 48, "di": 49, "diagnos": [14, 32, 41, 54], "diagnosi": 38, "diagnost": [49, 51], "diagon": [15, 22, 33, 38, 41], "diagram": [17, 24, 35, 37, 40, 41], "dialogu": 46, "dict": [38, 45], "dict_kei": 40, "dictionari": [8, 16, 23, 34, 37, 38, 40, 41, 51], "did": [6, 12, 13, 15, 19, 20, 22, 31, 33, 41, 43, 46, 48, 52, 56, 58], "didn": [28, 37, 40, 41, 44, 46, 48, 49, 51], "die": 52, "diet": [13, 20, 31, 46], "diff": 48, "differ": [1, 2, 5, 7, 8, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 26, 28, 30, 31, 32, 33, 35, 36, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 55, 56], "differenti": [11, 12, 13, 19, 20, 30, 31], "difficult": [4, 6, 7, 38, 42, 43, 50], "difficulti": [43, 54], "dig": [38, 39], "digit": [48, 50], "dilemma": 45, "dim": [27, 28, 47], "dimens": [8, 18, 36, 42], "dimension": [2, 8, 18, 20, 27, 36, 37, 38, 40, 42, 43, 46], "dine": 51, "direct": [18, 23, 29, 36, 41, 42, 44, 46, 52], "direct_bilirubin": [12, 19, 30], "directli": [1, 8, 17, 24, 28, 35, 39, 47, 49, 51, 58], "director": 45, "directori": [10, 13, 14, 16, 21, 23, 27, 31, 32, 34], "dirichlet": [46, 47], "disabl": 46, "disadvantag": [37, 40, 44, 45, 57], "disast": [12, 30], "discard": [42, 46], "disciplin": [38, 42], "disclos": [52, 58], "discourag": 8, "discours": 45, "discov": [42, 43], "discoveri": [12, 19, 30], "discret": [13, 20, 28, 31, 42], "discrete_scatt": [13, 14, 15, 18, 20, 21, 22, 27, 31, 32, 33, 36, 43, 44, 47, 53, 55, 56], "discretization_feat": 42, "discrimin": 40, "discuss": [4, 14, 15, 16, 18, 21, 22, 23, 32, 33, 34, 36, 41, 42, 43, 44, 48, 54, 56, 57, 58], "diseas": [13, 20, 31, 38, 49], "dislik": [28, 50], "displaci": [46, 52], "displai": [7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 44, 45, 47, 48, 49, 55, 56, 57], "display_heatmap": 37, "display_label": 38, "displaystyl": 46, "disput": 46, "disrespect": 4, "dissemin": 51, "dist": [15, 22, 27, 33, 43, 44], "distanc": [8, 16, 23, 27, 34, 42, 44, 45, 46], "distinct": [38, 42, 48, 50], "distinguish": [13, 15, 17, 20, 22, 24, 27, 31, 33, 35, 38, 56], "distract": 58, "distribut": [0, 10, 12, 14, 21, 26, 28, 32, 38, 41, 42, 44, 46, 47, 48, 58], "district": [16, 18, 23, 34, 36], "districtdatalab": 43, "disturb": [12, 19, 30], "dive": 41, "divers": [11, 40, 43, 45, 48], "divid": [18, 36, 38, 40, 41, 48, 56], "divis": [20, 41], "divorc": [40, 41], "dktal": 49, "dlwqn": 49, "dmp": 58, "do": [0, 1, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 18, 19, 20, 21, 22, 24, 26, 27, 30, 31, 32, 33, 36, 39, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58], "dobj": 46, "doc": [8, 9, 12, 29, 41, 46, 47, 51, 52, 58], "doc_id": 46, "docker": 51, "doctor": [38, 40, 41], "document": [0, 1, 7, 12, 13, 14, 16, 17, 19, 21, 23, 24, 26, 27, 28, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 52, 54, 58], "document_top": 46, "documentari": 45, "doe": [5, 8, 10, 12, 14, 15, 16, 19, 22, 23, 27, 28, 30, 32, 33, 34, 37, 39, 40, 41, 42, 43, 45, 46, 48, 49, 51, 52, 54, 56, 58], "doesn": [7, 8, 12, 14, 16, 17, 21, 23, 24, 32, 34, 35, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 50, 54], "dog": [27, 38, 47], "dolist": 51, "dollar": [4, 18, 36, 39, 50], "dolli": 52, "domain": [0, 12, 19, 30, 41, 43, 46], "domin": [16, 23, 34, 39, 47], "domingo": [1, 14, 32, 42], "dominican_republ": 46, "don": [4, 12, 13, 14, 16, 17, 19, 21, 24, 26, 27, 28, 30, 32, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "done": [5, 10, 12, 14, 17, 19, 21, 24, 32, 35, 37, 38, 47, 48, 50, 54, 57], "dont": 52, "door": 47, "dosa": 46, "dot": [15, 18, 22, 33, 36, 38, 40, 41, 42, 44, 46], "dot_product": 46, "doubl": 37, "down": [14, 21, 28, 32, 38, 41, 46, 49, 50, 56, 58], "downfal": 45, "download": [5, 7, 10, 12, 13, 16, 18, 19, 23, 26, 30, 31, 34, 36, 38, 39, 41, 46, 47, 50, 52, 56], "downright": 50, "dpi": [27, 42], "dr": 46, "draft": 1, "drag": 7, "drama": 45, "drastic": 38, "draw": [18, 36, 37, 46, 50], "drawback": [11, 41, 45], "drawn": 40, "dream": 47, "dreampharmaceut": 46, "drink": 50, "drinker": 46, "drive": [12, 19, 29, 30, 41], "driven": [10, 37, 38], "droit": 46, "drop": [7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 48, 49, 50, 51, 52, 54, 56, 57, 58], "drop_dupl": [15, 22, 33, 37], "drop_feat": [17, 24, 28, 35, 54], "drop_feats_new": 28, "drop_featur": [38, 39, 40, 41, 48, 49, 50, 52], "dropdrop": [17, 24, 28, 35, 39, 40, 50, 52], "drope": [16, 23, 34], "dropna": [38, 48, 51], "dropoff": 43, "drought": 29, "drug": [12, 19, 30, 51], "dsci": [1, 9, 41, 50, 53], "dsl": 49, "dt": [26, 56], "dt_best": 56, "dt_final": 26, "dt_pipe": 37, "dt_regr": 26, "dtype": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52], "dtypelik": 28, "dual": 38, "duan": [1, 58], "duck": [47, 50], "duckbil": 47, "due": [7, 12, 13, 14, 16, 17, 18, 19, 36, 40, 42, 45, 58], "dummi": [13, 15, 16, 17, 18, 20, 22, 23, 24, 26, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 47, 48, 49, 50, 55, 57], "dummy_clf": [13, 20, 31, 55], "dummy_regr": 26, "dummy_scor": [15, 22, 33], "dummy_valid_accuraci": [15, 22, 33], "dummyclassifi": [14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 47, 50, 51, 52, 55, 56, 57], "dummyregressor": [17, 24, 26, 35, 40, 41, 42, 50, 51, 57], "dump": 51, "dun": [12, 19, 30], "dunno": [12, 19, 30], "duplex": 39, "duplic": 8, "durat": [7, 42, 48, 49], "duration_col": 49, "duration_m": [15, 16, 23, 33, 34, 37], "dure": [1, 4, 8, 12, 13, 15, 17, 18, 19, 20, 22, 24, 26, 30, 31, 33, 35, 36, 37, 40, 41, 42, 45, 46, 51, 54, 55, 56, 57, 58], "dwell": 39, "e": [6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54], "e737c5242822": 49, "e_": [14, 21, 32], "each": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58], "eager": 51, "earli": [41, 49, 50, 58], "earlier": [16, 23, 34, 40, 42, 48, 49], "early_stopping_round": 40, "earnest": 58, "easi": [7, 15, 16, 18, 22, 23, 33, 34, 36, 40, 41, 42, 43, 44, 46, 50, 52], "easier": [5, 7, 38, 41, 42, 45, 50], "easiest": [41, 49], "easili": [40, 42, 48, 50, 51, 55], "east": 28, "eat_out_freq": 28, "echidna": 47, "econom": [17, 24, 35, 48], "ecosystem": 47, "eda": [14, 21, 26, 28, 32, 46, 49, 54], "edg": [13, 20, 31, 37], "edgecolor": [37, 48], "edit": [37, 46], "edu": 9, "educ": [38, 40, 41, 45], "education_level": [38, 40, 41], "effect": [15, 18, 22, 26, 27, 33, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 51, 54, 56, 58], "effici": 37, "effort": [4, 10, 37, 42, 43, 45, 47, 58], "egg": 43, "either": [4, 13, 14, 15, 17, 20, 21, 22, 24, 27, 31, 32, 33, 35, 38, 41, 43, 44, 46, 47, 48, 56], "elast": 49, "elbow": 44, "elect": 46, "electr": [39, 41, 50], "electrical_engin": 46, "electrical_fusea": 39, "electrical_fusef": 39, "electrical_fusep": 39, "electrical_miss": 39, "electrical_mix": 39, "electrical_sbrkr": 39, "electron": [49, 58], "eleg": [16, 23, 34, 46, 50], "elegantli": 46, "element": [0, 1, 9, 14, 17, 24, 32, 35, 46, 55], "eli5": 41, "elif": [13, 20, 31, 48, 49], "elimin": 11, "els": [13, 17, 20, 24, 27, 28, 31, 35, 38, 47, 48, 49, 52], "email": [1, 12, 13, 14, 19, 21, 30, 32, 38, 51, 58], "emb": [7, 15, 22, 33, 38, 43, 44], "embed": [1, 11, 17, 24, 35, 47, 51, 54], "emoji": [29, 52], "emoticon": [42, 43], "emp": 41, "empathi": 46, "emphas": 11, "emphasi": [51, 58], "emploi": [27, 48, 49, 51, 54], "employ": 45, "employe": [13, 20, 31], "empti": [18, 27, 36, 46, 47, 48], "en": [48, 49, 50, 52], "en_core_web_lr": 46, "en_core_web_md": [46, 52], "enabl": [10, 45, 46, 48], "enable_categor": 40, "enable_halving_search_cv": 37, "enc": [16, 17, 23, 24, 34, 35, 48], "enclosedporch": [39, 41, 50], "encod": [12, 14, 19, 21, 26, 28, 29, 30, 32, 37, 38, 39, 41, 45, 49, 54, 57], "encompass": [49, 50, 54], "encount": [17, 24, 35, 37], "encourag": 10, "end": [4, 8, 11, 12, 14, 15, 18, 19, 21, 22, 27, 30, 32, 33, 36, 37, 38, 42, 43, 44, 45, 46, 48, 49, 50, 51, 56, 58], "endors": 0, "endpoint": 49, "energi": [15, 16, 23, 33, 34, 37, 48], "engag": 58, "engin": [1, 9, 11, 17, 24, 35, 38, 39, 43, 45, 46, 49, 51], "england": 52, "english": [12, 16, 19, 23, 28, 29, 30, 34, 37, 38, 46, 47, 51, 52], "enhanc": 58, "enjoi": [1, 18, 29, 36], "enjoy_class": [17, 24, 35], "enjoy_cours": [17, 24, 35, 54], "enjoy_course_enc": [17, 24, 35], "enjoy_the_mo": [38, 51], "enough": [7, 15, 17, 22, 33, 35, 38, 39, 40, 43, 45, 54], "enrol": 58, "ensembl": [1, 11, 28, 39, 41, 42, 44, 45, 48, 49, 50, 51], "ensiti": 44, "ensur": [7, 11, 16, 23, 26, 34, 40, 48], "ensure_2d": 28, "ensure_all_finit": 28, "ensure_min_featur": 28, "ensure_min_sampl": 28, "ensure_non_neg": 28, "ent": [46, 52], "enter": [17, 24, 35, 49, 50], "enterpris": 5, "entertain": 46, "enthusiast": [12, 19, 30, 50], "entir": [4, 8, 12, 14, 19, 21, 32, 39, 47, 48, 50, 51, 52, 58], "entiti": [42, 45, 46, 52], "entitl": [17, 24, 35], "entlebuch": [12, 19, 30, 47], "entri": [15, 16, 17, 18, 22, 23, 24, 33, 34, 35, 36, 38, 39, 42, 45, 48, 49], "entropi": [13, 20, 31, 50], "enumer": 40, "env": [10, 17, 20, 24, 27, 28, 31, 32, 35, 37, 41, 49, 52, 53], "environ": [3, 5, 8, 12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 34, 35, 37, 38, 39, 40, 41, 42, 46, 47, 49, 50, 52, 58], "environemnt": 10, "environment": 54, "ep": [13, 14, 15, 18, 21, 22, 31, 32, 33, 36, 44, 55], "epoch": 48, "epsilon": [44, 50], "equal": [8, 15, 17, 22, 33, 35, 38, 39, 40, 41, 44, 45, 48, 54, 58], "equat": [4, 12, 18, 19, 36], "equip": [15, 22, 33, 49, 58], "equival": [8, 38, 40], "erik": 46, "err": 46, "error": [4, 6, 7, 8, 10, 11, 13, 15, 17, 18, 20, 22, 24, 28, 31, 33, 35, 36, 40, 41, 42, 46, 49, 50, 51, 54, 56], "error_": [14, 21, 32], "erupt": [12, 30], "erythrocebu": [12, 19, 30, 47], "es": 48, "eskimo": 38, "esl": 1, "especi": [2, 15, 20, 22, 31, 33, 37, 38, 40, 42, 45, 48], "essenti": [49, 54], "establish": 26, "estat": [13, 20, 31], "estim": [14, 15, 17, 18, 22, 24, 28, 32, 33, 35, 36, 37, 42, 43, 49, 50, 51, 54], "estimator_nam": 28, "estimators_": 40, "et": [40, 46], "etc": [1, 2, 7, 8, 13, 20, 31, 42, 46, 47, 48, 49, 50, 51, 52, 58], "ethic": [1, 11, 51], "euclidean": [43, 44, 46], "euclidean_dist": [15, 16, 22, 23, 33, 34, 43, 44, 46], "ev": 52, "eva": 45, "eva_model": 45, "eval": 47, "eval_metr": [40, 41], "eval_on_featur": 48, "evalu": [1, 8, 11, 13, 14, 20, 21, 26, 31, 32, 37, 39, 41, 43, 48, 50, 51, 56], "evapor": 48, "even": [0, 7, 11, 12, 13, 14, 18, 19, 20, 21, 28, 31, 32, 36, 37, 38, 42, 43, 44, 45, 48, 49, 50, 52, 54, 56, 57, 58], "event": [0, 38, 39, 58], "event_col": 49, "event_observ": 49, "ever": [13, 20, 31, 53], "everi": [8, 12, 13, 14, 19, 20, 21, 31, 32, 40, 44, 48, 56], "everydai": [8, 46], "everyon": [6, 41, 50, 54], "everyth": [12, 17, 19, 24, 35, 38, 45, 48, 51], "everywher": 48, "evict": 52, "evo": 51, "evocarshar": 51, "evok": 46, "ex": [39, 41, 50], "ex1_idx": 41, "ex2_idx": 41, "ex_df": 29, "exact": [4, 49], "exactli": [7, 12, 14, 19, 20, 21, 30, 32, 41, 56], "exagger": 50, "exam": [1, 6, 12, 19, 50, 51], "examin": [14, 15, 16, 18, 21, 22, 23, 26, 27, 28, 32, 33, 34, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53], "exampl": [0, 4, 5, 6, 7, 8, 10, 21, 27, 28, 29, 39, 44, 45, 47, 48, 51, 53, 54, 55, 56, 58], "example1": [13, 20, 31], "example2": [13, 20, 31], "exceedingli": 56, "excel": [17, 18, 24, 29, 35, 36, 39, 41, 49, 54, 57], "except": [0, 1, 7, 8, 14, 21, 28, 32, 48, 49, 58], "exception": 4, "exchang": [38, 54], "excit": 45, "execut": [4, 7, 43, 51], "exercis": [1, 7, 9, 12, 19, 46, 51, 52, 56, 57, 58], "exist": [8, 38, 42, 49, 51], "exp": [18, 36, 49, 50], "expand": [1, 13, 20, 31, 58], "expect": [1, 4, 7, 8, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 54, 56, 58], "expected_valu": 41, "expenditur": 48, "expens": [12, 19, 30, 38, 39, 42, 43, 45], "experi": [12, 19, 30, 37, 45, 46, 58], "experienc": 58, "experiment": [37, 51], "expert": [12, 13, 14, 19, 20, 21, 30, 31, 32, 37, 41, 42], "explain": [4, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54], "explan": [4, 14, 15, 22, 32, 33, 54], "explanatori": [13, 20, 31], "explicit": [38, 49], "explicitli": [8, 12, 19, 30, 51], "exploit": 6, "explor": [13, 14, 17, 21, 24, 26, 27, 29, 31, 32, 35, 37, 38, 41, 42, 45, 46, 47, 51, 56], "exploratori": [39, 49, 51, 54], "explos": 52, "expm1": [39, 50], "expon": 37, "exponenti": 37, "export_graphviz": [13, 20, 31, 55], "expos": 29, "exposur": 45, "express": [0, 8, 17, 18, 24, 35, 36, 42, 46, 50], "extend": [46, 47, 53, 58], "extend_block": 49, "extens": [1, 12, 15, 19, 22, 27, 33, 38, 41, 43, 44, 46, 48, 56, 58], "extent": [43, 46], "extercond": [39, 41, 50], "exterior": 41, "exterior1st": [39, 41, 50], "exterior1st_asbshng": 39, "exterior1st_asphshn": 39, "exterior1st_brkcomm": 39, "exterior1st_brkfac": 39, "exterior1st_cblock": 39, "exterior1st_cemntbd": 39, "exterior1st_hdboard": 39, "exterior1st_imstucc": [39, 41], "exterior1st_metalsd": 39, "exterior1st_plywood": 39, "exterior1st_ston": 39, "exterior1st_stucco": 39, "exterior1st_vinylsd": 39, "exterior1st_wd": 39, "exterior1st_wdsh": 39, "exterior2nd": [39, 41, 50], "exterior2nd_asbshng": 39, "exterior2nd_asphshn": 39, "exterior2nd_brk": 39, "exterior2nd_brkfac": 39, "exterior2nd_cblock": 39, "exterior2nd_cmentbd": 39, "exterior2nd_hdboard": 39, "exterior2nd_imstucc": 39, "exterior2nd_metalsd": 39, "exterior2nd_oth": 39, "exterior2nd_plywood": [39, 50], "exterior2nd_ston": [39, 50], "exterior2nd_stucco": [39, 50], "exterior2nd_vinylsd": [39, 50], "exterior2nd_wd": [39, 50], "external_tool": 51, "exterqu": [39, 41, 50], "extra": [4, 43, 48, 51, 58], "extract": [27, 42, 43, 45, 46, 47, 52, 58], "extractor": 54, "extrapol": [48, 49], "extratreesclassifi": 40, "extrem": [6, 17, 35, 38, 40, 41, 45, 49, 52], "ey": 52, "f": [8, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 38, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 56], "f1": [11, 39, 54], "f1_score": 38, "fa": [39, 41, 50], "fac": 52, "face": [12, 13, 15, 19, 27, 30, 31, 33, 45, 47], "facebook": [45, 46, 58], "facial": [15, 33], "facil": 58, "facilit": [8, 58], "fact": [12, 30, 37, 38, 40, 47, 48, 49, 50], "factor": [13, 20, 31, 37, 41, 42, 44, 45, 49], "fail": [1, 7, 8, 10, 14, 16, 17, 21, 23, 24, 32, 34, 35, 42, 44, 46, 49, 50], "failur": [7, 12, 19, 30, 49, 58], "fair": [6, 14, 16, 21, 23, 32, 34, 39, 41, 43, 51, 54, 58], "fairli": [14, 21, 32, 37, 38, 41, 51], "fake": [15, 22, 29, 33], "fake_review": 29, "fall": [15, 22, 33, 43, 46, 48], "fals": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 54], "famili": [12, 19, 30, 37, 38, 39, 40, 41, 43, 51, 58], "familiar": [8, 10, 11, 13, 16, 20, 23, 31, 34, 50, 56, 58], "famou": [1, 9, 29, 46, 47], "fanci": [4, 12, 19, 30, 37], "fancier": 42, "far": [13, 15, 16, 17, 18, 22, 23, 24, 31, 33, 34, 35, 36, 38, 41, 42, 43, 44, 46, 47, 48, 49, 53, 54, 56], "farm": 38, "farthest": [13, 20, 31], "fashion": [20, 40, 46], "fast": [14, 15, 18, 21, 32, 33, 36, 40, 41, 46, 49, 51, 58], "faster": [12, 19, 30, 37, 40, 42, 47], "fastest": 40, "fasttext": 46, "favour": 51, "favourit": 46, "fc": [18, 36], "fcluster": 44, "feat": [28, 37, 48, 52], "feat1": 43, "feat2": 43, "feat_nam": [28, 48, 52], "feat_vec": [29, 45], "featur": [1, 11, 14, 21, 26, 27, 29, 32, 38, 40, 43, 44, 46, 49, 51, 53, 56, 57, 58], "feature_extract": [12, 17, 18, 19, 24, 28, 29, 30, 35, 36, 37, 38, 46, 51, 52], "feature_import": 26, "feature_importances_": [26, 42], "feature_nam": [13, 14, 18, 20, 21, 26, 29, 31, 32, 36, 40, 41, 42, 46], "feature_names_in_": 26, "feature_names_out": [17, 24, 35], "feature_select": 42, "feature_typ": 40, "features_lag": 48, "features_nonzero": 48, "features_poli": 48, "feb": [1, 16, 18], "februari": [26, 48], "feder": [38, 41, 46, 48], "feed": [27, 28], "feedback": [20, 31, 54], "feel": [5, 6, 14, 21, 28, 32, 43, 51, 54], "feli": [12, 19, 30, 47], "fell": [18, 36], "felt": 28, "femal": [38, 40, 41, 49], "female_cm": 38, "female_pr": 38, "fenc": [39, 41, 47, 50], "fernandez": 40, "fetch_california_h": [18, 36], "few": [1, 8, 12, 18, 19, 28, 29, 30, 36, 39, 40, 42, 45, 46, 47, 48, 49, 51, 55], "fewer": [10, 40, 42, 44], "feynman": 50, "fiber": 49, "fiction": 52, "field": [2, 4, 11, 12, 17, 19, 24, 30, 35, 46, 47, 48, 51], "fig": [14, 15, 18, 21, 22, 27, 32, 33, 36, 38, 42, 43, 44, 47, 56], "figsiz": [13, 14, 15, 16, 18, 20, 21, 22, 23, 27, 28, 31, 32, 33, 34, 36, 38, 41, 42, 43, 44, 47, 48, 49, 50, 56], "figur": [4, 8, 10, 12, 13, 15, 19, 20, 22, 27, 30, 31, 33, 37, 39, 41, 42, 43, 44, 47, 48, 49, 50, 56], "file": [0, 1, 4, 5, 7, 8, 10, 12, 13, 17, 19, 24, 28, 31, 35, 38, 41, 47, 49, 51], "file_nam": 27, "filenam": 47, "fill": [15, 18, 22, 26, 27, 28, 33, 36, 37, 45, 51, 56, 58], "fill_diagon": [15, 22, 33], "fill_valu": [28, 38, 39, 40, 41, 48, 50], "film": [46, 52], "filter": [4, 11, 12, 14, 19, 21, 30, 32, 43, 48, 54], "filterwarn": [15, 19, 21, 22, 33, 49], "final": [1, 6, 7, 12, 14, 16, 19, 21, 23, 26, 32, 34, 40, 42, 50, 51, 55, 57], "final_estim": 40, "final_estimator_": 40, "finalis": 29, "financ": [47, 48], "find": [1, 7, 8, 12, 13, 16, 19, 20, 23, 27, 28, 29, 30, 31, 34, 37, 39, 40, 41, 43, 44, 45, 46, 50, 52, 53, 58], "fine": [7, 16, 17, 23, 24, 34, 35, 38, 45, 47, 48, 51], "finish": [12, 19, 30, 39], "fira": [0, 1], "firasm": 38, "firefox": [12, 19], "fireplac": [39, 41, 50], "fireplacequ": [39, 41, 50], "first": [1, 4, 8, 13, 15, 17, 18, 20, 22, 24, 28, 29, 31, 33, 35, 36, 37, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 58], "first_dai": 48, "first_day_retail": 48, "first_pass_isfinit": 28, "firth": 46, "fish": [38, 41], "fist": 48, "fit": [0, 12, 14, 15, 17, 18, 19, 21, 22, 24, 26, 27, 28, 29, 30, 32, 33, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58], "fit_intercept": 38, "fit_method": 28, "fit_predict": 44, "fit_resampl": 38, "fit_tim": [14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 48, 49, 52], "fit_transform": [16, 17, 23, 24, 28, 29, 34, 35, 38, 40, 41, 42, 44, 45, 46, 48, 54], "fittedcolumntransform": [17, 24, 35, 40], "fittedpipelin": [35, 37, 39], "fittedvotingclassifi": 40, "fitter": 49, "five": 37, "fix": [16, 17, 23, 24, 28, 34, 35, 40, 49, 51, 53, 56, 58], "flag": 49, "flagstaff": 52, "flaki": 38, "flashcard": 54, "flask": 51, "flat": 44, "flatten": [27, 29, 40, 41, 44, 48], "flatten_train": 47, "flatten_transform": 47, "flatten_valid": 47, "flaw": [14, 16, 21, 23, 32, 34], "flawless": [18, 29, 36], "flexibl": [7, 12, 30, 42, 47, 54, 58], "flibbertigibbet": 46, "flickr_cat_000002": 47, "flight": 42, "flip": [1, 14, 32, 38, 39, 51], "flip_i": 38, "float": [8, 28, 39, 42, 49, 52], "float32": [46, 47], "float64": [13, 15, 16, 17, 18, 22, 23, 24, 27, 28, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 45, 48, 49], "floatlogslid": [15, 22, 33, 56], "floatslid": [15, 22, 27, 33, 38, 43, 44, 56], "floor": [12, 13, 19, 26, 30, 31, 58], "flower": [15, 22, 27, 33, 38, 51, 56], "fmt": 37, "fn": 38, "fnlwgt": [38, 40, 41], "focu": [1, 11, 12, 16, 17, 18, 19, 23, 24, 28, 30, 34, 35, 36, 41, 44, 45, 46, 48, 54, 56, 57, 58], "focus": [12, 18, 30, 36, 43, 46, 54], "fold": [14, 16, 17, 21, 23, 24, 32, 34, 35, 37, 38, 39, 40, 51, 56], "folder": [5, 6, 23, 32, 34, 41, 51, 52], "folk": [49, 51, 58], "follow": [0, 5, 6, 7, 8, 10, 15, 16, 17, 18, 20, 22, 23, 24, 28, 29, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58], "font": [12, 13, 14, 19, 20, 21, 30, 31, 32, 43, 44, 45, 48, 49, 50], "font_scal": 41, "fontsiz": [13, 14, 15, 20, 21, 22, 26, 27, 31, 32, 33, 38, 40, 41, 43, 47, 50, 55, 56], "food": [28, 43, 46, 47, 58], "food_typ": 28, "food_type_canadian": 28, "food_type_chines": 28, "food_type_fus": 28, "food_type_indian": 28, "food_type_italian": 28, "food_type_mexican": 28, "food_type_nan": 28, "food_type_oth": 28, "food_type_quebecoi": 28, "food_type_thai": 28, "foot": [39, 41], "footag": [18, 36], "footstal": 47, "forc": [38, 41, 56], "force_all_finit": 28, "force_plot": 41, "force_writ": 28, "forecast": [11, 13, 20, 31, 49, 50, 54], "forest": [11, 38, 39, 47, 48, 49, 51, 54], "forev": 48, "forg": [10, 38, 39, 40, 41, 46, 49, 52], "forget": [13, 15, 16, 17, 20, 24, 31, 35, 40], "form": [1, 12, 17, 19, 22, 24, 35, 38, 42, 44, 45, 46, 49, 50, 51, 54], "formal": 58, "format": [0, 1, 13, 20, 26, 28, 31, 38, 44, 46, 48, 49], "former": 49, "formul": [4, 37], "formula": [18, 36, 39, 47, 53], "forum": [12, 19], "forward": [49, 51], "found": [1, 7, 14, 17, 21, 24, 25, 26, 28, 32, 35, 37, 39, 43, 45, 46, 52, 54, 58], "foundat": [1, 9, 11, 38, 39, 41, 50], "foundation_brktil": 39, "foundation_cblock": 39, "foundation_pconc": 39, "foundation_slab": 39, "foundation_ston": 39, "foundation_wood": 39, "fountain": 47, "four": [13, 14, 20, 31, 32, 42, 44, 51, 54], "fourth": 44, "foxhound": [12, 19, 30, 47], "foyer": 39, "fp": 38, "fpr": 38, "fpr_lr": 38, "fpr_svc": 38, "frac": [13, 18, 20, 31, 36, 38, 39, 43, 46, 47], "fractal": 42, "fraction": [17, 24, 35, 38, 45], "fragment": 56, "frame": [16, 17, 23, 24, 34, 35, 38, 39, 42, 48, 49, 50, 51], "framework": [31, 37], "fraud": [13, 20, 31, 38, 39, 43, 48], "fraudul": [13, 20, 31, 38, 50], "frederick": [1, 58], "free": [0, 5, 17, 24, 35, 39, 46, 49, 51], "freedom": [0, 52], "french": [16, 23, 34, 46], "freq": 48, "frequenc": [17, 24, 35, 46, 48, 49, 54], "frequent": [13, 16, 20, 23, 31, 34, 45, 46, 49], "fresh": [45, 46], "fri": [12, 48], "fridai": [14, 19, 58], "friend": [13, 14, 20, 31, 32, 38, 41, 44, 45, 51, 54, 58], "from": [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58], "from_block": 49, "from_estim": 38, "front": 58, "fruit": 46, "frustrat": [4, 6, 37], "full": [26, 37, 40, 47, 48, 49, 58], "full_pip": 28, "fullbath": [39, 41, 50], "fulli": 44, "fun": [38, 46, 47], "func": [8, 17, 18, 24, 35, 36, 39, 50], "function": [2, 12, 13, 14, 15, 17, 19, 20, 21, 22, 24, 27, 30, 31, 32, 33, 35, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54, 56], "functiontransform": [17, 24, 28, 35, 49], "fund": 52, "fundament": [1, 2, 9, 11, 16, 18, 23, 34, 36, 37, 39, 42, 47, 49, 58], "funni": [12, 30, 40, 52], "furnish": 0, "furnitur": 54, "further": [26, 38, 40, 42, 43, 46, 47, 49, 51, 56, 58], "furthermor": 50, "fusion": 28, "futur": [11, 14, 19, 21, 23, 32, 34, 37, 39, 49, 52, 54], "futurewarn": [23, 32, 34, 39, 41, 52, 53], "fuyi": [12, 13, 14, 16, 17, 18, 58], "fyi": 49, "g": [6, 7, 8, 11, 12, 13, 16, 17, 18, 19, 20, 23, 24, 26, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54], "g26r0dcx4b35vf3nk31216hc0000gr": [34, 41, 52], "gain": [6, 11, 13, 20, 31, 38, 40, 41], "game": [13, 20, 31, 41, 46], "gamma": [18, 27, 36, 37, 40, 50, 56], "gamma_log": [15, 22, 27, 33, 56], "gamma_widget": [15, 22, 27, 33, 56], "gap": [14, 21, 26, 32, 48, 49, 50, 54, 56], "garagearea": [39, 41, 50], "garagecar": [39, 41, 50], "garagecond": [39, 41, 50], "garagefinish": [39, 41, 50], "garagefinish_fin": 39, "garagefinish_miss": 39, "garagefinish_rfn": 39, "garagefinish_unf": 39, "garagequ": [39, 41, 50], "garagetyp": [39, 41, 50], "garagetype_2typ": 39, "garagetype_attchd": 39, "garagetype_bas": 39, "garagetype_builtin": 39, "garagetype_carport": 39, "garagetype_detchd": 39, "garagetype_miss": 39, "garageyrblt": [39, 41, 50], "garlic": 43, "gaurav": [1, 58], "gauss": 46, "gaussian": 44, "gaussianmixtur": 44, "gave": [28, 45, 48], "gbr": 8, "gca": [43, 44, 49], "gd": [12, 19, 30, 39, 41, 50], "gdprv": [39, 41, 50], "gdwo": [39, 41, 50], "gelbart": [0, 1, 20, 31, 46], "gender": [12, 17, 19, 30, 35, 38, 46, 48, 49], "gender_femal": 49, "gender_mal": 49, "gener": [7, 9, 12, 13, 16, 17, 20, 23, 24, 26, 28, 31, 34, 35, 37, 38, 39, 41, 44, 46, 47, 48, 49, 50, 51, 53, 54, 56, 58], "genet": 42, "genom": 42, "genr": 45, "gensim": 46, "gentl": 11, "geog": [1, 58], "geograph": [18, 36, 51], "geometr": [13, 31], "georg": 46, "geq": [18, 36], "ger": 8, "german": 46, "get": [1, 4, 5, 6, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58], "get_avg_word_length": 52, "get_cmap": [16, 23, 34], "get_depth": [26, 56], "get_dummi": [16, 23, 34], "get_featur": [27, 47], "get_feature_names_out": [16, 17, 23, 24, 28, 29, 34, 35, 38, 39, 40, 41, 42, 46, 48, 49, 50, 52], "get_length_in_word": 52, "get_lr_data_per_us": 45, "get_param": 27, "get_permutation_import": 41, "get_relative_length": 52, "get_season": 48, "get_senti": 52, "get_stat": 45, "get_tag": 28, "get_user_profil": 45, "getattr": 49, "ghassemi": [1, 58], "gif": [43, 44], "gift": 52, "gigaword": 46, "gini": [13, 20, 31, 41, 50], "git": [3, 8, 12, 19], "github": [0, 1, 7, 9, 10, 12, 16, 17, 19, 23, 24, 25, 26, 27, 28, 30, 34, 35, 37, 38, 39, 40, 41, 42, 47, 50, 51, 52], "githubusercont": 8, "gitlf": 38, "giulia": [0, 1, 58], "give": [0, 12, 13, 14, 17, 18, 19, 20, 21, 23, 24, 26, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 55, 56], "given": [0, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56], "gladwel": 43, "glass": 50, "glob": [12, 19, 27, 30, 47], "global": [16, 23, 34, 38, 40, 43, 46, 54], "global_skip_valid": 28, "glove": [11, 46], "glq": [39, 41, 50], "gmail": [12, 19, 30, 43], "go": [1, 5, 7, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56], "goal": [2, 11, 15, 16, 22, 23, 33, 34, 37, 38, 43, 44, 45, 46, 51, 52], "goe": [2, 12, 14, 15, 17, 19, 21, 22, 24, 32, 33, 35, 38, 40, 41, 44, 45, 47, 50, 51], "gold": 8, "goldcoast": 48, "golden": [15, 26, 29, 33, 51, 54, 56], "good": [9, 10, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 26, 28, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57], "good_serv": 28, "goodarzvand": [1, 58], "googl": [1, 4, 12, 13, 19, 20, 30, 31, 40, 41, 42, 43, 46, 50, 52], "google_news_vector": 46, "got": [15, 18, 22, 29, 33, 36, 37, 38, 39, 47], "gotten": 49, "gov": [38, 40, 41], "govern": [46, 58], "gpe": 46, "gpt": [45, 46], "gpu": [40, 46, 47], "grad": [38, 40, 41], "grade": [1, 3, 7, 12, 14, 16, 17, 21, 24, 26, 30, 32, 35, 37, 50, 54, 56, 57], "grader": 6, "grades_df": 54, "gradescop": [1, 6, 12, 13, 19, 58], "gradient": [51, 54], "gradientboostingclassifi": 40, "gradientboostingregressor": [40, 50], "gradientexplain": 41, "grading_concern": 6, "graduat": 47, "grai": 47, "grain": [18, 36, 41], "gram": 46, "grammat": 46, "grandma": 42, "grandmoth": [38, 51], "grant": 0, "grant_macewan": 46, "granular": 44, "graph": [1, 27, 47, 48], "graphic": 47, "graphic_design": 46, "graphviz": [13, 20, 31, 55], "grasp": [11, 54], "grayscal": 47, "great": [12, 15, 17, 18, 19, 21, 22, 24, 28, 30, 31, 33, 35, 36, 41, 42, 46, 47, 48, 50, 52], "greater": [10, 42, 43], "greater_is_bett": 39, "greedili": 44, "green": [15, 22, 33, 37, 43, 50, 53], "grei": 58, "grid": [18, 36, 39, 48, 49, 54], "grid_result": 50, "grid_search": [37, 50], "gridsearchcv": [15, 22, 33, 40, 41], "gridsearchcvifittedgridsearchcv": 37, "grinberg": 51, "grip": 46, "grlivarea": [39, 41, 50], "groak": 46, "groceri": [47, 52], "groin": 47, "ground": [14, 21, 32, 42, 44, 45, 58], "ground_truth_categori": [38, 51], "group": [7, 11, 13, 15, 16, 17, 18, 20, 22, 27, 31, 33, 35, 36, 40, 42, 54, 56, 57], "groupbi": 48, "grow": [37, 40, 42], "grow_polici": 40, "growth": [48, 49], "groyn": 47, "grv": 39, "gsc": 50, "gt": [17, 18, 24, 35, 36, 37, 38, 39, 40], "gtl": 41, "gtoti": [20, 24], "guarante": [37, 38, 40, 43, 47], "guenon": 47, "guess": [15, 16, 22, 23, 33, 34, 46, 52], "guid": [1, 7, 9, 12, 19, 42, 47, 51, 58], "guidanc": 41, "guidelin": [16, 41, 42, 51], "guido": 1, "h": [26, 38, 40, 41, 43, 46, 47, 49, 51, 52], "ha": [1, 2, 5, 6, 13, 14, 16, 17, 18, 20, 21, 23, 24, 29, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 56, 58], "hab": 46, "habit": [17, 24, 35, 50, 51], "hacki": [47, 53], "had": [12, 16, 17, 18, 19, 23, 24, 30, 34, 35, 36, 38, 45, 46, 47, 48, 49, 51], "hadn": [46, 49], "haidilao": 28, "hal": 1, "half": [1, 6, 12, 13, 18, 19, 20, 31, 36, 42, 44], "halfbath": [39, 41, 50], "halvingrandomsearchcv": 37, "halvingrandomsearchcvifittedhalvingrandomsearchcv": 37, "ham": [12, 19, 30], "hand": [4, 9, 11, 28, 38, 45, 58], "handi": 38, "handl": [11, 26, 28, 40, 41, 44, 49, 51, 53, 54, 56], "handle_unknow": [17, 24, 35], "handle_unknown": [16, 17, 23, 24, 28, 34, 35, 37, 38, 39, 40, 41, 48, 49, 50, 54], "handler": [38, 41], "handrail": 47, "handwritten": [38, 50], "hang": 38, "happen": [4, 6, 12, 15, 17, 22, 24, 28, 30, 33, 35, 37, 40, 41, 42, 45, 48, 49, 50, 54, 58], "happi": [26, 28, 38, 43, 49], "happier": [51, 58], "happydb": [38, 51], "hard": [8, 12, 14, 15, 16, 18, 19, 21, 22, 23, 30, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 50, 51, 52, 54], "hardi": [1, 58], "hardli": 45, "hardwar": 47, "harmon": 38, "harri": [1, 46, 58], "has_emoji": 52, "has_nan_error": 28, "hasn": [4, 45, 46, 49], "hassl": [8, 41, 48], "hat": [18, 36, 39, 40], "have": [0, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58], "haven": [14, 21, 28, 32, 46, 49, 50, 51, 54], "haylei": [20, 31], "hazard": 11, "hc_truncation_toy_demo": 44, "hdbscan": 44, "he": [14, 17, 21, 24, 32, 35, 46], "head": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 54, 57], "header": 51, "headlin": [46, 50], "health": 46, "healthcar": 41, "healthi": [46, 50], "heard": [14, 21, 32], "heart": [13, 20, 31, 52], "hearti": 28, "heat": [37, 39, 41, 50], "heating_floor": 39, "heating_gasa": 39, "heating_gasw": 39, "heating_grav": 39, "heating_othw": [39, 41], "heating_wal": 39, "heatingqc": [39, 41, 50], "heatmap": 41, "heavi": [40, 52], "heavili": [45, 47, 48], "heeren": 46, "hei": 29, "height": [13, 14, 20, 21, 27, 31, 32, 38, 46, 52, 55], "hell": 52, "help": [3, 7, 10, 12, 14, 16, 19, 21, 23, 28, 30, 32, 34, 35, 37, 38, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52, 55, 56, 57, 58], "henc": [5, 38, 39, 41, 43], "her": [12, 19, 30, 45, 46], "here": [1, 4, 5, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58], "herebi": 0, "herself": [46, 52], "herta": [15, 33], "hesist": 50, "hesit": 50, "heurist": [13, 20, 31, 37], "hi": [46, 56], "hidden": [42, 46, 47, 50], "hide": [8, 47], "hier_label": 44, "hier_labels1": 44, "hier_labels2": 44, "hierarch": [11, 54], "hierarchi": [13, 20, 31, 44], "high": [6, 11, 14, 15, 18, 20, 21, 22, 28, 32, 33, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51], "high_corr": 41, "higher": [13, 14, 15, 18, 20, 21, 22, 31, 32, 33, 36, 38, 39, 40, 41, 42, 43, 45, 49, 50, 51, 56], "highest": [29, 40, 41, 45, 46, 47, 50, 53, 56], "highland": 52, "highli": [1, 10, 16, 23, 29, 34, 41, 45], "highlight": [4, 47, 50, 54], "highwai": [18, 36], "him": 46, "himself": 46, "hinder": 58, "hindi": [16, 23, 34], "hint": [41, 56], "hist": [16, 23, 28, 34, 37, 39, 42, 49], "histgradientboostingclassifi": [28, 40], "histgradientboostingregressor": 40, "histogram": 49, "histor": 54, "histori": [18, 36, 45, 48, 58], "hit": [12, 19, 30, 37], "hitter": 52, "hl": [39, 41, 50], "hmid": [38, 51], "hmmm": 49, "hockei": 46, "hold": [28, 50, 51], "holder": 0, "holdout": 38, "holi": 50, "holidai": [45, 58], "home": [13, 18, 20, 27, 28, 31, 36, 38, 47, 51], "homemak": 46, "homepag": 1, "homework": [1, 3, 4, 6, 8, 10, 15, 33, 36, 37, 46, 51, 54, 58], "honest": 50, "honour": 58, "hood": [14, 21, 28, 32, 51], "hope": [14, 21, 32, 50, 51], "hopefulli": 51, "hopeless": 42, "hopelessli": [15, 22, 33], "horizont": [13, 17, 20, 24, 28, 31, 35], "host": [5, 49, 51], "hot": [14, 17, 21, 24, 28, 32, 35, 41, 54], "hound": [12, 19, 30, 47], "hour": [1, 4, 10, 12, 38, 40, 41, 42, 45, 48, 51, 54, 58], "hourli": [49, 54], "hous": [20, 26, 39, 41, 42, 49, 50, 56], "houseag": [18, 36], "household": [16, 18, 23, 34, 35, 36, 42, 57], "housestyl": [39, 41, 50], "housestyle_1": 39, "housestyle_1stori": 39, "housestyle_2": 39, "housestyle_2stori": 39, "housestyle_sfoy": 39, "housestyle_slvl": 39, "housewif": 46, "housing_df": [13, 16, 23, 26, 31, 34, 35, 42, 56, 57], "housing_median_ag": [16, 23, 34, 35, 42, 57], "houston": 52, "how": [0, 3, 8, 10, 11, 12, 17, 19, 24, 26, 27, 30, 35, 37, 38, 39, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58], "howard": 43, "howev": [2, 8, 16, 17, 23, 24, 27, 34, 35, 38, 39, 41, 43, 45, 48, 49, 51, 53, 56], "hsjcy": 49, "hstack": 48, "html": [7, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 47, 49, 50, 51, 52, 55, 57], "htrz": 58, "http": [0, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 47, 48, 49, 50, 51, 52, 58], "hug": 45, "huge": [17, 24, 35, 39, 46, 47, 48, 49], "human": [0, 12, 15, 16, 17, 18, 19, 23, 24, 30, 33, 34, 35, 36, 37, 38, 41, 42, 43, 46, 47], "humidity3pm": 48, "humidity3pm_lag1": 48, "humidity9am": 48, "hummu": [43, 46], "humour": [1, 46], "hundr": [18, 36], "hungri": 28, "hurrican": [12, 30], "husband": [38, 40, 41], "hussar": [12, 19, 30, 47], "hw": [12, 16, 30], "hw1": [1, 4, 13, 14, 16, 17, 55], "hw2": [1, 14, 15, 16, 23, 33, 34], "hw3": [1, 16, 17, 18], "hw4": 1, "hw5": 1, "hw6": 1, "hw6a": 7, "hw6b": 7, "hw7": 1, "hw8": 1, "hw9": 1, "hybrid": 45, "hyper": 50, "hyperband": 37, "hyperopt": 37, "hyperparamet": [1, 14, 21, 27, 29, 32, 38, 44, 45, 46, 47, 50, 51], "hyperparameter_": 50, "hyperparamt": [14, 21, 32, 37, 49], "hyperparlan": [18, 36], "hyperplan": [18, 36], "hypothesi": [46, 49, 51], "hypothet": [18, 36, 43], "i": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 18, 20, 22, 26, 27, 28, 29, 31, 33, 36, 39, 44, 47, 48, 49, 53, 54, 55, 56, 57, 58], "i1": 40, "i2": 40, "ia": 52, "ibm": 52, "ic": 46, "icc": [1, 58], "iclick": 1, "id": [12, 13, 19, 26, 30, 31, 39, 41, 45, 50, 56], "idea": [8, 13, 14, 16, 20, 21, 23, 26, 27, 28, 31, 32, 34, 37, 41, 43, 44, 45, 46, 47, 48, 49, 51, 54, 56], "ideal": [4, 16, 28, 38, 40, 42, 45, 49, 51], "ident": [27, 46, 47], "identif": [12, 19, 30, 52], "identifi": [11, 13, 14, 15, 16, 20, 21, 23, 26, 29, 31, 32, 33, 34, 37, 38, 39, 43, 44, 46, 47, 48, 50, 51, 54], "idf": [17, 24, 35], "idli": 46, "idx": [27, 47], "idxmax": [15, 22, 26, 29, 33], "if_binari": [17, 24, 28, 35, 38, 40, 41, 54, 57], "ifram": [14, 21, 32, 38], "igloo": 46, "ignor": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 46, 48, 49, 50, 54], "ignore_index": 8, "ii": 38, "iii": 1, "ij": [18, 29, 36, 45], "ik": 40, "ill": 58, "illus": 38, "illustr": [44, 48], "iloc": [8, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 29, 31, 32, 33, 34, 35, 40, 41, 46, 48, 52, 55], "im": 52, "imag": [7, 11, 14, 21, 23, 32, 38, 41, 42, 43, 44, 48, 50, 54], "image_dataset": [27, 47], "image_datasets_bw": 47, "image_fil": 27, "image_s": [27, 47], "imagefold": [27, 47], "imagenet": 53, "imagenet1k_v1": [27, 47], "imagenet_class": [12, 19, 30, 47], "imagin": [12, 13, 14, 16, 18, 19, 20, 21, 23, 30, 31, 32, 34, 36, 38, 41, 42, 43, 46, 49, 50, 51, 54, 55], "imaginari": [14, 21, 32, 46], "imbal": [43, 49], "imbalanc": [38, 39, 53], "imblearn": 38, "imdb": 29, "imdb_df": 29, "imdb_mast": 29, "img": [12, 19, 27, 30, 47], "img_classifi": [12, 19, 30], "img_ind": 27, "img_path": [12, 19, 30], "img_t": 47, "immedi": [28, 41, 45, 58], "imp": [16, 23, 34, 35, 48], "impact": [7, 11, 17, 18, 24, 35, 36, 40, 41, 44, 48, 50, 56, 58], "implement": [2, 4, 12, 16, 19, 23, 30, 34, 38, 39, 40, 42, 44, 45, 46, 49, 50, 51, 53], "impli": [0, 49], "implic": [11, 16, 23, 34, 51, 54], "implicit": 46, "import": [8, 11, 53, 57, 58], "importance_typ": 40, "importances_mean": 41, "impos": [16, 23, 34], "imposs": 43, "impress": 41, "improv": [11, 26, 28, 37, 38, 39, 40, 42, 43, 44, 45, 48, 49, 50, 51, 54, 58], "impur": [13, 20, 26, 31, 40], "imput": [14, 17, 18, 21, 24, 28, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 48, 49, 50, 51, 54, 57], "imread": 47, "imshow": [12, 19, 27, 30, 47], "inabl": 19, "inbox": [14, 21, 32], "inc": [41, 46], "incept": [45, 47], "inception": 47, "incl": 39, "includ": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 19, 20, 23, 24, 27, 31, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 56, 57, 58], "include_bia": [42, 48], "incom": [14, 18, 21, 32, 36, 38, 40, 41], "incomplet": 49, "inconsist": [17, 24, 35], "incorpor": [37, 39, 42, 49, 51, 54], "incorrect": [49, 50], "incorrectli": [12, 19, 30, 38], "increament": 51, "increas": [8, 14, 15, 17, 18, 21, 22, 24, 26, 29, 32, 33, 35, 36, 40, 41, 42, 43, 44, 47, 56], "increasingli": [12, 19, 30], "incred": 47, "increment": 51, "inde": 41, "independ": [8, 9, 13, 19, 20, 31, 37, 39, 40, 42, 48, 58], "index": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 56], "index_col": [8, 15, 16, 23, 33, 34, 37, 38, 45, 51], "india": 46, "indian": [28, 38], "indian_liver_pati": [12, 19, 30], "indic": [0, 17, 24, 28, 29, 35, 43, 45, 46, 47, 48, 49], "indirectli": 50, "individu": [28, 40, 41, 43, 45, 46, 49, 51, 58], "industri": [40, 42, 46, 47], "inequ": 38, "inertia_": 43, "inertia_valu": 43, "inf": [15, 22, 33, 49], "infeas": 37, "infer": [13, 31, 46, 47, 48, 51, 55], "infin": [15, 22, 33, 50], "infinit": 37, "inflamm": 9, "inflat": 41, "inflect": [43, 46], "influenc": [13, 14, 20, 21, 31, 32, 37, 41, 43, 45, 49, 56], "info": [1, 3, 8, 16, 17, 23, 24, 34, 35, 38, 39, 42, 46, 48, 49, 56], "infom": 46, "infor_m": 46, "inform": [1, 4, 7, 10, 12, 13, 16, 17, 18, 20, 23, 24, 27, 31, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 56, 58], "informa_t": 46, "informaion": 46, "informaiton": 46, "informationabout": 46, "informationon": 46, "inhabit": 58, "inher": [20, 38, 48, 49], "initi": [27, 44, 47], "initj": 41, "inject": [42, 45, 54], "ink": 50, "inland": [16, 23, 34, 35, 42, 57], "inlin": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 55, 56], "inner": [17, 24, 35, 37, 46], "inplac": [8, 12, 13, 19, 30, 31, 37], "input": [8, 13, 16, 18, 20, 23, 27, 28, 31, 34, 36, 40, 41, 44, 46, 47, 48, 51, 52, 54], "input_img": 47, "input_nam": 28, "input_tag": 28, "inputs_bw": 47, "insid": [9, 17, 24, 35, 38], "insight": [2, 11, 15, 22, 33, 38, 41, 43], "inspct": 38, "inspect": [41, 44], "inspir": [13, 31, 38, 40], "instal": [12, 15, 19, 27, 28, 30, 33, 38, 39, 40, 41, 43, 46, 47, 49, 51, 52], "instanc": [12, 13, 14, 17, 18, 19, 20, 21, 24, 27, 28, 30, 31, 32, 35, 36, 38, 43, 44, 45, 46, 47, 48, 53], "instanti": [26, 37, 56], "instead": [5, 8, 10, 13, 14, 16, 17, 18, 20, 23, 24, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 50, 53, 56], "institut": [46, 52], "instruct": [3, 4, 5, 10, 12, 15, 16, 19, 33, 50, 51, 58], "instructor": [4, 6, 12, 19, 30, 50, 51, 58], "instrument": [15, 16, 23, 33, 34, 37], "int": [16, 17, 23, 24, 34, 35, 38, 40, 41, 46, 48, 52], "int32": [15, 22, 33, 43, 44, 48], "int64": [13, 15, 16, 17, 20, 24, 26, 28, 31, 33, 35, 38, 39, 45, 46, 48, 49, 51, 52], "integ": [8, 16, 23, 32, 34, 37, 40, 41, 48, 52], "integr": [11, 51], "intellig": [1, 46], "intelligen": 46, "intend": [0, 50, 58], "intens": 46, "inter": 52, "interact": [9, 12, 15, 19, 22, 27, 33, 37, 38, 41, 43, 44, 45, 48, 51, 52, 56], "interaction_constraint": 40, "interaction_onli": [42, 48], "interactive_plot": [15, 22, 27, 33, 56], "intercept": [41, 47, 53], "intercept_": [18, 36, 40, 47, 53], "intercept_sc": 38, "interest": [2, 12, 14, 19, 21, 28, 30, 32, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 56], "interfac": [40, 51], "intermedi": [44, 47], "intern": [0, 1, 13, 20, 31, 47, 48, 49], "internet": [49, 50, 51], "internetservic": 49, "internetservice_dsl": 49, "internetservice_fib": 49, "internetservice_no": 49, "internship": [12, 19, 30], "interpret": [1, 10, 11, 15, 16, 22, 23, 26, 33, 34, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 50], "interv": [11, 48, 49, 54], "interweb": 51, "intrins": 48, "intro": [1, 46, 47], "introduc": [17, 24, 35, 38, 49], "introduct": [1, 9, 10, 11, 26, 48, 49, 56], "intslid": [15, 22, 27, 33, 56], "intuit": [11, 15, 16, 17, 22, 23, 24, 33, 34, 35, 37, 39, 41, 43, 44, 49, 52], "invalid": 37, "inventori": 54, "invers": [18, 36, 39], "inverse_func": [39, 50], "investig": [15, 22, 27, 33, 41, 56], "involv": [2, 4, 37, 39, 40, 44, 46, 47], "io": [9, 16, 23, 25, 34, 47, 49, 52], "ipykernel_13054": 52, "ipykernel_19402": 41, "ipykernel_22611": 28, "ipykernel_32469": 34, "ipykernel_70329": 23, "ipykernel_79734": 32, "ipynb": [7, 8, 12, 19], "ipython": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 38, 46, 55, 57], "ipywidget": [15, 22, 33, 56], "ir1": [39, 41, 50], "ir2": [39, 41, 50], "iri": [15, 22, 27, 33, 56], "iris_df": [15, 22, 27, 33, 56], "irregular": 11, "irregularli": 54, "irrelev": [15, 22, 33, 42, 46], "irrelevant_po": 46, "irrespect": [14, 18, 21, 32, 36, 58], "is_avail": [27, 47], "is_classifi": 28, "is_leap_year": 48, "is_stop": 46, "is_year_end": 48, "isinst": [28, 49], "island": [16, 23, 34, 35], "isn": [14, 15, 22, 32, 33, 38, 39, 40, 46, 50], "isnul": [16, 23, 28, 34], "iso": 29, "isol": [10, 38, 39, 41, 50], "issu": [4, 6, 7, 12, 19, 26, 40, 45, 49, 54, 58], "issubclass": 49, "isupp": 52, "itali": 46, "italian": 28, "item": [12, 19, 27, 30, 40, 41, 43, 45, 46, 47, 49, 54], "item_inverse_mapp": 45, "item_kei": 45, "item_mapp": 45, "iter": [27, 37, 42, 43, 44, 47, 51], "iterable_with_config": [17, 24, 35], "iterrow": 45, "its": [8, 11, 12, 14, 15, 17, 18, 19, 22, 23, 24, 27, 28, 30, 32, 33, 35, 36, 38, 41, 43, 44, 46, 47, 48, 49, 52, 53, 56, 58], "itself": [7, 38, 40, 44, 46], "j": [8, 18, 36, 41, 42, 43, 45, 47], "jackin": 37, "jackpot": [17, 24, 35], "jaguar": [12, 19, 30, 47], "jalebi": 46, "jam": 37, "jame": [46, 49, 52], "jan": [1, 12, 13, 16], "januari": [12, 19, 48], "japan": 46, "jargon": [13, 20, 31], "jason": [1, 42], "javascript": 41, "jazz_musician": 46, "jellyfish": 47, "jennif": 52, "jerri": 45, "jet": [16, 23, 34], "jetti": 47, "jieba": 46, "jim": 45, "jmlr": 37, "joan_baez": 46, "job": [17, 24, 35, 48, 49], "joblib": [17, 24, 35, 51], "joei": 28, "john": 40, "johnny_cash": 46, "join": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 58], "jointli": 48, "joke": [12, 19, 30, 45], "jolen": 52, "joni_mitchel": 46, "journal": 46, "journei": [1, 44, 58], "jpg": [27, 47], "json": 51, "ju": [12, 19, 30], "jubatu": [12, 19, 30, 47], "judg": 42, "judgment": 50, "juic": 46, "juli": 48, "june": 48, "jupyt": [1, 7, 8, 9, 10, 16, 17, 23, 24, 26, 27, 28, 30, 34, 35, 37, 38, 39, 40, 41, 42, 47, 50, 51, 52], "jupyter_notebook": 49, "jupyterlab": 41, "jurafski": 46, "jurisdict": 46, "just": [4, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 54, 56, 58], "justic": [41, 46], "k": [1, 7, 11, 14, 18, 21, 27, 28, 29, 32, 36, 38, 39, 40, 42, 46, 47, 49, 51, 52, 53, 56], "k_neighbor": 38, "k_valu": [15, 22, 33], "kaggl": [13, 16, 23, 27, 31, 34, 38, 39, 40, 41, 42, 47, 50], "kaggler": 42, "kangaroo": 47, "kaplan": 11, "kaplanmeierfitt": 49, "kazmi": [1, 58], "kb": [17, 24, 35, 39, 49], "kbinsdiscret": 42, "kbinsdiscretizer__latitude_0": 42, "kbinsdiscretizer__latitude_1": 42, "kbinsdiscretizer__latitude_2": 42, "kbinsdiscretizer__latitude_3": 42, "kbinsdiscretizer__latitude_4": 42, "kbinsdiscretizer__latitude_5": 42, "kbinsdiscretizer__latitude_6": 42, "kbinsdiscretizer__latitude_7": 42, "kbinsdiscretizer__latitude_8": 42, "kbinsdiscretizer__latitude_9": 42, "kbinsdiscretizer__longitude_11": 42, "kbinsdiscretizer__longitude_12": 42, "kbinsdiscretizer__longitude_13": 42, "kbinsdiscretizer__longitude_14": 42, "kbinsdiscretizer__longitude_15": 42, "kbinsdiscretizer__longitude_16": 42, "kbinsdiscretizer__longitude_17": 42, "kbinsdiscretizer__longitude_18": 42, "kbinsdiscretizer__longitude_19": 42, "kbinsdiscretizerkbinsdiscret": 42, "kc_house_data": [12, 13, 19, 26, 30, 31, 56], "kdtree": 28, "keep": [1, 14, 15, 16, 17, 21, 22, 23, 24, 26, 32, 33, 34, 35, 38, 40, 41, 42, 43, 45, 46, 49, 51, 56, 57, 58], "keep_empty_featur": 45, "kei": [9, 11, 13, 15, 16, 20, 22, 23, 31, 32, 33, 34, 37, 38, 39, 40, 45, 46, 49, 52], "kelbowvisu": 43, "kellei": [18, 36], "kept": [14, 21, 32], "kera": 41, "kernel": [1, 7, 16, 18, 23, 27, 34, 36, 37, 41, 42, 50, 56], "kernelexplain": 41, "keyword": [4, 37, 52], "kfold": 38, "kick": 46, "kiddi": 29, "kilian": 41, "kill": 49, "kimia": [1, 58], "kind": [0, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 30, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 45, 47, 48, 49, 51, 53], "king": [26, 45, 46, 56], "kitchenabvgr": [39, 41, 50], "kitchenqu": [39, 41, 50], "kiwi": 46, "kk": 43, "km": [49, 50, 54], "km_label": 43, "kmean": [43, 44, 54], "kmf": 49, "kmqfw": 49, "kneighbor": 27, "kneighborregressor": [16, 23, 34], "kneighborsclassifi": [16, 17, 18, 23, 24, 28, 34, 35, 36, 42, 56, 57], "kneighborsclassifierifittedkneighborsclassifi": 28, "kneighborsregressor": [16, 17, 18, 23, 24, 34, 35, 36, 57], "kneighborsregressorkneighborsregressor": [16, 23, 34, 35], "knew": 43, "knn": [2, 14, 15, 16, 18, 21, 22, 23, 32, 33, 34, 35, 36, 41, 42, 45, 47, 51, 53, 54], "knn1": [15, 22, 33], "knn100": [15, 22, 33], "knn_pipe": 35, "knn_scale": [16, 23, 34], "knn_unscal": [16, 23, 34], "knn_valid_accuraci": [15, 22, 33], "knnimput": 45, "knob": [13, 20, 31, 50], "know": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58], "knowledg": [8, 12, 13, 17, 19, 20, 24, 31, 35, 37, 42, 43, 46, 50, 54], "knowleg": 54, "known": [27, 45, 46, 49], "koala": 47, "kolhatkar": [0, 1, 20, 46], "kr9rkqfj4w78h49djkz8yy9r0000gp": 32, "ksatr": 49, "kvarada": [10, 31, 32, 35, 37, 41, 46, 47, 49, 52, 53], "kvarada01": 10, "kwantlen": 46, "kwarg": [14, 16, 17, 21, 23, 24, 28, 32, 34, 35, 49, 52], "l": 10, "l1": 49, "l123": 4, "l17": 4, "l1_ratio": 38, "l2": [38, 46, 49], "l9": 4, "la": 50, "lab": [10, 12, 13, 14, 19, 21, 31, 32, 43, 45], "lab1": [13, 14, 17, 20, 21, 24, 31, 32, 35, 54], "lab2": [13, 14, 17, 20, 21, 24, 31, 32, 35, 54], "lab3": [13, 14, 17, 20, 21, 24, 31, 32, 35, 54], "lab4": [13, 14, 17, 20, 21, 24, 31, 32, 35, 54], "label": [7, 8, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 26, 27, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 52, 57], "label_": [46, 52], "label_encod": [40, 41], "label_n_clust": 44, "labelencod": [40, 41], "labels": [38, 43], "labels_": [43, 44], "lack": [14, 21, 32, 45, 50], "lag": [49, 54], "lag_df": 48, "lakehead_univers": 46, "lakeshor": 47, "lakesid": 47, "lamb": 28, "lambda": [8, 13, 18, 20, 28, 31, 36, 44, 47, 48, 49, 52], "land": 49, "landcontour": [39, 41, 50], "landcontour_bnk": 39, "landcontour_hl": 39, "landcontour_low": 39, "landcontour_lvl": 39, "landmark": 54, "landown": 52, "landscap": [43, 46], "landslop": [39, 41, 50], "landslope_gtl": [39, 41], "landslope_mod": [39, 41], "landslope_sev": [39, 41], "langara_colleg": 46, "languag": [2, 9, 16, 17, 23, 24, 34, 35, 45, 47, 51, 52], "language_enc": [16, 23, 34], "language_english": [16, 23, 34], "language_french": [16, 23, 34], "language_hindi": [16, 23, 34], "language_mandarin": [16, 23, 34], "language_spanish": [16, 23, 34], "language_vietnames": [16, 23, 34], "laptop": [12, 19, 30, 51], "lar": [12, 19, 30], "larg": [12, 14, 15, 16, 18, 19, 21, 22, 23, 26, 29, 30, 32, 33, 34, 36, 38, 39, 43, 44, 46, 47, 51, 54, 56], "larger": [13, 14, 15, 16, 18, 21, 22, 23, 31, 32, 33, 34, 36, 37, 39, 40, 41, 43, 44, 49], "largest": 39, "larvatu": [12, 19, 30, 47], "last": [8, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 27, 28, 31, 32, 33, 34, 35, 38, 41, 45, 47, 48, 49, 50, 51, 56, 58], "last_row": 8, "lastp": 44, "lat": [12, 13, 19, 26, 30, 31], "late": [19, 38, 58], "latent": [45, 46, 47], "latentdirichletalloc": 46, "later": [10, 13, 17, 20, 24, 31, 35, 38, 47, 48, 51, 56], "latest": [17, 24, 35, 41, 49], "latex": [4, 7, 12, 19], "latin": [12, 19, 30, 38], "latitud": [14, 15, 16, 18, 21, 22, 23, 32, 33, 34, 35, 36, 42, 57], "latitude_0": 42, "latitude_1": 42, "latitude_10": 42, "latitude_11": 42, "latitude_12": 42, "latitude_13": 42, "latitude_14": 42, "latitude_15": 42, "latitude_16": 42, "latitude_17": 42, "latitude_18": 42, "latitude_19": 42, "latitude_2": 42, "latitude_3": 42, "latitude_4": 42, "latitude_5": 42, "latitude_6": 42, "latitude_7": 42, "latitude_8": 42, "latitude_9": 42, "latter": 39, "launch": [12, 19], "lauvagrand": 52, "law": [28, 46], "lawsuit": 46, "layer": [27, 47], "layout": [15, 22, 27, 33, 56], "lazi": [15, 22, 33], "lbfg": 38, "lda": 47, "ldot": 37, "lead": [1, 8, 14, 18, 21, 32, 36, 39, 44, 45, 46, 49, 50], "leaf": [13, 20, 31, 44, 46], "leagu": 46, "leak": [16, 23, 34, 49, 54], "leakag": 54, "leaner": [14, 21, 32], "learn": [2, 9, 10, 28, 52, 53, 54, 55, 56, 57, 58], "learner": [14, 15, 21, 22, 32, 33, 40], "learning_method": 46, "learning_r": 40, "learnxinyminut": 9, "least": [1, 4, 14, 15, 21, 22, 29, 32, 33, 38, 39, 41, 42, 43, 44, 50], "least_confident_i": [18, 36], "least_confident_x": [18, 36], "leav": [7, 13, 20, 31, 44, 47, 49, 50, 53], "lectur": [5, 7, 8, 10, 25, 54], "lecun": 41, "lecuy": 1, "lee": 41, "left": [7, 12, 19, 30, 37, 38, 39, 43, 44, 46, 48, 49, 50, 58], "legal": [0, 46], "legend": [7, 8, 15, 18, 22, 33, 36, 38, 39, 42, 43, 47, 48, 49, 50, 53], "legendari": 52, "leisur": [38, 51], "lemma": 46, "lemma_": 46, "lemmat": 46, "lemon": 43, "len": [12, 14, 16, 21, 23, 27, 32, 34, 37, 38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 52], "length": [13, 14, 15, 18, 20, 21, 22, 26, 27, 31, 32, 33, 36, 39, 41, 43, 44, 46, 48, 49, 52, 56], "leo": 40, "leopard": [12, 19, 30, 47], "leq": [42, 43], "less": [1, 5, 6, 12, 15, 17, 18, 19, 22, 24, 30, 33, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 49, 50, 54, 56], "lesson": [9, 16, 23, 34, 52], "lesssim": [14, 21, 32], "let": [12, 13, 14, 18, 19, 20, 21, 26, 27, 29, 30, 31, 32, 36, 37, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58], "letter": [18, 36, 52], "lev": 39, "level": [11, 15, 18, 22, 33, 36, 38, 39, 40, 41, 42, 44, 46, 47, 48, 50, 51], "leverag": [41, 45], "lewi": 52, "lexic": 46, "lexicon": 52, "lgbm": [11, 40, 41, 54], "lgbmclassifi": [12, 19, 30, 40, 41], "lgbmclassifierifittedlgbmclassifi": [12, 19, 30, 41], "lgbmclassifierlgbmclassifi": 40, "lgbmregressor": [12, 19, 30, 40], "li": [1, 18, 36, 58], "liabil": 0, "liabl": 0, "liao": [12, 19, 30], "lib": [17, 20, 24, 27, 28, 31, 32, 35, 37, 41, 49, 53], "librari": [4, 8, 10, 14, 21, 26, 28, 32, 38, 41, 42, 46, 47, 48, 50, 52, 56], "licensor": 0, "life": [13, 18, 28, 31, 36, 43, 45, 50, 51, 55, 58], "lifelin": [11, 49], "lifetim": 49, "lighter": 37, "lightgbm": [12, 19, 30, 41, 51], "lightweight": 46, "like": [1, 2, 4, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58], "likelihood": 49, "likewis": 7, "lime": 41, "limit": [0, 12, 13, 14, 17, 19, 21, 24, 30, 31, 32, 35, 40, 41, 50, 51, 52, 54, 55, 58], "linalg": 46, "line": [4, 8, 10, 12, 13, 17, 18, 19, 20, 24, 28, 31, 35, 36, 37, 38, 39, 43, 46, 47, 48, 49, 50, 56], "line2d": 8, "linear": [1, 37, 38, 40, 42, 44, 45, 47, 48, 49, 50, 51, 53, 54], "linear_model": [12, 18, 19, 29, 30, 36, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 53], "linear_svc": [18, 36], "linearli": [18, 36, 42, 48], "linearregress": [18, 36, 39, 42, 49], "linestyl": [43, 48], "linewidth": [48, 50], "linger": [15, 33], "lingual": 46, "linguist": [17, 24, 35], "link": [0, 4, 5, 7, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 35, 36, 37, 38, 39, 40, 44, 49, 50, 51, 58], "linkag": 44, "linkage_arrai": 44, "linkage_typ": 44, "linkedin": 45, "linspac": [18, 36, 37, 39, 42, 50], "lion": 45, "list": [4, 7, 8, 10, 14, 15, 16, 17, 18, 21, 23, 24, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 49, 50, 58], "listedcolormap": [18, 36], "literatur": 40, "littl": [8, 38, 47, 50, 51], "live": [1, 10, 12, 15, 16, 17, 19, 23, 24, 33, 34, 35, 37, 43, 49, 50, 51], "liver": [13, 20, 31], "livestream": 58, "ll": [1, 6, 7, 10, 12, 13, 15, 16, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 53, 54, 56, 58], "llazx": 49, "lo": 52, "load": [8, 12, 15, 16, 17, 18, 19, 22, 23, 24, 26, 27, 28, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 50, 52, 56, 57], "load_breast_canc": 42, "load_citibik": 48, "load_digit": 50, "load_iri": [15, 22, 27, 33, 56], "loan": 38, "loc": [8, 15, 18, 22, 33, 36, 38, 41, 45, 48, 49, 50], "local": [5, 7, 10, 27, 28, 38, 40, 41, 42, 47, 52], "locat": [8, 17, 24, 27, 35, 43, 45, 46, 48, 52, 58], "location_katherin": 48, "location_mountginini": 48, "location_townsvil": 48, "location_witchcliff": 48, "location_wollongong": 48, "lock": [14, 21, 32], "log": [12, 13, 15, 22, 27, 28, 33, 39, 40, 49, 50, 51, 56], "log10": 39, "log1p": [39, 50], "log2": 49, "log_likelihood_ratio_test": 49, "log_loss": 50, "logarithm": [15, 22, 27, 33, 56], "logic": 42, "logical_xor": 42, "login": 45, "logisit": 47, "logist": [29, 40, 41, 48, 49, 50, 51, 52, 53, 54], "logisticregress": [12, 18, 19, 29, 30, 36, 39, 40, 41, 42, 46, 47, 51, 52, 53], "logisticregressionifittedlogisticregress": 47, "logisticregressionlogisticregress": [38, 40, 47, 52], "logloss": 41, "lognorm": 37, "logspac": [27, 37], "loguniform": 37, "lol": [17, 24, 35], "london": 52, "lone": 44, "long": [0, 12, 13, 18, 19, 20, 26, 30, 31, 36, 38, 40, 44, 45, 49, 51, 54, 58], "longer": [7, 37, 38, 47, 49, 50, 51], "longest": [13, 20, 31], "longitud": [14, 15, 16, 18, 21, 22, 23, 32, 33, 34, 35, 36, 42, 57], "longitude_0": 42, "longitude_1": 42, "longitude_10": 42, "longitude_11": 42, "longitude_12": 42, "longitude_13": 42, "longitude_14": 42, "longitude_15": 42, "longitude_16": 42, "longitude_17": 42, "longitude_18": 42, "longitude_19": 42, "longitude_2": 42, "longitude_3": 42, "longitude_4": 42, "longitude_5": 42, "longitude_6": 42, "longitude_7": 42, "longitude_8": 42, "longitude_9": 42, "look": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56], "lookatm": [12, 19, 30], "loop": [37, 40, 48, 53, 54], "loos": [44, 51], "lose": [6, 17, 24, 35], "loss": [2, 38, 39, 40, 41, 46, 49], "lot": [5, 9, 12, 13, 15, 17, 18, 19, 20, 21, 22, 24, 28, 30, 31, 33, 35, 36, 37, 38, 39, 41, 42, 44, 47, 48, 49, 50, 51, 58], "lotarea": [39, 41, 50], "lotconfig": [39, 41, 50], "lotconfig_corn": 39, "lotconfig_culdsac": 39, "lotconfig_fr2": 39, "lotconfig_fr3": 39, "lotconfig_insid": 39, "lotfrontag": [39, 41, 50], "lotshap": [39, 41, 50], "lotshape_ir1": [39, 50], "lotshape_ir2": [39, 50], "lotshape_ir3": [39, 50], "lotshape_reg": [39, 50], "loud": [15, 16, 23, 28, 33, 34, 37, 54], "loui": 48, "lourenzutti": 37, "love": [51, 52], "low": [6, 14, 15, 21, 22, 28, 32, 33, 37, 38, 39, 41, 42, 43, 44, 49, 50, 51], "lower": [14, 15, 21, 22, 32, 33, 38, 39, 41, 43, 45, 46, 49, 50], "lowerbound_peopl": 28, "lowercas": [16, 17, 23, 24, 34, 35], "lowest": [56, 58], "lowqualfinsf": [39, 41, 50], "lr": [18, 29, 36, 38, 39, 41, 47, 48, 49, 52, 53], "lr_1": 42, "lr_2": 42, "lr_3": 42, "lr_coef": [41, 48, 49], "lr_coefs_landslop": 41, "lr_flatten_pip": 47, "lr_item": 45, "lr_pipe": [39, 41, 48], "lr_pred": [38, 39], "lr_scale": 41, "lr_schedul": 47, "lr_x": 45, "lr_y": 45, "ls15hb": [12, 19, 30], "lstm": 48, "lt": [14, 16, 17, 21, 23, 24, 32, 34, 35, 37, 38, 39, 40, 41, 42, 49], "ltorgo": [18, 36], "luck": 51, "lucki": [15, 22, 33, 37], "lundberg": 41, "luster": 44, "lvert": 46, "lvl": [39, 41, 50], "lwq": [39, 41, 50], "lynx": [12, 19, 30, 47], "l\u00e9cuyer": [46, 58], "m": [10, 12, 14, 19, 21, 26, 27, 28, 30, 32, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "m_neighbor": 38, "ma": [37, 46], "macaqu": [12, 19, 30, 47], "macbook": 10, "mach": 46, "machin": [2, 9, 10, 11, 16, 17, 23, 24, 27, 28, 34, 35, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 52, 54, 56, 58], "machine_learn": 50, "mackworth": 1, "made": [0, 6, 7, 8, 12, 13, 19, 20, 30, 31, 38, 40, 41, 45, 46, 47, 48, 50, 51], "magazin": 46, "magnitud": [23, 29, 37, 39, 41, 46, 48], "maguir": 45, "mahsa": [1, 58], "mai": [0, 1, 7, 8, 10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 51, 55, 56, 57, 58], "mail": 49, "main": [8, 10, 12, 13, 15, 17, 19, 20, 22, 24, 26, 31, 33, 35, 40, 43, 44, 54, 58], "mainland": [18, 36], "mainli": 58, "maintain": [40, 45, 50, 54], "mainten": 40, "maissan": [1, 58], "maj1": [39, 41, 50], "maj2": [39, 41, 50], "major": [2, 14, 15, 16, 17, 21, 22, 23, 24, 32, 33, 34, 35, 46, 54, 55], "major_biologi": [17, 24, 35], "major_comput": [17, 24, 35], "major_econom": [17, 24, 35], "major_linguist": [17, 24, 35], "major_mathemat": [17, 24, 35], "major_mechan": [17, 24, 35], "major_phys": [17, 24, 35], "major_psychologi": [17, 24, 35], "make": [2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58], "make_blob": [15, 22, 33, 43, 44, 47, 53], "make_circl": 44, "make_classif": [15, 22, 33, 38], "make_column_transform": [28, 37, 38, 39, 40, 41, 42, 48, 49, 50, 52, 57], "make_forg": [15, 22, 33], "make_grid": [27, 47], "make_imb_pipelin": 38, "make_moon": 44, "make_num_tree_plot": 40, "make_pipelin": [12, 17, 18, 19, 24, 28, 29, 30, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 51, 52, 57], "make_scor": [39, 42], "maker": 50, "malcolm": [43, 45], "malcom": 43, "male": [38, 40, 41, 49], "male_cm": 38, "male_pr": 38, "mall": 52, "mamba": [27, 28], "man": [45, 46], "manag": [5, 11, 48, 49, 50, 54], "mandarin": [16, 23, 34], "mango": 46, "mani": [1, 2, 5, 8, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 56, 58], "manipul": 50, "manner": [0, 40], "manual": [10, 12, 17, 19, 20, 24, 27, 30, 35, 38, 42, 43, 44, 46], "manual_se": 27, "manufactur": 47, "map": [1, 13, 14, 17, 20, 21, 24, 29, 31, 32, 35, 37, 45], "mape": [51, 54], "mape_scor": 39, "maple_leaf": 46, "mapper": 45, "mar": 1, "march": 48, "marit": [38, 40, 41], "mark": [6, 7, 19, 37, 38, 44, 58], "markdown": [12, 19], "marker": [15, 18, 22, 33, 36, 43], "markers": [18, 36, 38], "market": [12, 19, 30, 43, 47, 48, 50, 51], "markov": 46, "marri": [38, 40, 41], "martin": 46, "mask": 37, "massiv": [17, 24, 35, 37], "master": [8, 37, 38, 40, 41, 46], "masvnrarea": [39, 41, 50], "masvnrtyp": [39, 41, 50], "masvnrtype_brkcmn": 39, "masvnrtype_brkfac": 39, "masvnrtype_miss": 39, "masvnrtype_ston": 39, "match": [17, 18, 24, 35, 36, 38, 40, 41, 48], "materi": [8, 10, 12, 13, 14, 15, 19, 22, 30, 31, 32, 33, 43, 46, 49, 51, 54, 58], "matern": 42, "math": [2, 43, 45, 49], "mathcal": [15, 33], "mathemat": [2, 17, 24, 35, 40, 51, 54], "mathematician": 46, "mathia": [1, 17, 58], "matlab": 8, "matplotlib": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 54, 55, 56, 57], "matplotlibdeprecationwarn": 41, "matric": [12, 15, 19, 22, 33, 38, 45], "matrix": [17, 24, 28, 35, 44, 46, 51, 54], "matter": [16, 17, 23, 24, 34, 35, 38, 40, 44, 50, 54, 58], "max": [8, 14, 16, 18, 21, 23, 26, 28, 29, 32, 34, 36, 37, 38, 39, 40, 43, 44, 48], "max_bin": 40, "max_cat_threshold": 40, "max_cat_to_onehot": 40, "max_clust": 44, "max_colwidth": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 44, 45, 55, 56, 57], "max_delta_step": 40, "max_depth": [14, 15, 21, 22, 26, 27, 32, 33, 37, 40, 41, 50, 55, 56], "max_depth_widget": [15, 22, 27, 33, 56], "max_df": [17, 24, 35], "max_displai": 41, "max_featur": [12, 17, 19, 24, 28, 29, 30, 35, 37, 40, 50], "max_it": [12, 19, 30, 38, 40, 41, 42, 46, 47, 48, 49, 50, 51, 52, 53], "max_leaf_nod": [13, 20, 31, 50], "max_leav": 40, "max_opt": [15, 22, 33, 38, 43, 44], "max_row": 49, "max_sampl": 50, "maxabsscal": 28, "maxclust": 44, "maxent": 53, "maxim": [12, 19, 30, 38, 39, 43], "maximum": [13, 16, 20, 23, 28, 29, 31, 34, 39, 40, 43, 44, 56], "maxosx": 10, "maxtemp": 48, "may": 1, "mayb": [38, 41, 48, 50, 58], "maybe_coerce_valu": 49, "mb": [16, 23, 34, 35, 38, 42, 48, 49], "mcld": 58, "mcml": [1, 58], "md": [10, 12, 13, 31, 46], "me": [8, 12, 19, 30, 37, 46, 50, 51, 52], "mean": [5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 45, 47, 48, 49, 51, 52, 53, 54, 56, 58], "mean_absolute_error": 51, "mean_absolute_percentage_error": 39, "mean_cv_error": [14, 21, 32], "mean_cv_scor": [15, 18, 22, 27, 29, 33, 36, 37], "mean_fit_tim": [37, 39], "mean_scor": [14, 16, 21, 23, 32, 34, 37, 52], "mean_score_tim": [37, 39], "mean_squared_error": [39, 42], "mean_std_cross_val_scor": [14, 16, 21, 23, 32, 34, 35, 40, 41, 49, 52], "mean_test_neg_mean_squared_error": 39, "mean_test_scor": [37, 39], "mean_train_error": [14, 21, 32], "mean_train_neg_mean_squared_error": 39, "mean_train_scor": [15, 18, 22, 27, 29, 33, 36, 37, 39], "meaning": [11, 15, 17, 22, 24, 27, 33, 35, 38, 41, 43, 46, 57], "meaningless": 44, "measur": [0, 12, 13, 14, 15, 19, 20, 21, 22, 30, 31, 32, 33, 38, 39, 41, 43, 44, 45, 46, 48, 49, 50, 51, 54, 56], "meat": 28, "mechan": [17, 24, 35, 54], "mechanical_engin": 46, "medal": 8, "media": 50, "median": [13, 16, 18, 20, 23, 28, 31, 34, 35, 36, 39, 41, 42, 48, 49, 50], "median_house_valu": [16, 23, 34, 35, 42, 57], "median_incom": [16, 23, 34, 35, 42, 57], "mediat": 50, "medic": [38, 43, 58], "medinc": [18, 36], "medit": [38, 51], "medium": [0, 15, 22, 28, 33, 49, 54], "meet": 46, "meier": 11, "melbourneairport": 48, "member": [18, 36, 40, 58], "membership": [17, 24, 35, 43, 44], "memori": [8, 16, 17, 23, 24, 28, 34, 35, 38, 39, 40, 42, 47, 48, 49, 54], "mental": 50, "mention": [0, 4, 18, 36, 49, 50], "menu": [10, 51], "merchant": 0, "merg": [0, 5, 10, 44], "meshgrid": 42, "mess": [45, 49], "messag": [4, 6, 10, 14, 17, 21, 24, 28, 32, 35], "messi": [42, 46], "met": 58, "meta": 40, "metacademi": 1, "method": [2, 11, 13, 15, 16, 18, 20, 22, 23, 26, 27, 29, 31, 33, 34, 36, 38, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54], "methodologi": [16, 23, 34, 48], "metric": [1, 11, 15, 17, 22, 24, 28, 33, 35, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51], "mexican": 28, "mexico": 38, "mglearn": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 43, 46, 47, 48, 53, 55, 56], "mi": [12, 19, 30, 37, 38, 50], "microsoft": 52, "middl": 29, "midnight": 48, "midterm": [1, 6, 12, 18, 19], "might": [1, 6, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 54, 56, 58], "mightn": 46, "miguel": 51, "mike": [0, 1, 9, 20, 31, 51], "mikolov": 46, "milk": 46, "mill": 40, "millennia": 58, "million": 47, "min": [1, 18, 23, 26, 28, 36, 39, 44, 48], "min1": [39, 41, 50], "min2": [39, 41, 50], "min_child_weight": 40, "min_df": [17, 24, 35], "min_impurity_decreas": 50, "min_impurity_split": 50, "min_sampl": 44, "min_samples_leaf": [13, 20, 31, 50], "min_samples_split": [13, 20, 31, 50], "min_token_len": 46, "min_token_length": 46, "min_weight_fraction_leaf": 50, "mind": [14, 16, 17, 21, 23, 32, 34, 35, 40, 41, 45, 49, 50, 51, 54, 58], "mine": 1, "minibatchkmean": 44, "miniconda": 10, "miniconda3": [10, 17, 52], "miniforge3": [31, 32, 35, 37, 41, 49, 53], "minim": [5, 13, 20, 31, 39, 43, 44, 50], "minimum": [8, 14, 16, 21, 23, 32, 34, 44, 46], "minmaxscal": [16, 17, 23, 24, 28, 34, 35, 50], "minor": [6, 49], "mintemp": 48, "minut": [4, 12, 13, 19, 20, 31, 42, 49, 54], "miracl": 52, "miscalcul": 1, "miscfeatur": [39, 41, 50], "miscfeature_gar2": 39, "miscfeature_miss": 39, "miscfeature_othr": 39, "miscfeature_sh": 39, "miscfeature_tenc": 39, "misconduct": 58, "miscval": [39, 41, 50], "mishaal": [1, 58], "mislead": [14, 21, 32, 38], "miss": [10, 15, 16, 17, 18, 22, 23, 24, 26, 28, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 48, 49, 50, 54, 56, 58], "mistak": [16, 23, 34, 40, 49, 50, 56], "mit": [0, 1], "mitig": [11, 45], "mitlp": 49, "mitt": 46, "mitten": 46, "mix": [12, 19, 39, 50, 51], "mixtur": [44, 46, 47], "ml": [1, 2, 9, 11, 13, 16, 20, 23, 31, 34, 40, 44, 46, 47, 51], "ml_experi": [13, 14, 17, 20, 21, 24, 31, 32, 35, 54], "mlpclassifi": 47, "mlpregressor": 47, "mm": 48, "mmsto": [12, 19, 30], "mn": [39, 41, 50], "mnprv": [39, 41, 50], "mnww": [39, 41, 50], "mo": 46, "mobil": [17, 24, 35, 47], "mobilenet": 47, "mod": [39, 41, 50], "mode": [15, 16, 23, 33, 34, 37], "model": [1, 2, 11, 22, 37, 38, 43, 44, 45, 48, 50, 53, 55], "model_nam": 45, "model_select": [12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 47, 48, 49, 50, 51, 56, 57], "modern": [1, 15, 22, 33, 46, 50], "modif": 49, "modifi": [0, 10, 38, 49, 51, 58], "modul": [9, 14, 20, 21, 27, 28, 31, 32, 38, 52], "moe": 37, "mole": 47, "mom": 42, "moment": [38, 58], "moment_predictor": 51, "mon": 48, "monarch": 46, "monarchi": 46, "mondai": [1, 18, 48, 58], "monei": [8, 49], "monitor": 46, "monkei": [12, 19, 30, 47], "monotone_constraint": 40, "montani": 52, "month": [14, 17, 24, 32, 35, 39, 49], "month_nam": [26, 48], "monthli": 49, "monthlycharg": 49, "montreal": [46, 52], "moon": 44, "moosvi": [0, 1, 46], "moral": [0, 43], "more": [1, 2, 5, 6, 7, 8, 10, 12, 14, 19, 27, 28, 32, 37, 40, 41, 43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58], "morn": [12, 19, 30], "morpholog": 46, "moskowitz": 43, "mosold": [39, 41, 50], "mosold_1": 39, "mosold_10": 39, "mosold_11": 39, "mosold_12": 39, "mosold_2": 39, "mosold_3": 39, "mosold_4": 39, "mosold_5": 39, "mosold_6": 39, "mosold_7": 39, "mosold_8": 39, "mosold_9": 39, "most": [7, 8, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 58], "most_confident_i": [18, 36], "most_confident_x": [18, 36], "most_frequ": [13, 15, 16, 20, 22, 23, 28, 31, 33, 34, 38, 39, 41, 50, 55], "most_negative_id": 29, "most_positive_id": 29, "most_similar": 46, "mostli": [8, 17, 24, 35, 48], "motiv": [12, 17, 19, 24, 30, 35], "mountginini": 48, "move": [7, 18, 29, 36, 41, 42, 55, 58], "movi": [18, 29, 36, 46, 52], "movie_feats_df": 45, "movie_id": 45, "movie_nam": 45, "movies_rated_by_pat": 45, "movies_to_pr": 45, "movieto": 52, "mpimg": 47, "mri": 54, "mrtssm448usn": 48, "mse": [13, 20, 31, 45, 51, 54], "msg": [17, 24, 35, 49], "msg_dtype": 28, "msg_err": 28, "mssubclass": [39, 41, 50], "mssubclass_120": 39, "mssubclass_160": 39, "mssubclass_180": 39, "mssubclass_190": 39, "mssubclass_20": 39, "mssubclass_30": 39, "mssubclass_40": 39, "mssubclass_45": 39, "mssubclass_50": 39, "mssubclass_60": 39, "mssubclass_70": 39, "mssubclass_75": 39, "mssubclass_80": 39, "mssubclass_85": 39, "mssubclass_90": 39, "mszone": [39, 41, 50], "mszoning_c": [39, 41], "mszoning_fv": 39, "mszoning_rh": 39, "mszoning_rl": 39, "mszoning_rm": 39, "much": [4, 5, 8, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 38, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 56, 58], "mueller": 1, "multi": [39, 41, 43, 46, 48, 51], "multi_class": [38, 53], "multi_output": 28, "multi_strategi": 40, "multiclass": [47, 51, 53], "multicoliniar": 41, "multicultur": 46, "multilevel": 39, "multimod": 43, "multinomi": 53, "multipl": [7, 8, 14, 18, 21, 26, 32, 36, 37, 40, 41, 46, 47, 48, 49], "multiplelin": 49, "multiplelines_no": 49, "multiplelines_y": 49, "multipli": [18, 36, 37, 38, 40, 42, 49], "music": [28, 45, 52], "musqueam": 58, "must": [0, 6, 7, 8, 12, 13, 14, 16, 19, 20, 23, 31, 32, 34, 41, 44, 46, 49], "mustn": 46, "mutual": 44, "my": [6, 10, 12, 19, 30, 37, 38, 43, 46, 50, 51, 52, 58], "my_heatmap": 37, "my_map": 39, "mypreprocessor": 46, "myself": [31, 46, 50], "m\u00fcller": 9, "n": [1, 13, 15, 18, 20, 22, 27, 28, 29, 31, 33, 36, 37, 39, 40, 41, 42, 44, 45, 46, 48, 50, 52, 53, 56], "n_bin": 42, "n_class": [15, 22, 33, 38], "n_cluster": [43, 44], "n_clusters_per_class": 38, "n_compon": 46, "n_constitu": 40, "n_estim": [42, 48, 49, 50], "n_estimators_valu": 50, "n_exampl": 43, "n_feat": [15, 22, 33], "n_featur": [15, 22, 33, 38, 43], "n_features_to_select": 42, "n_imag": 27, "n_inform": 38, "n_init": 43, "n_job": [17, 24, 35, 38, 39, 40, 50], "n_neighbor": [27, 45, 56], "n_neighbors_selector": [15, 22, 33], "n_neighbors_widget": [15, 22, 27, 33, 56], "n_peopl": 28, "n_redund": 38, "n_rental": 48, "n_rentalsin3hour": 48, "n_rentalsin6hour": 48, "n_repeat": 41, "n_resourc": 37, "n_sampl": [15, 22, 33, 38, 43, 44, 47, 53], "n_split": 48, "n_threshold": 38, "n_top_feat": 29, "n_top_featur": 29, "n_topic": 46, "n_train": 48, "n_word": [46, 52], "na": [39, 41, 50], "nafter": 46, "nah": [17, 24, 35], "naiv": 44, "name": [1, 4, 5, 6, 7, 8, 10, 13, 15, 16, 17, 20, 22, 23, 24, 26, 27, 28, 29, 31, 33, 34, 35, 37, 38, 40, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 56, 58], "named_estimators_": 40, "named_step": [18, 29, 36, 38, 39, 40, 41, 42, 48, 50, 52], "named_transformers_": [17, 24, 28, 35, 38, 39, 40, 41, 42, 48, 49, 50, 52], "namespac": 28, "nan": [16, 17, 23, 24, 28, 34, 35, 38, 39, 40, 41, 42, 45, 48, 49, 50, 52, 54], "nanmean": 45, "nanosecond": 48, "narr": 46, "narrow": [12, 19, 45, 50], "nasali": [12, 19, 30, 47], "nation": 58, "nativ": [28, 38, 40, 41, 47, 53], "natur": [2, 11, 12, 17, 24, 28, 30, 35, 38, 40, 42, 47, 51, 53], "navig": [7, 10, 51], "nbsp": [12, 19, 30, 34, 35, 37, 38, 39, 40, 41, 42, 47, 50, 52], "nbviewer": [12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 34, 35, 37, 38, 39, 40, 41, 42, 47, 50, 52], "nc": 1, "ncol": [18, 36], "ndarrai": [8, 17, 24, 28, 35], "ndate": 52, "ndframe": [42, 49], "ndim": [8, 28], "ne": 48, "nearbi": [15, 22, 33, 43], "nearest": [27, 28, 38, 44, 56], "nearestneighbor": 27, "nearestneighborsifittednearestneighbor": 27, "nearli": 26, "necessari": [0, 7, 13, 28, 31, 37, 54, 57], "necessarili": [14, 21, 32, 39, 40, 45, 51], "necvq": 49, "need": [5, 7, 8, 10, 12, 13, 15, 17, 19, 20, 22, 24, 26, 27, 28, 30, 31, 33, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58], "needn": 46, "neg": [13, 14, 15, 18, 20, 21, 22, 31, 32, 33, 36, 39, 40, 41, 46, 48, 49, 52, 56], "neg_mean_absolute_percentage_error": 39, "neg_mean_squared_error": [39, 50], "neg_prob": 29, "neg_root_mean_square_error": 39, "neg_root_mean_squared_error": 39, "neigh": [15, 22, 27, 33], "neighbor": [15, 16, 17, 18, 22, 23, 24, 27, 28, 33, 34, 35, 36, 38, 42, 44, 56, 57], "neighborhood": [18, 36, 39, 41, 50], "neighborhood_blmngtn": 39, "neighborhood_bluest": 39, "neighborhood_brdal": 39, "neighborhood_brksid": 39, "neighborhood_clearcr": 39, "neighborhood_collgcr": 39, "neighborhood_crawfor": 39, "neighborhood_edward": 39, "neighborhood_gilbert": 39, "neighborhood_idotrr": 39, "neighborhood_meadowv": 39, "neighborhood_mitchel": 39, "neighborhood_nam": 39, "neighborhood_noridg": [39, 41], "neighborhood_npkvil": 39, "neighborhood_nridght": [39, 41], "neighborhood_nwam": 39, "neighborhood_oldtown": [39, 41], "neighborhood_sawy": [39, 41], "neighborhood_sawyerw": [39, 41], "neighborhood_somerst": [39, 41], "neighborhood_stonebr": [39, 41], "neighborhood_swisu": [39, 41], "neighborhood_timb": [39, 41], "neighborhood_veenk": [39, 41], "neighborsbas": 28, "neighbour": [14, 27, 32, 41, 43, 44, 46, 56], "neighbourhood": [18, 36, 42, 44, 57], "neither": [14, 17, 21, 24, 32, 35, 45], "neo": [1, 58], "neq": [41, 45], "ner": 46, "nervou": [13, 20, 31], "nest": [37, 54], "net": [47, 49], "netflix": [45, 52], "network": [1, 11, 12, 17, 19, 24, 30, 35, 40, 42, 43, 45, 46, 48, 51], "neu": 52, "neural": [1, 11, 42, 48], "neutral": 52, "never": [38, 40, 41, 45, 47, 49], "nevertheless": 58, "new": [1, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 57], "new_cent": 43, "new_column": [39, 41, 48, 49, 50], "new_data": 49, "new_df": 48, "new_exampl": [13, 20, 31, 43], "new_feature_nam": 48, "new_valu": 49, "newaxi": 8, "newcastl": 52, "newer": 39, "newli": [16, 23, 34, 39, 42, 44], "newsgroup": 46, "newswir": 46, "next": [1, 10, 13, 14, 15, 16, 18, 20, 22, 23, 27, 28, 31, 32, 33, 34, 35, 38, 39, 40, 46, 47, 48, 50, 57, 58], "nfeat": [15, 22, 33], "nfeats_accuraci": [15, 22, 33], "ng": [1, 9, 37, 42], "ngram": 42, "ngram_rang": [17, 24, 35], "nhl": 46, "nhqxu": 49, "nice": [4, 12, 19, 37, 38, 40, 41, 44, 47, 49, 50, 51], "nicki": 37, "night": [38, 48, 51], "nightmar": 50, "niki": [1, 58], "nlemma": 46, "nlp": [17, 24, 35, 47, 52], "nltk": [46, 52], "nltk_data": [46, 52], "nmax": 50, "nn": [1, 16, 23, 27, 29, 34, 47, 56], "nne": 48, "nnw": 48, "nnz": [17, 24, 35], "no_grad": [27, 47], "no_val_x": 28, "nobodi": [12, 30], "node": [13, 20, 31, 40, 44, 47, 55], "nois": [44, 54, 56], "noise_cat": 28, "noise_level": 28, "non": [1, 8, 12, 13, 14, 16, 18, 19, 20, 21, 23, 30, 31, 32, 34, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 49, 51, 54, 58], "noncommerci": 1, "none": [1, 14, 16, 17, 18, 21, 23, 24, 28, 32, 34, 35, 36, 37, 38, 40, 42, 44, 48, 49, 50], "noninfring": 0, "nonzero": [17, 24, 35], "noodl": 28, "noqa": 37, "nor": [7, 14, 17, 21, 24, 32, 35, 46], "norg": [46, 52], "norm": [28, 37, 46], "normal": [6, 23, 27, 28, 38, 39, 40, 41, 43, 44, 46, 47, 48, 50, 52], "north": 46, "north_america": 28, "norvig": 1, "notat": [15, 33], "note": [0, 1, 3, 7, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 45, 51, 53, 54, 58], "notebook": [5, 7, 9, 10, 13, 14, 15, 16, 17, 21, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 47, 50, 52, 57], "notic": [0, 17, 18, 24, 28, 35, 36, 38, 39, 42], "notion": [15, 22, 33, 37, 43, 45], "notna": 48, "noun": [46, 52], "nov": 48, "novel": 54, "novemb": 48, "novic": 9, "now": [8, 10, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 55, 56, 57], "np": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 54, 55, 56, 57], "nperson": 52, "npie": 8, "npo": 46, "npr": [42, 46, 54], "npt": 28, "nsubj": 46, "ntest": [15, 22, 27, 33, 37, 56], "ntoken": 46, "ntree": 40, "null": [16, 17, 23, 24, 34, 35, 38, 39, 42, 48, 49], "null_distribut": 49, "num": [38, 40, 41], "num_output_channel": 47, "num_parallel_tre": 40, "num_sent": [38, 51], "num_work": [27, 47], "number": [1, 4, 6, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 49, 51, 54, 56, 58], "number_test": 37, "numberbatch": 46, "numer": [2, 13, 16, 17, 18, 20, 23, 24, 27, 28, 31, 34, 35, 36, 38, 39, 40, 45, 46, 48, 49, 50, 56, 57], "numeric_feat": [17, 24, 28, 35, 37, 42, 54], "numeric_featur": [35, 38, 39, 40, 41, 48, 49, 50, 52], "numeric_looking_column": 39, "numeric_transform": [28, 35, 38, 39, 40, 41, 48, 50], "numpi": [9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 56, 57], "numpy_dtyp": 49, "nuniqu": 26, "nutrit": 46, "nw": 48, "nwith": [15, 22, 33], "ny": 52, "nyt": 50, "o": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57], "obelisk": 47, "object": [14, 16, 17, 18, 21, 23, 24, 26, 28, 29, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 52, 54, 55, 56], "observ": [12, 13, 14, 15, 19, 20, 21, 22, 27, 30, 31, 32, 33, 40, 41, 43, 44, 48, 49, 56], "obtain": [0, 18, 27, 29, 36, 43, 44, 45, 49, 56], "obviou": [44, 46], "occasion": 38, "occup": [38, 40, 41], "occupation_farm": 41, "occupation_miss": 41, "occupation_priv": 41, "occupi": 58, "occur": [8, 13, 14, 17, 20, 21, 24, 31, 32, 35, 46, 49], "occurr": [46, 49], "ocean": [16, 23, 34, 35, 42, 57], "ocean_proxim": [16, 23, 34, 35, 42, 57], "ocean_proximity_": [16, 23, 34, 35], "ocean_proximity_inland": [16, 23, 34, 35], "ocean_proximity_island": [16, 23, 34, 35], "ocean_proximity_near": [16, 23, 34, 35], "oct": 36, "octob": [26, 48], "oe": [17, 24, 35, 54], "oe_encod": 54, "off": [11, 18, 27, 36, 37, 38, 39, 42, 43, 46, 47, 49, 50, 54], "offens": 4, "offer": [8, 40, 45, 46, 49, 58], "offic": [1, 4, 10, 12, 54, 58], "offici": [46, 58], "offlin": 45, "offset": [18, 36], "often": [8, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 30, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56], "ogunrind": [12, 19, 30], "oh": [28, 41, 42, 47, 48, 49, 51, 54, 58], "ohe_column": [39, 41, 50], "ohe_enc": [17, 24, 35], "ohe_encod": 54, "ohe_feat": 28, "ohe_feat_nam": 28, "ohe_feature_nam": [41, 48], "ohehotencod": [17, 24, 35], "ois": 44, "ok": [12, 15, 19, 22, 30, 33, 39, 48, 49, 51, 54], "okai": [43, 51], "ola": 46, "old": [9, 40, 41], "old_cent": 43, "older": 39, "olymp": 8, "omit": 41, "omw": 46, "onc": [6, 7, 8, 10, 13, 14, 16, 17, 20, 21, 23, 24, 27, 31, 32, 34, 35, 37, 42, 44, 45, 46, 47, 51, 58], "onca": [12, 19, 30, 47], "one": [6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 58], "one_c": [15, 22, 33], "one_ex_preprocess": 41, "one_ex_preprocessed_perturb": 41, "one_exampl": 41, "one_example_perturb": 41, "onehot": [17, 24, 35, 42], "onehotencod": [16, 18, 23, 28, 34, 36, 37, 38, 39, 40, 41, 42, 48, 49, 50, 54, 57], "onehotencoder__major_biologi": [17, 24, 35], "onehotencoder__major_comput": [17, 24, 35], "onehotencoder__major_econom": [17, 24, 35], "onehotencoder__major_linguist": [17, 24, 35], "onehotencoder__major_mathemat": [17, 24, 35], "onehotencoder__major_mechan": [17, 24, 35], "onehotencoder__major_phys": [17, 24, 35], "onehotencoder__major_psychologi": [17, 24, 35], "onehotencoderonehotencod": [17, 24, 28, 35, 37, 39, 40, 50], "ones": [8, 12, 15, 16, 19, 22, 23, 26, 27, 30, 33, 34, 40, 41, 43, 45, 46, 56], "onevsoneclassifi": 53, "onevsrestclassifi": 53, "onli": [2, 4, 8, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 56, 57, 58], "onlin": [3, 5, 7, 10, 20, 31, 46, 58], "onlinebackup": 49, "onlinebackup_no": 49, "onlinebackup_y": 49, "onlinesecur": 49, "onlinesecurity_no": 49, "onlinesecurity_y": 49, "onrend": 51, "ontario": 46, "ontonot": 46, "oob_scor": 50, "op": 38, "open": [5, 6, 10, 12, 19, 30, 47, 51, 58], "openporchsf": [39, 41, 50], "oper": [4, 8, 10, 17, 24, 35, 42, 46, 51], "operand": 8, "opinion": 40, "opportun": [26, 45], "oppos": [39, 40], "opposit": [8, 39, 40, 41], "opt": [10, 27, 28, 40], "optic": 49, "optim": [1, 2, 13, 14, 15, 20, 21, 22, 27, 29, 31, 32, 33, 35, 38, 40, 41, 42, 43, 44, 47, 49, 50, 51], "optimist": 37, "optimized_c": 29, "option": [1, 7, 8, 13, 19, 20, 31, 39, 43, 46, 50], "orang": [18, 36], "orch": 58, "order": [5, 7, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 51, 54], "ordering_ordinal_oth": [39, 41, 50], "ordering_ordinal_reg": [39, 41, 50], "ordin": [39, 54, 57], "ordinal_feat": [17, 24, 28, 35], "ordinal_featur": [38, 40, 41], "ordinal_features_oth": [39, 41, 50], "ordinal_features_reg": [39, 41, 50], "ordinal_transform": [28, 38, 40, 41], "ordinal_transformer_oth": [39, 41, 50], "ordinal_transformer_reg": [39, 41, 50], "ordinalencod": [16, 17, 23, 24, 28, 34, 35, 38, 39, 40, 41, 42, 48, 49, 50, 54, 57], "ordinalencoderordinalencod": [17, 24, 28, 35, 39, 40, 50], "ordinari": 39, "oreilli": [47, 48], "org": [9, 12, 14, 16, 17, 19, 21, 23, 24, 26, 27, 28, 30, 32, 34, 35, 37, 38, 39, 40, 41, 42, 46, 47, 50, 52], "organ": [12, 13, 16, 19, 20, 23, 30, 31, 34, 46, 50, 51], "orgin": 8, "orig_featur": 48, "orig_pr": 41, "orig_scor": 38, "origin": [12, 16, 17, 19, 23, 24, 34, 35, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 52, 56, 58], "original_hm": [38, 51], "originaltweet": 52, "ornithorhynchu": 47, "oscar": [18, 36], "ostblom": 46, "other": [0, 1, 4, 5, 6, 7, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 31, 32, 34, 35, 36, 37, 38, 40, 41, 44, 45, 47, 51, 52, 53, 54, 56, 58], "otherwis": [0, 7, 17, 24, 35], "ounc": [12, 19, 30, 47], "our": [5, 6, 8, 10, 12, 13, 15, 17, 18, 19, 20, 22, 24, 26, 27, 28, 29, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 54, 55, 56, 58], "ourselv": [13, 20, 31, 38, 46, 47, 48], "out": [0, 1, 4, 7, 8, 10, 12, 13, 14, 15, 17, 19, 20, 21, 22, 24, 26, 28, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 52, 54, 56, 58], "out_col": [14, 16, 21, 23, 32, 34, 52], "out_step": 38, "outer": 52, "outlier": [28, 39, 44, 51, 54], "outlook": 49, "output": [7, 8, 10, 12, 13, 14, 17, 18, 19, 20, 21, 24, 28, 30, 31, 32, 35, 36, 38, 40, 41, 46, 47, 48, 50, 51, 54, 58], "outsid": [7, 38, 40, 41, 45, 46, 48, 49], "over": [14, 32, 37, 39, 46, 47, 48, 49, 50, 51, 54, 58], "over_confident_i": [18, 36], "over_confident_x": [18, 36], "over_sampl": 38, "overal": [10, 28, 29, 38, 41, 43, 46, 47, 50, 54, 58], "overallcond": [39, 41, 50], "overallqu": [39, 41, 50], "overconfid": [41, 42, 51], "overcrowd": 58, "overfit": [1, 11, 15, 18, 22, 26, 27, 29, 33, 36, 39, 40, 42, 47, 51, 56], "overflow": 7, "overhead": [17, 24, 35], "overlap": [2, 14, 21, 32, 43, 51], "overli": [15, 22, 27, 33, 37, 56], "overload": [45, 49], "overpredict": 39, "oversample_pip": 38, "overshadow": 46, "overst": 50, "overus": 40, "overview": [43, 44, 45, 46], "overwhelm": 43, "overzeal": 6, "own": [4, 5, 8, 12, 14, 16, 19, 23, 32, 34, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53], "p": [18, 36, 37, 44, 46, 49, 51], "p_i": 43, "p_value_threshold": 49, "pace": [18, 36, 43, 46, 58], "packag": [5, 8, 11, 17, 20, 24, 27, 28, 31, 32, 35, 37, 38, 41, 43, 44, 45, 46, 47, 49, 51, 52, 53], "pad": [27, 47], "page": [1, 4, 7, 12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 34, 35, 37, 38, 39, 40, 41, 42, 46, 47, 50, 52, 58], "pai": [41, 51], "pain": [4, 47, 48, 50], "pair": [44, 46, 53], "pairwis": [15, 22, 33, 44], "panda": [9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57], "pane": [15, 22, 27, 33, 56], "panel": [15, 22, 27, 33, 38, 41, 43, 44, 56], "panic": 52, "panther": [12, 19, 30, 47], "panthera": [12, 19, 30, 47], "paper": [7, 41, 42, 46, 47, 49, 51, 52], "paperlessbil": 49, "paperlessbilling_no": 49, "paperlessbilling_y": 49, "paradigm": [12, 13, 19, 20, 30, 31, 43, 46], "paradox": 45, "paragraph": 46, "paraleg": 46, "parallel": [17, 24, 35, 37, 40], "param": [15, 17, 22, 24, 27, 33, 35, 37, 39, 56], "param_columntransformer__countvectorizer__max_featur": 37, "param_dist": 37, "param_distribut": 37, "param_grid": [14, 15, 21, 22, 32, 33, 37, 39, 50], "param_grid1": 37, "param_grid2": 37, "param_grid3": 37, "param_grid4": 37, "param_ridge__alpha": 39, "param_svc__c": 37, "param_svc__gamma": 37, "paramet": [15, 16, 17, 22, 23, 24, 27, 28, 33, 34, 35, 39, 40, 41, 43, 44, 46, 48, 49, 50, 52, 55, 56], "parametr": 44, "params_": 49, "params_str": 37, "paramter": [15, 22, 33], "pardu": [12, 19, 30, 47], "parent": 44, "park": [42, 47, 51, 52], "pars": 46, "parse_d": [8, 48], "parser": 46, "part": [1, 4, 9, 10, 16, 17, 18, 23, 34, 35, 36, 37, 38, 40, 41, 42, 44, 46, 48, 50, 51, 52, 58], "part1": 45, "part2": 45, "parti": 46, "partial": [4, 49, 50], "particip": 58, "particular": [0, 9, 10, 16, 17, 23, 24, 34, 35, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 56], "particularli": [40, 45, 58], "partit": [17, 24, 35, 43, 44], "partner": [49, 58], "partner_no": 49, "partner_y": 49, "parton": 52, "pass": [8, 14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 28, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 46, 47, 56, 58], "passthrough": [17, 24, 35, 37, 49, 52], "passthrough__ml_experi": [17, 24, 35], "passthrough_feat": [17, 24, 35, 37, 54], "passthrough_featur": [49, 52], "passthroughpassthrough": [17, 24, 35, 37, 52], "past": [13, 14, 20, 21, 31, 32, 40, 48, 49, 50, 54], "pat": 45, "pat_i": 45, "pat_model": 45, "pat_x": 45, "pata": [12, 19, 30, 47], "path": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57], "patial": 44, "patient": [13, 20, 31, 51], "patio": 47, "patric": 41, "patrick": [1, 58], "pattern": [12, 13, 14, 17, 19, 20, 21, 24, 26, 30, 31, 32, 35, 37, 42, 43, 46, 48, 50, 56], "pav_bhaji": 46, "pave": [39, 41, 50], "paveddr": [39, 41, 50], "paveddrive_i": 39, "paveddrive_n": 39, "paveddrive_p": 39, "paymentmethod": 49, "paymentmethod_bank": 49, "paymentmethod_credit": 49, "paymentmethod_electron": 49, "paymentmethod_mail": 49, "pca": [38, 44, 45], "pcarter": 9, "pd": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57], "pdf": [7, 9], "peac": 46, "pedest": 47, "pedro": [1, 14, 32, 42], "peer": [51, 54, 58], "pembrok": [12, 19, 30, 47], "penal": [6, 49], "penalti": [38, 46, 58], "peopl": [4, 13, 14, 16, 18, 20, 21, 23, 31, 32, 34, 36, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 58], "per": [8, 18, 36, 38, 39, 40, 41, 45, 47, 48, 50, 53, 54], "perceiv": 6, "percent": 39, "percent_error": 39, "percentag": [13, 20, 31, 38, 45, 50], "perfect": [6, 13, 14, 20, 21, 26, 31, 32, 38, 39, 41, 45, 49, 52], "perfectli": [2, 45, 46], "perform": [11, 13, 14, 15, 16, 18, 20, 21, 22, 23, 26, 27, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 54, 55, 57], "performac": [14, 21, 32], "perhap": [39, 48, 53], "perimet": 42, "period": [46, 48, 49, 52, 58], "perm_sorted_idx": 41, "perman": 8, "permiss": [0, 58], "permit": [0, 16, 23, 34, 38, 58], "permut": 41, "persist": 45, "person": [0, 1, 4, 6, 12, 19, 30, 38, 43, 46, 47, 48, 49, 51, 52, 58], "perspect": [40, 45], "pertain": 5, "perthairport": 48, "perturb": [28, 41, 44], "perturbed_pr": 41, "pete_seeg": 46, "peter": 1, "ph": 46, "pharma": 51, "phascolarcto": 47, "phase": [14, 21, 32], "phd": 46, "phdei": 49, "phenomenon": [45, 49, 56], "philippin": 52, "philosoph": 46, "phone": [12, 19, 30, 49, 58], "phoneservic": 49, "phoneservice_no": 49, "phoneservice_y": 49, "photo": [52, 54], "photograph": 58, "phrase": 46, "physic": [17, 24, 35, 48], "pi": 8, "piazza": [1, 6, 7, 12, 13, 19], "pick": [13, 18, 20, 26, 31, 36, 38, 40, 41, 42, 43, 44, 47, 50, 51, 53, 55, 56], "pictur": [40, 41, 44, 46, 48, 50], "pie": 8, "piec": [18, 36, 49], "pil": [12, 19, 27, 30, 47], "pin": [7, 47], "pineappl": 46, "pip": [10, 41, 46, 47, 51, 52], "pipe": [16, 17, 18, 23, 24, 34, 35, 36, 37, 38, 40, 46, 47, 52], "pipe_bestalpha": 39, "pipe_bigalpha": 39, "pipe_catboost": 40, "pipe_dt": [40, 41], "pipe_forward": 42, "pipe_knn": 28, "pipe_lgbm": [40, 41], "pipe_lr": [29, 38, 40, 41, 51], "pipe_lr_all_feat": 42, "pipe_lr_balanc": 38, "pipe_lr_model_bas": 42, "pipe_lr_weight": 38, "pipe_ohe_knn": 28, "pipe_ordinal_knn": 28, "pipe_rf": [40, 41], "pipe_rf_demo": 40, "pipe_ridg": [18, 36, 39], "pipe_sklearn_gb": 40, "pipe_sklearn_histgb": 40, "pipe_smallalpha": 39, "pipe_svc": [28, 38], "pipe_svm": 37, "pipe_xgb": [40, 41], "pipe_xor": 42, "pipelin": [1, 2, 11, 12, 14, 17, 18, 19, 21, 24, 29, 30, 32, 35, 36, 37, 38, 39, 40, 41, 42, 47, 48, 49, 50, 51, 52, 57], "pipeline__lab1": [17, 24, 35], "pipeline__lab2": [17, 24, 35], "pipeline__lab3": [17, 24, 35], "pipeline__lab4": [17, 24, 35], "pipeline__quiz1": [17, 24, 35], "pipeline__rooms_per_household": 42, "pipeline__university_year": [17, 24, 35], "pipelineifittedpipelin": [16, 17, 23, 24, 34, 35, 37, 38, 42, 47, 52], "pipelineinot": [35, 37, 39], "pipelinepipelin": 37, "pitch": 50, "pitfal": [48, 50], "pixel": 41, "pizza": 46, "pkg": 10, "pla": 46, "place": [5, 46, 48, 58], "plagiar": 58, "plai": [13, 15, 20, 22, 31, 33, 37, 41, 44, 46, 55, 56], "plain": 43, "plan": [10, 12, 19, 30, 39, 42, 49, 51, 52, 57, 58], "plane": [18, 20, 36], "plant": 54, "plastic": 46, "platform": 4, "platypu": 47, "player": [41, 46, 47], "pleas": [1, 4, 7, 10, 12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 34, 35, 37, 38, 39, 40, 41, 42, 47, 50, 51, 52, 58], "plinth": 47, "plot": [7, 13, 14, 15, 16, 18, 20, 21, 22, 23, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 42, 44, 45, 46, 47, 48, 50, 51, 56], "plot_2d_scor": [18, 36], "plot_2d_separ": [15, 18, 22, 27, 33, 36, 56], "plot_coeff_exampl": 29, "plot_confusion_matrix": 38, "plot_confusion_matrix_exampl": 38, "plot_cross_valid": [14, 21, 32, 48], "plot_dbscan": 44, "plot_dbscan_with_label": 44, "plot_dendrogram_clust": 44, "plot_elbow": 43, "plot_example_dist": 43, "plot_fruit_tre": [13, 31], "plot_grid_search_overview": 37, "plot_improper_process": 28, "plot_k_means_dbscan_comparison": 44, "plot_km_initi": 43, "plot_km_it": 43, "plot_km_iter": 43, "plot_kmean": 44, "plot_knn_clf": [15, 22, 33], "plot_knn_decision_boundari": [15, 22, 33], "plot_knn_regress": [15, 22, 33], "plot_lda_w_vector": 46, "plot_linkage_criteria": 44, "plot_logistic_regress": [18, 36], "plot_logistic_regression_graph": 47, "plot_loss_diagram": 50, "plot_multiclass_lr_ovr": 53, "plot_original_clust": 44, "plot_partial_effects_on_outcom": 49, "plot_proper_process": 28, "plot_result": [15, 22, 27, 33, 56], "plot_sample_img": 27, "plot_scal": [16, 23, 34], "plot_silhouette_dist": 43, "plot_single_hidden_layer_graph": 47, "plot_support_vector": [15, 22, 33], "plot_survival_funct": 49, "plot_svc_c": [15, 22, 33], "plot_svc_gamma": [15, 22, 33], "plot_time_spacing_distribut": 48, "plot_train_test_point": [15, 22, 33], "plot_tre": 26, "plot_tree_decision_boundari": [14, 21, 32], "plot_tree_decision_boundary_and_tre": [13, 14, 20, 21, 31, 32, 55], "plot_two_hidden_layer_graph": 47, "plot_typ": 41, "plot_x_dendrogram": 44, "plotli": [42, 46], "plotting_funct": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 47, 50, 53, 55, 56, 57], "plotting_functions_unsup": [43, 44, 45, 46], "plt": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 53, 54, 55, 56, 57], "plu": [18, 36, 47], "plural": [17, 24, 35], "pm": [1, 12, 16, 18, 19, 48, 58], "pmltt": 1, "pn": [15, 22, 27, 33, 38, 43, 44, 56], "po": [18, 23, 29, 32, 34, 36, 39, 41, 46, 50, 52], "pobox": [12, 19, 30], "poet": 46, "point": [1, 4, 11, 12, 13, 14, 16, 17, 18, 19, 20, 23, 24, 26, 28, 30, 31, 32, 34, 35, 36, 37, 39, 42, 44, 49, 50, 51, 53, 54, 56, 58], "point_ind": 43, "point_index": 43, "polarity_scor": 52, "pole": 47, "polici": [3, 4, 7, 19, 58], "polit": [45, 46, 47], "poly_transform": 48, "polynomialfeatur": [42, 48], "pomegran": 47, "pool": [1, 29], "poolarea": [39, 41, 50], "poolqc": [39, 41, 50], "poor": [17, 24, 35, 39, 42, 54, 57], "poorli": [15, 22, 33, 39, 44, 48], "pope": 46, "popul": [16, 18, 23, 34, 35, 36, 42, 48, 57], "popular": [8, 11, 14, 15, 16, 17, 18, 22, 23, 24, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 50, 52], "population_per_household": [16, 23, 34, 35, 57], "port": 51, "porter": 46, "porterstemm": 46, "portion": [0, 14, 16, 21, 23, 29, 32, 34, 37, 39, 41, 50, 58], "portug": [38, 41], "pos_": [46, 52], "pos_label": 39, "pos_prob": 29, "posit": [13, 14, 15, 18, 21, 22, 23, 31, 32, 33, 34, 36, 39, 40, 41, 46, 48, 49, 52], "posix": 49, "possess": 50, "possibl": [4, 5, 6, 8, 12, 13, 14, 16, 19, 20, 21, 23, 26, 28, 29, 30, 31, 32, 34, 37, 38, 40, 41, 42, 44, 45, 46, 47, 49, 50, 54, 56, 57, 58], "possibli": [7, 46], "post": [1, 4, 6, 7, 8, 12, 17, 19, 46, 48, 51, 58], "postprocess": 47, "potenti": [11, 15, 16, 22, 23, 26, 33, 34, 43, 46, 50, 51], "powder": 46, "power": [8, 14, 21, 28, 32, 40, 45, 46, 47, 50], "pplicat": 44, "pr": 54, "practic": [0, 1, 6, 9, 12, 14, 16, 21, 23, 32, 34, 42, 47, 50, 51, 54, 57, 58], "practition": 50, "prairielearn": [1, 12, 17, 19, 58], "pre": [1, 10, 12, 19, 27, 30, 40, 42, 46, 50, 51, 52, 54], "precipit": 51, "precis": [11, 39, 50, 51, 54], "precision_lr": 38, "precision_recall_curv": 38, "precision_scor": 38, "precision_svc": 38, "precisionrecallcurvedisplai": 38, "precisionrecalldisplai": 38, "pred": [38, 39, 45, 48, 49], "pred_df": [12, 19, 30, 45], "pred_dict": [12, 19, 30], "pred_g": 45, "pred_lin_reg": 45, "pred_train": 39, "pred_x": 45, "prediciton": 49, "predict": [2, 11, 14, 15, 16, 21, 22, 23, 24, 26, 28, 29, 32, 33, 34, 37, 38, 39, 42, 43, 44, 46, 48, 50, 51, 52, 54, 56, 57], "predict_expect": 49, "predict_for_usr": 45, "predict_proba": [29, 38, 40, 41, 47, 53], "predict_survival_funct": 49, "predicted_categori": [38, 51], "predicted_n_rent": 48, "predicted_quiz2": [13, 20, 31], "predicted_sal": 48, "predicted_target": [12, 19, 30], "predictor": [13, 20, 31, 54], "prefer": [12, 19, 30, 40, 43, 45], "prefer_skip_nested_valid": 28, "prefix": 8, "preliminari": [16, 23, 34, 42], "prepar": [16, 23, 34, 42, 47], "prepend": 10, "preprocess": [1, 11, 14, 15, 18, 21, 22, 26, 27, 28, 32, 33, 36, 37, 38, 40, 41, 42, 44, 45, 47, 49, 56, 57], "preprocess_featur": 48, "preprocessing_fin": 49, "preprocessing_notenur": 49, "preprocessor": [28, 35, 37, 38, 39, 40, 41, 48, 49, 50, 52, 57], "preprocessor1": 42, "preprocessor2": 42, "preprocessor3": 42, "prereq": 51, "prerequisit": [2, 49, 58], "preschool": [38, 40, 41], "presenc": [17, 24, 35, 41, 49], "present": [7, 14, 21, 27, 29, 32, 38, 45, 46, 47, 48, 49, 50, 51, 54, 56], "preserv": [38, 43], "pressure3pm": 48, "pressure9am": 48, "pretend": [13, 14, 21, 31, 32, 48], "pretrain": [46, 47, 52], "pretti": [13, 18, 20, 28, 31, 35, 36, 38, 40, 43, 46, 48, 49], "prevent": [37, 46, 49, 58], "previou": [12, 13, 19, 20, 26, 31, 39, 40, 43, 44, 48, 49, 50, 54], "previous": [45, 47, 48], "price": [8, 16, 18, 20, 23, 26, 28, 34, 36, 39, 41, 42, 49, 50, 56], "primari": [8, 15, 22, 29, 33], "primarili": [12, 13, 19, 20, 31, 41, 47, 51], "prime": [12, 19, 30], "princ": 46, "princess": 46, "principl": [9, 11, 13, 31, 54], "print": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 56], "print_top": 46, "prior": [43, 48, 54], "priorit": [42, 54], "privaci": [0, 11, 43, 51], "privat": [7, 38, 40, 41], "privileg": 6, "prize": [17, 24, 35], "pro": [43, 47, 50], "prob": [18, 36, 40], "proba": 47, "probabilist": [2, 46], "probabl": [12, 15, 16, 19, 22, 23, 28, 29, 30, 33, 34, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 54], "problem": [1, 4, 6, 11, 12, 17, 18, 19, 24, 26, 28, 30, 35, 36, 38, 39, 40, 41, 43, 44, 46, 47, 49, 50, 53, 54, 56, 58], "problemat": [38, 41, 49], "probosci": [12, 19, 30, 47], "proce": [27, 58], "procedur": 40, "proceed": [14, 32], "process": [2, 5, 7, 11, 13, 15, 16, 17, 20, 22, 23, 24, 26, 27, 31, 33, 34, 35, 37, 42, 43, 44, 47, 50, 51, 52, 56], "procfil": 51, "prod": [17, 24, 35, 37], "produc": [2, 7, 20, 28, 39, 41, 44, 49, 50, 54, 56], "product": [5, 37, 45, 46, 50, 52], "prof": [38, 40, 41], "profession": [45, 51], "profil": 39, "profile_df": 45, "profilereport": 39, "profit": 50, "program": [0, 4, 9, 10, 12, 19, 30, 46, 58], "programm": 46, "progress": 43, "project": [10, 16, 23, 34, 40, 42, 47, 50, 51, 54, 58], "promin": 46, "promis": [12, 19, 26, 30, 46, 48, 51], "promot": 49, "prompt": [10, 12, 58], "pron": [46, 52], "prone": 37, "proper": [47, 55], "properli": [7, 12, 19, 49, 50], "properti": [13, 20, 31, 39, 41, 42], "prophet": 48, "propn": [46, 52], "proport": [11, 13, 14, 17, 18, 20, 21, 24, 31, 32, 35, 36, 38, 39, 40, 41, 50], "proportional_hazard_test": 49, "prostitut": 46, "protocol": 51, "prototyp": [51, 54], "prove": 38, "provid": [0, 5, 7, 10, 11, 13, 14, 17, 18, 20, 21, 24, 27, 31, 32, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 54, 58], "provinc": [17, 24, 35, 46], "provinci": 46, "proxi": [14, 21, 32], "proxim": [18, 36, 46, 58], "prune": 42, "psychologi": [17, 24, 35, 54], "pt": [18, 36, 37, 47], "public": [0, 4, 7, 46, 52], "publish": [0, 1, 18, 36, 46], "puck": 46, "pud": 39, "pull": [10, 18, 36, 46], "punct": [46, 52], "punctuat": [17, 24, 35, 46], "punish": 50, "punkt": 52, "punkt_tab": 52, "purchas": [12, 19, 27, 30, 45, 51], "pure": [13, 20, 31, 48], "purpos": [0, 13, 14, 16, 20, 21, 23, 29, 31, 32, 34, 45, 46, 48, 51, 54, 55, 56, 58], "pursuit": 50, "push": [7, 41], "put": [7, 8, 10, 13, 14, 16, 17, 21, 23, 24, 27, 28, 29, 31, 32, 34, 35, 42, 43, 44, 45, 51], "px": [42, 46], "py": [13, 17, 20, 23, 24, 27, 28, 31, 32, 34, 35, 37, 40, 41, 43, 44, 49, 51, 52, 53], "pybo": 37, "pydata": 42, "pyplot": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 54, 55, 56, 57], "pysurviv": 49, "python": [1, 3, 4, 11, 30, 37, 39, 45, 46, 47, 48, 49, 50, 51, 52, 58], "python3": [9, 17, 20, 24, 27, 28, 31, 32, 35, 37, 41, 49, 53], "pythonwarn": 39, "pytorch": [12, 19, 30, 47], "pyviz": 38, "q": 1, "qualit": 28, "qualiti": [38, 41, 43, 44, 50], "quantifi": 38, "quantil": 28, "quantit": 28, "quebecoi": 28, "queen": 46, "queen_consort": 46, "queri": [16, 23, 27, 34, 38, 40, 43, 45, 46, 48, 49, 58], "query_img": 27, "query_point": [15, 22, 33], "quest": 42, "question": [1, 6, 7, 58], "queuepredictor": 51, "quick": [4, 12, 19, 46, 51, 58], "quickli": [13, 15, 16, 20, 22, 23, 31, 33, 34, 37, 44, 49, 54, 58], "quickstart": 9, "quirk": [14, 21, 32], "quit": [6, 12, 13, 16, 20, 23, 27, 30, 31, 34, 37, 38, 39, 41, 42, 44, 46, 47, 48, 49, 50, 52], "quiz": [1, 12, 16, 19, 46, 58], "quiz1": [13, 14, 17, 20, 21, 24, 31, 32, 35, 54], "quiz2": [14, 17, 21, 24, 32, 35, 54], "quizz": [13, 15, 17, 20, 31], "r": [11, 13, 17, 18, 20, 24, 29, 31, 35, 36, 38, 48, 50], "r1": 40, "r2": [26, 39, 40, 54, 56], "r2_score": [39, 42], "r4": 40, "race": [17, 35, 38, 40, 41, 58], "radial": [15, 22, 33], "radiu": [42, 44], "rail": 47, "rain": 48, "rain_df": 48, "rain_df_modifi": 48, "rainfal": 48, "rainfall_lag1": 48, "rainfall_lag2": 48, "rainfall_lag3": 48, "raintodai": 48, "raintoday_miss": 48, "raintoday_no": 48, "raintoday_y": 48, "raintomorrow": 48, "rais": [6, 17, 19, 24, 28, 35, 38, 48, 49], "rand": [8, 40], "randint": 37, "randn": [18, 36, 42], "random": [6, 8, 11, 14, 15, 18, 21, 22, 27, 32, 33, 36, 38, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54], "random_forest_data": 40, "random_search": 37, "random_st": [12, 15, 16, 18, 19, 22, 23, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57], "randomforestclassifi": [41, 42, 48, 50], "randomforestclassifierrandomforestclassifi": 40, "randomforestregressor": [39, 40, 41, 42, 48, 49, 50, 51], "randomhorizontalflip": 47, "randomizedsearchcv": [15, 22, 33, 40, 41, 50], "randomizedsearchcvifittedrandomizedsearchcv": 37, "randomli": [14, 18, 21, 32, 36, 37, 38, 40, 49], "randomoversampl": 38, "randomresizedcrop": 47, "randomst": [42, 44], "randomundersampl": 38, "rang": [4, 8, 11, 14, 15, 16, 17, 18, 21, 22, 23, 24, 28, 32, 33, 34, 35, 36, 40, 43, 45, 46, 47, 48, 49, 50, 52], "rangeindex": [17, 24, 35, 42, 48, 49], "rank": [38, 42, 45, 46, 49], "rank_test_mape_scor": 39, "rank_test_neg_mean_squared_error": 39, "rank_test_scor": [37, 39], "ranking_": 42, "rare": [17, 35, 38, 39, 43, 46, 54], "rate": [12, 18, 19, 30, 36, 38, 40, 43, 49, 50, 54], "rated_item": 45, "rather": [12, 17, 19, 24, 28, 30, 35, 37, 38, 39, 40, 41, 43, 46, 47, 58], "ratings_df": 45, "ratio": [38, 40, 46, 49], "ravel": [27, 29, 38, 54], "raw": [8, 17, 24, 35, 38, 41, 42, 46, 47, 50, 53], "raw_model_output": [18, 36], "raw_scor": 41, "rbf": [1, 14, 16, 18, 21, 23, 32, 34, 36, 37, 40, 41, 42, 50, 51, 54, 56], "rcparam": [12, 13, 14, 19, 20, 21, 30, 31, 32, 38, 43, 44, 45, 47, 48, 49, 50, 55], "re": [4, 7, 8, 10, 12, 13, 14, 17, 19, 20, 21, 24, 29, 30, 31, 32, 35, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 51, 54, 55], "reach": [1, 6, 43, 58], "read": [1, 4, 7, 12, 15, 16, 17, 19, 22, 23, 24, 27, 33, 34, 35, 38, 39, 40, 41, 46, 48, 50, 51], "read_csv": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 57], "read_excel": 8, "read_html": 8, "read_img_dataset": 27, "read_json": 8, "readabl": [0, 8], "reader": 11, "readi": [7, 12, 14, 15, 16, 18, 21, 22, 23, 32, 33, 34, 36], "readlin": 47, "readm": 49, "readthedoc": 49, "real": [14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 28, 32, 33, 34, 35, 36, 38, 41, 43, 44, 45, 46, 47, 50, 52, 54], "realdonaldtrump": 52, "realist": [16, 23, 34, 48, 51], "realiti": [14, 21, 32, 39, 49], "realiz": 50, "realli": [8, 14, 18, 21, 32, 36, 37, 40, 42, 44, 45, 47, 48, 49, 51], "reason": [0, 2, 4, 8, 11, 14, 16, 21, 23, 32, 34, 37, 38, 39, 41, 43, 45, 46, 48, 49, 50, 51, 54, 58], "rec": [39, 41, 50], "recal": [11, 13, 14, 15, 16, 17, 18, 21, 23, 24, 28, 31, 32, 33, 34, 35, 36, 39, 43, 48, 51, 54], "recall_lr": 38, "recall_scor": 38, "recall_svc": 38, "receiv": [6, 7, 17, 19, 24, 35, 44, 47, 48, 51], "recent": [8, 10, 12, 17, 19, 24, 28, 30, 35, 42, 45, 46, 48, 49], "recip": [14, 21, 32], "recogn": [11, 14, 21, 32, 44, 48, 50, 58], "recognit": [12, 13, 15, 19, 30, 31, 33, 38, 46, 58], "recommend": [1, 2, 4, 8, 10, 11, 14, 15, 21, 27, 29, 30, 32, 33, 37, 38, 43, 46, 47, 50, 51], "record": [13, 20, 31, 49], "rectangular": 43, "recurr": 48, "recurs": 11, "red": [13, 15, 20, 22, 31, 33, 38, 41, 42, 43, 48], "redbon": 37, "redefin": 49, "redistribut": 0, "reduc": [7, 8, 12, 15, 19, 22, 30, 33, 37, 38, 39, 40, 41, 42, 45, 46, 47, 53, 56, 58], "reduct": [2, 38, 40, 42, 43], "redund": [18, 36, 41], "ref": [38, 49], "refer": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 38, 41, 43, 45, 46, 47, 56, 58], "referenc": 58, "referenti": 46, "refin": [15, 22, 27, 33, 56], "refit": 39, "reflect": [15, 22, 33, 39, 41, 46, 56, 58], "reflection_period": [38, 51], "reg": [13, 20, 31, 40], "reg_model": [13, 20, 31], "regard": 58, "regardless": 7, "regex": 46, "regim": 51, "region": [13, 20, 31, 38, 44, 48, 51, 53], "region_data": 48, "regist": [12, 19, 51, 58], "registered_nurs": 46, "regrad": [6, 19], "regress": [1, 2, 11, 12, 16, 17, 19, 23, 24, 26, 29, 30, 34, 35, 41, 42, 45, 48, 49, 50, 51, 52, 53, 54, 56], "regression_df": [13, 20, 31], "regressor": [13, 16, 17, 20, 23, 24, 26, 28, 31, 34, 35, 39, 48], "regular": [15, 17, 18, 22, 24, 33, 35, 36, 40, 46, 48, 49, 50, 54], "regulatori": 41, "reinforc": [12, 19, 30, 43], "reject": 38, "rel": [18, 21, 28, 36, 41, 44, 46, 52, 53], "rel_char_len": 52, "relabel": 43, "relat": [2, 6, 10, 12, 18, 19, 30, 36, 38, 39, 40, 41, 42, 43, 45, 46, 48, 49, 52, 58], "relationship": [11, 38, 40, 41, 42, 46, 48, 50, 52, 54, 55, 56, 58], "relationship_husband": 41, "relationship_own": 41, "releas": [1, 7, 14, 15, 16, 17], "relev": [1, 4, 8, 11, 13, 15, 16, 20, 22, 23, 31, 33, 34, 37, 41, 48, 58], "reli": [14, 15, 21, 22, 27, 32, 33, 42, 44, 45, 48, 56], "reliabl": [12, 19, 21, 30, 43], "religi": 46, "remain": [5, 39, 42, 45, 48, 50], "remaind": 6, "rememb": [7, 15, 17, 19, 22, 24, 29, 33, 35, 37, 38, 41, 42, 44, 47, 48, 49, 55, 56], "remind": 55, "remix": 0, "remov": [7, 16, 23, 27, 34, 38, 40, 41, 42, 46, 47, 49, 53], "renam": [12, 19, 30, 38, 41, 48, 51], "render": [4, 7, 12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 34, 35, 37, 38, 39, 40, 41, 42, 43, 46, 47, 50, 52], "rent": 48, "rental": [48, 51], "rentals_df": 48, "rentals_lag5": 48, "rentals_lag5_i": 48, "rentals_lag5_x": 48, "rentals_model": 48, "repair": [38, 40, 41], "repeat": [8, 42, 43, 44, 47, 51], "repeatedli": 6, "rephras": 50, "replac": [12, 16, 19, 23, 28, 29, 30, 34, 38, 40, 41, 45, 49], "replace_tag": 29, "replic": 51, "repo": [1, 38, 51], "report": [6, 13, 20, 31, 37, 39, 42, 48, 52], "repositori": [0, 1, 5, 10, 12, 18, 19, 27, 28, 36, 38, 51, 58], "repres": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54], "represent": [12, 13, 16, 19, 20, 23, 26, 27, 28, 29, 30, 31, 34, 37, 38, 39, 40, 41, 42, 43, 44, 46, 50, 51, 52, 54], "reproduc": [4, 14, 21, 32, 37, 40, 51, 58], "republ": 41, "request": [6, 19, 46, 58], "requir": [5, 7, 15, 16, 22, 23, 27, 28, 33, 34, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 54, 56, 58], "rerun": [12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 34, 35, 37, 38, 39, 40, 41, 42, 47, 50, 52], "res_mean": [14, 21, 32], "resampl": 38, "research": [12, 14, 19, 21, 30, 32, 37, 45, 46, 51], "reserv": [48, 58], "reset": 28, "reset_index": [12, 19, 30], "reshap": [8, 18, 28, 36, 37, 47, 48], "reshape_transform": 28, "resid": [18, 36], "residu": 40, "resiz": [27, 47], "resnet": 47, "resolut": 46, "resolv": 58, "resort": [18, 36], "resourc": [1, 3, 5, 31, 40, 41, 46, 47, 51, 54], "respect": [18, 36, 37, 38, 40, 41], "respons": [4, 7, 13, 20, 31, 43, 46, 50, 58], "rest": [18, 36, 37, 47, 49, 51, 54], "restart": [7, 10], "restaur": [28, 45, 51], "restaurant_df": 28, "restaurant_nam": 28, "restrict": [0, 39, 40, 46], "resubmit": 19, "result": [1, 2, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 51, 52, 56, 58], "result_block": 49, "result_img": 47, "results_df": [14, 15, 18, 21, 22, 26, 27, 29, 32, 33, 36, 56], "results_dict": [14, 15, 16, 21, 22, 23, 27, 32, 33, 34, 35, 37], "results_single_valid_df": [26, 56], "retail": [52, 54], "retail_df": 48, "retail_df_test": 48, "retail_df_train": 48, "retail_lag_5": 48, "retail_model": 48, "retail_test_5": 48, "retail_test_5_pr": 48, "retail_train_5": 48, "retail_train_5_d": 48, "retail_train_5_i": 48, "retail_train_5_x": 48, "retent": 49, "retrain": [37, 51], "return": [5, 8, 10, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 27, 28, 29, 31, 32, 33, 34, 35, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 56], "return_gener": [17, 24, 35], "return_predict": 51, "return_train_scor": [14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 48, 49, 52, 56], "reus": [38, 58], "revenu": 45, "revers": [17, 24, 35, 39], "review": [1, 4, 18, 36, 43, 50, 52, 54, 58], "review_pp": 29, "revisit": [38, 54], "revok": 0, "reward": [12, 17, 19, 24, 30, 35, 43], "rf": [48, 49], "rf_imp_df": 41, "rfe_cv": 42, "rfe_pip": 42, "rfecv": 42, "rgb": [12, 19, 30], "rhode_island": 46, "rich": [41, 46, 49, 50, 54], "richard": 50, "rico": 41, "rid": [10, 17, 24, 28, 35, 40, 41, 46, 49], "ridg": [41, 42, 45, 48, 49, 50, 51], "ridge__alpha": 39, "ridge_pr": 39, "ridge_tun": 39, "ridgecv": 42, "ridgecv_pip": 39, "ridgeridg": [39, 42], "right": [0, 1, 11, 12, 18, 19, 26, 28, 30, 36, 37, 38, 39, 42, 43, 44, 45, 46, 50, 51, 54], "rightarrow": [13, 15, 18, 22, 31, 33, 36, 38, 39, 40, 43, 44, 45, 46, 50, 51, 54], "rindfleischetikettierungs\u00fcberwachungsaufgaben\u00fcbertragungsgesetz": 46, "rise": [42, 46], "risk": [1, 38, 42, 50, 56], "riti": [19, 20, 21, 22, 23, 24, 58], "river": [18, 36], "rl": [39, 41, 50], "rmse": [45, 54], "rng": [42, 44], "rnn": 48, "ro": 38, "roast": 43, "robot": [45, 46], "robust": [12, 14, 15, 16, 19, 21, 22, 23, 28, 30, 32, 33, 34, 37, 40, 44, 56], "robustscal": 28, "roc": [11, 51, 54], "roc_auc": 38, "roc_auc_scor": 38, "roc_curv": 38, "roc_lr": 38, "roc_svc": 38, "roccurvedisplai": 38, "rodolfo": 37, "rodr\u00edguez": 46, "roger": 42, "role": [18, 36, 37, 41, 47], "roman": 45, "romanc": 45, "romant": 45, "ronald": [18, 36], "roof": 41, "roofmatl": [39, 41, 50], "roofmatl_clytil": [39, 41], "roofmatl_compshg": [39, 41], "roofmatl_membran": 39, "roofmatl_met": 39, "roofmatl_rol": 39, "roofmatl_tar": 39, "roofmatl_wdshak": 39, "roofmatl_wdshngl": [39, 41], "roofstyl": [39, 41, 50], "roofstyle_flat": 39, "roofstyle_g": 39, "roofstyle_gambrel": 39, "roofstyle_hip": 39, "roofstyle_mansard": 39, "roofstyle_sh": 39, "room": [12, 13, 18, 19, 20, 28, 30, 31, 36, 39, 42, 51, 52, 58], "rooms_per_household": [16, 23, 34, 35, 42, 57], "rooms_per_household_0": 42, "rooms_per_household_1": 42, "rooms_per_household_10": 42, "rooms_per_household_11": 42, "rooms_per_household_12": 42, "rooms_per_household_13": 42, "rooms_per_household_14": 42, "rooms_per_household_15": 42, "rooms_per_household_16": 42, "rooms_per_household_17": 42, "rooms_per_household_18": 42, "rooms_per_household_19": 42, "rooms_per_household_2": 42, "rooms_per_household_3": 42, "rooms_per_household_4": 42, "rooms_per_household_5": 42, "rooms_per_household_6": 42, "rooms_per_household_7": 42, "rooms_per_household_8": 42, "rooms_per_household_9": 42, "root": [10, 13, 15, 20, 22, 27, 31, 33, 45, 47, 54], "rose": 46, "rostin": [1, 58], "rotat": 48, "roth": [1, 58], "rough": 4, "roughli": [5, 14, 32, 46, 51, 54], "round": [8, 15, 16, 22, 23, 27, 33, 34, 37, 38, 40, 44, 47, 56], "rout": [5, 13, 20, 31, 48], "row": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 58], "rry": 46, "rsh": 37, "ru": [8, 38], "rubric": [18, 19, 36], "rule": [1, 8, 12, 13, 15, 18, 19, 20, 26, 29, 30, 31, 33, 36, 38, 40, 46, 51, 54, 56], "run": [1, 4, 5, 7, 10, 12, 14, 15, 17, 19, 21, 24, 27, 30, 32, 33, 35, 37, 38, 39, 41, 43, 44, 46, 47, 51, 52, 53, 55, 56], "runtimewarn": 37, "ruscorpora": 46, "rush": 42, "russel": 1, "rv": 37, "rv_continuous_frozen": 37, "rv_discrete_frozen": 37, "rvert_2": 46, "s1": [8, 46], "s19": [16, 23, 34], "s2": [8, 46], "s_lag": 48, "sa": 1, "sabr": 46, "sabrina": 1, "sadli": 46, "safe": [16, 23, 34], "safeti": 47, "sai": [8, 13, 15, 16, 17, 20, 22, 23, 24, 31, 33, 34, 35, 38, 39, 40, 41, 46, 48, 50, 54], "said": [14, 16, 18, 21, 23, 32, 34, 36, 41, 44, 45, 46, 50], "sal": [39, 41, 50], "sale": [8, 26, 38, 39, 48, 50, 56], "salecondit": [39, 41, 50], "salecondition_abnorml": 39, "salecondition_adjland": 39, "salecondition_alloca": 39, "salecondition_famili": 39, "salecondition_norm": 39, "salecondition_parti": 39, "salepric": [39, 41, 50], "sales_data": 48, "salesforc": 52, "saleswoman": 46, "saletyp": [39, 41, 50], "saletype_cod": 39, "saletype_con": 39, "saletype_conld": 39, "saletype_conli": 39, "saletype_conlw": 39, "saletype_cwd": 39, "saletype_new": 39, "saletype_oth": 39, "saletype_wd": 39, "salt": [18, 36, 41], "sam": 45, "same": [6, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 54, 55, 56], "samosa": 46, "sampl": [12, 13, 15, 16, 18, 20, 21, 22, 23, 27, 28, 31, 33, 34, 36, 37, 41, 44, 47, 48, 49, 50, 51, 55, 56], "sample_df": [38, 51], "sample_text": 52, "sampling_strategi": 38, "samuel": [12, 19, 30], "sand": 47, "sandbar": 47, "saniti": [13, 20, 31, 49], "sarah": 1, "sat": 48, "satisfactori": 43, "satisfi": 43, "satur": 50, "saturdai": 48, "sauc": 28, "save": [7, 8, 17, 24, 35, 37, 41, 46, 47, 48, 50, 52, 57], "saw": [16, 18, 23, 34, 36, 37, 38, 44, 54], "sb": 42, "scalabl": [12, 19, 30, 44], "scalar": 8, "scale": [14, 15, 17, 21, 22, 24, 26, 27, 32, 33, 35, 37, 38, 39, 40, 42, 44, 47, 49, 50, 51, 54, 56, 57], "scale_pos_weight": 40, "scaler": [16, 23, 28, 34, 41, 42], "scan": 54, "scari": 51, "scatter": [16, 23, 34, 39, 41, 42], "scatter_3d": 42, "scatterplot": [42, 51], "scc": 46, "scenario": [11, 14, 17, 21, 24, 32, 35, 40, 41, 42, 44, 48, 49, 51, 54], "schafer": 51, "schedul": [49, 54, 58], "schmidt": 37, "school": [12, 19, 30, 38, 40, 41, 45], "schoolteach": 46, "scienc": [1, 2, 9, 10, 11, 17, 24, 35, 43, 48, 50, 54, 56], "scientif": [45, 46], "scientist": [1, 9, 44], "scikit": [9, 10, 11, 13, 15, 18, 20, 22, 28, 31, 33, 36, 37, 38, 40, 43, 44, 47, 48, 50, 52, 53], "scipi": [10, 37, 44, 46], "scm": 5, "scope": [12, 19, 46, 48], "score": [11, 12, 15, 16, 17, 19, 22, 23, 24, 26, 27, 28, 29, 30, 33, 34, 35, 40, 41, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 58], "score_func": 39, "score_gb_test": 50, "score_gb_train": 50, "score_lr_print_coeff": 48, "score_param": [17, 24, 35], "score_rf_test": 50, "score_rf_train": 50, "score_tim": [14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 48, 49, 52], "scorer": [17, 24, 35, 39], "scores_dict": [18, 29, 36], "scores_imag": [18, 36], "scoring_method": 49, "scoring_metr": [40, 41, 52], "scotland": 46, "scott": 50, "scratch": [2, 47, 51], "screen": [7, 29], "screennam": 52, "screenplai": 46, "screenporch": [39, 41, 50], "screenshot": 50, "script": 10, "scroog": 52, "sdng": [39, 50], "se": [48, 49], "sea": 47, "seaborn": [41, 42, 43, 44, 45], "seacoast": 47, "search": [4, 5, 10, 39, 46, 54], "search_multi": 39, "seashor": 47, "season_autumn": 48, "season_fal": 48, "season_summ": 48, "season_wint": 48, "seat": [47, 58], "seattl": 52, "seawal": 47, "second": [4, 6, 13, 18, 19, 20, 31, 36, 40, 41, 44, 47, 48, 50], "secondari": [12, 19, 30], "secpompeo": 52, "section": [1, 7, 10, 14, 20, 31, 32, 42, 58], "secur": [41, 51, 58], "see": [1, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 54, 55, 56, 58], "seed": [18, 27, 36, 37, 43, 44, 51], "seem": [13, 15, 16, 17, 18, 20, 22, 23, 24, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 48, 49, 52, 53, 56], "seemingli": 38, "seen": [8, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 30, 32, 33, 34, 35, 36, 42, 44, 45, 49, 54, 56], "segment": [11, 38, 46, 47, 49, 51, 54], "segmentspher": 51, "select": [1, 5, 6, 10, 11, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 47, 48, 49, 50, 51], "select_dtyp": 39, "select_knn": 42, "select_rf": 42, "select_svc": 42, "selectfrommodel": 42, "self": [12, 17, 19, 24, 28, 30, 35, 49, 58], "sell": [0, 8, 13, 20, 31, 50], "semant": [11, 43, 44, 46], "semest": [12, 19, 58], "semi": [1, 12, 46], "semicolon": 8, "semilogx": 39, "send": [4, 12, 19, 30], "senior": 49, "seniorcitizen": 49, "sens": [6, 14, 17, 18, 21, 24, 29, 32, 35, 36, 38, 39, 41, 42, 43, 45, 46, 48, 49, 51, 53], "sensibl": [7, 51], "sensit": [14, 16, 21, 23, 32, 34, 37, 38, 39, 43, 49], "sent": [12, 19, 30, 46], "sent_token": 46, "sentenc": [46, 50], "sentiment": [13, 18, 29, 31, 36, 46, 52], "sentimentintensityanalyz": 52, "sepal": [15, 22, 27, 33, 56], "separ": [13, 14, 16, 17, 18, 20, 21, 23, 24, 28, 31, 32, 34, 35, 36, 38, 42, 43, 45, 46, 48, 53, 54, 55, 56, 57], "septemb": 48, "sequenc": [14, 17, 21, 24, 32, 35, 47, 48], "sequenti": [13, 20, 31, 40, 48, 49, 54], "sequentialfeatureselector": 42, "ser": [23, 32, 34, 49, 52], "seri": [1, 2, 11, 14, 16, 17, 21, 23, 24, 32, 34, 35, 38, 42, 47, 49, 51, 52], "serial": 40, "seriou": [6, 38, 45, 46, 49, 51, 58], "serv": [5, 11, 13, 20, 31, 41, 58], "server": 5, "servic": [28, 40, 41, 45, 49, 52], "session": [12, 13, 43, 54, 58], "set": [1, 7, 8, 9, 13, 15, 16, 17, 18, 20, 22, 23, 24, 27, 30, 31, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 54, 56, 57], "set_config": [37, 40], "set_index": [14, 15, 21, 22, 27, 32, 33, 37, 38, 39], "set_opt": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 44, 45, 55, 56, 57], "set_properti": [12, 19, 30], "set_se": 27, "set_titl": [15, 18, 22, 27, 33, 36, 38, 47, 56], "set_xlabel": [15, 18, 22, 27, 33, 36, 43, 56], "set_ylabel": [15, 18, 22, 27, 33, 36, 43, 56], "setup": [3, 7, 10, 12, 19, 55], "sev": [39, 41, 50], "sever": [10, 16, 18, 23, 34, 36, 43, 44, 46, 47, 48, 53, 58], "sex": [38, 40, 41, 42], "sexual": 58, "sfu": 46, "shall": [0, 46], "shallow": [29, 40], "shan": 46, "shap": 51, "shape": [13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56], "shape_df": [14, 21, 32], "shape_dict": [14, 21, 32], "share": [0, 28, 42, 51, 58], "sharealik": 1, "sharex": [16, 23, 34], "she": [12, 19, 30, 45, 46, 52], "shed": [39, 41, 50], "sheet": [9, 51, 54], "shelf": [40, 46], "shell": [5, 9, 12, 19], "shelv": 52, "shift": 48, "shipyard": 28, "shit": 52, "shng": [39, 50], "shop": 45, "short": [1, 10, 14, 32, 37, 40, 46, 58], "shorter": 49, "shorthand": [16, 23, 34], "shortli": 51, "shot": 42, "should": [5, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 38, 41, 42, 43, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58], "shouldn": [38, 40, 46, 56], "show": [4, 7, 10, 12, 14, 16, 17, 19, 21, 23, 24, 26, 27, 28, 30, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 51, 52, 54, 56], "show_nearest_neighbor": 27, "show_plot": 49, "showcas": 46, "shown": [7, 10, 12, 13, 15, 19, 20, 22, 30, 31, 33, 38, 40, 43, 44, 48, 50], "shrink": [37, 42, 50], "shuffl": [14, 21, 27, 32, 47, 48], "si": [12, 19, 30], "sibl": 42, "sick": [43, 52], "sid": 52, "side": [6, 47, 50], "sift": 45, "sigma": 47, "sign": [4, 29, 39, 41, 47, 56, 58], "signal": [14, 21, 32, 46], "signific": [11, 16, 23, 28, 34, 47, 50], "significantli": [17, 24, 35, 38, 45], "sigoptsearchcv": 37, "silhouett": 44, "silhouettevisu": [43, 44], "sim": 41, "sim_word": 46, "simard": 41, "similar": [1, 10, 13, 14, 17, 18, 19, 20, 21, 24, 27, 31, 32, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 49, 50, 53], "similarity_": 46, "similarli": [41, 43, 49], "simon_fras": 46, "simp": 48, "simpl": [1, 13, 15, 16, 20, 22, 23, 31, 33, 34, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51, 54, 55], "simplefilt": [40, 41], "simpleimput": [16, 17, 18, 23, 24, 34, 35, 36, 37, 38, 39, 40, 41, 42, 48, 49, 50, 54, 57], "simpleimputersimpleimput": [16, 17, 23, 24, 28, 34, 35, 39, 40, 42, 50], "simpler": [18, 26, 36, 37, 51, 56], "simplest": [17, 24, 35], "simpli": [16, 23, 34, 42, 43, 46], "simplic": [13, 17, 20, 24, 31, 35, 45], "simplist": [15, 22, 27, 33, 41, 56], "simul": 42, "sin": 8, "sinc": [5, 12, 18, 19, 27, 36, 39, 41, 42, 43, 45, 47, 48, 49, 50, 53, 54, 55], "singer_songwriter_bob_dylan": 46, "singl": [8, 15, 16, 18, 22, 23, 27, 33, 34, 36, 37, 38, 40, 41, 44, 48, 49, 54, 55, 56], "sit": [28, 58], "sitarist_ravi_shankar": 46, "site": [5, 12, 17, 20, 24, 27, 28, 31, 32, 35, 37, 41, 49, 53, 58], "situat": [6, 12, 19, 30, 38, 40, 43, 47, 49, 58], "six": [14, 32, 40, 48, 51], "size": [12, 13, 14, 15, 17, 19, 20, 21, 22, 24, 27, 30, 31, 32, 33, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 54, 55, 56, 58], "skeleton": 50, "skeptic": 50, "skew": 39, "skill": [11, 40, 51], "skin": 52, "skip_check_arrai": 28, "skip_parameter_valid": 28, "skipna": 49, "sklearn": [1, 12, 14, 15, 18, 19, 21, 22, 26, 27, 29, 30, 32, 33, 36, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "sklearn_gb": 40, "sklearn_histgb": 40, "sktime": 48, "skyblu": 48, "skyscrap": 48, "sl": 46, "slice": 8, "slide": [1, 9, 16, 23, 25, 34, 47, 58], "slightli": [17, 18, 24, 27, 28, 35, 36, 38, 40, 49], "slipper": 50, "slope": [18, 36], "sloppi": [16, 23, 34], "slot": 58, "slow": [15, 22, 33, 40, 42, 47], "slower": [40, 43], "sm": [12, 17, 19, 24, 30, 35], "smac": 37, "small": [10, 14, 15, 17, 21, 22, 24, 27, 28, 32, 33, 35, 37, 39, 40, 41, 42, 43, 45, 47, 49, 54, 56], "small_citi": [15, 22, 33], "small_train_df": [15, 22, 33], "smallalpha_coeff": 39, "smaller": [15, 16, 17, 18, 22, 23, 24, 26, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 48, 49, 50, 56], "smallest": [18, 36, 39, 43, 44], "smart": [43, 50, 52], "smile": 52, "smooth": [15, 22, 33, 56], "smoothli": 10, "smote_pip": 38, "sms_df": [12, 19, 30], "sn": [41, 43, 44], "snake": [18, 36, 47], "snake_length": [18, 36], "snakes_df": [18, 36], "snbf": 40, "snippet": [7, 12, 19], "snow": [12, 19, 30, 47], "snp": 42, "so": [0, 1, 4, 5, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58], "social": [43, 44, 45, 48], "societ": 11, "societi": [38, 46], "sofist": 56, "soft": [18, 28, 36, 40], "softmax": 54, "softwar": [1, 5, 10, 49], "solar": 45, "sold": [8, 39], "sole": [38, 44], "solidifi": 54, "solut": [12, 14, 19, 20, 21, 30, 31, 32, 40, 43, 49, 50, 51, 54, 58], "solv": [4, 12, 13, 15, 19, 20, 21, 22, 30, 31, 33, 42, 46, 50, 51, 56, 58], "solver": 38, "some": [4, 6, 7, 8, 10, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58], "someon": [12, 13, 14, 19, 20, 21, 30, 31, 32, 42, 49, 50], "someth": [4, 7, 10, 13, 17, 20, 24, 31, 35, 38, 39, 40, 41, 43, 48, 49, 50, 51, 54, 58], "sometim": [6, 13, 14, 17, 18, 20, 21, 24, 31, 32, 35, 36, 37, 40, 41, 46, 50, 51], "somewhat": 39, "somewher": [12, 19, 30, 39], "song": [15, 16, 23, 33, 34, 45, 52], "song_titl": [15, 16, 23, 33, 34, 37], "soon": [12, 15, 16, 19, 22, 23, 30, 33, 34, 48, 51], "sopha": [12, 19, 30], "sophist": [37, 41, 46], "sort": [1, 5, 13, 14, 16, 21, 23, 29, 31, 32, 34, 41, 45, 46, 47, 48, 51], "sort_index": [8, 37, 39, 48], "sort_valu": [16, 17, 18, 23, 24, 26, 29, 34, 35, 36, 37, 39, 40, 41, 42, 48, 49, 52], "sound": [41, 42], "soundtrack": 46, "sourc": [10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 28, 30, 31, 32, 33, 34, 35, 37, 40, 41, 42, 43, 44, 45, 46, 47, 52, 55, 58], "south": [17, 35], "space": [15, 18, 20, 22, 33, 36, 37, 42, 43, 44, 46, 52, 58], "spaci": 42, "spacymoji": 52, "spam": [14, 21, 32, 38, 43], "spam_predict": [12, 19, 30], "span": [46, 48], "spanish": [16, 23, 34], "spars": [12, 15, 18, 19, 22, 28, 33, 36, 40, 45, 46, 54], "sparse_output": [16, 17, 23, 24, 28, 34, 35, 38, 39, 40, 41, 48, 49, 50, 54], "spatial": [18, 36], "speak": [5, 51], "spearmint": 37, "speci": [15, 22, 27, 33, 54, 56], "special": [11, 12, 17, 19, 24, 30, 35, 45, 46, 47, 48, 49, 56], "specialti": [38, 40, 41], "specif": [8, 11, 13, 14, 20, 21, 28, 31, 32, 37, 38, 41, 43, 45, 46, 47, 48, 49, 50, 51, 54, 56], "specifi": [8, 13, 14, 17, 20, 21, 24, 27, 31, 32, 35, 37, 38, 43, 44, 47, 50, 51], "spectrogram": 42, "speech": [42, 46, 52], "speechi": [15, 16, 23, 33, 34, 37], "speed": [8, 13, 20, 29, 31, 40, 47, 51], "spell": [12, 19, 30], "spend": [12, 16, 19, 23, 28, 30, 34, 42, 50, 52, 58], "spent": [6, 16, 23, 34, 42], "spheric": [44, 54], "spici": 43, "spini": 47, "spit": 47, "split": [11, 13, 15, 17, 18, 20, 22, 24, 29, 31, 33, 35, 36, 37, 39, 40, 42, 45, 46, 49, 51, 52, 54], "split0_test_r2": 39, "split0_test_scor": 37, "split0_train_neg_mean_squared_error": 39, "split0_train_scor": 37, "split1_test_r2": 39, "split1_test_scor": 37, "split1_train_neg_mean_squared_error": 39, "split1_train_scor": 37, "split2_test_r2": 39, "split2_test_scor": 37, "split2_train_neg_mean_squared_error": 39, "split2_train_scor": 37, "split3_test_r2": 39, "split3_test_scor": 37, "split3_train_neg_mean_squared_error": 39, "split3_train_scor": 37, "split4_test_scor": 37, "split4_train_neg_mean_squared_error": 39, "split4_train_scor": 37, "spoken": [17, 24, 35], "sport": [46, 47, 48], "spot": [38, 39, 51, 56], "spotifi": [15, 33, 45], "spotify_df": [15, 16, 23, 33, 34, 37], "spotlight": [5, 10], "spous": [38, 40, 41], "spread": 44, "spring_month": 48, "sqft": 41, "sqft_abov": [12, 13, 19, 26, 30, 31], "sqft_basement": [12, 13, 19, 26, 30, 31], "sqft_live": [12, 13, 19, 26, 30, 31], "sqft_living15": [12, 13, 19, 26, 30, 31], "sqft_lot": [12, 13, 19, 26, 30, 31], "sqft_lot15": [12, 13, 19, 26, 30, 31], "sqrt": [15, 22, 33, 39, 41, 45, 46], "squar": [8, 11, 13, 15, 18, 20, 22, 31, 33, 36, 41, 45, 49, 50, 52, 54], "squash": [18, 36, 47], "squeez": [8, 28, 49], "src": [21, 32, 38], "sse": 48, "ssw": 48, "st": [48, 52], "stabil": 10, "stabl": [14, 21, 28, 32, 38, 40, 56], "stack": [7, 11, 28, 51, 54], "stacking_model": 40, "stacking_model_tre": 40, "stackingclassifi": 40, "stackingregressor": 40, "staff": 6, "stai": [12, 19, 38, 49], "stakehold": [11, 50, 51], "stale": 43, "stand": [15, 22, 33, 37, 46, 51], "standard": [4, 6, 14, 16, 21, 23, 32, 34, 37, 40, 41, 42, 46, 51], "standardscal": [17, 18, 24, 28, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 54, 57], "standardscalerstandardscal": [16, 17, 23, 24, 28, 34, 35, 37, 38, 39, 40, 42, 47, 50, 52], "stanford": 46, "star": [15, 22, 33, 43, 45, 52], "start": [7, 8, 10, 13, 14, 15, 20, 21, 22, 27, 28, 31, 32, 33, 38, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57], "startswith": 41, "starttim": 48, "stat": [37, 49], "state": [6, 8, 14, 21, 32, 38, 40, 41, 45, 46, 51, 52], "statement": [7, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 32, 33, 34, 35, 36, 37, 38, 39, 42, 47, 49, 50], "static": [12, 19, 51], "station": 48, "statist": [1, 9, 11, 13, 18, 20, 31, 36, 41, 45, 46, 49], "statistician": [15, 22, 33], "statlib": [18, 36], "statsmodel": [48, 49], "statu": [38, 40, 41], "status_marri": 41, "status_nev": 41, "std": [14, 15, 16, 21, 22, 23, 26, 27, 28, 32, 33, 34, 38, 39, 47, 48, 52, 53], "std_cv_error": [14, 21, 32], "std_cv_score": [15, 22, 27, 33], "std_fit_tim": [37, 39], "std_score": [14, 16, 21, 23, 32, 34, 52], "std_score_tim": [37, 39], "std_test_neg_mean_squared_error": 39, "std_test_scor": [14, 21, 32, 37], "std_train_error": [14, 21, 32], "std_train_neg_mean_squared_error": 39, "std_train_scor": [14, 15, 21, 22, 27, 32, 33, 37], "stdki": 49, "stem": 46, "step": [7, 12, 14, 15, 16, 17, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58], "stereotyp": 46, "stick": [13, 29, 48], "still": [4, 10, 20, 37, 38, 39, 40, 42, 43, 48, 49, 52, 56, 57], "stipul": 50, "stochast": [42, 43], "stock": [12, 19, 30, 48], "stop": [8, 26, 28, 43, 46, 47, 49, 56], "stop_word": [28, 29, 37, 38, 46, 51, 52], "stopword": 46, "storag": [15, 33], "store": [7, 8, 15, 16, 17, 22, 23, 24, 33, 34, 35, 37, 38, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52], "stori": [39, 40, 52], "storylin": 46, "str": [27, 37, 41, 46, 48, 49, 52], "straight": [49, 51], "straightforward": 41, "strain": 7, "strang": [41, 49], "strata": 49, "strategi": [13, 15, 16, 17, 20, 22, 23, 24, 28, 31, 33, 34, 35, 38, 39, 41, 43, 45, 48, 49, 50, 51, 54, 55], "stratif": 49, "stratifi": 49, "stratifiedkfold": [14, 21, 32, 38], "stream": 49, "streamingmovi": 49, "streamingmovies_no": 49, "streamingmovies_y": 49, "streamingtv": 49, "streamingtv_no": 49, "streamingtv_y": 49, "street": [39, 41, 50], "street_grvl": 39, "street_pav": 39, "strength": [46, 54], "stress": 43, "strftime": [48, 49], "string": [8, 10, 15, 22, 28, 33, 38, 39, 40, 41, 46, 48, 49, 56], "strip": [41, 47], "strong": [40, 49, 54], "stronger": 40, "strongli": 40, "structur": [8, 43, 46, 47], "struggl": [43, 48], "stuart": [1, 40], "stuck": [4, 8], "student": [1, 4, 5, 6, 7, 11, 12, 13, 18, 19, 20, 30, 31, 36, 38, 39, 41, 42, 43, 44, 45, 47, 51, 52, 58], "studi": [12, 17, 19, 24, 30, 35, 42, 46, 49], "stuff": [15, 22, 27, 33, 47, 49], "stump": [13, 14, 15, 20, 21, 22, 26, 31, 32, 33, 40, 55], "stupid": 52, "style": [30, 39, 42, 43, 45, 46, 47, 51, 52], "sub": [29, 37, 43, 46, 49, 51, 54], "subdirectori": [41, 51], "subgroup": 49, "subject": [0, 1, 49, 58], "sublicens": 0, "submiss": [3, 58], "submit": [1, 8, 16, 19, 51, 58], "subplot": [14, 15, 18, 21, 22, 27, 32, 33, 36, 38, 43, 47, 49, 50, 56], "subplot_kw": [14, 21, 27, 32], "subprocess": 39, "subscrib": 49, "subscript": [48, 49], "subset": [13, 14, 20, 21, 27, 31, 32, 37, 40, 47, 48, 53, 56], "substanti": 0, "substitut": 0, "subtl": 46, "subtleti": [14, 21, 32, 39], "subtract": [15, 19, 22, 33, 38, 41], "suburb": 52, "subword": 46, "succe": [42, 58], "success": [5, 8, 10, 12, 19, 30, 38, 40, 45, 46, 47, 48, 51], "successfulli": [10, 12, 19, 30, 52], "sudo": 5, "suei": 37, "suffer": 37, "suffici": [7, 46], "suggest": [0, 1, 13, 20, 29, 31, 45, 49, 51], "suicid": 46, "suit": [23, 45], "suitabl": [10, 11, 12, 19, 26, 30, 43, 45, 51, 54], "sultan": 46, "sum": [8, 15, 16, 17, 18, 22, 23, 24, 28, 33, 34, 35, 36, 40, 41, 43, 47, 52], "sum_": [15, 22, 33, 39, 43, 46, 47], "sum_i": [41, 46], "sum_prob_ex1_class_0": 40, "sum_prob_ex1_class_1": 40, "summar": [1, 12, 18, 19, 30, 36, 38, 39, 43, 46, 51], "summari": [0, 53, 54, 56], "summary_plot": 41, "summat": [40, 50], "summer": [45, 48], "summer_month": 48, "sun": [46, 48], "sundai": 48, "sundial": 47, "sunshin": 48, "sunstrum": [1, 58], "super": [17, 24, 35, 54], "superfici": [15, 22, 33], "superior": 11, "supermarket": 52, "supervis": [11, 16, 17, 23, 24, 28, 34, 35, 37, 38, 39, 42, 44, 46, 48, 49, 54, 58], "suppli": 58, "support": [10, 13, 16, 20, 23, 27, 28, 31, 34, 38, 40, 41, 42, 44, 46, 50, 52, 53, 56, 58], "support_": [15, 22, 33, 42], "suppos": [12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 50, 54, 55], "suppress": 8, "suprem": 46, "supr\u00eam": 46, "sure": [4, 7, 8, 10, 13, 14, 15, 16, 17, 22, 24, 32, 33, 35, 38, 39, 40, 41, 44, 47, 48, 50, 51, 56, 58], "surfac": 20, "surgeri": 49, "surpris": [41, 45], "surprisingli": [17, 18, 24, 35, 36], "surround": [4, 11, 50], "survei": [28, 43], "surviv": [1, 2, 11, 50, 51], "survival_function_": 49, "suscept": [44, 51], "suspect": 37, "svc": [15, 16, 17, 18, 22, 23, 24, 27, 28, 33, 34, 35, 36, 37, 40, 41, 42, 47, 56, 57], "svc__c": 37, "svc__gamma": 37, "svc_pipe": 37, "svc_pred": 38, "svcsvc": [17, 24, 35, 37, 38], "svm": [1, 14, 16, 17, 21, 23, 24, 28, 32, 34, 35, 37, 40, 41, 42, 47, 48, 50, 51, 53, 54, 56, 57], "svm_estim": 38, "svr": [15, 22, 33, 35, 41, 50], "svr_c_pipe": 35, "svr_pipe": 35, "sw": 48, "swai": [12, 30], "swamp": [15, 22, 33], "swan": 47, "swcarpentri": 9, "sweep": 38, "sweet": 52, "switch": [13, 41, 43, 48, 49, 50], "swng": [1, 58], "sy": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 54, 55, 56, 57], "sydnei": 48, "syllabu": [3, 7, 12, 13, 15, 16, 17, 19], "symbol": [20, 31], "symmetri": 42, "sync": 5, "synonym": 46, "synopsi": 46, "syntact": 46, "syntax": [4, 8, 12, 19, 30, 42, 49], "synthet": [42, 53], "system": [1, 2, 4, 5, 6, 10, 11, 12, 14, 15, 17, 19, 21, 27, 30, 32, 33, 35, 38, 41, 43, 48, 50, 51], "systemat": [13, 20, 31, 35, 37, 41, 46], "t": [1, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56], "t2a": 58, "t2b": 58, "t2c": 58, "t2d": 58, "t2e": 58, "t2f": 58, "t2g": 58, "t2h": 58, "t2i": 58, "t2j": 58, "t2k": 58, "ta": [7, 12, 19, 30, 39, 41, 50, 51, 55, 56, 57], "tab": [12, 19], "tabbi": [12, 19, 30, 47], "tabl": [7, 28], "tabular": [8, 12, 19, 27, 30, 47, 48], "tackl": [14, 16, 21, 23, 32, 34, 38, 44, 56], "taco": 42, "tag": [4, 46, 52], "tail": [8, 48], "tailor": [11, 43, 50, 51], "take": [2, 4, 5, 6, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58], "taken": [48, 53, 58], "talk": [13, 14, 16, 18, 20, 21, 23, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53, 54, 58], "tall": 46, "target": [14, 15, 16, 18, 21, 22, 23, 27, 28, 29, 32, 33, 34, 36, 37, 38, 40, 41, 42, 45, 47, 48, 49, 50, 51, 54, 56, 57], "target_column": [40, 41, 49], "target_nam": 38, "target_names_toi": 38, "target_tag": 28, "tariff": 46, "task": [11, 16, 17, 18, 23, 24, 26, 27, 34, 35, 36, 37, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 54], "tast": [28, 43, 45], "tasti": 28, "taught": [17, 24, 35, 46, 58], "tax": 50, "tba": 1, "teach": [4, 12, 16, 19, 23, 30, 34, 46, 54], "team": [4, 8, 12, 19, 30, 40, 41, 46], "tech": [15, 33, 38, 41], "technic": [50, 51, 58], "techniqu": [1, 11, 12, 15, 22, 33, 37, 42, 45, 47, 49, 51, 53, 54], "technolog": 0, "technologi": 46, "techsupport": 49, "techsupport_no": 49, "techsupport_y": 49, "ted": 43, "tediou": 44, "telco": 49, "telecom": 49, "telephon": 46, "tell": [14, 15, 16, 18, 21, 23, 32, 33, 34, 36, 38, 41, 42, 45, 46, 48, 49, 50, 51, 56], "temp3pm": 48, "temp9am": 48, "temperatur": [13, 20, 31], "templat": 51, "tempo": [15, 16, 23, 33, 34, 37], "tempor": [49, 54], "tend": [14, 15, 18, 21, 22, 32, 33, 36, 40, 42, 45, 48, 49, 58], "tendenc": [14, 21, 32], "tensor": [27, 47], "tensorflow": [10, 41, 47], "tent": 12, "tenur": [49, 50, 54], "tenure_lm": 49, "tenure_predict": 49, "term": [0, 2, 13, 15, 17, 18, 20, 22, 24, 31, 33, 35, 36, 38, 41, 42, 45, 46, 49, 50, 51, 54], "termin": [5, 10, 13, 31, 43, 51], "terminologi": [14, 32, 38, 54, 55], "terrac": 47, "terribl": [39, 45], "territori": 58, "tesoro": 37, "test": [1, 7, 8, 10, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 44, 49, 50, 51, 53, 54, 56, 58], "test_accuraci": 38, "test_average_precis": 38, "test_df": [12, 16, 18, 19, 23, 29, 30, 34, 35, 36, 38, 39, 40, 41, 42, 48, 49, 50, 51, 52, 57], "test_df_churn": 49, "test_df_nan": [38, 40, 41], "test_df_sort": 48, "test_df_surv": 49, "test_exampl": 40, "test_f1": 38, "test_format": [15, 22, 33], "test_g50k": 40, "test_idx": 27, "test_imag": [12, 19, 30, 47], "test_l50k": 40, "test_mape_scor": 39, "test_nam": 49, "test_neg_mean_squared_error": 39, "test_neg_root_mean_square_error": 39, "test_point": [15, 22, 33, 53], "test_precis": 38, "test_r2": 39, "test_recal": 38, "test_roc_auc": 38, "test_scor": [14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 48, 49, 52, 56], "test_shap_valu": 41, "test_siz": [12, 15, 16, 18, 19, 22, 23, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 47, 48, 50, 51, 52, 53, 56, 57], "test_sklearn": 39, "test_statist": 49, "test_x": 49, "testabl": 19, "text": [1, 7, 11, 12, 13, 18, 19, 20, 23, 29, 30, 31, 36, 37, 38, 39, 40, 41, 42, 45, 47, 50, 51, 54], "text_feat": 37, "text_featur": 52, "text_pip": 28, "text_pp": 46, "text_transform": 28, "textbook": [3, 9, 50], "textrm": [14, 21, 32], "textual": 11, "textur": 42, "tf": [17, 24, 35], "tfidfvector": [18, 29, 36], "th": [12, 18, 19, 36, 45], "thai": 28, "than": [6, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 53, 55, 56, 58], "thank": [12, 19, 30, 46, 56], "thankfulli": 48, "thei": [1, 7, 8, 13, 14, 15, 18, 19, 20, 21, 22, 28, 31, 32, 33, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 58], "theirs": 46, "them": [1, 2, 4, 7, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 58], "theme": 46, "themselv": [43, 44, 46], "theoret": [16, 23, 34, 38, 40, 54], "theori": 41, "thepopbreak": 52, "therefor": [19, 56], "thermostat": [13, 20, 31], "thi": [0, 1, 2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 18, 20, 21, 22, 27, 29, 31, 32, 33, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58], "thick": [28, 43], "thing": [1, 5, 7, 8, 12, 13, 14, 15, 19, 20, 21, 22, 29, 31, 32, 33, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 56], "think": [4, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 28, 30, 31, 32, 33, 35, 36, 38, 39, 41, 42, 43, 45, 47, 48, 49, 50, 51, 54, 55, 56], "third": 44, "thk": [12, 19, 30], "thorough": 10, "thoroughli": 54, "those": [5, 8, 10, 11, 12, 16, 19, 23, 34, 39, 40, 41, 45, 46, 49, 50, 51, 58], "though": [14, 17, 18, 20, 21, 24, 28, 32, 35, 36, 43, 44, 45, 51, 52], "thought": [4, 15, 22, 33, 41, 49, 54], "thousand": [18, 36, 44, 45], "thrasher": 46, "threahold": 42, "threaten": 52, "three": [8, 13, 16, 18, 23, 27, 31, 34, 36, 38, 40, 41, 42, 43, 44, 46, 47, 48, 53, 54, 58], "thresh": 8, "threshold": [13, 18, 20, 31, 36, 40, 42, 44, 46, 49], "thresholds_lr": 38, "thresholds_svc": 38, "through": [1, 7, 10, 12, 13, 19, 20, 31, 38, 39, 42, 44, 45, 46, 47, 50, 58], "throughout": [14, 21, 32, 50], "throught": [19, 58], "throw": [17, 24, 35, 47, 49, 50, 54], "thu": [1, 6, 12, 37, 48, 49, 58], "thumb": [13, 20, 31, 52], "thursdai": [12, 58], "ti": [17, 24, 35], "tianyu": [1, 58], "tick": 48, "tick_label": 41, "tick_param": 43, "tiffin": 46, "tiger": [12, 19, 30, 47], "tight": [15, 22, 27, 33, 44, 56], "tight_layout": [47, 50], "tightrop": [15, 22, 27, 33, 56], "tile": 41, "till": [15, 22, 33, 46, 49], "timber": 46, "time": [1, 2, 4, 8, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58], "time_diff": 48, "time_signatur": [15, 16, 23, 33, 34, 37], "timedelta": 48, "timeit": [8, 53], "timelin": 50, "timeseri": [47, 48], "timeseriessplit": [48, 49, 54], "timestamp": 48, "timezon": [1, 49], "tinder": 45, "tini": [7, 14, 21, 32, 38, 44], "tip": 46, "tire": 52, "titan": 45, "titi": [12, 19, 30], "titl": [7, 14, 15, 18, 21, 22, 26, 27, 32, 33, 36, 39, 42, 44, 47, 48, 49, 50, 56], "tldr": [12, 19], "tmp": 28, "tn": 38, "to_datetim": [26, 48], "to_html": [12, 13, 14, 19, 21, 30, 31, 32], "to_notebook_ifram": 39, "to_numpi": [15, 22, 33, 45, 48], "to_str": [12, 19, 30, 47], "toarrai": [17, 24, 29, 35, 41, 48], "tobago": [40, 41], "todai": [13, 20, 31, 45, 47, 48, 49, 51, 54], "todens": [41, 42], "togeth": [5, 8, 12, 13, 15, 16, 17, 19, 20, 22, 23, 24, 28, 31, 33, 34, 35, 43, 46, 56], "toi": [8, 14, 15, 21, 22, 32, 33, 42, 43, 44, 45, 48, 54], "toilet": [47, 52], "token": [7, 19, 52, 58], "token_pattern": [17, 24, 35], "tol": [38, 42, 50], "told": [5, 58], "tolist": [12, 13, 14, 17, 18, 19, 20, 21, 24, 26, 27, 28, 29, 30, 31, 32, 35, 36, 38, 39, 40, 41, 42, 43, 45, 48, 49, 52], "tomasbeuzen": 8, "tomorrow": [13, 16, 17, 20, 31, 48, 49, 54], "ton": 37, "tone": 52, "too": [6, 7, 14, 15, 17, 21, 22, 23, 24, 27, 32, 33, 35, 37, 39, 40, 41, 46, 48, 49, 50, 51, 56, 58], "took": 48, "tool": [1, 7, 8, 10, 11, 17, 18, 24, 29, 35, 36, 38, 39, 41, 44, 45, 47, 48, 49, 51, 54, 58], "toolbox": [15, 22, 33, 40, 46], "toolkit": 46, "top": [13, 17, 20, 24, 29, 31, 35, 37, 38, 44, 48, 50, 51], "topi": 46, "topic": [1, 2, 8, 11, 13, 20, 31, 38, 39, 43, 45, 47, 51, 54, 58], "topic2vec": 46, "topics_per_chunk": 46, "topn": [12, 19, 30, 47], "torch": [27, 47], "torchvis": [12, 19, 27, 30, 47], "toronto": [46, 50, 52], "tort": 0, "total": [1, 8, 13, 16, 17, 20, 23, 24, 31, 34, 35, 38, 39, 40, 41, 42, 46, 48, 49, 50], "total_bedroom": [16, 23, 34, 35, 42, 57], "total_bilirubin": [12, 19, 30], "total_protien": [12, 19, 30], "total_room": [16, 23, 34, 35, 42, 57], "total_second": 48, "totalbsmtsf": [39, 41, 50], "totalcharg": 49, "totem": 47, "totensor": [27, 47], "toti": [0, 1, 46, 58], "totrmsabvgrd": [39, 41, 50], "touch": 51, "toward": [18, 29, 36, 41, 46, 58], "towardsdatasci": [47, 49], "town": 52, "townsvil": 48, "toy_clust": 46, "toy_clust_df": 43, "toy_df": [17, 24, 35, 46], "toy_lda_data": 46, "toy_movie_feat": 45, "toy_rat": 45, "toy_spam": [17, 24, 35], "toy_x": 46, "tp": 38, "tpot": 37, "tpr": 38, "tpr_lr": 38, "tpr_svc": 38, "tr_score": [26, 56], "traceback": [4, 8, 17, 24, 28, 35, 49], "track": [1, 17, 24, 35, 51, 58], "trade": [11, 18, 36, 38, 42, 43, 54], "tradeoff": [15, 16, 18, 22, 23, 26, 33, 34, 36, 39, 42, 43, 47], "tradit": [12, 19, 30, 45, 47, 49, 58], "tradition": 58, "trail": 8, "train": [7, 15, 16, 22, 23, 26, 27, 28, 29, 33, 34, 37, 39, 40, 41, 42, 43, 45, 46, 49, 52, 53, 54, 55, 56, 57], "train_accuraci": 38, "train_dataload": 47, "train_df": [12, 16, 18, 19, 23, 29, 30, 34, 35, 36, 38, 39, 40, 41, 42, 48, 49, 50, 51, 52, 57], "train_df_churn": 49, "train_df_nan": [38, 40, 41], "train_df_ord": 48, "train_df_sort": 48, "train_df_surv": 49, "train_df_surv_not_churn": 49, "train_dir": 27, "train_f1": 38, "train_flatten": 47, "train_for_usr": 45, "train_load": 47, "train_mape_scor": 39, "train_mat": 45, "train_mat_imp": 45, "train_neg_mean_squared_error": 39, "train_neg_root_mean_square_error": 39, "train_precis": 38, "train_r2": 39, "train_recal": 38, "train_scor": [14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 48, 49, 52, 56], "train_shap_valu": 41, "train_sklearn": 39, "train_test_split": [12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 47, 48, 49, 50, 51, 52, 53, 56, 57], "train_x": 45, "transact": [13, 20, 31, 38, 48, 50], "transfer": [49, 51], "transfer_learning_tutori": 47, "transform": [0, 15, 22, 27, 28, 29, 33, 37, 38, 40, 41, 44, 46, 47, 48, 49, 51, 52, 54, 56, 57], "transformed_exampl": 40, "transformed_oh": [16, 23, 34], "transformedtargetregressor": [39, 42, 50, 54], "transformedtargetregressortransformedtargetregressor": 39, "translat": [1, 9, 12, 19, 30], "transpar": [38, 54], "transpos": [27, 42, 47], "trasform": [16, 23, 34], "trash": 55, "traumat": 58, "treat": [8, 16, 17, 23, 24, 32, 34, 35, 38, 39, 45, 48, 49, 50, 52, 54], "treati": 58, "treatment": [17, 24, 35], "tree": [1, 2, 14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 29, 32, 33, 34, 35, 36, 37, 39, 42, 44, 47, 48, 49, 51, 53, 54, 55, 57], "tree1": 40, "tree2": 40, "tree3": 40, "tree_numeric_transform": 41, "treeexplain": 41, "trend": [11, 49, 54], "tri": [20, 40, 41, 50, 53], "trial": [37, 49], "triangl": [15, 22, 33, 43], "trick": [5, 39], "tricki": [17, 24, 35, 37, 41, 45], "trigger": [15, 22, 33], "trigram": 46, "trivial": 44, "troubl": 10, "true": [8, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 51, 52, 53, 56], "truli": [39, 46], "truncat": 44, "truncate_mod": 44, "truncation_mod": 44, "trust": [12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 34, 35, 37, 38, 39, 40, 41, 42, 45, 47, 50, 52], "trustworthi": 44, "truth": [40, 42, 43, 44, 45, 48], "try": [1, 4, 5, 8, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 26, 27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 56, 58], "tsa": 48, "tscv": 48, "tslearn": 48, "tsunami": [12, 30], "ttr": 39, "ttr_pipe": 39, "tue": [1, 12, 13, 48, 58], "tuesdai": [1, 12, 19, 42, 48, 58], "tuggeranong": 48, "tumor": 54, "tune": [14, 21, 26, 32, 37, 40, 44, 45, 47, 50, 51], "turn": [4, 14, 21, 27, 32, 46, 47, 49, 57, 58], "tusker": 47, "tutori": [1, 4, 5, 9, 10, 12, 19, 45, 47, 51, 54, 58], "tweak": [15, 22, 27, 33, 56], "tweet": [46, 52], "tweetat": 52, "twice": [8, 14, 17, 18, 24, 32, 35, 36], "twinx": 50, "twist": 46, "twitter": 46, "twitter_allowed_char": 52, "two": [4, 6, 7, 8, 9, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 28, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 57, 58], "two_citi": [15, 22, 33], "two_song": [16, 23, 34], "two_songs_subset": [16, 23, 34], "tx": [18, 36, 52], "tx_i": 50, "txt": [12, 19, 30, 47, 51], "typ": [39, 41, 50], "type": [4, 8, 10, 11, 13, 15, 16, 17, 20, 23, 24, 28, 31, 33, 34, 35, 37, 40, 42, 44, 45, 46, 47, 51, 54, 56, 57], "typeerror": 49, "typic": [2, 7, 12, 13, 15, 16, 18, 19, 20, 22, 23, 30, 31, 33, 34, 36, 37, 38, 39, 40, 41, 43, 45, 48, 50, 51], "u": [4, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 55, 56, 57], "u6": [13, 20, 31], "u_1": [15, 22, 33], "u_2": [15, 22, 33], "u_i": [15, 22, 33], "u_n": [15, 22, 33], "ubc": [0, 4, 5, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58], "ubc_img": 47, "ubc_okanagan": 46, "ubco": 46, "ubyssei": 46, "ucsb": 9, "ud036": 9, "udac": 9, "ufunc": 39, "ufv": 46, "uint8": 27, "ultim": [4, 14, 21, 32, 50], "ultralyt": 47, "uluru": 48, "umbrella": 45, "un": [39, 49], "unabl": [12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 34, 35, 37, 38, 39, 40, 41, 42, 44, 47, 49, 50, 52, 58], "unambigu": 46, "unassign": [43, 44], "unbias": 38, "unced": 58, "uncertain": [18, 36], "uncertainti": [18, 36, 38, 50, 51], "unchang": 41, "uncia": [12, 19, 30, 47], "uncomfort": 45, "uncorrel": 41, "under": [0, 1, 7, 13, 14, 21, 28, 31, 32, 39, 46, 47, 49, 51], "under_sampl": 38, "underestim": 49, "underfit": [15, 18, 22, 26, 27, 33, 36, 37, 47, 56], "underli": [2, 41, 42, 43], "underneath": 7, "underpredict": 39, "undersample_pip": 38, "understand": [0, 1, 4, 7, 11, 12, 13, 14, 15, 17, 18, 19, 22, 24, 26, 27, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 54, 55, 58], "understood": 38, "unemploi": 49, "unexpect": [17, 18, 24, 35, 36, 37, 46], "unexplain": 39, "unf": [39, 41, 50], "unfinish": 39, "unfortun": [6, 37, 41, 43, 44], "uniform": [37, 38, 44], "unimport": [37, 41], "uninstal": 10, "uninterpret": 41, "unintuit": 8, "union": 8, "uniqu": [16, 17, 23, 24, 34, 35, 38, 39, 40, 41, 45, 46, 48, 49], "unit": [18, 28, 36, 38, 39, 40, 41, 46, 47, 49, 52], "unitless": 39, "univers": [1, 9, 46], "university_year": [17, 24, 35, 54], "unix": [5, 48], "unknown": [6, 46, 54], "unlabel": [12, 14, 19, 21, 30, 32, 44], "unless": [7, 19, 58], "unlik": [8, 12, 14, 15, 17, 19, 21, 22, 24, 32, 33, 35, 39, 41, 43, 44], "unlimit": 48, "unlucki": [14, 21, 32], "unmarri": [40, 41], "unnam": [12, 19, 30], "uno": 28, "unoffici": 58, "unqualifi": 38, "unreason": [6, 19, 39], "unrecogniz": [12, 19], "unreli": [14, 21, 32], "unrespond": [12, 19], "unscal": [16, 23, 34], "unseen": [13, 31, 42, 43, 47, 51, 56], "unsqueez": 47, "unstructur": 46, "unsupervis": [12, 19, 30, 45, 46, 47, 51, 58], "unsur": [7, 50], "until": [4, 13, 14, 20, 21, 31, 32, 37, 42, 43, 44, 46, 49, 50, 51], "unus": 56, "unusu": 28, "unwieldi": [13, 16, 20, 23, 31, 34], "unzip": [41, 52], "uoft": 46, "up": [7, 8, 13, 16, 17, 18, 20, 23, 24, 26, 28, 29, 30, 31, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 58], "uparrow": 44, "upcom": 43, "updat": [10, 15, 16, 17, 22, 23, 24, 27, 33, 34, 35, 40, 43, 56], "update_cent": 43, "update_plot": [15, 22, 27, 33, 56], "update_z": 43, "upei": 46, "upgrad": 46, "upload": 7, "upon": [0, 13, 14, 17, 20, 21, 24, 31, 32, 35, 38, 40, 41, 42, 43, 44, 46], "upper": [38, 49], "upperbound_pric": 28, "uppercas": 52, "upto": 48, "ur": [12, 19, 30], "urgent": [17, 24, 35, 46], "url": [4, 14, 21, 32, 38, 49, 51], "us": [0, 1, 2, 4, 5, 10, 11, 18, 26, 28, 29, 36, 37, 41, 44, 45, 48, 49, 51, 52, 54, 56, 57], "usa": [8, 14, 15, 18, 21, 22, 32, 33, 36, 46], "usabl": 51, "usag": [16, 17, 23, 24, 34, 35, 38, 39, 42, 46, 48, 49], "usec_": 49, "useless": [37, 41, 42], "user": [10, 12, 16, 17, 19, 20, 23, 24, 27, 30, 31, 32, 34, 35, 37, 40, 41, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54], "user_id": 45, "user_inverse_mapp": 45, "user_kei": 45, "user_mapp": 45, "user_nam": 45, "usernam": 52, "userwarn": [17, 20, 24, 27, 31, 32, 35, 40, 41], "usf": [17, 24, 35], "using_copy_on_writ": [28, 49], "using_cow": 49, "usual": [1, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 58], "utc": [48, 49], "utcnow": 49, "util": [5, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 47, 49, 50, 54, 55, 56, 57], "utilities_allpub": 39, "utilities_nosewa": 39, "utility_mat": 45, "uvic": 46, "v": [1, 3, 7, 17, 18, 24, 26, 27, 35, 36, 44, 46, 48, 49, 50, 54], "v1": [12, 19, 30, 38], "v10": 38, "v11": 38, "v12": 38, "v13": 38, "v14": 38, "v15": 38, "v16": 38, "v17": 38, "v18": 38, "v19": 38, "v2": [12, 19, 30, 38], "v20": 38, "v21": 38, "v22": 38, "v23": 38, "v24": 38, "v25": 38, "v26": 38, "v27": 38, "v28": 38, "v3": 38, "v4": 38, "v5": 38, "v6": 38, "v7": 38, "v8": 38, "v9": 38, "v_1": [15, 22, 33], "v_2": [15, 22, 33], "v_i": [15, 22, 33], "v_n": [15, 22, 33], "vacat": [18, 36], "vaccin": [50, 52], "vada_pav": 46, "vader": 52, "vader_lexicon": 52, "vader_senti": 52, "vain": 37, "val": [45, 49], "valenc": [15, 16, 23, 33, 34, 37, 52], "valid": [1, 15, 17, 20, 22, 24, 27, 28, 29, 31, 33, 35, 39, 40, 41, 42, 43, 45, 47, 49, 50, 51, 52, 54, 57], "valid_dataload": 47, "valid_dir": 27, "valid_flatten": 47, "valid_load": 47, "valid_mat": 45, "valid_sample_df": 40, "valid_sample_i": 40, "valid_sample_x": 40, "valid_scor": [26, 56], "valid_x": 45, "validate_data": 28, "validate_separ": 28, "valu": [7, 8, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "valuabl": [11, 42, 44, 58], "value_count": [13, 17, 20, 24, 26, 28, 31, 35, 38, 40, 41, 48, 49, 51, 52], "value_throttl": [15, 22, 27, 33, 56], "valueerror": [8, 16, 17, 23, 24, 28, 34, 35, 49], "values_format": 38, "vancouv": [46, 50], "vancouver_canuck": 46, "vanilla": [18, 36], "var": [23, 32, 34, 41, 52], "var_": 41, "varada": [0, 1, 20], "vari": [11, 13, 20, 31, 37, 40, 44, 49, 56], "variabl": [7, 8, 13, 16, 17, 18, 20, 23, 24, 26, 31, 34, 35, 36, 37, 39, 41, 42, 48, 49, 50, 56], "varianc": [39, 41, 44, 48, 56], "variant": [41, 44], "variat": [14, 18, 21, 32, 36, 38, 39, 42], "varieti": [12, 19, 30, 40, 46], "variou": [11, 12, 15, 19, 22, 27, 30, 33, 39, 41, 47, 48, 49, 50, 51, 54, 56], "vault": [14, 21, 32], "ve": [7, 8, 12, 14, 15, 19, 21, 22, 26, 27, 30, 32, 33, 38, 39, 41, 45, 46, 47, 48, 50, 51, 53], "vec": [17, 24, 29, 35, 46, 47], "vec1": 46, "vec1_i": 46, "vec2": 46, "vec2_i": 46, "vec8": [17, 24, 35], "vec8_binari": [17, 24, 35], "vec_binari": [17, 24, 35], "vecom": 37, "vector": [13, 18, 20, 23, 27, 31, 36, 38, 45, 47, 50, 56], "verb": [46, 52], "verbos": [12, 19, 30, 38, 40, 41, 50], "veri": [2, 4, 5, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 56, 58], "versa": [39, 56], "version": [1, 4, 5, 7, 8, 10, 12, 18, 20, 23, 28, 32, 34, 36, 37, 39, 41, 44, 46, 48, 49, 52, 53], "versu": 9, "vert": 41, "vertic": [13, 20, 31, 38, 48], "vgg": 47, "vgg16": [27, 47], "vgg16_weight": 47, "via": [4, 7, 10, 12, 19, 38, 42, 58], "vibe": 28, "vice": [39, 56], "video": [1, 7, 8, 9, 10, 26, 45, 47, 49, 50, 51, 56, 58], "vietnames": [16, 23, 34], "view": [6, 7, 10, 12, 13, 19, 26, 30, 31, 41, 44, 47, 48, 49, 50], "viewpoint": 45, "vif": 41, "vikski": 46, "violat": [16, 17, 23, 24, 34, 35, 49, 51, 58], "virginia": 47, "viridi": 37, "vision": [1, 51, 53], "visit": [8, 58], "visual": [1, 11, 13, 14, 15, 17, 18, 20, 21, 22, 24, 26, 29, 31, 32, 33, 35, 36, 38, 39, 40, 41, 43, 44, 47, 48, 49, 52, 54, 57], "visualize_coeffici": 29, "viu": 46, "viz": 50, "voc": [38, 40, 41], "vocab": [29, 46], "vocabulari": [17, 18, 24, 35, 36, 46], "vocabulary_": [17, 24, 35], "voic": [12, 19, 30], "volcano": [12, 30], "volum": 51, "vote": [15, 16, 22, 23, 33, 34, 40, 53], "voting_ndt": 40, "votingclassifi": 40, "votingclassifierinot": 40, "votingregressor": 40, "vyfj": [30, 31, 35, 36, 37, 38, 39, 40], "w": [10, 17, 18, 24, 35, 36, 39, 43, 46, 48, 50, 51], "w_0": [18, 36], "w_1": [18, 36], "w_1x_1": [18, 36], "w_2x_2": [18, 36], "w_3x_3": [18, 36], "w_4x_4": [18, 36], "w_d": [18, 36], "w_dx_d": [18, 36], "w_j": [18, 29, 36], "wa": [4, 5, 10, 14, 16, 17, 18, 19, 20, 21, 23, 27, 28, 29, 31, 32, 34, 36, 38, 40, 41, 45, 46, 47, 49, 50, 52, 53, 55, 56, 58], "wa_fn": 49, "wai": [0, 2, 6, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 56, 58], "wait": [4, 12, 15, 17, 19, 20, 22, 24, 30, 31, 33, 35, 49, 51, 58], "waitlist": [13, 58], "walk": [15, 22, 27, 33, 38, 51, 56], "walker": [12, 19, 30, 47], "wallabi": 47, "wang": [1, 58], "want": [4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 27, 28, 30, 31, 32, 33, 34, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 57, 58], "war": 45, "ward": 44, "warm": [16, 23, 34], "warm_start": [38, 50], "warn": [6, 12, 15, 17, 19, 21, 22, 24, 27, 32, 33, 35, 39, 40, 41, 49, 53], "warranti": 0, "washington": 52, "washroom": 58, "wasn": [28, 46], "wast": [4, 17, 24, 35, 50], "watch": [1, 10, 12, 15, 18, 19, 33, 36, 45, 46, 54], "watchfil": 27, "water": 50, "waterfal": 41, "waterfront": [12, 13, 19, 26, 30, 31], "wavelet": 42, "wb": 51, "wd": [39, 41, 50], "we": [1, 4, 5, 6, 7, 10, 12, 13, 15, 19, 20, 22, 27, 28, 29, 30, 31, 33, 44, 46, 47, 48, 52, 53, 54, 55, 56, 57, 58], "weak": 54, "weather": [13, 20, 31, 48, 51], "weatherau": 48, "web": [5, 12, 19, 46, 54], "web_api": 51, "web_appl": 51, "weblog": 46, "websit": [4, 10], "wed": 48, "wednesdai": [48, 58], "week": [1, 6, 14, 15, 16, 17, 19, 22, 23, 24, 32, 33, 34, 35, 38, 39, 40, 41, 45, 46, 48, 50, 58], "weekdai": 48, "weekend": [8, 48, 50], "weekli": [12, 52], "weight": [15, 19, 22, 27, 33, 40, 42, 45, 46, 47, 58], "weighted_averag": 38, "weinberg": 41, "weird": 39, "welcom": [55, 58], "well": [4, 5, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 54, 58], "wellyanto": [1, 58], "welsh": [12, 19, 30, 47], "went": [39, 52], "were": [0, 6, 12, 18, 19, 28, 35, 36, 38, 39, 46, 47, 48, 49, 50, 58], "weren": 46, "what": [7, 8, 9, 13, 15, 20, 22, 26, 27, 28, 29, 31, 33, 37, 44, 47, 48, 52, 53, 54, 55, 56, 57, 58], "whatev": 42, "when": [4, 6, 7, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58], "wher": 52, "where": [0, 1, 7, 10, 13, 14, 15, 18, 20, 21, 22, 23, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 50, 51, 54, 56], "wherea": [2, 13, 18, 20, 28, 31, 36, 37, 39, 41, 44, 50], "whether": [0, 4, 7, 8, 13, 14, 16, 17, 18, 20, 21, 23, 24, 28, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 44, 46, 48, 49, 51, 52, 55, 58], "which": [4, 6, 8, 10, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 39, 41, 42, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], "whichev": 40, "while": [14, 18, 20, 21, 23, 31, 32, 36, 37, 38, 40, 41, 43, 45, 46, 49, 52], "white": [38, 40, 41, 44, 46], "whitespac": [46, 49], "who": [4, 5, 6, 12, 19, 30, 38, 41, 43, 44, 46, 48, 49, 50, 51, 52, 54, 58], "whole": [14, 21, 32, 37, 39, 41, 45, 51], "whom": [0, 46, 52], "whose": 4, "why": [8, 14, 15, 20, 22, 26, 28, 32, 33, 38, 39, 40, 43, 44, 46, 48, 49, 54, 55, 56, 57], "wid": [38, 51], "wide": [10, 18, 36, 37, 40, 42, 45, 47, 50], "wider": [15, 22, 27, 33, 56], "widespread": 46, "widget": [15, 22, 27, 33, 38, 43, 44, 56], "width": [13, 14, 15, 20, 21, 22, 27, 31, 32, 33, 38, 46, 55, 56], "wife": [12, 30, 38, 40, 41], "wiki": [46, 50], "wiki_df": 46, "wiki_dict": 46, "wikipedia": [46, 47, 50], "wikipedia2vec": 46, "wild": [12, 14, 19, 21, 27, 30, 32, 47], "willing": 38, "win": [15, 17, 22, 24, 29, 33, 35, 40, 41, 42, 45, 53], "wind": [13, 20, 31], "winddir3pm": 48, "winddir3pm_miss": 48, "winddir3pm_ss": 48, "winddir3pm_ssw": 48, "winddir3pm_sw": 48, "winddir3pm_w": 48, "winddir3pm_wnw": 48, "winddir3pm_wsw": 48, "winddir9am": 48, "windgustdir": 48, "windgustspe": 48, "window": 49, "windsor": 52, "windspeed3pm": 48, "windspeed9am": 48, "wine_1": 8, "winter": 48, "winter_month": 48, "wire": 45, "wisdom": 40, "wish": [12, 13, 19, 20, 30, 31, 43, 50, 58], "within": [13, 16, 18, 20, 23, 27, 31, 34, 36, 40, 42, 43, 44, 49, 51, 54], "without": [0, 7, 12, 13, 19, 20, 30, 31, 38, 40, 41, 42, 45, 47, 48, 49, 50, 51, 58], "wnw": 48, "wolv": 44, "woman": 46, "wombat": 47, "won": [5, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 31, 32, 33, 35, 36, 42, 45, 46, 47, 48, 49, 51, 52], "wonder": [12, 14, 19, 30, 32], "wooddecksf": [39, 41, 50], "word": [11, 12, 18, 19, 26, 28, 29, 30, 36, 37, 38, 42, 43, 44, 45, 47, 48, 49, 50, 54, 58], "word1": 46, "word2": 46, "word2vec": [11, 46, 47], "word3": 46, "word_coeff_df": 29, "word_pair": 46, "word_token": [46, 52], "wordnet": 46, "wordnetlemmat": 46, "words_in_ex": 29, "work": [0, 4, 5, 7, 8, 10, 12, 15, 16, 17, 18, 19, 22, 23, 24, 28, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 54, 58], "workclass": [38, 40, 41], "workclass_feder": [40, 41], "workclass_loc": [40, 41], "workclass_miss": 41, "workclass_nev": [40, 41], "workclass_priv": [40, 41], "workclass_self": 41, "workclass_st": 41, "workclass_without": 41, "workflow": [13, 20, 31, 51, 58], "worksheet": 51, "world": [15, 16, 17, 18, 21, 22, 23, 24, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 54], "worm": 47, "worri": [12, 19, 30, 43, 44, 45], "wors": [13, 20, 31, 37, 39, 40, 49, 55], "worst": [38, 42, 43], "worth": [13, 15, 20, 22, 31, 33, 38, 39], "worthi": [18, 36], "would": [4, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 56, 57, 58], "wouldn": [17, 24, 35, 37, 46, 49], "wow": 41, "wrangl": 28, "wrap": [17, 24, 35], "wrapper": [28, 42], "write": [4, 7, 11, 12, 19, 30, 37, 41, 42, 43, 46, 50, 51, 52, 56, 58], "written": [7, 17, 24, 35, 41, 48, 50], "wrong": [10, 14, 18, 21, 28, 32, 36, 39, 42, 43, 49, 50], "wrote": [46, 48], "wsw": 48, "wtf": 51, "www": [9, 18, 36], "x": [4, 8, 10, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56], "x0": 42, "x0_male": 38, "x1": [42, 45], "x1x2": 42, "x2": [42, 44, 45], "x27": [16, 17, 23, 24, 28, 34, 35, 37, 38, 39, 40, 42, 47, 50, 52], "x_": [18, 29, 36], "x_1": [18, 36, 42, 43], "x_1x_2": 42, "x_2": [18, 36, 42, 43], "x_anim_train": 27, "x_anim_valid": 27, "x_binari": [13, 20, 31], "x_citi": [15, 22, 33], "x_count": [17, 24, 35], "x_d": [18, 36], "x_femal": 38, "x_hour": 48, "x_hour_week": 48, "x_hour_week_onehot": 48, "x_hour_week_onehot_poli": 48, "x_hour_week_onehot_poly_lag": 48, "x_i": [18, 36, 45], "x_imp_ohe_train": [16, 23, 34], "x_init": 43, "x_int": [17, 24, 35], "x_label": [13, 14, 15, 20, 21, 22, 31, 32, 33, 55], "x_lag_featur": 48, "x_lag_features_imp": 48, "x_male": 38, "x_mask": [17, 24, 35], "x_multi": 53, "x_n": 42, "x_orig": 44, "x_re": 38, "x_small_citi": [15, 22, 33], "x_spotifi": [15, 33, 37], "x_subset": [13, 14, 20, 21, 31, 32], "x_test": [12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 47, 48, 49, 50, 52, 53, 56, 57], "x_test_big": 37, "x_test_cat": 28, "x_test_cat_oh": 28, "x_test_enc": [41, 48, 49, 50], "x_test_happi": [38, 51], "x_test_imp": [16, 23, 34], "x_test_multi": 53, "x_test_num": 28, "x_test_num_imp": 28, "x_test_num_imp_sc": 28, "x_test_pr": 48, "x_test_predict": [16, 23, 34], "x_test_scal": [16, 23, 34], "x_test_transform": [16, 23, 34], "x_toi": [15, 16, 17, 22, 23, 24, 33, 34, 35, 48], "x_toy_oh": [16, 23, 34], "x_toy_ord": [16, 17, 23, 24, 34, 35], "x_tr": [26, 56], "x_train": [12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 47, 48, 49, 50, 52, 53, 56, 57], "x_train_big": 38, "x_train_cat": 28, "x_train_cat_oh": 28, "x_train_enc": [38, 39, 41, 48, 49, 50], "x_train_happi": [38, 51], "x_train_hous": 42, "x_train_imp": [16, 23, 34], "x_train_imp_sc": [16, 23, 34], "x_train_multi": 53, "x_train_num": 28, "x_train_num_imp": 28, "x_train_num_imp_sc": 28, "x_train_oversampl": 38, "x_train_perm": 41, "x_train_pp": 35, "x_train_predict": [16, 23, 34], "x_train_scal": [16, 23, 34, 42], "x_train_subsampl": 38, "x_train_tini": 37, "x_train_transform": [16, 23, 34], "x_train_usr": 45, "x_transform": [17, 24, 35], "x_valid": [26, 27, 38, 45, 56], "x_vari": 44, "x_xor": 42, "xanni": 37, "xavier": [42, 45], "xcode": 5, "xgbclassifi": [40, 41], "xgbclassifierxgbclassifi": 40, "xgboost": 41, "xgbregressor": [12, 19, 30, 40], "xlabel": [8, 13, 14, 15, 18, 20, 21, 22, 27, 31, 32, 33, 36, 37, 38, 39, 41, 44, 47, 48, 49, 50, 53, 55], "xlim": 49, "xor": [18, 36, 42], "xp": 28, "xt": [17, 24, 35], "xtick": [14, 21, 27, 32, 38, 48], "xticklabel": 37, "xticks_rot": 38, "xwm\u0259\u03b8kw\u0259y": 58, "xx": [42, 43], "y": [8, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56], "y_": 45, "y_citi": [15, 22, 33], "y_femal": 38, "y_hat": [18, 36, 40], "y_i": [39, 40, 42, 45], "y_init": 43, "y_label": [13, 14, 15, 20, 21, 22, 31, 32, 33, 55], "y_male": 38, "y_mat": 45, "y_multi": 53, "y_numer": 28, "y_pred": [38, 48], "y_pred_lower_threshold": 38, "y_pred_toi": 38, "y_pred_train": 48, "y_re": 38, "y_small_citi": [15, 22, 33], "y_spotifi": 37, "y_test": [12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 47, 48, 49, 50, 52, 53, 56, 57], "y_test_big": 37, "y_test_happi": [38, 51], "y_test_multi": 53, "y_test_num": [40, 41], "y_toi": [15, 22, 33, 48], "y_tr": [26, 56], "y_train": [12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 47, 48, 49, 50, 52, 53, 56, 57], "y_train_big": 38, "y_train_happi": [38, 51], "y_train_hous": 42, "y_train_multi": 53, "y_train_num": [40, 41], "y_train_ord": 48, "y_train_oversampl": 38, "y_train_subsampl": 38, "y_train_tini": 37, "y_train_usr": 45, "y_true": 50, "y_true_toi": 38, "y_valid": [26, 27, 38, 45, 47, 56], "y_vari": 44, "y_xor": 42, "yale": 46, "yan": [1, 58], "yann": 41, "ycxmx": 49, "ye": [4, 12, 13, 16, 17, 19, 20, 23, 24, 28, 30, 31, 34, 35, 41, 43, 44, 45, 47, 48, 50, 51, 52, 54], "year": [12, 13, 19, 20, 31, 45, 46, 47, 48, 49], "yearbuilt": [39, 41, 50], "yearremodadd": [39, 41, 50], "yellow": 37, "yellowbrick": [43, 44], "yesterdai": 48, "yet": [1, 10, 11, 18, 28, 36, 41, 45, 48, 49, 56], "yifei": [1, 58], "ylabel": [8, 13, 14, 15, 18, 20, 21, 22, 26, 27, 31, 32, 33, 36, 37, 38, 39, 44, 47, 48, 49, 50, 53, 55, 56], "ylim": [49, 50], "yml": 10, "yolo": 47, "yolo8": 47, "yolo_input": 47, "yolo_result": 47, "yolo_test": 47, "yolov8n": 47, "york": [48, 52], "you": [0, 1, 4, 5, 6, 7, 8, 10, 26, 27, 41, 46, 52, 53, 54, 55, 56, 57, 58], "your": [0, 1, 2, 4, 6, 7, 8, 10, 14, 15, 16, 17, 18, 21, 22, 23, 24, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58], "your_miniconda_path": 52, "your_nam": 10, "yourself": [4, 11, 17, 24, 35, 38, 45, 46, 50, 58], "yourselv": 46, "youtub": [1, 12, 19, 45, 46, 50, 58], "yr_built": [12, 13, 19, 26, 30, 31], "yr_renov": [12, 13, 19, 26, 30, 31], "yrpxn": 49, "yrsold": [39, 41, 50], "ytick": [14, 21, 27, 32, 38], "yticklabel": 37, "yy": [42, 48], "yyyi": 48, "z": [8, 18, 27, 36, 42, 43, 44, 45, 47, 49], "z_i": 47, "z_j": 47, "z_km": 43, "z_train": [27, 47], "z_valid": [27, 47], "zachari": 49, "zarei": [1, 58], "zefeng": [1, 58], "zeng": [1, 58], "zero": [8, 14, 17, 21, 24, 32, 35, 37, 45, 46, 50], "zero_divis": 38, "zhiyanov": [1, 58], "zip": [15, 18, 22, 27, 33, 36, 45, 52, 56], "zipcod": [12, 13, 19, 26, 30, 31, 56], "zone": 48, "zoom": 7, "\u0259m": 58, "\u03bc": 53}, "titles": ["LICENSE", "UBC CPSC 330: Applied Machine Learning (2024W2)", "CPSC 330 vs. CPSC 340", "CPSC 330 Documents", "How to ask for help", "What are git and GitHub?", "CPSC 330 grading policies", "Homework info &amp; submission guidelines", "CPSC 330 Python notes", "Reference material", "Setting up coding environment", "Course Learning Objectives", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "&lt;no title&gt;", "Lecture 3: ML Fundamentals Class Demo", "Lecture 4: Class demo", "Lecture 5 and 6: Class demo", "Lectures 7: Class demo", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 12: Ensembles", "Lecture 13: Feature importances and model transparency", "Lecture 14: Feature engineering and feature selection", "Lecture 15: K-Means Clustering", "Lecture 16: More Clustering", "Lecture 17: Recommender Systems", "Lecture 18: Introduction to natural language processing", "Lecture 19: Multi-class classification and introduction to computer vision", "Lecture 20: Time series", "Lecture 21: Survival analysis", "Lecture 22: Communication", "Lecture 24: Deployment and conclusion", "Appendix A: Demo of feature engineering for text data", "Appendix B: Multi-class, meta-strategies", "Final exam preparation: guiding questions", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Syllabus"], "titleterms": {"": [12, 14, 15, 16, 17, 19, 22, 23, 24, 28, 30, 32, 33, 34, 35, 38, 39, 41, 48, 50], "0": 40, "1": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 49, 50, 54, 55, 56, 57], "10": 39, "12": 40, "13": 41, "14": 42, "15": [43, 50, 51], "16": 44, "17": 45, "18": 46, "19": 47, "2": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 44, 45, 49, 50, 54, 55, 56, 57], "20": [48, 50, 51], "2024w2": 1, "21": 49, "22": 50, "24": 51, "3": [12, 13, 14, 16, 19, 20, 21, 23, 26, 30, 31, 32, 34, 42, 43, 44, 49, 55, 56, 57], "330": [1, 2, 3, 6, 8, 12, 19, 51], "340": [2, 12, 19, 51], "4": [13, 14, 15, 20, 21, 22, 27, 31, 32, 33, 50, 55, 56, 57], "5": [8, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 28, 31, 32, 33, 34, 35, 38, 41, 42, 43, 46, 47, 49, 50, 56, 57], "6": [17, 24, 28, 35, 56], "7": [18, 29, 36], "8": 37, "9": 38, "A": [4, 38, 44, 48, 52], "No": 8, "Not": 54, "One": [16, 23, 34, 48, 53], "The": [1, 14, 18, 21, 32, 36, 37, 40, 42, 43], "__": 37, "about": [8, 12, 19, 42, 45, 50], "academ": 58, "access": [7, 18, 36, 58], "accommod": 58, "acknowledg": 58, "activ": [12, 19, 26, 38, 41, 42, 43, 46, 50], "actual": [17, 35], "ad": 8, "addit": [7, 41], "address": 38, "advantag": 37, "advic": 42, "ai": 58, "aka": 50, "algorithm": [13, 15, 20, 22, 31, 33, 42, 43], "all": [12, 13, 16, 18, 19, 30, 31, 34, 36, 38, 43, 44, 45, 50], "alpha": [18, 36, 39], "alreadi": 51, "altern": [13, 16, 20, 23, 28, 31, 34], "an": [40, 50, 52], "analogi": [15, 33], "analysi": [26, 28, 48, 49, 51, 54, 56], "angl": 50, "announc": [12, 13, 14, 15, 16, 17, 18, 22, 24, 31, 33, 35, 36, 40], "answer": 49, "ap": 38, "api": [16, 23, 34, 51], "app": 51, "appendix": [52, 53], "appli": [1, 8, 16, 17, 23, 24, 34, 35, 39, 50], "applic": 43, "applymap": 8, "approach": [45, 48, 49, 50, 51, 53], "approxim": [14, 21, 32], "ar": [5, 12, 13, 16, 18, 19, 23, 30, 31, 34, 36, 38, 43, 44, 45], "area": 38, "argument": [14, 15, 21, 22, 32, 33], "around": 50, "arrai": 8, "articl": 9, "asap": 50, "ask": 4, "assess": 26, "assign": [7, 58], "associ": [18, 36], "assum": 49, "attent": [13, 15, 20, 22, 31, 33], "attribut": [41, 50], "auc": 38, "autom": 37, "averag": [38, 40, 45], "avoid": [14, 21, 32], "b": [43, 53], "backward": 42, "bad": 37, "bag": [17, 24, 35, 52], "balanc": 38, "base": [15, 33, 40, 42, 45, 48], "baselin": [13, 16, 20, 23, 26, 31, 34, 38, 40, 41, 45, 56], "basic": 46, "befor": [12, 16, 19, 23, 34], "best": 42, "better": [14, 21, 32, 37, 38, 42, 50], "between": [13, 15, 22, 31, 33, 51, 55], "beyond": [41, 45], "bia": [14, 21, 32, 37], "big": [13, 14, 16, 20, 21, 23, 31, 32, 34], "binari": 38, "book": 1, "boost": [40, 50], "bootstrap": 40, "bottom": 50, "boundari": [13, 15, 18, 20, 22, 27, 31, 33, 36, 55], "bow": [17, 24, 35], "box": 47, "break": [8, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 31, 32, 33, 34, 35, 42, 46, 47, 49, 50, 51], "broadcast": 8, "browser": [12, 19], "build": [12, 13, 19, 20, 26, 29, 30, 31, 39, 45, 51], "c": [15, 22, 33, 37], "calcul": [18, 36], "california": [18, 35, 36, 57], "can": [8, 14, 16, 21, 23, 32, 34, 40, 41, 42, 43], "canada": [13, 31, 55], "care": [45, 50], "carri": [16, 23, 34, 42], "case": [17, 18, 24, 35, 36, 44], "catboost": 40, "categor": [16, 17, 23, 24, 28, 34, 35, 41, 48], "categori": [17, 24, 35], "censor": 49, "centr": 58, "certain": [17, 35], "cfa": 58, "chang": 38, "charact": [12, 19, 30], "characterist": 38, "cheatsheet": 8, "checklist": [12, 19], "choos": [15, 22, 33, 43], "chunk": 50, "churn": 49, "cite": 7, "citi": [18, 36], "claim": 50, "class": [12, 19, 26, 27, 28, 29, 37, 38, 39, 40, 41, 45, 47, 53, 58], "class_attend": [17, 24, 35], "class_weight": 38, "classif": [13, 20, 27, 31, 38, 47, 51, 54], "classifi": [13, 18, 20, 28, 29, 31, 36, 40, 52], "clearli": 42, "cluster": [43, 44, 54], "co": [1, 58], "code": [10, 58], "coeffici": [18, 29, 36, 41], "color": [55, 56, 57], "column": [8, 16, 17, 23, 24, 34, 35, 48], "columntransform": [17, 24, 35, 57], "com": 15, "combin": 40, "come": [14, 15, 21, 22, 32, 33], "command": 5, "comment": [13, 20, 31, 37, 38, 39, 43, 44, 45], "common": [16, 23, 34, 43], "commonli": 46, "commun": [12, 19, 50, 54], "compact": [16, 23, 34], "companion": 9, "complet": 45, "complex": [14, 21, 32], "complic": 48, "compon": [18, 36], "comprehens": 57, "comput": [12, 19, 47, 54], "con": [15, 22, 33, 44, 54], "concept": [26, 50], "concern": 6, "concess": 58, "conclus": 51, "conda": 10, "conduct": 58, "confid": [18, 36, 50], "confus": [38, 50], "consid": 49, "construct": 40, "content": 45, "context": 46, "continu": [13, 20, 31], "conveni": [17, 24, 35], "corpu": 51, "correct": 43, "correl": 41, "countri": [13, 31, 55], "countvector": [17, 24, 35], "cours": [1, 9, 11, 12, 19, 30, 51, 58], "cover": [45, 49, 51], "cox": 49, "cpsc": [1, 2, 3, 6, 8, 12, 19], "creat": [7, 13, 14, 17, 20, 21, 24, 31, 32, 35, 45, 51], "credit": 10, "cross": [14, 16, 21, 23, 26, 32, 34, 38, 42, 48, 56], "cross_val_scor": [14, 21, 32], "cross_valid": [14, 21, 32, 39], "csv": 8, "curs": [15, 22, 33], "curv": [38, 49], "custom": [43, 49], "cv": 37, "dai": 48, "data": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 47, 48, 50, 51, 52, 56], "datafram": [8, 17, 24, 35], "dataset": [7, 13, 16, 18, 20, 23, 29, 31, 34, 35, 36, 37, 38, 39, 47, 48, 50, 57], "date": [1, 48], "datetim": 48, "dbscan": 44, "deal": [17, 24, 35, 38], "debug": 10, "decis": [13, 15, 18, 20, 22, 26, 27, 31, 33, 36, 41, 50, 56], "decisiontreeclassifi": [13, 20, 31, 40], "decreas": 38, "deep": [47, 48], "defin": 42, "definit": [12, 19, 30], "deliver": [1, 12, 19], "demo": [26, 27, 28, 29, 42, 48, 51, 52], "demonstr": 38, "dendrogram": 44, "depend": 42, "deploi": 51, "deploy": [14, 21, 32, 51, 54], "descript": 58, "desktop": 5, "detail": [21, 38, 39, 44], "detect": 47, "df": 8, "did": [14, 16, 17, 21, 23, 24, 32, 34, 35, 38, 39, 45, 49, 50, 51], "differ": [16, 23, 34, 37, 38, 39, 41, 51, 54], "dimens": [15, 22, 33], "dimension": [15, 22, 33], "directori": 51, "discuss": [26, 28, 37, 38, 45, 46, 50, 51], "diseas": [12, 19, 30], "distanc": [15, 22, 33, 43], "distribut": 37, "do": [16, 17, 23, 28, 34, 35, 37, 38, 40, 41, 42, 50, 51], "document": [3, 8, 43], "doe": [13, 18, 20, 21, 31, 36, 44, 50], "domain": 42, "drop": 8, "due": 1, "dummi": [27, 28, 52], "dummyclassifi": [13, 20, 31, 40, 48, 49], "dummyregressor": [13, 16, 20, 23, 31, 34, 39], "eda": [16, 23, 34, 38, 39, 51, 56], "effect": [40, 50], "elbow": 43, "element": 8, "elimin": 42, "embed": 46, "encod": [16, 17, 23, 24, 34, 35, 42, 48], "engin": [42, 48, 52, 54], "ensembl": [40, 54], "enter": 28, "environ": [10, 51], "equal": 50, "error": [14, 21, 32, 37, 38, 39, 45], "estim": [16, 23, 34, 40], "ethic": 54, "euclidean": [15, 22, 33], "eva": [12, 14, 19, 30, 32], "evalu": [38, 44, 45, 49, 54], "evalut": 38, "event": 49, "everyon": 49, "exactli": [18, 36], "exam": [54, 58], "examin": [17, 24, 29, 35, 39, 50, 54], "exampl": [12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 46, 49, 50, 52], "exercis": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 45, 47, 49, 55], "exhaust": 37, "experi": 50, "explain": [41, 50], "explan": [41, 50], "explor": [15, 22, 33, 43], "exploratori": [26, 28, 48, 56], "extract": [17, 24, 35, 48], "extractor": 47, "f1": 38, "failur": 44, "fair": 38, "fancier": 37, "farewel": 51, "faster": 8, "fastest": 8, "featur": [12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 28, 30, 31, 33, 34, 35, 36, 39, 41, 42, 45, 47, 48, 50, 52, 54], "feature_importances_": 41, "few": [38, 44, 50], "fictiti": [12, 19, 30], "figur": 7, "filter": [8, 45], "final": [13, 20, 31, 37, 43, 44, 45, 48, 54, 56, 58], "find": [15, 22, 33, 42], "first": [12, 16, 19, 23, 34], "fit": [13, 16, 20, 23, 31, 34, 40], "flatten": 47, "follow": [12, 13, 14, 19, 21, 26, 30, 31, 32, 43, 44, 45], "font": [55, 56, 57], "forecast": 48, "forest": [40, 41, 50], "format": [7, 8, 12, 19], "formul": 45, "forward": 42, "from": [8, 50, 52], "full": 51, "function": [8, 18, 36, 39], "fundament": [14, 15, 21, 22, 26, 32, 33, 40, 54], "further": [48, 52], "futur": 48, "fuyi": 15, "gamma": [15, 22, 33], "garbag": 42, "gb": 50, "gener": [4, 6, 14, 15, 18, 21, 22, 32, 33, 36, 40, 42], "geometr": [15, 22, 33], "get": 41, "git": [5, 10], "github": 5, "given": [12, 13, 19, 20, 30, 31], "global": 45, "goal": [14, 21, 32], "golden": [14, 16, 17, 21, 23, 24, 32, 34, 35], "good": [38, 50], "grade": [4, 6, 13, 19, 20, 31, 58], "gradescop": 7, "gradient": [40, 50], "grid": [37, 50], "gridsearchcv": [37, 39, 50], "group": [26, 38, 43], "guid": 54, "guidelin": [4, 6, 7], "ha": [12, 19, 30], "halv": 37, "handl": 38, "have": [40, 41, 50], "hazard": 49, "heatmap": 37, "help": [4, 42], "here": [14, 21, 32], "hierarch": 44, "home": 44, "homework": [7, 12, 19], "hot": [16, 23, 34, 42, 48], "hous": [12, 13, 16, 18, 19, 23, 30, 31, 34, 35, 36, 57], "how": [4, 7, 13, 14, 15, 16, 18, 20, 21, 22, 23, 28, 31, 32, 33, 34, 36, 40, 41, 42, 44, 50], "http": 15, "hyper": 37, "hyperparamet": [13, 15, 17, 18, 20, 22, 24, 26, 31, 33, 35, 36, 37, 39, 40, 43, 54, 56], "i": [12, 14, 16, 17, 19, 21, 23, 24, 30, 32, 34, 35, 37, 38, 40, 41, 42, 43, 45, 46, 50, 51, 52], "iclick": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 49, 58], "idea": [15, 22, 33, 38, 40, 42, 50], "identifi": [17, 24, 35, 41], "imag": [12, 19, 27, 30, 47], "imagenet": 47, "imbal": [38, 39, 40, 41], "import": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56], "improv": 52, "imput": [16, 23, 34, 45], "incorpor": [17, 24, 28, 35], "increas": 38, "index": 8, "inertia": 43, "info": 7, "inform": [41, 48], "initi": [43, 51], "inject": 40, "input": [12, 19, 30, 43], "instal": [5, 10], "instruct": [0, 7], "instructor": 1, "interact": 42, "intercept": [18, 36], "interest": 50, "interim": [38, 41, 42, 48], "interpret": [18, 29, 36, 41, 51], "intra": 43, "intro": 45, "introduct": [8, 12, 19, 30, 41, 42, 43, 44, 46, 47, 50, 54], "intuit": [18, 36], "involv": [48, 50], "issu": 50, "join": 15, "jupyt": [12, 19], "jupyterlab": 10, "k": [15, 16, 22, 23, 33, 34, 43, 44, 45], "kaplan": 49, "kei": [41, 50, 51], "kernel": [15, 22, 33], "kind": 40, "kneighborsclassifi": [15, 22, 27, 33], "knn": [27, 28], "label": [12, 19, 30, 43, 50], "lag": 48, "land": 58, "languag": 46, "larg": 37, "late": 7, "latitud": [13, 31, 55], "lda": 46, "learn": [1, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "least": [18, 36], "lectur": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 58], "let": [15, 16, 17, 22, 23, 24, 28, 33, 34, 35, 38, 39, 41, 50], "licens": [0, 1], "lightgbm": 40, "limit": [6, 18, 36, 44], "line": 5, "linear": [18, 29, 36, 39, 41], "link": 1, "list": 9, "liver": [12, 19, 30], "ll": [14, 21, 32], "lo": [14, 16, 17, 18, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 45, 47, 48, 51], "load": 51, "local": 51, "localhost": 51, "logist": [18, 36, 38, 47], "logisticregress": [38, 48, 49, 50], "longitud": [13, 31, 55], "look": [38, 43], "loop": 8, "loss": 50, "lower": 37, "mac": 5, "machin": [1, 12, 13, 14, 15, 19, 20, 21, 22, 26, 30, 31, 32, 33, 38, 43, 51], "maco": 10, "macro": 38, "magnitud": [18, 36], "mai": 42, "main": [18, 36, 45, 50], "make": [8, 18, 36, 50], "make_column_transform": [17, 24, 35], "make_pipelin": [16, 23, 34], "mani": [17, 35, 37], "manual": 37, "mape": 39, "materi": [0, 1, 9], "matplotlib": 8, "matric": [17, 24, 35], "matrix": [38, 45], "matter": 21, "max_depth": [13, 20, 31], "mean": [39, 43, 44, 46, 50], "measur": 42, "media": 46, "meet": [12, 19, 30, 58], "meier": 49, "messag": [12, 19, 30, 44], "meta": 53, "method": [8, 28, 37, 42, 43], "metric": [38, 39, 54], "midterm": [43, 58], "might": 49, "min": [8, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 31, 32, 33, 34, 35, 38, 41, 42, 43, 46, 47, 49, 50, 51], "minor": 38, "misc": [1, 9], "miscellan": 45, "mislead": 50, "ml": [12, 14, 15, 19, 21, 22, 26, 30, 32, 33, 38, 41, 50, 54], "model": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 46, 47, 49, 51, 52, 54, 56], "model_select": 37, "moment": 51, "month": 48, "more": [13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 31, 33, 34, 35, 36, 38, 39, 42, 44, 48], "most": [18, 29, 36], "motiv": [14, 15, 16, 18, 21, 22, 23, 32, 33, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 50], "movi": 45, "mse": 39, "much": 37, "multi": [38, 47, 53], "multiclass": 54, "multipl": [15, 17, 22, 24, 33, 35, 39], "multipli": 8, "n_estim": 40, "n_iter": 37, "n_job": 37, "n_neighbor": [15, 22, 33], "name": [14, 21, 32, 39, 45], "natur": 46, "nearest": [15, 16, 22, 23, 33, 34, 43, 45], "need": [16, 23, 34, 37], "neg": [29, 38], "neighbour": [15, 16, 22, 23, 33, 34, 45], "nest": 8, "netflix": 40, "network": 47, "neural": 47, "new": [50, 51], "next": [12, 19, 51], "nlp": [46, 54], "nn": [15, 22, 33], "non": [15, 17, 22, 24, 33, 35, 41], "notat": 8, "note": [8, 14, 32, 48, 56], "notebook": [12, 19], "now": 49, "number": [40, 43, 48], "numer": [41, 42], "numpi": 8, "object": [11, 13, 20, 31, 40, 46, 47, 48, 49, 50, 51], "observ": 38, "occasion": [16, 23, 34], "off": [14, 15, 21, 22, 32, 33, 40], "oh": [16, 17, 23, 24, 34, 35], "ok": [16, 17, 23, 24, 34, 35], "onc": 38, "one": [17, 24, 35, 42], "onehotencod": [17, 24, 35], "onli": [17, 24, 35, 49], "onlin": [1, 9], "oper": 38, "optim": [26, 37, 54], "option": [10, 15, 16, 22, 23, 33, 34, 37, 38, 40, 42, 49, 51], "ordin": [1, 16, 17, 23, 24, 28, 34, 35, 41, 58], "other": [8, 15, 22, 33, 39, 42, 43, 46, 48, 49, 50], "our": [7, 14, 16, 21, 23, 32, 34, 50, 51, 52], "out": [16, 23, 34, 42, 47, 50, 51], "outcom": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45], "outlin": [55, 56, 57], "output": 43, "over": [8, 15, 18, 22, 33, 36, 38], "overfit": [14, 21, 32, 37], "oversampl": 38, "overview": [15, 22, 33, 38], "ovo": 53, "ovr": 53, "packag": [10, 48], "panda": 8, "pandas_profil": 39, "paper": [38, 40], "paradigm": [16, 23, 34], "paramet": [13, 18, 20, 31, 36, 37, 38, 54], "parametr": [15, 22, 33], "pars": 48, "part": 54, "pass": 37, "patient": [12, 19, 30], "perfect": 43, "perhap": 50, "permutation_import": 41, "persona": [12, 19, 30], "piazza": 4, "pick": [14, 21, 32, 37], "pictur": [13, 14, 16, 20, 21, 23, 31, 32, 34], "piec": 50, "pipelin": [16, 23, 28, 34, 46], "plan": 44, "playground": [15, 22, 27, 33, 56], "plot": [8, 41, 43, 49], "point": [15, 22, 33, 38, 41, 43, 48], "polici": 6, "poll": 43, "ponder": 29, "popular": [12, 19, 30], "posit": [29, 38], "posix": 48, "possibl": [17, 24, 35, 39, 43, 52], "post": 9, "pr": 38, "practic": [15, 20, 31, 33], "pre": 47, "precis": 38, "predict": [12, 13, 17, 18, 19, 20, 30, 31, 35, 36, 40, 41, 45, 47, 49, 53, 55], "predict_proba": [18, 36, 50], "predictor": 51, "prefer": 50, "prepar": [7, 54], "preprocess": [16, 17, 23, 24, 34, 35, 39, 46, 48, 50, 51, 54], "prerequisit": [12, 19], "preval": [12, 19, 30], "price": [12, 13, 19, 30, 31], "principl": 50, "prize": 40, "pro": [15, 22, 33, 44, 54], "probabl": [18, 36, 37], "problem": [13, 14, 15, 16, 20, 21, 22, 23, 31, 32, 33, 34, 37, 42, 45, 48, 51, 52], "procedur": 38, "process": 46, "product": [12, 19, 30], "profil": 45, "program": [13, 20, 31], "project": 52, "properli": 28, "proport": 49, "python": [8, 9, 10, 12, 19], "q": 4, "qualiti": 42, "queri": [8, 15, 22, 33], "question": [4, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57], "quick": [15, 33], "quiz": [13, 20, 31], "quiz2": [13, 20, 31], "quot": 42, "r": 39, "random": [37, 40, 41, 50], "random_st": [14, 21, 32], "randomforestclassifi": [40, 49], "randomizedsearchcv": [37, 39], "rang": 37, "rate": 45, "raw": [18, 36], "rbf": [15, 22, 27, 33], "re": 50, "read": [8, 13, 20, 31, 37, 47], "reader": 50, "real": [13, 31, 51, 55], "realist": [17, 24, 35], "reason": 6, "recal": 38, "recap": [13, 15, 20, 31, 33, 44, 49, 50, 55, 57], "receiv": 38, "recip": 51, "recommend": [12, 16, 19, 23, 34, 45, 54], "record": 58, "recurs": 42, "red": [55, 56, 57], "refer": [1, 9, 49], "reflect": [13, 14, 20, 21, 31, 32, 43, 44], "registr": [12, 19, 58], "regress": [13, 15, 18, 20, 22, 31, 33, 36, 38, 39, 40, 47], "regressor": [15, 22, 33], "relat": [4, 13, 15, 20, 22, 31, 33, 50], "relev": [9, 38, 40, 42], "remark": 48, "rememb": 43, "remind": [13, 31, 45], "remov": 8, "renam": 8, "render": 51, "report": [7, 38], "repositori": 7, "represent": [17, 24, 35, 47], "request": 51, "requir": [12, 19, 51], "rescu": [14, 21, 32], "resourc": [9, 12, 19, 37, 38, 42, 43, 44, 45], "rest": 53, "result": [37, 50], "retail": 48, "reus": 50, "review": [29, 51], "revis": 26, "rf": 50, "rfe": 42, "ridg": [18, 36, 39], "ridgecv": 39, "right": 49, "rmse": 39, "roc": 38, "root": 39, "row": 8, "rule": [14, 16, 17, 21, 23, 24, 32, 34, 35], "run": [16, 23, 34, 50], "same": 8, "sampl": [38, 40, 43], "sauc": 43, "save": [12, 19, 30, 51], "scale": [12, 16, 18, 19, 23, 28, 30, 34, 36, 41], "schedul": 1, "scheme": 58, "scikit": [14, 16, 17, 21, 23, 24, 32, 34, 35, 39], "score": [13, 14, 18, 20, 21, 31, 32, 36, 37, 38, 39, 42, 43, 52], "search": [15, 22, 33, 37, 42, 50], "season": 48, "segment": 43, "select": [12, 13, 19, 30, 31, 42, 43, 44, 45, 54], "send": 51, "separ": [39, 41, 50], "seri": [8, 48, 54], "server": 51, "servic": 51, "set": [5, 10, 12, 14, 19, 21, 26, 32, 37, 38, 51], "set_config": [17, 24, 35], "shap": 41, "shape": [8, 44], "shaplei": 41, "short": 9, "should": [40, 45, 50], "show": [41, 50], "sigmoid": [18, 36, 47], "sign": [18, 36], "silhouett": 43, "similar": [15, 22, 33], "simpl": [14, 21, 32, 52], "simplefeatur": 41, "simpleimput": 28, "singl": [14, 21, 26, 32], "size": 8, "sklearn": [13, 16, 17, 20, 23, 24, 28, 31, 34, 35, 37, 38, 40, 41], "slowest": 8, "small": 50, "smote": 38, "social": 46, "softmax": 47, "softwar": [0, 47, 48], "solv": 37, "some": [13, 20, 31, 37, 38, 40, 42, 51], "sort": 8, "sort_valu": 8, "sourc": 7, "space": 48, "spaci": [46, 52], "spaghetti": 43, "spam": [12, 17, 19, 24, 30, 35], "spars": [17, 24, 35], "specif": [4, 42], "split": [14, 16, 21, 23, 26, 28, 32, 34, 38, 48, 56], "spotifi": [16, 23, 34, 37], "squar": 39, "stack": 40, "standardscal": [16, 23, 34], "statement": [12, 13, 19, 30, 31, 43, 44, 45], "statist": 51, "step": [13, 20, 26, 31, 46, 57], "strategi": [40, 53], "stratifi": 38, "strength": [18, 36, 40], "structur": 51, "studi": 54, "style": [12, 19], "submiss": 7, "submit": 7, "success": 37, "summari": [8, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], "supervis": [12, 13, 14, 15, 19, 20, 21, 22, 26, 30, 31, 32, 33, 43, 45, 51], "support": [15, 22, 33], "surviv": [49, 54], "svc": 38, "svm": [15, 18, 22, 27, 33, 36], "syllabu": [1, 58], "syntax": [16, 17, 23, 24, 34, 35, 37], "synthet": 38, "system": [45, 54], "ta": [1, 58], "tabular": [13, 15, 20, 22, 31, 33, 51], "tackl": 39, "take": 44, "takeawai": 51, "target": [12, 13, 17, 19, 20, 24, 30, 31, 35, 39, 43], "task": 46, "teach": [1, 58], "team": [1, 58], "techniqu": [16, 23, 34, 38], "templat": 7, "tempor": 48, "tent": 1, "terminologi": [13, 20, 31, 47], "test": [5, 14, 21, 26, 32, 37, 48], "test_df": [14, 21, 32], "test_siz": [14, 21, 32], "text": [17, 24, 28, 35, 46, 52], "than": [17, 24, 35, 37, 42, 50], "thei": 40, "them": 8, "thi": [8, 12, 16, 17, 19, 23, 24, 26, 28, 30, 34, 35, 41, 50, 51], "thing": [16, 23, 34, 50], "threshold": 38, "time": [6, 12, 19, 30, 48, 49, 54], "tip": 54, "todai": [14, 16, 17, 21, 23, 24, 32, 34, 35, 38, 39, 50], "toi": [13, 17, 20, 24, 31, 35, 38, 46], "token": 46, "tool": 46, "topic": 46, "trade": [14, 15, 21, 22, 32, 33, 40], "tradeoff": [14, 21, 32, 38, 40], "tradit": [13, 20, 31, 48], "train": [12, 13, 14, 17, 18, 19, 20, 21, 24, 30, 31, 32, 35, 36, 38, 47, 48, 50, 51], "train_df": [14, 21, 32], "train_siz": [14, 21, 32], "transfer": 47, "transform": [16, 17, 23, 24, 34, 35, 39, 42, 50], "transpar": [41, 51], "tree": [13, 20, 26, 31, 40, 41, 50, 56], "trend": 48, "true": [12, 19, 30, 43, 44, 45], "try": [16, 23, 28, 34, 39, 50, 51], "tune": [39, 43, 56], "tutori": [22, 55, 56, 57], "two": [17, 24, 35], "type": [12, 14, 19, 21, 30, 32, 38, 39, 41, 43, 48, 49, 50], "typic": [14, 21, 26, 32, 46], "u": 50, "ubc": 1, "ubuntu": 5, "under": 38, "underfit": [14, 21, 32], "undersampl": 38, "understand": 51, "unequ": 48, "unknown": [17, 24, 35], "unlabel": 43, "unseen": [12, 14, 19, 21, 30, 32], "unsupervis": [13, 20, 31, 43], "up": [5, 10, 12, 14, 15, 19, 21, 22, 32, 33, 50, 51], "updat": 7, "url": 8, "us": [7, 8, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 27, 30, 31, 32, 33, 34, 35, 38, 39, 40, 42, 43, 46, 47, 50, 53, 55, 58], "usa": [13, 31, 55], "user": [5, 45], "usual": 42, "util": 45, "v": [2, 12, 13, 14, 15, 19, 20, 21, 22, 31, 32, 33, 38, 41, 43, 47, 51, 53], "valid": [14, 16, 21, 23, 26, 32, 34, 37, 38, 48, 56], "varianc": [14, 21, 32], "vector": [8, 15, 22, 33, 46], "video": [12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 30, 31, 32, 33, 34, 36, 38, 39, 40, 43, 44, 46], "view": [15, 17, 22, 24, 33, 35], "violat": [14, 21, 32], "virtual": 10, "vision": [47, 54], "visual": [9, 37, 50], "vocabulari": 29, "wai": [37, 42, 50], "waitlist": [12, 19], "want": [17, 24, 35, 41, 49], "warn": [13, 20, 31, 42], "watch": 50, "we": [8, 14, 16, 17, 18, 21, 23, 24, 26, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 49, 50, 51], "weak": 40, "web": 51, "websit": [12, 19], "weight": [18, 36, 38], "what": [5, 10, 12, 14, 16, 17, 18, 19, 21, 23, 24, 30, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 49, 50, 51], "when": [8, 16, 23, 34, 37, 50], "where": [17, 24, 35, 49], "whether": [12, 19, 30], "which": [12, 13, 19, 30, 31, 38, 40, 43, 44, 45], "why": [10, 12, 17, 19, 21, 24, 30, 35, 37, 41, 42, 45, 47, 50], "window": [5, 10], "wise": 8, "without": 43, "word": [17, 24, 35, 46, 52], "work": [13, 20, 31, 40, 44, 50], "workflow": [12, 14, 21, 30, 32, 38], "would": [14, 21, 28, 32, 51], "wrapper": 53, "write": [13, 20, 31], "x": [12, 13, 19, 20, 30, 31, 39, 41, 50], "xgboost": 40, "y": [12, 13, 19, 20, 30, 31, 39, 41, 50], "ye": 49, "yield": 37, "you": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51], "your": [5, 12, 13, 19, 20, 26, 31, 50]}})