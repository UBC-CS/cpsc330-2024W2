Search.setIndex({"alltitles": {"": [[42, "id1"]], "(Optional)": [[40, "optional"]], "(Optional) Changing the data": [[20, "optional-changing-the-data"], [57, "optional-changing-the-data"]], "(Optional) Evaluation": [[68, "optional-evaluation"]], "(Optional) Evaluation metrics for multi-class classification": [[20, "optional-evaluation-metrics-for-multi-class-classification"], [57, "optional-evaluation-metrics-for-multi-class-classification"]], "(Optional) Example 1: Optimization bias": [[19, "optional-example-1-optimization-bias"], [33, "optional-example-1-optimization-bias"], [56, "optional-example-1-optimization-bias"]], "(Optional) Example 2: Optimization bias": [[19, "optional-example-2-optimization-bias"], [33, "optional-example-2-optimization-bias"], [56, "optional-example-2-optimization-bias"]], "(Optional) Fancier methods": [[19, "optional-fancier-methods"], [33, "optional-fancier-methods"], [56, "optional-fancier-methods"]], "(Optional) Fitting in boosted regression trees.": [[22, "optional-fitting-in-boosted-regression-trees"], [38, "optional-fitting-in-boosted-regression-trees"], [59, "optional-fitting-in-boosted-regression-trees"]], "(Optional) Forward or backward selection": [[24, "optional-forward-or-backward-selection"], [40, "optional-forward-or-backward-selection"], [61, "optional-forward-or-backward-selection"]], "(Optional) Macro average and weighted average": [[20, "optional-macro-average-and-weighted-average"], [34, "optional-macro-average-and-weighted-average"], [57, "optional-macro-average-and-weighted-average"]], "(Optional) Parametric vs non parametric": [[15, "optional-parametric-vs-non-parametric"], [28, "optional-parametric-vs-non-parametric"], [52, "optional-parametric-vs-non-parametric"]], "(Optional) Passing probability distributions to random search": [[19, "optional-passing-probability-distributions-to-random-search"], [33, "optional-passing-probability-distributions-to-random-search"], [56, "optional-passing-probability-distributions-to-random-search"]], "(Optional) Prediction in boosted regression trees": [[22, "optional-prediction-in-boosted-regression-trees"], [38, "optional-prediction-in-boosted-regression-trees"], [59, "optional-prediction-in-boosted-regression-trees"]], "(Optional) Problems with feature selection": [[24, "optional-problems-with-feature-selection"], [40, "optional-problems-with-feature-selection"], [61, "optional-problems-with-feature-selection"]], "(Optional) Search and score": [[24, "optional-search-and-score"], [40, "optional-search-and-score"], [61, "optional-search-and-score"]], "(Optional) Searching for optimal parameters with successive halving\u00b6": [[19, "optional-searching-for-optimal-parameters-with-successive-halving"], [33, "optional-searching-for-optimal-parameters-with-successive-halving"], [56, "optional-searching-for-optimal-parameters-with-successive-halving"]], "(Optional) Setting up a directory structure and environment": [[70, "optional-setting-up-a-directory-structure-and-environment"]], "(Optional) Some more details": [[20, "optional-some-more-details"], [47, "optional-some-more-details"], [57, "optional-some-more-details"]], "(Supervised) machine learning: popular definition": [[12, "supervised-machine-learning-popular-definition"], [25, "supervised-machine-learning-popular-definition"], [49, "supervised-machine-learning-popular-definition"]], "(iClicker) Exercise 14.1": [[61, "id1"]], "(iClicker) Exercise 14.1 https://join.iclicker.com/FUYI": [[24, "id1"]], "(iClicker) Exercise 14.2": [[40, "iclicker-exercise-14-2"]], "(iClicker) Exercise 14.3": [[40, "iclicker-exercise-14-3"]], "(iClicker) Exercise 21.1": [[68, "iclicker-exercise-21-1"]], "(iClicker) Exercise 21.2": [[68, "iclicker-exercise-21-2"]], "(iClicker) Exercise 4.1": [[28, "iclicker-exercise-4-1"], [52, "iclicker-exercise-4-1"]], "(iClicker) Exercise 4.1 https://join.iclicker.com/FUYI": [[15, "iclicker-exercise-4-1-https-join-iclicker-com-fuyi"]], "(iClicker) Exercise 4.2": [[28, "iclicker-exercise-4-2"], [52, "iclicker-exercise-4-2"]], "(iClicker) Exercise 4.2 https://join.iclicker.com/FUYI": [[15, "iclicker-exercise-4-2-https-join-iclicker-com-fuyi"]], "(iClicker) Exercise 5.1": [[16, "iclicker-exercise-5-1"], [29, "iclicker-exercise-5-1"], [53, "iclicker-exercise-5-1"]], "(iClicker) Exercise 5.2": [[16, "iclicker-exercise-5-2"], [29, "iclicker-exercise-5-2"], [53, "iclicker-exercise-5-2"]], "(iClicker) Exercise 5.3": [[16, "iclicker-exercise-5-3"], [29, "iclicker-exercise-5-3"], [53, "iclicker-exercise-5-3"]], "(iClicker) Exercise 6.1": [[17, "iclicker-exercise-6-1"], [30, "iclicker-exercise-6-1"], [54, "iclicker-exercise-6-1"]], "(iClicker) Exercise 6.2": [[17, "iclicker-exercise-6-2"], [30, "iclicker-exercise-6-2"], [54, "iclicker-exercise-6-2"]], "(iClicker) Exercise 7.1": [[18, "iclicker-exercise-7-1"], [32, "iclicker-exercise-7-1"], [55, "iclicker-exercise-7-1"]], "(iClicker) Exercise 7.2": [[18, "iclicker-exercise-7-2"], [32, "iclicker-exercise-7-2"], [55, "iclicker-exercise-7-2"]], "(iClicker) Exercise 7.3": [[32, "iclicker-exercise-7-3"]], "(iClicker) Exercise 8.1": [[19, "iclicker-exercise-8-1"], [33, "iclicker-exercise-8-1"], [56, "iclicker-exercise-8-1"]], "(iClicker) Midterm poll": [[62, "iclicker-midterm-poll"]], "15.1 Select all of the following statements which are True (iClicker)": [[62, "select-all-of-the-following-statements-which-are-true-iclicker"]], "15.2 Select all of the following statements which are True (iClicker)": [[62, "id1"]], "15.3 Select all of the following statements which are True (iClicker)": [[62, "id3"]], "16.1 Select all of the following statements which are True (iClicker)": [[63, "select-all-of-the-following-statements-which-are-true-iclicker"]], "16.2 Select all of the following statements which are True (iClicker)": [[63, "id2"]], "16.3 Select all of the following statements which are True": [[63, "select-all-of-the-following-statements-which-are-true"]], "330 vs. 340": [[70, "vs-340"]], "<font color='red'>Question 10</font>": [[79, "question-10"]], "<font color='red'>Question 1</font>": [[74, "question-1"], [75, "question-1"], [77, "question-1"], [78, "question-1"], [79, "question-1"]], "<font color='red'>Question 2: Baseline model</font>": [[75, "question-2-baseline-model"]], "<font color='red'>Question 2</font>": [[74, "question-2"], [77, "question-2"], [78, "question-2"], [79, "question-2"]], "<font color='red'>Question 3: Decision tree</font>": [[75, "question-3-decision-tree"]], "<font color='red'>Question 3</font>": [[74, "question-3"], [77, "question-3"], [78, "question-3"], [79, "question-3"]], "<font color='red'>Question 4: Hyperparameter tuning</font>": [[75, "question-4-hyperparameter-tuning"]], "<font color='red'>Question 4</font>": [[74, "question-4"], [77, "question-4"], [78, "question-4"], [79, "question-4"]], "<font color='red'>Question 5: Cross-validation</font>": [[75, "question-5-cross-validation"]], "<font color='red'>Question 5</font>": [[77, "question-5"], [78, "question-5"], [79, "question-5"]], "<font color='red'>Question 6: Hyperparameters playground</font>": [[75, "question-6-hyperparameters-playground"]], "<font color='red'>Question 6</font>": [[77, "question-6"], [78, "question-6"], [79, "question-6"]], "<font color='red'>Question 7</font>": [[77, "question-7"], [79, "question-7"]], "<font color='red'>Question 8</font>": [[77, "question-8"], [79, "question-8"]], "<font color='red'>Question 9</font>": [[79, "question-9"]], "<font color='red'>Recap Questions</font>": [[74, "recap-questions"]], "<font color='red'>Recap/comprehension questions</font>": [[76, "recap-comprehension-questions"]], "A few comments on PR curve": [[20, "a-few-comments-on-pr-curve"], [34, "a-few-comments-on-pr-curve"], [47, "a-few-comments-on-pr-curve"], [57, "a-few-comments-on-pr-curve"]], "A few comments on clustering evaluation": [[63, "a-few-comments-on-clustering-evaluation"]], "AP score": [[20, "ap-score"], [34, "ap-score"], [47, "ap-score"], [57, "ap-score"]], "AP vs. F1-score": [[20, "ap-vs-f1-score"], [34, "ap-vs-f1-score"], [47, "ap-vs-f1-score"], [57, "ap-vs-f1-score"]], "API on the localhost": [[70, "api-on-the-localhost"]], "AUC or AP?": [[34, "auc-or-ap"]], "About this course": [[12, "about-this-course"], [25, "about-this-course"]], "About this document": [[8, "about-this-document"]], "Academic concessions": [[80, "academic-concessions"]], "Accessing homework assignments": [[7, "accessing-homework-assignments"]], "Accessing learned parameters": [[18, "accessing-learned-parameters"], [32, "accessing-learned-parameters"], [55, "accessing-learned-parameters"]], "Activity": [[12, "activity"], [25, "activity"]], "Activity (~5 mins)": [[23, "activity-5-mins"], [23, "id3"], [37, "activity-5-mins"], [37, "id3"], [39, "activity-5-mins"], [39, "id3"], [60, "activity-5-mins"], [60, "id3"]], "Activity: Context and word meaning": [[65, "activity-context-and-word-meaning"]], "Activity: Discuss the following questions in your group": [[42, "activity-discuss-the-following-questions-in-your-group"]], "Activity: How can you measure quality of the data? (~3 mins)": [[61, "activity-how-can-you-measure-quality-of-the-data-3-mins"]], "Activity: explaining GridSearchCV (15 min)": [[69, "activity-explaining-gridsearchcv-15-min"]], "Adding/removing columns with [] and drop()": [[8, "adding-removing-columns-with-and-drop"]], "Adding/removing rows with [] and drop()": [[8, "adding-removing-rows-with-and-drop"]], "Additional sources": [[37, "additional-sources"]], "Additional submission instructions": [[7, "additional-submission-instructions"]], "Addressing class imbalance": [[20, "addressing-class-imbalance"], [34, "addressing-class-imbalance"], [57, "addressing-class-imbalance"]], "Advantages of RandomizedSearchCV": [[19, "advantages-of-randomizedsearchcv"], [19, "id1"], [33, "advantages-of-randomizedsearchcv"], [33, "id1"], [56, "advantages-of-randomizedsearchcv"], [56, "id1"]], "Alternative and more compact syntax: make_pipeline": [[16, "alternative-and-more-compact-syntax-make-pipeline"], [29, "alternative-and-more-compact-syntax-make-pipeline"], [53, "alternative-and-more-compact-syntax-make-pipeline"]], "Alternative methods for scaling": [[44, "alternative-methods-for-scaling"]], "Alternative terminology for examples, features, targets, and training": [[13, "alternative-terminology-for-examples-features-targets-and-training"], [26, "alternative-terminology-for-examples-features-targets-and-training"], [50, "alternative-terminology-for-examples-features-targets-and-training"]], "An effective strategy": [[22, "an-effective-strategy"], [36, "an-effective-strategy"], [38, "an-effective-strategy"], [59, "an-effective-strategy"]], "An example from a project": [[71, "an-example-from-a-project"]], "An example of a bootstrap samples": [[22, "an-example-of-a-bootstrap-samples"], [36, "an-example-of-a-bootstrap-samples"], [38, "an-example-of-a-bootstrap-samples"], [59, "an-example-of-a-bootstrap-samples"]], "An introduction to Grid Search": [[69, "an-introduction-to-grid-search"]], "Analogy-based algorithms in practice": [[15, "analogy-based-algorithms-in-practice"], [52, "analogy-based-algorithms-in-practice"]], "Analogy-based models": [[15, "analogy-based-models"], [52, "analogy-based-models"]], "Announcements": [[12, "announcements"], [13, "announcements"], [14, "announcements"], [16, "announcements"], [17, "announcements"], [18, "announcements"], [20, "announcements"], [38, "announcements"], [39, "announcements"], [40, "announcements"], [55, "announcements"]], "Appendix A: Demo of feature engineering for text data": [[71, null]], "Appendix B: Multi-class, meta-strategies": [[72, null]], "Applying feature transformations": [[21, "applying-feature-transformations"], [35, "applying-feature-transformations"], [48, "applying-feature-transformations"], [58, "applying-feature-transformations"], [69, "applying-feature-transformations"]], "Applying functions to a dataframe with df.apply() and df.applymap()": [[8, "applying-functions-to-a-dataframe-with-df-apply-and-df-applymap"]], "Approach 1: Only consider the examples where \u201cChurn\u201d=Yes": [[68, "approach-1-only-consider-the-examples-where-churn-yes"]], "Approach 2: Assume everyone churns right now": [[68, "approach-2-assume-everyone-churns-right-now"]], "Approach 3: Survival analysis": [[68, "approach-3-survival-analysis"]], "Approach from all angles": [[69, "approach-from-all-angles"]], "Are we doing better with class_weight=\"balanced\"?": [[20, "are-we-doing-better-with-class-weight-balanced"], [34, "are-we-doing-better-with-class-weight-balanced"], [57, "are-we-doing-better-with-class-weight-balanced"]], "Are we getting the same alpha with mape?": [[48, "are-we-getting-the-same-alpha-with-mape"]], "Area under the curve (AUC)": [[20, "area-under-the-curve-auc"], [34, "area-under-the-curve-auc"], [47, "area-under-the-curve-auc"], [57, "area-under-the-curve-auc"]], "Assessing on the test set": [[42, "assessing-on-the-test-set"]], "Assignments": [[80, "assignments"]], "Attention": [[13, null], [13, null], [15, null], [26, null], [26, null], [28, null], [50, null], [50, null], [50, null], [52, null]], "Attribution": [[69, "attribution"]], "Automated hyperparameter optimization": [[19, "automated-hyperparameter-optimization"], [19, "id3"], [33, "automated-hyperparameter-optimization"], [33, "id3"], [56, "automated-hyperparameter-optimization"], [56, "id3"]], "Averaging": [[22, "averaging"], [36, "averaging"], [38, "averaging"], [59, "averaging"]], "Averaging simulation": [[79, "averaging-simulation"]], "Bad range for hyperparameters": [[19, "bad-range-for-hyperparameters"], [33, "bad-range-for-hyperparameters"], [56, "bad-range-for-hyperparameters"]], "Bag of words (BOW) representation": [[17, "bag-of-words-bow-representation"], [30, "bag-of-words-bow-representation"], [54, "bag-of-words-bow-representation"]], "Bag-of-words model": [[71, "bag-of-words-model"]], "Baseline": [[20, "baseline"], [23, "baseline"], [34, "baseline"], [37, "baseline"], [39, "baseline"], [47, "baseline"], [48, "baseline"], [57, "baseline"], [60, "baseline"]], "Baseline Approaches": [[64, "baseline-approaches"]], "Baseline model": [[42, "baseline-model"]], "Baselines": [[13, "baselines"], [22, "baselines"], [26, "baselines"], [36, "baselines"], [38, "baselines"], [50, "baselines"], [59, "baselines"]], "Baselines [video]": [[13, "baselines-video"], [26, "baselines-video"], [50, "baselines-video"]], "Basic text preprocessing [video]": [[65, "basic-text-preprocessing-video"]], "Better features usually help more than a better model.": [[24, "better-features-usually-help-more-than-a-better-model"], [40, "better-features-usually-help-more-than-a-better-model"], [61, "better-features-usually-help-more-than-a-better-model"]], "Beyond error rate in recommendation systems": [[64, "beyond-error-rate-in-recommendation-systems"]], "Bias vs variance tradeoff": [[14, "bias-vs-variance-tradeoff"], [27, "bias-vs-variance-tradeoff"], [51, "bias-vs-variance-tradeoff"]], "Big picture and datasets": [[13, "big-picture-and-datasets"], [26, "big-picture-and-datasets"], [50, "big-picture-and-datasets"]], "Big picture and motivation": [[14, "big-picture-and-motivation"], [27, "big-picture-and-motivation"], [51, "big-picture-and-motivation"]], "Books": [[1, "books"]], "Bottom-up explanations": [[69, "bottom-up-explanations"]], "Break (5 min)": [[8, "break-5-min"], [12, "break-5-min"], [13, "break-5-min"], [14, "break-5-min"], [15, "break-5-min"], [16, "break-5-min"], [17, "break-5-min"], [24, "break-5-min"], [25, "break-5-min"], [26, "break-5-min"], [27, "break-5-min"], [28, "break-5-min"], [30, "break-5-min"], [50, "break-5-min"], [51, "break-5-min"], [52, "break-5-min"], [53, "break-5-min"], [54, "break-5-min"], [61, "break-5-min"], [65, "break-5-min"], [66, "break-5-min"], [68, "break-5-min"], [69, "break-5-min"]], "Break (~15 min)": [[70, "break-15-min"]], "Broadcasting in numpy": [[8, "broadcasting-in-numpy"]], "Building a model": [[70, "building-a-model"]], "Building a supervise machine learning model": [[12, "building-a-supervise-machine-learning-model"], [25, "building-a-supervise-machine-learning-model"], [49, "building-a-supervise-machine-learning-model"]], "Building and deploying a web app": [[70, "building-and-deploying-a-web-app"]], "Building decision trees with sklearn": [[13, "building-decision-trees-with-sklearn"], [26, "building-decision-trees-with-sklearn"], [50, "building-decision-trees-with-sklearn"]], "Building user profiles": [[64, "building-user-profiles"]], "CPSC 330 Documents": [[3, null]], "CPSC 330 Python notes": [[8, null]], "CPSC 330 grading policies": [[6, null]], "CPSC 330 vs. 340": [[12, "cpsc-330-vs-340"], [25, "cpsc-330-vs-340"]], "CPSC 330 vs. CPSC 340": [[2, null]], "Can we get feature importances for non-linear models?": [[39, "can-we-get-feature-importances-for-non-linear-models"]], "Can we learn without targets?": [[62, "can-we-learn-without-targets"]], "Can we use this feature in the model?": [[16, "can-we-use-this-feature-in-the-model"], [29, "can-we-use-this-feature-in-the-model"], [53, "can-we-use-this-feature-in-the-model"]], "Cases where it\u2019s OK to break the golden rule": [[17, "cases-where-it-s-ok-to-break-the-golden-rule"], [30, "cases-where-it-s-ok-to-break-the-golden-rule"], [54, "cases-where-it-s-ok-to-break-the-golden-rule"]], "CatBoost": [[22, "catboost"], [36, "catboost"], [38, "catboost"], [59, "catboost"]], "Categorical features": [[23, "categorical-features"], [37, "categorical-features"], [39, "categorical-features"], [44, "categorical-features"], [60, "categorical-features"]], "Categorical features [video]": [[16, "categorical-features-video"], [29, "categorical-features-video"], [53, "categorical-features-video"]], "Categorical features with only two possible categories": [[17, "categorical-features-with-only-two-possible-categories"], [30, "categorical-features-with-only-two-possible-categories"], [54, "categorical-features-with-only-two-possible-categories"]], "Censoring and survival analysis": [[68, "censoring-and-survival-analysis"]], "Centre for Accessibility (CfA) Exam Accommodations": [[80, "centre-for-accessibility-cfa-exam-accommodations"]], "Changing the training procedure": [[20, "changing-the-training-procedure"], [34, "changing-the-training-procedure"], [57, "changing-the-training-procedure"]], "Characters in this course?": [[12, "characters-in-this-course"], [25, "characters-in-this-course"], [49, "characters-in-this-course"]], "Checklist for you before next class": [[12, "checklist-for-you-before-next-class"], [25, "checklist-for-you-before-next-class"]], "Choosing K [video]": [[62, "choosing-k-video"]], "Choosing n_neighbors": [[15, "choosing-n-neighbors"], [28, "choosing-n-neighbors"], [52, "choosing-n-neighbors"]], "Citing sources": [[7, "citing-sources"]], "Class imbalance in training sets": [[20, "class-imbalance-in-training-sets"], [34, "class-imbalance-in-training-sets"], [57, "class-imbalance-in-training-sets"]], "Class meetings": [[80, "class-meetings"]], "Classification report": [[20, "classification-report"], [34, "classification-report"], [47, "classification-report"], [57, "classification-report"]], "Classification vs. Regression": [[13, "classification-vs-regression"], [26, "classification-vs-regression"], [50, "classification-vs-regression"]], "Classification with KNeighborsClassifier": [[43, "classification-with-kneighborsclassifier"]], "Clustering": [[73, "clustering"]], "Clustering Activity (~5 mins)": [[62, "clustering-activity-5-mins"]], "Clustering motivation [video]": [[62, "clustering-motivation-video"]], "Clustering: Input and (possible) output": [[62, "clustering-input-and-possible-output"]], "Code of conduct": [[80, "code-of-conduct"]], "Coefficients and intercept": [[18, "coefficients-and-intercept"], [32, "coefficients-and-intercept"], [55, "coefficients-and-intercept"]], "ColumnTransformer example": [[17, "columntransformer-example"], [30, "columntransformer-example"], [54, "columntransformer-example"]], "ColumnTransformer on the California housing dataset": [[54, "columntransformer-on-the-california-housing-dataset"], [76, "columntransformer-on-the-california-housing-dataset"]], "ColumnTransformer: Transformed data": [[17, "columntransformer-transformed-data"], [30, "columntransformer-transformed-data"], [54, "columntransformer-transformed-data"]], "Coming up \u2026": [[14, "coming-up"], [27, "coming-up"], [51, "coming-up"]], "Coming up:": [[15, "coming-up"], [28, "coming-up"], [52, "coming-up"]], "Command-line git": [[5, "command-line-git"]], "Common applications": [[62, "common-applications"]], "Common preprocessing techniques": [[16, "common-preprocessing-techniques"], [29, "common-preprocessing-techniques"], [53, "common-preprocessing-techniques"]], "Communication": [[73, "communication"]], "Communications": [[12, "communications"], [25, "communications"]], "Completing the utility matrix with content-based filtering": [[64, "completing-the-utility-matrix-with-content-based-filtering"]], "Components of a linear classifier": [[18, "components-of-a-linear-classifier"], [32, "components-of-a-linear-classifier"], [55, "components-of-a-linear-classifier"]], "Concepts then labels, not the other way around": [[69, "concepts-then-labels-not-the-other-way-around"]], "Concepts we revised in this demo": [[42, "concepts-we-revised-in-this-demo"]], "Conclusion & farewell": [[70, "conclusion-farewell"]], "Confidence and predict_proba (20 min)": [[69, "confidence-and-predict-proba-20-min"]], "Confusing and perhaps misleading visualization of results": [[69, "confusing-and-perhaps-misleading-visualization-of-results"]], "Confusion matrix": [[20, "confusion-matrix"], [47, "confusion-matrix"]], "Confusion matrix (video)": [[34, "confusion-matrix-video"], [57, "confusion-matrix-video"]], "Confusion matrix with cross-validation": [[20, "confusion-matrix-with-cross-validation"], [34, "confusion-matrix-with-cross-validation"], [47, "confusion-matrix-with-cross-validation"], [57, "confusion-matrix-with-cross-validation"]], "Cons of k-NNs for supervised learning": [[15, "cons-of-k-nns-for-supervised-learning"], [28, "cons-of-k-nns-for-supervised-learning"], [52, "cons-of-k-nns-for-supervised-learning"]], "Content-based filtering": [[64, "content-based-filtering"]], "Convenient make_column_transformer syntax": [[17, "convenient-make-column-transformer-syntax"], [30, "convenient-make-column-transformer-syntax"], [54, "convenient-make-column-transformer-syntax"]], "Course Learning Objectives": [[11, null]], "Course co-ordinator": [[1, "course-co-ordinator"], [80, "course-co-ordinator"]], "Course description": [[80, "course-description"]], "Course format": [[12, "course-format"], [25, "course-format"]], "Course review / conclusion (~20 min)": [[70, "course-review-conclusion-20-min"]], "Course website": [[12, "course-website"], [25, "course-website"]], "Cox proportional hazards model": [[68, "cox-proportional-hazards-model"]], "Create X and y": [[13, "create-x-and-y"], [26, "create-x-and-y"], [50, "create-x-and-y"]], "Create a classifier object": [[13, "create-a-classifier-object"], [26, "create-a-classifier-object"], [50, "create-a-classifier-object"]], "Create a column transformer": [[17, "create-a-column-transformer"], [30, "create-a-column-transformer"], [54, "create-a-column-transformer"]], "Creating train_df and test_df": [[14, "creating-train-df-and-test-df"], [27, "creating-train-df-and-test-df"], [51, "creating-train-df-and-test-df"]], "Creating utility matrix": [[64, "creating-utility-matrix"]], "Credit": [[10, "credit"]], "Cross validation with different metrics": [[20, "cross-validation-with-different-metrics"], [34, "cross-validation-with-different-metrics"], [47, "cross-validation-with-different-metrics"], [57, "cross-validation-with-different-metrics"]], "Cross-validation": [[42, "cross-validation"], [67, "cross-validation"], [67, "id4"]], "Cross-validation [video]": [[14, "cross-validation-video"], [27, "cross-validation-video"], [51, "cross-validation-video"]], "Cross-validation to the rescue!!": [[14, "cross-validation-to-the-rescue"], [27, "cross-validation-to-the-rescue"], [51, "cross-validation-to-the-rescue"]], "Cross-validation using scikit-learn": [[14, "cross-validation-using-scikit-learn"], [27, "cross-validation-using-scikit-learn"], [51, "cross-validation-using-scikit-learn"]], "Curse of dimensionality": [[15, "curse-of-dimensionality"], [28, "curse-of-dimensionality"], [52, "curse-of-dimensionality"]], "Customer churn": [[68, "customer-churn"]], "Customer segmentation": [[62, "customer-segmentation"]], "DBSCAN [video]": [[63, "dbscan-video"]], "DBSCAN introduction": [[63, "dbscan-introduction"]], "DBSCAN: failure cases": [[63, "dbscan-failure-cases"], [63, "id1"]], "Data": [[17, "data"], [18, "data"], [22, "data"], [23, "data"], [23, "id1"], [30, "data"], [32, "data"], [36, "data"], [37, "data"], [37, "id1"], [38, "data"], [39, "data"], [39, "id1"], [54, "data"], [55, "data"], [59, "data"], [60, "data"], [60, "id1"]], "Data Splitting [video]": [[14, "data-splitting-video"], [27, "data-splitting-video"], [51, "data-splitting-video"]], "Data and main approaches": [[64, "data-and-main-approaches"]], "Data and splitting": [[44, "data-and-splitting"]], "Data exploration": [[62, "data-exploration"]], "Data splitting": [[42, "data-splitting"], [75, "data-splitting"]], "Dataframe summaries": [[8, "dataframe-summaries"]], "Dataset": [[48, "dataset"], [66, "dataset"], [69, "dataset"]], "Dataset [video]": [[21, "dataset-video"], [35, "dataset-video"], [58, "dataset-video"]], "Dataset for demonstration": [[20, "dataset-for-demonstration"], [34, "dataset-for-demonstration"], [47, "dataset-for-demonstration"], [57, "dataset-for-demonstration"]], "Dataset, splitting, and baseline": [[16, "dataset-splitting-and-baseline"], [29, "dataset-splitting-and-baseline"], [53, "dataset-splitting-and-baseline"]], "Datasets": [[7, "datasets"]], "Dealing with class imbalance (video)": [[34, "dealing-with-class-imbalance-video"], [57, "dealing-with-class-imbalance-video"]], "Dealing with class imbalance [video]": [[20, "dealing-with-class-imbalance-video"]], "Dealing with unknown categories": [[17, "dealing-with-unknown-categories"], [30, "dealing-with-unknown-categories"], [54, "dealing-with-unknown-categories"]], "Debugging": [[10, "debugging"]], "Decision boundaries playground": [[43, "decision-boundaries-playground"]], "Decision boundary": [[13, "decision-boundary"], [26, "decision-boundary"], [50, "decision-boundary"]], "Decision boundary for max_depth=1": [[13, "decision-boundary-for-max-depth-1"], [26, "decision-boundary-for-max-depth-1"], [50, "decision-boundary-for-max-depth-1"]], "Decision boundary for max_depth=2": [[13, "decision-boundary-for-max-depth-2"], [26, "decision-boundary-for-max-depth-2"], [50, "decision-boundary-for-max-depth-2"]], "Decision boundary for max_depth=5": [[13, "decision-boundary-for-max-depth-5"], [26, "decision-boundary-for-max-depth-5"], [50, "decision-boundary-for-max-depth-5"]], "Decision boundary of SVMs": [[15, "decision-boundary-of-svms"], [28, "decision-boundary-of-svms"], [52, "decision-boundary-of-svms"]], "Decision boundary of logistic regression": [[18, "decision-boundary-of-logistic-regression"], [32, "decision-boundary-of-logistic-regression"], [55, "decision-boundary-of-logistic-regression"]], "Decision tree algorithm": [[13, "decision-tree-algorithm"], [26, "decision-tree-algorithm"], [50, "decision-tree-algorithm"]], "Decision tree feature importances": [[23, "decision-tree-feature-importances"], [37, "decision-tree-feature-importances"], [39, "decision-tree-feature-importances"], [60, "decision-tree-feature-importances"]], "Decision tree for regression problems": [[13, "decision-tree-for-regression-problems"], [26, "decision-tree-for-regression-problems"], [50, "decision-tree-for-regression-problems"]], "Decision tree model": [[42, "decision-tree-model"]], "Decision tree with max_depth=1": [[13, "decision-tree-with-max-depth-1"], [26, "decision-tree-with-max-depth-1"], [50, "decision-tree-with-max-depth-1"]], "Decision tree with max_depth=3": [[13, "decision-tree-with-max-depth-3"], [26, "decision-tree-with-max-depth-3"], [50, "decision-tree-with-max-depth-3"]], "Decision trees [video]": [[13, "decision-trees-video"], [26, "decision-trees-video"], [50, "decision-trees-video"]], "Decision trees with continuous features": [[13, "decision-trees-with-continuous-features"], [26, "decision-trees-with-continuous-features"], [50, "decision-trees-with-continuous-features"]], "DecisionTreeClassifier baseline": [[22, "decisiontreeclassifier-baseline"], [36, "decisiontreeclassifier-baseline"], [38, "decisiontreeclassifier-baseline"], [59, "decisiontreeclassifier-baseline"]], "DecisionTreeClassifier on quiz2 grade prediction toy dataset": [[13, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"], [26, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"], [50, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"]], "Decisions involve a few key pieces": [[69, "decisions-involve-a-few-key-pieces"]], "Decreasing the threshold": [[20, "decreasing-the-threshold"], [34, "decreasing-the-threshold"], [47, "decreasing-the-threshold"], [57, "decreasing-the-threshold"]], "Deep learning": [[67, "deep-learning"]], "Deep learning software": [[66, "deep-learning-software"]], "Deliverable due dates (tentative)": [[1, "deliverable-due-dates-tentative"]], "Demo of creating a new web service": [[70, "demo-of-creating-a-new-web-service"]], "Demo of feature engineering with numeric features": [[24, "demo-of-feature-engineering-with-numeric-features"], [40, "demo-of-feature-engineering-with-numeric-features"], [61, "demo-of-feature-engineering-with-numeric-features"]], "Demo: A more complicated dataset": [[67, "demo-a-more-complicated-dataset"]], "Demo: Deploying moment classification model": [[70, "demo-deploying-moment-classification-model"]], "Demo: Model interpretation of linear classifiers": [[31, "demo-model-interpretation-of-linear-classifiers"], [45, "demo-model-interpretation-of-linear-classifiers"], [46, "demo-model-interpretation-of-linear-classifiers"]], "Dendrogram": [[63, "dendrogram"]], "Deploying the API on a server (not covered)": [[70, "deploying-the-api-on-a-server-not-covered"]], "Deployment (Not examinable)": [[73, "deployment-not-examinable"]], "Difference between Statistics and Machine Learning": [[70, "difference-between-statistics-and-machine-learning"]], "Different models": [[23, "different-models"], [37, "different-models"], [39, "different-models"], [60, "different-models"]], "Different range for hyperparameters yields better results!": [[19, "different-range-for-hyperparameters-yields-better-results"], [33, "different-range-for-hyperparameters-yields-better-results"], [56, "different-range-for-hyperparameters-yields-better-results"]], "Different scoring functions with cross_validate": [[21, "different-scoring-functions-with-cross-validate"], [35, "different-scoring-functions-with-cross-validate"], [48, "different-scoring-functions-with-cross-validate"], [58, "different-scoring-functions-with-cross-validate"]], "Dimensions in ML problems": [[15, "dimensions-in-ml-problems"], [28, "dimensions-in-ml-problems"], [52, "dimensions-in-ml-problems"]], "Discuss the following questions in your group": [[42, "discuss-the-following-questions-in-your-group"]], "Discussion": [[70, "discussion"]], "Discussion question": [[65, "discussion-question"]], "Discussion questions": [[44, "discussion-questions"]], "Discussion questions:": [[69, "discussion-questions"]], "Distance between feature vectors": [[15, "distance-between-feature-vectors"], [28, "distance-between-feature-vectors"], [52, "distance-between-feature-vectors"]], "Do we actually want to use certain features for prediction?": [[17, "do-we-actually-want-to-use-certain-features-for-prediction"], [54, "do-we-actually-want-to-use-certain-features-for-prediction"]], "Do we have class imbalance?": [[22, "do-we-have-class-imbalance"], [23, "do-we-have-class-imbalance"], [36, "do-we-have-class-imbalance"], [37, "do-we-have-class-imbalance"], [38, "do-we-have-class-imbalance"], [39, "do-we-have-class-imbalance"], [59, "do-we-have-class-imbalance"], [60, "do-we-have-class-imbalance"]], "Do we have correlated features?": [[23, "do-we-have-correlated-features"], [37, "do-we-have-correlated-features"], [39, "do-we-have-correlated-features"], [60, "do-we-have-correlated-features"]], "Document clustering": [[62, "document-clustering"]], "Domain-specific transformations": [[24, "domain-specific-transformations"], [40, "domain-specific-transformations"], [61, "domain-specific-transformations"]], "Domain-specific transformations (Genomics)": [[40, "domain-specific-transformations-genomics"], [40, "id1"]], "Dummy Classifier": [[44, "dummy-classifier"]], "Dummy classifier": [[71, "dummy-classifier"]], "Dummy model": [[43, "dummy-model"]], "DummyClassifier": [[13, "dummyclassifier"], [26, "dummyclassifier"], [50, "dummyclassifier"], [67, "dummyclassifier"], [68, "dummyclassifier"]], "DummyClassifier baseline": [[22, "dummyclassifier-baseline"], [36, "dummyclassifier-baseline"], [38, "dummyclassifier-baseline"], [59, "dummyclassifier-baseline"]], "DummyClassifier on quiz2 grade prediction toy dataset": [[13, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"], [26, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"], [50, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"]], "DummyRegressor": [[13, "dummyregressor"], [21, "dummyregressor"], [26, "dummyregressor"], [35, "dummyregressor"], [50, "dummyregressor"], [58, "dummyregressor"]], "EDA": [[16, "eda"], [20, "eda"], [21, "eda"], [29, "eda"], [34, "eda"], [35, "eda"], [47, "eda"], [48, "eda"], [53, "eda"], [57, "eda"], [58, "eda"]], "EDA: Exploratory Data Analysis": [[75, "eda-exploratory-data-analysis"]], "Encoding text data": [[17, "encoding-text-data"], [30, "encoding-text-data"], [54, "encoding-text-data"]], "Encoding time as a number": [[67, "encoding-time-as-a-number"]], "Encoding time of day as a categorical feature": [[67, "encoding-time-of-day-as-a-categorical-feature"]], "Ensemble models": [[36, "ensemble-models"]], "Ensembles": [[73, "ensembles"]], "Equally good": [[69, "equally-good"]], "Ethics": [[73, "ethics"]], "Euclidean distance": [[15, "euclidean-distance"], [28, "euclidean-distance"], [52, "euclidean-distance"]], "Evaluating DBSCAN clusters": [[63, "evaluating-dbscan-clusters"]], "Evaluation": [[64, "evaluation"], [64, "id3"]], "Evaluation metrics": [[73, "evaluation-metrics"]], "Evaluation metrics for binary classification: Motivation": [[20, "evaluation-metrics-for-binary-classification-motivation"], [34, "evaluation-metrics-for-binary-classification-motivation"], [47, "evaluation-metrics-for-binary-classification-motivation"], [57, "evaluation-metrics-for-binary-classification-motivation"]], "Evalution metrics overview": [[20, "evalution-metrics-overview"], [34, "evalution-metrics-overview"], [47, "evalution-metrics-overview"], [57, "evalution-metrics-overview"]], "Examining learned coefficients": [[31, "examining-learned-coefficients"], [45, "examining-learned-coefficients"], [46, "examining-learned-coefficients"]], "Examining the preprocessed data": [[21, "examining-the-preprocessed-data"], [35, "examining-the-preprocessed-data"], [48, "examining-the-preprocessed-data"], [58, "examining-the-preprocessed-data"], [69, "examining-the-preprocessed-data"]], "Examining the vocabulary": [[31, "examining-the-vocabulary"], [45, "examining-the-vocabulary"], [46, "examining-the-vocabulary"]], "Example": [[18, "example"], [22, "example"], [32, "example"], [36, "example"], [38, "example"], [55, "example"], [59, "example"]], "Example 1": [[39, "example-1"]], "Example 1: Predicting whether a patient has a liver disease or not": [[12, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"], [25, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"], [49, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"]], "Example 1: What is \u201ccorrect\u201d grouping?": [[62, "example-1-what-is-correct-grouping"]], "Example 1: quiz 2 grade prediction": [[13, "example-1-quiz-2-grade-prediction"], [26, "example-1-quiz-2-grade-prediction"], [50, "example-1-quiz-2-grade-prediction"]], "Example 2": [[39, "example-2"]], "Example 2: Predicting country using the longitude and latitude": [[13, "example-2-predicting-country-using-the-longitude-and-latitude"], [50, "example-2-predicting-country-using-the-longitude-and-latitude"]], "Example 2: Predicting the label of a given image": [[12, "example-2-predicting-the-label-of-a-given-image"], [25, "example-2-predicting-the-label-of-a-given-image"], [49, "example-2-predicting-the-label-of-a-given-image"]], "Example 3: Predicting housing prices": [[12, "example-3-predicting-housing-prices"], [25, "example-3-predicting-housing-prices"], [49, "example-3-predicting-housing-prices"]], "Example showing how can we interpret coefficients of scaled features.": [[23, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"], [37, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"], [39, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"], [60, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"]], "Example: Is \u201cRelevance\u201d clearly defined?": [[24, "example-is-relevance-clearly-defined"], [40, "example-is-relevance-clearly-defined"], [61, "example-is-relevance-clearly-defined"]], "Example: Predict whether a message is spam or not": [[12, "example-predict-whether-a-message-is-spam-or-not"], [25, "example-predict-whether-a-message-is-spam-or-not"], [49, "example-predict-whether-a-message-is-spam-or-not"]], "Example: Supervised vs unsupervised learning": [[62, "example-supervised-vs-unsupervised-learning"]], "Example: Tabular data for grade prediction": [[13, "example-tabular-data-for-grade-prediction"], [26, "example-tabular-data-for-grade-prediction"], [50, "example-tabular-data-for-grade-prediction"]], "Example: Tabular data for the housing price prediction": [[13, "example-tabular-data-for-the-housing-price-prediction"], [50, "example-tabular-data-for-the-housing-price-prediction"]], "Example: class_weight parameter of sklearn LogisticRegression": [[20, "example-class-weight-parameter-of-sklearn-logisticregression"], [34, "example-class-weight-parameter-of-sklearn-logisticregression"], [57, "example-class-weight-parameter-of-sklearn-logisticregression"]], "Example: k-nearest neighbours on the Spotify dataset": [[16, "example-k-nearest-neighbours-on-the-spotify-dataset"], [29, "example-k-nearest-neighbours-on-the-spotify-dataset"], [53, "example-k-nearest-neighbours-on-the-spotify-dataset"]], "Examples": [[12, "examples"], [25, "examples"], [49, "examples"]], "Exercise 17.1 Select all of the following statements which are True (iClicker)": [[64, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 17.2 Select all of the following statements which are True (iClicker)": [[64, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 2.1 Select all of the following statements which are examples of supervised machine learning": [[13, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"], [50, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"]], "Exercise 2.3": [[26, "exercise-2-3"]], "Exercise 2.4": [[13, "exercise-2-4"], [50, "exercise-2-4"]], "Exercise 8.2": [[19, "exercise-8-2"], [33, "exercise-8-2"], [56, "exercise-8-2"]], "Exercise: Predicting country using the longitude and latitude": [[74, "exercise-predicting-country-using-the-longitude-and-latitude"]], "Exhaustive grid search: sklearn.model_selection.GridSearchCV": [[19, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"], [33, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"], [56, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"]], "Explaining a prediction": [[23, "explaining-a-prediction"], [37, "explaining-a-prediction"], [39, "explaining-a-prediction"], [60, "explaining-a-prediction"]], "Explanation 1": [[69, "explanation-1"]], "Explanation 2": [[69, "explanation-2"]], "Exploratory Data Analysis": [[42, "exploratory-data-analysis"]], "Exploratory data analysis": [[44, "exploratory-data-analysis"], [67, "exploratory-data-analysis"]], "Exploring the model": [[48, "exploring-the-model"]], "Extracting BOW features using scikit-learn": [[17, "extracting-bow-features-using-scikit-learn"], [30, "extracting-bow-features-using-scikit-learn"], [54, "extracting-bow-features-using-scikit-learn"]], "Extracting date and time information": [[67, "extracting-date-and-time-information"]], "F1-score": [[20, "f1-score"], [34, "f1-score"], [47, "f1-score"], [57, "f1-score"]], "Faster method: vectorize the loop over rows": [[8, "faster-method-vectorize-the-loop-over-rows"]], "Fastest method: broadcasting": [[8, "fastest-method-broadcasting"]], "Feature crosses for one-hot encoded features": [[24, "feature-crosses-for-one-hot-encoded-features"], [40, "feature-crosses-for-one-hot-encoded-features"], [61, "feature-crosses-for-one-hot-encoded-features"]], "Feature engineering": [[40, "feature-engineering"], [67, "feature-engineering"]], "Feature engineering and selection": [[73, "feature-engineering-and-selection"]], "Feature engineering for date/time columns": [[67, "feature-engineering-for-date-time-columns"]], "Feature engineering: Encoding date/time as feature(s)": [[67, "feature-engineering-encoding-date-time-as-feature-s"]], "Feature engineering: Motivation": [[24, "feature-engineering-motivation"], [40, "feature-engineering-motivation"], [61, "feature-engineering-motivation"]], "Feature importances": [[23, "feature-importances"], [37, "feature-importances"], [39, "feature-importances"], [60, "feature-importances"], [73, "feature-importances"]], "Feature importances in linear models": [[23, "feature-importances-in-linear-models"], [23, "id2"], [37, "feature-importances-in-linear-models"], [37, "id2"], [39, "feature-importances-in-linear-models"], [39, "id2"], [60, "feature-importances-in-linear-models"], [60, "id2"]], "Feature interactions and feature crosses": [[24, "feature-interactions-and-feature-crosses"], [40, "feature-interactions-and-feature-crosses"], [61, "feature-interactions-and-feature-crosses"]], "Feature names of transformed data": [[21, "feature-names-of-transformed-data"], [35, "feature-names-of-transformed-data"], [58, "feature-names-of-transformed-data"]], "Feature selection: Introduction and motivation": [[24, "feature-selection-introduction-and-motivation"], [40, "feature-selection-introduction-and-motivation"], [61, "feature-selection-introduction-and-motivation"]], "Feature transformations and the golden rule": [[16, "feature-transformations-and-the-golden-rule"], [29, "feature-transformations-and-the-golden-rule"], [53, "feature-transformations-and-the-golden-rule"]], "Feature types": [[21, "feature-types"], [21, "id1"], [35, "feature-types"], [35, "id1"], [48, "feature-types"], [58, "feature-types"], [58, "id1"], [69, "feature-types"]], "Feature vectors": [[15, "feature-vectors"], [52, "feature-vectors"]], "Figures": [[7, "figures"]], "Filtering a dataframe with [] and df.query()": [[8, "filtering-a-dataframe-with-and-df-query"]], "Final comments and summary": [[19, "final-comments-and-summary"], [33, "final-comments-and-summary"], [56, "final-comments-and-summary"], [64, "final-comments-and-summary"]], "Final comments, summary, and reflection": [[13, "final-comments-summary-and-reflection"], [26, "final-comments-summary-and-reflection"], [50, "final-comments-summary-and-reflection"], [62, "final-comments-summary-and-reflection"], [63, "final-comments-summary-and-reflection"]], "Final exam": [[80, "final-exam"]], "Final exam preparation: guiding questions": [[73, null]], "Final note": [[75, "final-note"]], "Final remarks": [[67, "final-remarks"]], "Finding the distances to a query point": [[15, "finding-the-distances-to-a-query-point"], [28, "finding-the-distances-to-a-query-point"], [52, "finding-the-distances-to-a-query-point"]], "Finding the nearest neighbour": [[15, "finding-the-nearest-neighbour"], [28, "finding-the-nearest-neighbour"], [52, "finding-the-nearest-neighbour"]], "First deliverables": [[12, "first-deliverables"], [25, "first-deliverables"]], "Forecasting further into the future": [[67, "forecasting-further-into-the-future"]], "Forecasting further into the future on a retail dataset": [[67, "forecasting-further-into-the-future-on-a-retail-dataset"]], "Formulating the problem of recommender systems": [[64, "formulating-the-problem-of-recommender-systems"]], "GB better than RF": [[69, "gb-better-than-rf"]], "Garbage in, garbage out.": [[24, "garbage-in-garbage-out"], [40, "garbage-in-garbage-out"], [61, "garbage-in-garbage-out"]], "General advice on finding relevant features": [[24, "general-advice-on-finding-relevant-features"], [40, "general-advice-on-finding-relevant-features"], [61, "general-advice-on-finding-relevant-features"]], "General guidelines": [[6, "general-guidelines"]], "General idea": [[22, "general-idea"], [36, "general-idea"], [38, "general-idea"], [59, "general-idea"]], "General idea of k-nearest neighbours algorithm": [[15, "general-idea-of-k-nearest-neighbours-algorithm"], [28, "general-idea-of-k-nearest-neighbours-algorithm"], [52, "general-idea-of-k-nearest-neighbours-algorithm"]], "General idea of search and score methods": [[24, "general-idea-of-search-and-score-methods"], [40, "general-idea-of-search-and-score-methods"], [61, "general-idea-of-search-and-score-methods"]], "General questions": [[4, "general-questions"]], "Generalization [video]": [[14, "generalization-video"], [27, "generalization-video"], [51, "generalization-video"]], "Generalization: Fundamental goal of ML": [[14, "generalization-fundamental-goal-of-ml"], [27, "generalization-fundamental-goal-of-ml"], [51, "generalization-fundamental-goal-of-ml"]], "Generalizing to more features": [[18, "generalizing-to-more-features"], [32, "generalizing-to-more-features"], [55, "generalizing-to-more-features"]], "Generalizing to unseen data": [[14, "generalizing-to-unseen-data"], [27, "generalizing-to-unseen-data"], [51, "generalizing-to-unseen-data"]], "Geometric view of tabular data and dimensions": [[15, "geometric-view-of-tabular-data-and-dimensions"], [28, "geometric-view-of-tabular-data-and-dimensions"], [52, "geometric-view-of-tabular-data-and-dimensions"]], "Git": [[10, "git"]], "GitHub Desktop": [[5, "github-desktop"]], "Global average baseline": [[64, "global-average-baseline"]], "Golden rule violation: Example 1": [[14, "golden-rule-violation-example-1"], [51, "golden-rule-violation-example-1"]], "Golden rule violation: Example 2": [[14, "golden-rule-violation-example-2"], [51, "golden-rule-violation-example-2"]], "Grades": [[25, "grades"]], "Gradient boosted trees [video]": [[22, "gradient-boosted-trees-video"], [36, "gradient-boosted-trees-video"], [38, "gradient-boosted-trees-video"], [59, "gradient-boosted-trees-video"]], "Gradient boosting in sklearn": [[22, "gradient-boosting-in-sklearn"], [36, "gradient-boosting-in-sklearn"], [38, "gradient-boosting-in-sklearn"], [59, "gradient-boosting-in-sklearn"]], "Grading concerns: time limit": [[6, "grading-concerns-time-limit"]], "Grading scheme": [[80, "grading-scheme"]], "Grading-related questions": [[4, "grading-related-questions"]], "Handling imbalance": [[20, "handling-imbalance"], [34, "handling-imbalance"], [57, "handling-imbalance"]], "Here is the workflow we\u2019ll generally follow.": [[14, "here-is-the-workflow-we-ll-generally-follow"], [27, "here-is-the-workflow-we-ll-generally-follow"], [51, "here-is-the-workflow-we-ll-generally-follow"]], "Hierarchical clustering [video]": [[63, "hierarchical-clustering-video"]], "Homework info & submission guidelines": [[7, null]], "How are we making predictions?": [[18, "how-are-we-making-predictions"], [32, "how-are-we-making-predictions"], [55, "how-are-we-making-predictions"]], "How can we avoid violating golden rule?": [[14, "how-can-we-avoid-violating-golden-rule"], [27, "how-can-we-avoid-violating-golden-rule"], [51, "how-can-we-avoid-violating-golden-rule"]], "How can we get feature importances for non sklearn models?": [[23, "how-can-we-get-feature-importances-for-non-sklearn-models"], [39, "how-can-we-get-feature-importances-for-non-sklearn-models"], [60, "how-can-we-get-feature-importances-for-non-sklearn-models"]], "How do they work?": [[22, "how-do-they-work"], [36, "how-do-they-work"], [38, "how-do-they-work"], [59, "how-do-they-work"]], "How do we carry out feature selection?": [[24, "how-do-we-carry-out-feature-selection"], [40, "how-do-we-carry-out-feature-selection"], [61, "how-do-we-carry-out-feature-selection"]], "How does fit work?": [[13, "how-does-fit-work"], [13, "id2"], [26, "how-does-fit-work"], [50, "how-does-fit-work"], [50, "id2"]], "How does it work?": [[63, "how-does-it-work"], [69, "how-does-it-work"]], "How does logistic regression calculate these probabilities?": [[18, "how-does-logistic-regression-calculate-these-probabilities"], [32, "how-does-logistic-regression-calculate-these-probabilities"], [55, "how-does-logistic-regression-calculate-these-probabilities"]], "How does predict work?": [[13, "how-does-predict-work"], [26, "how-does-predict-work"], [50, "how-does-predict-work"]], "How to approximate generalization error?": [[14, "how-to-approximate-generalization-error"], [27, "how-to-approximate-generalization-error"], [51, "how-to-approximate-generalization-error"]], "How to ask for help": [[4, null]], "How to carry out cross-validation?": [[16, "how-to-carry-out-cross-validation"], [29, "how-to-carry-out-cross-validation"], [53, "how-to-carry-out-cross-validation"]], "How to choose n_neighbors?": [[15, "how-to-choose-n-neighbors"], [28, "how-to-choose-n-neighbors"], [52, "how-to-choose-n-neighbors"]], "How to pick a model that would generalize better?": [[14, "how-to-pick-a-model-that-would-generalize-better"], [27, "how-to-pick-a-model-that-would-generalize-better"], [51, "how-to-pick-a-model-that-would-generalize-better"]], "How to submit": [[7, "how-to-submit"]], "How would you do it properly? Enter sklearn pipelines!!": [[44, "how-would-you-do-it-properly-enter-sklearn-pipelines"]], "Hyperparameter alpha of Ridge": [[18, "hyperparameter-alpha-of-ridge"], [32, "hyperparameter-alpha-of-ridge"], [55, "hyperparameter-alpha-of-ridge"]], "Hyperparameter optimization": [[42, "hyperparameter-optimization"], [73, "hyperparameter-optimization"]], "Hyperparameter optimization motivation": [[19, "hyperparameter-optimization-motivation"], [56, "hyperparameter-optimization-motivation"]], "Hyperparameter optimization motivation (video)": [[33, "hyperparameter-optimization-motivation-video"]], "Hyperparameter tuning for the number of clusters": [[62, "hyperparameter-tuning-for-the-number-of-clusters"]], "Hyperparameters of SVM": [[15, "hyperparameters-of-svm"], [28, "hyperparameters-of-svm"], [52, "hyperparameters-of-svm"]], "Hyperparameters: the problem": [[19, "hyperparameters-the-problem"], [33, "hyperparameters-the-problem"], [56, "hyperparameters-the-problem"]], "Identify the transformations we want to apply": [[17, "identify-the-transformations-we-want-to-apply"], [30, "identify-the-transformations-we-want-to-apply"], [54, "identify-the-transformations-we-want-to-apply"]], "Image classification using KNNs and SVM RBF": [[43, "image-classification-using-knns-and-svm-rbf"]], "ImageNet": [[66, "imagenet"]], "Import": [[71, "import"]], "Importance of scaling": [[18, "importance-of-scaling"], [32, "importance-of-scaling"], [55, "importance-of-scaling"]], "Important hyperparameters": [[22, "important-hyperparameters"], [36, "important-hyperparameters"], [38, "important-hyperparameters"], [59, "important-hyperparameters"]], "Important hyperparameters of CountVectorizer": [[17, "important-hyperparameters-of-countvectorizer"], [30, "important-hyperparameters-of-countvectorizer"], [54, "important-hyperparameters-of-countvectorizer"]], "Important links": [[1, "important-links"]], "Important points to remember": [[62, "important-points-to-remember"]], "Imports": [[12, "imports"], [13, "imports"], [14, "imports"], [15, "imports"], [15, "id1"], [16, "imports"], [17, "imports"], [18, "imports"], [19, "imports"], [20, "imports"], [21, "imports"], [22, "imports"], [23, "imports"], [24, "imports"], [25, "imports"], [26, "imports"], [27, "imports"], [28, "imports"], [29, "imports"], [30, "imports"], [32, "imports"], [33, "imports"], [34, "imports"], [35, "imports"], [36, "imports"], [37, "imports"], [42, "imports"], [43, "imports"], [44, "imports"], [45, "imports"], [46, "imports"], [47, "imports"], [49, "imports"], [50, "imports"], [51, "imports"], [52, "imports"], [53, "imports"], [54, "imports"], [55, "imports"], [56, "imports"], [57, "imports"], [58, "imports"], [59, "imports"], [60, "imports"], [61, "imports"], [62, "imports"], [63, "imports"], [64, "imports"], [65, "imports"], [66, "imports"], [67, "imports"], [68, "imports"], [69, "imports"], [70, "imports"], [73, "imports"], [74, "imports"], [75, "imports"]], "Imports and LO": [[19, "imports-and-lo"], [21, "imports-and-lo"], [33, "imports-and-lo"], [35, "imports-and-lo"], [56, "imports-and-lo"], [58, "imports-and-lo"], [66, "imports-and-lo"], [67, "imports-and-lo"]], "Imports and LOs": [[20, "imports-and-los"], [34, "imports-and-los"], [57, "imports-and-los"], [70, "imports-and-los"]], "Imports and learning outcomes": [[62, "imports-and-learning-outcomes"]], "Imports, Announcements, LOs": [[50, "imports-announcements-los"]], "Imports, Announcements, and LO": [[30, "imports-announcements-and-lo"], [32, "imports-announcements-and-lo"], [54, "imports-announcements-and-lo"], [55, "imports-announcements-and-lo"]], "Imports, LOs": [[14, "imports-los"], [16, "imports-los"], [23, "imports-los"], [27, "imports-los"], [29, "imports-los"], [37, "imports-los"], [51, "imports-los"], [53, "imports-los"], [60, "imports-los"]], "Imports, and LO": [[17, "imports-and-lo"], [18, "imports-and-lo"]], "Imports, announcements, LOs": [[22, "imports-announcements-los"], [36, "imports-announcements-los"], [59, "imports-announcements-los"]], "Imports, announcements, and LOs": [[28, "imports-announcements-and-los"], [52, "imports-announcements-and-los"]], "Imputation": [[16, "imputation"], [29, "imputation"], [53, "imputation"]], "Imputation and scaling [video]": [[16, "imputation-and-scaling-video"], [29, "imputation-and-scaling-video"], [53, "imputation-and-scaling-video"]], "Incorporating ordinal feature class_attendance": [[17, "incorporating-ordinal-feature-class-attendance"], [30, "incorporating-ordinal-feature-class-attendance"], [54, "incorporating-ordinal-feature-class-attendance"]], "Incorporating text features": [[44, "incorporating-text-features"]], "Increasing the threshold": [[20, "increasing-the-threshold"], [34, "increasing-the-threshold"], [47, "increasing-the-threshold"], [57, "increasing-the-threshold"]], "Indexing Dataframes": [[8, "indexing-dataframes"]], "Indexing cheatsheet": [[8, "indexing-cheatsheet"]], "Inertia": [[62, "inertia"]], "Initial analysis, EDA, preprocessing": [[70, "initial-analysis-eda-preprocessing"]], "Initialization of K-Means": [[62, "initialization-of-k-means"]], "Inject randomness in the classifier construction": [[22, "inject-randomness-in-the-classifier-construction"], [36, "inject-randomness-in-the-classifier-construction"], [38, "inject-randomness-in-the-classifier-construction"], [59, "inject-randomness-in-the-classifier-construction"]], "Input data": [[12, "input-data"], [25, "input-data"], [49, "input-data"]], "Input features X and target y": [[12, "input-features-x-and-target-y"], [25, "input-features-x-and-target-y"], [49, "input-features-x-and-target-y"]], "Installing Python packages": [[10, "installing-python-packages"]], "Instructional Material": [[0, "instructional-material"]], "Instructors": [[1, "instructors"]], "Interesting to you != useful to the reader (aka it\u2019s not about you)": [[69, "interesting-to-you-useful-to-the-reader-aka-it-s-not-about-you"]], "Interim summary": [[20, "interim-summary"], [23, "interim-summary"], [24, "interim-summary"], [34, "interim-summary"], [37, "interim-summary"], [39, "interim-summary"], [40, "interim-summary"], [47, "interim-summary"], [57, "interim-summary"], [60, "interim-summary"], [61, "interim-summary"], [67, "interim-summary"]], "Interpretation of coefficients": [[18, "interpretation-of-coefficients"], [32, "interpretation-of-coefficients"], [55, "interpretation-of-coefficients"]], "Interpretation of coefficients in linear models": [[18, "interpretation-of-coefficients-in-linear-models"], [32, "interpretation-of-coefficients-in-linear-models"], [55, "interpretation-of-coefficients-in-linear-models"]], "Interpreting coefficients of numeric features": [[23, "interpreting-coefficients-of-numeric-features"], [37, "interpreting-coefficients-of-numeric-features"], [39, "interpreting-coefficients-of-numeric-features"], [60, "interpreting-coefficients-of-numeric-features"]], "Introduction": [[63, "introduction"], [73, "introduction"]], "Introduction to NLP": [[73, "introduction-to-nlp"]], "Introduction to computer vision": [[66, "introduction-to-computer-vision"]], "Introduction to neural networks": [[66, "introduction-to-neural-networks"]], "Introduction to pandas": [[8, "introduction-to-pandas"]], "Introduction to unsupervised learning": [[62, "introduction-to-unsupervised-learning"]], "Is it possible to further improve the scores?": [[71, "is-it-possible-to-further-improve-the-scores"]], "Is stratifying a good idea?": [[20, "is-stratifying-a-good-idea"], [34, "is-stratifying-a-good-idea"], [57, "is-stratifying-a-good-idea"]], "Is this a realistic representation of text data?": [[17, "is-this-a-realistic-representation-of-text-data"], [30, "is-this-a-realistic-representation-of-text-data"], [54, "is-this-a-realistic-representation-of-text-data"]], "Is this misleading?": [[69, "is-this-misleading"]], "Is \u201cRelevance\u201d clearly defined?": [[24, "is-relevance-clearly-defined"], [24, "id2"], [24, "id3"], [24, "id4"], [24, "id5"], [24, "id6"], [24, "id7"], [40, "is-relevance-clearly-defined"], [40, "id2"], [40, "id3"], [40, "id4"], [40, "id5"], [40, "id6"], [40, "id7"], [61, "is-relevance-clearly-defined"], [61, "id2"], [61, "id3"], [61, "id4"], [61, "id5"], [61, "id6"], [61, "id7"]], "K-Means algorithm": [[62, "k-means-algorithm"]], "K-Means clustering [video]": [[62, "k-means-clustering-video"]], "K-Means example": [[62, "k-means-example"]], "K-Means limitations": [[63, "k-means-limitations"]], "K-Means limitations: Shape of K-Means clusters": [[63, "k-means-limitations-shape-of-k-means-clusters"]], "K-Means recap": [[63, "k-means-recap"]], "K-Means: failure case 1": [[63, "k-means-failure-case-1"]], "K-Means: failure case 2": [[63, "k-means-failure-case-2"]], "K-Means: failure case 3": [[63, "k-means-failure-case-3"]], "Kaplan-Meier survival curve": [[68, "kaplan-meier-survival-curve"]], "Key point": [[23, "key-point"], [37, "key-point"], [39, "key-point"], [60, "key-point"]], "L1 vs L2 penalty summary (Optional)": [[40, "l1-vs-l2-penalty-summary-optional"]], "LDA topics in social media": [[65, "lda-topics-in-social-media"]], "LICENSE": [[0, null]], "Labeled vs. Unlabeled data": [[62, "labeled-vs-unlabeled-data"]], "Lag-based features": [[67, "lag-based-features"], [67, "id5"]], "Land acknowledgement": [[80, "land-acknowledgement"]], "Large datasets solve many of these problems": [[19, "large-datasets-solve-many-of-these-problems"], [33, "large-datasets-solve-many-of-these-problems"], [56, "large-datasets-solve-many-of-these-problems"]], "Lasso regression (L1 penalty) (Optional)": [[40, "lasso-regression-l1-penalty-optional"]], "Late submissions": [[7, "late-submissions"]], "Learned coefficients associated with all features": [[18, "learned-coefficients-associated-with-all-features"], [32, "learned-coefficients-associated-with-all-features"], [55, "learned-coefficients-associated-with-all-features"]], "Learned model": [[42, "learned-model"]], "Learning git": [[5, "learning-git"]], "Learning objectives": [[65, "learning-objectives"], [66, "learning-objectives"], [67, "learning-objectives"], [68, "learning-objectives"], [69, "learning-objectives"], [70, "learning-objectives"]], "Learning outcomes": [[12, "learning-outcomes"], [13, "learning-outcomes"], [14, "learning-outcomes"], [15, "learning-outcomes"], [16, "learning-outcomes"], [17, "learning-outcomes"], [18, "learning-outcomes"], [19, "learning-outcomes"], [20, "learning-outcomes"], [21, "learning-outcomes"], [23, "learning-outcomes"], [24, "learning-outcomes"], [25, "learning-outcomes"], [26, "learning-outcomes"], [27, "learning-outcomes"], [28, "learning-outcomes"], [29, "learning-outcomes"], [30, "learning-outcomes"], [32, "learning-outcomes"], [33, "learning-outcomes"], [34, "learning-outcomes"], [35, "learning-outcomes"], [37, "learning-outcomes"], [39, "learning-outcomes"], [40, "learning-outcomes"], [48, "learning-outcomes"], [49, "learning-outcomes"], [50, "learning-outcomes"], [51, "learning-outcomes"], [52, "learning-outcomes"], [53, "learning-outcomes"], [54, "learning-outcomes"], [55, "learning-outcomes"], [56, "learning-outcomes"], [57, "learning-outcomes"], [58, "learning-outcomes"], [60, "learning-outcomes"], [61, "learning-outcomes"], [62, "learning-outcomes"], [63, "learning-outcomes"]], "Learning outcomes <a name=\"lo\"></a>": [[64, "learning-outcomes"]], "Least confident cases": [[18, "least-confident-cases"], [32, "least-confident-cases"], [55, "least-confident-cases"]], "Lecture 10: Regression metrics": [[21, null], [35, null], [48, null], [58, null]], "Lecture 12: Ensembles": [[22, null], [36, null], [38, null], [59, null]], "Lecture 13: Feature importances and model transparency": [[23, null], [37, null], [39, null], [60, null]], "Lecture 14: Feature engineering and feature selection": [[24, null], [40, null], [61, null]], "Lecture 15: K-Means Clustering": [[62, null]], "Lecture 16: More Clustering": [[63, null]], "Lecture 17: Recommender Systems": [[64, null]], "Lecture 18: Introduction to natural language processing": [[65, null]], "Lecture 19: Multi-class classification and introduction to computer vision": [[66, null]], "Lecture 1: Course Introduction": [[12, null], [25, null], [49, null]], "Lecture 20: Time series": [[67, null]], "Lecture 21: Survival analysis": [[68, null]], "Lecture 22: Communication": [[69, null]], "Lecture 24: Deployment and conclusion": [[70, null]], "Lecture 2: Terminology, Baselines, Decision Trees": [[13, null], [26, null], [50, null]], "Lecture 3: ML Fundamentals Class Demo": [[42, null]], "Lecture 3: Machine Learning Fundamentals": [[14, null], [27, null], [51, null]], "Lecture 4: Class demo": [[43, null]], "Lecture 4: k-Nearest Neighbours and SVM RBFs": [[15, null], [28, null], [52, null]], "Lecture 5 and 6: Class demo": [[44, null]], "Lecture 5: Preprocessing and sklearn pipelines": [[16, null], [29, null], [53, null]], "Lecture 6: sklearn ColumnTransformer and Text Features": [[17, null], [30, null], [54, null]], "Lecture 7: Class demo": [[31, null]], "Lecture 7: Linear Models": [[18, null], [32, null], [55, null]], "Lecture 8: Hyperparameter Optimization and Optimization Bias": [[19, null], [33, null], [56, null]], "Lecture 9: Class demo": [[47, null]], "Lecture 9: Classification metrics": [[20, null], [34, null], [57, null]], "Lecture and homework format: Jupyter notebooks": [[12, "lecture-and-homework-format-jupyter-notebooks"], [25, "lecture-and-homework-format-jupyter-notebooks"]], "Lecture learning objectives": [[22, "lecture-learning-objectives"], [36, "lecture-learning-objectives"], [38, "lecture-learning-objectives"], [59, "lecture-learning-objectives"]], "Lecture plan and learning outcomes": [[63, "lecture-plan-and-learning-outcomes"]], "Lecture recordings": [[80, "lecture-recordings"]], "Lecture schedule (tentative)": [[1, "lecture-schedule-tentative"]], "Lecture style": [[12, "lecture-style"], [25, "lecture-style"]], "Lectures 7: Class demo": [[45, null], [46, null]], "Let\u2019s do it on our housing data": [[16, "let-s-do-it-on-our-housing-data"], [29, "let-s-do-it-on-our-housing-data"], [53, "let-s-do-it-on-our-housing-data"]], "Let\u2019s examine the transformed data": [[17, "let-s-examine-the-transformed-data"], [30, "let-s-examine-the-transformed-data"], [54, "let-s-examine-the-transformed-data"]], "Let\u2019s explore SVM RBFs": [[15, "let-s-explore-svm-rbfs"], [28, "let-s-explore-svm-rbfs"], [52, "let-s-explore-svm-rbfs"]], "Let\u2019s first run our baseline model DummyRegressor": [[16, "let-s-first-run-our-baseline-model-dummyregressor"], [29, "let-s-first-run-our-baseline-model-dummyregressor"], [53, "let-s-first-run-our-baseline-model-dummyregressor"]], "Let\u2019s identify feature types": [[23, "let-s-identify-feature-types"], [37, "let-s-identify-feature-types"], [60, "let-s-identify-feature-types"]], "Let\u2019s look at all the scores at once": [[20, "let-s-look-at-all-the-scores-at-once"], [34, "let-s-look-at-all-the-scores-at-once"], [47, "let-s-look-at-all-the-scores-at-once"], [57, "let-s-look-at-all-the-scores-at-once"]], "Let\u2019s separate X and y": [[21, "let-s-separate-x-and-y"], [23, "let-s-separate-x-and-y"], [35, "let-s-separate-x-and-y"], [37, "let-s-separate-x-and-y"], [58, "let-s-separate-x-and-y"], [60, "let-s-separate-x-and-y"], [69, "let-s-separate-x-and-y"]], "Let\u2019s try KNN on this data": [[44, "let-s-try-knn-on-this-data"]], "Let\u2019s try a linear model: Ridge": [[21, "let-s-try-a-linear-model-ridge"], [35, "let-s-try-a-linear-model-ridge"], [58, "let-s-try-a-linear-model-ridge"]], "Let\u2019s try cross-validation with our pipeline": [[16, "let-s-try-cross-validation-with-our-pipeline"], [29, "let-s-try-cross-validation-with-our-pipeline"], [53, "let-s-try-cross-validation-with-our-pipeline"]], "License": [[1, "license"]], "LightGBM": [[22, "lightgbm"], [36, "lightgbm"], [38, "lightgbm"], [59, "lightgbm"]], "Limitations of linear models": [[18, "limitations-of-linear-models"], [32, "limitations-of-linear-models"], [55, "limitations-of-linear-models"]], "Linear SVM": [[18, "linear-svm"], [32, "linear-svm"], [55, "linear-svm"]], "Linear models [video]": [[18, "linear-models-video"], [32, "linear-models-video"], [55, "linear-models-video"]], "Linear models recap (Optional)": [[40, "linear-models-recap-optional"]], "Linear regression": [[18, "linear-regression"], [32, "linear-regression"], [55, "linear-regression"]], "Lists of resources": [[9, "lists-of-resources"]], "Loading our saved model": [[70, "loading-our-saved-model"]], "Log transform": [[48, "log-transform"]], "Logistic regression (L1 and L2) (Optional)": [[40, "logistic-regression-l1-and-l2-optional"]], "Logistic regression [video]": [[18, "logistic-regression-video"], [32, "logistic-regression-video"], [55, "logistic-regression-video"]], "Logistic regression intuition": [[18, "logistic-regression-intuition"], [32, "logistic-regression-intuition"], [55, "logistic-regression-intuition"]], "Logistic regression on the cities data": [[18, "logistic-regression-on-the-cities-data"], [32, "logistic-regression-on-the-cities-data"], [55, "logistic-regression-on-the-cities-data"]], "Logistic regression with flattened representation of images": [[66, "logistic-regression-with-flattened-representation-of-images"]], "LogisticRegression": [[67, "logisticregression"], [68, "logisticregression"]], "MAPE": [[21, "mape"], [35, "mape"], [48, "mape"], [58, "mape"]], "ML and decision-making (5 min)": [[69, "ml-and-decision-making-5-min"]], "ML fairness activity": [[78, "ml-fairness-activity"]], "ML fairness activity (tutorial)": [[34, "ml-fairness-activity-tutorial"]], "ML fairness activity (~5 mins)": [[20, "ml-fairness-activity-5-mins"], [57, "ml-fairness-activity-5-mins"]], "ML fundamentals": [[73, "ml-fundamentals"]], "Mac Users": [[5, "mac-users"]], "Machine learning workflow": [[12, "machine-learning-workflow"], [20, "machine-learning-workflow"], [34, "machine-learning-workflow"], [47, "machine-learning-workflow"], [49, "machine-learning-workflow"], [57, "machine-learning-workflow"]], "Magnitude of the coefficients": [[18, "magnitude-of-the-coefficients"], [32, "magnitude-of-the-coefficients"], [55, "magnitude-of-the-coefficients"]], "Main hyperparameter of logistic regression": [[18, "main-hyperparameter-of-logistic-regression"], [32, "main-hyperparameter-of-logistic-regression"], [55, "main-hyperparameter-of-logistic-regression"]], "Main hyperparameters": [[18, "main-hyperparameters"], [32, "main-hyperparameters"], [55, "main-hyperparameters"]], "Main issues in ML-related communication": [[69, "main-issues-in-ml-related-communication"]], "Manual hyperparameter optimization": [[19, "manual-hyperparameter-optimization"], [33, "manual-hyperparameter-optimization"], [56, "manual-hyperparameter-optimization"]], "Mean intra-cluster distance (a)": [[62, "mean-intra-cluster-distance-a"]], "Mean nearest-cluster distance (b)": [[62, "mean-nearest-cluster-distance-b"]], "Mean squared error (MSE)": [[21, "mean-squared-error-mse"], [35, "mean-squared-error-mse"], [48, "mean-squared-error-mse"], [58, "mean-squared-error-mse"]], "Meet Eva (a fictitious persona)!": [[12, "meet-eva-a-fictitious-persona"], [25, "meet-eva-a-fictitious-persona"], [49, "meet-eva-a-fictitious-persona"]], "Method 1: The Elbow method": [[62, "method-1-the-elbow-method"]], "Method 2: The Silhouette method": [[62, "method-2-the-silhouette-method"]], "Midterms": [[80, "midterms"]], "Misc": [[1, "misc"], [9, "misc"]], "Miscellaneous comments on content-based filtering": [[64, "miscellaneous-comments-on-content-based-filtering"]], "Model building": [[21, "model-building"], [35, "model-building"], [58, "model-building"], [70, "model-building"]], "Model building on the dataset": [[31, "model-building-on-the-dataset"], [45, "model-building-on-the-dataset"], [46, "model-building-on-the-dataset"]], "Model complexity and training error": [[14, "model-complexity-and-training-error"], [27, "model-complexity-and-training-error"], [51, "model-complexity-and-training-error"]], "Model deployment": [[70, "model-deployment"], [70, "id1"]], "Model interpretability beyond linear models": [[23, "model-interpretability-beyond-linear-models"], [37, "model-interpretability-beyond-linear-models"], [39, "model-interpretability-beyond-linear-models"], [60, "model-interpretability-beyond-linear-models"]], "Model predictions on unseen data": [[12, "model-predictions-on-unseen-data"], [25, "model-predictions-on-unseen-data"], [49, "model-predictions-on-unseen-data"]], "Model training and evaluation": [[78, "model-training-and-evaluation"]], "Model transparency and interpretation": [[70, "model-transparency-and-interpretation"]], "Model-based selection": [[24, "model-based-selection"], [40, "model-based-selection"], [61, "model-based-selection"]], "Modeling": [[44, "modeling"]], "More comments on tackling class imbalance": [[21, "more-comments-on-tackling-class-imbalance"], [35, "more-comments-on-tackling-class-imbalance"], [48, "more-comments-on-tackling-class-imbalance"], [58, "more-comments-on-tackling-class-imbalance"]], "More details": [[27, "more-details"]], "More details on DBSCAN": [[63, "more-details-on-dbscan"]], "More on feature transformations": [[17, "more-on-feature-transformations"], [30, "more-on-feature-transformations"], [54, "more-on-feature-transformations"]], "More on k-NNs [video]": [[15, "more-on-k-nns-video"], [28, "more-on-k-nns-video"], [52, "more-on-k-nns-video"]], "More terminology [video]": [[13, "more-terminology-video"], [26, "more-terminology-video"], [50, "more-terminology-video"]], "More than one ordinal columns?": [[17, "more-than-one-ordinal-columns"], [30, "more-than-one-ordinal-columns"], [54, "more-than-one-ordinal-columns"]], "Most confident cases": [[18, "most-confident-cases"], [32, "most-confident-cases"], [55, "most-confident-cases"]], "Most negative review": [[31, "most-negative-review"], [45, "most-negative-review"], [46, "most-negative-review"]], "Most positive review": [[31, "most-positive-review"], [45, "most-positive-review"], [46, "most-positive-review"]], "Motivating example": [[18, "motivating-example"], [32, "motivating-example"], [55, "motivating-example"]], "Motivation": [[19, "motivation"], [33, "motivation"], [56, "motivation"], [67, "motivation"], [69, "motivation"]], "Motivation [video]": [[22, "motivation-video"], [36, "motivation-video"], [59, "motivation-video"]], "Motivation and big picture [video]": [[16, "motivation-and-big-picture-video"], [29, "motivation-and-big-picture-video"], [53, "motivation-and-big-picture-video"]], "Motivation and context": [[65, "motivation-and-context"]], "Motivation and distances [video]": [[15, "motivation-and-distances-video"], [28, "motivation-and-distances-video"], [52, "motivation-and-distances-video"]], "Movie features": [[64, "movie-features"]], "Multi-class classification": [[66, "multi-class-classification"]], "Multiclass classification and computer vision": [[73, "multiclass-classification-and-computer-vision"]], "Multiple transformations in a transformer": [[17, "multiple-transformations-in-a-transformer"], [30, "multiple-transformations-in-a-transformer"], [54, "multiple-transformations-in-a-transformer"]], "NOTE:": [[8, "note"]], "New ideas in small chunks": [[69, "new-ideas-in-small-chunks"]], "No-loop method: make them the same size, and multiply element-wise": [[8, "no-loop-method-make-them-the-same-size-and-multiply-element-wise"]], "Note": [[14, null], [14, null], [51, null], [51, null], [67, null]], "Number of trees and fundamental trade-off": [[22, "number-of-trees-and-fundamental-trade-off"], [36, "number-of-trees-and-fundamental-trade-off"], [38, "number-of-trees-and-fundamental-trade-off"], [59, "number-of-trees-and-fundamental-trade-off"]], "Numpy array shapes": [[8, "numpy-array-shapes"]], "Numpy arrays": [[8, "numpy-arrays"]], "OHE with many categories": [[17, "ohe-with-many-categories"], [54, "ohe-with-many-categories"]], "Object detection": [[66, "object-detection"]], "Observations": [[20, "observations"], [34, "observations"], [47, "observations"], [57, "observations"]], "One Vs. One approach": [[72, "one-vs-one-approach"]], "One Vs. One prediction": [[72, "one-vs-one-prediction"]], "One vs. Rest": [[72, "one-vs-rest"]], "One-hot encoding (OHE)": [[16, "one-hot-encoding-ohe"], [29, "one-hot-encoding-ohe"], [53, "one-hot-encoding-ohe"]], "One-hot encoding of the month": [[67, "one-hot-encoding-of-the-month"]], "One-hot encoding seasons": [[67, "one-hot-encoding-seasons"]], "OneHotEncoder and sparse features": [[17, "onehotencoder-and-sparse-features"], [30, "onehotencoder-and-sparse-features"], [54, "onehotencoder-and-sparse-features"]], "Online courses": [[1, "online-courses"], [9, "online-courses"]], "Operating point": [[20, "operating-point"], [34, "operating-point"], [47, "operating-point"], [57, "operating-point"]], "Optimization bias of hyper-parameter learning": [[19, "optimization-bias-of-hyper-parameter-learning"], [33, "optimization-bias-of-hyper-parameter-learning"], [56, "optimization-bias-of-hyper-parameter-learning"]], "Optimization bias of parameter learning": [[19, "optimization-bias-of-parameter-learning"], [33, "optimization-bias-of-parameter-learning"], [56, "optimization-bias-of-parameter-learning"]], "Optimization bias on the Spotify dataset": [[19, "optimization-bias-on-the-spotify-dataset"], [33, "optimization-bias-on-the-spotify-dataset"], [56, "optimization-bias-on-the-spotify-dataset"]], "Optimization bias/Overfitting of the validation set": [[19, "optimization-bias-overfitting-of-the-validation-set"], [56, "optimization-bias-overfitting-of-the-validation-set"]], "Optimization bias/Overfitting of the validation set (video)": [[33, "optimization-bias-overfitting-of-the-validation-set-video"]], "Optional readings and resources": [[19, "optional-readings-and-resources"], [33, "optional-readings-and-resources"], [56, "optional-readings-and-resources"]], "Ordinal encoding (occasionally recommended)": [[16, "ordinal-encoding-occasionally-recommended"], [29, "ordinal-encoding-occasionally-recommended"], [53, "ordinal-encoding-occasionally-recommended"]], "Ordinal features": [[23, "ordinal-features"], [37, "ordinal-features"], [39, "ordinal-features"], [44, "ordinal-features"], [60, "ordinal-features"]], "Other applications": [[62, "other-applications"]], "Other approaches / what did we not cover?": [[68, "other-approaches-what-did-we-not-cover"]], "Other commonly used preprocessing steps": [[65, "other-commonly-used-preprocessing-steps"]], "Other possible preprocessing?": [[21, "other-possible-preprocessing"], [35, "other-possible-preprocessing"], [58, "other-possible-preprocessing"]], "Other software package": [[67, "other-software-package"]], "Other tools for preprocessing": [[65, "other-tools-for-preprocessing"]], "Other typical NLP tasks": [[65, "other-typical-nlp-tasks"]], "Other useful arguments of KNeighborsClassifier": [[15, "other-useful-arguments-of-kneighborsclassifier"], [28, "other-useful-arguments-of-kneighborsclassifier"], [52, "other-useful-arguments-of-kneighborsclassifier"]], "Other ways to search": [[24, "other-ways-to-search"], [40, "other-ways-to-search"], [61, "other-ways-to-search"]], "Our typical supervised learning set up is as follows:": [[14, "our-typical-supervised-learning-set-up-is-as-follows"], [27, "our-typical-supervised-learning-set-up-is-as-follows"], [51, "our-typical-supervised-learning-set-up-is-as-follows"]], "Outline": [[74, "outline"], [75, "outline"], [76, "outline"], [77, "outline"], [78, "outline"], [79, "outline"]], "Over confident cases": [[18, "over-confident-cases"], [32, "over-confident-cases"], [55, "over-confident-cases"]], "Overfitting": [[14, "overfitting"], [27, "overfitting"], [51, "overfitting"]], "Overfitting of the validation data": [[19, "overfitting-of-the-validation-data"], [33, "overfitting-of-the-validation-data"], [56, "overfitting-of-the-validation-data"]], "Overfitting of the validation error": [[19, "overfitting-of-the-validation-error"], [33, "overfitting-of-the-validation-error"], [56, "overfitting-of-the-validation-error"]], "Oversampling": [[20, "oversampling"], [57, "oversampling"]], "Overview": [[15, "overview"], [28, "overview"], [52, "overview"]], "POSIX time feature": [[67, "posix-time-feature"]], "PR curves for logistic regression and SVC": [[20, "pr-curves-for-logistic-regression-and-svc"], [34, "pr-curves-for-logistic-regression-and-svc"], [47, "pr-curves-for-logistic-regression-and-svc"], [57, "pr-curves-for-logistic-regression-and-svc"]], "Pandas DataFrames": [[8, "pandas-dataframes"]], "Pandas Series": [[8, "pandas-series"]], "Parameters": [[13, "parameters"], [26, "parameters"], [50, "parameters"]], "Parameters and hyperparameters: Summary": [[13, "parameters-and-hyperparameters-summary"], [26, "parameters-and-hyperparameters-summary"], [50, "parameters-and-hyperparameters-summary"]], "Parsing datetimes": [[67, "parsing-datetimes"]], "Part 1": [[73, "part-1"]], "Part 2": [[73, "part-2"]], "Piazza-specific Q&A guidelines": [[4, "piazza-specific-q-a-guidelines"]], "Pipelines": [[16, "pipelines"], [29, "pipelines"], [53, "pipelines"]], "Playground": [[15, "playground"], [52, "playground"]], "Playground (in tutorial)": [[28, "playground-in-tutorial"]], "Plotting with matplotlib": [[8, "plotting-with-matplotlib"]], "Practice exercises": [[26, "practice-exercises"], [50, "practice-exercises"]], "Precision": [[20, "precision"], [34, "precision"], [47, "precision"], [57, "precision"]], "Precision and recall: toy example": [[20, "precision-and-recall-toy-example"], [34, "precision-and-recall-toy-example"], [47, "precision-and-recall-toy-example"], [57, "precision-and-recall-toy-example"]], "Precision, recall, f1 score": [[20, "precision-recall-f1-score"], [47, "precision-recall-f1-score"]], "Precision, recall, f1 score (video)": [[34, "precision-recall-f1-score-video"], [57, "precision-recall-f1-score-video"]], "Precision-recall curve": [[20, "precision-recall-curve"], [20, "id1"], [34, "precision-recall-curve"], [34, "id1"], [47, "precision-recall-curve"], [47, "id1"], [57, "precision-recall-curve"], [57, "id1"]], "Precision/Recall tradeoff": [[20, "precision-recall-tradeoff"], [34, "precision-recall-tradeoff"], [47, "precision-recall-tradeoff"], [57, "precision-recall-tradeoff"]], "Predicting on unseen data using the trained model": [[12, "predicting-on-unseen-data-using-the-trained-model"], [25, "predicting-on-unseen-data-using-the-trained-model"], [49, "predicting-on-unseen-data-using-the-trained-model"]], "Predicting probability scores [video]": [[18, "predicting-probability-scores-video"], [32, "predicting-probability-scores-video"], [55, "predicting-probability-scores-video"]], "Predicting with learned weights": [[18, "predicting-with-learned-weights"], [32, "predicting-with-learned-weights"], [55, "predicting-with-learned-weights"]], "Prediction": [[68, "prediction"]], "Prediction of linear regression": [[18, "prediction-of-linear-regression"], [32, "prediction-of-linear-regression"], [55, "prediction-of-linear-regression"]], "Prediction with learned parameters": [[18, "prediction-with-learned-parameters"], [32, "prediction-with-learned-parameters"], [55, "prediction-with-learned-parameters"]], "Predictions": [[66, "predictions"]], "Preferences in LogisticRegression": [[69, "preferences-in-logisticregression"]], "Preparation": [[7, "preparation"]], "Preprocessing": [[17, "preprocessing"], [30, "preprocessing"], [54, "preprocessing"], [67, "preprocessing"], [73, "preprocessing"], [78, "preprocessing"]], "Preprocessing the targets?": [[17, "preprocessing-the-targets"], [30, "preprocessing-the-targets"], [54, "preprocessing-the-targets"]], "Prevalence of ML": [[12, "prevalence-of-ml"], [25, "prevalence-of-ml"], [49, "prevalence-of-ml"]], "Principles of effective communication": [[69, "principles-of-effective-communication"]], "Principles of good explanations (~15 min)": [[69, "principles-of-good-explanations-15-min"]], "Problem formulation": [[64, "problem-formulation"]], "Problem: Different transformations on different columns": [[16, "problem-different-transformations-on-different-columns"], [29, "problem-different-transformations-on-different-columns"], [53, "problem-different-transformations-on-different-columns"]], "Problems with exhaustive grid search": [[19, "problems-with-exhaustive-grid-search"], [33, "problems-with-exhaustive-grid-search"], [56, "problems-with-exhaustive-grid-search"]], "Problems with single train/validation split": [[14, "problems-with-single-train-validation-split"], [27, "problems-with-single-train-validation-split"], [51, "problems-with-single-train-validation-split"]], "Pros of k-NNs for supervised learning": [[15, "pros-of-k-nns-for-supervised-learning"], [28, "pros-of-k-nns-for-supervised-learning"], [52, "pros-of-k-nns-for-supervised-learning"]], "Pros, cons, parameters and hyperparameters of different ML models": [[73, "pros-cons-parameters-and-hyperparameters-of-different-ml-models"]], "Python and Conda": [[10, "python-and-conda"]], "Python requirements/resources": [[12, "python-requirements-resources"], [25, "python-requirements-resources"]], "Python resources": [[9, "python-resources"]], "Question": [[15, "question"], [28, "question"], [52, "question"]], "Question for you": [[63, "question-for-you"]], "Question for you to ponder on": [[31, "question-for-you-to-ponder-on"], [45, "question-for-you-to-ponder-on"], [46, "question-for-you-to-ponder-on"]], "Questions for class discussion": [[64, "questions-for-class-discussion"]], "Questions for class discussion (hyperparameter optimization)": [[19, "questions-for-class-discussion-hyperparameter-optimization"], [33, "questions-for-class-discussion-hyperparameter-optimization"], [56, "questions-for-class-discussion-hyperparameter-optimization"]], "Quick recap": [[15, "quick-recap"], [52, "quick-recap"]], "RF better than GB": [[69, "rf-better-than-gb"]], "RFE algorithm": [[24, "rfe-algorithm"], [40, "rfe-algorithm"], [61, "rfe-algorithm"]], "R^2 (not in detail)": [[21, "r-2-not-in-detail"], [35, "r-2-not-in-detail"], [48, "r-2-not-in-detail"], [58, "r-2-not-in-detail"]], "Random forest feature importances": [[23, "random-forest-feature-importances"], [37, "random-forest-feature-importances"], [39, "random-forest-feature-importances"], [60, "random-forest-feature-importances"]], "Random forests": [[22, "random-forests"], [36, "random-forests"], [38, "random-forests"], [59, "random-forests"]], "Random forests: number of trees (n_estimators) and the fundamental tradeoff": [[22, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"], [36, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"], [38, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"], [59, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"]], "RandomForestClassifier": [[22, "randomforestclassifier"], [36, "randomforestclassifier"], [38, "randomforestclassifier"], [59, "randomforestclassifier"], [68, "randomforestclassifier"]], "Randomized hyperparameter search": [[19, "randomized-hyperparameter-search"], [33, "randomized-hyperparameter-search"], [56, "randomized-hyperparameter-search"]], "Range of C": [[19, "range-of-c"], [33, "range-of-c"], [56, "range-of-c"]], "Raw scores": [[18, "raw-scores"], [32, "raw-scores"], [55, "raw-scores"]], "Reading from .csv": [[8, "reading-from-csv"]], "Reading from other formats": [[8, "reading-from-other-formats"]], "Reading from url": [[8, "reading-from-url"]], "Reading the data": [[13, "reading-the-data"], [26, "reading-the-data"], [50, "reading-the-data"], [66, "reading-the-data"]], "Real boundary between Canada and USA": [[13, "real-boundary-between-canada-and-usa"], [50, "real-boundary-between-canada-and-usa"], [74, "real-boundary-between-canada-and-usa"]], "Reasonable grading concerns": [[6, "reasonable-grading-concerns"]], "Recall": [[20, "recall"], [34, "recall"], [47, "recall"], [57, "recall"]], "Recap": [[68, "recap"], [69, "recap"]], "Recap and motivation [video]": [[63, "recap-and-motivation-video"]], "Recap: Supervised machine learning": [[13, "recap-supervised-machine-learning"], [26, "recap-supervised-machine-learning"], [50, "recap-supervised-machine-learning"]], "Receiver Operating Characteristic (ROC) curve": [[20, "receiver-operating-characteristic-roc-curve"], [34, "receiver-operating-characteristic-roc-curve"], [47, "receiver-operating-characteristic-roc-curve"], [57, "receiver-operating-characteristic-roc-curve"]], "Recipe to approach a supervised learning problem with tabular data": [[70, "recipe-to-approach-a-supervised-learning-problem-with-tabular-data"]], "Recommended browser": [[12, "recommended-browser"], [25, "recommended-browser"]], "Recommender systems": [[73, "recommender-systems"]], "Recommender systems intro and motivation": [[64, "recommender-systems-intro-and-motivation"]], "Recommender systems problem": [[64, "recommender-systems-problem"]], "Recursive feature elimination (RFE)": [[24, "recursive-feature-elimination-rfe"], [40, "recursive-feature-elimination-rfe"], [61, "recursive-feature-elimination-rfe"]], "Reference Material": [[1, "reference-material"]], "Reference material": [[9, null]], "References": [[68, "references"]], "Registration": [[80, "registration"]], "Registration, waitlist and prerequisites": [[12, "registration-waitlist-and-prerequisites"], [25, "registration-waitlist-and-prerequisites"]], "Regression scoring functions": [[21, "regression-scoring-functions"], [35, "regression-scoring-functions"], [48, "regression-scoring-functions"], [58, "regression-scoring-functions"]], "Regression with k-nearest neighbours (k-NNs)": [[15, "regression-with-k-nearest-neighbours-k-nns"], [28, "regression-with-k-nearest-neighbours-k-nns"], [52, "regression-with-k-nearest-neighbours-k-nns"]], "Relation of C and the fundamental trade-off": [[15, "relation-of-c-and-the-fundamental-trade-off"], [28, "relation-of-c-and-the-fundamental-trade-off"], [52, "relation-of-c-and-the-fundamental-trade-off"]], "Relation of gamma and the fundamental trade-off": [[15, "relation-of-gamma-and-the-fundamental-trade-off"], [28, "relation-of-gamma-and-the-fundamental-trade-off"], [52, "relation-of-gamma-and-the-fundamental-trade-off"]], "Relevant companion materials": [[9, "relevant-companion-materials"]], "Relevant papers": [[22, "relevant-papers"], [36, "relevant-papers"], [38, "relevant-papers"], [59, "relevant-papers"]], "Relevant papers and resources": [[20, "relevant-papers-and-resources"], [34, "relevant-papers-and-resources"], [57, "relevant-papers-and-resources"]], "Relevant resources": [[24, "relevant-resources"], [40, "relevant-resources"], [61, "relevant-resources"]], "Reminder": [[64, "reminder"]], "Renaming columns with df.rename()": [[8, "renaming-columns-with-df-rename"]], "Render set-up (I already did these):": [[70, "render-set-up-i-already-did-these"]], "Report format": [[7, "report-format"]], "Requirements (I already did these)": [[70, "requirements-i-already-did-these"]], "Resources": [[62, "resources"], [63, "resources"], [64, "resources"]], "Reuse your running examples": [[69, "reuse-your-running-examples"]], "Ridge": [[18, "ridge"], [32, "ridge"], [55, "ridge"]], "Ridge on the California housing dataset": [[18, "ridge-on-the-california-housing-dataset"], [32, "ridge-on-the-california-housing-dataset"], [55, "ridge-on-the-california-housing-dataset"]], "Ridge regression": [[48, "ridge-regression"]], "Ridge regression (L2 penalty) (Optional)": [[40, "ridge-regression-l2-penalty-optional"]], "RidgeCV": [[21, "ridgecv"], [35, "ridgecv"], [48, "ridgecv"], [58, "ridgecv"]], "Root mean squared error or RMSE": [[21, "root-mean-squared-error-or-rmse"], [35, "root-mean-squared-error-or-rmse"], [48, "root-mean-squared-error-or-rmse"], [58, "root-mean-squared-error-or-rmse"]], "SHAP  (SHapley Additive exPlanations) introduction": [[23, "shap-shapley-additive-explanations-introduction"], [37, "shap-shapley-additive-explanations-introduction"], [39, "shap-shapley-additive-explanations-introduction"], [60, "shap-shapley-additive-explanations-introduction"]], "SHAP Dependence plot": [[39, "shap-dependence-plot"]], "SHAP Force plot": [[39, "shap-force-plot"]], "SHAP on LGBM model": [[39, "shap-on-lgbm-model"]], "SHAP plots": [[23, "shap-plots"], [37, "shap-plots"], [39, "shap-plots"], [60, "shap-plots"]], "SHAP summary plot": [[39, "shap-summary-plot"]], "SHAP waterfall plot": [[39, "shap-waterfall-plot"]], "SHAP: visualizing multiple predictions": [[39, "shap-visualizing-multiple-predictions"]], "SMOTE idea": [[20, "smote-idea"], [57, "smote-idea"]], "SMOTE: Synthetic Minority Over-sampling Technique": [[20, "smote-synthetic-minority-over-sampling-technique"], [57, "smote-synthetic-minority-over-sampling-technique"]], "SVM Regressor": [[15, "svm-regressor"], [28, "svm-regressor"], [52, "svm-regressor"]], "Saving the model": [[70, "saving-the-model"]], "Saving time and scaling products": [[12, "saving-time-and-scaling-products"], [25, "saving-time-and-scaling-products"], [49, "saving-time-and-scaling-products"]], "Scaling": [[16, "scaling"], [29, "scaling"], [53, "scaling"]], "Scaling using scikit-learn\u2019s StandardScaler": [[16, "scaling-using-scikit-learn-s-standardscaler"], [29, "scaling-using-scikit-learn-s-standardscaler"], [53, "scaling-using-scikit-learn-s-standardscaler"]], "Search over multiple hyperparameters": [[15, "search-over-multiple-hyperparameters"], [28, "search-over-multiple-hyperparameters"], [52, "search-over-multiple-hyperparameters"]], "Seasonality and trends": [[67, "seasonality-and-trends"]], "Select all of the following statements which are True (iClicker)": [[12, "select-all-of-the-following-statements-which-are-true-iclicker"], [25, "select-all-of-the-following-statements-which-are-true-iclicker"], [49, "select-all-of-the-following-statements-which-are-true-iclicker"]], "Sending a request to the API": [[70, "sending-a-request-to-the-api"]], "Separate X and y": [[48, "separate-x-and-y"]], "Setting up": [[5, "setting-up"]], "Setting up a virtual environment: Conda environments": [[10, "setting-up-a-virtual-environment-conda-environments"]], "Setting up coding environment": [[10, null]], "Setting up your computer for the course": [[12, "setting-up-your-computer-for-the-course"], [25, "setting-up-your-computer-for-the-course"]], "Short posts/articles": [[9, "short-posts-articles"]], "Sigmoid vs. Softmax": [[66, "sigmoid-vs-softmax"]], "Sign of the coefficients": [[18, "sign-of-the-coefficients"], [32, "sign-of-the-coefficients"], [55, "sign-of-the-coefficients"]], "Silhouette distance for a sample": [[62, "silhouette-distance-for-a-sample"]], "Similarity between examples": [[15, "similarity-between-examples"], [28, "similarity-between-examples"], [52, "similarity-between-examples"]], "Simple feature engineering for our problem.": [[71, "simple-feature-engineering-for-our-problem"]], "Simple train/test split": [[14, "simple-train-test-split"], [27, "simple-train-test-split"], [51, "simple-train-test-split"]], "SimpleFeature correlations": [[23, "simplefeature-correlations"], [37, "simplefeature-correlations"], [39, "simplefeature-correlations"], [60, "simplefeature-correlations"]], "Single validation set": [[42, "single-validation-set"]], "Slowest method: nested loop": [[8, "slowest-method-nested-loop"]], "Software": [[0, "software"]], "Solution": [[36, "solution"]], "Some important hyperparameters:": [[22, "some-important-hyperparameters"], [36, "some-important-hyperparameters"], [38, "some-important-hyperparameters"], [59, "some-important-hyperparameters"]], "Some key takeaways": [[70, "some-key-takeaways"]], "Some quotes on feature engineering": [[24, "some-quotes-on-feature-engineering"], [40, "some-quotes-on-feature-engineering"], [61, "some-quotes-on-feature-engineering"]], "Some terminology related to trees": [[13, "some-terminology-related-to-trees"], [26, "some-terminology-related-to-trees"], [50, "some-terminology-related-to-trees"]], "Some ways to pick hyperparameters:": [[19, "some-ways-to-pick-hyperparameters"], [33, "some-ways-to-pick-hyperparameters"], [56, "some-ways-to-pick-hyperparameters"]], "Sorting a dataframe with df.sort_values()": [[8, "sorting-a-dataframe-with-df-sort-values"]], "Spam/non spam toy example": [[17, "spam-non-spam-toy-example"], [30, "spam-non-spam-toy-example"], [54, "spam-non-spam-toy-example"]], "Specific questions": [[4, "specific-questions"]], "Stacking": [[22, "stacking"], [36, "stacking"], [38, "stacking"], [59, "stacking"], [79, "stacking"]], "Step 1": [[76, "step-1"]], "Step 2": [[76, "step-2"]], "Step 3": [[76, "step-3"]], "Step 4": [[76, "step-4"]], "Step 5": [[76, "step-5"]], "Steps to train a classifier using sklearn": [[13, "steps-to-train-a-classifier-using-sklearn"], [26, "steps-to-train-a-classifier-using-sklearn"], [50, "steps-to-train-a-classifier-using-sklearn"]], "Stratified Splits": [[20, "stratified-splits"], [34, "stratified-splits"], [57, "stratified-splits"]], "Strengths": [[38, "strengths"]], "Strengths and weaknesses": [[22, "strengths-and-weaknesses"], [36, "strengths-and-weaknesses"], [59, "strengths-and-weaknesses"]], "Strengths of linear models": [[18, "strengths-of-linear-models"], [32, "strengths-of-linear-models"], [55, "strengths-of-linear-models"]], "Study tips": [[73, "study-tips"]], "Submitting on Gradescope": [[7, "submitting-on-gradescope"]], "Summary": [[12, "summary"], [15, "summary"], [22, "summary"], [25, "summary"], [28, "summary"], [36, "summary"], [38, "summary"], [49, "summary"], [52, "summary"], [59, "summary"], [65, "summary"], [66, "summary"], [68, "summary"]], "Summary and reflection": [[14, "summary-and-reflection"], [27, "summary-and-reflection"], [51, "summary-and-reflection"]], "Summary of linear models": [[18, "summary-of-linear-models"], [32, "summary-of-linear-models"], [55, "summary-of-linear-models"]], "Summary of train, validation, test, and deployment data": [[14, "summary-of-train-validation-test-and-deployment-data"], [27, "summary-of-train-validation-test-and-deployment-data"], [51, "summary-of-train-validation-test-and-deployment-data"]], "Summary: Pros and cons": [[63, "summary-pros-and-cons"]], "Supervised approach to rating prediction": [[64, "supervised-approach-to-rating-prediction"]], "Supervised learning": [[62, "supervised-learning"]], "Supervised learning (Reminder)": [[13, "supervised-learning-reminder"], [50, "supervised-learning-reminder"]], "Supervised learning vs. Unsupervised learning": [[13, "supervised-learning-vs-unsupervised-learning"], [26, "supervised-learning-vs-unsupervised-learning"], [50, "supervised-learning-vs-unsupervised-learning"]], "Supervised machine learning": [[12, "supervised-machine-learning"], [25, "supervised-machine-learning"], [49, "supervised-machine-learning"]], "Support Vector Machines (SVMs) with RBF kernel [video]": [[15, "support-vector-machines-svms-with-rbf-kernel-video"], [28, "support-vector-machines-svms-with-rbf-kernel-video"], [52, "support-vector-machines-svms-with-rbf-kernel-video"]], "Support vectors": [[15, "support-vectors"], [28, "support-vectors"], [52, "support-vectors"]], "Survival analysis": [[73, "survival-analysis"]], "Survival plots": [[68, "survival-plots"]], "Syllabus": [[1, "syllabus"], [80, null]], "TAs": [[1, "tas"], [80, "tas"]], "Tabular data": [[13, "tabular-data"], [26, "tabular-data"], [50, "tabular-data"]], "Take-home message": [[63, "take-home-message"]], "Teaching Team": [[80, "teaching-team"]], "Terminology": [[66, "terminology"]], "Terminology [video]": [[13, "terminology-video"], [26, "terminology-video"], [50, "terminology-video"]], "Testing your git installation": [[5, "testing-your-git-installation"]], "The Netflix prize": [[22, "the-netflix-prize"], [36, "the-netflix-prize"], [59, "the-netflix-prize"]], "The __ syntax": [[19, "the-syntax"], [33, "the-syntax"], [56, "the-syntax"]], "The best features may be dependent on the model you use.": [[24, "the-best-features-may-be-dependent-on-the-model-you-use"], [40, "the-best-features-may-be-dependent-on-the-model-you-use"], [61, "the-best-features-may-be-dependent-on-the-model-you-use"]], "The dataset": [[79, "the-dataset"]], "The golden rule <a name=\"4\"></a>": [[14, "the-golden-rule"], [27, "the-golden-rule"], [51, "the-golden-rule"]], "The random forests classifier": [[22, "the-random-forests-classifier"], [36, "the-random-forests-classifier"], [38, "the-random-forests-classifier"], [59, "the-random-forests-classifier"]], "The sigmoid function": [[18, "the-sigmoid-function"], [32, "the-sigmoid-function"], [55, "the-sigmoid-function"]], "The teaching team": [[1, "the-teaching-team"]], "The \u201cfundamental tradeoff\u201d of supervised learning:": [[14, "the-fundamental-tradeoff-of-supervised-learning"], [27, "the-fundamental-tradeoff-of-supervised-learning"], [51, "the-fundamental-tradeoff-of-supervised-learning"]], "The \u201cperfect\u201d spaghetti sauce": [[62, "the-perfect-spaghetti-sauce"]], "Things to watch out for": [[69, "things-to-watch-out-for"]], "Thresholding": [[47, "thresholding"]], "Time series": [[73, "time-series"]], "Time to event and censoring": [[68, "time-to-event-and-censoring"]], "Tokenization": [[65, "tokenization"]], "Topic modeling": [[65, "topic-modeling"]], "Topic modeling motivation": [[65, "topic-modeling-motivation"]], "Topic modeling pipeline": [[65, "topic-modeling-pipeline"]], "Topic modeling toy example": [[65, "topic-modeling-toy-example"]], "Toy datasets": [[13, "toy-datasets"], [50, "toy-datasets"]], "Traditional time series approaches": [[67, "traditional-time-series-approaches"]], "Train/test split for temporal data": [[67, "train-test-split-for-temporal-data"]], "Train/test splits": [[67, "train-test-splits"]], "Train/validation/test split": [[14, "train-validation-test-split"], [27, "train-validation-test-split"], [51, "train-validation-test-split"]], "Training a supervised machine learning model with X and y": [[12, "training-a-supervised-machine-learning-model-with-x-and-y"], [25, "training-a-supervised-machine-learning-model-with-x-and-y"], [49, "training-a-supervised-machine-learning-model-with-x-and-y"]], "Training data for the motivating example": [[18, "training-data-for-the-motivating-example"], [32, "training-data-for-the-motivating-example"], [55, "training-data-for-the-motivating-example"]], "Training error vs. Generalization error": [[14, "training-error-vs-generalization-error"], [27, "training-error-vs-generalization-error"], [51, "training-error-vs-generalization-error"]], "Training models with transformed data": [[17, "training-models-with-transformed-data"], [30, "training-models-with-transformed-data"], [54, "training-models-with-transformed-data"]], "Training on the full corpus": [[70, "training-on-the-full-corpus"]], "Training random forests and gradient boosted trees": [[69, "training-random-forests-and-gradient-boosted-trees"]], "Transfer learning": [[66, "transfer-learning"]], "Transformations on the toy data": [[17, "transformations-on-the-toy-data"], [30, "transformations-on-the-toy-data"], [54, "transformations-on-the-toy-data"]], "Transforming the targets": [[21, "transforming-the-targets"], [35, "transforming-the-targets"], [48, "transforming-the-targets"], [58, "transforming-the-targets"]], "Transparency and explainability of ML models: Motivation": [[23, "transparency-and-explainability-of-ml-models-motivation"], [37, "transparency-and-explainability-of-ml-models-motivation"], [39, "transparency-and-explainability-of-ml-models-motivation"], [60, "transparency-and-explainability-of-ml-models-motivation"]], "Tree-based ensemble models": [[22, "tree-based-ensemble-models"], [38, "tree-based-ensemble-models"], [59, "tree-based-ensemble-models"]], "Tree-based models": [[22, "tree-based-models"], [36, "tree-based-models"], [38, "tree-based-models"], [59, "tree-based-models"]], "Try out this moment predictor": [[70, "try-out-this-moment-predictor"]], "Tuning alpha hyperparameter of Ridge": [[21, "tuning-alpha-hyperparameter-of-ridge"], [35, "tuning-alpha-hyperparameter-of-ridge"], [48, "tuning-alpha-hyperparameter-of-ridge"], [58, "tuning-alpha-hyperparameter-of-ridge"]], "Tutorial 1": [[74, null]], "Tutorial 2": [[75, null]], "Tutorial 3": [[76, null]], "Tutorial 4": [[77, null]], "Tutorial 5": [[78, null]], "Tutorial 6": [[79, null]], "Types of censoring": [[68, "types-of-censoring"]], "Types of errors": [[14, "types-of-errors"], [27, "types-of-errors"], [51, "types-of-errors"]], "Types of machine learning": [[12, "types-of-machine-learning"], [25, "types-of-machine-learning"], [49, "types-of-machine-learning"], [62, "types-of-machine-learning"]], "Types of problems involving time series": [[67, "types-of-problems-involving-time-series"]], "Types of questions we might want to answer:": [[68, "types-of-questions-we-might-want-to-answer"]], "Typical steps to build a supervised machine learning model": [[42, "typical-steps-to-build-a-supervised-machine-learning-model"]], "UBC CPSC 330: Applied Machine Learning (2024W2)": [[1, null]], "Ubuntu Users": [[5, "ubuntu-users"]], "Underfitting": [[14, "underfitting"], [27, "underfitting"], [51, "underfitting"]], "Underfitting, overfitting, the fundamental trade-off, the golden rule [video]": [[14, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"], [27, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"], [51, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"]], "Undersampling": [[20, "undersampling"], [57, "undersampling"]], "Understanding the problem": [[70, "understanding-the-problem"]], "Unequally spaced time points": [[67, "unequally-spaced-time-points"]], "Unsupervised learning": [[62, "unsupervised-learning"]], "Updates to assignments": [[7, "updates-to-assignments"]], "Use of AI in the course": [[80, "use-of-ai-in-the-course"]], "Use our template to create a repository": [[7, "use-our-template-to-create-a-repository"]], "Using OVR and OVO as wrappers": [[72, "using-ovr-and-ovo-as-wrappers"]], "Using SMOTE": [[20, "using-smote"], [57, "using-smote"]], "Using Silhouette scores to select the number of clusters": [[62, "using-silhouette-scores-to-select-the-number-of-clusters"]], "Using multiple metrics in GridSearchCV or RandomizedSearchCV": [[21, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"], [35, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"], [48, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"], [58, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"]], "Using pre-trained models as feature extractor": [[66, "using-pre-trained-models-as-feature-extractor"]], "Using pre-trained models out-of-the-box": [[66, "using-pre-trained-models-out-of-the-box"]], "Using regression metrics with scikit-learn": [[21, "using-regression-metrics-with-scikit-learn"], [35, "using-regression-metrics-with-scikit-learn"], [48, "using-regression-metrics-with-scikit-learn"], [58, "using-regression-metrics-with-scikit-learn"]], "Viewing the transformed data as a dataframe": [[17, "viewing-the-transformed-data-as-a-dataframe"], [30, "viewing-the-transformed-data-as-a-dataframe"], [54, "viewing-the-transformed-data-as-a-dataframe"]], "Virtual environment": [[10, "virtual-environment"]], "Visualization": [[9, "visualization"]], "Visualizing the parameter grid as a heatmap": [[19, "visualizing-the-parameter-grid-as-a-heatmap"], [33, "visualizing-the-parameter-grid-as-a-heatmap"], [56, "visualizing-the-parameter-grid-as-a-heatmap"]], "Visualizing your results": [[69, "visualizing-your-results"]], "Warning": [[13, null], [26, null], [50, null]], "Warnings about feature selection": [[24, "warnings-about-feature-selection"], [24, "id8"], [40, "warnings-about-feature-selection"], [61, "warnings-about-feature-selection"], [61, "id8"]], "Weaknesses": [[22, "weaknesses"], [36, "weaknesses"], [38, "weaknesses"], [59, "weaknesses"]], "Web app on a real server": [[70, "web-app-on-a-real-server"]], "Web app on local server": [[70, "web-app-on-local-server"]], "What all transformations we need to apply on the dataset?": [[16, "what-all-transformations-we-need-to-apply-on-the-dataset"], [53, "what-all-transformations-we-need-to-apply-on-the-dataset"]], "What and Why": [[10, "what-and-why"]], "What are git and GitHub?": [[5, null]], "What are the options?": [[16, "what-are-the-options"], [29, "what-are-the-options"], [53, "what-are-the-options"]], "What are we exactly learning?": [[18, "what-are-we-exactly-learning"], [32, "what-are-we-exactly-learning"], [55, "what-are-we-exactly-learning"]], "What did we cover?": [[64, "what-did-we-cover"], [70, "what-did-we-cover"]], "What did we learn today?": [[14, "what-did-we-learn-today"], [16, "what-did-we-learn-today"], [17, "what-did-we-learn-today"], [20, "what-did-we-learn-today"], [21, "what-did-we-learn-today"], [27, "what-did-we-learn-today"], [29, "what-did-we-learn-today"], [30, "what-did-we-learn-today"], [34, "what-did-we-learn-today"], [35, "what-did-we-learn-today"], [48, "what-did-we-learn-today"], [51, "what-did-we-learn-today"], [53, "what-did-we-learn-today"], [54, "what-did-we-learn-today"], [57, "what-did-we-learn-today"], [58, "what-did-we-learn-today"], [69, "what-did-we-learn-today"]], "What does this have to do with applied ML?": [[69, "what-does-this-have-to-do-with-applied-ml"]], "What does this mean for us, when we\u2019re trying to make claims about our data?": [[69, "what-does-this-mean-for-us-when-we-re-trying-to-make-claims-about-our-data"]], "What if we apply OHE?": [[17, "what-if-we-apply-ohe"], [30, "what-if-we-apply-ohe"], [54, "what-if-we-apply-ohe"]], "What is Natural Language Processing (NLP)?": [[65, "what-is-natural-language-processing-nlp"]], "What is a recommender system?": [[64, "what-is-a-recommender-system"]], "What is clustering?": [[62, "what-is-clustering"]], "What is deployment?": [[70, "what-is-deployment"]], "What is feature engineering?": [[24, "what-is-feature-engineering"], [40, "what-is-feature-engineering"], [61, "what-is-feature-engineering"]], "What is feature selection?": [[24, "what-is-feature-selection"], [40, "what-is-feature-selection"], [61, "what-is-feature-selection"]], "What is grid search?": [[69, "what-is-grid-search"]], "What is model interpretability?": [[23, "what-is-model-interpretability"], [37, "what-is-model-interpretability"], [39, "what-is-model-interpretability"], [60, "what-is-model-interpretability"]], "What is supervised machine learning (ML)?": [[12, "what-is-supervised-machine-learning-ml"], [25, "what-is-supervised-machine-learning-ml"], [49, "what-is-supervised-machine-learning-ml"]], "What is \u201cpositive\u201d and \u201cnegative\u201d?": [[20, "what-is-positive-and-negative"], [34, "what-is-positive-and-negative"], [47, "what-is-positive-and-negative"], [57, "what-is-positive-and-negative"]], "What kind of estimators can we combine?": [[22, "what-kind-of-estimators-can-we-combine"], [36, "what-kind-of-estimators-can-we-combine"], [38, "what-kind-of-estimators-can-we-combine"], [59, "what-kind-of-estimators-can-we-combine"]], "What next?": [[70, "what-next"]], "What should be the loss? (Activity: 4 mins)": [[69, "what-should-be-the-loss-activity-4-mins"]], "What to look for in these plots?": [[62, "what-to-look-for-in-these-plots"]], "What transformations do we need to apply on the dataset?": [[29, "what-transformations-do-we-need-to-apply-on-the-dataset"]], "What would I do differently?": [[70, "what-would-i-do-differently"]], "What\u2019s the problem?": [[16, "what-s-the-problem"], [29, "what-s-the-problem"], [53, "what-s-the-problem"]], "When can we use broadcasting?": [[8, "when-can-we-use-broadcasting"]], "When experimenting, show the results asap": [[69, "when-experimenting-show-the-results-asap"]], "When is it OK to do things before splitting?": [[16, "when-is-it-ok-to-do-things-before-splitting"], [29, "when-is-it-ok-to-do-things-before-splitting"], [53, "when-is-it-ok-to-do-things-before-splitting"]], "When test score is much lower than CV score": [[19, "when-test-score-is-much-lower-than-cv-score"], [33, "when-test-score-is-much-lower-than-cv-score"], [56, "when-test-score-is-much-lower-than-cv-score"]], "Which model is doing better in this scenario: SVC or Logistic Regression?": [[47, "which-model-is-doing-better-in-this-scenario-svc-or-logistic-regression"]], "Which model should I use?": [[22, "which-model-should-i-use"], [36, "which-model-should-i-use"], [38, "which-model-should-i-use"], [59, "which-model-should-i-use"]], "Which type of error is more important?": [[20, "which-type-of-error-is-more-important"], [34, "which-type-of-error-is-more-important"], [57, "which-type-of-error-is-more-important"]], "Which types of errors would be most critical for the bank to address?": [[47, "which-types-of-errors-would-be-most-critical-for-the-bank-to-address"]], "Why do we need a test set?": [[19, "why-do-we-need-a-test-set"], [33, "why-do-we-need-a-test-set"], [56, "why-do-we-need-a-test-set"]], "Why do we want this information?": [[23, "why-do-we-want-this-information"], [37, "why-do-we-want-this-information"], [39, "why-do-we-want-this-information"], [60, "why-do-we-want-this-information"]], "Why does it matter": [[27, "why-does-it-matter"]], "Why feature selection?": [[24, "why-feature-selection"], [40, "why-feature-selection"], [61, "why-feature-selection"]], "Why machine learning (ML)? [video]": [[12, "why-machine-learning-ml-video"], [25, "why-machine-learning-ml-video"], [49, "why-machine-learning-ml-video"]], "Why model transparency/interpretability?": [[23, "why-model-transparency-interpretability"], [37, "why-model-transparency-interpretability"], [39, "why-model-transparency-interpretability"], [60, "why-model-transparency-interpretability"]], "Why neural networks?": [[66, "why-neural-networks"], [66, "id1"]], "Why not neural networks?": [[66, "why-not-neural-networks"], [66, "id2"]], "Why should I use it?": [[69, "why-should-i-use-it"]], "Why should we care about effective communication?": [[69, "why-should-we-care-about-effective-communication"]], "Why should we care about recommendation systems?": [[64, "why-should-we-care-about-recommendation-systems"]], "Why sparse matrices?": [[17, "why-sparse-matrices"], [30, "why-sparse-matrices"], [54, "why-sparse-matrices"]], "Windows": [[10, "windows"]], "Windows Users": [[5, "windows-users"]], "Word embeddings": [[65, "word-embeddings"]], "Word vectors with spaCy": [[65, "word-vectors-with-spacy"]], "Writing a traditional program to predict quiz2 grade": [[13, "writing-a-traditional-program-to-predict-quiz2-grade"], [26, "writing-a-traditional-program-to-predict-quiz2-grade"], [50, "writing-a-traditional-program-to-predict-quiz2-grade"]], "XGBoost": [[22, "xgboost"], [36, "xgboost"], [38, "xgboost"], [59, "xgboost"]], "[Optional] Jupyterlab and Python": [[10, "optional-jupyterlab-and-python"]], "[] notation": [[8, "notation"]], "announcements": [[15, "announcements"]], "class_weight=\"balanced\"": [[20, "class-weight-balanced"], [34, "class-weight-balanced"], [57, "class-weight-balanced"]], "cross_val_score": [[14, "cross-val-score"], [27, "cross-val-score"], [51, "cross-val-score"]], "cross_validate": [[14, "cross-validate"], [27, "cross-validate"], [51, "cross-validate"]], "fit and transform paradigm for transformers": [[16, "fit-and-transform-paradigm-for-transformers"], [29, "fit-and-transform-paradigm-for-transformers"], [53, "fit-and-transform-paradigm-for-transformers"]], "fit the classifier": [[13, "fit-the-classifier"], [26, "fit-the-classifier"], [50, "fit-the-classifier"]], "fit, predict , and score summary": [[13, "fit-predict-and-score-summary"], [26, "fit-predict-and-score-summary"], [50, "fit-predict-and-score-summary"]], "iClicker": [[39, "iclicker"], [80, "iclicker"]], "iClicker Exercise 10.1": [[21, "iclicker-exercise-10-1"], [35, "iclicker-exercise-10-1"], [58, "iclicker-exercise-10-1"]], "iClicker Exercise 10.2": [[21, "iclicker-exercise-10-2"], [35, "iclicker-exercise-10-2"], [58, "iclicker-exercise-10-2"]], "iClicker Exercise 12.0": [[36, "iclicker-exercise-12-0"], [38, "iclicker-exercise-12-0"], [59, "iclicker-exercise-12-0"]], "iClicker Exercise 12.1": [[22, "iclicker-exercise-12-1"], [36, "iclicker-exercise-12-1"], [38, "iclicker-exercise-12-1"], [59, "iclicker-exercise-12-1"]], "iClicker Exercise 14.1": [[40, "iclicker-exercise-14-1"], [61, "iclicker-exercise-14-1"]], "iClicker Exercise 14.1 https://join.iclicker.com/FUYI": [[24, "iclicker-exercise-14-1-https-join-iclicker-com-fuyi"]], "iClicker Exercise 19.1": [[66, "iclicker-exercise-19-1"]], "iClicker Exercise 2.1 Supervised vs unsupervised": [[26, "iclicker-exercise-2-1-supervised-vs-unsupervised"]], "iClicker Exercise 2.2 Classification vs regression": [[26, "iclicker-exercise-2-2-classification-vs-regression"]], "iClicker Exercise 2.2 Supervised vs unsupervised": [[13, "iclicker-exercise-2-2-supervised-vs-unsupervised"], [50, "iclicker-exercise-2-2-supervised-vs-unsupervised"]], "iClicker Exercise 2.3 Classification vs regression": [[13, "iclicker-exercise-2-3-classification-vs-regression"], [50, "iclicker-exercise-2-3-classification-vs-regression"]], "iClicker Exercise 2.4: Baselines and decision trees": [[26, "iclicker-exercise-2-4-baselines-and-decision-trees"]], "iClicker Exercise 2.5: Baselines and decision trees": [[13, "iclicker-exercise-2-5-baselines-and-decision-trees"], [50, "iclicker-exercise-2-5-baselines-and-decision-trees"]], "iClicker Exercise 3.1": [[14, "iclicker-exercise-3-1"], [27, "iclicker-exercise-3-1"], [51, "iclicker-exercise-3-1"]], "iClicker Exercise 3.2": [[14, "iclicker-exercise-3-2"], [27, "iclicker-exercise-3-2"], [51, "iclicker-exercise-3-2"]], "iClicker Exercise 9.1": [[20, "iclicker-exercise-9-1"], [34, "iclicker-exercise-9-1"], [57, "iclicker-exercise-9-1"]], "iClicker Exercise 9.2": [[20, "iclicker-exercise-9-2"], [34, "iclicker-exercise-9-2"], [57, "iclicker-exercise-9-2"]], "k-Nearest Neighbours (k-NNs) [video]": [[15, "k-nearest-neighbours-k-nns-video"], [28, "k-nearest-neighbours-k-nns-video"], [52, "k-nearest-neighbours-k-nns-video"]], "k-nearest neighbours imputation": [[64, "k-nearest-neighbours-imputation"]], "macOS": [[10, "macos"]], "n_iter": [[19, "n-iter"], [33, "n-iter"], [56, "n-iter"]], "n_jobs=-1": [[19, "n-jobs-1"], [33, "n-jobs-1"], [56, "n-jobs-1"]], "pandas_profiler": [[21, "pandas-profiler"], [35, "pandas-profiler"], [58, "pandas-profiler"]], "predict the target of given examples": [[13, "predict-the-target-of-given-examples"], [26, "predict-the-target-of-given-examples"], [50, "predict-the-target-of-given-examples"]], "predict_proba": [[18, "predict-proba"], [32, "predict-proba"], [55, "predict-proba"]], "random_state argument": [[14, "random-state-argument"], [27, "random-state-argument"], [51, "random-state-argument"]], "score your model": [[13, "score-your-model"], [26, "score-your-model"], [50, "score-your-model"]], "sklearn API summary: estimators": [[16, "sklearn-api-summary-estimators"], [29, "sklearn-api-summary-estimators"], [53, "sklearn-api-summary-estimators"]], "sklearn API summary: transformers": [[16, "sklearn-api-summary-transformers"], [29, "sklearn-api-summary-transformers"], [53, "sklearn-api-summary-transformers"]], "sklearn set_config": [[17, "sklearn-set-config"], [30, "sklearn-set-config"], [54, "sklearn-set-config"]], "sklearn\u2019s ColumnTransformer": [[17, "sklearn-s-columntransformer"], [30, "sklearn-s-columntransformer"], [54, "sklearn-s-columntransformer"]], "sklearn\u2019s SimpleImputer": [[44, "sklearn-s-simpleimputer"]], "sklearn\u2019s feature_importances_ and permutation_importance": [[23, "sklearn-s-feature-importances-and-permutation-importance"], [37, "sklearn-s-feature-importances-and-permutation-importance"], [60, "sklearn-s-feature-importances-and-permutation-importance"]], "sklearn\u2019s feature_importances_ attribute vs permutation_importance": [[23, "sklearn-s-feature-importances-attribute-vs-permutation-importance"], [37, "sklearn-s-feature-importances-attribute-vs-permutation-importance"], [39, "sklearn-s-feature-importances-attribute-vs-permutation-importance"], [60, "sklearn-s-feature-importances-attribute-vs-permutation-importance"]], "spaCy": [[71, "spacy"]], "test score vs. cross-validation score": [[14, "test-score-vs-cross-validation-score"], [27, "test-score-vs-cross-validation-score"], [51, "test-score-vs-cross-validation-score"]], "test_size, train_size arguments": [[14, "test-size-train-size-arguments"], [27, "test-size-train-size-arguments"], [51, "test-size-train-size-arguments"]], "\u201cDeployment\u201d data": [[14, "deployment-data"], [27, "deployment-data"], [51, "deployment-data"]], "\u2753\u2753 Questions for group discussion": [[20, "questions-for-group-discussion"], [34, "questions-for-group-discussion"], [57, "questions-for-group-discussion"], [78, "questions-for-group-discussion"]], "\u2753\u2753 Questions for you": [[12, "questions-for-you"], [13, "questions-for-you"], [13, "id1"], [13, "id3"], [14, "questions-for-you"], [14, "id1"], [15, "questions-for-you"], [15, "id2"], [16, "questions-for-you"], [16, "id1"], [16, "id2"], [17, "questions-for-you"], [17, "id1"], [18, "questions-for-you"], [18, "id1"], [18, "id2"], [19, "questions-for-you"], [19, "id2"], [20, "questions-for-you"], [20, "id2"], [21, "questions-for-you"], [21, "id2"], [22, "questions-for-you"], [22, "id1"], [24, "questions-for-you"], [25, "questions-for-you"], [26, "questions-for-you"], [26, "id1"], [27, "questions-for-you"], [27, "id1"], [28, "questions-for-you"], [28, "id1"], [29, "questions-for-you"], [29, "id1"], [29, "id2"], [30, "questions-for-you"], [30, "id1"], [31, "questions-for-you"], [32, "questions-for-you"], [32, "id1"], [33, "questions-for-you"], [33, "id2"], [34, "questions-for-you"], [34, "id2"], [35, "questions-for-you"], [35, "id2"], [36, "questions-for-you"], [36, "id1"], [36, "id2"], [38, "questions-for-you"], [45, "questions-for-you"], [46, "questions-for-you"], [49, "questions-for-you"], [50, "questions-for-you"], [50, "id1"], [50, "id3"], [51, "questions-for-you"], [51, "id1"], [52, "questions-for-you"], [52, "id1"], [53, "questions-for-you"], [53, "id1"], [53, "id2"], [54, "questions-for-you"], [54, "id1"], [55, "questions-for-you"], [55, "id1"], [55, "id2"], [56, "questions-for-you"], [56, "id2"], [57, "questions-for-you"], [57, "id2"], [58, "questions-for-you"], [58, "id2"], [59, "questions-for-you"], [59, "id1"], [59, "id2"], [61, "questions-for-you"], [62, "questions-for-you"], [62, "id2"], [63, "questions-for-you"], [63, "id3"], [64, "questions-for-you"], [64, "id1"], [64, "id2"], [66, "questions-for-you"], [67, "questions-for-you"], [67, "id1"], [67, "id2"], [67, "id3"], [68, "questions-for-you"], [68, "id1"], [68, "id2"], [68, "id3"], [68, "id4"], [69, "questions-for-you"], [69, "id1"], [70, "questions-for-you"], [70, "id2"]], "\ud83e\udd14 Eva\u2019s questions": [[12, "eva-s-questions"], [14, "eva-s-questions"], [25, "eva-s-questions"], [49, "eva-s-questions"], [51, "eva-s-questions"]]}, "docnames": ["LICENSE", "README", "docs/330_vs_340", "docs/README", "docs/asking_for_help", "docs/git_installation", "docs/grades", "docs/homework_instructions", "docs/python_notes", "docs/resources", "docs/setup", "learning-objectives", "lectures/201-Lecuyer-lectures/01_intro", "lectures/201-Lecuyer-lectures/02_terminology-decision-trees", "lectures/201-Lecuyer-lectures/03_ml-fundamentals", "lectures/201-Lecuyer-lectures/04_kNNs-SVM-RBF", "lectures/201-Lecuyer-lectures/05_preprocessing-pipelines", "lectures/201-Lecuyer-lectures/06_column-transformer-text-feats", "lectures/201-Lecuyer-lectures/07_linear-models", "lectures/201-Lecuyer-lectures/08_hyperparameter-optimization", "lectures/201-Lecuyer-lectures/09_classification-metrics", "lectures/201-Lecuyer-lectures/10_regression-metrics", "lectures/201-Lecuyer-lectures/12_ensembles", "lectures/201-Lecuyer-lectures/13_feat-importances", "lectures/201-Lecuyer-lectures/14_feature-engineering-selection", "lectures/202-203-Giulia-lectures/01_intro", "lectures/202-203-Giulia-lectures/02_terminology-decision-trees", "lectures/202-203-Giulia-lectures/03_ml-fundamentals", "lectures/202-203-Giulia-lectures/04_kNNs-SVM-RBF", "lectures/202-203-Giulia-lectures/05_preprocessing-pipelines", "lectures/202-203-Giulia-lectures/06_column-transformer-text-feats", "lectures/202-203-Giulia-lectures/07_class-demo", "lectures/202-203-Giulia-lectures/07_linear-models", "lectures/202-203-Giulia-lectures/08_hyperparameter-optimization", "lectures/202-203-Giulia-lectures/09_classification-metrics", "lectures/202-203-Giulia-lectures/10_regression-metrics", "lectures/202-203-Giulia-lectures/12_ensembles", "lectures/202-203-Giulia-lectures/13_feat-importances", "lectures/204-Andy-lectures/12_ensembles", "lectures/204-Andy-lectures/13_feature_importance", "lectures/204-Andy-lectures/14_feature_selection", "lectures/204-Andy-lectures/README", "lectures/204-Andy-lectures/class_demos/demo_03-ml-fundamentals", "lectures/204-Andy-lectures/class_demos/demo_04-kNNs-SVMs", "lectures/204-Andy-lectures/class_demos/demo_05-06-preprocessing", "lectures/204-Andy-lectures/class_demos/demo_07-linear-models_clean", "lectures/204-Andy-lectures/class_demos/demo_07-linear-models_filled", "lectures/204-Andy-lectures/class_demos/demo_09-classification-metrics", "lectures/204-Andy-lectures/class_demos/demo_10-regression-metrics", "lectures/notes/01_intro", "lectures/notes/02_terminology-decision-trees", "lectures/notes/03_ml-fundamentals", "lectures/notes/04_kNNs-SVM-RBF", "lectures/notes/05_preprocessing-pipelines", "lectures/notes/06_column-transformer-text-feats", "lectures/notes/07_linear-models", "lectures/notes/08_hyperparameter-optimization", "lectures/notes/09_classification-metrics", "lectures/notes/10_regression-metrics", "lectures/notes/12_ensembles", "lectures/notes/13_feat-importances", "lectures/notes/14_feature-engineering-selection", "lectures/notes/15_K-Means", "lectures/notes/16_DBSCAN-hierarchical", "lectures/notes/17_recommender-systems", "lectures/notes/18_natural-language-processing", "lectures/notes/19_intro_to_computer-vision", "lectures/notes/20_time-series", "lectures/notes/21_survival-analysis", "lectures/notes/22_communication", "lectures/notes/24_deployment-conclusion", "lectures/notes/appendixA_feature-engineering-text-data", "lectures/notes/appendixB_multiclass-strategies", "lectures/notes/final-exam-review-guiding-question", "lectures/tutorials/01_decision_boundaries", "lectures/tutorials/02_ML_fundamentals", "lectures/tutorials/03_Preprocessing", "lectures/tutorials/04_Hyperparameter_optimization", "lectures/tutorials/05_Classification_metrics", "lectures/tutorials/06_Ensembles", "syllabus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["LICENSE.md", "README.md", "docs/330_vs_340.md", "docs/README.md", "docs/asking_for_help.md", "docs/git_installation.md", "docs/grades.md", "docs/homework_instructions.md", "docs/python_notes.ipynb", "docs/resources.md", "docs/setup.md", "learning-objectives.md", "lectures/201-Lecuyer-lectures/01_intro.ipynb", "lectures/201-Lecuyer-lectures/02_terminology-decision-trees.ipynb", "lectures/201-Lecuyer-lectures/03_ml-fundamentals.ipynb", "lectures/201-Lecuyer-lectures/04_kNNs-SVM-RBF.ipynb", "lectures/201-Lecuyer-lectures/05_preprocessing-pipelines.ipynb", "lectures/201-Lecuyer-lectures/06_column-transformer-text-feats.ipynb", "lectures/201-Lecuyer-lectures/07_linear-models.ipynb", "lectures/201-Lecuyer-lectures/08_hyperparameter-optimization.ipynb", "lectures/201-Lecuyer-lectures/09_classification-metrics.ipynb", "lectures/201-Lecuyer-lectures/10_regression-metrics.ipynb", "lectures/201-Lecuyer-lectures/12_ensembles.ipynb", "lectures/201-Lecuyer-lectures/13_feat-importances.ipynb", "lectures/201-Lecuyer-lectures/14_feature-engineering-selection.ipynb", "lectures/202-203-Giulia-lectures/01_intro.ipynb", "lectures/202-203-Giulia-lectures/02_terminology-decision-trees.ipynb", "lectures/202-203-Giulia-lectures/03_ml-fundamentals.ipynb", "lectures/202-203-Giulia-lectures/04_kNNs-SVM-RBF.ipynb", "lectures/202-203-Giulia-lectures/05_preprocessing-pipelines.ipynb", "lectures/202-203-Giulia-lectures/06_column-transformer-text-feats.ipynb", "lectures/202-203-Giulia-lectures/07_class-demo.ipynb", "lectures/202-203-Giulia-lectures/07_linear-models.ipynb", "lectures/202-203-Giulia-lectures/08_hyperparameter-optimization.ipynb", "lectures/202-203-Giulia-lectures/09_classification-metrics.ipynb", "lectures/202-203-Giulia-lectures/10_regression-metrics.ipynb", "lectures/202-203-Giulia-lectures/12_ensembles.ipynb", "lectures/202-203-Giulia-lectures/13_feat-importances.ipynb", "lectures/204-Andy-lectures/12_ensembles.ipynb", "lectures/204-Andy-lectures/13_feature_importance.ipynb", "lectures/204-Andy-lectures/14_feature_selection.ipynb", "lectures/204-Andy-lectures/README.md", "lectures/204-Andy-lectures/class_demos/demo_03-ml-fundamentals.ipynb", "lectures/204-Andy-lectures/class_demos/demo_04-kNNs-SVMs.ipynb", "lectures/204-Andy-lectures/class_demos/demo_05-06-preprocessing.ipynb", "lectures/204-Andy-lectures/class_demos/demo_07-linear-models_clean.ipynb", "lectures/204-Andy-lectures/class_demos/demo_07-linear-models_filled.ipynb", "lectures/204-Andy-lectures/class_demos/demo_09-classification-metrics.ipynb", "lectures/204-Andy-lectures/class_demos/demo_10-regression-metrics.ipynb", "lectures/notes/01_intro.ipynb", "lectures/notes/02_terminology-decision-trees.ipynb", "lectures/notes/03_ml-fundamentals.ipynb", "lectures/notes/04_kNNs-SVM-RBF.ipynb", "lectures/notes/05_preprocessing-pipelines.ipynb", "lectures/notes/06_column-transformer-text-feats.ipynb", "lectures/notes/07_linear-models.ipynb", "lectures/notes/08_hyperparameter-optimization.ipynb", "lectures/notes/09_classification-metrics.ipynb", "lectures/notes/10_regression-metrics.ipynb", "lectures/notes/12_ensembles.ipynb", "lectures/notes/13_feat-importances.ipynb", "lectures/notes/14_feature-engineering-selection.ipynb", "lectures/notes/15_K-Means.ipynb", "lectures/notes/16_DBSCAN-hierarchical.ipynb", "lectures/notes/17_recommender-systems.ipynb", "lectures/notes/18_natural-language-processing.ipynb", "lectures/notes/19_intro_to_computer-vision.ipynb", "lectures/notes/20_time-series.ipynb", "lectures/notes/21_survival-analysis.ipynb", "lectures/notes/22_communication.ipynb", "lectures/notes/24_deployment-conclusion.ipynb", "lectures/notes/appendixA_feature-engineering-text-data.ipynb", "lectures/notes/appendixB_multiclass-strategies.ipynb", "lectures/notes/final-exam-review-guiding-question.ipynb", "lectures/tutorials/01_decision_boundaries.ipynb", "lectures/tutorials/02_ML_fundamentals.ipynb", "lectures/tutorials/03_Preprocessing.ipynb", "lectures/tutorials/04_Hyperparameter_optimization.ipynb", "lectures/tutorials/05_Classification_metrics.ipynb", "lectures/tutorials/06_Ensembles.ipynb", "syllabus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 4, 5, 7, 8, 9, 10, 13, 18, 19, 22, 24, 26, 27, 31, 32, 33, 36, 38, 40, 42, 43, 45, 46, 48, 50, 55, 56, 59, 61, 62, 63, 64, 65, 66, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "0": [0, 1, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "00": [1, 12, 13, 15, 17, 18, 19, 20, 23, 25, 30, 32, 33, 34, 37, 39, 40, 42, 44, 46, 49, 50, 52, 54, 55, 56, 57, 60, 63, 64, 67, 68, 69, 80], "000": [12, 14, 15, 16, 18, 19, 21, 22, 23, 25, 27, 28, 29, 32, 33, 35, 36, 37, 38, 39, 46, 48, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 65, 66, 68, 71], "0000": [16, 18, 20, 29, 32, 34, 46, 53, 55, 57, 65, 71], "00000": [19, 33, 46, 56, 67], "000000": [13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 67, 68], "00000000e": [23, 37, 39, 60], "000000e": [19, 33, 44, 56], "000001": [19, 21, 35, 58], "000004": 39, "000009": 19, "00000e": [15, 52], "000010": [19, 21, 35, 58], "000011": [20, 34, 57], "000012": 39, "000013": 39, "000015": 19, "000021": [16, 29, 53], "000025": 39, "000036": [20, 34, 57], "000057": [16, 29, 53], "000065": 56, "000067": 56, "000071": 19, "000077": 56, "000087": 55, "000089": 55, "0001": [18, 20, 21, 32, 34, 35, 55, 57, 58, 68, 69], "000100": [16, 21, 29, 33, 35, 53, 58], "000101": 18, "000102": 18, "000102e": 42, "000106": 33, "000108": 55, "000109": 33, "000113": [19, 20, 34, 57], "000114": 56, "000116": 18, "000117": [21, 35, 58], "000124": [32, 33], "000126": 19, "000128": 43, "000130": 55, "000134": 32, "000136": 66, "000137": 56, "000140": 18, "000142": [18, 33], "000144": 43, "000145": 56, "000146": 55, "000147": 56, "000149": [16, 29, 43, 53], "000150": 55, "000151": 56, "000153": 18, "000154": 43, "000155": [16, 20, 29, 34, 53, 57], "000156": 43, "000159": 56, "000161": 32, "000162": 43, "000163": [43, 56], "000165": 32, "000166": [18, 55, 56], "000170": 32, "000173": 33, "000175": 43, "000177": [53, 67], "000179": 43, "000180": [21, 53], "000181": 56, "000182": 55, "000183": [21, 55], "000187": [19, 21, 33, 43, 55], "000188": 53, "000190": 67, "000191": 33, "000192": [16, 21, 67], "000193": [19, 33], "000194": 55, "000195": 53, "000196": [18, 19], "000197": [16, 32], "000198": [20, 34, 57], "000200": 33, "000201": 56, "000203": [16, 21], "000206": 56, "000207": 32, "000208": [16, 29, 53], "000210": 56, "000212": 61, "000213": 55, "000215": 33, "000218": [29, 55], "000220": 33, "000221": [21, 58], "000222": 29, "000223": 35, "000225": 16, "000226": [35, 58], "000227": [20, 34, 35, 57], "000228": 29, "000229": [21, 35], "000231": [35, 53], "000232": 66, "000234": [15, 19, 33, 52, 56], "000235": [20, 34, 35, 43, 53, 57], "000236": 43, "000238": 35, "000239": [18, 33], "000240": [18, 53], "000241": [29, 43], "000242": 21, "000245": [19, 33, 56], "000247": [35, 66], "000248": [16, 43], "000251": 19, "000255": [19, 55], "000256": [18, 67], "000259": 53, "000260": 53, "000261": 16, "000262": 33, "000263": 21, "000265": 43, "000266": 19, "000267": [16, 19], "000270": 43, "000271": 67, "000273": 66, "000274": 66, "000278": [18, 29], "000279": 29, "000280": 18, "000281": [43, 55], "000283": 55, "000285": [29, 55], "000286": [33, 56], "000289": [16, 19, 29, 53], "000294": 56, "000296": 43, "000299": 21, "000304": 16, "000306": 29, "000307": 33, "000310": 43, "000312": [20, 34, 44, 57], "000313": [35, 43], "000316": 43, "000318": 18, "000321": 43, "000328": 43, "000329": [33, 43], "000331": 19, "000332": [44, 58], "000336": [32, 66], "000337": 19, "000339": [44, 56], "000342": 29, "000348": 56, "000351": 18, "000353": [18, 33, 56], "000354": 56, "000363": 66, "000366": [20, 34, 57], "000370": 56, "000371": 55, "000373": [35, 58], "000374": [24, 43], "000378": 55, "00038": [19, 33, 56], "000384": 32, "000386": [19, 32], "000387": 43, "000397": [18, 21, 35, 58], "000399": 66, "000402": 18, "000412": 18, "000415": [32, 44], "000416": 18, "000419": 32, "000420": 43, "000423": 43, "000428": 43, "000432": [43, 44], "000433": 58, "000434": [14, 32], "000435": [14, 66], "000437": 66, "000438": 14, "000441": [14, 43], "000445": 14, "000448": 14, "000450": 44, "000451": 14, "000452": 53, "000459": [14, 55], "000460": 43, "000463": 14, "000471": [14, 67], "000472": 66, "000475": 43, "000477": 27, "000480": [27, 43], "000489": 56, "000492": [20, 34, 57], "000494": 21, "000496": 27, "000498": 67, "0005": 69, "000500": [14, 21], "000502": [21, 27, 29], "000503": [15, 19, 33, 56], "000506": 21, "000507": 44, "000508": [19, 33, 56], "000511": 14, "000520": [43, 58], "000524": 14, "000528": 15, "000532": 21, "000534": 27, "000540": 43, "000542": 43, "000545": 15, "000548": 15, "000549": 15, "000551": 27, "000556": 44, "000557": 19, "000558": [27, 44], "000559": 21, "000561": [15, 43], "000568": 19, "000570": 20, "000575": 67, "000579": 46, "00058": [19, 33, 56], "000580": 52, "000582": 35, "000587": 16, "000590": 32, "000602": 15, "000607": 15, "000608": 35, "000609": 46, "000610": [27, 32], "000612": 15, "000616": 35, "000619": 46, "000623": 35, "000625": 15, "000626": 14, "000629": 35, "000630": [20, 34, 57], "000633": [35, 52], "000636": 14, "000637": [14, 21, 66], "000639": 14, "000640": 15, "000642": 14, "000644": 14, "000645": 43, "000646": 14, "000647": [21, 52], "000650": 52, "000651": [35, 52], "000652": [14, 58], "000654": [35, 46], "000655": [14, 52], "000657": 14, "000661": 52, "000664": 14, "000666": 15, "000671": 52, "000675": [14, 28], "000678": 56, "000683": 15, "000685": 43, "000686": 14, "000691": 27, "000696": 27, "000697": 15, "000700": 28, "000701": [15, 27], "000707": 27, "000710": 28, "000711": 27, "000712": 27, "000713": [43, 58], "000714": 28, "000720": 27, "000722": 14, "000726": [20, 34, 57], "000727": 46, "000728": 28, "000729": 21, "000736": 28, "000737": 67, "000739": 28, "000740": 43, "000742": 15, "000746": 15, "000747": [33, 56], "000748": 53, "000752": [15, 52], "000757": 14, "000758": 66, "000765": 53, "000768": 21, "000774": 53, "000786": [20, 34, 57], "000787": 52, "000789": [33, 44], "00079": [19, 33, 56], "000794": 52, "000795": 52, "000797": 52, "000800": 14, "000803": 58, "000805": [15, 40], "000812": [14, 43], "000815": 15, "000816": 27, "000820": 15, "000823": 27, "000829": [43, 52], "000831": 52, "000832": 58, "000839": [27, 28, 43], "000842": 15, "000851": 28, "000863": 40, "000867": 53, "000869": 67, "000870": 27, "000873": 52, "000878": 33, "000881": 29, "000889": 52, "000890": 43, "000891": [20, 34, 57], "000894": 29, "000902": 16, "000917": [19, 33, 56], "000927": [20, 34, 57], "000934": 43, "000936": 52, "000944": [15, 40], "000945": 61, "000950": [19, 28], "000952": 29, "000960": 66, "000964": 61, "000967": 28, "000969": 28, "000975": 14, "000976": [19, 33, 56], "000977": 52, "000982": [19, 33, 56], "000989": 46, "000997": 16, "001": [12, 14, 15, 16, 18, 19, 21, 22, 23, 25, 28, 29, 32, 33, 35, 36, 37, 38, 39, 46, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 66, 68, 69, 71], "0010": [18, 32, 55], "00100": [19, 56], "001000": [19, 21, 33, 35, 56, 58], "001002": 51, "001003": 46, "001006": 51, "001010": [46, 51], "001011": [14, 52, 58], "001014": [16, 51], "001016": 51, "001017": 51, "001021": 14, "001026": 51, "001027": 51, "001029": 51, "001031": 46, "001038": 51, "001040": 57, "001043": 53, "001057": [51, 56], "001060": [16, 29, 53], "001063": 51, "001064": 66, "001068": [23, 37, 39, 60], "001071": 51, "001078": 51, "001079": 29, "001082": 27, "001084": 32, "001086": 51, "001087": 61, "001091": 35, "001097": 33, "001103": 51, "001109": 43, "001111": 51, "001113": 27, "001116": 28, "001126": 28, "001139": 52, "001144": 14, "001145": 15, "001146": 28, "001149": 51, "001155": 61, "001162": [19, 33, 56, 61], "001166": 33, "001168": 21, "001174": 51, "001178": 43, "001179": 15, "001195": 24, "001200": 16, "001201": 24, "001204": 15, "001205": [20, 34, 57], "001220": 55, "001224": 52, "001226": 66, "001230": 43, "001236": 56, "001239": [20, 34, 57], "001253": 24, "001260": 15, "001266": [21, 35, 58], "001271": 15, "001272": 16, "001274": 24, "001279": 61, "001282": 15, "001283": 32, "001286": [20, 34, 57], "001289": 19, "001294": 51, "001299": [34, 51], "001300": 21, "001302": 28, "001305": 51, "001307": 51, "001315": 51, "001317": 51, "001322": 51, "001323": 51, "001325": 52, "001329": 51, "001334": 19, "001337": 51, "001338": [28, 55], "001344": 15, "001347": 56, "001352": 51, "001361": 55, "001362": 55, "001363": 35, "001365": 52, "001371": 54, "001372": 33, "001375": 43, "001383": 33, "001389": 24, "001390": 51, "001391": 51, "001392": 52, "001400": 54, "001406": 58, "001407": 51, "001412": 56, "001414": 52, "001416": 15, "001419": 43, "001422": [35, 58], "001423": 56, "001429": 51, "001433": 58, "001439": [19, 46], "001441": 51, "001448": 54, "001453": 51, "00146": 56, "001466": 54, "001467": 56, "001472": 21, "001480": 40, "001488": 19, "001492": 56, "001495": 52, "001503": 40, "001511": 43, "001519": 15, "001521": 28, "001541": 28, "001563": 54, "001566": [43, 58], "001572": 40, "001580": 28, "001585": 56, "001586": 52, "001591": 54, "001594": [19, 33, 56], "001595": 52, "001600": 52, "001604": 54, "001606": 54, "001608": 56, "001616": 56, "001620": 56, "001629": 56, "001641": 66, "001645": 55, "001647": 54, "001679": 56, "001682": 56, "001687": 43, "001693": 61, "001699": 51, "0017": [20, 34, 57], "001700": [20, 34, 57], "001710": 55, "001715": 54, "001730": 15, "00174": 19, "001740": [18, 21, 35, 58], "001762": 18, "001769": 56, "001773": 52, "001776": 51, "001790": 58, "001792": [19, 33, 56], "001805": 15, "001807": 15, "001836": 15, "001847": 61, "001849": 19, "001850": [40, 55], "001873": 15, "001877": 52, "001882": 43, "001883": 17, "001887": 19, "001888": 28, "001894": 58, "001900": 52, "001911": 21, "001920": 54, "001922": 54, "001929": 17, "001933": [35, 58], "001949": 61, "001952": 52, "001960": 17, "0019627889": 65, "001968": 51, "001986": 19, "001994": 61, "002": [14, 18, 22, 23, 32, 36, 37, 38, 51, 55, 59, 60, 65, 68], "002003": 56, "002021": 30, "002022": 54, "002030": 52, "002035": 30, "002045": 56, "002055": 40, "002057": [16, 29, 53, 54], "002059": 30, "002066": 19, "002069": 30, "002070": 30, "002076": 19, "002077": 33, "002083": 52, "002084": 19, "002088": 17, "002092": [17, 19], "002096": 66, "002102": 33, "002105": [19, 33, 56], "002108": 24, "002114": 18, "002116": 54, "002118": 52, "002120": 33, "002121": 18, "002123": [19, 56], "002137": 32, "002143": 51, "002146": 56, "002147": 33, "002151": 33, "002158": 61, "002159": 56, "002161": 19, "002189": 17, "002197": [33, 56], "002201": 40, "002218": 17, "002221": 58, "002224": 28, "002225": 28, "002226": 24, "002228": 21, "002231": 17, "002238": 17, "002251": 15, "002268": 33, "00227": 19, "002272": 17, "002274": 32, "002282": 19, "002292": 32, "002298": 19, "002317": 30, "002321": [43, 55], "00234": 56, "002351": 17, "002353": 24, "002355": 61, "002359": 24, "002367": 30, "002376": 33, "002385": 58, "002388": 33, "002395": 19, "002397": 24, "0024": 19, "002411": 24, "002418": 43, "002421": 19, "002441": 61, "002459": 33, "002460": 66, "002477": [32, 43], "002478": 30, "002481": 18, "002512": 30, "002516": 28, "002525": 66, "002541": 19, "002542": 33, "002549": 30, "002555": 19, "002561": [19, 33, 56], "002564": 30, "002571": 30, "002614": 19, "002618": 32, "002643": 43, "002646": 61, "002664": 61, "002675": 56, "002682": 66, "002690": [16, 29, 53], "002692": 56, "002701": 24, "002703": 18, "002704": [24, 56], "002711": 66, "002716": 28, "002720": 28, "002726": 21, "002730": 24, "002731": 40, "002736": 20, "002746": 58, "002761": 18, "002769": 24, "002783": 56, "002788": 54, "002789": 54, "0028": 19, "002802": 43, "002807": 54, "002814": 29, "002818": 17, "002835": 56, "002842": 17, "002844": 24, "002845": 30, "002848": 43, "002858": 54, "002867": 61, "002873": [19, 24], "002878": 24, "002889": [20, 34, 57], "002895": 40, "0029": 68, "002902": 17, "002910": 54, "002921": 43, "002928": 16, "002929": 33, "002934": 55, "002939": 19, "002940": 66, "002948": 52, "002949": 28, "00296": 19, "002962": 66, "002965": 43, "00297": 19, "002974": 32, "002975": 33, "002986": 66, "002987": 43, "002996": 24, "002999": 56, "003": [22, 33, 36, 38, 56, 59], "003013": 54, "003014": 56, "003015": [30, 56], "003026": 18, "003027": 56, "003037": 24, "003038": [43, 56], "003041": 40, "003044": 43, "003046": 33, "003052": 16, "003066": 16, "003078": 21, "003083": 56, "003086": 54, "003088": 43, "003095": 21, "003103": 18, "003106": 16, "003113": 16, "003115": 54, "003124": [35, 58], "003133": [21, 35, 58], "003146": 54, "003148": 55, "003149": 19, "003159": 40, "003162": 40, "003165": 32, "003166": [53, 61], "003181": 53, "003183": 61, "003185": 68, "003186": 54, "003188": [53, 54], "003194": [18, 32, 55], "003199": 33, "00321": 19, "003210": 43, "003212": 53, "003218": 28, "003224": 28, "003228": 33, "003232": 17, "003241": 40, "003242": 66, "003248": 19, "003257": 66, "003268": 40, "00327": 33, "003272": 43, "003273": 51, "003274": 19, "003283": 66, "003284": 28, "003288": [35, 58], "003292": 24, "003300": [16, 29, 53], "003309": 40, "003311": 19, "003316": 29, "00332": 56, "003324": 53, "003333": 40, "003361": [19, 34], "003365": 54, "003388": 29, "003401": 61, "003421": 56, "003423": 61, "003427": 61, "003442": 29, "003463": 43, "003472": 56, "003477": 66, "003479": [29, 32, 56], "003483": 56, "003493": 61, "003501": 19, "003507": 17, "003508": 40, "003517": 19, "003519": 30, "00352": 19, "003527": 19, "003528": 56, "003529": 56, "003540": 43, "003547": [21, 33, 35, 58], "003561": [14, 27], "003563": [21, 56], "003565": 30, "003569": [33, 40], "003586": 30, "003593": 43, "003603": 19, "003616": 33, "003633": 56, "003634": 19, "003644": 40, "003647": 66, "003650": 33, "003652": 32, "003663": 43, "003665": 17, "003666": [17, 29], "003669": 33, "003680": 33, "003681": [23, 37], "003688": 19, "00369": 56, "003733": 33, "003736": 30, "003748": 56, "003749": 17, "003757": 56, "003785": [21, 35, 43, 58], "003801": 19, "003820": 30, "003846": 19, "003856": 19, "003871": 19, "003877": 43, "003883": 19, "003885": 56, "003887": [19, 33], "003898": 28, "003902": 17, "003904": [30, 33], "003905": 19, "003910": 43, "003913": 17, "003919": [19, 33, 43, 56], "003919287722401839": [19, 33, 56], "00392157": 66, "003923": 54, "003924": 61, "003933": 56, "003936": 17, "003949": 30, "003951": 17, "003964": 19, "003968": 17, "003984": 19, "003998": 56, "004": [15, 19, 22, 23, 33, 36, 37, 38, 39, 52, 56, 59, 60, 66], "004057": 56, "004065": 67, "004074": 19, "004079": 19, "004081": 17, "004082": 67, "004094": 40, "004111": 40, "004121": [35, 58], "004139": 19, "004143": 58, "004174": 19, "004203": 30, "004221": 33, "004225": 33, "004262": 30, "004263": 19, "004264": [14, 27, 51], "004293": 56, "004301": 33, "004305": 56, "004315": 21, "004337": [19, 33, 56], "004345": 33, "00435173": 62, "004352": 62, "004358": 30, "004364": 40, "004373": 17, "004379": 19, "004386": 33, "004388": 33, "004398": [33, 60], "004402": 56, "004438": 18, "004443": 19, "004461": 43, "004462": 28, "004466": 56, "004469": 43, "004496": 56, "004521": 58, "004529": 60, "004556": 56, "004574": 58, "004585": 33, "004594": 43, "004602": [35, 58], "004607": 33, "00461": 56, "004653": 33, "004660": 24, "004665": 32, "004685": 33, "004712": 40, "004713": 17, "004714": 56, "004723": 60, "004727": 33, "004745": 30, "004761": 60, "004769": [14, 27], "004770": [16, 29, 53], "004783": 21, "004801": [16, 29, 53, 54], "004807": 54, "004816": 33, "004826": 58, "004829": [35, 58], "004838": 21, "00484": 19, "004842": 21, "004848": 16, "004852": 43, "004854": 58, "004864": 19, "00488": 33, "004884": 66, "004919": 56, "004934": 57, "004952": 56, "004959": 56, "00496": 56, "004961": 33, "004964": 17, "004978": 19, "005": [12, 22, 23, 25, 36, 37, 38, 39, 49, 59, 60, 68, 69], "005039": 19, "005047": 40, "005067": 53, "005071": 30, "005074": 66, "005093": 53, "005098": [35, 58], "005103": 16, "005114": [35, 58], "005126": 56, "005136": 42, "005151": [19, 33, 56], "005157": 53, "005167": 58, "005169": 40, "005191": 16, "005196": 56, "005204": [16, 24], "005208": 33, "005241": [35, 58], "005247": 33, "00525962": [16, 29, 53], "005269": 58, "005270": 43, "005273": 24, "005288": 54, "005290": 16, "005309": 28, "005313": 28, "005335": 56, "005336": [35, 58], "005373": 29, "005377": 29, "005387": [20, 34, 57], "005388": 33, "005398": 29, "005401": 19, "005406": 40, "005415": 21, "005423": 56, "005425": 33, "005426": [19, 33, 56], "00543825": [16, 29, 53], "005440": 66, "005443": 28, "005478": 60, "00548": 56, "005508": 30, "005515": 21, "005520": 33, "005525": 46, "005538": [35, 58], "005543": 40, "005563": 27, "005579": 58, "005593": 28, "005597": 33, "005608": 17, "005622": 29, "005641": [35, 58], "005674": [35, 58], "005699": [14, 27, 51], "005706": 21, "005708": 56, "005716": [33, 40], "00573": [19, 33, 56], "005734": 56, "005735": 56, "005746": 19, "005767": 56, "005771": 21, "005781": 21, "005809": 67, "005815": 33, "005834": 56, "005836": 53, "00585": 19, "005868": 30, "005883": 33, "005888": [16, 29, 53], "005934": 35, "005948": 21, "00599": 19, "006": [22, 23, 36, 37, 38, 39, 59, 60, 68], "006012": 56, "006034": 21, "006035": 21, "006046": 58, "006055": 56, "006067": [35, 58], "006070": 43, "006082": 19, "006092": 21, "006106": [46, 56], "006110": [15, 19, 33, 35, 52, 56, 58], "006136": 21, "006149": 19, "006208": 43, "006236": [35, 43, 58], "006244": 56, "006250": 43, "006284": 21, "006297": 19, "006321": 23, "006373": 19, "006405": 19, "006413": 21, "006435": 56, "006438": 32, "00644254": 46, "006452": [18, 32, 55], "006455": 33, "006465": 28, "006469": 21, "006476": 58, "006505": 66, "006520": 21, "006522": 33, "006531": [14, 27, 51], "006545": [19, 33, 56], "006546893270012566": [18, 32, 55], "006553": 23, "006557": [18, 32, 55], "006570": 29, "006574": 21, "006578": [16, 29, 53, 54], "006631": 19, "006649": 28, "006652": 56, "006667": [43, 56], "006669": 21, "00667": 56, "006700": 21, "00671": 33, "006734": 33, "006737": 30, "006744": [21, 35, 58], "00676": 33, "006766": 21, "006770": 43, "006805": [14, 27, 51], "006821": 21, "006843": 23, "006861": 56, "006875": 20, "006887": 19, "006904": 56, "006905": 33, "00691": 56, "006917": [19, 35], "006973": 53, "006991": 17, "006994": 21, "007": [22, 29, 36, 38, 46, 53, 59, 60, 68, 71], "007023": 37, "007068": 61, "007074": 32, "007096": 37, "007100": 23, "007116": 30, "007119": 33, "007126": 21, "00715": 56, "007163": 21, "007175": 21, "007194": 33, "00720988e": [23, 37, 39, 60], "007210": 21, "007228": [35, 58], "007236": 33, "007263": 33, "007264": 21, "007291": 54, "007299": 23, "007316": [14, 27, 51], "007333": 39, "007361": 57, "007362": 56, "00741": 19, "007434": [23, 37, 60], "007458": [16, 29, 53, 54], "007482": 33, "007515": 39, "007517": [35, 58], "007529": 21, "007542": 42, "007544": 56, "007563": 56, "007587": 37, "007588": 62, "00758803": 62, "00759438": [23, 37, 39, 60], "007655": 56, "007666": [20, 34, 57], "00767": 56, "007689": 33, "007714": 37, "007717": 39, "007737": 58, "007776": [19, 35, 58], "007785": 20, "007794": 44, "007817": 19, "007818": 56, "007837": 21, "007911": 33, "007926": 28, "007938": [14, 51], "007986": [35, 58], "008": [16, 22, 59, 60, 71], "008040": 67, "008095": 19, "008112": 20, "008120": [35, 58], "008147": 34, "008150": 37, "008153": 56, "008165": 19, "008167": [16, 29, 53, 54], "008222": 33, "008259": 39, "008286": 43, "008289": 19, "00830586": [17, 30, 54], "008306": [17, 30, 54], "008322e": 68, "008333": 54, "008346": [35, 58], "008355": 20, "008377": 56, "008413": 21, "00846": 19, "008472": [35, 58], "008498": 43, "008565": 20, "008577": 66, "008581": 58, "008589": 20, "008606": [35, 58], "008617": [35, 58], "008661": 33, "008667": [19, 33, 56], "008676": 21, "00871": 56, "008735": [15, 28, 52], "008783": 33, "008785": [35, 58], "008936": 33, "008949": 19, "009": [22, 23, 36, 54, 59, 68, 71], "009006": 20, "009014": 33, "009059": [14, 27, 51], "009063": [19, 33, 56], "009082": 56, "009090": [35, 58], "009131": 43, "009132": 56, "009140": [35, 58], "009221": 19, "009251": 19, "009260": 27, "009294": 33, "009297": [21, 56], "009305": 56, "009326": 39, "009328": 21, "009339": [35, 58], "009422": [14, 51], "009470": 21, "009512": 56, "009514e": [21, 35, 58], "009573": [22, 36], "009605": 33, "009655": 33, "009664": [35, 58], "009692": 66, "009703": 43, "009710": 19, "009724": 61, "009757": 19, "009848": 21, "009935": 19, "009940": 24, "009952": 24, "009963": 33, "00pm": 1, "01": [15, 16, 18, 19, 20, 21, 23, 28, 29, 32, 33, 34, 35, 37, 39, 44, 48, 52, 53, 55, 56, 57, 58, 60, 66, 67, 68, 69, 72, 80], "010": [12, 18, 19, 22, 25, 32, 33, 36, 37, 39, 46, 49, 55, 56, 68], "0100": [18, 32, 55], "01000": [19, 33, 56], "010000": [16, 19, 21, 29, 33, 35, 53, 56, 58], "010027": [18, 32, 55], "010065": 33, "010126": 19, "010152": 19, "010183": [16, 29, 53, 54], "010191": 24, "0102": [15, 19, 33, 52, 56], "010201": 19, "010205": 33, "010208": 61, "010294": [14, 27, 51], "010340": 20, "010344": 33, "010547": [21, 27], "010628": 19, "010650": [14, 27, 51], "010673": 33, "010679": [14, 51], "010681": 33, "010688": 61, "010715": [19, 33, 56], "010741": 24, "010750": 61, "010781": 19, "010824": 20, "010847": 21, "010864": 19, "010920": 24, "010954": 24, "010955": 33, "011": [12, 23, 25, 38, 49, 54, 66, 68], "011005": 21, "011036": 33, "01109": 33, "011105": 21, "011210": 61, "011234": [20, 34, 57], "011246": 24, "011248": [35, 58], "011252": 61, "011269e": [21, 35, 58], "011281": 33, "011287": 61, "011316": 24, "011332": 68, "011336": [15, 28, 52], "011379": 24, "011415": 43, "011421": 19, "011440": [35, 58], "011576": 21, "011617": 56, "011678": [20, 34, 57], "011767": [21, 35, 58], "011773": 59, "011957": 19, "012": [16, 29, 36, 38, 53, 54, 59, 60, 66, 68, 71], "012011": 21, "012019": [27, 51], "012030": 61, "012065": 14, "012232": [35, 58], "012240": 61, "012247": 43, "012252": 56, "012300": 19, "012394": 19, "012455": 40, "012472": 24, "012616": [19, 33, 56], "012624": [35, 58], "012707": 57, "012758": [35, 58], "012788": 35, "012858": 35, "012924": 35, "012995": 33, "013": [16, 22, 37], "013031": [35, 58], "013061": 21, "01311996044": 35, "01311996071": 58, "01311996074": 21, "013120": [23, 39, 60], "013132": 19, "013157": 56, "013161": [19, 33, 56], "013189": 35, "013244": 33, "013268": 40, "013303": 33, "013398": 40, "013433": [15, 28, 52], "013567": 33, "013629": 56, "013668": 21, "013706928443177698": [19, 33, 56], "013707": [19, 33, 56], "013726": 33, "013863": 56, "013888": 56, "014": [16, 23, 29, 36, 37, 38, 51, 53, 59, 60, 68], "014030": [35, 58], "014081e": [21, 35, 58], "01409912": 65, "0141": 33, "014132": 19, "014153": 19, "01425": 19, "014305": [35, 58], "014321": 33, "01432486e": [23, 37, 39, 60], "014337": 43, "014360": 19, "014414": 21, "014420e": 19, "014439": 19, "014481": 56, "014503": 56, "014511": 19, "014584": 19, "014638": 33, "014650": 68, "014665": 19, "014680": 19, "014722": 19, "014730": 54, "01473536": [15, 28, 52], "014758": 68, "014891": 33, "014965": 19, "014990": 43, "015": [12, 16, 22, 25, 29, 49, 53, 54, 59, 68, 71], "015003": 56, "015039": [20, 34, 57], "015056": 56, "015114": 19, "015147": 19, "015165": [35, 58], "015181": 19, "015235": 19, "015237": 19, "015328": 19, "015372": 56, "015396": 40, "015580": [23, 37], "015639": 43, "01568": 19, "015708": 33, "015724": 61, "015755": 56, "015794": 35, "015819": 56, "015861": 33, "015929": 19, "015966": 34, "015974": 19, "016": [22, 38], "016073": 21, "016138": 33, "016173": 19, "016202": 19, "016263": 56, "016313": 19, "016330": 43, "016356": 34, "016372": 56, "016442": 19, "016459": 33, "016469": 33, "01647": [19, 33, 56], "016525": [21, 23, 35, 37, 39, 58, 60, 69], "016555": [18, 32, 55], "016587": [20, 34, 57], "016598": 56, "016602": 56, "016607": 56, "016660": 44, "016676": 62, "016685": 19, "016688": [16, 24, 29, 53, 61], "016693": [35, 58], "0168": 33, "016807": [18, 32, 55], "016815": 56, "016849": 19, "016871": 19, "016879": 19, "016918": [20, 34, 57], "016944": [15, 28, 52], "016945": 33, "017": [36, 37, 54, 66], "017054": 33, "017068": 33, "017074": 33, "017185": 56, "017226": [35, 58], "017308": 56, "017401": [19, 40], "017424": 19, "017427": 56, "017438": 19, "017455": 20, "017561": 33, "017610": 60, "017696": 60, "017737": 60, "017741": 60, "017788": 19, "017795": 43, "017807": 40, "017829": 67, "017837": 56, "01784": 56, "017878": 33, "017891": 19, "017927": 56, "017943": 19, "017951": 43, "017959e": [21, 35, 58], "017972": [16, 29, 53], "018": [38, 39, 59], "018003": 19, "018014": 60, "018022": 33, "018046": 57, "018077": 56, "018137": 33, "018178": [15, 28, 52], "018190": 40, "018243": 56, "018267": 40, "01831": 33, "018310": [15, 28, 52], "018434": 67, "018439": 35, "018456": 33, "018459e": [21, 35, 58], "018487": [18, 32, 55], "0185": [18, 32, 55], "018505": 56, "018507e": [21, 35, 58], "018533": 35, "018551": 19, "018558": 56, "018581": [35, 58], "0186": 19, "018613": 33, "018622": 44, "018636": 33, "018653": 56, "018659": 33, "018745": [12, 25, 49], "018763": 33, "018789": 56, "018846": 56, "018854": [20, 34, 57], "018944": 35, "019": [38, 59, 71], "019003": 19, "019012": 56, "019071": 20, "019118": 19, "019158": 33, "019163": 56, "019293": 43, "019381838999846482": [19, 33, 56], "019382": [19, 33, 56], "019396": [33, 56], "019444": 54, "019446": 56, "019531": [20, 34, 57], "019556": 68, "0195598": [18, 32, 55], "019574": 56, "019701": 19, "019794": 33, "019839": [19, 33, 56], "019890": 20, "019976": 46, "02": [15, 16, 18, 19, 21, 23, 24, 29, 32, 33, 35, 37, 39, 40, 42, 44, 52, 53, 54, 55, 56, 58, 60, 61, 67, 68, 76, 80], "020": 39, "020000": 43, "02000e": [15, 52], "020077": 40, "020123": [35, 58], "020215": 33, "020403": 56, "020414": [19, 33, 56], "020641": 60, "020648": [35, 58], "020653": [14, 27, 51], "02074": 40, "020833": 64, "020853": 33, "020862": [35, 58], "020873": [16, 29, 53], "020888": 33, "021": [36, 59], "021043": 57, "021082": 43, "021100": [16, 29, 53], "021244": 39, "021269": 33, "02128": 33, "021281": 56, "021289": 33, "021305": [15, 28, 52], "021345": [19, 33, 56], "021396": 20, "021402": 39, "021523": 57, "021549": 33, "021603": 66, "021705": 33, "021712": 39, "021721": 56, "021746": 56, "021750": 23, "021766": 40, "021813": 57, "021816": 21, "021862": 56, "021900": [15, 19, 33, 52, 56], "022": [22, 36], "022039": [20, 34, 57], "022156": 33, "022264": 34, "022331": [23, 37, 60], "022337": 23, "022356e": 19, "022367": 33, "022433": 56, "022467": 39, "022559": 33, "022597": 37, "022629": [19, 33, 56], "022652": 33, "022658": 33, "022663": 37, "022686": 56, "022730": 43, "022848": [14, 27, 51], "022866": [20, 34, 57], "022999": 33, "023": [23, 38, 59, 66], "023086": 68, "023105": 67, "023235": 33, "023279": 44, "023305": [35, 58], "023366": [24, 61], "023367": 57, "023462": 19, "023511": 56, "023554": [35, 58], "023588": 23, "023636": [20, 34, 57], "023666": 56, "023810": 71, "023839": 35, "023972": 37, "023983": 23, "02398696": 46, "024": [38, 59], "024028": [19, 33, 56], "024122": [19, 33, 56], "024291": 67, "024323": 21, "024351e": [21, 35, 58], "024388": 33, "024390": [24, 40, 61], "02446630e": [23, 37, 39, 60], "024540": [16, 29, 53], "024609": 21, "024687": 33, "024867": 33, "024944": 43, "025": [20, 34, 47, 53, 57], "025017": 23, "025157": 33, "025225": 35, "025332": 21, "025338": 35, "025377": 35, "025381": [23, 37, 39, 60, 69], "025391": [16, 29, 53, 54], "025396": [19, 33, 56], "025460": 43, "02548": 19, "025489": [23, 37, 60], "025689": [19, 33, 56], "025736": 21, "025807": 34, "025871": 33, "025898": 37, "025910": [15, 28, 52], "025998": [16, 29, 53, 54], "026": [36, 38, 68], "0261": [15, 19, 33, 52, 56], "026222": 40, "026282": 21, "026445": 21, "026553": 33, "026569": 21, "026598": 33, "026616": 43, "026620": [19, 33, 56], "026630": 21, "026667": 43, "026777": [19, 33, 56], "02677733855112973": [19, 33, 56], "026793": [21, 23, 35, 37, 39, 58, 60, 69], "02681": 40, "026877": 21, "026878": 21, "026972": 58, "026984": 35, "027": 39, "027070": [35, 58], "027079": 43, "027112": 67, "027172": 33, "027309": 33, "027321": [24, 40, 61], "027357": 33, "027484": [35, 58], "027578": 58, "027752": 33, "027942": 21, "027960": 21, "028": [22, 39], "028023": [20, 34, 57], "028036": 21, "028043": 33, "02807617": 65, "028186": 43, "028337": [19, 33, 56], "028351": [19, 33, 56], "028420": [35, 58], "0285": 19, "028566": 21, "028626": 37, "028672": [24, 40, 61], "028684": 21, "028740": 21, "028772": [35, 58], "028830": 38, "028892": 21, "028912e": 21, "029": 65, "029010": 19, "029038": 21, "029120": 21, "029137": 57, "029146": [20, 34, 57], "029164": 67, "029198": [19, 33, 56], "029207": 21, "029264": 58, "029396": 43, "029409": 58, "029467": 21, "029475": [35, 58], "029635": 21, "029898": 34, "029909": [14, 51], "029947": 33, "029950e": [21, 35, 58], "029965": 21, "02d": 67, "03": [1, 16, 18, 19, 21, 23, 32, 33, 35, 37, 39, 42, 55, 56, 58, 60, 66, 67, 68, 71, 80], "030": [23, 38, 60], "03003": 40, "03017665e": [23, 37, 39, 60], "030200": [16, 29, 53], "030343": [35, 58], "030349": [35, 58], "030408": [15, 28, 52], "03049217": [15, 28, 52], "0305": [15, 28, 52], "030618": 27, "030739733331869412": [18, 32, 55], "030786": [35, 58], "030805": [35, 58], "030897": 21, "031": 54, "031070": 58, "0312": 19, "031212": 21, "031385": [15, 28, 52], "031458": 21, "031483": [35, 58], "031564": [16, 29, 53], "031794": [21, 35, 58], "031809": 21, "031811": 21, "031863": 58, "0319": 65, "031994": 58, "032": [19, 36], "032000": 43, "032140": [35, 58], "032280": 57, "032320": 46, "032324": [19, 33, 56], "032404": [19, 33, 56], "03251": 40, "032566": [17, 30, 54], "03256625": [17, 30, 54], "032656": [15, 28, 52], "032660": 43, "032813": 39, "032838": 19, "032874": [15, 28, 52], "033070": 21, "033149": [22, 36], "033165": [35, 58], "033222": 68, "033267": 67, "033279": [23, 37, 60], "033305": 66, "033322": 58, "033459": [15, 28, 52], "0335": [33, 56], "033574": 21, "033723": 58, "033739": [35, 58], "033764": 21, "033780": 68, "033833": [20, 34, 57], "0339": [16, 29, 53], "033993": 43, "034": 37, "034071": [20, 34, 57], "03411038e": [23, 37, 39, 60], "034132": [35, 58], "0344": [15, 19, 33, 52, 56], "034452": 21, "034894": 60, "034977": [35, 58], "034979e": [21, 35, 58], "035": [36, 38, 66], "035074": 21, "0351": [16, 29, 53], "035105": 33, "0351607": 39, "03516073": [23, 37, 39, 60], "035161": [23, 37, 39, 60], "035223": [35, 58], "035230": 67, "035314": 21, "03546": 40, "035632": 21, "035722": [35, 58], "036": [14, 16, 29, 53, 59, 66], "036136": [24, 40, 61], "0362": [16, 29, 53], "036646": [21, 35, 58], "036749": 57, "036764": [20, 34, 57], "036782": 21, "036837": 39, "036865": 21, "036879": 21, "036886": 59, "036910": 21, "037": 22, "0370": [16, 29, 53], "03710": 40, "0373": [16, 29, 53], "037414": 67, "037779": 21, "037785": [20, 34, 57], "0378": [16, 29, 53, 68], "037854": 21, "038102": [18, 32, 55], "038453": 33, "038609": [35, 58], "038707": [23, 37, 60], "038873": 43, "038948": [35, 58], "039": 66, "0394": 19, "039498": [18, 32, 55], "039739": 43, "039741": 52, "0399": [16, 29, 53], "04": [16, 19, 21, 23, 29, 33, 35, 37, 39, 40, 42, 44, 53, 54, 56, 58, 60, 67, 68, 76, 80], "040": 59, "040000": 43, "040000e": 42, "040129": 68, "040497": [20, 34, 57], "040563": 43, "040634": 46, "040698e": [21, 35, 58], "040954": 68, "040984": 67, "041": [36, 38, 59, 66], "041031": [20, 34, 57], "04108378": [18, 32, 55], "041084": [18, 32, 55], "041129": [15, 28, 52], "041201": [20, 34, 57], "041488": [35, 58], "041704": [23, 39, 60], "041769": [35, 58], "042": [22, 38], "042081": [23, 37, 39, 60], "042382": [24, 61], "042722": 33, "042743": [35, 58], "042957": [16, 29, 53, 54], "043": [33, 56], "043257": 54, "043319": [23, 37, 60], "043509": [19, 33, 56], "043643": 46, "0437": [13, 14, 15, 27, 28, 50, 51, 52, 74], "043890": [15, 28, 52], "044": [15, 19, 33, 52, 56], "044029": [16, 29, 53, 54], "044166": [18, 32, 55], "044199": 35, "044253": [23, 37, 60], "044313": [16, 29, 53], "044409": 58, "044614": 56, "044873": [14, 27, 51], "044948": 39, "045": [13, 19, 22, 42, 50, 66], "045267": 67, "045280": 57, "045304": [15, 28, 52], "045415": 53, "045481": 67, "045600": 19, "046": [38, 66], "04600e": [15, 52], "046020": [15, 28, 52], "046114": 43, "046116": [19, 33, 56], "046193e": [21, 35, 58], "046216": 56, "046638": 54, "0468": 68, "0469": [16, 29, 53], "046917": 34, "046945": 56, "047": 38, "04709519e": [23, 37, 39, 60], "047338": 21, "047397": 40, "0474": [18, 32, 55], "047567": [35, 58], "047577": 16, "047710": 19, "04774884": 62, "047749": 62, "047851": 29, "048": [14, 27, 51, 54], "048301": 19, "048378": [14, 27, 51], "04861878": 62, "048630": 67, "048860": [16, 29, 53], "048889": [21, 35, 58], "048940": 14, "049": [37, 54, 66], "049097": 43, "049117": 35, "049302e": 21, "049378": 21, "049945": 34, "05": [15, 16, 19, 20, 21, 29, 33, 34, 35, 42, 44, 47, 52, 53, 56, 57, 58, 63, 67, 68, 69, 80], "050": [12, 25, 49, 66], "050110e": [35, 58], "050132": [16, 29, 53, 54], "051": 66, "051269": [16, 29, 53, 54], "05137470e": [23, 37, 39, 60], "051392": 66, "051472": [15, 28, 52], "051620": [16, 29, 53], "051824": [35, 58], "051925": [19, 33, 56], "052": [16, 29, 53], "052106": 33, "052244": 33, "052270e": 33, "052349": [16, 29, 53], "052607": [20, 34, 57], "052790": [20, 34, 57], "052819": [20, 34, 57], "05290827e": [23, 37, 39, 60], "053": 39, "053156": 62, "05350962": 72, "05361": 40, "0537": [33, 56], "053763": [14, 27, 51], "053918": [19, 33, 56], "054": [36, 38], "054054": [20, 34, 57], "054112": 19, "054225": 44, "054461": [20, 34, 57], "054616": 34, "054653": [17, 30, 54], "05465323": [17, 30, 54], "054654": 46, "054669": [21, 23, 35, 37, 39, 58, 60, 69], "054784": [17, 30, 54], "05478443": [17, 30, 54], "054884": 19, "055": [16, 22, 29, 51, 53, 54], "055100": [33, 56], "055176": 19, "05529": 40, "055398": 15, "055433": 19, "055857": 46, "055915e": [21, 35, 58], "05598498": [17, 30, 54], "055985": [17, 30, 54], "056": 66, "05603": 33, "056347": 19, "056478": [16, 29, 53, 54], "05656664": 65, "056599": 43, "056703": [20, 34, 57], "057": [16, 29, 53, 66], "057003": [15, 28, 52], "057082": [35, 58], "057254": 68, "057291": 40, "057296": [20, 34, 57], "057331": [35, 58], "057609": 46, "05764": 40, "057646": [15, 28, 52], "057729": [20, 34, 57], "057732e": 68, "057793": [16, 29, 53, 54], "057910": [16, 29, 53, 54], "058": [38, 59], "0580": [14, 18, 27, 32, 51, 55], "058176": 69, "058298": [35, 58], "058311": 57, "058555": 19, "059": [12, 16, 25, 29, 36, 49, 53], "059077": [20, 34, 57], "0591": [16, 29, 53], "059242": [16, 29, 53, 54], "059360": 66, "059588": 56, "059863": [15, 28, 52], "06": [16, 19, 21, 29, 33, 35, 40, 42, 53, 56, 58, 63, 65, 66, 67, 68, 72, 80], "060": 66, "06042": 40, "060425": 19, "060477": [35, 58], "060543": 61, "0608": 19, "061100": [16, 29, 53], "061206": [20, 34, 57], "061241": [15, 28, 52], "061312": [35, 58], "061313": 66, "061348": 19, "061724": 46, "061839": 19, "061937": [15, 28, 52], "062": [12, 15, 19, 25, 33, 49, 52, 56], "062043": 56, "062277": 20, "062449": 68, "06246": 40, "062658e": [21, 35, 58], "062723": [27, 51], "062792": [15, 28, 52], "062793": 65, "063004": 61, "063090": 38, "063110": [16, 29, 53, 54], "063173": [23, 37, 60], "064": [33, 56, 60], "06405": 56, "064050": 56, "064200": [15, 28, 52], "064205": 14, "064307": [24, 40, 61], "064322": 46, "064452": [15, 28, 52], "065": [22, 66], "065018": 16, "065041": 19, "0651": 19, "065100": 19, "065127": 19, "065169": 56, "065199": 57, "065449": [21, 35, 58], "065463": [20, 34, 57], "065495": 40, "066": 38, "06606": 40, "06609": 40, "066136": 19, "066148": 46, "066166": 68, "066251": [27, 51], "066273": 19, "066322": 19, "066484": 19, "066512": 43, "066596": 19, "066605": 56, "066667": [16, 29, 53], "0667579112160865": [18, 32, 55], "066768": [22, 36], "066810": 68, "066944": [19, 33, 56], "066960": 14, "067099": 43, "067112": 46, "067119": 53, "067120": [27, 51], "067262": 19, "067283": 19, "06729": 19, "067474": 19, "06754": 40, "067600": 46, "06767839": 46, "06772": 40, "067786": 19, "067860": 24, "06797961": [21, 35, 58], "067991": [16, 29, 53], "068": [12, 23, 25, 49], "068116": 40, "068214": [18, 32, 55, 56], "068282": 19, "068291": 66, "068428": 43, "068498": 56, "068775": 56, "068800e": 42, "068891": 56, "069": 42, "069119": 24, "069150": [23, 37, 39, 60], "06915047": [23, 37, 39, 60], "069188": 68, "069284": 33, "0694": [15, 19, 33, 52, 56], "069530": [15, 28, 52], "069895": 33, "07": [1, 19, 21, 24, 33, 35, 40, 44, 56, 58, 61, 67, 68], "070047": 29, "070081": 56, "070195": 56, "07079": 40, "070850": [20, 34, 57], "070898": 56, "070907": [14, 27, 51], "070929": [20, 34, 57], "071": [37, 39, 66], "071303": 19, "071330": 67, "071541": [16, 29, 53, 54], "071654": [24, 61], "07174469097": 35, "07174469222": 58, "07174469245": 21, "071745": [23, 39, 60], "071761": 33, "071975": [24, 40, 61], "072": [16, 36, 59], "072012": 19, "072043": 56, "0721": 19, "072243": [23, 37, 60], "0723": [16, 29, 53], "072333": 33, "072396": 56, "07245741": [21, 35, 58], "072567": 46, "072595": 56, "072707": [14, 51], "072858": 19, "07287": 40, "072966": 16, "073016": 69, "073036": 19, "073058": 53, "073233": [18, 32, 55], "073366": 53, "073541": 19, "074": [16, 29, 53, 59], "0741": [15, 28, 52], "074141": [15, 28, 52], "07418": 56, "074296": 19, "074327": 59, "074418": 66, "074453": 19, "074475": 53, "074556": 16, "074719": [17, 30, 54], "07471942": [17, 30, 54], "074773": 27, "074835": 16, "074853": 69, "075000": 64, "075024": 19, "075122": 19, "075170": 67, "075343": 46, "075453": 68, "075467": 68, "075668": 43, "075747": 56, "076018": 43, "076076": 33, "076104": [21, 35, 58], "0762": [16, 29, 53], "076276": 19, "076284": 62, "076358": 29, "07639": 56, "076533": [21, 35, 58], "076687": 19, "076798": [15, 28, 52], "076938": 29, "077": [38, 59, 66], "077129": 19, "077204": [23, 37, 60], "077214": 33, "077355": 19, "077505": 19, "077749": 65, "077761": 68, "077803": 56, "077874": 19, "077887": [19, 39], "078": [18, 32, 55, 59], "0780": [13, 14, 27, 50, 51, 74], "078052": [20, 34, 57], "07808506982896266": [35, 58], "0780850698289627": 21, "078243": 56, "078387": 68, "07839": 40, "078552": 56, "078740": 56, "07877994e": 72, "078848": 19, "078880": 54, "079": [33, 38, 56], "07911": 40, "079181": 29, "07927": 33, "079282": 56, "079377": 68, "079382": 19, "0794": [15, 19, 33, 52, 56], "079471e": [21, 35, 58], "079623": 19, "079848": 19, "079852e": [21, 35, 58], "07987": 40, "08": [16, 19, 21, 24, 29, 33, 35, 40, 53, 56, 58, 61, 63, 66, 67, 68], "080": [19, 66], "080006": 19, "08002986030": [17, 30, 54], "080084": 56, "080101": 33, "080165": 56, "080319": [17, 30, 54], "08031924": [17, 30, 54], "0804": 19, "08045": 40, "080526": 19, "080571": 40, "080694": [23, 37, 60], "080734": 51, "0808": [33, 56], "080847": 14, "080999": 20, "081": [12, 25, 49], "081001": 19, "08116": 56, "081167": 68, "081209": 19, "081292": 67, "08151507e": [23, 37, 39, 60], "081837": 68, "082": 53, "082100": [33, 56], "082251": [18, 32, 55], "082265e": 68, "08233": 33, "082386": 19, "082749": [15, 28, 52], "082835": [23, 37, 60], "082949": [15, 28, 52], "083": [15, 19, 33, 52, 56, 59], "083001": 19, "083123": [16, 29, 53, 54], "083338": [14, 27, 51], "08338644": 65, "083545": [20, 34, 57], "083615": 56, "083813": [16, 29, 53, 54], "083836": 14, "084101": 20, "084173": 20, "084288": 56, "084490": 69, "0846": 40, "084683": 43, "084746": [16, 29, 53, 54], "084870": 27, "084909": 20, "084951": 33, "085150": 67, "08523": 40, "085244": 19, "085415": [23, 37, 39, 60, 69], "085477": [20, 34, 57], "085508": [21, 35, 58], "085546": [21, 35, 58], "085550": [21, 35, 58], "085551": [21, 35, 58], "085693": 56, "085698": [21, 35, 58], "085991": 20, "086078": 43, "08613": 56, "086163": 19, "086165": 19, "086395": 19, "08642578": 65, "086461": [24, 40, 61], "086517": 42, "086529": 19, "086595": 33, "086606": 46, "086656": 46, "086825": 46, "086932": 51, "087": 54, "087076": 33, "087128": 56, "08740234": 65, "087427": 19, "087668": [33, 56], "087678": 19, "087685": 19, "087703": 46, "087809": 33, "08791477": 65, "087994": 19, "087996e": 56, "088": 66, "0880": [16, 29, 53], "088045": 19, "088129": 46, "088151": 46, "088192": 33, "088373": 14, "088543": 56, "088676": 19, "088948": [15, 28, 52], "089021": 33, "089136": 27, "089294": 56, "089313": 56, "089317": 33, "089354": [14, 27], "089485": [27, 51], "089692": 46, "089892": 27, "09": [14, 19, 21, 27, 33, 35, 42, 51, 54, 56, 58, 67, 68], "090000": [20, 34, 57], "090073": 19, "09009799": [21, 35, 58], "090231": [23, 37, 60], "090376e": [21, 35, 58], "090453": [20, 34, 57], "090473": 56, "090579": 43, "09058097218": [12, 25, 49], "090785": [21, 35, 58], "090951": 28, "090971": 20, "090978": 42, "091": 66, "091092": 19, "091124": 19, "091243": 56, "091625": [24, 40, 61], "091632": 43, "091819": 51, "091985": 33, "092": 59, "092002": 19, "092072": 56, "092123": 56, "0922": [15, 19, 33, 52, 56], "092204": [14, 51], "092209": 19, "09221": 40, "092331": 14, "092369": 19, "09245358900622544": [19, 33, 56], "092454": [19, 33, 56], "092499": 40, "092604": [14, 27, 51], "092660": 68, "092669": 27, "092670": 56, "092729": 56, "092930": [17, 30, 54], "093": 38, "093051": 56, "0931": [33, 56], "093228": [24, 61], "093350": 69, "093390": [15, 28, 52], "09345386": [17, 30, 54], "093454": [17, 30, 54], "093501": 40, "093624": 51, "093787": 56, "093893": 56, "094": [12, 25, 49, 65], "094088": 19, "0942": 40, "094290": 68, "09430199": [17, 30, 54], "094302": [17, 30, 54], "094472": 19, "094581": [17, 30, 54], "094586": [20, 34, 57], "094637": 19, "094725": 56, "094863": 56, "095018": 56, "09503409246217484": [21, 35, 58], "095177": 56, "095345": 56, "095445": 33, "095499": 20, "095725": 19, "09573445": [19, 33, 56], "095812": 33, "096": 22, "096094": 33, "09619141": 65, "096426": 27, "096462": [21, 35, 58], "096692": [16, 29, 53], "096722": 56, "096858": 56, "096927": [20, 34, 57], "096960": [21, 35, 58], "096990": 51, "096997": 66, "097": [22, 66], "09706504": 66, "097088": 68, "097172": 19, "097184": 56, "097293": [16, 29, 53, 54], "097403": 33, "097446": 33, "097516": [16, 29, 53], "097707": 56, "097763": 56, "097880": 33, "097938": 27, "098": [18, 32, 55, 66], "098019": 14, "098133": 33, "098152": 56, "098307": [21, 35, 58], "098322": 33, "098324": 40, "098326": [15, 28, 52, 66], "098559": 56, "098629e": 56, "098663": 56, "098787": 43, "09891476780532049": [18, 32], "0989147678053208": 55, "098915": [18, 32, 55], "098950": 56, "098966": [16, 29, 53], "099": [22, 36, 59], "099141": 33, "099199": 19, "099230": [23, 37, 60], "099240": [16, 29, 53, 54], "099454": 56, "099558": [16, 29, 53, 54], "099685": [21, 35, 58], "099723": [16, 29, 53], "099729": 56, "099749": 67, "099763": 33, "099802": 56, "099869": 56, "0x1227a36e0": 8, "0x155a90620": 19, "0x155ae2090": 19, "0x155f0c5c0": 19, "0x1577111f0": 56, "0x16888d4c0": 56, "0x168921100": 56, "0x30888e660": 33, "0x308dc0470": 33, "0x308df5c40": 33, "1": [1, 7, 8, 9, 10, 23, 31, 37, 42, 43, 44, 45, 46, 47, 48, 60, 65, 67, 70, 71, 72, 80], "10": [1, 4, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 80], "100": [12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 28, 29, 30, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 46, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 77], "1000": [12, 14, 15, 18, 19, 20, 21, 23, 24, 27, 28, 31, 32, 33, 34, 35, 39, 40, 46, 47, 48, 51, 52, 54, 55, 56, 57, 58, 60, 61, 66, 67, 68, 69, 71, 72, 77, 78], "10000": [12, 13, 18, 19, 21, 31, 32, 33, 35, 42, 45, 46, 50, 54, 55, 56, 58, 67], "100000": [12, 15, 17, 18, 19, 21, 28, 30, 32, 33, 35, 52, 54, 55, 56, 58, 67], "1000000": [19, 33, 44, 56], "100103": 67, "100105": 56, "100139": [17, 30, 54], "100146": 67, "100248": [15, 28, 52], "100253": 33, "100261": 33, "100275": [24, 61], "1004": [15, 28, 52], "1005": 67, "1006": 67, "1007": 67, "10070": 40, "1008": 67, "10083": 42, "100835": 33, "100882": [20, 34, 57], "100892": 33, "1009": 67, "10092665203438746": [35, 58], "10092665203438747": 21, "101": [1, 9, 46, 62, 66, 68, 80], "1010": 67, "1012": 67, "101259": [21, 35, 58], "101387": 27, "1014": [19, 33, 43, 56, 66], "1015": [43, 66, 67], "1016": [43, 66, 67], "101638": 19, "101688": [19, 33, 56], "1017": [43, 66, 67], "101772": 14, "101796": [21, 35, 58], "1018": [43, 66, 67], "101810": 51, "101832": 56, "101894": [20, 34, 57], "1019": [43, 66, 67], "102": [20, 21, 34, 35, 44, 57, 58, 79], "1020": [24, 33, 40, 42, 43, 56, 61, 66, 67], "102044": [24, 40, 61], "1021": [43, 66, 67], "102135": [20, 34, 57], "1022": [43, 66, 67], "1023": [43, 66, 67], "1024": [43, 54, 66, 67], "102435": [15, 21, 28, 35, 52, 58], "102474": [17, 30, 54], "10247431": [17, 30, 54], "1025": 67, "10254": 67, "1026": [18, 32, 55, 67], "1027": 67, "10273": [21, 35, 58], "10274": [20, 34, 57], "1028": 67, "1029": 67, "103": 68, "103023": 56, "1031": 67, "103219": [24, 61], "103222": 66, "1034": [24, 40, 61], "103428": 35, "103439": [17, 30, 54], "103474": 33, "10360": 40, "103619": 44, "10361902": 44, "103797": 33, "1039": 67, "104": [15, 16, 28, 29, 52, 53, 59, 62, 66], "1040": [16, 19, 29, 53], "104070": [21, 35, 58], "1041": [21, 23, 35, 37, 58, 60, 67, 71], "10416666666666667": 64, "1042": [19, 33, 56], "1043": [17, 30], "104353": 33, "104393": 33, "1044": [12, 25, 49], "104499": 33, "104596": 56, "104643": [21, 35, 58], "105": [19, 22, 42, 59], "1050": [13, 42, 50], "105080": [24, 61], "105089": [17, 30, 54], "10513": 67, "1052": 44, "1053": [44, 71], "105314": 67, "105340": 33, "1054": 44, "1055": 44, "10556679": 62, "1056": 44, "105656": [23, 39, 60], "1057": 44, "1058": 44, "10584063": 66, "1059": 44, "105995": 33, "106": 44, "106000": [16, 29, 53], "106023": [21, 35, 58], "106112": 67, "106180": 67, "106319": 67, "106322": 67, "106424": 67, "10644531": 65, "106452": [15, 28, 52], "10645223": [15, 28, 52], "106485": 33, "10653": 67, "1066": 40, "106705": 67, "106764": 56, "1068": 71, "106816": 67, "106832": 33, "1069": 71, "10693359": 65, "106996": 56, "107": [22, 59], "1070": [24, 40, 61], "107050": 67, "107292": 67, "107360": 33, "107374": 33, "107502": 67, "1076": [42, 54], "107623": 33, "107718": 56, "10781": [22, 23, 36, 37, 38, 39, 59, 60], "107867": 33, "107917": 67, "10793260e": 66, "107947": [21, 35, 58], "107985": [21, 35, 58], "107991": [20, 34, 57], "108": [12, 25, 36, 49], "1080": [12, 25, 49], "10800": [12, 25, 49], "1085": [18, 32, 55], "10868": 67, "108681": [15, 28, 52], "108780": 33, "1089": [21, 35, 58], "109000": 19, "10910": 67, "109242": 35, "10931": 54, "1095": 40, "109526": [20, 34, 57], "109580": 43, "109639": 19, "1099": [21, 35, 58], "10_000": [31, 68], "10th": [19, 20, 22, 23, 33, 34, 36, 37, 38, 39, 40, 56, 57, 59, 60, 78], "10x": [20, 34, 57], "11": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 39, 40, 42, 43, 44, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 71, 73, 75, 80], "110": [18, 32, 55, 66], "110000": 19, "1101": [17, 30, 44], "1102": 44, "1103": 44, "110316": 67, "110319": 67, "1104": [15, 28, 44, 52], "11057": 67, "1106": [24, 40, 44, 61], "110645": [21, 35, 58], "1107": 44, "1108": 44, "1109": 44, "110911": 33, "110915e": [21, 35, 58], "111": [16, 19, 20, 21, 29, 33, 34, 35, 47, 53, 56, 57, 58, 68, 78], "1110": 44, "1111": 44, "111111": 16, "111182": 33, "1112": 44, "11121453": 62, "111215": 62, "111220": 67, "1114": 44, "11140": 40, "111438": [24, 61], "1115": 44, "111543": [21, 35, 58], "111546": 33, "1116": 44, "112": [15, 16, 19, 28, 36, 52], "112164": 33, "1122": [21, 23, 35, 37, 58, 60, 71], "1123": [33, 56, 71], "112356": 33, "112409": 33, "112441": 56, "112490": 56, "112527": 60, "112848": [21, 35, 58], "112915": 33, "1131": 42, "113175": 33, "11331": 71, "11336331e": [23, 37, 39, 60], "113381": 39, "113600": [16, 29, 53, 54, 76], "113782": 33, "1138": [24, 40, 61], "113815": 39, "113831": 33, "113837": [21, 35, 58], "1139": [21, 23, 35, 37, 58, 60, 69], "113949e": 68, "113993": 33, "114": [16, 29, 36, 53], "1140": [12, 21, 23, 25, 35, 37, 49, 58, 60, 69], "114000": [16, 24, 29, 40, 53, 61], "114079": 56, "114214": 56, "114507": 66, "114521": 39, "11457": [21, 23, 35, 37, 58, 60, 69], "114757": 42, "114766": [23, 37, 60], "1148": 40, "114836": [24, 61], "114966": [23, 37, 60], "115": 54, "1150": [12, 25, 49], "115083": [16, 29, 53], "115089": 67, "11509": [21, 35, 58], "115090": 67, "115091": 67, "115092": 67, "115183": 56, "11520": 40, "115276": 68, "115401": [21, 35, 58], "115406": [15, 28, 52], "115428": 67, "115956": [18, 32, 55], "116": [16, 29, 53], "116145": [24, 61], "116167": [18, 32, 55], "116443": [24, 61], "116497": [21, 35, 58], "11664": 71, "11670": 40, "11693": [21, 35, 58], "116963": 33, "117": [16, 18, 24, 29, 32, 44, 53, 54, 55, 61, 76], "117058": [18, 32, 55], "117379": 56, "117380": [16, 29, 53], "117412": [21, 35, 58], "117528": [24, 40, 61], "11758": 67, "117612": 66, "117647": 33, "117703": 19, "117712": 67, "117816": [16, 29, 53], "117899e": [21, 35, 58], "1179": [16, 29, 53], "118": [16, 18, 21, 23, 24, 29, 32, 35, 37, 39, 40, 44, 53, 54, 55, 58, 60, 61, 69], "1180": [13, 42, 50], "118182": [16, 29, 53, 54], "118347": [21, 35, 58], "118450": [20, 34, 57], "118518": 33, "118563": [24, 61], "11886432": [19, 33, 56], "118874": [21, 35, 58], "118934": [20, 34, 57], "11898": [20, 34, 57], "119": [16, 18, 24, 29, 32, 36, 53, 54, 55, 61, 67, 76], "1190": [16, 29, 42, 53], "119049": 67, "11909976": 62, "119100": 62, "119121": 43, "11914062": 65, "119189": 43, "119368": 38, "119400": [16, 29, 53], "1195": [17, 30], "119570": [24, 61], "119911": 67, "11th": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "12": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 39, 40, 43, 44, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 79, 80], "120": [15, 16, 18, 21, 28, 29, 32, 35, 44, 46, 48, 52, 53, 55, 58, 59, 66, 67, 72], "1204": [15, 28, 52], "120769e": [21, 35, 58], "121": [12, 16, 18, 19, 22, 24, 25, 29, 32, 33, 36, 38, 42, 44, 49, 53, 54, 55, 56, 59, 61, 67], "1210": [33, 56], "121056e": [21, 35, 58], "121084e": [21, 35, 58], "121351": 60, "12138": [16, 29, 53], "1214": [21, 35, 58], "121438": 68, "12150684": [18, 32, 55], "121531": [20, 34, 57], "121599": [23, 37, 60], "121628": [15, 28, 52], "121655": 33, "1217": 68, "12178": [24, 40, 61], "121846": [23, 37, 60], "121985": [21, 35, 58], "122": [12, 13, 14, 16, 24, 25, 27, 29, 40, 42, 44, 49, 50, 51, 53, 54, 61, 66, 74, 79], "1220": [12, 16, 25, 29, 33, 49, 53, 56], "122087": 19, "1222": [19, 33, 56], "122210": 39, "122307": [16, 29, 53, 54], "122331": [21, 35, 58], "122403": 33, "122668": 56, "123": [4, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78], "123049e": 42, "1231": 40, "123322": 35, "123367": [21, 35, 58], "1235387316046016": [19, 33, 56], "123539": [19, 33, 56], "123785": 33, "124": [16, 29, 44, 53, 65], "1240": [12, 25, 49], "1241": [21, 24, 35, 58, 61], "1243": [16, 29, 53], "12436984": [17, 30, 54], "124370": [17, 30, 54], "1247": [19, 33, 56], "12498": [23, 37, 60], "124982": [24, 61], "125": [8, 21, 35, 44, 58], "1250": [16, 29, 53, 54, 76], "125000": 42, "12508": [21, 23, 35, 37, 39, 58, 60, 69], "125440e": [21, 35, 58], "125476": [15, 28, 52], "125523": 67, "1256": 72, "125617": 67, "125644": [21, 35, 58], "1258": 68, "126": [24, 40, 44, 61], "126238": [24, 40, 61], "126398": [16, 29, 53, 54], "126488": 62, "12649": [16, 29, 53], "126500": [16, 29, 53], "126563": [19, 33, 56], "126808": [16, 29, 53, 54], "127": [14, 16, 18, 27, 29, 32, 33, 40, 44, 51, 53, 55, 56, 70], "127086": [16, 29, 53], "127087": 68, "1271": [22, 36, 38, 59], "127107": [23, 37, 60], "127226": 54, "127242": [21, 35, 58], "1273": [23, 37, 60], "127326": [21, 35, 58], "1274": [24, 40, 61], "127418": [21, 35, 58], "127439": [21, 35, 58], "127441": [21, 35, 58], "127614": [21, 35, 58], "12761659": [21, 35, 58], "12768": 42, "127878": [15, 28, 52], "1279": [21, 35, 58], "1280": [16, 19, 21, 29, 33, 35, 53, 56, 58], "1281": [21, 35, 58], "128188": [16, 29, 53, 54], "128384": [21, 35, 58], "128432": 39, "128528": [21, 35, 58], "128692": [23, 37], "1287": 42, "128820": 67, "128828": 67, "128829": 67, "128830": 67, "12890625": 65, "128984": [21, 35, 58], "129": [15, 18, 24, 28, 32, 38, 40, 52, 55, 61, 68, 79], "1290": [16, 29, 53, 54], "12906": [12, 25, 49], "129257": [21, 35, 58], "12927": [12, 25, 49], "129300": [16, 29, 53, 54, 76], "129459": [24, 40, 61], "12960": 40, "129600": [21, 35, 58], "129746": 33, "129900": [20, 34, 57], "129904": [21, 35, 58], "129985": [16, 29, 53], "12th": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "13": [1, 8, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 27, 28, 29, 30, 33, 34, 35, 36, 38, 40, 42, 43, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 63, 64, 65, 67, 68, 71, 73, 76], "130": [12, 13, 14, 15, 16, 21, 23, 24, 25, 27, 28, 29, 33, 35, 37, 49, 50, 51, 52, 53, 54, 56, 58, 60, 61, 69, 74, 76], "1300": [21, 23, 35, 37, 39, 58, 60, 69], "1302": [20, 57], "130395": 67, "1304": [15, 28, 52, 68, 69], "130432": 67, "1306": 70, "130690e": [21, 35, 58], "1307": [21, 35, 58], "13071": 33, "130710": 33, "130855": [23, 37], "131": [16, 29, 44, 53, 59, 67, 68], "131000": [21, 35, 58], "13107": 67, "131275": [20, 34, 57], "1313": [21, 35, 58], "1314": [21, 23, 35, 37, 58, 60, 69], "131437e": 21, "131607": [21, 23, 35, 37, 58, 60, 69], "131693": 46, "131773": 68, "13179824": 46, "1319796954314723": [22, 36, 38, 59], "132": [16, 68], "1320": [24, 40, 61], "1321": [12, 25, 49], "132158": [21, 35, 58], "1322": 40, "132292": [24, 40, 61], "13229595e": [23, 37, 39, 60], "13255": 67, "132875": [16, 29, 53, 54], "132886": 67, "133": [33, 56, 68], "133000": [21, 35, 58], "133009e": 19, "133210": 56, "133270": [21, 35, 58], "133302": 33, "133337": [21, 35, 58], "133562": 68, "1337": 19, "13392236": 66, "134": [13, 14, 18, 27, 32, 50, 51, 54, 55, 74], "1340": [13, 42, 50], "134061": [24, 40, 61], "13407": [23, 37, 60], "13418": 16, "134287": [20, 34, 57], "13452": 46, "1346": [16, 21, 23, 24, 29, 35, 37, 40, 53, 58, 60, 61, 68, 71], "134615": [18, 32, 55], "134658": [16, 29, 53], "1347": 71, "13476562": 65, "134894": 67, "135": [67, 68], "1350": 42, "135134": 67, "135197": 67, "13521135": [23, 37, 60], "135299": [24, 40, 61], "135305": [16, 29, 53, 54], "135384": [21, 35, 58], "13540": 42, "135422": [21, 35, 58], "1357": [12, 25, 42, 49], "135853": 40, "136": [16, 29, 39, 53, 54], "1360": [13, 42, 50], "136301": 33, "1364": 44, "1365": 44, "1366": 44, "13665": [16, 29, 53, 54, 76], "1367": 44, "136714": [20, 34, 57], "1368": 44, "1369": 44, "1370": [12, 15, 19, 25, 33, 44, 49, 52, 56, 68], "13704": [21, 23, 35, 37, 39, 58, 60, 69], "1371": 44, "1372": [44, 69], "1373": 44, "1374": 44, "137410": 62, "1375": 44, "137500": [16, 29, 53, 54, 76], "137553": 33, "1376": 44, "1377": 44, "1378": [21, 35, 44, 58], "1379": 44, "138": 71, "1380": [12, 25, 44, 49], "1381": 44, "138103": 66, "1382": 44, "1383": [19, 33, 44, 56], "1384": 44, "1385": 44, "138503": [24, 40, 61], "138528": [18, 32, 55], "138564": 42, "1386": 44, "1387": 44, "1388": 44, "138836": 46, "138876": 68, "1389": [16, 21, 23, 29, 35, 37, 44, 53, 58, 60], "139": [16, 17, 29, 30, 53, 71], "1390": [12, 25, 49], "139297": [20, 34, 57], "139317": [20, 57], "139322": [20, 34, 57], "139349": [20, 34, 57], "13941": [20, 34, 57], "139554": [20, 57], "1396": [33, 56], "1397": [19, 33, 56], "14": [1, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 25, 27, 28, 29, 30, 33, 34, 35, 37, 43, 44, 49, 50, 51, 52, 53, 54, 56, 57, 58, 60, 63, 64, 65, 66, 67, 68, 73], "140": [16, 29, 53], "140185": [24, 61], "140371": 43, "1404": [15, 28, 52, 68], "1405": [24, 40, 61], "140561": 35, "1406": [16, 21, 23, 29, 35, 37, 53, 58, 60], "140641": 67, "1407": 40, "140828": 42, "140953": 67, "141": [16, 18, 29, 32, 53, 55], "1410": 42, "141232": 67, "14159265358979323": 8, "14160": [20, 34, 57], "141636": 33, "141851": 67, "142": [39, 59], "142051e": 42, "142193": 67, "142199": 67, "1423": [20, 57], "142398": 67, "1424": 40, "142467": [14, 27, 51], "1427": [42, 69], "14280": 40, "142806": 67, "142857": 54, "14289": [16, 29, 53, 54, 76], "143": [20, 33, 34, 56, 57], "143693": 67, "143803": [24, 61], "1438387200": 67, "1438398000": 67, "1438408800": 67, "1438419600": 67, "1438430400": 67, "1438441200": 67, "1438452000": 67, "1438462800": 67, "1438473600": 67, "1438484400": 67, "143975": 67, "144": [12, 19, 25, 33, 40, 49, 56], "144000": [21, 23, 35, 37, 58, 60, 69], "1441": 71, "144199": 67, "144221": 33, "144686": [23, 37, 60], "14471": [16, 29, 53, 54, 76], "144729": 67, "144730": 67, "144731": 67, "144732": 67, "144733": 67, "144750": [15, 28, 52], "14485": [21, 35, 58], "145": [23, 40, 43, 67], "145186": 43, "1452": [24, 40, 61], "145425": [21, 35, 58], "145454": 67, "145455": 67, "145456": 67, "145457": 67, "145458": 67, "145459": 67, "145460": 67, "1457": [16, 29, 53, 54, 68, 76], "14579": [24, 61], "1458": [16, 29, 53, 54, 76], "145833": 64, "145915": [22, 36], "146": [12, 25, 43, 49, 59, 69], "1460": [21, 35, 58, 68], "14648438": 65, "1465": [16, 29, 53, 54, 76], "146656": 67, "1467": [24, 40, 61], "146767": [20, 23, 34, 37, 57, 60], "146809": [20, 34, 57], "146830": [20, 34, 57], "14690": 54, "147": [23, 37, 39, 43, 60, 69], "147166": [22, 23, 36, 37, 38, 39, 59, 60], "14716638": [23, 37, 39, 60], "1472": 44, "147226": 43, "147487": 33, "147641": [21, 35, 58], "147737": 66, "147893": [16, 29, 53], "147898": [20, 34, 57], "147979": 33, "148": [15, 19, 23, 33, 37, 43, 44, 52, 56, 60, 72], "1480": 19, "14813": 67, "148141": 59, "148343": [21, 35, 58], "148349": 68, "14841": [20, 34, 57], "149": [43, 68], "1490": 42, "149122": 70, "14970": [16, 29, 53], "149788": [23, 37, 60], "149822": [16, 29, 53, 54], "14999": [16, 29, 53], "14th": [12, 13, 25], "15": [1, 8, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 71, 73, 74, 78, 80], "150": [15, 19, 21, 33, 35, 43, 48, 52, 56, 58, 66, 69], "1500": [19, 44], "150000": [20, 34, 57, 64], "150115": [19, 33, 56], "1502": 40, "15026771": [21, 35, 58], "150395": [15, 28, 52], "1504": [15, 28, 52], "1505": [16, 29, 53], "1509": 42, "150mb": [20, 34, 47, 57], "150p": [12, 25, 49], "151357": [24, 61], "1514": 70, "152": [44, 67], "1520": [19, 33, 56], "1523300141": 42, "1523300157": 42, "152401": [20, 34, 57], "1524625640014508": 38, "152691": 43, "15278": 16, "152859": [20, 34, 57], "152998": 33, "153": 44, "1530": [12, 25, 42, 49], "1531": [17, 30], "1534": [16, 29, 53], "15377": [16, 24, 29, 53, 61], "154": 44, "1540": [12, 25, 49], "154076": [20, 23, 34, 37, 57, 60], "154105": [24, 40, 61], "15429": 67, "154386": [16, 29, 53, 54], "1545": [24, 61], "154733": 33, "154795": [21, 23, 35, 37, 39, 58, 60, 69], "154842": 68, "154883": 43, "155": [12, 19, 25, 33, 44, 49, 56], "15500": [21, 35, 58], "155178e": [21, 35, 58], "1553": 40, "15559528e": [23, 37, 39, 60], "155624": [21, 35, 58], "155900": 42, "156": [16, 19, 20, 29, 33, 34, 44, 53, 56, 57], "1560": 42, "1562": [19, 33, 56], "15620": 40, "156311e": [21, 35, 58], "1564": [19, 33, 56], "15661": 67, "157": [12, 19, 25, 33, 44, 49, 56, 66], "157008": [21, 35, 58], "157157": 71, "157234": [24, 40, 61], "15725": [16, 24, 29, 53, 61], "157572": 43, "15775": 67, "1578": [23, 37, 60], "15795": [20, 23, 34, 37, 57, 60], "158": [19, 33, 56], "1580": [12, 25, 49], "1582": [23, 37, 39, 60], "158867": 67, "158982": [21, 35, 58], "159": [19, 33, 38, 56], "1590": [15, 19, 33, 52, 56], "15915": 67, "159751": 43, "15992": [23, 37, 60], "15pm": 1, "16": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 38, 40, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 61, 64, 65, 67, 68, 70, 71, 73, 74], "160": [14, 15, 18, 19, 21, 27, 32, 33, 35, 46, 48, 51, 52, 55, 56, 58, 60], "1600": 42, "160000": [21, 23, 35, 37, 39, 58, 60, 69], "160258": [14, 27, 51], "160282": [24, 40, 61], "1604": [15, 28, 52], "160506": [20, 34, 57], "160634": 66, "16063983": [17, 30, 54], "160640": [17, 30, 54], "160727": [23, 37, 39, 60], "160729": 67, "161": [16, 29, 44, 53], "1610243052583633": [18, 32], "1610243052583638": 55, "16111330565237114": [18, 32], "16111330565237164": 55, "1613": [16, 29, 53], "161300e": 42, "161429": 43, "16153": 67, "16157": 67, "16160": 67, "161606": [16, 29, 53, 54], "161782": [20, 34, 57], "1619": [19, 33, 56], "161931": [21, 23, 35, 37, 58, 60, 69], "162": [12, 25, 49], "162000": [21, 35, 58], "162007": 71, "162214": 69, "162330": [20, 34, 57], "162628": 33, "162667": [20, 23, 34, 37, 57, 60], "16269": 16, "1627": [24, 40, 61], "162904": 68, "163": 42, "1631": [19, 33, 56], "163195": [16, 29, 53, 54], "163397": [16, 29, 53, 54], "1634": [16, 19, 29, 33, 53, 54, 56, 76], "16358": 67, "164": [24, 40, 61, 66], "1641": 40, "1645": [18, 32, 55], "16460": [24, 40, 61], "164679": [20, 34, 57], "164728": 19, "165": [18, 21, 32, 35, 55, 58], "1650": [15, 19, 33, 52, 56], "16507": [18, 24, 32, 40, 55, 61], "16508": [18, 24, 32, 40, 55, 61], "16509": [18, 24, 32, 40, 55, 61], "16510": [18, 24, 32, 40, 55, 61], "16511": [18, 24, 32, 40, 55, 61], "16512": [18, 24, 32, 40, 55, 61], "165198e": [35, 58], "1652": [14, 18, 27, 32, 51, 55], "16533": 67, "165485": [23, 37, 60], "165617": 67, "165811": [19, 33, 56], "166": [27, 38, 40], "16630": [24, 40, 61], "166631": [16, 29, 53, 54], "16686": 16, "167": [14, 27, 44, 51], "167214": [15, 28, 52], "167241": 71, "167540": 20, "167600": [24, 61], "167620": 66, "168": [21, 35, 44, 58], "1680": [13, 42, 50], "168151": 66, "168196": [16, 29, 53, 54], "168244": [23, 37, 60], "1687": [33, 56], "1688": 40, "169": [14, 18, 24, 27, 32, 40, 44, 51, 55, 61], "1690": [12, 13, 25, 42, 49, 50], "169269e": 68, "169421": 56, "169693": [15, 28, 52], "169748": [18, 32, 55], "16991815": 8, "1699181533555938": 8, "17": [1, 4, 8, 13, 15, 16, 17, 18, 19, 20, 21, 24, 28, 29, 30, 32, 33, 34, 35, 40, 42, 44, 47, 50, 52, 53, 54, 55, 56, 57, 58, 61, 65, 67, 68, 73, 76], "170": [16, 29, 53, 63], "1700": 19, "170100": [16, 29, 53, 54, 76], "170277": [22, 23, 36, 37, 38, 39, 59, 60], "1704": [15, 28, 52], "17054987": 66, "170670": [21, 35, 58], "17080": 40, "170931": 66, "171": [12, 25, 49, 66], "17144": 67, "171468": [21, 23, 35, 37, 58, 60, 69], "1715": [19, 33, 56], "171657": [14, 27, 51], "171899": 68, "172": 40, "1720": [16, 29, 53], "17205": 67, "1724668": 65, "172592": 40, "172792": [20, 34, 57], "17290": 42, "173": [15, 19, 33, 52, 56], "173025": [19, 33, 56], "17347071": 46, "173483": 46, "17393037": 8, "1739787032867638": [19, 33, 56], "173979": [19, 33, 56], "174": [12, 15, 19, 25, 33, 49, 52, 56], "174590": [20, 34, 57], "17476": 16, "174766": [24, 61], "1750": [16, 29, 53, 70], "175000": [21, 23, 35, 37, 58, 60, 69], "17518": 67, "175459": 42, "176": [16, 29, 53], "176026": 43, "1766": [21, 35, 58], "1767": 40, "176924": 68, "177": [24, 40, 61], "17730": [16, 24, 29, 53, 61], "177709": 68, "178": [12, 21, 25, 35, 49, 58], "17847": 16, "178494": [21, 35, 58], "1788": 42, "17896": 67, "179": [22, 36, 38, 59, 68], "179080": [20, 34, 57], "179123": [15, 28, 52], "179152": 44, "179300": [16, 29, 53], "179631": 42, "179730": [19, 33, 56], "17973005068132514": [19, 33, 56], "179802": [21, 35, 58], "18": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35, 40, 44, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 61, 62, 64, 67, 68, 69, 73, 76], "180": [19, 21, 33, 35, 48, 56, 58, 66], "1800": [12, 13, 15, 19, 25, 33, 42, 49, 50, 52, 56], "18000": 67, "180000": [13, 42, 50], "180279e": [21, 35, 58], "180388": [15, 28, 52], "1804": [15, 28, 52], "18066406": 65, "180900": [24, 61], "180926": 43, "18096": 67, "181": [22, 68], "18113": 67, "18116": 67, "1813": [19, 33, 56], "182": [67, 68], "18201414": [23, 37, 39, 60], "182382": 43, "18245": 67, "182639": [21, 35, 58], "182648": [21, 35, 58], "1830": 42, "18311": 67, "18313": 67, "18317085": 8, "183179": 68, "183423": [15, 28, 52], "183471e": [21, 35, 58], "18365": 54, "18391": [16, 29, 53, 54], "184": [67, 68], "1840": [12, 25, 42, 49], "184282": 46, "184405": [23, 37, 60], "1847": [17, 30, 54], "185": [14, 27, 37, 68], "185000": 14, "185155": [23, 37, 60], "185175": 68, "18533": 67, "1854": [19, 33, 56], "185707": [15, 19, 33, 52, 56], "18571": [16, 29, 53, 54], "18572": [16, 29, 53, 54], "18573": [16, 29, 53, 54], "18574": [16, 29, 53, 54], "18575": [16, 29, 53, 54], "18576": [16, 29, 53, 54], "1858": [24, 40, 61], "185868": [24, 61], "185975": [23, 37, 39, 60], "18597545": [23, 37, 39, 60], "186": 44, "186024": [12, 25, 49], "186814": [20, 34, 57], "186899": [20, 34, 57], "187": [14, 18, 27, 32, 51, 55, 59], "1870": [33, 56], "187000": [16, 29, 53], "1872": [21, 35, 58], "1875": [18, 32, 55, 65], "187503": 67, "187663": [15, 28, 52], "187700": [16, 29, 53], "188": [12, 14, 18, 25, 27, 32, 49, 51, 55], "1880": [19, 33, 56], "1886": [18, 32, 55], "1887": [20, 23, 34, 37, 57, 60], "189": [38, 44], "18955": 67, "1896": 19, "189981": [21, 35, 58], "19": [1, 8, 12, 13, 14, 15, 17, 19, 20, 21, 24, 25, 28, 30, 33, 34, 35, 40, 42, 49, 50, 51, 52, 54, 56, 57, 58, 61, 64, 65, 67, 68, 71, 73], "190": [14, 21, 24, 27, 35, 40, 48, 51, 58, 61], "1900": 42, "19000e": [15, 52], "1901": [12, 25, 49], "190319": [24, 40, 61], "19032": 67, "1904": [15, 28, 52], "190617": [16, 29, 53, 54], "190833": 27, "191": [16, 27, 29, 51, 53], "1910": 42, "1911": [24, 61], "191169": [21, 23, 35, 39, 58, 60], "191204": [24, 40, 61], "191250": [14, 27, 51], "191396": [15, 28, 52], "191700": [24, 40, 61], "1918": [17, 30, 54], "191k": [23, 39, 60], "192": 38, "1920": [12, 25, 49], "19213263": [17, 30, 54], "192133": [17, 30, 54], "19266": 67, "1927": 71, "1928": 71, "193": [22, 66], "1930": [12, 25, 49], "193021": [20, 34, 57], "193122": [20, 34, 57], "193247": [24, 61], "1933": [13, 42, 50], "193346": [23, 39, 60], "1934": 42, "193427": [33, 56], "19365": 67, "193704": 67, "19380": 67, "194": 19, "1940": [17, 30, 54], "194002": [15, 28, 52], "194034": 67, "194040": [16, 29, 53], "19422": [23, 39, 60], "19433594": 65, "1944": 42, "1945": [21, 35, 48, 58], "194519": 46, "1946": [12, 21, 25, 35, 48, 49, 58], "194710": [21, 35, 58], "1948": 42, "19485": [16, 29, 53], "194914": 43, "194985": [21, 35, 58], "195": [16, 29, 38, 53], "1950": [21, 35, 58], "1951": [13, 42, 50], "195228": 54, "1953": [19, 21, 33, 35, 56, 58], "19536": [20, 34, 57], "1954": 65, "1954400510": 42, "1955": [13, 42, 50], "195564": [24, 61], "1957": 65, "1959": [12, 25, 42, 49], "19591": [24, 40, 61], "1960": [13, 42, 50], "1962": 65, "1963": [19, 33, 56], "196385": [23, 37, 39, 60], "196442": 33, "1965": [13, 42, 50], "196599": [21, 35, 58], "1966": [21, 35, 58], "196717": 66, "196739": 67, "1968": [12, 25, 49], "196963": 43, "1970": [18, 21, 32, 35, 55, 58, 67], "197083": 14, "1971": 42, "1972": [21, 35, 58], "1975": 42, "197500": 27, "197617": 40, "197649": [24, 40, 61], "1977": [12, 25, 49, 68], "19777": [22, 23, 36, 37, 38, 39, 59, 60], "19781": 67, "197884": 44, "1979": 46, "198": [40, 66], "198127": [21, 35, 58], "1982": 40, "1984": [21, 35, 58], "1985": [21, 35, 58], "1986": 42, "198629": 66, "198645": 68, "1987": [12, 13, 25, 42, 49, 50], "1989": [12, 25, 49], "198924": [16, 29, 53, 54], "199": [12, 15, 20, 25, 28, 34, 47, 49, 52, 57], "1990": [15, 18, 19, 32, 33, 52, 55, 56], "1991": [13, 22, 36, 38, 42, 50, 59], "1992": 67, "1993": [21, 35, 58], "199364": [20, 34, 57], "1994": [12, 25, 49], "199412": [43, 68], "199413": [15, 19, 33, 52, 56], "1995": 40, "19966": [16, 24, 29, 53, 54, 61], "1997": [18, 19, 32, 33, 42, 55, 56], "199771": [23, 37, 39, 60], "1_000_000_000": 56, "1d": [44, 66], "1e": [19, 21, 33, 35, 56, 58, 77], "1e3": [19, 33, 56, 77], "1e4": [19, 33, 56], "1h": [16, 24, 29, 40, 53, 54, 61], "1st": [8, 20, 22, 23, 34, 36, 37, 38, 39, 46, 57, 59, 60, 67, 78], "1stflrsf": [21, 23, 35, 37, 39, 48, 58, 60, 69], "1v": 72, "1v2": 72, "1v3": 72, "2": [1, 4, 7, 8, 9, 10, 22, 23, 24, 36, 37, 38, 42, 43, 44, 46, 47, 59, 60, 61, 65, 66, 67, 70, 71, 72, 80], "20": [1, 4, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 68, 71, 72, 73, 75, 76, 80], "200": [12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 65, 66, 69, 74, 75, 76, 77, 78], "2000": [15, 19, 20, 21, 22, 23, 24, 28, 31, 33, 35, 36, 37, 38, 39, 40, 44, 46, 52, 56, 57, 58, 59, 60, 61, 66, 70, 72, 77], "20000": 19, "200000": [19, 33, 56, 67], "200000e": 42, "2003": [40, 42], "200326e": [21, 35, 58], "2004": [21, 35, 42, 58], "200458": 43, "200475": [20, 34, 57], "2005": 42, "2006": [21, 23, 35, 37, 39, 58, 60, 69], "2007": [21, 23, 35, 37, 42, 58, 60, 67, 69], "2008": [21, 23, 35, 37, 39, 42, 58, 60, 67, 69], "200876": [17, 30, 54], "20087625": [17, 30, 54], "2009": [21, 23, 35, 37, 42, 58, 60, 67, 69], "200978": [15, 28, 52], "200k": 78, "201": [1, 15, 28, 52, 80], "2010": [21, 23, 31, 35, 37, 46, 58, 60, 67], "20113": [16, 29, 53, 54, 76], "2012": [8, 16, 19, 29, 33, 53, 56, 80], "2013": [42, 65, 67], "201332": 63, "2014": [12, 22, 25, 36, 38, 42, 49, 59, 67], "20140521t000000": 42, "20140623t000000": 42, "20141013t000000": 42, "20141015t000000": 42, "20141209t000000": 42, "2015": [42, 66, 67], "20150116t000000": 42, "20150218t000000": 42, "20150223t000000": 42, "20150225t000000": 42, "20150630": 67, "2016": [8, 66, 67], "20160101": 67, "2017": [23, 37, 39, 60, 67], "201810": [20, 34, 57], "201862": [24, 40, 61], "202": [1, 15, 28, 52, 54, 80], "2020": 71, "2022": 67, "202247": 43, "2022w2": [12, 25], "2023": [1, 67], "2024": [0, 1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 74, 75, 76, 77, 78, 79], "20248": [16, 29, 53], "2024w1": [0, 10, 12, 66], "2024w2": [10, 12, 25], "2025": [1, 39, 40], "20274": 67, "20277493": 44, "202775": 44, "202839": [20, 34, 57], "203": [1, 15, 28, 52, 80], "20310": 67, "20311": [24, 61], "20319": 67, "203265": [23, 37, 60], "20334": 67, "203421": [21, 35, 58], "203500": [16, 29, 53], "20357847293371834": [18, 32], "20357847293371892": 55, "204": [1, 13, 14, 15, 27, 28, 33, 50, 51, 52, 56, 65, 74, 80], "204000": 19, "204167": [14, 27, 51], "2043": 68, "204302": 67, "20433": [24, 40, 61], "204583": [14, 27, 51], "2046": 54, "204600": [15, 19, 33, 52, 56], "204692": [21, 35, 58], "204734": [20, 34, 57], "20485": 67, "205": [13, 14, 15, 27, 28, 39, 44, 50, 51, 52, 74], "205000": [16, 21, 23, 29, 35, 37, 39, 53, 54, 58, 60, 69, 76], "205059": [24, 40, 61], "20509": 67, "20514": 67, "205144": [24, 61], "205323": 67, "205479": [18, 32, 55], "205597": [21, 35, 58], "20564": 67, "206": [13, 14, 15, 19, 20, 27, 28, 33, 50, 51, 52, 56, 57, 70, 74], "206019": 43, "206041": 60, "206073": [20, 34, 57], "206099": [19, 33, 56], "20620": 67, "206292": [16, 29, 53], "20639": [24, 40, 61], "2064": [16, 29, 53], "20640": [18, 24, 32, 40, 55, 61], "206724": 68, "20683258": [18, 32, 55], "20694": 67, "20699": 42, "207": [13, 14, 15, 16, 19, 27, 28, 29, 33, 50, 51, 52, 53, 56, 65, 66, 74], "207039e": [21, 35, 58], "2071": [24, 40, 61], "207814e": [21, 35, 58], "2079": 42, "20794": 67, "208": [13, 14, 15, 18, 19, 22, 27, 28, 32, 33, 36, 50, 51, 52, 55, 56, 74], "2081": 40, "20870": 40, "209": [12, 13, 14, 15, 19, 25, 27, 28, 33, 49, 50, 51, 52, 56, 74], "209221": 69, "209583": 51, "209746": [20, 34, 57], "209903": [24, 40, 61], "209978": 34, "20analysi": 68, "20assumpt": 68, "20hazard": 68, "20intro": 68, "20learn": 66, "20lifelin": 68, "20with": 68, "21": [1, 12, 13, 15, 16, 17, 20, 21, 24, 25, 26, 27, 28, 29, 30, 34, 35, 40, 42, 44, 49, 50, 52, 53, 54, 57, 58, 61, 62, 64, 65, 67, 71, 80], "210": [19, 33, 56], "210000": 14, "210001": [20, 34, 57], "210240": [33, 56], "210272": [24, 40, 61], "210286": 43, "210417": 27, "210591": [16, 29, 53, 54], "210779": 67, "21086181023099465": [18, 32], "21086181023099526": 55, "211": [19, 33, 56], "2110": [16, 29, 53], "211250": [14, 27, 51], "211343": [24, 40, 61], "211544": [20, 34, 57], "211724": 43, "211892": [16, 29, 53, 54], "212": [1, 14, 19, 33, 38, 51, 56, 80], "212385": [23, 37, 39, 60], "212581": [24, 40, 61], "21274": 67, "212870": [21, 35, 58], "212975": [21, 35, 58], "213": [14, 19, 33, 56, 66, 67], "2130": [12, 25, 49], "21353": 67, "21382972": 59, "21389": 67, "213896": 42, "2139": [16, 29, 53, 54, 76], "214": [12, 19, 25, 33, 49, 54, 56], "21405": 67, "21413528": [22, 36], "21436": 42, "2144": [19, 33, 56], "21450": 42, "214740": [16, 29, 53], "214769": 66, "214821": 67, "214852": [20, 34, 57], "2149": 44, "215": [19, 33, 56], "2150": 44, "2151": 44, "215167": 43, "2152": 44, "215245": [21, 35, 58], "2153": 44, "21530": 67, "2154": 44, "215412": [21, 35, 58], "21549": 67, "2155": 44, "215573": 19, "2156": 44, "21571": 67, "21581": 67, "21582031": 65, "215865": [23, 37, 60], "21596": 67, "216": [19, 33, 56], "21603": 67, "21605": 67, "21608": 42, "21609": 42, "21610": 42, "21611": 42, "21612": 42, "216123": 68, "21613": [13, 42, 50], "21616484": 72, "21617": 67, "2162": 40, "216250": 27, "216346": [23, 37, 39, 60], "21634631": [23, 37, 39, 60], "216585": [16, 29, 53], "216596": 67, "21668": 67, "21670": 67, "216718": [20, 34, 57], "216728": [16, 29, 53], "21694": 67, "21697": 67, "217": [38, 44, 70], "2170": [13, 42, 50], "217083": 14, "217334": [17, 30, 54], "21733442": [17, 30, 54], "2173627": 65, "21739617": 38, "217500": 14, "21767954": [23, 37, 39, 60], "21768": [22, 23, 37, 39, 60, 67], "217680": [23, 36, 37, 38, 59, 60], "21774": 67, "218": [17, 30, 44], "218207": [16, 29, 53, 54], "21847": 67, "21872": [21, 23, 35, 37, 58, 60, 69], "218760": [23, 37, 39, 60], "218830": [16, 29, 53], "218867": 43, "219": [24, 40, 44, 61], "2190": [16, 29, 53], "219141": 39, "2192": [19, 33, 56], "219500e": 42, "219512": [24, 40, 61], "219700": [24, 40, 61], "219714": 43, "21972656": 65, "219845e": [21, 35, 58], "22": [15, 16, 19, 20, 21, 22, 23, 24, 28, 29, 33, 34, 35, 36, 37, 38, 39, 40, 44, 52, 53, 54, 56, 57, 58, 59, 60, 61, 65, 67, 68, 71, 72, 76, 80], "220": [44, 51], "2200": 44, "22001": [23, 39, 60], "220392": 68, "22057": 67, "2206": 68, "22078": 67, "220819e": 19, "221": 44, "2210": [12, 25, 42, 49], "221070": 40, "22114": 67, "221329": [21, 35, 58], "221348": 67, "2214": 71, "22154": 67, "221622": [16, 29, 53, 54], "22168237": 72, "221720": 19, "221760": 43, "22187945": 38, "221900": [13, 42, 50], "222": [1, 44, 80], "22219": 67, "22221894": [21, 35, 58], "222222": [16, 29, 53], "22225": 67, "222307": [16, 29, 53], "222500": [27, 51], "22260": 67, "222647": [21, 23, 35, 37, 39, 58, 60, 69], "22283835": [22, 36], "2229": [18, 32, 55], "222963e": [35, 58], "223": [36, 44], "22305705": 59, "22320": 67, "223333": [27, 51], "223460": 68, "223750": [27, 51], "223804": [23, 39, 60], "224": [19, 33, 44, 56, 66], "224072": 46, "22452": 67, "2246468746": 51, "224662": [21, 35, 58], "22471154513694652": [18, 32], "22471154513694713": 55, "224865": [21, 23, 35, 37, 39, 58, 60], "224887": 33, "225": 66, "225301e": [21, 35, 58], "2254": [16, 29, 53], "22550": 67, "225646": 46, "226": [19, 23, 33, 39, 56], "226111": 40, "226415": [16, 29, 53], "226789": 68, "2268": [22, 36, 38, 59], "22697768": [17, 30, 54], "226978": [17, 30, 54], "2270": [33, 56], "227143": [16, 29, 53], "227167": 40, "2272": [20, 57, 70], "227304": 67, "22741": [24, 61], "227559": [21, 23, 35, 37, 58, 60, 69], "227568e": 19, "227836": [20, 34, 57], "22788": 67, "22811601": [18, 32, 55], "22826": 67, "228329": [20, 34, 57], "2285": 67, "22851562": 65, "228603": [21, 35, 58], "228750": [14, 27, 51], "229": 66, "229000": [16, 29, 53], "22910": 67, "229102": [23, 37, 39, 60], "229167": 14, "2293467570951035": 59, "2295": 67, "229583": [14, 27, 51], "229718": [23, 37, 60], "23": [1, 15, 16, 18, 19, 20, 21, 24, 28, 29, 32, 33, 34, 35, 40, 42, 44, 52, 53, 54, 55, 56, 57, 58, 61, 65, 67, 68, 76], "230": [15, 19, 33, 52, 56], "2300": [12, 25, 49], "230000": 42, "2300778984319707": [22, 36], "23011": [23, 37, 60], "230412": 39, "2305": [23, 37, 60], "2307": [14, 18, 27, 32, 51, 55], "23087929": [22, 36], "2309": 67, "23091772": 59, "231": [1, 80], "2310": [42, 67], "2311": 67, "2312": 67, "2313": 67, "23175": 67, "231815": [23, 37, 39, 60], "23182687": 38, "232": 44, "232075": 43, "232143": 54, "232751": 68, "23290": 67, "233": [13, 42, 50], "2334": 16, "234": 68, "234040": [20, 34, 57], "234303": 42, "234436": 68, "235": [24, 40, 44, 61], "235096": [16, 29, 53, 54], "235152": [15, 28, 52], "235417": 51, "235706": [24, 40, 61], "235833": 14, "236": [15, 19, 33, 44, 52, 56, 68], "2360": 42, "236096": 66, "236174": [24, 61], "236210": 62, "23621041": 62, "23640124": [18, 32, 55], "236456": [16, 29, 53], "23654": [20, 23, 34, 37, 57, 60], "236960": [33, 56], "237": [20, 44, 57, 68], "237895": 57, "237935": [23, 37, 60], "238": [20, 34, 44, 57, 68], "238129e": 19, "238192": [20, 23, 34, 37, 57, 60], "2388": 42, "2389": 54, "239": [44, 68], "23902": 67, "239082": 43, "23941": 67, "239676": 46, "239944e": [21, 35, 58], "24": [1, 10, 12, 15, 16, 20, 21, 22, 23, 24, 25, 28, 29, 34, 35, 36, 37, 38, 39, 40, 43, 44, 49, 52, 53, 57, 58, 59, 60, 61, 65, 66, 67, 68], "240": 68, "2401": [24, 40, 61], "240893": [24, 61], "241": 68, "241489": 68, "241620": [20, 34, 57], "24182": 67, "242015": [22, 23, 36, 37, 38, 39, 59, 60], "242083": 51, "242169": [20, 34, 57], "24220": 40, "242381": 67, "242740": 43, "24295676": [17, 30, 54], "242957": [17, 30, 54], "242996": [16, 29, 53, 54], "243": 67, "2431": 16, "243243": [21, 35, 58], "243447": [23, 37], "2435": [24, 61], "2436": [24, 61], "24395": [22, 23, 36, 37, 38, 39, 59, 60], "24397122221206388": 67, "244": 67, "244592": [15, 28, 52], "2447": [22, 36, 38, 59], "244814": 68, "245": 67, "2451": [19, 33, 56], "245329": [21, 35, 58], "245521": [20, 34, 57], "245635": 43, "245686": [20, 34, 57], "246": [67, 71], "246332": [21, 35, 58], "246486": 44, "246646": [19, 33, 56], "246646103936": [19, 33, 56], "246653": [33, 56], "247": 67, "247119": 67, "2471338": 46, "247439": 62, "24743939": 62, "247596": [22, 36], "247690828913": [19, 33, 56], "247691": [19, 33, 56], "248": 67, "2483": 46, "248328": 59, "248333": [27, 51], "2484": [12, 25, 49], "248400": 38, "248457": [21, 23, 35, 37, 39, 58, 60, 69], "248609": [21, 35, 58], "248664": [24, 61], "2487200875": 42, "2488": [15, 28, 52], "248999": 68, "249": 71, "2496": [14, 18, 27, 32, 51, 55], "249601e": [21, 35, 58], "249618e": [21, 35, 58], "249720": [15, 28, 52], "249807": 39, "24h": [20, 57, 70], "24th": [12, 25], "25": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79], "250": 38, "2500": [8, 44, 71], "250000": [16, 19, 20, 21, 29, 34, 35, 42, 53, 57, 58], "25031": 67, "25037": 67, "250588": 44, "2506": [13, 14, 27, 50, 51, 74], "250900": [21, 35, 58], "251093": [33, 56], "251158e": [21, 35, 58], "2516": [22, 36, 38, 59], "2517": [40, 46], "25176": 67, "251769": 66, "252": 70, "252042": [24, 40, 61], "25214": 67, "252160": [15, 28, 52], "2523": 40, "252859": 60, "2530": [12, 25, 49], "2533": [14, 18, 27, 32, 51, 55], "253312": [16, 29, 53, 54], "253432": [23, 37, 60], "253724": [15, 28, 52], "253914": [21, 35, 58], "254": 19, "254380": 68, "254443": [20, 34, 57], "25498295": 44, "254983": 44, "255": [16, 29, 43, 53], "2550": 42, "2551": 71, "255134": 66, "2556": [22, 36, 38, 59], "255751": [24, 61], "255855": 40, "255889": 67, "256": [12, 25, 49, 66], "25622": 67, "256263": [22, 23, 36, 37, 38, 39, 59, 60], "256271e": 19, "256333": [16, 29, 53], "256437": [24, 61], "25658": [24, 61], "256813": [15, 28, 52], "257": [13, 42, 50], "2570": [12, 13, 25, 42, 49, 50], "257024": [19, 33, 56], "257103": [20, 34, 57], "2574": [24, 40, 61], "257787": 44, "2580": [12, 25, 49], "258225": 67, "25823": [20, 34, 57], "258272e": 19, "258387": [23, 37, 39, 60], "2584": 65, "258427": [15, 28, 52], "258886": 57, "259": [21, 24, 35, 40, 58, 61], "259026": 43, "25904": 67, "2590575478171857": 32, "2590575478171884": [18, 55], "259085": 43, "259286": [15, 28, 52], "259500": [16, 29, 53], "259520": 43, "26": [8, 12, 15, 19, 20, 21, 22, 23, 24, 25, 28, 29, 33, 34, 35, 36, 37, 38, 39, 40, 44, 49, 52, 53, 56, 57, 58, 59, 60, 61, 62, 65, 67, 68, 71], "2600": [16, 29, 53, 54, 76], "260145": 46, "260258": [24, 40, 61], "26048": [23, 37, 39, 60], "260572": [21, 35, 58], "26063": 67, "260890": [21, 23, 35, 37, 39, 58, 60, 69], "261035": [21, 35, 58], "261953": 67, "262": [21, 23, 35, 37, 39, 58, 60, 68, 69], "262079e": [21, 35, 58], "262156e": [21, 35, 58], "262269e": [21, 35, 58], "2623": [21, 35, 58], "262361": [24, 61], "262500": [21, 35, 58], "263": [21, 35, 58], "2630": [16, 29, 53], "263000018": 42, "263541": 68, "263600": [16, 29, 53], "26370005": [18, 32, 55], "263736": 68, "263742e": [21, 35, 58], "26376": 67, "264": 22, "264042": 46, "264189e": 21, "264195": 68, "264283e": [21, 35, 58], "26447953": [17, 30, 54], "264480": [17, 30, 54], "265": 59, "265273": [18, 32, 55], "265483": 43, "266120": 67, "266135": [16, 29, 53, 54], "2670": [33, 56], "267209": 19, "267612e": [21, 35, 58], "268": [19, 33, 56], "2683": [20, 34, 57], "26831": 67, "2691": [13, 14, 27, 50, 51, 74], "26919": [24, 40, 61], "269689": 57, "269880": [15, 28, 52], "269972": [21, 23, 35, 37, 39, 58, 60, 69], "27": [1, 8, 15, 16, 17, 19, 20, 21, 28, 30, 33, 34, 35, 42, 44, 52, 54, 56, 57, 58, 65, 67, 68], "270093": [19, 33, 56], "270093376167": [19, 33, 56], "27021": 67, "270270": 64, "27048": [20, 34, 57], "2705": [19, 33, 56], "270920": 19, "271037": [24, 40, 61], "271287": 67, "271500": [24, 40, 61], "271738e": [21, 35, 58], "2720": [13, 42, 50], "27206": 67, "27263": [23, 39, 60], "272667": [16, 29, 53, 54], "2727": 40, "2730": [16, 29, 53], "27304": 42, "273382": [16, 29, 53, 54], "273606": [16, 29, 53, 54], "273890": 66, "2739": [26, 43], "273962": [24, 40, 61], "274": [16, 29, 53, 54, 67, 76], "274404": [16, 29, 53], "275008": 67, "27502379069": 58, "27502379089": 21, "27502379118": 35, "275290": [20, 34, 57], "275352": [15, 28, 52], "275410": [18, 32, 55], "2759": [23, 37, 60], "276": [16, 29, 53], "27610135": 65, "27638": 67, "27652": [20, 34, 57], "276687": [21, 35, 58], "27676": [20, 57, 70], "27678": [20, 57, 70], "276943e": [21, 35, 58], "27697": [20, 57, 70], "277": 36, "2770": [33, 56], "27705": [20, 57, 70], "27715": [20, 57, 70], "277381": [15, 28, 52], "2777": 68, "278": 71, "278441": 67, "278634": [20, 57], "27874871715903093": 55, "27874871715903127": [18, 32], "278755": [17, 30, 54], "27875502": [17, 30, 54], "2788": [14, 18, 27, 32, 51, 55], "27901526": 46, "2794": [18, 32, 55], "28": [1, 15, 16, 18, 19, 20, 21, 24, 28, 29, 32, 33, 34, 35, 40, 52, 53, 54, 55, 56, 57, 58, 61, 62, 65, 67, 68], "280": [16, 24, 29, 40, 53, 61, 71], "2800": 8, "280028": [24, 40, 61], "280310": [16, 29, 53, 54], "2806": [19, 33, 56], "280618": [20, 34, 57], "2807": 68, "280801": 68, "281": [16, 29, 37, 53], "28100": 40, "28122025543": [35, 58], "281220255445": 21, "281583": [21, 35, 58], "2817": [23, 37, 39, 60], "2820": 56, "282021e": [21, 35, 58], "2822": [23, 37, 60], "282600": 68, "282900e": 21, "283119e": [21, 35, 58], "28327": 67, "283421": [21, 35, 58], "2836": [23, 37, 60], "28362": 67, "283857": [15, 28, 52], "283921": [16, 29, 53], "284": [24, 40, 46, 61, 67], "2845": 68, "2846": 71, "2847": 71, "285": [16, 29, 53, 54, 67, 76], "285263": [23, 37, 39, 60], "28526302": [23, 37, 39, 60], "285467": [21, 23, 35, 37, 39, 58, 60, 69], "28571429": [13, 26, 50], "286": [14, 15, 19, 27, 33, 51, 52, 56, 67], "286000": [33, 56], "286200": [24, 61], "286326": 43, "286416": 54, "2865025": 72, "286821": [15, 28, 52], "287": 67, "287031": 67, "287079e": [35, 58], "287344": [16, 29, 53, 54], "287500": [24, 40, 61], "28753559": 65, "288": 67, "288002": 67, "288462": [18, 32, 55], "28854": 67, "28868": [20, 34, 57], "289": 67, "2890": [15, 19, 33, 52, 56], "289269": [23, 37], "28953": 67, "289541": [21, 23, 35, 37, 58, 60, 69], "289799": [15, 28, 52], "29": [8, 15, 16, 20, 21, 28, 29, 34, 35, 42, 44, 52, 53, 57, 58, 65, 67, 68, 71], "290": [42, 67], "290002": [20, 34, 57], "290424": [21, 35, 58], "29045704": [21, 35, 58], "290961e": [21, 35, 58], "291": [18, 32, 42, 55, 67], "291310100": 42, "291667": 64, "292": 67, "292530": 40, "292587": 68, "293": 67, "29324459": 66, "293663": [20, 34, 57], "294": [16, 23, 29, 38, 53, 65], "294133e": 21, "294157": 34, "294251": [17, 30, 54], "2948": [16, 29, 53, 54, 76], "294855": [23, 37, 39, 60], "295193": 43, "2953863599856858": [18, 32], "2953863599856862": 55, "295397": [20, 34, 57], "29545": [21, 35, 58], "2957": 44, "29572402": 65, "2958": 44, "2959": 44, "296": [16, 29, 53], "2960": 44, "2961": 44, "2962": 44, "2963": 44, "2964": 44, "296601": [24, 40, 61], "29691": 67, "297": [18, 32, 55], "29802": [20, 23, 34, 37, 57, 60], "298043": 43, "298436": 43, "298561": 68, "298612": 67, "29881": 67, "298813": 57, "299": [42, 66], "299164": [24, 61], "2d": [26, 44, 66], "2d454e5fd9a5": 68, "2e": 1, "2f": [14, 19, 27, 31, 33, 45, 46, 51, 56, 64, 67], "2m7m0lw97rvf654x1cwtdfmr0000gr": 29, "2nd": [46, 55], "2ndflrsf": [21, 23, 35, 37, 39, 48, 58, 60, 69], "2v": 72, "2v3": 72, "3": [1, 7, 8, 10, 15, 17, 18, 19, 20, 21, 22, 23, 24, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 43, 44, 45, 46, 47, 48, 52, 54, 55, 56, 57, 58, 59, 60, 64, 65, 66, 67, 69, 70, 72, 73, 80], "30": [1, 4, 12, 14, 15, 18, 20, 21, 22, 23, 24, 25, 27, 28, 32, 34, 35, 36, 37, 38, 39, 40, 44, 48, 49, 51, 52, 55, 57, 58, 59, 60, 61, 65, 67, 68, 69, 71, 80], "300": [15, 28, 52, 63, 65, 69, 72], "3000": [44, 66], "30000": 19, "300000": [16, 19, 29, 53, 54, 67], "3000000": 65, "300464": [24, 40, 61], "300837": [20, 34, 57], "301": [36, 68], "3010": [24, 40, 61], "301200": [19, 33, 56], "3014": [24, 40, 61], "30146": 67, "301563": [21, 35, 58], "30167": 67, "301784": 68, "3018": 80, "301838": 69, "3019": [13, 14, 18, 27, 32, 50, 51, 55, 74], "301952": [24, 40, 61], "302": [21, 23, 35, 37, 39, 58, 60, 69], "302043": 43, "302131": [21, 35, 58], "30279": 67, "302801": 68, "302844": 68, "302927e": 21, "303": [21, 23, 35, 37, 39, 58, 60, 69], "303000": [16, 29, 53], "303004": [24, 40, 61], "303030": [18, 32, 55], "303109": [17, 30, 54], "303161": 46, "303694": 43, "303790": 56, "3038": 71, "3038344082": [39, 60], "303916": [15, 28, 52], "304": [15, 28, 52], "3040": 67, "3041": 67, "3042": 67, "3043": 67, "304358": 46, "3044": 67, "304784": [21, 35, 58], "305": [12, 25, 49], "30504657": 62, "305047": 62, "30530902": [15, 28, 52], "305346": [15, 28, 52], "305674": [24, 61], "3057": [14, 18, 27, 32, 51, 55], "30573": [24, 40, 61], "305851": 46, "306500": [15, 28, 52], "306564": 66, "307": [16, 29, 53], "307516": 66, "307521": [18, 32, 55], "30792853": 65, "30798381": 65, "308": 38, "308120": [16, 29, 53], "30815": [21, 35, 58], "308216": 66, "308220": 57, "308236": 43, "308448": [15, 28, 52], "308506": 40, "3089": [19, 33, 56], "308900e": 42, "309": [24, 40, 61], "3092": [13, 14, 27, 50, 51, 74], "309249": 66, "309859": [18, 32, 55], "30am": 12, "30pm": 1, "31": [1, 12, 15, 16, 18, 20, 21, 22, 23, 25, 28, 29, 32, 34, 35, 36, 37, 38, 39, 40, 42, 49, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 67, 68, 71, 76], "310000": [16, 29, 53], "31000e": [15, 52], "310284": [23, 37, 60], "31029469": 44, "310295": 44, "31038074": 65, "310405": [20, 34, 57], "311": [16, 29, 53], "3110": [16, 29, 53], "31103996": 46, "311151": 68, "31127015": [23, 37, 39, 60], "311310": [12, 25, 49], "311769": [24, 40, 61], "3119640638146517": [18, 32], "31196406381465247": 55, "3120": [16, 29, 53], "3125": [16, 29, 53], "312500": [16, 64], "312501": [21, 23, 35, 37, 39, 58, 60, 69], "312696": 71, "3129": 71, "31297381": [17, 30, 54], "312974": [17, 30, 54], "31298589e": 66, "313": [21, 35, 54, 58], "31384": [20, 34, 57], "314": [16, 29, 36, 53], "3140": [16, 29, 53], "314000": [33, 56], "31449687e": [23, 37, 39, 60], "31454": [24, 40, 61], "314582": [23, 37, 60], "314840": [24, 40, 61], "314929": 67, "315000": 42, "315134": 67, "315630": [20, 34, 57], "316164": [24, 40, 61], "316230": [24, 61], "31634363": 65, "316363": [15, 28, 52], "316395e": [21, 35, 58], "316426": [24, 61], "316552": [17, 30, 54], "31655231": [17, 30, 54], "316798": [24, 40, 61], "317": [1, 16, 23, 29, 37, 53, 60, 80], "317005": 34, "317277": [24, 40, 61], "317334": 40, "31767136668453344": 42, "317761": [20, 34, 57], "318": [16, 29, 53], "3180": [33, 56], "3180174485124284": [16, 29, 53], "318937": [16, 29, 53, 54], "319": [13, 16, 17, 29, 30, 42, 50, 53], "31908384": 66, "3193": 40, "319481": 43, "319559": 42, "319630": 68, "31984311": [21, 35, 58], "31st": 67, "32": [8, 15, 16, 18, 19, 21, 28, 29, 32, 33, 35, 40, 43, 44, 52, 53, 54, 55, 56, 58, 62, 65, 67, 68, 76], "320": [16, 29, 53], "320155": [20, 34, 57], "3202": 40, "320430": [21, 35, 58], "32064171": 59, "3209427041566191": 42, "321": 60, "321050": 42, "3210656": 38, "32112113": [22, 36], "32127053": [21, 35, 58], "322": [24, 40, 61], "32240": [22, 23, 36, 37, 38, 39, 59, 60], "322465": 42, "32247597e": [23, 37, 39, 60], "322585": 46, "322755": [15, 28, 52], "323045": [16, 29, 53, 54], "32323": [12, 25, 49], "323612": 34, "32397724e": [23, 37, 39, 60], "324": 38, "3245": [12, 49], "324762": 43, "325000": 42, "3252": [24, 40, 61], "325319": [24, 40, 61], "32561": [20, 34, 57], "326": [16, 24, 29, 53, 61], "326616": 42, "326730": [20, 34, 57], "326741e": 68, "326911": 46, "326933": [15, 19, 33, 52, 56], "327188": [20, 34, 57], "327195": 40, "3272": 68, "327283": [21, 35, 58], "32734": [24, 40, 61], "3274": 68, "327408": [20, 34, 57], "32791718": 65, "328": [24, 40, 61], "328000": 42, "328077e": [21, 35, 58], "328799": 57, "328944": 46, "328953": [15, 28, 52], "3298721": 66, "3299": [65, 71], "33": [8, 12, 15, 16, 18, 19, 20, 21, 24, 25, 28, 29, 32, 33, 34, 35, 40, 42, 49, 52, 53, 54, 55, 56, 57, 58, 61, 65, 67, 68], "330": [9, 10, 13, 26, 44, 49, 50, 66, 67, 69, 71, 80], "33000e": [15, 52], "330346": 68, "330942": 34, "330_vs_340": 12, "3310": [16, 29, 53], "331588": 43, "33191802": 65, "332125": 57, "332130": [21, 35, 58], "33223002": 65, "3322447": 65, "33224516": 65, "33224759": 65, "332671": [23, 37, 60], "3327": 67, "332710": [21, 35, 58], "332746": 68, "332791": 68, "332824": [21, 35, 58], "333": 44, "3330": [16, 29, 53], "33308783": [17, 30, 54], "333088": [17, 30, 54], "333139": [20, 34, 57], "333333": [13, 16, 19, 26, 29, 33, 43, 50, 53, 56, 64], "3333333333333333": [64, 66], "333340": [15, 28, 52], "33380649": 65, "33380754": 65, "33380761": 65, "33381373": 65, "33394593": 65, "3339473": 65, "33394769": 65, "33395626": 65, "33397112": 65, "334": [24, 61], "33400489": 65, "33411086": 65, "33425967": 65, "33435326": 65, "33439238": 65, "33440682": 65, "334411": [15, 28, 52], "334576": [21, 35, 58], "33462759": 65, "334764": 43, "33476534": 65, "335": 59, "335309": [21, 35, 58], "3355": [16, 29, 53, 54, 76], "335649": 34, "3356700488_183566145b": 66, "33590": 67, "336": 22, "336389": 60, "33641142": [23, 37, 39, 60], "3364114233677307": [23, 37, 39, 60], "336411423367732": [23, 37, 39, 60], "33643394": 44, "336434": 44, "336735": [19, 33, 56], "336826": [17, 30, 54], "33682642": [17, 30, 54], "33683087": [18, 32, 55], "336831": [18, 32, 55], "337034": 61, "33726089": [21, 35, 58], "33732465": 65, "337625": 43, "33782315": 65, "33797555": 65, "338": [15, 19, 33, 52, 56], "33888659": 8, "339": [20, 34, 47, 57], "339368": 68, "339889": 68, "34": [12, 15, 16, 18, 20, 21, 24, 25, 28, 29, 32, 34, 35, 40, 44, 49, 52, 53, 54, 55, 57, 58, 61, 65, 67, 68, 76], "340": [1, 3, 13, 22, 24, 26, 36, 38, 40, 50, 59, 61, 66, 67, 68], "34000e": [15, 52], "340480": 46, "340988": [20, 34, 57], "341028e": 33, "341109": [21, 35, 58], "341300": [24, 40, 61], "341556": 46, "341571": 68, "34161762": [21, 23, 35, 37, 39, 58, 60], "341712": 67, "34182": [23, 39, 60], "3420": [16, 29, 53], "342200": [24, 40, 61], "342605e": [21, 35, 58], "3436": 67, "343676": 34, "3437": 71, "3438": 71, "343943": 39, "344": [16, 29, 53], "3442": 68, "34426571": [21, 35, 58], "34441": [21, 35, 58], "345": [23, 37, 39, 60], "345136": [15, 28, 52], "345386e": [21, 35, 58], "3454": [68, 71], "3455": 71, "345831": [12, 25, 49], "345835": 34, "346": [16, 29, 42, 53, 54, 76], "346850": [20, 34, 57], "34691": 67, "347001": 46, "347523": [19, 33, 56], "348": [16, 24, 29, 53, 61], "34806": [21, 35, 58], "348569": 69, "34900": [21, 35, 58], "34924955": 65, "35": [15, 16, 18, 20, 21, 22, 23, 28, 29, 32, 34, 35, 36, 37, 38, 39, 42, 52, 53, 55, 57, 58, 59, 60, 65, 67, 68, 75, 79], "350": [12, 25, 49], "3500": [44, 75], "350000": [16, 29, 53], "351": 19, "351351": 64, "351366": [20, 34, 57], "3515": 68, "351821": 68, "351883": 69, "3520": 68, "352062": 39, "3521": [12, 25, 49], "352100": [24, 40, 61], "352114": [23, 37], "352930": [16, 29, 53, 54], "353": [1, 19, 66, 80], "35375221": 72, "353961": [19, 33, 56], "354114": [21, 23, 35, 37, 58, 60, 69], "354604": [20, 34, 57], "3547": [24, 40, 61], "354759e": [21, 35, 58], "35561437": 65, "356689": [22, 23, 36, 37, 38, 39, 59, 60], "35671794": [23, 37, 60], "356959": 40, "357": [16, 29, 53], "3573886": 65, "357500": [16, 29, 53, 54], "3576": [12, 25, 49], "35771821": 65, "357823": [12, 25, 49], "358": [12, 19, 25, 33, 49, 56], "358000": 19, "358032": 60, "3582": [68, 71], "358264": [21, 23, 35, 37, 58, 60, 69], "3583": 71, "358333": [15, 28, 52], "358500": [24, 40, 61], "358913": [17, 30, 54], "3589134": [17, 30, 54], "359": [15, 19, 33, 52, 56], "3590": [19, 33, 56], "359784": [19, 33, 56], "359887": 62, "359992": [15, 28, 52], "35p": [12, 25, 49], "36": [15, 16, 18, 19, 20, 21, 22, 23, 24, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 67, 68], "360": [1, 54, 80], "360000": 42, "360172": 57, "360918": 67, "361": 68, "361622": 33, "361718": [20, 34, 57], "362": [42, 68], "362009": 67, "362185e": [21, 35, 58], "362553": [24, 40, 61], "36269995": [17, 30, 54], "362700": [17, 30, 54], "363": 68, "363192": [15, 28, 52], "363828": 40, "363913": [20, 34, 57], "364": [67, 68], "364352": [18, 32, 55], "364998": [23, 37], "365": 67, "3650": 19, "36525": [23, 39, 60], "365420": 71, "365603": [18, 32, 55], "365623": [15, 28, 52], "365898": 43, "365925": 43, "366": [17, 30, 54, 67, 68], "366005": [20, 34, 57], "366071": 16, "3663": 68, "366626": [15, 28, 52], "36695134": 65, "367": 67, "367329e": 68, "367423": [19, 33, 56], "368": [67, 71], "3681": [23, 37, 60], "368304": [18, 32, 55], "3684": 68, "368406": 44, "368922": 63, "369": [21, 35, 58], "369432": 40, "369822": 46, "369875": [15, 28, 52], "369896": 66, "37": [16, 18, 21, 24, 29, 32, 35, 40, 42, 44, 53, 54, 55, 58, 61, 65, 67, 68, 71, 76], "37050406": 8, "370643": [20, 34, 57], "370842": 42, "371": [24, 40, 61, 67], "3717": [23, 37, 60], "371722": [23, 39, 60], "372": [16, 29, 40, 53], "372572": 46, "372706": 67, "372763": [21, 23, 35, 37, 39, 58, 60, 69], "373031": [15, 28, 52], "373275": 67, "373318": 43, "373411": 42, "373623580": 44, "373656": 67, "374": [16, 29, 53], "374584": 66, "37546": [23, 39, 60], "376": [16, 21, 29, 35, 44, 53, 58], "376089": [21, 35, 58], "37647072": 59, "37658964": [22, 36], "3768": 71, "3769": 71, "377": 38, "377032": [21, 35, 58], "377619": [19, 33, 56], "377619120792": [19, 33, 56], "37797291": [17, 30, 54], "377973": [17, 30, 54], "37807203": 65, "378159": [21, 35, 58], "378764": [15, 28, 52], "378971e": [21, 35, 58], "37903": 44, "37906": [20, 34, 57], "379416e": [21, 35, 58], "379875e": [21, 35, 58], "38": [8, 15, 16, 18, 20, 21, 24, 28, 29, 32, 34, 35, 40, 42, 52, 53, 55, 57, 58, 61, 65, 67, 68], "3803": 68, "380436": [17, 30, 54], "38043616": [17, 30, 54], "380495": [15, 28, 52], "380504": [16, 29, 53, 54], "380643": [15, 28, 52], "381": 40, "381190": [24, 40, 61], "3814": 54, "381416e": 68, "381428": [21, 23, 35, 37, 39, 58, 60, 69], "381676": [15, 28, 52], "38192364": 62, "381924": 62, "382558": [20, 34, 57], "382733": 19, "3828": 40, "3828125": 65, "383": [16, 24, 29, 40, 53, 61], "384111": 71, "384127": [15, 28, 52], "384528": 43, "384613e": 56, "3851": [20, 34, 57], "3856": [15, 28, 52], "385639": 62, "386": [19, 33, 56], "386071e": [21, 35, 58], "386467": 46, "3865": 40, "386530": [23, 37, 60, 69], "386772": 40, "387": [19, 33, 56], "387502": 46, "388014": 46, "388023": [20, 34, 57], "388169": [24, 40, 61], "38853": [21, 35, 58], "3889": 54, "389": [19, 24, 33, 56, 61], "389065": [23, 37, 60], "389349": [24, 61], "389736": [16, 29, 53, 54], "39": [15, 19, 20, 21, 28, 33, 34, 35, 52, 56, 57, 58, 62, 65, 67, 79], "390428669205": [19, 33, 56], "390429": [19, 33, 56], "390691": 42, "390725": [21, 35, 58], "39095422e": [23, 37, 39, 60], "391": [16, 29, 53], "3912": 68, "391304": 42, "39163": [20, 34, 57], "391728": 20, "391996": 66, "392": [12, 25, 49, 68], "392082": [23, 37, 39, 60], "392221": [18, 32, 55], "392385": 68, "392612": [21, 35, 58], "392893": [15, 19, 33, 52, 56], "393": [13, 40, 42, 44, 50, 54], "3932": 68, "39375": 67, "394": 22, "394113e": [21, 35, 58], "394600e": 33, "394920": [16, 29, 53], "395": 40, "395282e": [21, 35, 58], "395686e": [21, 35, 58], "395688": 68, "395697e": [21, 35, 58], "396": [16, 29, 44, 53, 68], "396266": 66, "396752e": [21, 35, 58], "396991": [16, 29, 53, 54], "397": 68, "398": [24, 40, 61], "398495": 67, "398915": 43, "39896994": [17, 30, 54], "398970": [17, 30, 54], "399": [16, 19, 29, 42, 53], "3990": [13, 14, 27, 50, 51, 74], "3991": [21, 35, 58], "39931": [23, 39, 60], "399827": [20, 34, 57], "39x15": 65, "3blue1brown": 66, "3d": [24, 40, 61, 66], "3f": [13, 14, 15, 16, 20, 21, 26, 27, 28, 29, 31, 34, 35, 40, 45, 46, 47, 48, 50, 51, 52, 53, 57, 58, 64, 65, 71], "3h": 67, "3m": 66, "3rd": [46, 65], "3ssnporch": [21, 23, 35, 37, 39, 48, 58, 60, 69], "3v": 72, "4": [0, 1, 8, 9, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 46, 47, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 80], "40": [8, 12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 48, 49, 52, 55, 56, 57, 58, 59, 60, 61, 63, 67, 68, 69, 75, 80], "400": [13, 16, 19, 29, 33, 42, 50, 53, 56, 69, 77], "40000": [66, 67], "400000": [16, 19, 33, 42, 56, 67], "400047": 68, "400157": [24, 61], "400164": 66, "400649628005": [19, 33, 56], "400650": [19, 33, 56], "400881e": 42, "401": [15, 19, 33, 42, 52, 56], "4011": 65, "401102": 67, "401541": [20, 34, 57], "401623": [21, 35, 58], "401729": 43, "4018": 80, "401830": [23, 37, 60], "401895": [19, 33, 56], "402": [12, 25, 36, 49], "402101": 42, "402258": 42, "402808": [23, 37, 60], "404": [15, 24, 28, 40, 52, 61], "405": [59, 80], "405227e": [21, 35, 58], "405415": [15, 28, 52], "405650": [21, 35, 58], "406": 66, "406202": [19, 33, 56], "40689": [24, 40, 61], "407": [20, 57], "40708132": [22, 36], "407234": 66, "40725012": 66, "4074": 80, "407510": [20, 34, 57], "40756124": 59, "407862": 68, "4084": 68, "409": 80, "409430": 42, "40_000": 66, "40b5a809b05a": 68, "41": [15, 16, 20, 21, 23, 24, 28, 29, 34, 35, 37, 40, 52, 53, 57, 58, 60, 61, 62, 64, 67, 68], "410": [16, 29, 53], "410240": [20, 23, 34, 37, 57, 60], "410599": [24, 61], "410714": 16, "41128554": 38, "411412": [21, 35, 58], "41150573": [21, 35, 58], "411816e": 33, "412": [12, 15, 19, 25, 33, 49, 52, 56], "41210938": 65, "412500": [24, 61], "413": 38, "413050": 66, "413718": 68, "413796": [21, 35, 58], "413958": [20, 34, 57], "414": 71, "4143": 68, "414405": 43, "415": 44, "4151": [22, 36, 38, 59], "415178e": 19, "4153": [24, 61], "415383": 46, "4158382658": [29, 53, 71], "415888": 46, "416": [36, 60], "4165": [22, 36, 38, 59], "4169": 68, "417592": 20, "418": [19, 65], "418031": [15, 28, 52], "418069": [19, 33, 56], "41901484361": [19, 33, 56], "419015": [19, 33, 56], "419355": [18, 32, 55], "4195": [23, 37, 60], "4197": [13, 14, 18, 27, 32, 50, 51, 55, 74], "419973": 57, "42": [12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 72, 74, 75, 78, 79], "420": [33, 56], "420000": [12, 25, 49], "42060": [24, 40, 61], "421": 66, "42104086": [23, 37, 39, 60], "421215": 62, "42121526": 62, "421875": [18, 32, 55], "422": [21, 35, 58], "422222": 16, "4234": [23, 37, 60], "4236": [23, 37, 39, 60], "4237": 39, "4238": [20, 57], "423852": [20, 34, 57], "424221": 35, "424222": [21, 58], "424337e": [21, 35, 58], "425": 59, "425047e": 33, "425204": 40, "425365": 68, "42541681": 72, "425419": [21, 35, 58], "426067": [16, 29, 53], "426410": [15, 28, 52], "426905e": 21, "427": 68, "427516": 43, "4276": 70, "428": [19, 68], "428279": 43, "429": [21, 23, 35, 37, 58, 60, 69], "429217": [20, 34, 57], "429634": 68, "4296875": 65, "43": [15, 18, 19, 20, 21, 28, 32, 33, 34, 35, 52, 55, 56, 57, 58, 67, 68], "430": [21, 23, 33, 35, 37, 56, 58, 60, 68, 69], "430323": [16, 29, 53], "43049251": 38, "43049251280029016": 38, "430571": [20, 34, 57], "430704": 62, "4307043": 62, "430868": [18, 32, 55], "431": [51, 68], "4310": [15, 16, 19, 29, 33, 52, 53, 56], "431104": 43, "431137": [18, 32, 55], "4314": [20, 34, 57], "432": [40, 68], "433": 68, "433514": 67, "433814": 68, "434": [15, 18, 19, 32, 33, 52, 55, 56, 68], "43445": [24, 40, 61], "435": 68, "435186": [15, 28, 52], "435489": [20, 34, 57], "435792": [19, 33, 56], "436": 68, "436492": [21, 35, 58], "43697758253484525": [18, 32], "43697758253484614": 55, "4372": 62, "437367": [16, 29, 53, 54], "4375": [24, 40, 61, 64], "437500": 64, "437684": 67, "438": 64, "438231": 66, "438275": [17, 30, 54], "43827545": [17, 30, 54], "43833466": [21, 35, 58], "438592": [23, 37, 39, 60, 69], "438906": [23, 37, 60], "439": [16, 29, 53], "4390": [15, 19, 33, 52, 56], "439209": [20, 34, 57], "439254e": 44, "439360": [16, 29, 53], "439779": [20, 34, 57], "44": [14, 15, 16, 18, 20, 21, 24, 27, 28, 29, 32, 34, 35, 51, 52, 53, 55, 57, 58, 61, 65, 67, 68, 71], "440": [19, 33, 56, 67], "440897": 42, "441": [21, 35, 58], "441404": 66, "441445": [24, 40, 61], "442": 42, "442377e": [21, 35, 58], "442806": [15, 28, 52], "442917": 43, "4430": 68, "44311": [24, 40, 61], "4432": [24, 40, 61], "443317": [15, 28, 52], "443419": [21, 23, 35, 37, 58, 60, 69], "444297": [24, 40, 61], "4443": 16, "444444": [16, 29, 53], "444497": 40, "4448": [24, 40, 61], "445": [19, 33, 56], "445111e": [21, 35, 58], "445124e": [21, 35, 58], "445707": 40, "44586935": 59, "44586935141902073": 59, "44601557968639416": [22, 36], "44601558": [22, 36], "446216": [24, 40, 61], "446284e": [21, 35, 58], "446869": [24, 40, 61], "447": [16, 23, 29, 37, 40, 53, 60], "447461": 67, "447517": [23, 37, 39, 60], "44787197": 65, "4482": [12, 25, 49], "4484": [15, 28, 52], "448757": 68, "449262": 43, "449666": [15, 28, 52], "44966612": [15, 28, 52], "45": [8, 13, 14, 15, 16, 18, 20, 21, 27, 28, 32, 34, 35, 48, 50, 51, 52, 55, 57, 58, 65, 67, 68, 70, 74], "450000": 64, "450000e": 42, "450132": 67, "450739": [21, 35, 58], "450822": [24, 40, 61], "451888": [20, 34, 57], "452600": [24, 40, 61], "453367": [24, 40, 61], "4537": 68, "454427": [16, 29, 53, 54], "454677": 62, "45467725": 62, "454788": [23, 37, 60, 69], "454966": [20, 34, 57], "455": 54, "455026455026455": 44, "4552": [23, 37, 60], "455410": 46, "45555535": [23, 37, 60], "455652": 42, "45587": 67, "45588": 67, "45589": 67, "45590": 67, "45591": 67, "456": 66, "456419": [24, 40, 61], "45653693": [17, 30, 54], "456537": [17, 30, 54], "457435": 67, "45756": 71, "458": [16, 29, 53], "458333": 64, "458524": 68, "459": [21, 35, 44, 58], "4591": [16, 29, 53], "459214e": [21, 35, 58], "459873": 68, "459937": 65, "45a": 67, "45am": 67, "46": [8, 13, 14, 15, 16, 18, 20, 21, 27, 28, 29, 32, 35, 44, 50, 51, 52, 53, 54, 55, 57, 58, 67, 68, 71, 74, 76], "460047": 68, "46019608e": [23, 37, 39, 60], "46021": 71, "46075": 71, "4608": [13, 14, 27, 50, 51, 74], "460950": 62, "461": [16, 19, 29, 33, 53, 56], "462": 38, "462060": 68, "462545": [23, 37, 60], "462963": [18, 32, 55], "46299": 71, "463": [20, 34, 57], "46357616": 44, "463582": [22, 36, 38, 59], "464": 37, "464104e": [35, 58], "465279e": [21, 35, 58], "46530779": [17, 30, 54], "465308": [17, 30, 54], "46534653465346537": 19, "466246": 66, "4664": [12, 25, 49], "46666667": 44, "46729488": [21, 35, 58], "467379": [23, 37, 60], "467628": [24, 40, 61], "468": [15, 19, 23, 33, 37, 39, 52, 56, 60], "468232": 67, "4687": [24, 61], "46880": 71, "468995": 43, "469": [16, 20, 29, 53, 57], "469383": [20, 34, 57], "4695": [20, 34, 57], "469536": 40, "469571": [24, 40, 61], "47": [1, 12, 13, 14, 15, 16, 18, 19, 21, 24, 25, 27, 28, 29, 32, 33, 35, 40, 42, 49, 50, 51, 52, 53, 55, 56, 58, 61], "470": [16, 29, 53, 71], "4700": [33, 56], "470060": [21, 35, 58], "470666": [21, 35, 58], "471000": 42, "471032": [23, 37, 39, 60], "472": [17, 30, 71], "47242662": 72, "4726": 68, "472603": [21, 35, 58], "472790": [20, 34, 57], "473": [36, 65], "473691": [15, 28, 52], "474": [20, 36, 44, 57], "474552": [15, 28, 52], "47491": [20, 34, 57], "475": [19, 44], "475099": [23, 37, 60], "475540": 65, "476": [13, 26, 44, 50], "4760": [33, 56], "47606": [24, 40, 61], "476092": [21, 23, 35, 37, 39, 58, 60, 69], "476406": [23, 37, 39, 60], "476412": 62, "47641249": 62, "477": [19, 33, 44, 56], "477291": [24, 40, 61], "47799": 71, "478": 44, "478060": 67, "47810154525386317": 44, "478515": 43, "479": 44, "479109": [15, 28, 52], "479132": [24, 40, 61], "479773": 65, "48": [13, 14, 15, 18, 20, 21, 27, 28, 32, 34, 35, 50, 51, 52, 55, 57, 58, 64, 67, 68, 74, 80], "480": [21, 35, 44, 58], "4800": [12, 25, 49], "480249": [15, 28, 52], "4806334": 65, "48073598": 62, "4809": [19, 33, 56], "481": [16, 29, 44, 53], "4810": 70, "4813": [14, 18, 27, 32, 51, 55], "481514": [21, 35, 58], "481793": [16, 29, 53], "481893": [20, 34, 57], "481960": [20, 34, 57], "482": 44, "4820": 42, "4822": 68, "483": 44, "48344371": 44, "483751": [15, 28, 52], "48390": 71, "484": 44, "48407": 71, "484937": [18, 32, 55], "485": [44, 66], "485191": 43, "48535": 71, "4854": [23, 37, 60], "485722": 65, "486": [44, 60], "4861": [16, 29, 53, 54, 76], "486266": [16, 29, 53], "486664": 65, "487": [16, 29, 53], "48721": 71, "487740": 65, "4879": 71, "488": [16, 29, 44, 53], "488163": 65, "488753": 67, "489": 44, "489130": [18, 32, 55], "489593": 65, "49": [15, 16, 18, 20, 21, 24, 28, 32, 34, 35, 40, 52, 55, 57, 58, 61, 67, 68, 79], "490": [19, 24, 44, 61, 72], "490000": [16, 29, 53], "490033": [21, 35, 58], "490568": [19, 33, 56], "490797": 65, "490930": 65, "491217": [20, 34, 57], "491366": [23, 37, 60, 69], "491379": [16, 24, 29, 53, 61], "491968": 65, "492": [16, 20, 29, 53, 57], "492270": [17, 30, 54], "492307": 65, "492551": 65, "493": [16, 29, 50, 51, 53], "493489": 65, "493544": [16, 29, 53], "493921": [17, 30, 54], "494": [15, 16, 19, 29, 33, 52, 53, 56], "4943": [19, 33, 56], "494309": 42, "495": 38, "495524": 43, "49575": [20, 34, 57], "496": [24, 40, 61], "496213": [21, 35, 58], "49668874": 44, "496757": [23, 37, 60], "497143": 65, "497386": [15, 28, 52], "497787": [21, 35, 58], "497949": 65, "498": [19, 20, 22, 57, 70], "498133e": [21, 35, 58], "498164": 43, "498562": [15, 28, 52], "499900": [16, 29, 53], "4f": [15, 17, 20, 28, 30, 31, 34, 45, 46, 47, 52, 54, 57, 65], "4m": 66, "4th": [20, 22, 23, 34, 36, 37, 38, 39, 46, 57, 59, 60, 78], "4x": 80, "5": [1, 4, 18, 19, 21, 22, 31, 32, 33, 34, 35, 36, 38, 40, 42, 43, 46, 47, 48, 49, 55, 56, 58, 59, 63, 64, 67, 71, 72, 73, 74, 80], "50": [1, 12, 15, 16, 17, 20, 21, 22, 23, 24, 25, 28, 29, 30, 34, 35, 36, 37, 38, 39, 40, 42, 44, 46, 48, 49, 52, 53, 54, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 77, 78, 80], "500": [12, 14, 16, 20, 22, 23, 24, 25, 29, 31, 34, 36, 37, 38, 40, 45, 46, 49, 53, 57, 59, 60, 61, 78], "5000": [12, 13, 25, 42, 46, 49, 50, 70], "50000": 67, "500000": [15, 16, 20, 21, 29, 34, 35, 42, 53, 54, 57, 58, 63, 67, 71], "500000e": [19, 33, 42, 56], "500001": [16, 29, 53], "5002": [21, 35, 58], "500625": [15, 28, 52], "50062e": [15, 52], "500924": [16, 29, 53, 54], "501": [16, 29, 53, 71], "501071": 66, "501191": 65, "501250": [15, 28, 52], "501304e": [21, 35, 58], "5014": 12, "501875": [15, 28, 52], "5024752475247525": [33, 56], "502500": [15, 28, 52], "502985": [20, 34, 57], "503": 46, "503000": [16, 29, 53], "503090": [20, 34, 57], "503125": [15, 52], "50325": 46, "50350": 46, "503750": [15, 28, 52], "503807": 65, "504": [15, 24, 28, 40, 46, 52, 61], "504231": 68, "504375": [28, 52], "504429": [17, 30, 54], "504644": [19, 33, 56], "50475372e": [23, 37, 39, 60], "504fde4fcf8": 68, "505000": 15, "505026": 42, "505180": 65, "505335": [20, 34, 57], "505592e": [21, 35, 58], "505625": [15, 28, 52], "5057": [21, 35, 58], "50596432e": 72, "506023": [22, 36, 38, 59], "506035e": [21, 35, 58], "506052": 46, "506079e": [21, 35, 58], "506084e": [21, 35, 58], "506211": [16, 19, 29, 33, 53, 56], "506250": 28, "506410": [18, 32, 55], "50666667": 44, "506875": [15, 28, 52], "507130": [19, 33, 56], "507359": [16, 19, 29, 33, 53, 56], "507500": [15, 52], "50774": [19, 33, 56], "507740": [16, 29, 53], "50775": [19, 33, 56], "507750": [19, 33, 56], "507752": [16, 19, 29, 33, 53, 56], "507995": [18, 32, 55], "508": [16, 21, 29, 35, 53, 58], "508125": [15, 28, 52], "508133": [16, 19, 29, 33, 53, 56], "508371": [19, 33, 56], "508534": 65, "508741": 65, "508750": 28, "50884": [24, 40, 61], "508971": 20, "50899": [19, 33, 56], "509": 40, "509000": [12, 25, 49], "509001": [21, 35, 58], "509045": 42, "509317": [16, 19, 29, 33, 53, 56], "5098": 65, "509859": 65, "509930": 67, "50k": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "51": [15, 16, 19, 20, 21, 23, 28, 29, 33, 34, 35, 37, 40, 52, 53, 54, 56, 57, 58, 60, 62, 67, 68, 69, 76], "5100": 42, "510000": [13, 15, 19, 33, 42, 50, 52, 56], "510421": 65, "510505": 65, "5106": 71, "510625": 28, "510697e": 42, "5107": 42, "510836": [19, 33, 56], "5109": [23, 37, 60], "511": 9, "5112": [13, 42, 50], "51137414e": [23, 37, 39, 60], "51143": [24, 40, 61], "51150": [20, 34, 57], "511620e": [21, 35, 58], "5118": [23, 37, 39, 60], "511875": 28, "512": 66, "5120": [12, 25, 49], "512000": [15, 19, 33, 52, 56], "51226051": 62, "5123": 65, "512319": [16, 29, 53], "512408": [21, 23, 35, 37, 39, 58, 60, 69], "512897": [15, 28, 52], "512x640": 66, "513": [16, 29, 53], "5131": 65, "513125": 15, "513333": 44, "513678": 68, "513750": 15, "514150": 65, "514155": [16, 21, 29, 35, 53, 54, 58], "514347": 65, "514598e": [21, 35, 58], "5146": [18, 32, 55], "514950": 44, "515000": 52, "51503393": [17, 30, 54], "515034": [17, 30, 54], "515351e": [21, 35, 58], "515443": [23, 37], "5156": [16, 24, 29, 53, 61], "515755": 44, "515848": [24, 61], "516199": 65, "516394": [24, 40, 61], "516556": 44, "516788": 43, "516858": 65, "517273": 65, "517346": [20, 34, 57], "518113": 65, "519000": 42, "519029": [20, 34, 57], "519129": 43, "52": [15, 16, 18, 20, 21, 24, 28, 29, 32, 34, 35, 40, 52, 53, 55, 57, 58, 61, 67, 68, 71], "520495": 65, "52061": 67, "520700": 65, "520782": 65, "5208": [13, 42, 50], "520857": [20, 34, 57], "5209": [21, 35, 58], "5212": [21, 35, 58], "521284e": [21, 35, 58], "521567e": [21, 35, 58], "521578e": [21, 35, 58], "521743e": [21, 35, 58], "521772": 65, "522": [21, 35, 58], "522563e": [21, 35, 58], "5227966": 65, "523595": 65, "523684": 65, "5238095238095238": [13, 26, 50], "52398": [24, 61], "524": [13, 26, 50, 64], "524364": 68, "525": 44, "5253": [23, 37, 60], "525554": [24, 61], "525757": [15, 28, 52], "526046": 65, "526078": [16, 29, 53, 54], "526214": 60, "526442": 43, "526596": [24, 61], "526602": [21, 35, 58], "526783": 43, "5274": 68, "527500": [16, 29, 53], "528": [21, 35, 58], "5282": 68, "528403": [15, 28, 52], "52881619": [15, 28, 52], "529210": [20, 34, 57], "529388e": [21, 35, 58], "5294": [22, 36, 38, 59], "529412": [16, 29, 53], "52980132": 44, "53": [18, 21, 32, 35, 42, 55, 58, 67], "530052": [19, 33, 56], "530978": [20, 34, 57], "531": 69, "5310": 16, "531116e": [21, 35, 58], "531353": 66, "5315": [19, 33, 56], "53187": 70, "532034": [21, 35, 58], "533027": 43, "533333": 16, "533454": 66, "533498": [15, 28, 52], "534069": 46, "534114": [19, 33, 56], "534342": [24, 40, 61], "5345": 42, "535": [16, 24, 29, 40, 53, 61], "535014": [16, 29, 53], "53520104": [15, 28, 52], "535604": [16, 29, 53], "535622": [24, 40, 61], "536362": 62, "53636249": 62, "537267": [16, 29, 53], "537732": 65, "538000": [13, 42, 50], "538702": [15, 28, 52], "538816": [20, 34, 57], "5390": [20, 23, 34, 37, 57, 60], "5391": [16, 24, 29, 53, 61], "539116": 67, "539258": 43, "539376": 68, "539459": 71, "539989": 42, "54": [21, 35, 58, 67, 68, 79], "540": 67, "540000": [16, 29, 53], "540039": 65, "540359": [24, 40, 61], "541117": [21, 35, 58], "541347": 65, "541488": [24, 40, 61], "54152": [20, 34, 57], "541667": 54, "541795": [20, 34, 57], "542": 69, "542049": [23, 37], "54240": [20, 34, 57], "542624": [23, 37, 60], "542873": [16, 29, 53, 54], "543297": [19, 33, 56], "543351": [23, 37, 39, 60], "543464": 65, "543678": 43, "544": [33, 56], "544079": 43, "544462": 60, "545": [21, 35, 58], "546": [16, 29, 53], "5461": [21, 35, 58], "546150": 43, "546473": [18, 32, 55], "546610": [15, 28, 52], "54676006e": [23, 37, 39, 60], "547": [21, 33, 35, 56, 58, 60], "547090": 65, "5471258278145695": 44, "547993": [20, 34, 57], "548831": [23, 37, 39, 60], "549": 23, "549475": 40, "54966887": 44, "549682": [20, 34, 57], "5498": [15, 28, 52], "549946": 65, "55": [13, 14, 15, 18, 20, 21, 22, 23, 27, 28, 32, 34, 35, 36, 37, 38, 39, 50, 51, 52, 55, 57, 58, 59, 60, 67, 68, 69, 74], "55000": 56, "550000": [16, 29, 33, 53, 54, 56], "550004": [22, 36, 38, 59], "550616": [20, 34, 57], "55101": 67, "5513": [19, 33, 56], "5514": [22, 23, 36, 37, 38, 39, 59, 60], "5515": 68, "551579e": [35, 58], "551862e": [21, 35, 58], "551975": [21, 35, 58], "552": [16, 21, 29, 35, 53, 58], "552492": 42, "552721": [22, 36, 59], "553": 42, "553125": 15, "553965": [23, 37, 39, 60], "553979": [20, 34, 57], "55398442": [22, 36], "553984420313606": [22, 36], "5540": 68, "5541306485809793": 59, "55413065": 59, "554180": 67, "554463": 65, "554621": [24, 40, 61], "5551": [18, 32, 55], "555180": 42, "555740": [15, 28, 52], "556352": 39, "5566": [16, 29, 53, 54, 76], "556716": 44, "557197": 66, "557242": [20, 34, 57], "557739": [21, 35, 58], "558": [21, 23, 24, 35, 37, 40, 58, 60, 61, 69], "558564": [20, 34, 57], "55862988e": [23, 37, 39, 60], "55873324": 66, "5588": [12, 25, 49], "558824": [20, 34, 57], "558889": [21, 35, 58], "559": [19, 21, 23, 33, 35, 37, 56, 58, 60, 69], "559284": 42, "56": [15, 20, 21, 28, 34, 35, 52, 54, 57, 58, 67, 68, 79], "560": 42, "560053": 42, "5601": 40, "560225": [16, 29, 53], "560625": 28, "560768": [21, 35, 58], "5609808539232339": 16, "561": [1, 15, 19, 23, 24, 33, 37, 52, 56, 60, 61], "561467": [16, 29, 53, 54], "561602": [23, 37, 39, 60], "561645e": [21, 35, 58], "562112": [16, 29, 53], "5623062252998352": 65, "562712": 65, "563": 1, "5630224174651539": 55, "5630224174651548": [18, 32], "5630921721458435": 65, "563125": 15, "5631500400": 42, "563314": [21, 23, 35, 37, 58, 60, 69], "563467": [16, 29, 53], "5644": [21, 35, 58], "564483": [24, 40, 61], "565": [24, 40, 61], "5650": [13, 42, 50], "565062": 68, "56521734": 8, "565625": 28, "565679": [20, 34, 57], "565746": 68, "565888": [16, 29, 53], "566": [16, 29, 53], "566092": [16, 29, 53], "566222": 66, "5667": [20, 34, 57], "567724": 66, "567856e": [21, 35, 58], "568": 66, "568009": [15, 28, 52], "56804591": [21, 35, 58], "568125": 15, "568663": [21, 35, 58], "568697e": 21, "5690201394269164": 39, "5690201394302518": [23, 37, 60], "56902014": [23, 37, 60], "569375": 52, "5694": [24, 40, 61], "5695074871997099": 38, "56950749": 38, "57": [15, 16, 20, 21, 23, 28, 29, 34, 35, 37, 42, 52, 53, 54, 57, 58, 60, 67, 68, 69, 76], "57000": 68, "570015": [21, 35, 58], "570449": [20, 34, 57], "570473": [24, 40, 61], "570648": 46, "5707": 68, "570739": [24, 40, 61], "571": [44, 62, 72], "571431": 65, "571500": [24, 40, 61], "5717": 40, "571800": 42, "571875": 28, "571901e": [21, 35, 58], "571969": [24, 40, 61], "572": 1, "572105": [15, 28, 52], "572500": 15, "572549": [16, 29, 53], "572962": 68, "573": 72, "573050": [20, 34, 57], "573125": 15, "573129": [21, 23, 35, 37, 39, 58, 60, 69], "5732": [20, 57, 70], "57333333": 44, "573542": [24, 40, 61], "573818": [20, 34, 57], "574": 42, "57415": 67, "574260": [24, 40, 61], "575000": 64, "575043": 42, "575046357615894": 44, "57510": [24, 61], "5755444169044495": 65, "575636": 44, "575907": [24, 40, 61], "576": [16, 29, 39, 53], "57615894": 44, "57640869": [17, 30, 54], "576409": [17, 30, 54], "576921": 65, "577500": 15, "578452": 43, "578523": [18, 32, 55], "578569": 43, "578654": [20, 34, 57], "578684": 39, "5789": [21, 35, 58], "579091": [24, 40, 61], "579245": 65, "579432": [18, 32, 55], "579559e": [21, 35, 58], "57966": 22, "579660": [36, 38, 59], "5798": [22, 36, 38, 59], "57994": [20, 34, 57], "58": [13, 14, 15, 18, 21, 27, 28, 32, 35, 50, 51, 52, 55, 58, 67, 68, 74], "580": 66, "580302e": 42, "5804311633110046": 65, "580539e": [21, 35, 58], "580625": 15, "581": [23, 37, 60], "5813": 42, "58137177": [17, 30, 54], "581372": [17, 30, 54], "5814": [12, 25, 49], "581687": [24, 40, 61], "581787": 68, "582": [12, 22, 25, 36, 38, 49, 59], "582090": [20, 34, 57], "5824530720710754": 65, "582469": [21, 35, 58], "582570": 44, "583": 42, "583125": 15, "58387198": 62, "583872": 62, "583972": 43, "584": [16, 29, 53], "584615": [16, 24, 29, 53, 61], "585": [16, 29, 53], "585157": 46, "585187": 44, "585513": [18, 32, 55], "5857": 68, "586095": [16, 29, 53, 54], "586875": 28, "587773": [20, 34, 57], "588": [15, 19, 33, 52, 56], "588125": 52, "588235": [18, 32, 55], "588307": [16, 29, 53], "58871446": 38, "589": 19, "589286": 71, "59": [1, 12, 15, 16, 18, 21, 25, 28, 35, 52, 58, 67, 68, 80], "590": 42, "590243": 65, "59049": [20, 57], "59050": [20, 57], "590618": [24, 40, 61], "590625": 15, "59082668": [17, 30, 54], "590827": [17, 30, 54], "5915": 54, "592": 71, "592401": [12, 25, 49], "59243876": 59, "592507": 43, "5925410985946655": 65, "59291868": [22, 36], "59300": [24, 61], "5931": [21, 35, 58], "593370": [21, 35, 58], "593508": 62, "5938": [16, 29, 53], "594": [16, 29, 53], "5941": 42, "5944": 42, "594595": [15, 28, 52], "594982": [20, 34, 57], "594995": [20, 34, 57], "5950": [16, 29, 53], "595000": 28, "595427": 66, "595569e": [21, 35, 58], "595625": 15, "596088e": [35, 58], "596151": [24, 40, 61], "596810": [15, 28, 52], "596864": [21, 35, 58], "596875": 28, "5970": [22, 36, 38, 59], "59700": [20, 57], "597015": [18, 32, 55], "59708": [20, 34, 57], "597326": [20, 34, 57], "597555": [12, 25, 49], "597924": [21, 23, 35, 37, 58, 60, 69], "598": [16, 29, 53], "598057": 44, "59810": [20, 34, 57], "598100": [18, 32, 55], "598149": [21, 23, 35, 37, 58, 60, 69], "598750": 52, "599": 71, "5993570685386658": 65, "599492": [18, 32, 55], "599717": 40, "599860": [15, 28, 52], "599894": 67, "59pm": [12, 25], "5fin": [21, 35, 58], "5th": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "5unf": [21, 35, 58], "6": [1, 8, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 80], "60": [8, 12, 16, 20, 21, 23, 24, 25, 29, 35, 37, 40, 48, 49, 53, 57, 58, 60, 61, 62, 64, 65, 67, 68, 69], "600": [16, 18, 29, 32, 53, 55, 65], "60000": 67, "600000": [14, 15, 19, 28, 33, 51, 52, 56, 67], "600193": [20, 34, 57], "60023631": [21, 35, 58], "600288": 43, "600625": 28, "600k": [21, 35, 48, 58], "601": [19, 33, 56], "601042": [12, 25, 49], "601220": 24, "601504": [18, 32, 55], "601712": [20, 34, 57], "601790": [18, 32, 55], "602": [16, 29, 42, 53, 54, 76], "602000": [16, 29, 53], "602649": [15, 28, 52], "6028": [20, 34, 57], "602941": [20, 34, 57], "602954": [22, 36, 59], "603125": 28, "6031432151794434": 65, "60319915": 72, "603243": 42, "603684e": 56, "603739": 42, "603970": 68, "604": [15, 28, 52], "6040": [15, 19, 33, 52, 56], "604000": [13, 42, 50], "604032": [20, 34, 57], "60429913": [21, 35, 58], "604320": [18, 32, 55], "604421": 46, "60455": 67, "604619": [18, 32, 55], "604797": [18, 32, 55], "6048": 67, "604807": 68, "60495488": [15, 28, 52], "605060": [20, 34, 57], "6051": [16, 29, 53, 54, 76], "605100": [18, 32, 55], "605101": [18, 32, 55], "605102": [18, 32, 55], "605263": [15, 28, 52], "605625": 52, "605696": [18, 32, 55], "606": [16, 29, 53], "606061": [18, 32, 55], "6063088774681091": 65, "606557": [18, 32, 55], "606567": [18, 32, 55], "606811": [19, 33, 56], "606875": 52, "606902": [18, 32, 55], "607062": 67, "608050": [18, 32, 55], "608125": 52, "6082": [16, 29, 53], "608299": 38, "608468": [18, 32, 55], "608532": 66, "608565": 68, "60860": [16, 29, 53], "6086405515670776": 65, "609": [16, 29, 40, 53], "6092": [12, 25, 49], "6093292236328125": 65, "609375": 52, "60943": [20, 34, 57], "60k": [21, 35, 48, 58], "61": [15, 17, 18, 20, 21, 28, 30, 32, 34, 35, 40, 52, 54, 55, 57, 58, 62, 67, 68], "610000": 15, "610142": 43, "61029914": [21, 35, 58], "610407": [20, 34, 57], "610593": 40, "610931": 63, "611": 54, "611007": 66, "6111123561859131": 65, "611178": 67, "612349": [17, 30, 54], "61234944": [17, 30, 54], "6124": 68, "612500": 28, "612546": [20, 34, 57], "612621": [18, 32, 55], "612755": [15, 28, 52], "613231": 44, "613507": [18, 32, 55], "613738": [19, 33, 56], "613738418384": [19, 33, 56], "614": [16, 29, 53], "61420598": [17, 30, 54], "614206": [17, 30, 54], "614567": [24, 40, 61], "614872": 43, "614940": 38, "615": [16, 29, 53], "615000": 28, "615124": [22, 36], "6154": [16, 24, 40, 61], "615730": 59, "616": [19, 33, 56], "616099": [19, 33, 56], "6168": [13, 42, 50], "617234": 46, "617342": 68, "617431": 63, "6176": [20, 34, 57], "617647": [20, 34, 57], "618": [16, 29, 53], "618000e": 42, "618012": [19, 33, 56], "6186580061912537": 65, "618967": 65, "619": 71, "61912405": [23, 37, 60], "619375": 28, "62": [15, 16, 19, 20, 21, 28, 33, 34, 35, 44, 52, 56, 57, 58, 67, 68], "620726": 43, "6210": 42, "621931e": 21, "622255": [16, 29, 53], "622454": [19, 33, 56], "622500": [15, 52], "6226": [24, 40, 61], "622612": [20, 34, 57], "622709": [18, 32, 55], "623": 19, "623000": [16, 29, 53], "62320": 67, "62341036": [22, 36], "62352928": 59, "624049": [21, 35, 58], "6241": [12, 25, 49], "624375": 52, "624450e": [21, 35, 58], "624615": [21, 35, 58], "6250": [16, 29, 53], "625307": 40, "625387": [19, 33, 56], "6257": 68, "626206": [21, 35, 58], "62657": 67, "626875": 52, "62688064": [23, 37, 39, 60], "627": 68, "6273": [19, 33, 56], "6275": [13, 14, 27, 50, 51, 74], "627722": [23, 37, 60], "627966": [16, 29, 53], "628032": [24, 40, 61], "628139": [20, 34, 57], "62873917": [23, 37, 60], "629532": 38, "629792e": [21, 35, 58], "63": [15, 19, 20, 21, 28, 33, 34, 35, 52, 56, 57, 58, 67, 68, 71], "6303": [16, 29, 53, 54, 76], "6306": [16, 24, 29, 53, 61], "630625": 15, "631899": 68, "632": 71, "6320": [18, 32, 55], "6320979595184326": 65, "6322": [24, 61], "632296": 43, "632353": [20, 34, 46, 57], "632786": 67, "63316788": 72, "63362": [21, 35, 58], "633933424949646": 65, "634397": [18, 32, 55], "634490": 54, "634686": [20, 34, 57], "635": [16, 29, 53], "635200": [24, 61], "635239": [16, 29, 53, 54], "635648": [18, 32, 55], "635815": [22, 36], "635831": 38, "636": [12, 16, 25, 29, 49, 53, 54, 68, 76], "636364": [16, 71], "636410": 59, "636849e": [21, 35, 58], "637": 66, "637982": [15, 28, 52], "638169": [23, 37, 39, 60], "6389": [16, 24, 29, 53, 61], "6391518364256": 68, "6392": [24, 40, 61], "639412e": 19, "639754": [21, 35, 58], "64": [10, 15, 16, 18, 21, 28, 32, 35, 52, 55, 58, 66, 67, 68], "640": [19, 33, 56, 66], "6400": [16, 29, 53], "640000": [20, 34, 57, 71], "640201": 34, "640266": [16, 29, 53, 54], "640625": 15, "640x480": [15, 28, 52], "641216": 67, "6414100192": 42, "641538": 68, "641873": [21, 35, 58], "642071": 43, "642676": 67, "642965": [20, 34, 57], "643": [33, 37, 56], "6431": [24, 40, 61], "643311e": [21, 35, 58], "643315": 44, "643750": 15, "644106": [20, 34, 57], "64417243": 66, "644375": 28, "64454": [20, 34, 57], "644657e": 19, "644770": 63, "6453951434878586": 44, "645519": [20, 34, 57], "6458": [13, 14, 27, 50, 51, 74], "645963": [19, 33, 56], "646050": [23, 37, 60], "6464": 68, "646617": 69, "647796": [24, 61], "648": [15, 16, 19, 29, 33, 52, 53, 56], "6480": [22, 36, 38, 59], "648195": [20, 34, 57], "648550": 66, "648555": 40, "649349e": 19, "649658": [23, 37, 39, 60], "64994": 67, "65": [13, 17, 21, 30, 33, 35, 40, 50, 54, 58, 68], "650": [20, 34, 57], "65000": [33, 56], "650000": [19, 33, 56], "65000e": [15, 52], "65013704": 62, "650743": 42, "6507517": 44, "650752": 44, "651": 42, "651250": 15, "65125032": 72, "6513": [23, 37, 60], "651359e": 42, "651446": 67, "651875": 28, "65243": [21, 35, 58], "652487": [24, 61], "6526853": [21, 35, 58], "652828": [19, 33, 56], "652986": [24, 61], "653": [16, 29, 53], "653205": [19, 33, 56], "653205232272": [19, 33, 56], "654": [16, 29, 53], "65424895": [21, 35, 58], "654375": 28, "65486": 65, "656297e": [21, 35, 58], "656349": [15, 28, 52], "656827": [20, 34, 57], "656873": 42, "657675": [24, 61], "658047": [18, 32, 55], "658645": [18, 32, 55], "659056": [21, 35, 58], "66": [13, 14, 16, 18, 20, 21, 27, 29, 32, 34, 35, 50, 51, 53, 55, 57, 58, 66, 67, 74], "6600060120": 42, "6601256728172302": 65, "660171": [15, 28, 52], "6604": [16, 29, 53, 54, 76], "660714": 54, "661023": 65, "662126": 38, "66214339": [15, 28, 52], "66221": 67, "6622507572174072": 65, "662450": [20, 34, 57], "662541e": [21, 35, 58], "662745": [16, 29, 53], "662853": [22, 36], "662879": 59, "66368": [23, 37, 39, 60], "663680": [21, 23, 35, 37, 39, 58, 60, 69], "6637": 68, "6638": 68, "663822": [23, 37, 39, 60], "6639": 68, "6639009118080139": 65, "6641": 68, "6642": 68, "664207": [20, 34, 57], "6643": 68, "6644": 68, "6645": 68, "664625": 65, "664707": [18, 32, 55], "66473": 67, "665": [16, 29, 53], "665307": 65, "665351e": [21, 35, 58], "665625": 52, "665882": [22, 36, 38, 59], "666": [16, 29, 53, 54], "666166": 67, "6666666666666666": 66, "666667": [14, 16, 29, 51, 53, 64], "666754": 66, "667450": 67, "668": 65, "668787": [15, 28, 52], "6688": [12, 25, 49], "66941678": 44, "669417": 44, "669614": [20, 34, 57], "669725": 57, "669805e": [21, 35, 58], "67": [13, 14, 17, 18, 20, 21, 27, 30, 32, 35, 40, 50, 51, 54, 55, 57, 58, 67, 68], "670344": [15, 28, 52], "6709133982658386": 65, "671272e": 42, "6718650311": 35, "67186503136": 58, "67186503153": 21, "6731126308441162": 65, "673277": [19, 33, 56], "6733067729083665": 44, "6733849048614502": 65, "6734487414360046": 65, "674": 44, "6744": [23, 37, 60], "674490": [19, 33, 56], "674721": 59, "675000": [12, 25, 49], "67501": 67, "67512181": [21, 35, 58], "67562658": [17, 30, 54], "675627": [17, 30, 54], "675676": 64, "675814": [15, 28, 52], "6759470198675496": 44, "676": 69, "676250": 52, "676373": 57, "67672595": [21, 35, 58], "677": [16, 29, 44, 53], "6770": 19, "6771429181098938": 65, "6772": 68, "677268": 68, "677567": 42, "677579": [15, 28, 52], "677601": [19, 33, 56], "677629": [15, 28, 52], "6778583526611328": 65, "678": [15, 19, 33, 52, 56], "678000": 42, "678689": [18, 32, 55], "679240": 42, "679302": 38, "679478": [16, 29, 53], "679874": 40, "679877": [21, 23, 35, 37, 58, 60, 69], "68": [13, 14, 15, 17, 20, 21, 23, 27, 28, 30, 34, 35, 37, 39, 50, 51, 52, 54, 57, 58, 60, 62, 63, 67, 68, 72], "680000": [12, 25, 49], "6800296306610107": 65, "680657": [16, 29, 53], "681223": [15, 28, 52], "681428": 43, "681566": 46, "681716": 65, "682827": 40, "683015": [22, 36, 38, 59], "683171": [20, 34, 57], "68323": [19, 33, 56], "68339": 67, "684": 40, "684211": [15, 28, 52], "684447": [16, 29, 53], "684960": [16, 29, 53, 54], "685": [19, 42], "685006": 44, "685103e": [21, 35, 58], "68523": 67, "685786": [22, 36, 38, 59], "6858": [18, 32, 55], "686": [16, 29, 53], "686348e": [21, 35, 58], "687": [21, 35, 58], "687055": [20, 34, 57], "687307": [19, 33, 56], "687500": [14, 51], "687504": 65, "688": [19, 33, 56], "6880359361853475": 55, "6880359361853483": [18, 32], "688043475151062": 65, "688135": [19, 33, 56], "688484": 42, "688620": [22, 36], "68896004": 46, "689338": [21, 23, 35, 37, 58, 60, 69], "69": [13, 14, 15, 17, 21, 27, 28, 30, 35, 50, 51, 52, 54, 58, 62, 67, 68], "690": 71, "69027185e": [23, 37, 39, 60], "690402": [19, 33, 56], "690778": [23, 37, 60], "691241": [20, 34, 57], "691617": 65, "691640": [15, 28, 52], "691877": [19, 33, 56], "691924": 62, "69192445": 62, "692131": 43, "692308": [16, 29, 53], "692500": 15, "693": [16, 29, 53], "6932538631346579": 44, "693498": [19, 33, 56], "693590": [17, 30, 54], "6938": [12, 25, 49, 67], "693890": 67, "693898": 67, "693936": [17, 30, 54], "69393613": [17, 30, 54], "694": 44, "69411": [24, 61], "694155": [15, 28, 52], "694334": [22, 36, 38, 59], "6950": [23, 37, 39, 60], "695532": [16, 29, 53], "695783": 65, "696": 44, "696034e": [21, 35, 58], "6962": [16, 29, 53], "6963": [23, 37, 60], "696373": [16, 29, 53], "696429": [20, 34, 57], "696712": 67, "696859": [19, 33, 56], "696875": 52, "696970": [18, 32, 55], "69698010e": [23, 37, 39, 60], "697": [16, 24, 29, 53, 61], "697248": [20, 34, 57], "6973": [16, 29, 53], "698": [16, 29, 53], "698125": 15, "698167": 67, "698206": [21, 35, 58], "698384608345687": [19, 33, 56], "698385": [19, 33, 56], "6984": [24, 40, 61], "698857": [19, 33, 56], "699224": [15, 28, 52], "6993": 42, "699706": 66, "699901396097971": 63, "6th": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "6x6": 77, "7": [1, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 37, 39, 40, 42, 43, 49, 50, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73], "70": [13, 14, 17, 20, 21, 27, 30, 35, 39, 40, 42, 43, 46, 48, 50, 51, 54, 57, 58, 62, 63, 67, 68, 69], "70000": 67, "700000": [19, 67], "700000e": 42, "700855": [20, 34, 57], "701128": 67, "701173": [19, 33, 56], "701186e": [21, 35, 58], "70162085e": [23, 37, 39, 60], "7017": 68, "701863": [19, 33, 56], "702703": [15, 28, 52], "703406": 68, "704": [15, 16, 21, 28, 29, 35, 52, 53, 58], "704099": [17, 30, 54], "7041": 65, "7042": 68, "7043": 68, "7046136400143138": 55, "7046136400143141": [18, 32], "70472": [24, 40, 61], "704969": [19, 33, 56], "705000": [16, 29, 53], "7053": 40, "705470": 65, "705511": [19, 33, 56], "70560276": [17, 30, 54], "705603": [17, 30, 54], "70568": [21, 35, 58], "705696": [15, 28, 52], "705882": [14, 19, 27, 33, 51, 56], "70588235": [14, 27, 51], "705898": [24, 61], "706": 54, "706128": [15, 28, 52], "706444": [20, 34, 57], "706489": 42, "706783": [17, 30, 54], "70678332": [17, 30, 54], "706966": 67, "707681": [15, 28, 52], "707712": 68, "707850": 44, "707899": 62, "70789903": 62, "70799": [19, 33, 56], "708": [16, 19, 29, 33, 53, 54, 56, 59, 76], "708075": [19, 33, 56], "708527": [16, 29, 53], "708978": [19, 33, 56], "709": 22, "709185": [15, 28, 52], "70978": [24, 61], "709874": [19, 33, 56], "709880": [19, 33, 56], "709893": 67, "7099": [24, 40, 61], "71": [12, 13, 14, 17, 18, 20, 21, 25, 27, 30, 32, 35, 49, 50, 51, 54, 55, 57, 58, 62, 67, 68], "710": 22, "710000": [16, 29, 53], "710031": [23, 37, 39, 60], "710526": [15, 28, 52], "710896": [20, 34, 57], "71096": [24, 61], "711": [33, 54, 56], "711077": [16, 29, 53], "711086": [19, 33, 56], "711356": 42, "711717": [19, 33, 56], "711754": [16, 29, 53, 54], "711819": 65, "711852": [24, 40, 61], "71199006": [21, 35, 58], "712": [16, 29, 53], "712074": [19, 33, 56], "71219761": [17, 30, 54], "712198": [17, 30, 54], "712324": [19, 33, 56], "712402": [22, 36, 38, 59], "7129": [19, 33, 56], "7129300520": 42, "713": 54, "71327467": [21, 35, 58], "714": 66, "714077": [16, 29, 53, 54], "714286": [19, 33, 56], "714375": 28, "714402": 57, "714655": 20, "715072": 66, "71517": [19, 33, 56], "7153": 68, "715424": [19, 33, 56], "715728": [20, 34, 57], "715845": 44, "715992": 66, "716157": [20, 34, 57], "716655": [19, 33, 56], "716657": [19, 33, 56], "716792": [20, 34, 57], "716985": [15, 28, 52], "717289": [19, 33, 56], "717391": [19, 33, 56], "717829": [16, 29, 53], "718242": [19, 33, 56], "718266": [19, 33, 56], "718524": 67, "71866979": [21, 35, 58], "718750": 52, "7188": 54, "719": [12, 16, 24, 25, 29, 49, 53, 61], "719056": [22, 36, 38, 59], "719146": 46, "719427e": [21, 35, 58], "719500": [15, 28, 52], "719747": [20, 34, 57], "719915905190645": 42, "72": [13, 14, 15, 20, 21, 27, 28, 34, 35, 50, 51, 52, 57, 58, 67, 68, 74, 77], "720": 19, "7200": [19, 42], "720357": 67, "72036": 67, "720497": [19, 33, 56], "720859": [16, 29, 53], "720893": 68, "720904": 67, "72098474": 46, "7210": [13, 42, 50], "721006": [19, 33, 56], "721008": [19, 33, 56], "721250": 28, "7212512828409687": [18, 32], "7212512828409691": 55, "721616": [19, 33, 56], "721705": [16, 29, 53], "7218": [13, 14, 27, 50, 51, 74], "721818": [24, 40, 61], "721917": 42, "721921": [16, 29, 53], "722": [16, 23, 29, 53], "722241": [19, 33, 56], "722249": [19, 33, 56], "722803": 42, "722873": 42, "723": [16, 29, 53], "72345029": [21, 58], "7234503": 35, "723602": [19, 33, 56], "723613": [15, 28, 52], "723951": 42, "724068": 42, "7242": [13, 42, 50], "724410": 42, "724434": 46, "724458": [19, 33, 56], "724539": 67, "724891": [20, 34, 57], "725": [18, 32, 33, 55, 56], "7250894": 72, "726": [16, 20, 24, 29, 34, 53, 57, 61], "726269": 43, "726412": [16, 29, 53, 54], "726441": 43, "726474": 66, "726573": [19, 33, 56], "726583": [19, 33, 56], "726634": [20, 34, 57], "726659": 42, "7266666666666667": 72, "726788": [21, 35, 58], "727014": 67, "727198": [19, 33, 56], "727273": [15, 16, 28, 52], "727554": [19, 33, 56], "7277854625841886": 68, "727821": [19, 33, 56], "7278214718381631": [19, 33, 56], "727829": [19, 33, 56], "727992": 43, "728": [16, 20, 29, 34, 53, 57], "728235": [16, 29, 53, 54], "7283": [20, 34, 57], "728324": [20, 34, 57], "728777": [15, 28, 52], "729": [19, 33, 56], "729109": 71, "729143": [20, 34, 57], "7292": [24, 40, 61], "729374": 42, "729814": [19, 33, 56], "73": [13, 14, 17, 18, 19, 20, 21, 27, 30, 32, 33, 34, 35, 40, 50, 51, 54, 55, 56, 57, 58, 63, 67, 68], "730025": 42, "7303155587177662": 19, "730383": [20, 34, 57], "730704": 42, "7309347537642059": 33, "731498": 68, "7315": [18, 32, 55], "7315558717766282": 56, "731572": [18, 32, 55], "731583": [15, 28, 52], "73183": 65, "7328": [16, 29, 53], "732919": [19, 33, 56], "733102": [16, 29, 53, 54], "733199": 20, "733333": [14, 16, 29, 51, 53, 54], "733746": [19, 33, 56], "734": [21, 33, 35, 56, 58, 68], "734011": [19, 33, 56], "734048": 42, "734385": [20, 34, 57], "734816": 67, "734986": 42, "735": [21, 35, 58], "735043": [20, 34, 57], "735261": [19, 33, 56], "7352614272253524": [19, 33, 56], "735637": 42, "7356575131416321": 65, "735879": [19, 33, 56], "736285": 57, "7363681793212891": 65, "736498": [19, 33, 56], "736900": [16, 29, 53], "737285": 42, "7379": [13, 42, 50], "738": [16, 21, 27, 29, 35, 53, 58], "738564": 67, "738701": [16, 29, 53, 54], "738715": 68, "738839": [18, 32, 55], "738977": [19, 33, 56], "738984": 33, "739264": [16, 24, 29, 53, 61], "7395977155164125": [19, 33, 56], "739598": [19, 33, 56], "739600": 33, "739938": [19, 33, 56], "74": [13, 14, 16, 17, 18, 19, 20, 21, 27, 29, 30, 32, 33, 34, 35, 40, 50, 51, 53, 54, 55, 56, 57, 58, 63, 76], "740319": 42, "740542": [12, 25, 49], "74084": 19, "740840": 33, "740842": 19, "740844": [19, 56], "741": 68, "741037": 67, "741060": 42, "741250": 52, "741463": [19, 33, 56], "741465": 19, "7418": [23, 37, 39, 60], "741935": 71, "742084": [19, 33, 56], "742086": [19, 33], "742088": [19, 56], "742703": [33, 56], "742981": [20, 34, 57], "742986": 38, "743": [15, 16, 19, 29, 33, 52, 53, 56, 68, 71], "743133": [15, 28, 52], "743135": [20, 34, 57], "743321": [33, 56], "743323": [33, 56], "743324": [19, 56], "743391": [15, 28, 52], "743555": [23, 37, 60], "7436": [13, 14, 27, 50, 51, 74], "743917": [16, 29, 53, 54], "7440": [12, 25, 49], "744201": [20, 34, 57], "744565": 56, "745": 59, "745178": [19, 56], "745925": 42, "746114": [22, 36, 59], "746328": [15, 28, 52], "747": [12, 25, 49], "7472092076": 21, "74720920774": [35, 58], "74798624e": [23, 37, 39, 60], "748": [19, 44], "748510": [20, 34, 57], "748725": 68, "748749e": 56, "748797": [18, 32, 55], "749": 44, "749118": [23, 37, 60], "749326": 40, "75": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 27, 29, 30, 32, 33, 34, 35, 37, 39, 40, 42, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 67, 68, 69, 76], "750": [12, 25, 44, 49], "7500": [21, 35, 58], "750000": [16, 21, 35, 42, 58], "7503": [13, 42, 50], "7504": 71, "750401": 65, "751": [44, 71], "752": [38, 44], "752169": 42, "7524": 67, "752728": 42, "7528662": 46, "753": 44, "753286": [16, 29, 53, 54], "754": [16, 29, 53], "754165": 71, "754386": [20, 34, 57], "754620": 42, "754874": [24, 61], "754938": 42, "755": [14, 68], "755000": [21, 35, 58], "7551": [19, 33, 56], "755364": [15, 28, 52], "755418": [19, 33, 56], "755477": [15, 28, 52], "756": 68, "7562": [12, 25, 49], "75625": 67, "757": [20, 34, 57], "7574257425742574": [19, 33, 56], "75745416": 62, "757545": [21, 35, 58], "757591": 67, "757932": 68, "757985": [22, 23, 36, 37, 38, 39, 59, 60], "758": [22, 23, 36, 37, 38, 39, 59, 60, 68], "758029": 43, "758062e": [21, 35, 58], "758259": 42, "75826": [22, 23, 36, 37, 38, 39, 59, 60], "758514": [19, 33, 56], "7588186": 66, "7588527798652649": 65, "759561": 62, "75956122": 62, "7599": [18, 32, 55], "76": [14, 16, 18, 19, 20, 21, 23, 24, 27, 29, 32, 33, 34, 35, 37, 39, 51, 53, 55, 56, 57, 58, 60, 61, 68], "760": 68, "760000": 38, "760262": [19, 33, 56], "760678": 67, "760966": 42, "76161": [19, 33, 56], "761945e": [21, 35, 58], "762": [51, 68], "7620": [12, 25, 42, 49], "762093e": [21, 35, 58], "76270194": [23, 37, 60], "763": [16, 29, 53], "763480": 42, "7639": [13, 42, 50], "764052": [24, 61], "76470588": [14, 27, 51], "764706": [14, 15, 19, 27, 28, 33, 51, 52, 56], "765": [20, 57], "765591": [20, 34, 57], "765601": [21, 35, 58], "766317e": [21, 35, 58], "766318": 42, "766423": [21, 35, 58], "766430": [15, 28, 52], "767": [21, 23, 35, 37, 39, 58, 60, 69], "767742": [18, 32, 55], "767802": [19, 33, 56], "767819": 67, "767852": [15, 28, 52], "768": [16, 21, 23, 29, 35, 37, 39, 53, 54, 58, 60, 69, 76], "76817313": 38, "768176": 68, "768184": 42, "768279": 69, "768512": [20, 34, 57], "769030": 42, "76908228": 59, "76912071": [22, 36], "769231": [16, 29, 53], "7699221015680298": [22, 36], "77": [13, 14, 17, 18, 20, 21, 26, 27, 30, 32, 34, 35, 50, 51, 54, 55, 57, 58, 63, 67, 68, 73, 79], "770": [13, 42, 50], "770163": 42, "7706532429048965": 59, "770833": 64, "770898": [19, 33, 56], "771": [16, 29, 38, 53], "771969": [15, 28, 52], "772185": 42, "772532": [20, 34, 57], "7728396574320712": 42, "773017": [21, 23, 35, 37, 58, 60, 69], "773125": 28, "7736": [19, 33, 56], "773851": 67, "774261": 67, "774783": 40, "774844": [17, 30, 54], "77484447": [17, 30, 54], "775000": 19, "7750553478074826": 67, "775270": [21, 35, 58], "7752884548630529": 55, "7752884548630534": [18, 32], "775311": [23, 39, 60], "77536150e": [23, 37, 39, 60], "7758": [19, 33, 56], "776": [19, 33, 56], "7763": [16, 24, 29, 53, 61], "776427": 68, "77694295": 59, "77709": [19, 33, 56], "77716165": [22, 36], "777600": 42, "777934": [15, 28, 52], "77812055": 38, "7781845435415525": 67, "779": [16, 24, 29, 53, 61], "779271": [24, 61], "78": [12, 13, 14, 16, 17, 20, 21, 24, 25, 26, 27, 29, 30, 34, 35, 40, 49, 50, 51, 53, 54, 57, 58, 61, 62, 67, 68, 73], "7800": [19, 33, 56], "780000": [22, 36, 59], "780296": [21, 35, 58], "780298": [21, 35, 58], "780316": [21, 35, 58], "780497": [21, 35, 58], "78058051e": [23, 37, 39, 60], "780745e": 33, "780864": [20, 34, 57], "781": [16, 19, 29, 53], "781004": [15, 28, 52], "781531": [20, 34, 57], "7816": [21, 35, 58], "781975": 43, "782183": [21, 35, 58], "782219": [15, 28, 52], "78260383": 38, "7827": [20, 34, 57], "783282": [19, 33, 56], "783582": [15, 28, 52], "783784": 64, "783789": [15, 28, 52], "784424": [18, 32, 55], "784573": [24, 61], "785": 54, "785105": [21, 35, 58], "785108": [21, 35, 58], "785134": [21, 35, 58], "78521263": 65, "785399": [21, 35, 58], "785483": 67, "785714": [16, 29, 53], "78586472": [22, 36], "786115": [24, 61], "78617028": 59, "7862": 46, "786555": [21, 35, 58], "787": [16, 29, 53], "787574": [21, 35, 58], "787879": [15, 18, 28, 32, 52, 55], "787933": [21, 35, 58], "788": 51, "788374": 66, "788647472858429": 65, "7887": [23, 37, 39, 60], "7891381897690047": 55, "7891381897690053": [18, 32], "789436": [16, 29, 53], "789657": 67, "79": [13, 14, 16, 17, 18, 20, 21, 27, 29, 30, 32, 35, 40, 50, 51, 53, 54, 55, 57, 58, 67, 68, 74], "790": [20, 34, 57], "790000": [16, 29, 53], "79041": [21, 35, 58], "790481e": 44, "790521": 42, "790721": 69, "790731": [18, 32, 55], "791017": 68, "791467": [16, 29, 53], "792": 72, "792023": [23, 37, 39, 60, 69], "79250": [16, 29, 53], "792500": 15, "792577": [21, 35, 58], "792603": [15, 28, 52], "792828": [21, 35, 58], "793": [24, 61], "793243": [16, 29, 53], "79378": [20, 34, 57], "7938": 54, "794": 68, "794118": [15, 28, 52], "794190": 46, "794236": [16, 29, 53], "794820": [16, 29, 53], "795": [14, 15, 19, 33, 52, 56], "79500e": [15, 52], "7951": [19, 33, 56], "795155989041776": 21, "7951559890417761": [35, 58], "795902": 67, "796": [16, 29, 53], "7964215270662811": 55, "7964215270662817": [18, 32], "797": [16, 29, 53], "797355": [16, 29, 53, 54], "7978563117812038": [16, 29, 53], "798": [16, 29, 53], "7982": [15, 28, 52], "7986546": [21, 35, 58], "799291": 40, "799983": [15, 28, 52], "79998417": 72, "7f688092391a": 66, "7l": 29, "7pm": [24, 40, 61], "7th": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "8": [1, 9, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75], "80": [12, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 37, 39, 40, 43, 44, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 67, 68, 69, 73], "800": [12, 19, 25, 27, 33, 44, 49, 51, 56, 65, 77], "800000": [19, 33, 56, 67], "8001": [18, 32, 55], "800190": [15, 28, 52], "80062924": [15, 28, 52], "800k": 69, "801219e": [21, 35, 58], "801666": [20, 34, 57], "801863": [15, 28, 52], "802502": [24, 61], "802902": [21, 35, 58], "802987": [15, 28, 52], "803": [15, 16, 28, 29, 52, 53, 71], "803617": [20, 34, 57], "804": [15, 28, 52, 68, 71], "804818": [16, 29, 53, 54], "80482065": [17, 30, 54], "804821": [17, 30, 54], "805198": [21, 35, 58], "805342": 67, "805414": 43, "805970": [15, 18, 28, 32, 52, 55], "806": 54, "8062": [13, 42, 50], "806899": 66, "8076": [21, 35, 58], "807684": [15, 28, 52], "807735": [20, 34, 57], "8078": [12, 25, 49], "808": 68, "8080": [13, 42, 50], "808208": [20, 34, 57], "808958": [15, 28, 52], "809": [16, 29, 53], "8098": 68, "81": [13, 14, 15, 17, 18, 19, 20, 21, 23, 27, 28, 30, 32, 33, 34, 35, 37, 39, 42, 50, 51, 52, 54, 55, 56, 57, 58, 60, 62, 67, 68, 69], "810073": [21, 23, 35, 37, 39, 58, 60], "810098": [24, 40, 61], "810368": [15, 28, 52], "81071706": [19, 33, 56], "810811": 64, "8112": [12, 25, 49], "812272": [21, 35, 58], "812363": [21, 35, 58], "812500": [14, 51], "812593": 66, "812875": 68, "813": [16, 29, 53], "813586": [20, 34, 57], "815669": [20, 34, 57], "816": 38, "816200": 43, "8162831858407079": 70, "816717791411044": 68, "817": [22, 36, 38, 59], "817034": 71, "817558": [16, 29, 53, 54], "8180": [16, 29, 53], "818041": 68, "818868": [16, 29, 53], "819152": [15, 28, 52], "819213": 68, "8195": [18, 32, 55], "819549": [15, 28, 52], "819584": [15, 28, 52], "81970188": [17, 30, 54], "819702": [17, 30, 54], "82": [13, 17, 19, 20, 26, 30, 31, 33, 50, 54, 56, 57, 63, 67, 68], "820": [15, 28, 52], "820033": [21, 35, 58], "820143": [18, 32, 55], "82025568e": [23, 37, 39, 60], "820564": [21, 35, 58], "821040": [23, 37, 39, 60], "821327": 65, "821807": [21, 35, 58], "8219": [16, 29, 53], "822": 46, "8221": 54, "8225": 71, "82273995": [17, 30, 54], "822740": [17, 30, 54], "823": 19, "823280e": 19, "823364": 44, "82336432": 44, "823511": [20, 34, 57], "823529": [14, 15, 18, 27, 28, 32, 51, 52, 55], "82352941": [14, 27, 51], "823543": [24, 61], "8244": 46, "824849": [20, 34, 57], "824884": [21, 35, 58], "825": [16, 29, 53], "825123": [24, 61], "8253": [15, 28, 52], "825306": [19, 33, 56], "825470": 68, "825697": [21, 35, 58], "826142": [21, 35, 58], "826203": [18, 32, 55], "826216": [21, 35, 58], "82630": 46, "826513": 67, "82652929": 46, "826553": [21, 35, 58], "82670": 67, "826739": [21, 35, 58], "826758": [21, 35, 58], "826760": [21, 35, 58], "827039": [18, 32, 55], "827068": [18, 32, 55], "827130": [20, 34, 57], "827261": [21, 35, 58], "827842": [18, 32, 55], "827907": [19, 33, 56], "828": [42, 44], "8280229354283182": [21, 35, 58], "82804": [19, 33, 56], "828332": [21, 23, 35, 37, 58, 60, 69], "828358": [15, 28, 52], "828405": 67, "828682": [19, 33, 56], "82869879": 65, "828891": [19, 33, 56], "828976": [19, 33, 56], "829": 44, "83": [13, 14, 17, 19, 20, 26, 27, 30, 33, 34, 40, 47, 50, 51, 54, 56, 57, 63, 64, 65, 67, 68, 73], "830": 44, "830382": [20, 34, 57], "8304": 46, "830712e": [21, 35, 58], "831": 44, "831135": [15, 28, 52], "831611": [21, 23, 35, 37, 39, 58, 60], "831989": [19, 33, 56], "832": [16, 29, 44, 46, 53], "8320": 46, "832320": [18, 32, 55], "832370": [20, 34, 57], "832866": [21, 35, 58], "833": [15, 19, 33, 44, 46, 52, 56], "83320": 67, "8334": [23, 37, 46, 60], "833913": 42, "834": 44, "8340": [15, 28, 52], "834109": [19, 33, 56], "834356e": [21, 35, 58], "83437": [21, 35, 58], "834455": [15, 28, 52], "835": 44, "835563": 40, "8356": [23, 37, 39, 60], "835651": [19, 33, 56], "835749": [21, 23, 35, 37, 39, 58, 60], "835876": 42, "83603": [21, 23, 35, 39, 58, 60], "8361313": [21, 35, 58], "836189": [15, 28, 52], "836735": [20, 34, 57], "836878e": [21, 35, 58], "836880e": [21, 35, 58], "837": [38, 46], "837022e": [21, 35, 58], "837838": [15, 28, 52], "837848": [15, 28, 52], "838": [15, 19, 33, 52, 56], "83848729e": 66, "83876": [19, 33, 56], "8388866943476283": 55, "8388866943476289": [18, 32], "838951": [21, 35, 58], "8389756947416362": 55, "8389756947416367": [18, 32], "839225": [21, 35, 58], "84": [13, 14, 17, 26, 27, 30, 42, 50, 51, 54, 67, 68, 72, 73], "840": [16, 29, 53], "84002795": [17, 30, 54], "840028": [17, 30, 54], "840074": [14, 27, 51], "840183": [21, 35, 58], "840492": [21, 23, 35, 37, 39, 58, 60, 69], "84062193": [23, 37, 60], "841": [21, 35, 58], "841208": [19, 33, 56], "8418": 46, "841886": [19, 33, 56], "841983": [19, 33, 56], "842": [16, 29, 46, 53], "842028": [20, 34, 57], "842064": 68, "842105": [15, 28, 52], "843": [22, 36, 46, 59], "843281": [23, 37, 60], "843284": [15, 18, 28, 32, 52, 55], "843842": [16, 29, 53, 54], "843992": [21, 23, 35, 37, 39, 58, 60], "844": 38, "844409": [17, 30, 54], "84440919": [17, 30, 54], "844444": 16, "844921": 62, "845": [19, 33, 56], "846154": [16, 29, 53, 71], "8462": [24, 40, 61], "846260e": [21, 35, 58], "846650": [21, 35, 58], "84679073": [15, 28, 52], "84698489": 66, "847": [38, 39], "847178": [20, 34, 57], "847287": [19, 33, 56], "8475": 67, "8475374359985492": 38, "84772": [20, 34, 57], "847799": [19, 33, 56], "847808": [20, 34, 57], "8478316682480326": 67, "848": [22, 23, 36, 37, 59, 60], "8481": 71, "848214": 16, "84893192": [19, 33, 56], "849": [22, 23, 36, 37, 38, 39, 59, 60], "849102e": [35, 58], "849438e": [21, 35, 58], "849612": [19, 33, 56], "85": [13, 14, 17, 19, 20, 21, 22, 23, 24, 26, 27, 30, 34, 35, 36, 37, 38, 39, 40, 48, 50, 51, 54, 57, 58, 59, 60, 61, 67, 68, 73], "850": [12, 22, 23, 25, 36, 37, 38, 39, 49, 59, 60], "8502": [19, 33, 56], "850283": 67, "850503": [19, 33, 56], "850746": [15, 28, 52], "851460": [21, 35, 58], "851493": 40, "851852": [18, 32, 55], "852": [68, 71], "852053": [19, 33, 56], "852104": [21, 35, 58], "852941": [18, 32, 55], "853125": 52, "853399": [20, 34, 57], "854129": [21, 35, 58], "854167": 64, "854500": 68, "8546143543902771": 68, "854744525547446": 68, "854749": 67, "85545875": [15, 28, 52], "85597188": [17, 30, 54], "855972": [17, 30, 54], "856": [33, 56], "856175": [16, 29, 53], "856589": [19, 33, 56], "856722": 43, "857": [21, 35, 58], "857457": 43, "857874": [19, 33, 56], "858": [18, 32, 55], "8580": [16, 29, 53, 54, 76], "858209": [15, 18, 28, 32, 52, 55], "858240": 40, "858915": [19, 33, 56], "859": [22, 36, 59], "859318": [21, 35, 58], "859439": 62, "85943906": 62, "859455": 68, "85969": [19, 33, 56], "859799": [19, 33, 56], "86": [13, 15, 17, 18, 19, 20, 24, 26, 30, 32, 33, 34, 40, 50, 52, 54, 55, 56, 57, 61, 67, 68], "860": [20, 23, 34, 37, 38, 57, 60], "86000e": [15, 52], "8601643854446082": [21, 35, 58], "860677": [20, 34, 57], "861": [16, 29, 53], "86102": 67, "861157": 69, "861348": [19, 33, 56], "862432": [21, 35, 58], "862552": [16, 29, 53], "8625888648969532": 68, "86267067": [17, 30, 54], "862671": [17, 30, 54], "862855": 40, "862997": [24, 61], "863014": [18, 32, 55], "863889": 67, "863941": [21, 35, 58], "864": [22, 36, 38, 59], "86400": 67, "8641864337292489": 68, "864205": [23, 39, 60], "864292": 43, "864849": 40, "865562": 68, "8661": 71, "866110": [18, 32, 55], "866667": [14, 20, 34, 51, 57], "866980": [21, 35, 58], "867434": 66, "867558": [24, 61], "868003": [21, 35, 58], "86820176": 46, "868281": [21, 35, 58], "868305": [21, 35, 58], "868308": [21, 35, 58], "869": 19, "869077": [17, 30, 54], "86907725": [17, 30, 54], "869094": [19, 33, 56], "8691": 54, "869387e": 19, "869531": [15, 28, 52], "869964": [19, 33, 56], "87": [13, 16, 17, 20, 29, 30, 50, 53, 54, 57, 67, 68], "870": [22, 23, 36, 37, 38, 39, 59, 60], "870503": 66, "871": [22, 33, 36, 38, 56, 59], "871094": 67, "8711": [20, 34, 57], "871200": 42, "872": [22, 23, 36, 37, 38, 39, 59, 60], "872093": [19, 33, 56], "872603": 66, "872722908439952": [23, 37, 39, 60], "8727229084399575": [23, 37, 39, 60], "872961060": [21, 35, 58], "8729610607986": [21, 35, 58], "873": [36, 38, 59], "8731": [21, 23, 35, 37, 58, 60, 69], "873103": [15, 28, 52], "873182": 67, "873356": [15, 28, 52], "873643": [19, 33, 56], "873704": [21, 35, 58], "874062": [17, 30, 54], "87406235": [17, 30, 54], "874305": 67, "874516": [19, 33, 56], "874532": [21, 35, 58], "874767e": [21, 35, 58], "874962": 43, "875": [20, 57], "8750": [16, 24, 29, 53, 61], "875000": [14, 16, 51], "876065": [19, 33, 56], "876540": 68, "876566e": 42, "876574": [16, 29, 53, 54], "876668": 40, "87681182": 65, "877": 19, "877046": [24, 40, 61], "877390": [23, 39, 60], "877519": [19, 33, 56], "877551": [20, 34, 57], "877887": 46, "878183": [15, 28, 52], "87844893": [21, 35, 58], "87849316": [18, 32, 55], "879": [16, 29, 53], "87907": [19, 33, 56], "879938": [19, 33, 56], "88": [13, 14, 16, 17, 18, 20, 24, 27, 29, 30, 32, 34, 40, 50, 51, 53, 54, 55, 57, 61, 68, 76], "880": [24, 40, 61], "8801": 65, "880348": [19, 33, 56], "880831": 67, "881395": [19, 33, 56], "881720": [20, 34, 57], "883138": [19, 33, 56], "884586": [19, 33, 56], "885": [12, 25, 49, 54], "885044": [21, 23, 35, 37, 58, 60, 69], "8859": [31, 45, 46], "885968": 68, "886047": [19, 33, 56], "886759": [18, 32, 55], "887": [22, 36, 38, 59], "887017": [20, 34, 57], "887159": 67, "8873": [20, 34, 57], "887324": [20, 34, 57], "887343": [15, 28, 52], "887597": [19, 33, 56], "887701": [20, 34, 57], "8878117": [17, 30, 54], "887812": [17, 30, 54], "888": [22, 23, 33, 36, 37, 38, 39, 56, 59, 60], "888066": [23, 37, 60], "888372": [19, 33, 56], "888513": [20, 34, 57], "888811": [19, 33, 56], "888889": [16, 18, 29, 32, 53, 55], "888961": [23, 37, 60], "889086": [21, 35, 58], "889147": [19, 33, 56], "889429": 67, "889921": 67, "89": [13, 14, 17, 20, 26, 27, 30, 34, 40, 50, 51, 54, 57, 63, 67, 68, 73], "890": [22, 36, 38, 44, 59], "890456": 42, "890457": [21, 35, 58], "890933": 68, "891001": [20, 34, 57], "891557": [19, 33, 56], "892476": [20, 34, 57], "892477": [15, 28, 52], "892491": [16, 29, 53], "89270": [24, 61], "892733": 67, "892961": [24, 61], "893000": [16, 29, 53], "893260": [17, 30, 54], "8937442459553657": [23, 37, 39, 60], "894": [16, 29, 53], "894587": 69, "894960": 42, "895": [36, 38, 59], "89515383": 44, "895154": 44, "895349": [19, 33, 56], "895541": [21, 35, 58], "89572": 67, "895833": [20, 34, 57], "895963": [18, 32, 55], "897010": [16, 29, 53, 54], "89706451e": [23, 37, 39, 60], "897674": [19, 33, 56], "898": [23, 37, 39, 60], "898016": [19, 33, 56], "898243": 43, "898703e": [21, 35, 58], "899": [16, 22, 29, 33, 36, 38, 53, 54, 56, 59, 76], "8994": [23, 37, 39, 60], "8997": [21, 35, 58], "899736": 42, "899969": 67, "8m": 66, "8th": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "9": [1, 4, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 73, 80], "90": [8, 12, 13, 14, 15, 17, 20, 21, 25, 26, 27, 28, 30, 34, 35, 40, 47, 48, 49, 50, 51, 52, 54, 57, 58, 63, 64, 67, 68, 73], "900": [17, 19, 20, 30, 33, 54, 56, 57], "90000": 67, "900000": [14, 27, 51, 67], "900000e": 42, "900662": [14, 27, 51], "901": 36, "901085": [18, 32, 55], "9010852321946792": 55, "9010852321946795": [18, 32], "901262": 67, "90159483": 62, "901595": 62, "902343": 43, "902401": [19, 33, 56], "903101": [19, 33, 56], "903422": 43, "904": [15, 19, 28, 33, 52, 56], "90403853": [17, 30, 54], "904039": [17, 30, 54], "904226": [15, 28, 52], "904565": 43, "9047619047619048": [13, 26, 50], "904902": 66, "904930e": 42, "905": [15, 16, 28, 29, 52, 53], "905000": 28, "905327": 67, "906667": [14, 27, 43, 51], "90669": [24, 61], "906865": [14, 27, 51], "907": 68, "907143": 71, "907595": 67, "908": [16, 29, 53], "908140": [16, 29, 53, 54], "908215": [21, 35, 58], "909091": [16, 29, 53], "90982": [24, 61], "91": [13, 14, 16, 17, 19, 20, 24, 26, 27, 29, 30, 33, 34, 42, 50, 51, 53, 54, 56, 57, 61, 62, 67, 73], "910": [13, 17, 30, 42, 50], "9100": 67, "910018": [21, 35, 58], "910174": [21, 35, 58], "9103": 67, "910456e": [21, 35, 58], "91063776": [23, 37, 60], "910714": 71, "9108334653214172": 42, "910843": [21, 35, 58], "911": [22, 44], "911615": [21, 35, 58], "911846": [21, 35, 58], "912": [16, 29, 53], "912395": [23, 37, 39, 60], "913333": [14, 27, 43, 51], "913767": [21, 35, 58], "913849": [21, 35, 58], "914003": [23, 37, 39, 60], "914451894267": [21, 35, 58], "914585": [23, 37, 39, 60], "91515735": [21, 35, 58], "915714e": [21, 35, 58], "915952": [21, 35, 58], "916254": [15, 28, 52], "916347": 43, "916722": [23, 37, 39, 60], "917526": [20, 34, 57], "917837": [20, 34, 57], "918": [22, 36, 38, 42, 59], "918124": [20, 34, 57], "918191": 66, "9182": 67, "918224": 44, "91835": 46, "919198": [23, 37, 39, 60], "9196": [12, 25, 49], "92": [13, 14, 17, 20, 26, 27, 30, 34, 50, 51, 54, 57, 63, 66, 67, 68, 73], "920000": [14, 27, 43, 51], "9203": [19, 33, 56], "920305": [24, 40, 61], "920462": [23, 37, 39, 60], "920950": 40, "9212": 16, "92120500e": 72, "921422": 68, "921435": 43, "921438": [21, 35, 58], "921850": [21, 35, 58], "92195464": [23, 37, 39, 60], "921955": [23, 37, 39, 60], "922": 54, "923077": [20, 34, 57], "923283": [16, 29, 53, 54], "923432": [23, 37, 39, 60], "924485": [24, 40, 61], "9245": [14, 18, 27, 32, 51, 55], "925272e": [21, 35, 58], "925288e": [21, 35, 58], "925593": [15, 28, 52], "925768": [20, 34, 57], "926657": [21, 35, 58], "926667": 43, "926733e": [21, 35, 58], "926829": [20, 34, 57], "928": [19, 33, 56], "92809": [24, 61], "92852376": [15, 28, 52], "929": [22, 33, 56], "9295": [19, 33, 56], "93": [13, 14, 17, 18, 26, 27, 30, 32, 33, 40, 50, 51, 54, 55, 56, 62, 67, 68, 73], "930000": [16, 29, 53], "930062": 42, "930123": [15, 28, 52], "930561": [15, 28, 52], "9308647034083802": 42, "931439e": [21, 35, 58], "931786": [18, 32, 55], "931896": 42, "932": [16, 29, 53], "932070": 68, "932124": [15, 28, 52], "932143": 71, "93232161": 46, "93279": 67, "933020": 40, "933333": 43, "9336": [16, 29, 53], "934": 44, "934205": [15, 28, 52], "934269": [16, 29, 53, 54], "934783": [20, 34, 57], "9351": [24, 40, 61], "935512": 68, "935802": [15, 28, 52], "93665": 67, "937429": 69, "9375": [14, 27, 51], "937500": [14, 17, 27, 30, 51, 54], "938": [20, 34, 57], "938201": 42, "9383": [15, 18, 28, 32, 52, 55], "93869659": [17, 30, 54], "938697": [17, 30, 54], "939006": [20, 34, 57], "9391": [21, 35, 58], "939394": [15, 18, 28, 32, 52, 55], "939805": 42, "94": [13, 14, 16, 17, 18, 19, 20, 21, 26, 27, 29, 30, 32, 33, 34, 35, 50, 51, 53, 54, 55, 56, 57, 58, 67, 73, 76], "940000": 43, "9401": 67, "9406": [13, 14, 27, 50, 51, 74], "941": 68, "9410": 42, "941176": [14, 17, 27, 30, 51, 54], "94117647": [14, 27, 51], "942": 44, "943609": [24, 40, 61], "944": [12, 25, 49], "944092": [20, 34, 57], "944354": 54, "945000": 43, "945968": 43, "946667": 43, "946783": [15, 28, 52], "947": [16, 19, 29, 33, 53, 56, 71], "9471": [19, 33, 56], "948482": 68, "94888": [20, 34, 57], "949": [16, 17, 29, 30, 53], "9490": [16, 29, 53], "9492": [21, 35, 58], "94933723": [21, 35, 58], "94959681": [17, 30, 54], "949597": [17, 30, 54], "95": [13, 14, 17, 20, 26, 27, 30, 34, 50, 51, 54, 57, 63, 67, 68, 69], "950000": [16, 29, 53], "950088": [24, 61], "9505": [23, 37, 60], "950564": [24, 40, 61], "9506": [23, 37, 60], "950627": 40, "950696": 68, "950733": [15, 28, 52], "951": 19, "951294": [21, 35, 58], "951574": [24, 61], "951644": [24, 40, 61], "951667": 43, "951669": [24, 61], "951696": [15, 28, 52], "953": [22, 36, 59], "9530973451327434": 70, "953333": 43, "954": 38, "95511263": [15, 28, 52], "955113": [15, 28, 52], "9558": 67, "956": [16, 29, 53], "956966": [24, 61], "957075": [24, 61], "9573": 67, "9576": [12, 25, 49], "957886": 66, "957919": [15, 28, 52], "957987": [15, 28, 52], "9583333333333334": 66, "958393": [16, 24, 29, 53, 61], "95886206e": 66, "959": [16, 29, 44, 53], "959139": [23, 37, 39, 60], "959402e": [21, 35, 58], "959870": [20, 34, 57], "959873": 68, "96": [13, 17, 18, 19, 20, 24, 30, 32, 33, 34, 40, 50, 54, 55, 56, 57, 61, 67], "960": [17, 18, 30, 32, 44, 55], "960000e": 44, "961": 44, "961106": 57, "961109802000133": 63, "961404": [16, 29, 53, 54], "961498": [21, 23, 35, 37, 39, 58, 60, 69], "961576": 20, "961771": [18, 32, 55], "961898": [18, 32, 55], "962": 44, "962660": 20, "962776": 57, "963": 44, "963024": 42, "96319": 67, "96320": 67, "96321": 67, "96322": 67, "96323": 67, "96325": 67, "963333": 43, "963689": [24, 40, 61], "964": 44, "96554": [24, 61], "9661": [21, 35, 58], "966131": [16, 29, 53, 54], "9664": [13, 14, 27, 50, 51, 74], "966491": 57, "966667": 43, "966812": 42, "967102": 57, "967907": [20, 34, 57], "968": [16, 29, 53], "968233": [24, 40, 61], "96833": 65, "968333": 43, "96834506": [15, 28, 52], "968493": 68, "968514e": [21, 35, 58], "968620": 20, "96875": 66, "969048e": [35, 58], "9691": [21, 35, 58], "9692602666681306": [18, 32, 55], "96965253": [23, 37, 39, 60], "969653": [23, 37, 39, 60], "97": [13, 14, 16, 17, 18, 19, 23, 27, 30, 32, 33, 37, 39, 50, 51, 54, 55, 56, 60, 63, 67, 68], "970518": [20, 34, 57], "970683": [24, 40, 61], "971": 54, "971805": 40, "97203586": [17, 30, 54], "972036": [17, 30, 54], "97217": 67, "972198": [19, 33, 56], "97223953": [17, 30, 54], "972240": [17, 30, 54], "972379": 44, "97237936": 44, "972440": [20, 34, 57], "97253": 67, "9730": 54, "973225": [20, 34, 57], "973280": [17, 30, 54], "97328024": [17, 30, 54], "973294": 44, "973333": 43, "973482e": 56, "973750": [15, 52], "974": [16, 29, 53], "974183": 43, "974480": [24, 40, 61], "974531": 43, "9748": [18, 32, 55], "974801e": [21, 35, 58], "975104": 44, "975895": 67, "976": [16, 20, 22, 29, 34, 36, 38, 53, 57, 59], "97601304": 46, "976667": 43, "977": [16, 29, 53, 67], "977278": [24, 61], "9773": [13, 14, 15, 27, 28, 50, 51, 52, 74], "978": [18, 32, 55], "9781449369880": 67, "9781789957211": 66, "97823755": [18, 32, 55], "9785299": 65, "978738": [24, 61], "979": [22, 23, 36, 37, 38, 39, 59, 60], "979562": 68, "98": [13, 16, 17, 18, 21, 23, 29, 30, 32, 35, 37, 39, 50, 53, 54, 55, 58, 60, 62, 65, 67, 68, 69], "980": 67, "980000": 43, "98001": 42, "98007": [12, 25, 49], "98010": 42, "98024": 42, "98027": 42, "98028": [13, 42, 50], "98033": 42, "98038": 42, "98039": 42, "98045": [12, 25, 49], "98052": [12, 25, 42, 49], "98055": [12, 25, 49], "980634": 68, "98065": 42, "98072": [12, 25, 49], "98074": [13, 42, 50], "98075": [12, 25, 49], "98077": 42, "9808": [18, 32, 55], "980962": 43, "98102": 42, "98103": 42, "98107": [12, 25, 49], "98112": [12, 25, 49], "98115": 42, "98116": [12, 25, 49], "98117": 42, "98118": 42, "981195": 67, "98125": [13, 42, 50], "98136": [13, 42, 50], "98144": 42, "98146": 42, "98148": 42, "981643": 42, "981735": [18, 32, 55], "98178": [13, 42, 50], "98199": 42, "982": 54, "982184": [19, 33, 56], "982570": 68, "983": 66, "983333": 43, "983340": 42, "9837": [14, 18, 27, 32, 51, 55], "984": [19, 33, 56], "984653": [18, 32, 55], "984664": [21, 35, 58], "985000": 43, "985283": [19, 33, 56], "9854": [13, 14, 18, 27, 32, 50, 51, 55, 74], "985457": 68, "98565": 46, "985816": [14, 51], "986047": [19, 33, 56], "9862": 71, "986207": [19, 33, 56], "986803": 40, "987": [19, 33, 56, 66], "987062": [21, 35, 58], "987597": [19, 33, 56], "9876": [22, 23, 36, 37, 38, 39, 59, 60], "987681": [24, 40, 61], "988": [24, 40, 61], "9881": [13, 14, 27, 50, 51, 74], "988333": 43, "988381": [19, 33, 56], "988841": [19, 33, 56], "988901": [21, 35, 58], "989": [13, 26, 50], "989147": [19, 33, 56], "989156": [19, 33, 56], "989443": 68, "989922": [19, 33, 56], "989973": [18, 32, 55], "99": [13, 14, 16, 17, 19, 20, 27, 29, 30, 33, 34, 44, 47, 50, 51, 53, 54, 56, 57, 67, 78], "990631": 67, "990754": 67, "991": 46, "9912": [15, 18, 28, 32, 52, 55], "9915": 67, "991667": 43, "991810": 42, "991966": 68, "992": [33, 51, 56], "992220": 42, "992254": [19, 33, 56], "99240562": [23, 37, 39, 60], "992406": [19, 33, 56], "992569": 44, "9926": 54, "992857": [14, 51], "992908": 51, "993023": [19, 33, 56], "993029": [19, 33, 56], "993065": 68, "9931": [13, 14, 27, 50, 51, 74], "993333": 43, "9934531067299874": [18, 32, 55], "99355746": 46, "993666": [23, 37, 60], "993969": [21, 23, 35, 37, 39, 58, 60, 69], "994": [12, 25, 49], "994266": [19, 33, 56], "994574": [19, 33, 56], "994764": 67, "995": [24, 40, 61, 66], "9950": [24, 40, 61], "9951": [13, 14, 27, 50, 51, 74], "99515": 67, "995434": [21, 35, 58], "996424": 42, "996487": 42, "996588e": [35, 58], "996765": [23, 39, 60], "996788": 68, "996820": 68, "996899": [19, 33, 56], "99744241e": [23, 37, 39, 60], "9977957422135844": [23, 37, 60], "9977957422135846": 39, "998": [20, 34, 47, 57, 68, 71], "9983": [20, 34, 57], "998302": [20, 34, 57], "998370": 42, "998440": 42, "99845": [19, 33, 56], "998451": [19, 33, 56], "998562": 38, "999": [18, 32, 55, 71], "99907": [19, 33, 56], "999122": [20, 34, 57], "9991338290544213": 42, "999147": [20, 34, 57], "999172": [20, 34, 57], "999178": 42, "999183": [20, 34, 57], "999185": [20, 34, 57], "999192": [20, 34, 57], "999210": [20, 34, 57], "999213": 42, "999214": [20, 34, 57], "999221": [20, 34, 57], "999223": [20, 34, 57], "999225": [19, 33, 56], "999254": [20, 34, 57], "999298": [20, 34, 57], "999317": [20, 34, 57], "99931882": [21, 35, 58], "999335": [20, 34, 57], "999438": 42, "9994394006711425": 42, "999480": 42, "999518": 42, "999535": [19, 33, 56], "999539": 42, "999544": 42, "999545": 42, "999546": 42, "999558": 42, "999562": 42, "999567": 42, "999577": 67, "999622": [16, 29, 53], "99975": 46, "99980": 46, "9999": [12, 25], "9999999999999998": 39, "9am": [24, 40, 61], "9th": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "A": [0, 1, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 43, 44, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 72, 73, 80], "AND": [0, 21, 35, 48, 58], "AS": 0, "And": [12, 13, 19, 21, 25, 33, 35, 48, 49, 50, 56, 58, 65, 67, 68, 69, 74, 75], "As": [4, 14, 17, 19, 21, 22, 23, 27, 28, 30, 33, 35, 36, 37, 38, 48, 51, 54, 56, 58, 59, 60, 64, 67, 68, 69, 70, 72, 75, 77, 79, 80], "At": [4, 12, 14, 18, 20, 22, 24, 25, 32, 34, 36, 38, 40, 42, 44, 47, 49, 51, 55, 57, 59, 61, 62, 66, 67], "BE": [0, 65], "BUT": [0, 8], "BY": [0, 1], "Be": [7, 12, 15, 23, 25, 28, 37, 39, 52, 60, 69, 70, 73, 75], "Being": 66, "But": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 75, 77, 79, 80], "By": [11, 12, 14, 15, 17, 20, 22, 25, 27, 28, 30, 34, 36, 38, 40, 43, 49, 51, 52, 54, 57, 59, 62, 65, 66, 68, 69, 75, 77], "FOR": 0, "For": [0, 1, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 77, 78, 79, 80], "IN": [0, 14, 18, 27, 32, 51, 55], "IT": [18, 32, 55], "If": [4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80], "In": [1, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80], "Ines": 71, "It": [2, 4, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 75, 77, 79, 80], "Its": 68, "NEAR": [16, 24, 29, 40, 53, 54, 61, 76], "NO": 0, "NOT": [0, 8, 17, 18, 30, 32, 54, 55], "No": [0, 12, 13, 21, 22, 23, 24, 25, 26, 35, 36, 37, 38, 39, 40, 44, 48, 49, 50, 58, 59, 60, 61, 63, 67, 68, 69, 73], "Not": [20, 21, 22, 23, 24, 34, 35, 36, 37, 38, 39, 40, 57, 58, 59, 60, 61, 62, 64, 67, 68, 78], "OF": 0, "OR": [0, 8, 21, 35, 48, 58], "Of": [9, 17, 19, 30, 33, 54, 56], "On": [4, 7, 12, 16, 17, 19, 20, 21, 22, 23, 24, 25, 29, 30, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 48, 49, 53, 54, 56, 57, 58, 59, 60, 61, 63, 66, 68, 69, 71], "One": [5, 8, 13, 14, 17, 18, 19, 20, 23, 26, 27, 30, 31, 32, 33, 34, 37, 39, 44, 45, 46, 47, 50, 51, 54, 55, 56, 57, 60, 62, 63, 68, 73, 78], "Or": [15, 17, 19, 28, 33, 43, 52, 54, 56, 69, 75], "Such": [6, 64, 67], "THE": [0, 14, 27, 51], "TO": [0, 65], "That": [13, 14, 16, 18, 19, 21, 22, 23, 26, 27, 29, 32, 33, 35, 36, 37, 38, 39, 48, 50, 51, 53, 55, 56, 58, 59, 60, 62, 63, 64, 65, 67, 68, 69, 70, 78], "The": [0, 2, 5, 7, 8, 11, 12, 13, 15, 16, 17, 20, 21, 23, 25, 26, 28, 29, 30, 31, 34, 35, 37, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80], "Their": 5, "Then": [13, 18, 22, 26, 32, 36, 38, 39, 46, 50, 55, 59, 62, 67, 70, 78], "There": [1, 2, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 80], "These": [4, 10, 13, 14, 15, 18, 20, 21, 22, 23, 24, 26, 27, 28, 32, 35, 36, 37, 38, 39, 40, 48, 50, 51, 52, 55, 57, 58, 59, 60, 61, 62, 64, 67, 69, 79], "To": [8, 10, 12, 13, 14, 15, 16, 17, 18, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 35, 36, 38, 40, 43, 44, 46, 49, 50, 51, 52, 53, 54, 55, 58, 59, 61, 63, 65, 66, 67, 69, 70, 71, 75, 77, 79, 80], "WITH": 0, "Will": [20, 34, 57, 68, 71, 73, 78], "With": [0, 12, 13, 15, 16, 17, 18, 19, 21, 23, 24, 25, 26, 28, 29, 30, 32, 33, 35, 37, 39, 40, 43, 49, 50, 52, 53, 54, 55, 56, 58, 60, 61, 62, 63, 64, 66, 68, 72, 75], "_": [22, 38, 59, 65, 66, 68, 71], "__array__": 44, "__call__": [17, 30, 54], "__class__": [18, 32, 55, 67], "__finalize__": 68, "__getitem__": [29, 51, 53, 71], "__name__": [18, 32, 55, 67], "__sklearn_tags__": 44, "__testing_word2vec": 65, "_array_api": 44, "_asarray_with_ord": 44, "_assert_all_finit": 44, "_assert_all_finite_element_wis": 44, "_astype_nansaf": 68, "_base": 44, "_california_housing_dataset": [18, 32, 55], "_call_func_on_transform": [17, 30, 54], "_check_i": 44, "_classif": 44, "_column_transform": [17, 30, 54], "_constructor_from_mgr": 68, "_data": 56, "_deprecate_force_all_finit": 44, "_distn_infrastructur": [19, 33, 56], "_encod": [17, 30, 54], "_estim": 44, "_fit": 44, "_fit_context": 44, "_get_sequential_output": [17, 30, 54], "_i": [35, 66], "_is_numpy_namespac": 44, "_logist": 72, "_mgr": 68, "_proba": [36, 59], "_score": [17, 30, 54], "_scorer": [17, 30, 54], "_set_output": [17, 30, 54], "_time_fit_was_cal": 68, "_transform": [17, 30, 54], "_transform_on": [17, 30, 54], "_valid": [17, 30, 54], "_validate_param": 44, "_valu": 44, "_x_subset": 14, "ab": [18, 20, 21, 23, 32, 34, 35, 37, 39, 40, 47, 48, 55, 57, 58, 60], "abbrevi": 65, "abdelrahman": [1, 80], "abil": [12, 17, 19, 23, 25, 30, 31, 33, 37, 39, 45, 46, 49, 54, 56, 60, 65, 67, 75], "abl": [8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 69, 70, 75, 77], "about": [1, 2, 4, 7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80], "abov": [0, 5, 8, 10, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 42, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 72, 75, 77, 80], "absenc": [17, 23, 30, 37, 39, 54, 60, 64], "absolut": [11, 18, 20, 21, 23, 32, 35, 37, 39, 40, 44, 46, 47, 48, 55, 57, 58, 60, 62, 71], "abspath": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75, 77, 78, 79], "absurd": 46, "academ": [1, 7, 24, 40, 61, 70], "accent": 46, "accept": [5, 8, 20, 21, 34, 35, 44, 47, 48, 57, 58, 65, 70], "accept_large_spars": 44, "accept_spars": [17, 30, 44, 54], "access": [1, 10, 12, 14, 19, 22, 25, 27, 29, 33, 36, 38, 51, 53, 56, 59, 62, 64, 65, 67, 69, 70, 71, 77], "accessori": 67, "accident": [15, 16, 28, 29, 52, 53, 70], "accomod": 7, "accompani": [7, 12, 13, 25, 49, 50], "accomplish": [43, 70], "accord": [18, 20, 21, 24, 32, 34, 35, 40, 47, 55, 57, 58, 61, 64, 68, 77, 78, 79, 80], "account": [1, 7, 12, 14, 20, 24, 25, 34, 40, 51, 57, 61, 64, 68, 70, 73, 78], "accur": [12, 14, 22, 23, 24, 25, 27, 36, 37, 38, 39, 40, 49, 51, 59, 60, 61, 64, 68, 69, 73, 74], "accuraci": [11, 13, 14, 15, 16, 19, 20, 22, 23, 24, 26, 27, 28, 29, 33, 34, 36, 37, 38, 39, 40, 42, 43, 47, 50, 51, 52, 53, 56, 57, 59, 60, 61, 63, 66, 68, 69, 71, 73, 74, 78, 79, 80], "accuracy_scor": [20, 34, 47, 57], "acdm": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "acf": 67, "achiev": [8, 15, 20, 28, 34, 47, 52, 57, 70, 77, 79], "acinonyx": [12, 25, 49, 66], "ackland": 46, "acoust": [15, 16, 19, 29, 33, 52, 53, 56, 77], "acquir": 11, "acquisit": 64, "across": [12, 13, 14, 16, 20, 23, 25, 26, 27, 29, 34, 37, 39, 46, 47, 49, 50, 51, 53, 57, 60, 66, 80], "act": [18, 31, 32, 45, 46, 55, 80], "action": [0, 12, 22, 23, 25, 36, 37, 38, 39, 46, 48, 49, 59, 60, 62, 64, 65, 68, 80], "activ": [4, 10, 19, 33, 49, 56, 71, 73, 80], "actor": [64, 65], "actual": [7, 12, 18, 20, 22, 23, 25, 30, 31, 32, 34, 36, 37, 38, 39, 45, 46, 47, 48, 49, 55, 57, 59, 60, 62, 64, 65, 67, 68, 69, 77, 79], "ad": [17, 18, 19, 20, 22, 23, 24, 30, 32, 33, 34, 36, 37, 38, 39, 40, 46, 54, 55, 56, 57, 59, 60, 61, 63, 65, 66, 68, 71, 77], "adam": 46, "adapt": [0, 16, 17, 20, 29, 30, 34, 38, 53, 54, 57, 59, 65, 67, 69, 71], "add": [7, 8, 10, 14, 16, 20, 21, 22, 23, 24, 29, 35, 36, 37, 38, 39, 40, 46, 53, 54, 57, 58, 59, 60, 61, 63, 65, 67, 68, 70, 71, 76, 78, 79], "add_pip": 71, "addit": [0, 4, 12, 21, 25, 35, 58, 64, 69, 78, 80], "addition": [74, 75, 80], "address": [31, 63, 70, 78], "adelaid": 67, "adio": 69, "adj": [65, 71], "adject": 65, "adjust": [15, 19, 28, 33, 43, 52, 56, 63, 67, 75], "adm": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60], "admin": [1, 80], "administr": 1, "admit": [14, 51], "adopt": [6, 64], "ador": 46, "adp": [65, 71], "adult": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "adult_df_larg": [22, 23, 36, 37, 38, 39, 59, 60], "adv": 65, "advanc": [11, 17, 19, 30, 33, 54, 56, 62, 63, 64, 65, 66, 74], "advantag": [11, 16, 17, 18, 22, 29, 30, 31, 32, 36, 38, 45, 46, 53, 54, 55, 59, 63, 64, 65, 73], "advic": 68, "advis": [12, 25, 49], "advisor": 80, "af": [23, 37, 39, 60], "affect": [10, 15, 16, 18, 19, 20, 28, 29, 32, 33, 34, 52, 53, 55, 56, 57, 62, 67, 68, 70, 75], "affix": 65, "aft": 70, "after": [4, 6, 10, 14, 16, 17, 20, 21, 23, 27, 29, 30, 34, 35, 37, 39, 40, 44, 46, 47, 48, 51, 53, 54, 57, 58, 60, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 79, 80], "ag": [12, 18, 20, 21, 22, 23, 24, 25, 32, 34, 35, 36, 37, 38, 39, 44, 48, 49, 55, 57, 58, 59, 60, 61, 64, 78, 79], "again": [10, 14, 16, 26, 27, 29, 42, 43, 44, 50, 51, 53, 63, 64, 65, 66, 68, 70, 75, 78, 79], "against": [64, 65, 67, 77], "agenc": [65, 71], "agent": 1, "agglomerativeclust": 63, "aggress": 65, "agnost": [23, 37, 39, 60], "ago": [66, 67], "agre": 75, "agreement": [68, 80], "ahead": 78, "ahm": [1, 80], "ai": [7, 9, 20, 24, 34, 40, 57, 61, 65, 66, 78], "aight": [12, 25, 49], "aim": [44, 73], "ain": 65, "air": 46, "airplan": 69, "airport": [20, 57, 70], "aka": [18, 32, 55, 68], "al": [22, 36, 38, 59, 65], "alain": [1, 80], "alamine_aminotransferas": [12, 25, 49], "alan": 1, "alaska": [18, 32, 55], "alberta": 65, "album": [33, 56], "albumin": [12, 25, 49], "albumin_and_globulin_ratio": [12, 25, 49], "alburi": 67, "alexand": 69, "alexnet": 66, "algebra": [64, 65], "algorithm": [2, 11, 12, 14, 16, 17, 20, 21, 22, 23, 25, 29, 30, 34, 35, 36, 37, 38, 39, 43, 48, 49, 51, 53, 54, 57, 58, 59, 60, 63, 65, 66, 69, 70, 74, 75, 76, 78], "align": [8, 12, 13, 14, 25, 26, 27, 49, 50, 51], "align_kei": 68, "alison": [1, 80], "aliv": 70, "alkaline_phosphotas": [12, 25, 49], "all": [0, 1, 4, 5, 6, 7, 8, 10, 14, 15, 17, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 48, 51, 52, 54, 56, 58, 59, 60, 61, 65, 66, 67, 68, 70, 71, 72, 75, 76, 77, 78, 79, 80], "all_cap": 71, "all_featur": 67, "allei": [21, 23, 35, 37, 39, 58, 60, 69], "allen": 71, "alley_grvl": [21, 35, 37, 58], "alley_miss": [21, 35, 37, 58], "alley_pav": [21, 35, 37, 58], "alloc": [8, 65, 66], "allow": [5, 7, 10, 14, 16, 19, 20, 24, 29, 33, 34, 40, 44, 51, 53, 56, 57, 61, 65, 67, 68, 70, 74, 75, 77, 80], "allow_nan": 44, "allow_nd": 44, "allpub": [21, 23, 35, 37, 39, 58, 60, 69], "allya": [1, 80], "almost": [18, 19, 21, 24, 32, 33, 35, 40, 55, 56, 58, 61, 63, 64, 65, 78], "alon": 46, "along": [7, 13, 17, 20, 30, 34, 46, 47, 50, 54, 57, 66, 67, 69, 74], "alpha": [15, 16, 28, 29, 40, 43, 52, 53, 67, 75], "alpha_": [21, 35, 48, 58], "alphabet": [18, 32, 55], "alphago": [12, 25, 49, 62], "alq": [21, 23, 35, 37, 39, 48, 58, 60, 69], "alreadi": [4, 8, 10, 11, 12, 20, 21, 23, 25, 35, 37, 39, 48, 57, 58, 60, 62, 65, 67, 68, 69, 71, 74, 77], "also": [1, 2, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "altar": 66, "altern": [8, 19, 33, 43, 48, 56, 62, 69, 77, 80], "although": [14, 22, 27, 36, 51, 59, 62, 64, 68], "alwai": [12, 13, 15, 17, 18, 20, 21, 22, 23, 25, 26, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 42, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 71, 73, 74, 75, 77, 80], "am": [16, 25, 29, 31, 45, 46, 48, 53, 62, 65, 69, 71, 80], "amateurish": 46, "amatriain": 64, "amaz": [44, 46], "amazon": [12, 25, 49, 62, 64, 71], "ambienc": 44, "ambigu": 65, "amer": [20, 34, 57], "america": [17, 54, 65], "american": [44, 62], "amicu": 46, "amirali": [1, 80], "aml": [16, 29, 53], "among": [12, 13, 19, 20, 22, 23, 25, 26, 33, 34, 36, 37, 39, 47, 49, 50, 56, 57, 59, 60, 64, 79], "amongst": 71, "amount": [4, 12, 14, 18, 19, 20, 21, 23, 25, 27, 32, 33, 34, 35, 37, 39, 47, 48, 49, 51, 55, 56, 57, 58, 60, 62, 66, 67, 68, 70, 77], "amp": [22, 23, 36, 37, 38, 39, 46, 59, 60], "amplifi": [20, 34, 57, 65, 78], "amuel": [16, 29, 53], "an": [0, 1, 2, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 39, 40, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 76, 77, 79, 80], "anaconda": [10, 23, 37, 39, 60, 71], "anaconda3": [26, 30], "analogi": [28, 63, 65, 69], "analysi": [1, 2, 9, 11, 13, 20, 21, 34, 35, 50, 57, 58, 62, 63, 65, 69, 78], "analyt": 67, "analyz": [11, 20, 24, 31, 34, 38, 40, 47, 57, 61, 67, 68, 69], "anatinu": 66, "anca": [1, 80], "ancestor": [24, 40, 61], "ancestr": 80, "ancuta": [1, 80], "andrea": [1, 9], "andrew": [1, 9, 19, 24, 33, 38, 39, 40, 43, 56, 61, 80], "anemon": 66, "angel": [68, 71], "angl": 46, "ani": [0, 10, 13, 14, 16, 17, 18, 20, 22, 23, 24, 26, 27, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 42, 44, 46, 47, 50, 51, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 78, 80], "anim": [20, 34, 43, 57, 66], "animal_fac": [43, 66], "anita": 46, "anneal": [24, 40, 61], "annoi": 46, "annot": [23, 37, 39, 60, 62], "announc": 7, "annoyingli": [21, 35, 48, 58], "annual": 71, "anomali": [20, 21, 35, 48, 57, 58, 62], "anonym": 67, "anoth": [8, 10, 13, 15, 18, 19, 20, 22, 23, 26, 28, 32, 33, 34, 36, 37, 38, 39, 47, 50, 52, 55, 56, 57, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 73, 74, 76, 79], "answer": [4, 6, 7, 12, 13, 14, 19, 22, 25, 27, 33, 36, 38, 45, 46, 49, 50, 51, 56, 59, 62, 64, 65, 67, 69, 72, 74, 75, 78, 79, 80], "anteat": 66, "anthologi": 46, "anti": 68, "anymor": [21, 35, 48, 58, 62, 64, 75], "anyon": [12, 46, 48, 69, 70], "anyth": [0, 12, 14, 17, 20, 25, 27, 30, 34, 44, 47, 48, 51, 54, 57, 64, 65, 68, 70, 77], "anytim": 80, "anywher": [17, 30, 54], "ap": [11, 73], "ap_lr": [20, 34, 47, 57], "ap_svc": [20, 34, 47, 57], "apart": [15, 28, 46, 52, 63], "apeendixa": 61, "api": [20, 44, 57, 65, 67, 73], "app": [12, 13, 25, 26, 50, 73], "appar": 46, "appeal": 65, "appear": [2, 7, 17, 22, 30, 36, 38, 54, 59, 70, 75, 79, 80], "append": [4, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 74, 75, 76, 77, 78, 79], "appendix": [24, 40], "appendix_b": 65, "appendixb": 66, "appl": 65, "appli": [0, 2, 6, 9, 11, 12, 13, 14, 18, 19, 20, 23, 24, 25, 26, 27, 31, 32, 33, 34, 37, 39, 40, 44, 45, 46, 49, 50, 51, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 76], "applic": [0, 5, 12, 17, 19, 20, 21, 23, 24, 25, 30, 33, 34, 35, 37, 39, 40, 48, 49, 54, 56, 57, 58, 60, 61, 65, 68, 70, 73, 78, 80], "appreci": [11, 62, 80], "approach": [1, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 65, 66, 73, 75], "appropri": [0, 4, 10, 11, 13, 14, 17, 20, 21, 26, 27, 30, 34, 35, 40, 42, 48, 50, 51, 54, 57, 58, 62, 63, 67, 68, 70, 73, 80], "approv": [20, 34, 57, 78, 80], "approx": [15, 23, 28, 37, 39, 52, 60], "approxim": [13, 19, 24, 26, 33, 40, 50, 56, 61, 70], "apr": 1, "april": 67, "apt": 5, "ar": [0, 1, 2, 4, 6, 7, 8, 9, 10, 14, 15, 17, 19, 21, 22, 23, 24, 26, 27, 28, 30, 31, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 51, 52, 54, 56, 58, 59, 60, 61, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "arang": [8, 14, 15, 18, 19, 20, 21, 27, 28, 31, 32, 33, 34, 35, 42, 43, 45, 46, 47, 48, 51, 52, 55, 56, 57, 58, 75, 77], "arbitrari": [23, 37, 39, 60, 62, 63, 67], "architectur": 66, "area": [19, 21, 22, 24, 33, 35, 36, 38, 40, 46, 48, 56, 58, 59, 61, 62, 69, 77], "aren": [7, 21, 24, 35, 40, 46, 48, 58, 61, 62, 65, 66, 67, 71], "arena": [24, 40, 61], "arg": [14, 17, 27, 30, 43, 44, 51, 54], "argh": 68, "argmax": [31, 43, 46], "argmin": [14, 15, 20, 27, 28, 34, 47, 51, 52, 57, 62], "argsort": [23, 37, 39, 60, 65], "argu": [25, 62, 65, 77], "argument": [8, 13, 17, 19, 20, 21, 23, 26, 30, 33, 34, 35, 37, 39, 40, 47, 48, 50, 54, 56, 57, 58, 60, 69, 71, 73, 76], "arima": 67, "arima_model": 67, "aris": [0, 12, 49, 65], "aristotl": [15, 28, 52], "arithmet": 8, "arm": 46, "armi": 46, "aroth85": 41, "around": [7, 15, 17, 20, 21, 28, 30, 31, 33, 34, 35, 46, 47, 48, 52, 54, 57, 58, 67, 68, 74], "aroundn": [12, 49], "arr": [44, 68], "arr1": 8, "arr2": 8, "arrai": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 77], "array_equ": 8, "array_orig": 44, "arriv": [24, 40, 61], "art": 69, "arthur": [12, 25, 49], "articl": [1, 13, 14, 16, 20, 26, 29, 34, 50, 51, 53, 57, 62, 64, 65, 66, 69], "articul": [69, 73], "artifici": [1, 65], "artist": [15, 16, 19, 29, 33, 52, 53, 56, 77], "as_fram": [15, 28, 40, 43, 52, 75], "asarrai": 44, "ascend": [8, 17, 18, 19, 21, 22, 23, 24, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 45, 46, 48, 54, 55, 56, 58, 59, 60, 61, 67, 68, 73, 79], "ased": 63, "asia": [17, 54], "asid": [4, 14, 22, 27, 36, 38, 51, 59, 75], "ask": [3, 7, 10, 12, 13, 14, 15, 17, 20, 24, 25, 26, 27, 30, 34, 40, 46, 49, 50, 51, 52, 54, 57, 61, 62, 64, 65, 68, 69, 71, 74, 80], "asleep": [18, 32, 55], "aspartate_aminotransferas": [12, 25, 49], "aspect": [18, 23, 24, 32, 37, 39, 40, 55, 60, 61, 63, 64, 68, 69, 73], "assault": 80, "assert": [7, 17, 20, 22, 23, 30, 34, 36, 37, 38, 39, 54, 57, 59, 60, 78], "assess": [1, 6, 11, 12, 13, 14, 16, 20, 23, 25, 26, 27, 29, 34, 37, 39, 44, 47, 49, 50, 51, 53, 57, 60, 62, 69, 80], "assign": [1, 4, 6, 8, 10, 12, 13, 15, 16, 18, 19, 23, 24, 25, 26, 28, 29, 32, 33, 36, 37, 38, 39, 40, 43, 50, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 65, 67, 68, 69, 70, 71, 73, 74, 76, 78], "assist": [12, 25, 49], "assoc": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "associ": [0, 12, 14, 15, 20, 21, 23, 24, 25, 26, 27, 28, 31, 34, 35, 37, 39, 40, 45, 46, 48, 49, 51, 52, 57, 58, 60, 61, 62, 65, 66, 67, 68, 69, 70, 73, 79, 80], "assum": [12, 13, 17, 18, 20, 21, 25, 30, 32, 34, 49, 50, 54, 55, 57, 58, 63, 64, 65, 67, 69, 73, 78], "assumpt": 68, "asterisk": [19, 33, 56], "astyp": [8, 31, 43, 44, 45, 46, 67, 68], "astype_arrai": 68, "astype_array_saf": 68, "astype_is_view": 44, "atmospher": 46, "atratu": 66, "attack": [13, 26, 46, 50], "attempt": [14, 27, 33, 43, 51, 77, 78], "attend": 80, "attent": [6, 65, 70], "attic": [21, 35, 48, 58], "attract": 65, "attribut": [0, 1, 12, 13, 15, 16, 18, 19, 24, 25, 26, 28, 29, 31, 32, 33, 40, 45, 46, 49, 50, 52, 53, 55, 56, 61, 62, 65, 66, 77, 79], "attrit": 68, "auc": [11, 68, 70, 73, 78], "audienc": [11, 69, 70, 78], "audio": [66, 80], "audit": [70, 80], "auditor": 80, "augment": [20, 57], "august": 67, "austin": 65, "australia": 67, "auteur": 46, "authent": 62, "author": [0, 65, 80], "auto": [12, 19, 20, 24, 25, 33, 34, 40, 49, 56, 57, 61, 62, 69], "autocorrel": 67, "autom": [13, 21, 26, 35, 50, 58, 65, 69], "automat": [16, 17, 21, 24, 29, 30, 35, 40, 46, 48, 53, 54, 58, 61, 65, 67, 68, 69], "autoregress": [18, 32, 55], "autumn": 67, "autumn_month": 67, "aux": [65, 71], "av": [21, 23, 35, 37, 39, 48, 58, 60, 65, 69], "avail": [0, 1, 7, 9, 10, 12, 14, 17, 19, 20, 21, 25, 26, 27, 30, 33, 34, 35, 40, 51, 54, 56, 57, 58, 63, 64, 65, 66, 67, 68, 73, 78, 79, 80], "avebedrm": [18, 32, 55], "aveoccup": [18, 32, 55], "averag": [11, 14, 15, 17, 18, 19, 21, 23, 27, 28, 30, 32, 33, 35, 37, 39, 47, 48, 51, 52, 54, 55, 56, 58, 60, 62, 63, 65, 68, 70, 71, 73, 75], "average_precis": [20, 34, 47, 57], "average_precision_scor": [20, 34, 47, 57], "average_word_length": 71, "averaging_model": [22, 36, 38, 59, 79], "averaging_model_ndt": [22, 36, 38, 59], "averoom": [18, 32, 55], "avg": [20, 34, 57, 64, 67], "avg_sent_emb": 65, "avocado": 69, "avoid": [7, 8, 13, 16, 20, 21, 29, 34, 35, 40, 45, 46, 48, 50, 53, 57, 58, 63, 67, 68, 69, 70, 72, 73, 75, 78, 80], "aw": [44, 46, 70], "awai": [4, 6, 13, 18, 26, 32, 50, 55, 62, 64, 66, 68, 69, 70, 73], "awar": [17, 30, 54, 68, 69, 80], "awesom": [9, 46], "ax": [14, 15, 18, 20, 27, 28, 32, 34, 40, 43, 51, 52, 55, 57, 62, 63, 66, 68, 69, 75, 78], "axi": [7, 8, 12, 13, 14, 16, 17, 18, 23, 25, 26, 27, 29, 30, 31, 32, 37, 39, 43, 49, 50, 51, 53, 54, 55, 60, 62, 63, 65, 66, 67, 69], "axvlin": 62, "az": 71, "b": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69], "b3": [53, 60, 71], "babe": [12, 25, 49], "babi": [24, 40, 61, 65], "babysitt": 46, "bachelor": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "back": [8, 16, 19, 29, 33, 42, 43, 53, 56, 65, 73], "backdrop": 67, "background": [11, 50, 69, 70], "bad": [8, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 34, 35, 36, 37, 38, 40, 44, 46, 48, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 66, 67], "badgeryscreek": 67, "bag": [24, 31, 40, 44, 45, 46, 61, 65, 66, 73, 77], "bai": [16, 24, 29, 40, 53, 54, 61], "baidu": [14, 51], "bal_scor": [20, 34, 57], "balanc": [6, 15, 22, 28, 31, 36, 38, 44, 45, 46, 52, 59, 62, 64, 72, 78, 79], "ballarat": 67, "balltre": 44, "balust": 66, "balustrad": 66, "bambi": [19, 64], "banist": 66, "bank": [20, 23, 34, 37, 39, 57, 60, 67, 68, 78], "bannist": 66, "bar": [20, 21, 23, 34, 35, 37, 39, 47, 48, 57, 58, 60, 66, 67, 68, 69, 70], "baranski": 71, "barbu": [1, 80], "bare": 46, "barrel": 46, "barri": [18, 32, 55], "base": [5, 8, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 23, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 39, 43, 44, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 60, 62, 63, 65, 68, 69, 70, 71, 73, 74, 77, 78, 79, 80], "base_scor": [22, 36, 38, 59], "base_valu": [23, 37, 39, 60], "baseblockmanag": 68, "baselin": [43, 68, 70, 73, 74, 76, 77], "baseline_hazard_": 68, "bash": 5, "basi": [13, 15, 26, 28, 50, 52], "basic": [2, 8, 12, 13, 19, 24, 25, 26, 33, 40, 46, 50, 56, 61, 64, 66, 68, 71, 79], "batch": [43, 65, 66], "batch_siz": [43, 66], "batch_t": 66, "bath": [12, 25, 46, 49], "bathroom": [12, 13, 18, 25, 32, 42, 49, 50, 55], "bayesian": [19, 33, 56], "bayesopt": [19, 33, 56], "bazazeh": [1, 80], "bbc": 46, "beagl": [12, 25, 49, 66], "bear": 66, "beat": [22, 36, 38, 59, 68], "beatric": 46, "beauti": [46, 64, 65, 69], "becam": 66, "becaus": [1, 7, 8, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 46, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 78, 80], "becom": [4, 14, 15, 18, 19, 20, 23, 24, 27, 28, 32, 33, 37, 39, 40, 47, 48, 51, 52, 55, 56, 57, 60, 61, 62, 65], "bed": [20, 57, 70], "bedroom": [12, 13, 18, 25, 26, 32, 42, 49, 50, 55], "bedroomabvgr": [21, 23, 35, 37, 39, 48, 58, 60, 69], "bedrooms_per_household": [16, 29, 53, 54, 76], "beef": [44, 65], "been": [1, 4, 6, 12, 13, 16, 17, 18, 19, 20, 21, 23, 25, 29, 30, 32, 33, 34, 35, 37, 39, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 80], "befor": [1, 4, 10, 13, 14, 15, 17, 18, 21, 22, 26, 27, 28, 30, 32, 35, 36, 44, 46, 48, 49, 50, 51, 52, 54, 55, 58, 59, 62, 63, 64, 65, 66, 67, 68, 70, 74, 75, 77, 78, 79], "begin": [18, 24, 32, 40, 44, 50, 55, 61, 64, 67, 68, 73], "beginn": 66, "behav": [19, 23, 33, 37, 39, 56, 60], "behavior": [20, 29, 34, 47, 51, 53, 57, 64, 70, 71], "behaviour": [17, 30, 54, 78, 79], "behind": [11, 12, 18, 25, 32, 33, 49, 55, 80], "being": [4, 12, 14, 16, 20, 21, 22, 23, 25, 27, 29, 34, 35, 36, 39, 47, 49, 51, 53, 57, 58, 59, 60, 63, 65, 68, 69, 75, 80], "belief": 69, "believ": [19, 23, 33, 39, 42, 46, 56, 60, 67], "bell": 66, "belong": [13, 18, 32, 50, 55, 63, 74], "below": [1, 5, 8, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80], "bench": 66, "benchmark": [42, 66], "bendigo": 67, "benefici": [17, 30, 54, 69], "benefit": [4, 15, 22, 36, 52, 59, 63, 65, 69, 73], "bengio": [19, 33, 56], "bennett": 46, "ber": 65, "bergammi": 46, "bergstra": [19, 33, 56], "berri": 65, "bertop": 65, "best": [2, 13, 14, 15, 19, 20, 21, 22, 23, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38, 39, 42, 45, 46, 47, 48, 50, 51, 52, 56, 57, 58, 59, 60, 62, 63, 64, 68, 69, 70, 74, 75, 77, 79], "best_alpha": [21, 35, 48, 58], "best_c": 43, "best_depth": [14, 27, 42, 51], "best_estimator_": [19, 21, 33, 35, 48, 56, 58], "best_k": 43, "best_n_neighbour": [15, 28, 52], "best_param": [19, 33, 56, 69], "best_paramet": [19, 33, 56], "best_params_": [19, 21, 33, 35, 48, 56, 58, 69, 77], "best_scor": [19, 33, 56], "best_score_": [19, 21, 33, 35, 48, 56, 58, 77], "best_svr": 69, "bestalpha_coeff": [21, 35, 48, 58], "better": [6, 12, 13, 15, 16, 17, 18, 21, 22, 23, 25, 26, 28, 29, 30, 32, 35, 36, 37, 38, 39, 43, 44, 48, 49, 50, 52, 53, 54, 55, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 70, 73, 74, 75, 76, 77, 78, 79, 80], "between": [2, 8, 10, 11, 12, 14, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 51, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 73, 75], "bewar": 65, "beyond": [14, 19, 24, 27, 33, 40, 51, 56, 61, 69], "bhatt": [1, 80], "bia": [18, 20, 23, 32, 34, 37, 39, 55, 57, 60, 68, 70, 73, 78], "bias": [11, 20, 23, 34, 37, 39, 57, 60, 65, 68, 78], "bicycl": [13, 26, 50, 67], "big": [7, 15, 17, 19, 20, 22, 24, 28, 30, 31, 33, 34, 36, 40, 44, 45, 46, 48, 52, 54, 56, 57, 59, 61, 62, 63, 64, 65, 66, 68, 69, 75], "bigalpha_coeff": [21, 35, 48, 58], "bigger": [15, 17, 18, 21, 23, 28, 32, 35, 37, 39, 48, 52, 54, 55, 58, 60, 63, 65, 66, 67], "biggest": [21, 24, 35, 40, 58, 61], "bigotri": 46, "bike": 67, "bill": 66, "billboard": 67, "billie_holidai": 65, "billion": [21, 35, 48, 58], "billionth": 67, "bin": [16, 19, 21, 24, 29, 33, 35, 40, 44, 48, 53, 56, 58, 61, 67, 68, 69, 71, 74], "binar": [13, 17, 26, 30, 50, 54], "binari": [13, 16, 17, 18, 26, 29, 30, 32, 44, 50, 53, 54, 55, 66, 68, 69, 72, 73, 78], "binary_feat": [17, 30, 44, 54], "binary_featur": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78, 79], "binary_transform": [20, 22, 23, 34, 36, 37, 38, 39, 44, 57, 59, 60, 78, 79], "bincount": [20, 22, 34, 36, 38, 57, 59, 78], "bind": [15, 28, 43, 52, 75], "binomi": [19, 33, 56], "biolog": [24, 40, 61], "biologi": [17, 30, 54], "bird": 46, "bit": [10, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 45, 46, 47, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 62, 66, 67, 68, 69, 77, 78], "bite": 46, "black": [15, 23, 28, 37, 39, 52, 60, 62, 66, 67], "blackhawk": 65, "bland": 46, "bldgtype": [21, 23, 35, 37, 39, 58, 60, 69], "bldgtype_1fam": [21, 35, 58], "bldgtype_2fmcon": [21, 35, 58], "bldgtype_duplex": [21, 35, 58], "bldgtype_twnh": [21, 35, 58], "bldgtype_twnhs": [21, 35, 58], "blei": 65, "blend": 65, "blindli": [20, 21, 34, 35, 57, 58], "blob": [12, 72], "block": [18, 32, 55, 68], "blog": [65, 67], "blood": 46, "bloomberg": [1, 9], "blq": [21, 23, 35, 37, 39, 48, 58, 60, 69], "blue": [13, 15, 19, 20, 23, 24, 26, 28, 33, 34, 37, 39, 40, 50, 52, 56, 57, 60, 61, 62, 67], "bluesman": 65, "bmatrix": [24, 40, 61, 64], "board": 4, "boathous": 66, "bob_dylan": 65, "boggl": [22, 38, 59], "boi": 46, "bold": 69, "bond": [20, 57, 70], "bonu": [22, 36, 38, 59], "book": [9, 20, 21, 35, 40, 48, 57, 58, 64, 65, 67, 69, 80], "bool": [21, 31, 35, 45, 46, 48, 58, 67], "bool_t": 44, "boom": 71, "boost": [65, 70, 73], "booster": [22, 36, 38, 59], "bootstrap": [10, 69], "border": [13, 18, 32, 50, 55, 63, 65, 72, 74], "bore": [18, 31, 32, 45, 46, 55], "boston": [18, 32, 55], "both": [2, 6, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 48, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 73, 76, 77, 78, 80], "bother": [23, 37, 39, 60], "bottom": [46, 63], "bought": 64, "bound": [24, 61, 68], "boundari": [14, 27, 51, 63, 65, 69, 70, 75], "bow": [31, 45, 46], "bow_df": [17, 30, 54], "box": [9, 23, 37, 39, 60, 73], "boxplot": [23, 37, 39, 60], "boyc": [26, 50], "br": [31, 45, 46, 65], "bracket": 8, "brain": [24, 40, 61, 66], "branch": [13, 26, 50, 63, 65, 68], "brand": 69, "breach": 46, "break": [1, 20, 29, 31, 34, 45, 46, 47, 57, 73, 75], "breakdown": 25, "breakwat": 66, "breath": 73, "breathtak": 65, "breed": 73, "breiman": [22, 36, 38, 59], "bridg": 46, "brief": [4, 18, 22, 32, 36, 38, 55, 59], "briefli": [12, 20, 22, 24, 25, 34, 36, 38, 40, 47, 49, 57, 59, 61], "bring": [6, 23, 37, 39, 42, 60, 63, 70, 71, 73], "british": [1, 65], "british_columbia": 65, "broad": [15, 28, 43, 52, 65, 75], "broadcast": 65, "broader": [2, 22, 36, 38, 59, 65], "broadest": 65, "broadli": [13, 15, 18, 20, 22, 26, 28, 32, 34, 36, 38, 50, 52, 55, 57, 59, 62, 63, 65], "broken": 46, "broth": 44, "brownle": [24, 40, 61], "browser": 10, "bruno": 46, "brush": 66, "bryan": 46, "bsmtcond": [21, 23, 35, 37, 39, 48, 58, 60, 69], "bsmtexposur": [21, 23, 35, 37, 39, 48, 58, 60, 69], "bsmtfinsf1": [21, 23, 35, 37, 39, 48, 58, 60, 69], "bsmtfinsf2": [21, 23, 35, 37, 39, 48, 58, 60, 69], "bsmtfintype1": [21, 23, 35, 37, 39, 48, 58, 60, 69], "bsmtfintype2": [21, 23, 35, 37, 39, 48, 58, 60, 69], "bsmtfullbath": [21, 23, 35, 37, 39, 48, 58, 60, 69], "bsmthalfbath": [21, 23, 35, 37, 39, 48, 58, 60, 69], "bsmtqual": [21, 23, 35, 37, 39, 48, 58, 60, 69], "bsmtunfsf": [21, 23, 35, 37, 39, 48, 58, 60, 69], "btw": [23, 37, 60], "bubbl": [64, 66], "bucket": [24, 40, 61, 71], "buddi": 46, "budget": [19, 33, 56, 64], "bug": [4, 8], "bui": [64, 70], "build": [0, 2, 10, 11, 14, 16, 17, 22, 24, 27, 29, 30, 36, 38, 40, 44, 48, 51, 53, 54, 59, 61, 62, 65, 67, 69, 72, 75], "built": [8, 12, 13, 14, 18, 19, 23, 25, 26, 32, 33, 37, 39, 49, 50, 51, 55, 56, 60, 67, 69, 70], "bullshit": [1, 68], "bulwark": 66, "bunch": [8, 10, 13, 21, 22, 26, 35, 36, 38, 42, 48, 50, 58, 59, 66, 68, 69, 70, 75], "bundl": [7, 10], "bureau": [18, 32, 55], "busi": [20, 34, 47, 57, 62, 68, 71], "businesswoman": 65, "bustl": 67, "butterfli": 63, "buzz": [12, 25, 49], "bypass": 80, "c": [0, 1, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 75, 77, 80], "c1": 63, "c2": 63, "c_1": 62, "c_2": 62, "c_3": 62, "c_log": [15, 28, 43, 52, 75], "c_val": 43, "c_valu": 43, "c_widget": [15, 28, 43, 52, 75], "ca": [1, 5, 9, 12, 25, 70, 71, 80], "ca_transform": [17, 30, 54], "cache_s": 69, "cal_hous": [18, 32, 55], "calcul": [7, 14, 15, 16, 20, 21, 22, 23, 24, 27, 28, 29, 34, 35, 36, 37, 38, 39, 40, 42, 47, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 67, 70, 71, 72, 73, 75, 78], "calgary_flam": 65, "calibr": 70, "california": [16, 24, 29, 40, 53, 61], "california_h": [24, 40, 61], "californian": [16, 29, 53], "call": [1, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77, 79], "callback": [22, 36, 38, 59], "caller": 70, "calll": 40, "calm": 73, "came": 67, "camera": [17, 30, 46, 54], "campu": [24, 40, 61, 80], "can": [1, 4, 6, 7, 10, 12, 13, 15, 17, 18, 19, 20, 21, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 56, 57, 58, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80], "canada": [5, 14, 15, 17, 18, 27, 28, 30, 32, 51, 52, 54, 55, 65, 69, 71, 73], "canada_usa_c": [13, 14, 15, 18, 27, 28, 32, 50, 51, 52, 55, 74], "canadian": [44, 65], "canadien": 65, "canberra": 67, "cancel": 80, "cancer": [12, 24, 25, 49, 61], "candid": [19, 22, 33, 42, 56, 59, 65, 75], "cannibalist": 46, "cannonbal": 19, "cannot": [0, 8, 12, 14, 15, 19, 20, 22, 23, 24, 25, 27, 28, 33, 34, 36, 37, 38, 39, 40, 47, 51, 52, 56, 57, 59, 60, 61, 63, 67, 68, 69, 80], "canuck": 65, "canva": [1, 7, 12, 13, 25, 70], "capabl": 9, "capit": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "caption": [7, 66], "captiv": 65, "captur": [11, 14, 16, 18, 22, 24, 27, 29, 32, 36, 38, 40, 51, 53, 55, 59, 61, 63, 64, 65, 67, 68, 73], "car": [12, 25, 49, 65, 66, 70], "card": [12, 13, 20, 25, 26, 34, 47, 49, 50, 57, 68, 69, 78], "care": [5, 7, 14, 16, 19, 20, 21, 23, 24, 27, 29, 33, 34, 35, 37, 39, 40, 47, 51, 53, 56, 57, 58, 60, 61, 62, 67, 68, 73, 77, 79], "carefulli": [1, 12, 20, 21, 25, 34, 35, 57, 58, 78, 80], "carpentri": 5, "carri": [13, 14, 15, 17, 19, 20, 21, 22, 26, 27, 28, 30, 33, 34, 35, 36, 38, 42, 44, 48, 50, 51, 52, 54, 56, 57, 58, 59, 62, 64, 65, 67, 70, 71, 75, 77], "caruana": [23, 37, 39, 60], "case": [6, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 72, 73, 80], "cash": [12, 25, 46, 49], "cast": [46, 56, 64, 71], "castl": 66, "cat": [12, 20, 22, 25, 34, 36, 38, 43, 49, 57, 59, 65, 66, 71, 73], "catamount": [12, 25, 49, 66], "catboost": [11, 23, 37, 39, 60, 69, 73], "catboostclassifi": [22, 36, 38, 59], "catboostregressor": [22, 36, 38, 59], "catch": [20, 34, 57, 80], "categor": [13, 19, 20, 21, 22, 24, 26, 33, 34, 35, 36, 38, 40, 42, 47, 48, 50, 56, 57, 58, 59, 61, 62, 64, 65, 68, 69, 73, 75, 76, 78], "categori": [15, 16, 20, 21, 22, 23, 24, 28, 29, 34, 35, 36, 37, 38, 39, 40, 43, 44, 48, 52, 53, 57, 58, 59, 60, 61, 62, 66, 69, 73, 78], "categorical_feat": [17, 19, 30, 33, 44, 54, 56, 73, 77], "categorical_featur": [20, 21, 22, 23, 34, 35, 36, 37, 38, 39, 48, 54, 57, 58, 59, 60, 67, 68, 69, 78, 79], "categorical_transform": [20, 21, 22, 23, 34, 35, 36, 37, 38, 39, 44, 48, 54, 57, 58, 59, 60, 67, 69, 78, 79], "categories_": [16, 17, 29, 30, 53, 54], "cater": 62, "caus": [20, 23, 24, 37, 39, 40, 57, 60, 61, 64, 68, 77, 80], "causal": [23, 24, 37, 39, 40, 60, 61], "caution": 67, "cbar": [18, 32, 55], "cbtf": [1, 40, 80], "cc": [0, 1], "cc_df": [20, 34, 47, 57, 78], "cconj": 65, "ccp_alpha": 69, "ceil": 46, "cell": [7, 8, 12, 16, 17, 19, 20, 21, 22, 23, 24, 25, 29, 30, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 49, 53, 54, 56, 57, 58, 59, 60, 61, 64, 66, 68, 69, 71, 74, 75, 77, 79], "censor": [1, 11, 69, 70, 73], "censu": [18, 20, 22, 23, 32, 34, 36, 37, 38, 39, 55, 57, 59, 60, 78], "census_df": [20, 34, 57, 78], "cent": [21, 35, 48, 58], "center": [15, 28, 52, 62, 63, 66, 72], "centercrop": 66, "centers_idx": 62, "central": [5, 12], "centralair": [21, 23, 35, 37, 39, 58, 60, 69], "centralair_i": [21, 35, 58], "centralair_n": [21, 35, 58], "centric": [11, 69], "centroid": [62, 63], "centroids_idx": 62, "centroids_idx_init": 62, "centuri": 65, "certain": [10, 15, 18, 19, 20, 23, 24, 28, 32, 33, 34, 37, 39, 40, 45, 46, 52, 55, 56, 57, 60, 61, 62, 65, 68, 69, 78], "certainli": 74, "certainti": [20, 34, 47, 57], "cezannec": 66, "chaat": 65, "chage": 77, "chain": [17, 30, 54], "challeng": [6, 11, 14, 24, 25, 40, 51, 61, 62, 64, 66, 67, 70, 73, 79], "chambar": 44, "chanc": [14, 19, 20, 21, 24, 33, 34, 35, 40, 47, 50, 51, 56, 57, 58, 61, 62, 68, 69, 70, 78], "chang": [0, 5, 7, 8, 10, 12, 13, 14, 15, 16, 19, 21, 22, 23, 25, 26, 27, 28, 29, 33, 35, 36, 37, 39, 40, 43, 47, 48, 50, 51, 52, 53, 56, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 74, 75, 77, 78, 79, 80], "channel": [1, 10, 66], "chapter": 1, "charact": [17, 20, 30, 46, 54, 57, 65], "characterist": [13, 14, 18, 26, 27, 32, 50, 51, 55, 77], "charg": [0, 12, 25, 46, 49, 68], "charl": [18, 32, 46, 55], "charm": [46, 65], "chart": [23, 37, 39, 60, 67, 68, 69], "chat": 80, "chatgpt": [12, 65], "che210d": 9, "cheap": 46, "cheaper": [24, 40, 61], "cheat": 9, "check": [1, 4, 7, 10, 12, 13, 14, 16, 18, 20, 21, 23, 24, 25, 26, 27, 29, 32, 35, 37, 39, 40, 47, 48, 49, 50, 51, 53, 55, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 75, 78, 79], "check_arrai": 44, "check_assumpt": 68, "check_consistent_length": 44, "check_invers": [17, 30, 54], "check_param": 44, "check_x_i": 44, "check_y_param": 44, "checklist": 73, "checkmark": 64, "checkout": [19, 33, 56], "cheetah": [12, 25, 49, 66], "chegini": [1, 80], "chemic": 46, "chemistri": 46, "cherri": 69, "chest": [14, 27, 51], "chestpaintyp": 79, "chetah": [12, 25, 49, 66], "chi": 68, "chicago": 71, "chicken": 62, "child": [20, 23, 34, 37, 39, 46, 57, 60], "children": 64, "chill": 46, "chines": [44, 65], "chloe": 46, "chn": 8, "choic": [2, 19, 21, 22, 23, 27, 33, 35, 36, 37, 38, 39, 40, 56, 58, 59, 60, 62, 63, 64, 67, 71, 75, 76, 77], "cholesterol": 79, "choos": [12, 19, 20, 22, 33, 34, 36, 38, 49, 56, 57, 59, 63, 69, 70, 73, 75], "chop": [33, 56, 65, 69], "choreograph": 71, "chose": [42, 69], "chosen": [14, 19, 20, 27, 33, 47, 51, 56, 57, 68, 69, 73, 79], "chrbv": 68, "christin": 71, "christma": 71, "christoph": 46, "chrome": [12, 25], "chunki": 62, "churn": [69, 73], "ciml": 1, "cinematographi": [46, 65], "cinereu": 66, "circl": [15, 20, 28, 34, 47, 52, 57], "circumst": 7, "citat": 7, "cite": 68, "citi": [13, 14, 15, 27, 28, 50, 51, 52, 65, 67, 69, 73, 74], "citibik": 67, "cities_df": [15, 18, 28, 32, 52, 55], "citizen": 68, "cityscap": 67, "civ": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60], "clai": [23, 39, 60], "claim": [0, 19, 20, 33, 34, 56, 57], "clarif": 62, "clarifi": 73, "clariti": 11, "class": [1, 4, 5, 10, 13, 14, 15, 16, 17, 18, 24, 26, 27, 28, 29, 30, 32, 40, 49, 50, 51, 52, 53, 54, 55, 61, 62, 65, 67, 68, 69, 70, 74, 75, 78, 79], "class_attend": [13, 14, 26, 27, 50, 51, 73], "class_attendance_enc": [17, 30, 54], "class_attendance_level": [17, 30, 54], "class_label": [20, 34, 57], "class_labels_fil": [12, 25, 49], "class_nam": [13, 15, 22, 26, 28, 36, 38, 43, 50, 52, 59, 66], "class_sep": [20, 57], "class_weight": [22, 36, 38, 59, 69, 78], "classes_": [18, 20, 22, 23, 31, 32, 34, 36, 37, 38, 45, 46, 47, 55, 57, 59, 60, 66, 72], "classic": [15, 28, 46, 52, 66, 72], "classif": [1, 2, 11, 14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 28, 29, 30, 32, 35, 36, 37, 38, 39, 40, 42, 44, 48, 51, 52, 53, 54, 55, 58, 59, 60, 61, 64, 65, 67, 68, 69, 72, 74, 75, 77, 78, 79], "classifi": [14, 15, 16, 17, 19, 20, 23, 27, 28, 29, 30, 33, 34, 37, 39, 43, 47, 51, 52, 53, 54, 56, 57, 60, 66, 69, 72, 74, 76, 78, 79], "classification_df": [13, 14, 26, 27, 50, 51], "classification_report": [20, 34, 47, 57, 66, 78], "classifiers_ndt": [22, 36, 38, 59], "classify_imag": [12, 25, 49, 66], "classmat": [6, 75, 76, 77, 78, 79, 80], "classroom": [1, 70], "claudio": 46, "clean": [2, 12, 25, 31, 42, 44, 45, 46, 49, 63, 69, 80], "clean_text": 65, "cleaned_hm": [20, 57, 70], "cleaned_restaurant_data": 44, "cleaner": [20, 23, 34, 37, 57, 60], "clear": [7, 11, 20, 34, 47, 57, 62, 70, 75], "clearli": [4, 6, 7, 19, 22, 23, 33, 36, 37, 39, 46, 56, 59, 60, 67], "cleric": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60], "clever": 69, "clf": [12, 13, 15, 18, 25, 26, 28, 32, 49, 50, 52, 55, 66], "click": [1, 5, 7, 20, 34, 57, 64, 69, 70], "client": [64, 70], "clinic": [13, 26, 50], "clip": [12, 25, 43, 49], "cloak": 46, "clone": [5, 7, 10], "close": [2, 12, 14, 15, 18, 19, 20, 27, 28, 32, 33, 34, 43, 47, 51, 52, 55, 56, 57, 62, 63, 65, 67, 71, 72, 75, 80], "close_default_lr": [20, 34, 47, 57], "close_zero_svm": [20, 34, 47, 57], "closer": [15, 16, 18, 28, 29, 32, 52, 53, 55, 64, 74, 77, 80], "closest": [15, 16, 20, 27, 28, 29, 34, 47, 52, 53, 57, 62, 63, 65, 67], "closet": 46, "cloth": 67, "cloud": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 49, 50, 54, 55, 56, 58, 59, 71, 80], "cloud3pm": 67, "cloud9am": 67, "clust_label": 62, "cluster": [1, 2, 11, 64, 65, 67, 70], "cluster_cent": 62, "cluster_centers_": 62, "cluster_std": [63, 66], "clutter": [13, 50], "cm": [15, 18, 20, 23, 28, 32, 34, 37, 39, 43, 47, 52, 55, 57, 60, 64, 75, 78], "cmap": [16, 19, 20, 23, 29, 33, 34, 37, 39, 53, 56, 57, 60, 66, 77], "cmn": [21, 35, 58], "cmp": 68, "cnn": [66, 67], "co": [17, 30, 54, 65], "coast": 66, "cockpit": 69, "code": [4, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79], "codecademi": 9, "coef": [67, 68, 71], "coef0": 69, "coef_": [18, 21, 22, 23, 24, 31, 32, 35, 36, 37, 38, 39, 40, 45, 46, 48, 55, 58, 59, 60, 61, 64, 66, 67, 68, 71, 72, 79], "coef_df": [18, 23, 32, 37, 39, 55, 60], "coef_nonzero": 67, "coeff": [18, 31, 32, 45, 46, 55], "coeff_df": 67, "coeffici": [21, 22, 24, 35, 36, 38, 40, 48, 58, 59, 61, 64, 66, 67, 68, 69, 71, 72, 73, 79], "coefs_df": [24, 40, 61], "coher": 62, "col": [13, 17, 18, 26, 30, 32, 50, 54, 55, 64, 67, 73], "col1": 8, "col2": 8, "col3": 8, "col4": 8, "col5": 8, "col6": 8, "cold": [16, 29, 53], "colinear": [23, 37, 39, 60], "collabor": [5, 11, 64, 80], "collaps": [23, 37, 39, 60], "colleagu": [8, 9], "collect": [11, 12, 13, 16, 17, 20, 22, 23, 24, 25, 26, 29, 30, 34, 36, 37, 38, 39, 40, 44, 49, 50, 53, 54, 57, 59, 60, 61, 64, 65, 66, 67, 68, 70, 73, 79], "colleg": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "collinear": [24, 40, 61], "color": [18, 23, 24, 32, 37, 39, 40, 55, 60, 61, 62, 63, 67, 69], "color_continuous_scal": [24, 40, 61], "color_threshold": 63, "colorbar": [16, 18, 29, 32, 53, 55], "colour": [17, 18, 19, 23, 30, 32, 33, 37, 39, 54, 55, 56, 60, 62, 63, 66], "colsample_bylevel": [22, 36, 38, 59], "colsample_bynod": [22, 36, 38, 59], "colsample_bytre": [22, 36, 38, 59], "columbia": [1, 9, 65], "column": [7, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79], "column_nam": [17, 30, 54], "column_stack": [24, 40, 61], "columntranform": 76, "columntransform": [1, 16, 19, 20, 21, 22, 23, 24, 29, 33, 34, 35, 36, 37, 38, 39, 40, 44, 48, 53, 56, 57, 58, 59, 60, 61, 67, 68, 69, 71, 77, 78, 79], "columntransformer__countvectorizer__max_featur": [19, 33, 56, 77], "columntransformer__pipeline__polynomialfeatures__degre": 19, "columntransformercolumntransform": [17, 19, 21, 22, 24, 30, 33, 35, 36, 38, 54, 56, 58, 59, 61, 71], "columntransformerifittedcolumntransform": [17, 21, 30, 35, 44, 54, 58, 69], "columntransformerinot": [17, 22, 30, 36, 54, 59], "com": [0, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 47, 49, 50, 54, 55, 57, 58, 59, 66, 67, 68, 70, 71, 78, 80], "comat": 65, "combin": [13, 16, 19, 20, 24, 26, 29, 33, 34, 40, 44, 47, 50, 53, 54, 56, 57, 61, 64, 66, 67, 68, 69, 74, 75, 77, 79], "come": [10, 12, 13, 16, 17, 20, 24, 25, 26, 29, 30, 34, 40, 42, 44, 46, 49, 50, 53, 54, 57, 61, 64, 65, 66, 67, 68, 69, 74], "comedi": [46, 64], "comfi": 44, "comfort": [5, 46], "command": [4, 10, 20, 57, 65, 70], "comment": [8, 9, 44], "commerci": 0, "commit": [7, 20, 34, 47, 57, 80], "common": [1, 8, 11, 13, 14, 15, 19, 20, 21, 22, 24, 26, 27, 28, 33, 34, 35, 38, 40, 43, 48, 50, 51, 52, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 70, 72, 75, 80], "commonli": [13, 16, 19, 20, 26, 29, 33, 34, 47, 50, 53, 56, 57, 62, 68], "commonwealth": 65, "commun": [1, 2, 10, 11, 17, 19, 21, 30, 33, 35, 40, 48, 54, 56, 58, 70, 80], "commut": [8, 21], "comp_dict": [20, 34, 57], "compact": [19, 24, 33, 40, 56, 61], "compani": [20, 34, 57, 62, 64, 65, 68, 71, 78], "compar": [8, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 47, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 69, 72, 73, 77, 78, 79], "comparison": [44, 63, 66, 68, 73], "compassion": 80, "compat": [8, 23, 39, 60], "compatibitl": 8, "compel": 67, "compet": 71, "competit": [22, 36, 38, 59, 66, 72], "complain": [6, 71], "complaint": [6, 80], "complement": 65, "complet": [1, 6, 7, 12, 16, 19, 22, 23, 24, 25, 27, 29, 33, 36, 37, 38, 39, 40, 44, 46, 49, 53, 56, 59, 60, 61, 63, 65, 68, 69, 74, 75, 78, 79, 80], "complex": [11, 13, 15, 18, 19, 21, 22, 23, 24, 26, 28, 32, 35, 36, 37, 38, 39, 40, 43, 44, 50, 52, 55, 56, 58, 59, 60, 61, 63, 65, 66, 67, 70, 75], "complex_warn": 44, "complexwarn": 44, "compli": 0, "complic": [4, 13, 14, 19, 21, 24, 26, 33, 35, 40, 43, 44, 48, 50, 51, 56, 58, 61], "compon": [17, 20, 30, 34, 54, 57, 64, 67, 69, 70, 80], "components_": 65, "compos": [15, 17, 19, 20, 21, 22, 23, 24, 30, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 48, 52, 54, 56, 57, 58, 59, 60, 61, 66, 67, 68, 69, 76, 77, 78, 79], "composit": [17, 30, 54], "compound": [65, 66, 68, 71], "comprehend": [43, 65], "comprehens": [62, 73, 80], "compress": [17, 30, 46, 54, 62, 65], "compris": [12, 13, 25, 26, 49, 50, 62], "comput": [1, 7, 9, 10, 11, 17, 19, 20, 22, 23, 24, 30, 33, 34, 37, 39, 40, 43, 47, 49, 54, 56, 57, 59, 60, 61, 62, 63, 65, 67, 69, 70, 72, 78, 79, 80], "computation": [24, 40, 61], "compute_class_weight": [20, 34, 57], "computer_programm": 65, "coms4995": [16, 29, 53], "con": [62, 65, 66, 69], "concat": [12, 15, 16, 17, 18, 23, 25, 28, 29, 30, 32, 37, 39, 49, 52, 53, 54, 55, 60], "concaten": [17, 30, 54, 65], "concav": [24, 40, 61], "concensu": [14, 51], "concentr": [19, 56, 73], "concept": [1, 11, 13, 14, 23, 24, 26, 27, 37, 39, 40, 44, 50, 51, 60, 61, 62, 67, 73, 75, 80], "conceptnet": 65, "conceptu": [22, 36, 38, 59, 69], "concern": [4, 11, 17, 22, 25, 30, 36, 38, 42, 54, 59, 80], "concess": [1, 7], "concis": [13, 26, 50, 70], "conclus": 69, "concord": 68, "concordance_index": 68, "concordance_index_": 68, "concret": [12, 25, 49, 69], "conda": [12, 20, 21, 22, 23, 25, 34, 35, 36, 37, 38, 39, 43, 47, 49, 57, 58, 59, 60, 62, 65, 68, 71], "condens": 26, "condit": [0, 12, 13, 17, 24, 25, 26, 30, 40, 42, 46, 49, 50, 54, 61, 65, 68], "condition1": [21, 23, 35, 37, 39, 58, 60, 69], "condition1_arteri": [21, 35, 58], "condition1_feedr": [21, 35, 58], "condition1_norm": [21, 35, 58], "condition1_posa": [21, 35, 58], "condition1_posn": [21, 35, 58], "condition1_rra": [21, 35, 58], "condition1_rran": [21, 35, 58], "condition1_rrn": [21, 35, 58], "condition1_rrnn": [21, 35, 58], "condition2": [21, 23, 35, 37, 39, 58, 60, 69], "condition2_arteri": [21, 35, 58], "condition2_feedr": [21, 35, 58], "condition2_norm": [21, 35, 58], "condition2_posa": [21, 35, 58], "condition2_posn": [21, 23, 35, 39, 58, 60], "condition2_rra": [21, 35, 58], "condition2_rran": [21, 23, 35, 58], "condition2_rrnn": [21, 23, 35, 58], "conditional_aft": 68, "conduct": [11, 25], "confer": 65, "confid": [12, 14, 23, 25, 27, 31, 37, 39, 45, 46, 49, 51, 60, 68, 70, 73, 75, 78, 79], "confidenti": [20, 34, 47, 57], "config": 10, "config_context": 44, "configur": [19, 21, 22, 33, 36, 38, 56, 58, 59], "confirm": 10, "conflict": [10, 63, 80], "confound": [24, 40, 61], "confus": [8, 15, 17, 21, 28, 30, 35, 48, 52, 54, 58, 62, 70, 75, 78], "confusingli": [12, 25], "confusion_matrix": [20, 34, 47, 57, 66, 68], "confusionmatrixdisplai": [20, 34, 47, 57, 78], "congrat": [17, 30, 54], "conjunct": [24, 40, 61], "connect": [0, 13, 26, 50, 63, 64, 70], "connot": 65, "conort": [24, 40, 61], "consciou": 80, "consecut": 67, "consequ": [7, 12, 17, 20, 25, 34, 49, 54, 57, 64, 69, 78], "consid": [4, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 43, 44, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 67, 69, 70, 73, 75, 80], "consider": [2, 11, 20, 22, 36, 38, 46, 57, 59, 62, 64, 68, 69, 70], "consist": [6, 7, 13, 14, 16, 26, 27, 29, 44, 46, 50, 51, 53, 62, 70, 71], "const": 65, "constant": [13, 20, 21, 22, 23, 26, 34, 35, 36, 37, 38, 39, 44, 48, 50, 57, 58, 59, 60, 67, 68, 69, 78], "constitu": [22, 36, 38, 59], "constitut": [65, 80], "construct": 64, "constructor": [13, 16, 29, 50, 53], "consult": [15, 28, 43, 52, 75, 80], "consum": [12, 24, 25, 40, 49, 61, 62, 64, 70, 73], "consumpt": 67, "contact": [12, 25, 49, 80], "contain": [8, 10, 12, 13, 16, 17, 18, 21, 25, 26, 29, 30, 32, 35, 44, 46, 49, 50, 53, 54, 55, 58, 64, 65, 66, 70, 71, 72], "container": 70, "contamin": 46, "content": [1, 4, 10, 11, 25, 62, 65, 66, 70, 73, 80], "contest": 6, "context": [11, 13, 16, 18, 19, 20, 22, 23, 24, 26, 29, 32, 33, 34, 36, 37, 38, 39, 40, 47, 50, 53, 55, 56, 57, 59, 60, 61, 63, 64, 66, 67, 69, 73, 75], "contextu": 11, "contin": [17, 54], "conting": 63, "continu": [17, 19, 21, 22, 24, 30, 33, 35, 38, 44, 48, 54, 56, 58, 59, 61, 65, 67, 69], "contract": [0, 68], "contract_month": 68, "contract_on": 68, "contract_two": 68, "contrast": [11, 73], "contribut": [15, 18, 23, 28, 32, 37, 39, 52, 55, 60, 66, 79, 80], "control": [5, 8, 13, 14, 15, 17, 18, 21, 22, 26, 27, 28, 30, 32, 35, 36, 38, 40, 48, 50, 51, 52, 54, 55, 58, 59, 66, 80], "convei": 11, "conveni": [8, 12, 19, 20, 25, 33, 34, 47, 56, 57, 62, 65, 67, 68, 69, 70], "converg": 62, "convers": [20, 21, 23, 35, 37, 39, 48, 57, 58, 60, 65, 70, 77], "convert": [12, 16, 17, 18, 22, 23, 24, 25, 29, 30, 32, 36, 37, 38, 39, 44, 48, 49, 53, 54, 55, 59, 60, 61, 65, 67, 68, 80], "convinc": [17, 30, 54, 69], "convolut": [24, 40, 61, 66], "convolutional_neural_network": 66, "cooccurrencematrix": 65, "cook": 62, "cool": [46, 66], "coolwarm": [18, 32, 55], "coordin": [25, 80], "copi": [0, 7, 8, 10, 13, 22, 23, 26, 36, 37, 38, 39, 44, 50, 56, 59, 60, 62, 64, 66, 67, 68, 69, 79, 80], "copyright": 0, "cor": [23, 37, 39, 60], "coral": 66, "core": [9, 11, 16, 17, 19, 20, 21, 24, 29, 30, 33, 34, 35, 40, 44, 51, 53, 54, 56, 57, 58, 61, 63, 64, 67, 68, 70, 73], "corefer": 65, "corei": 70, "corgi": [12, 25, 49, 66], "corner": 46, "corona_nlp_test": 71, "coronapocalyps": 71, "coronaviru": 71, "corpor": [5, 71], "corpora": [17, 30, 54, 65], "corpu": [17, 20, 30, 54, 57, 65], "corr": [23, 37, 39, 60], "corr_df": [23, 37, 39, 60], "correct": [7, 12, 13, 14, 15, 20, 22, 23, 25, 26, 27, 28, 34, 36, 37, 38, 39, 47, 49, 50, 51, 52, 57, 59, 60, 68, 69, 74, 75, 79], "correctli": [1, 10, 13, 14, 20, 26, 27, 34, 47, 50, 51, 57], "correl": [40, 67, 73], "correspond": [1, 12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 25, 26, 27, 30, 32, 33, 34, 35, 37, 39, 43, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 62, 64, 67, 75, 77, 80], "cosin": 65, "cosine_similar": 65, "cost": [8, 12, 25, 46, 49, 66, 69, 80], "cost_rep": 8, "costco": 65, "costli": [20, 34, 47, 57], "cot": 66, "cote": 66, "could": [6, 8, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 33, 34, 35, 36, 38, 40, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 64, 65, 67, 68, 69, 70, 75, 77, 78, 80], "couldn": [46, 65], "count": [8, 13, 16, 17, 20, 21, 24, 26, 29, 30, 34, 35, 40, 42, 44, 46, 48, 50, 53, 54, 57, 58, 61, 65, 66, 67, 68, 70, 71, 72, 75, 77, 78, 80], "counter": [20, 57], "counti": [42, 75], "countri": [14, 15, 17, 18, 20, 22, 23, 27, 28, 32, 34, 36, 37, 38, 39, 51, 52, 54, 55, 57, 59, 60, 65, 78, 80], "country_columbia": [23, 37, 39, 60], "country_dominican": [23, 37, 39, 60], "country_guatemala": [23, 37, 60], "country_holand": 39, "country_hondura": [23, 37, 39, 60], "country_hong": [23, 37, 39, 60], "country_hungari": [23, 37, 39, 60], "country_india": [23, 37, 39, 60], "country_iran": [23, 37, 60], "country_ireland": 39, "country_miss": [22, 23, 36, 37, 38, 39, 59, 60], "country_outli": 39, "country_puerto": [22, 23, 37, 39, 60], "country_scotland": [22, 23, 37, 39, 60], "country_south": [22, 23, 37, 39, 60], "country_taiwan": [22, 23, 37, 39, 60], "country_thailand": [22, 23, 37, 39, 60], "country_trinadad": [22, 23, 36, 37, 38, 39, 59, 60], "country_unit": [22, 23, 36, 37, 38, 39, 59, 60], "country_vietnam": [22, 23, 36, 37, 38, 39, 59, 60], "country_yugoslavia": [22, 23, 36, 37, 38, 39, 59, 60], "countvector": [12, 18, 19, 20, 25, 31, 32, 33, 44, 45, 46, 49, 55, 56, 57, 65, 70, 71, 73, 77], "countvectorizercountvector": [17, 19, 30, 33, 46, 54, 56, 71], "countvectorizeroriginaltweet": 71, "countvectorizersong_titl": [19, 33, 56], "coupl": [4, 13, 19, 33, 50, 56, 63, 71], "cour": 65, "cours": [2, 4, 5, 6, 7, 10, 13, 14, 17, 18, 20, 21, 22, 23, 24, 26, 27, 30, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 50, 51, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 71, 73, 74, 75, 77], "coursera": [1, 9], "coursework": 80, "court": 65, "covari": [13, 26, 50, 68], "cover": [8, 11, 20, 22, 25, 34, 38, 57, 59, 62, 66, 67, 80], "coverag": [20, 34, 47, 57], "covid": 71, "covid2019": 71, "cow": 69, "cox": 11, "coxph_fitt": 68, "coxphfitt": 68, "cph": [68, 69, 73], "cph_param": 68, "cpsc": [9, 10, 13, 22, 24, 26, 36, 38, 40, 49, 50, 59, 61, 65, 66, 67, 69, 70, 71, 80], "cpsc330": [0, 1, 10, 12, 17, 23, 25, 26, 30, 37, 39, 41, 43, 44, 49, 50, 51, 54, 56, 60, 65, 66, 68, 70, 71, 80], "cpsc330env": 10, "cpu": [19, 33, 43, 56, 66], "craft": [15, 20, 22, 23, 28, 34, 36, 37, 38, 39, 52, 57, 59, 60, 62, 75], "crash": [1, 47], "crate": 66, "crawl": 46, "crazi": [44, 70], "creat": [8, 9, 10, 12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79], "create_lag_df": 67, "create_lag_featur": 67, "create_y_from_r": 64, "creativ": [1, 46, 65], "credenc": 69, "credit": [0, 13, 20, 26, 34, 38, 47, 50, 57, 59, 65, 67, 68, 69, 78], "creditcard": [20, 34, 47, 57, 78], "creepi": 46, "crime": [18, 32, 55], "crimin": [23, 37, 39, 60], "criteria": [13, 26, 50, 63], "criterion": [63, 69], "critic": [11, 69], "cross": [13, 15, 17, 19, 21, 22, 23, 26, 30, 33, 35, 36, 37, 38, 39, 44, 48, 50, 52, 54, 56, 58, 59, 60, 62, 64, 68, 69, 70, 71, 73, 76, 77, 78, 79], "cross_val": [22, 36, 38, 59], "cross_val_predict": [20, 22, 34, 36, 38, 47, 57, 59, 68], "cross_val_scor": [16, 17, 18, 19, 20, 21, 22, 23, 24, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 53, 54, 55, 56, 57, 58, 59, 60, 61, 67, 68, 69, 73, 76, 77, 78, 79], "cross_valid": [15, 16, 17, 18, 19, 20, 22, 23, 24, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 59, 60, 61, 64, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78, 79], "cross_validate_std": [14, 27, 51], "crowd": [22, 36, 38, 59, 63], "crown": 80, "crown_princ": 65, "crucial": [12, 14, 18, 23, 25, 27, 32, 37, 39, 49, 51, 55, 60, 62, 63, 64, 65], "crude": 65, "cs189": 9, "cs189_ch7": 9, "csr": 44, "css": 70, "csv": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79], "ct": [17, 30, 54], "cuda": [43, 66], "cui": [1, 80], "cuisin": 70, "cultiv": 11, "cultur": [66, 80], "curios": [12, 25, 49], "curiou": [12, 25, 49, 75], "curl": 70, "current": [1, 22, 36, 38, 59, 65, 66, 67, 68, 69, 70, 71], "curriculum": 11, "curs": 69, "curv": [7, 8, 11, 32, 62, 69, 73, 75], "cush": 46, "custom": [5, 8, 12, 13, 17, 20, 21, 25, 26, 30, 34, 35, 44, 47, 48, 49, 50, 54, 57, 58, 64, 70, 71, 73], "custom_plot_tre": [13, 14, 22, 23, 26, 27, 36, 37, 38, 39, 50, 51, 59, 60], "customerid": 68, "customiz": 71, "cut": 63, "cv": [14, 17, 20, 21, 22, 23, 24, 27, 30, 35, 36, 37, 38, 39, 40, 42, 43, 48, 51, 54, 57, 58, 59, 60, 61, 67, 68, 69, 70, 73, 75, 77], "cv_feat": 71, "cv_results_": [19, 21, 33, 35, 48, 56, 58, 77], "cv_score": [14, 21, 27, 35, 43, 48, 51, 58], "cv_train_scor": [42, 75], "cv_valid_scor": [42, 75], "cycl": 8, "cyclic": 67, "cycling_data": 8, "cygnu": 66, "d": [4, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 40, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 70, 78, 79], "d3": 62, "da": [12, 25, 49], "dabeaz": 9, "dad": [24, 40, 61], "daft": 46, "dai": [4, 8, 14, 24, 40, 44, 46, 61, 66, 68, 69, 73, 80], "daili": [68, 73], "dall": 67, "damag": [0, 20, 34, 57], "dan": 65, "danceabl": [15, 16, 19, 29, 33, 52, 53, 56, 77], "dark": 71, "darker": [19, 33, 56], "dashboard": [15, 28, 43, 52, 75], "data": [1, 2, 5, 7, 8, 9, 10, 11, 24, 31, 34, 40, 43, 45, 46, 47, 63, 65, 68, 72, 73, 74, 76, 77, 78, 79, 80], "data_dict": [18, 32, 55], "data_dir": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 77, 78, 79], "data_to_wrap": [17, 30, 54], "data_transform": [43, 66], "data_transforms_bw": 66, "data_url": [20, 34, 47, 57, 78], "datacamp": 9, "datafram": [12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 73, 75, 76, 77, 79], "dataload": [43, 66], "dataloaders_bw": 66, "datapoint": [18, 32, 55], "dataquest": 9, "dataset": [8, 11, 12, 14, 15, 17, 22, 23, 24, 25, 27, 28, 30, 36, 37, 38, 39, 40, 42, 43, 44, 49, 51, 52, 59, 60, 61, 62, 63, 68, 70, 71, 72, 73, 75, 77, 78], "dataset2": 62, "dataset_s": [43, 66], "dataviz": 69, "date": [7, 10, 12, 13, 25, 40, 42, 49, 50, 64, 65, 68, 70, 71, 73, 75, 80], "date_rang": 67, "dates_rain": 67, "datetim": 68, "datetime64": 67, "datetimeindex": 67, "datum": 65, "daughter": [20, 46, 57, 70], "daum\u00e9": 1, "daunt": 64, "dave": 65, "david": [1, 65, 69], "dawn": 46, "day_nam": 67, "daylight": 67, "dayofweek": 67, "days_sinc": 67, "dbscan": [11, 70], "dc": [67, 68, 71], "dcc": [18, 32, 55], "dd": 67, "de": [65, 67], "deactiv": 10, "dead": 46, "deadlin": [14, 25, 80], "deal": [0, 14, 15, 16, 21, 27, 28, 29, 35, 44, 48, 51, 52, 53, 58, 65, 68, 69, 70, 73, 76], "death": 80, "debat": [8, 23, 25, 37, 39, 60], "debbi": 71, "deborah": 46, "debug": [4, 23, 37, 39, 60], "decad": 66, "decemb": [42, 67], "decent": 46, "decid": [8, 13, 15, 18, 22, 23, 24, 26, 28, 32, 36, 37, 38, 39, 40, 46, 50, 52, 55, 59, 60, 61, 62, 63, 65, 67, 68, 73], "decis": [1, 2, 6, 14, 16, 19, 20, 22, 24, 27, 29, 31, 33, 34, 36, 38, 40, 45, 46, 47, 51, 53, 56, 57, 59, 61, 66, 72, 73, 74, 76, 79, 80], "decision_boundari": 72, "decision_funct": [20, 34, 47, 57], "decisiontreeclassifi": [14, 15, 16, 17, 18, 19, 23, 27, 28, 29, 30, 32, 33, 37, 39, 43, 51, 52, 53, 54, 55, 56, 60, 74, 75, 76, 77, 79], "decisiontreeclassifierdecisiontreeclassifi": [22, 36, 38, 59], "decisiontreeregressor": [13, 21, 26, 35, 42, 48, 50, 58, 74, 75], "decisiontreeregressorifitteddecisiontreeregressor": 42, "deck": 9, "declar": 80, "decomposit": [63, 64, 65], "decor": 44, "decreas": [14, 18, 19, 22, 23, 27, 32, 33, 36, 37, 38, 39, 42, 51, 55, 56, 59, 60, 62, 75], "deduct": 7, "deem": 6, "deep": [2, 9, 19, 23, 24, 33, 37, 39, 40, 56, 60, 61, 65, 68, 70], "deepen": [73, 80], "deeper": [2, 12, 19, 20, 21, 23, 25, 33, 34, 35, 37, 39, 47, 56, 57, 58, 60], "deepexplain": [23, 37, 39, 60], "def": [14, 15, 16, 19, 20, 21, 23, 27, 28, 29, 31, 33, 34, 35, 37, 39, 40, 43, 44, 45, 46, 47, 48, 51, 52, 53, 56, 57, 58, 60, 62, 63, 64, 65, 66, 67, 70, 71, 75, 77], "defalut": 77, "default": [5, 10, 12, 13, 14, 17, 18, 19, 20, 21, 22, 25, 26, 27, 30, 32, 33, 34, 35, 36, 38, 40, 43, 47, 48, 50, 51, 54, 55, 56, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 77, 78, 80], "default_check_param": 44, "default_threshold": [20, 34, 47, 57], "defaultdict": 64, "defin": [13, 15, 16, 17, 20, 22, 23, 28, 29, 30, 34, 36, 37, 38, 39, 44, 50, 52, 53, 54, 57, 59, 60, 62, 63, 64, 67, 70], "definit": [8, 15, 23, 28, 37, 39, 52, 60, 62, 65, 67, 72, 73, 74], "degre": [19, 20, 34, 47, 57], "degrees_freedom": 68, "degrees_of_freedom": 68, "del": [22, 36, 38, 59], "delai": [1, 10, 24, 40, 61], "deleg": 65, "delet": [4, 7, 16, 29, 53, 69], "delgado": [22, 36, 38, 59], "delight": 65, "deliver": 7, "delv": [11, 65], "demo": [1, 22, 25, 36, 38, 59, 69, 80], "demograph": [13, 26, 50, 64], "demonstr": [13, 14, 16, 18, 19, 21, 22, 26, 27, 29, 31, 32, 33, 35, 36, 38, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 58, 59, 62, 64, 65, 66], "denholm": 46, "denois": 12, "denomin": [21, 35, 48, 58, 71], "denot": [13, 26, 50, 64], "dens": [63, 65], "densenet": [43, 66], "densenet121": [43, 66], "densenet121_weight": [43, 66], "densiti": [23, 37, 39, 60, 63, 73], "dep": 65, "department": 80, "departur": [24, 40, 61], "depend": [2, 8, 10, 13, 14, 15, 17, 19, 20, 21, 22, 23, 26, 27, 28, 30, 33, 34, 35, 36, 37, 38, 48, 50, 51, 52, 54, 56, 57, 58, 59, 60, 62, 63, 65, 67, 68, 69, 79], "dependence_plot": [23, 37, 39, 60], "dependents_no": 68, "dependents_y": 68, "deploi": [14, 20, 27, 34, 42, 47, 51, 57, 64, 69, 73], "deploy": [11, 23, 37, 39, 60, 67], "deprec": [20, 21, 29, 35, 47, 51, 53, 57, 58, 68, 71, 72], "deprecationwarn": [22, 36, 38, 59, 68], "depth": [1, 13, 14, 19, 22, 26, 27, 33, 36, 38, 42, 50, 51, 56, 59, 63, 74, 75], "dequ": [22, 23, 36, 37, 38, 39, 59, 60, 79], "deran": 46, "deriv": [0, 13, 18, 20, 26, 32, 34, 50, 55, 57, 64, 68, 73, 78], "descend": [8, 31, 45, 46, 63, 66, 73], "descent": [46, 67], "descr": [18, 32, 55], "describ": [8, 11, 12, 13, 14, 15, 16, 18, 20, 21, 25, 26, 27, 28, 29, 32, 34, 35, 42, 44, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 64, 65, 67, 70, 75, 78], "descript": [1, 21, 35, 58, 68, 71], "desenet": 43, "deserv": 6, "design": [11, 23, 26, 37, 39, 50, 60, 63, 66, 69, 77, 80], "desir": [20, 34, 44, 47, 57, 65, 68, 76], "desk": 80, "despit": [24, 61, 65], "det": [46, 65, 71], "detach": [43, 66], "detail": [15, 17, 22, 28, 30, 34, 36, 52, 54, 59, 65, 66, 70, 80], "detect": [12, 13, 20, 21, 25, 26, 34, 35, 42, 47, 48, 49, 50, 57, 58, 62, 63, 67, 70, 78], "determin": [15, 26, 28, 43, 52, 62, 63, 65, 68, 69, 75, 79, 80], "detriment": [20, 34, 57, 64, 78], "dev": [14, 51, 72], "develop": [1, 9, 11, 12, 14, 16, 17, 19, 20, 21, 22, 25, 27, 29, 30, 33, 34, 35, 36, 37, 46, 47, 48, 49, 51, 53, 54, 56, 57, 58, 59, 65, 66, 69, 70, 71, 73], "devianc": 68, "deviat": [6, 14, 16, 22, 23, 27, 29, 36, 37, 38, 39, 51, 53, 59, 60], "devic": [22, 36, 38, 43, 44, 59, 66], "deviceprotect": 68, "deviceprotection_no": 68, "deviceprotection_y": 68, "df": [12, 13, 14, 16, 17, 19, 20, 21, 23, 24, 25, 27, 29, 30, 33, 34, 35, 37, 39, 40, 42, 44, 47, 48, 49, 50, 51, 53, 54, 56, 57, 58, 60, 61, 66, 67, 68, 69, 70, 71, 74], "df_concat": [12, 25, 49], "df_float_1": 8, "df_float_2": 8, "df_hour_week_ohe_poli": 67, "df_locat": 67, "di": 68, "diagnos": [14, 23, 37, 39, 51, 60, 73], "diagnosi": [20, 34, 57], "diagnost": [68, 70], "diagon": [15, 20, 23, 28, 34, 37, 39, 47, 52, 57, 60], "diagram": [17, 19, 22, 23, 30, 33, 36, 37, 38, 39, 54, 56, 59, 60], "dialogu": [46, 65], "dict": [20, 34, 57, 64], "dict_kei": [19, 22, 36, 38, 59], "dictionari": [8, 16, 19, 20, 22, 23, 29, 33, 34, 36, 37, 47, 53, 56, 57, 59, 60, 70], "did": [6, 12, 13, 15, 23, 25, 26, 28, 37, 39, 46, 47, 50, 52, 60, 62, 65, 67, 71, 75, 77, 78, 79, 80], "didn": [19, 22, 23, 33, 36, 37, 38, 39, 44, 46, 56, 59, 60, 63, 65, 67, 68, 70], "die": 71, "diet": [13, 26, 50, 65], "diff": 67, "differ": [1, 2, 5, 7, 8, 10, 11, 12, 13, 14, 15, 17, 18, 22, 24, 25, 26, 27, 28, 30, 32, 36, 38, 40, 42, 44, 46, 49, 50, 51, 52, 54, 55, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 74, 75, 77, 78, 79], "differenti": [11, 12, 13, 25, 26, 49, 50], "difficult": [4, 6, 7, 20, 24, 34, 40, 57, 61, 62, 69], "difficulti": [62, 73], "dig": [20, 21, 34, 35, 47, 57, 58], "digit": [67, 69], "dilemma": 64, "dim": [43, 44, 66], "dimens": [8, 18, 24, 32, 40, 55, 61], "dimension": [2, 8, 18, 19, 20, 22, 24, 26, 32, 33, 34, 36, 38, 40, 43, 47, 55, 56, 57, 59, 61, 62, 65], "dine": 70, "direct": [18, 23, 24, 29, 31, 32, 37, 39, 40, 45, 46, 55, 60, 61, 63, 65, 71], "direct_bilirubin": [12, 25, 49], "directli": [1, 8, 17, 21, 30, 35, 44, 54, 58, 66, 68, 70, 80], "director": [46, 64], "directori": [10, 13, 14, 16, 27, 29, 43, 50, 51, 53], "dirichlet": [65, 66], "disabl": 65, "disadvantag": [19, 22, 33, 36, 38, 56, 59, 63, 64, 76], "disappoint": 46, "disast": [12, 49], "discard": [24, 40, 61, 65], "disciplin": [20, 24, 34, 40, 57, 61], "disclos": [71, 80], "discomfort": 46, "discourag": [8, 40], "discours": 64, "discov": [24, 40, 61, 62], "discoveri": [12, 25, 49], "discret": [13, 24, 26, 40, 44, 50, 61], "discrete_scatt": [13, 14, 15, 18, 26, 27, 28, 32, 43, 50, 51, 52, 55, 62, 63, 66, 72, 74, 75], "discretization_feat": [24, 40, 61], "discrimin": [22, 59], "discuss": [4, 14, 15, 16, 18, 23, 24, 27, 28, 29, 32, 37, 39, 40, 47, 51, 52, 53, 55, 60, 61, 62, 63, 67, 73, 75, 76, 77, 79, 80], "diseas": [13, 20, 26, 34, 47, 50, 57, 68], "dislik": [44, 69], "dispers": 46, "displaci": [65, 71], "displai": [7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 63, 64, 66, 67, 68, 74, 75, 76, 77, 78], "display_heatmap": [19, 33, 56, 77], "display_label": [20, 34, 47, 57, 78], "displaystyl": 65, "disput": 65, "disregard": 46, "disrespect": 4, "dissemin": 70, "dist": [15, 28, 43, 52, 62, 63], "distanc": [8, 16, 24, 29, 40, 43, 53, 61, 63, 64, 65], "distinct": [20, 24, 34, 40, 47, 57, 61, 67, 69], "distinguish": [13, 15, 17, 20, 26, 28, 30, 34, 43, 47, 50, 52, 54, 57, 75], "distract": 80, "distribut": [0, 10, 12, 14, 20, 23, 24, 27, 34, 37, 39, 40, 42, 44, 47, 51, 57, 60, 61, 63, 65, 66, 67, 77, 80], "district": [16, 18, 29, 32, 53, 55], "districtdatalab": 62, "disturb": [12, 25, 49], "dive": [23, 37, 39, 60], "divers": [11, 22, 36, 38, 59, 62, 64, 67], "divid": [18, 20, 22, 23, 32, 34, 36, 37, 38, 39, 55, 57, 59, 60, 67, 75], "divis": [23, 26, 37, 39, 60], "divorc": [22, 23, 36, 37, 38, 39, 59, 60], "dktal": 68, "dlwqn": 68, "dmp": 80, "do": [0, 1, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 18, 21, 25, 26, 27, 28, 30, 32, 35, 42, 43, 46, 48, 49, 50, 51, 52, 55, 58, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "dobj": 65, "doc": [8, 9, 12, 31, 45, 46, 60, 65, 66, 70, 71, 80], "doc_id": 65, "docker": 70, "doctor": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "document": [0, 1, 7, 12, 13, 14, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 47, 48, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 65, 66, 67, 68, 69, 71, 73, 77, 78, 79, 80], "document_top": 65, "documentari": 64, "doe": [5, 8, 10, 12, 14, 15, 16, 19, 21, 22, 23, 24, 25, 28, 29, 33, 35, 36, 37, 38, 39, 40, 43, 44, 46, 48, 49, 51, 52, 53, 56, 58, 59, 60, 61, 62, 64, 65, 67, 68, 70, 71, 73, 75, 77, 79, 80], "doesn": [7, 8, 12, 14, 16, 17, 20, 21, 22, 23, 27, 29, 30, 34, 35, 36, 37, 38, 39, 46, 47, 51, 53, 54, 57, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 73], "dog": [20, 34, 43, 57, 66], "dolist": 70, "dollar": [4, 18, 21, 32, 35, 48, 55, 58, 69], "dolli": 71, "domain": [0, 12, 23, 25, 37, 39, 49, 60, 62, 65], "domin": [16, 21, 29, 35, 46, 53, 58, 66], "domingo": [1, 14, 24, 40, 51, 61], "dominican_republ": 65, "don": [4, 12, 13, 14, 16, 17, 19, 20, 22, 23, 24, 25, 27, 30, 31, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 46, 49, 51, 54, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "done": [5, 10, 12, 14, 17, 19, 20, 25, 27, 30, 33, 34, 46, 51, 54, 56, 57, 66, 67, 69, 73, 76, 78], "dont": 71, "door": 66, "dosa": 65, "dot": [15, 18, 20, 22, 23, 24, 28, 32, 34, 37, 38, 39, 40, 47, 52, 55, 57, 59, 60, 61, 63, 65], "dot_product": 65, "doubl": [19, 33, 46, 56], "down": [14, 20, 23, 27, 34, 37, 39, 44, 46, 47, 51, 57, 60, 65, 68, 69, 75, 79, 80], "downfal": 64, "download": [5, 7, 10, 12, 13, 16, 18, 20, 21, 23, 25, 29, 32, 34, 35, 37, 42, 47, 48, 49, 50, 53, 55, 57, 58, 60, 65, 66, 69, 71, 75, 79], "downright": 69, "dpi": [24, 40, 43, 61], "dr": 65, "draft": 1, "drag": 7, "drama": 64, "drastic": [20, 34, 57], "draw": [18, 19, 32, 33, 55, 56, 65, 69], "drawback": [11, 23, 37, 39, 60, 64], "drawn": [22, 36, 38, 59], "dream": 66, "dreampharmaceut": 65, "drink": 69, "drinker": 65, "drive": [12, 23, 25, 31, 37, 39, 45, 46, 49, 60], "driven": [10, 19, 20, 33, 34, 47, 56, 57], "droit": 65, "drop": [7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80], "drop_dupl": [15, 19, 28, 33, 52, 56], "drop_feat": [17, 30, 44, 54, 73], "drop_feats_new": 44, "drop_featur": [20, 21, 22, 23, 34, 35, 36, 37, 38, 39, 48, 57, 58, 59, 60, 67, 68, 69, 71, 78], "dropdrop": [17, 21, 22, 30, 35, 36, 38, 44, 54, 58, 59, 69, 71], "drope": [16, 29, 53], "dropna": [20, 57, 67, 70], "dropoff": 62, "drought": [45, 46], "drug": [12, 25, 49, 70], "dsci": [1, 9, 23, 37, 60, 69, 72], "dsl": 68, "dt": [42, 75], "dt_best": 75, "dt_final": 42, "dt_pipe": [19, 33, 56], "dt_regr": 42, "dtype": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 46, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 78, 79], "dtypelik": 44, "dual": [20, 34, 57], "duan": [1, 80], "dub": 46, "duck": [66, 69], "duckbil": 66, "due": [7, 12, 13, 14, 16, 17, 18, 22, 24, 25, 36, 38, 39, 40, 55, 59, 61, 64, 80], "duffel": 46, "dull": 46, "dummi": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 68, 69, 74, 76, 77, 78, 79], "dummy_clf": [13, 26, 50, 74], "dummy_regr": 42, "dummy_scor": [15, 28, 52], "dummy_valid_accuraci": [15, 28, 52], "dummyclassifi": [14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 66, 69, 70, 71, 74, 75, 76, 77, 78, 79], "dummyregressor": [17, 22, 23, 24, 30, 36, 37, 38, 39, 40, 42, 48, 54, 59, 60, 61, 69, 70, 76, 79], "dump": 70, "dun": [12, 25, 49], "dunham": 46, "dunno": [12, 25, 49], "duplex": [21, 35, 48, 58], "duplic": 8, "durat": [7, 24, 40, 61, 67, 68], "duration_col": 68, "duration_m": [15, 16, 19, 29, 33, 52, 53, 56], "dure": [1, 4, 8, 12, 13, 15, 17, 18, 19, 22, 23, 24, 25, 26, 28, 30, 32, 33, 36, 37, 38, 39, 40, 42, 46, 49, 50, 52, 54, 55, 56, 59, 60, 61, 64, 65, 70, 73, 74, 75, 76, 77, 78, 79, 80], "dwell": [21, 35, 48, 58], "e": [6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73], "e737c5242822": 68, "e_": [14, 27, 51], "each": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 79, 80], "eager": 70, "earli": [23, 37, 39, 46, 60, 68, 69, 80], "earlier": [16, 22, 24, 29, 36, 38, 40, 46, 53, 59, 61, 67, 68], "early_stopping_round": [22, 36, 38, 59], "earnest": 80, "easi": [7, 15, 16, 18, 22, 23, 24, 28, 29, 32, 36, 37, 38, 39, 40, 52, 53, 55, 59, 60, 61, 62, 63, 65, 69, 71], "easier": [5, 7, 20, 23, 24, 34, 37, 39, 40, 47, 57, 60, 61, 64, 69], "easiest": [23, 37, 39, 60, 68], "easili": [22, 24, 36, 38, 40, 59, 61, 67, 69, 70, 74], "east": [44, 46], "eat": 46, "eat_out_freq": 44, "echidna": 66, "econom": [17, 30, 54, 67], "ecosystem": 66, "eda": [14, 27, 42, 44, 51, 65, 68, 73], "edg": [13, 19, 26, 33, 50, 56], "edgecolor": [19, 33, 56, 67], "edit": [33, 56, 65], "edu": 9, "educ": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 64, 78], "education_level": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "effect": [15, 18, 19, 20, 21, 23, 24, 28, 32, 33, 34, 35, 37, 39, 40, 42, 43, 46, 48, 52, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 70, 73, 75, 78, 80], "effici": [19, 33, 56], "effort": [4, 10, 19, 24, 33, 40, 56, 61, 62, 64, 66, 80], "egg": 62, "either": [4, 13, 14, 15, 17, 20, 23, 26, 27, 28, 30, 34, 37, 39, 43, 47, 50, 51, 52, 54, 57, 60, 62, 63, 65, 66, 67, 75, 77], "elast": [40, 68], "elbow": 63, "elect": 65, "electr": [21, 23, 35, 37, 39, 58, 60, 69], "electrical_engin": 65, "electrical_fusea": [21, 35, 58], "electrical_fusef": [21, 35, 58], "electrical_fusep": [21, 35, 58], "electrical_miss": [21, 35, 58], "electrical_mix": [21, 35, 58], "electrical_sbrkr": [21, 35, 58], "electron": [68, 80], "eleg": [16, 29, 53, 65, 69], "elegantli": 65, "element": [0, 1, 9, 14, 17, 30, 46, 51, 54, 65, 74], "eli5": [23, 39, 60], "elif": [13, 26, 50, 67, 68], "elimin": 11, "elliott": 46, "els": [13, 17, 20, 26, 30, 34, 43, 44, 50, 54, 57, 66, 67, 68, 71, 78], "email": [1, 12, 13, 14, 20, 25, 27, 34, 49, 51, 57, 70, 80], "emb": [7, 15, 20, 28, 34, 47, 52, 57, 62, 63], "embarrass": 46, "embed": [1, 11, 17, 30, 54, 66, 70, 73], "emili": 46, "emoji": [45, 46, 71], "emoticon": [24, 40, 61, 62], "emp": [23, 37, 39, 60], "empathi": 65, "emphas": 11, "emphasi": [70, 80], "emploi": [43, 67, 68, 70, 73], "employ": 64, "employe": [13, 26, 50], "empti": [18, 32, 43, 55, 65, 66, 67], "en": [67, 68, 69, 71], "en_core_web_lr": 65, "en_core_web_md": [65, 71], "enabl": [10, 64, 65, 67], "enable_categor": [22, 36, 38, 59], "enable_halving_search_cv": [19, 33, 56], "enc": [16, 17, 29, 30, 53, 54, 67], "enclosedporch": [21, 23, 35, 37, 39, 48, 58, 60, 69], "encod": [12, 14, 19, 20, 21, 23, 25, 27, 31, 33, 34, 35, 37, 39, 42, 44, 45, 46, 47, 49, 51, 56, 57, 58, 60, 64, 68, 73, 76, 78], "encompass": [68, 69, 73], "encount": [17, 30, 54, 56], "encourag": 10, "end": [4, 8, 11, 12, 14, 15, 18, 19, 20, 24, 25, 27, 28, 32, 33, 34, 38, 40, 43, 46, 47, 49, 51, 52, 55, 56, 57, 61, 62, 63, 64, 65, 67, 68, 69, 70, 75, 80], "endors": 0, "endpoint": 68, "energi": [15, 16, 19, 29, 33, 52, 53, 56, 67, 77], "engag": 80, "engin": [1, 9, 11, 17, 20, 21, 30, 34, 35, 47, 54, 57, 58, 62, 64, 65, 68, 70], "england": 71, "english": [12, 16, 19, 20, 25, 29, 31, 33, 44, 45, 46, 49, 53, 56, 57, 65, 66, 70, 71, 77], "enhanc": 80, "enjoi": [1, 18, 31, 32, 45, 46, 55], "enjoy_class": [17, 30, 54], "enjoy_cours": [17, 30, 54, 73], "enjoy_course_enc": [17, 30, 54], "enjoy_the_mo": [20, 57, 70], "enough": [7, 15, 17, 20, 21, 22, 28, 34, 35, 36, 38, 46, 47, 52, 54, 57, 58, 59, 62, 64, 73, 77, 78], "enrol": 80, "ensembl": [1, 11, 21, 23, 24, 35, 37, 39, 40, 44, 48, 58, 60, 61, 63, 64, 67, 68, 69, 70, 79], "ensiti": 63, "ensur": [7, 11, 16, 22, 29, 36, 38, 42, 53, 59, 67], "ensure_2d": 44, "ensure_all_finit": 44, "ensure_min_featur": 44, "ensure_min_sampl": 44, "ensure_non_neg": 44, "ent": [65, 71], "enter": [17, 30, 54, 68, 69, 77], "enterpris": 5, "entertain": [46, 65], "enthusiast": [12, 25, 49, 69], "entir": [4, 8, 12, 14, 21, 25, 27, 35, 46, 51, 58, 66, 67, 69, 70, 71, 79, 80], "entiti": [24, 40, 61, 64, 65, 71], "entitl": [17, 30, 54], "entlebuch": [12, 25, 49, 66], "entri": [15, 16, 17, 18, 20, 21, 24, 28, 29, 30, 32, 34, 35, 40, 47, 52, 53, 54, 55, 57, 58, 61, 64, 67, 68], "entropi": [13, 26, 50, 69], "enumer": [22, 36, 59], "env": [10, 17, 26, 30, 43, 44, 50, 51, 54, 56, 60, 68, 71, 72], "environ": [3, 5, 8, 12, 16, 17, 19, 20, 21, 22, 23, 24, 25, 29, 30, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 47, 49, 53, 54, 56, 57, 58, 59, 60, 61, 65, 66, 68, 69, 71, 80], "environemnt": 10, "environment": 73, "ep": [13, 14, 15, 18, 27, 28, 32, 50, 51, 52, 55, 63, 74], "episod": 46, "epoch": 67, "epsilon": [63, 69], "equal": [8, 15, 17, 20, 21, 22, 23, 28, 34, 35, 36, 37, 38, 39, 47, 48, 52, 54, 57, 58, 59, 60, 63, 64, 67, 73, 80], "equat": [4, 12, 18, 25, 32, 40, 55], "equip": [15, 28, 52, 68, 80], "equival": [8, 20, 22, 34, 36, 38, 57, 59, 78], "erik": 65, "err": 65, "error": [4, 6, 7, 8, 10, 11, 13, 15, 17, 18, 22, 23, 24, 26, 28, 30, 32, 36, 37, 38, 39, 40, 44, 50, 52, 54, 55, 59, 60, 61, 65, 68, 69, 70, 73, 75, 79], "error_": [14, 27, 51], "error_scor": 19, "erupt": [12, 49], "erythrocebu": [12, 25, 49, 66], "es": 67, "escap": 46, "eskimo": [20, 34, 57], "esl": 1, "especi": [2, 15, 19, 20, 22, 24, 26, 28, 33, 34, 36, 37, 38, 46, 50, 52, 56, 57, 59, 61, 64, 67], "essenti": [68, 73], "establish": 42, "estat": [13, 26, 50], "estim": [14, 15, 17, 18, 19, 24, 28, 30, 32, 33, 40, 44, 51, 52, 54, 55, 56, 61, 62, 68, 69, 70, 73, 79], "estimator_nam": 44, "estimators_": [22, 36, 38, 59], "et": [22, 36, 38, 59, 65], "etc": [1, 2, 7, 8, 13, 24, 26, 39, 50, 61, 65, 66, 67, 68, 69, 70, 71, 80], "ethic": [1, 11, 70], "euclidean": [62, 63, 65], "euclidean_dist": [15, 16, 28, 29, 52, 53, 62, 63, 65], "ev": 71, "eva": 64, "eva_model": 64, "eval": 66, "eval_metr": [22, 23, 36, 37, 38, 39, 59, 60], "eval_on_featur": 67, "evalu": [1, 8, 11, 13, 14, 19, 21, 23, 26, 27, 33, 37, 39, 42, 50, 51, 56, 58, 60, 62, 67, 69, 70, 75, 79], "evapor": 67, "even": [0, 7, 11, 12, 13, 14, 18, 19, 20, 24, 25, 26, 27, 32, 34, 40, 44, 46, 50, 51, 55, 56, 57, 61, 62, 63, 64, 67, 68, 69, 71, 73, 75, 76, 78, 80], "evenli": 46, "event": [0, 20, 21, 35, 48, 57, 58, 80], "event_col": 68, "event_observ": 68, "ever": [13, 26, 46, 50, 72], "everi": [8, 12, 13, 14, 22, 25, 26, 27, 36, 38, 46, 50, 51, 59, 63, 67, 75], "everydai": [8, 65], "everyon": [6, 23, 37, 39, 60, 69, 73], "everyth": [12, 17, 20, 25, 30, 34, 47, 54, 57, 64, 67, 70, 79], "everywher": 67, "evict": 71, "evo": 70, "evocarshar": 70, "evok": 65, "ex": [21, 23, 35, 37, 39, 48, 58, 60, 69], "ex1_idx": [23, 37, 39, 60], "ex2_idx": [23, 37, 39, 60], "ex_df": [31, 45, 46], "exact": [4, 68], "exactli": [7, 12, 14, 23, 25, 26, 27, 37, 39, 46, 49, 51, 60, 75, 77], "exagger": 69, "exam": [1, 6, 12, 20, 25, 33, 40, 69, 70], "examin": [14, 15, 16, 18, 20, 22, 23, 24, 27, 28, 29, 32, 34, 36, 37, 38, 39, 40, 42, 43, 44, 51, 52, 53, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 70, 72, 78], "exampl": [0, 4, 5, 6, 7, 8, 10, 21, 27, 31, 35, 43, 44, 45, 46, 48, 58, 63, 64, 66, 67, 70, 72, 73, 74, 75, 77, 78, 80], "example1": [13, 26, 50], "example2": [13, 26, 50], "exceedingli": 75, "excel": [17, 18, 21, 23, 30, 31, 32, 35, 37, 39, 45, 46, 48, 54, 55, 58, 60, 68, 73, 76], "except": [0, 1, 7, 8, 14, 27, 44, 46, 51, 67, 68, 80], "exception": 4, "exchang": [20, 34, 47, 57, 73], "excit": 64, "execut": [4, 7, 62, 70], "exercis": [1, 7, 9, 12, 25, 65, 70, 71, 75, 76, 77, 78, 79, 80], "exerciseangina": 79, "exhaust": 77, "exist": [8, 19, 20, 24, 34, 57, 61, 68, 70, 78], "exp": [18, 32, 55, 68, 69], "expand": [1, 13, 26, 50, 80], "expect": [1, 4, 7, 8, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35, 37, 39, 40, 43, 44, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 72, 73, 75, 78, 80], "expected_valu": [23, 37, 39, 60], "expenditur": 67, "expens": [12, 20, 21, 24, 25, 34, 35, 40, 47, 49, 57, 58, 61, 62, 64], "experi": [12, 19, 25, 33, 49, 56, 64, 65, 80], "experienc": 80, "experiment": [19, 33, 46, 56, 70], "expert": [12, 13, 14, 19, 23, 24, 25, 26, 27, 33, 37, 39, 40, 49, 50, 51, 56, 60, 61, 78], "expertis": 40, "explain": [4, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 40, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 73, 78, 79], "explan": [4, 14, 15, 28, 46, 51, 52, 73, 78], "explanatori": [13, 26, 50], "explicit": [20, 34, 47, 57, 68], "explicitli": [8, 12, 25, 49, 70], "exploit": 6, "explor": [13, 14, 17, 19, 20, 23, 24, 27, 30, 31, 33, 34, 37, 39, 40, 42, 43, 45, 46, 47, 50, 51, 54, 56, 57, 60, 61, 64, 65, 66, 70, 75, 77], "exploratori": [21, 35, 58, 68, 70, 73], "explos": 71, "expm1": [21, 35, 48, 58, 69], "expon": [19, 33, 56], "exponenti": [19, 33, 56], "export_graphviz": [13, 26, 50, 74], "expos": [31, 45, 46], "exposur": 64, "express": [0, 8, 17, 18, 24, 30, 32, 40, 46, 54, 55, 61, 65, 69], "extend": [65, 66, 72, 80], "extend_block": 68, "extens": [1, 12, 15, 20, 23, 25, 28, 34, 37, 39, 43, 47, 52, 57, 60, 62, 63, 65, 67, 75, 80], "extent": [62, 65], "extercond": [21, 23, 35, 37, 39, 48, 58, 60, 69], "exterior": [23, 37, 39, 60], "exterior1st": [21, 23, 35, 37, 39, 58, 60, 69], "exterior1st_asbshng": [21, 35, 58], "exterior1st_asphshn": [21, 35, 58], "exterior1st_brkcomm": [21, 35, 58], "exterior1st_brkfac": [21, 35, 58], "exterior1st_cblock": [21, 35, 58], "exterior1st_cemntbd": [21, 35, 58], "exterior1st_hdboard": [21, 35, 58], "exterior1st_imstucc": [21, 23, 35, 39, 58, 60], "exterior1st_metalsd": [21, 35, 58], "exterior1st_plywood": [21, 35, 58], "exterior1st_ston": [21, 35, 58], "exterior1st_stucco": [21, 35, 58], "exterior1st_vinylsd": [21, 35, 58], "exterior1st_wd": [21, 35, 58], "exterior1st_wdsh": [21, 35, 58], "exterior2nd": [21, 23, 35, 37, 39, 58, 60, 69], "exterior2nd_asbshng": [21, 35, 58], "exterior2nd_asphshn": [21, 35, 58], "exterior2nd_brk": [21, 35, 58], "exterior2nd_brkfac": [21, 35, 58], "exterior2nd_cblock": [21, 35, 58], "exterior2nd_cmentbd": [21, 35, 58], "exterior2nd_hdboard": [21, 35, 58], "exterior2nd_imstucc": [21, 35, 58], "exterior2nd_metalsd": [21, 35, 58], "exterior2nd_oth": [21, 35, 58], "exterior2nd_plywood": [21, 35, 58, 69], "exterior2nd_ston": [21, 35, 58, 69], "exterior2nd_stucco": [21, 35, 58, 69], "exterior2nd_vinylsd": [21, 35, 58, 69], "exterior2nd_wd": [21, 35, 58, 69], "external_tool": 70, "exterqu": [21, 23, 35, 37, 39, 48, 58, 60, 69], "extra": [4, 62, 67, 70, 80], "extract": [24, 40, 43, 61, 62, 64, 65, 66, 71, 80], "extractor": 73, "extrapol": [67, 68], "extratreesclassifi": [22, 59], "extrem": [6, 17, 20, 22, 23, 34, 36, 37, 38, 39, 46, 47, 54, 57, 59, 60, 64, 68, 71], "ey": [48, 71], "f": [8, 10, 12, 13, 14, 15, 16, 17, 20, 23, 24, 25, 26, 27, 28, 29, 30, 34, 37, 39, 40, 43, 44, 47, 49, 50, 51, 52, 53, 54, 57, 60, 61, 62, 63, 65, 66, 67, 68, 70, 71, 75, 79], "f1": [11, 21, 58, 73], "f1_score": [20, 34, 47, 57], "fa": [21, 23, 35, 37, 39, 48, 58, 60, 69], "fac": 71, "face": [12, 13, 15, 25, 43, 46, 49, 50, 52, 64, 66], "facebook": [64, 65, 80], "facial": [15, 46, 52], "facil": 80, "facilit": [8, 80], "fact": [12, 19, 20, 22, 33, 34, 36, 47, 49, 56, 57, 59, 66, 67, 68, 69], "factor": [13, 19, 23, 24, 26, 33, 37, 39, 40, 50, 56, 60, 61, 63, 64, 68], "fail": [1, 7, 8, 10, 14, 16, 17, 24, 27, 29, 30, 40, 51, 53, 54, 61, 63, 65, 68, 69], "failur": [7, 12, 25, 49, 68, 79, 80], "fair": [6, 14, 16, 21, 23, 27, 29, 35, 37, 39, 48, 51, 53, 58, 60, 62, 70, 73, 80], "fairli": [14, 19, 20, 23, 27, 33, 34, 37, 39, 51, 56, 57, 60, 70, 78], "fake": [15, 28, 31, 45, 46, 52], "fake_review": [31, 45, 46], "fall": [15, 28, 52, 62, 65, 67], "fals": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 66, 67, 68, 69, 73, 78, 79], "famili": [12, 19, 20, 21, 22, 23, 25, 33, 34, 35, 36, 37, 38, 39, 46, 48, 49, 56, 57, 58, 59, 60, 62, 70, 80], "familiar": [8, 10, 11, 13, 16, 26, 29, 50, 53, 69, 75, 80], "famou": [1, 9, 31, 45, 46, 65, 66], "fanci": [4, 12, 19, 25, 49, 56], "fancier": [24, 40, 61], "fantast": 46, "far": [13, 15, 16, 17, 18, 20, 23, 24, 28, 29, 30, 32, 34, 37, 39, 40, 47, 50, 52, 53, 54, 55, 57, 60, 61, 62, 63, 65, 66, 67, 68, 72, 73, 75, 77, 79], "farm": [20, 34, 57], "farthest": [13, 26, 50], "fashion": [22, 26, 36, 38, 46, 59, 65], "fast": [14, 15, 18, 22, 23, 27, 32, 36, 37, 39, 46, 51, 52, 55, 59, 60, 65, 68, 70, 80], "faster": [12, 19, 22, 24, 25, 33, 36, 38, 40, 49, 56, 59, 61, 66], "fastest": [22, 36, 59], "fastingb": 79, "fasttext": 65, "favorit": 46, "favour": 70, "favourit": 65, "fc": [18, 32, 55], "fcluster": 63, "fear": 46, "feat": [33, 44, 56, 67, 71], "feat1": 62, "feat2": 62, "feat_nam": [44, 67, 71], "feat_vec": [31, 45, 46, 64], "feat_vect": 31, "featur": [1, 11, 14, 20, 22, 27, 31, 34, 36, 38, 42, 43, 45, 46, 47, 51, 57, 59, 62, 63, 65, 68, 70, 72, 75, 76, 77, 78, 79, 80], "feature_extract": [12, 17, 18, 19, 20, 25, 30, 31, 32, 33, 44, 45, 46, 49, 54, 55, 56, 57, 65, 70, 71, 77], "feature_import": 42, "feature_importances_": [24, 40, 42, 61], "feature_nam": [13, 14, 18, 22, 23, 24, 26, 27, 31, 32, 36, 37, 38, 39, 40, 42, 45, 46, 50, 51, 55, 59, 60, 61, 65], "feature_names_in_": 42, "feature_names_out": [17, 30, 54], "feature_select": [24, 40, 61], "feature_typ": [22, 36, 38, 59], "features_lag": 67, "features_nonzero": 67, "features_poli": 67, "feb": [1, 16, 18], "februari": [42, 67], "feder": [20, 23, 34, 37, 57, 60, 65, 67], "feed": [43, 44, 46], "feedback": [26, 50, 73], "feel": [5, 6, 14, 27, 44, 46, 51, 62, 70, 73], "feli": [12, 25, 49, 66], "felix": 1, "fell": [18, 32, 55], "felt": 44, "femal": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 68, 78], "female_cm": [20, 34, 57, 78], "female_pr": [20, 34, 57, 78], "fenc": [21, 23, 35, 37, 39, 48, 58, 60, 66, 69], "fernandez": [22, 36, 38, 59], "fest": 46, "fetch_california_h": [18, 32, 55], "few": [1, 8, 12, 18, 21, 22, 24, 25, 31, 32, 35, 38, 40, 44, 45, 46, 48, 49, 55, 58, 59, 61, 64, 65, 66, 67, 68, 70, 74, 79], "fewer": [10, 22, 24, 36, 40, 59, 61, 63], "fewest": 79, "feynman": 69, "fiber": 68, "fiction": 71, "field": [2, 4, 11, 12, 17, 25, 30, 49, 54, 65, 66, 67, 70], "fig": [14, 15, 18, 20, 24, 27, 28, 32, 34, 40, 43, 51, 52, 55, 57, 61, 62, 63, 66, 75, 78], "fight": 46, "figsiz": [13, 14, 15, 16, 18, 20, 23, 24, 26, 27, 28, 29, 32, 34, 37, 39, 40, 43, 44, 50, 51, 52, 53, 55, 57, 60, 61, 62, 63, 66, 67, 68, 69, 75, 78], "figur": [4, 8, 10, 12, 13, 15, 19, 21, 23, 24, 25, 26, 28, 33, 35, 37, 39, 40, 43, 49, 50, 52, 56, 58, 60, 61, 62, 63, 66, 67, 68, 69, 75], "file": [0, 1, 4, 5, 7, 8, 10, 12, 13, 17, 20, 23, 25, 30, 31, 34, 37, 39, 44, 47, 50, 54, 57, 60, 66, 68, 70, 78], "file_nam": 43, "filenam": 66, "fill": [15, 18, 19, 28, 32, 33, 42, 43, 44, 52, 55, 56, 64, 70, 75, 79, 80], "fill_diagon": [15, 28, 52], "fill_valu": [20, 21, 22, 23, 34, 35, 36, 37, 38, 39, 44, 48, 57, 58, 59, 60, 67, 69, 78], "film": [46, 65, 71], "filter": [4, 11, 12, 14, 25, 27, 49, 51, 62, 67, 73], "filterwarn": [15, 23, 25, 27, 28, 36, 37, 52, 68, 79], "final": [1, 6, 7, 12, 14, 16, 22, 24, 25, 27, 29, 36, 37, 38, 40, 42, 46, 51, 53, 59, 61, 69, 70, 74, 76, 79], "final_estim": [22, 36, 38, 59], "final_estimator_": [22, 36, 38, 59, 79], "finalis": [45, 46], "financ": [66, 67], "find": [1, 7, 8, 12, 13, 16, 19, 21, 22, 23, 25, 26, 29, 31, 33, 35, 36, 37, 38, 39, 43, 44, 45, 46, 48, 49, 50, 53, 56, 58, 59, 60, 62, 63, 64, 65, 69, 71, 72, 77, 78, 80], "fine": [7, 16, 17, 20, 29, 30, 34, 46, 53, 54, 57, 64, 66, 67, 70, 79], "finish": [12, 21, 25, 35, 46, 48, 49, 58], "fira": [0, 1], "firasm": [20, 34, 47, 57, 78], "firefox": [12, 25], "fireplac": [21, 23, 35, 37, 39, 48, 58, 60, 69], "fireplacequ": [21, 23, 35, 37, 39, 48, 58, 60, 69], "first": [1, 4, 8, 13, 15, 17, 18, 19, 22, 23, 26, 28, 30, 31, 32, 33, 36, 37, 38, 39, 44, 45, 46, 50, 52, 54, 55, 56, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75, 77, 78, 79, 80], "first_dai": 67, "first_day_retail": 67, "first_pass_isfinit": 44, "firth": 65, "fish": [20, 23, 34, 37, 39, 57, 60], "fist": 67, "fit": [0, 12, 14, 15, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78, 79, 80], "fit_intercept": [20, 34, 57], "fit_method": 44, "fit_predict": 63, "fit_resampl": [20, 57], "fit_tim": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 67, 68, 71], "fit_transform": [16, 17, 20, 22, 23, 24, 29, 30, 31, 34, 36, 37, 38, 39, 40, 44, 45, 46, 53, 54, 57, 59, 60, 61, 63, 64, 65, 67, 73, 78], "fittedcolumntransform": [17, 22, 30, 36, 54, 59], "fittedpipelin": [19, 21, 33, 35, 54, 56, 58], "fittedvotingclassifi": [22, 36, 38, 59], "fitter": 68, "five": [19, 33, 56], "fix": [16, 17, 22, 29, 30, 38, 44, 53, 54, 59, 68, 70, 72, 75, 80], "flag": 68, "flagstaff": 71, "flaki": [20, 57], "flashcard": 73, "flask": 70, "flat": 63, "flatten": [22, 23, 31, 36, 37, 38, 39, 43, 45, 46, 59, 60, 63, 67, 79], "flatten_train": 66, "flatten_transform": 66, "flatten_valid": 66, "flatter": 32, "flaw": [14, 16, 27, 29, 51, 53], "flawless": [18, 31, 32, 45, 46, 55], "flesh": 46, "flexibl": [7, 12, 24, 40, 49, 61, 66, 73, 80], "flibbertigibbet": 65, "flickr_cat_000002": 66, "flight": [24, 40, 61], "flip": [1, 14, 20, 21, 34, 35, 47, 48, 51, 57, 58, 70], "flip_i": [20, 57], "float": [8, 21, 24, 35, 40, 44, 58, 61, 68, 71], "float32": [65, 66], "float64": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 46, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 64, 67, 68], "floatlogslid": [15, 28, 52, 75], "floatslid": [15, 20, 28, 34, 43, 47, 52, 57, 62, 63, 75], "floor": [12, 13, 25, 42, 49, 50, 80], "flower": [15, 20, 28, 43, 52, 57, 70, 75], "fly": 46, "fmt": [19, 33, 56], "fn": [20, 34, 47, 57], "fnlwgt": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "focu": [1, 11, 12, 16, 17, 18, 23, 25, 29, 30, 32, 37, 39, 40, 44, 49, 53, 54, 55, 60, 63, 64, 65, 67, 73, 75, 76, 77, 78, 79, 80], "focus": [12, 18, 32, 40, 46, 49, 55, 62, 65, 73], "fog": 46, "foggi": 46, "fold": [14, 16, 17, 19, 20, 21, 22, 27, 29, 30, 33, 34, 35, 38, 48, 51, 53, 54, 56, 57, 58, 59, 70, 75], "folder": [5, 6, 29, 51, 53, 60, 70, 71], "folk": [68, 70, 80], "follow": [0, 5, 6, 7, 8, 10, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 80], "font": [12, 13, 14, 25, 26, 27, 49, 50, 51, 62, 63, 64, 67, 68, 69], "font_scal": [23, 37, 39, 60], "fontsiz": [13, 14, 15, 20, 22, 23, 26, 27, 28, 34, 36, 37, 38, 39, 42, 43, 47, 50, 51, 52, 57, 59, 60, 62, 66, 69, 74, 75], "food": [44, 62, 65, 66, 80], "food_typ": 44, "food_type_canadian": 44, "food_type_chines": 44, "food_type_fus": 44, "food_type_indian": 44, "food_type_italian": 44, "food_type_mexican": 44, "food_type_nan": 44, "food_type_oth": 44, "food_type_quebecoi": 44, "food_type_thai": 44, "foot": [21, 23, 35, 37, 39, 58, 60], "footag": [18, 32, 46, 55], "footstal": 66, "forc": [20, 23, 37, 57, 60, 75], "force_all_finit": 44, "force_plot": [23, 37, 39, 60], "force_writ": 44, "forecast": [11, 13, 26, 50, 68, 69, 73], "forest": [11, 20, 21, 35, 48, 57, 58, 66, 67, 68, 70, 73, 79], "forestcolumntransform": [22, 36, 38], "forev": 67, "forg": [10, 20, 21, 22, 23, 35, 36, 37, 38, 39, 57, 58, 59, 60, 65, 68, 71], "forget": [13, 15, 16, 17, 22, 26, 30, 36, 38, 50, 54, 59, 79], "form": [1, 12, 17, 20, 24, 25, 28, 30, 34, 40, 54, 57, 61, 63, 64, 65, 68, 69, 70, 73], "formal": 80, "format": [0, 1, 13, 20, 26, 34, 40, 42, 44, 47, 50, 57, 63, 65, 67, 68], "former": 68, "formul": [4, 19, 33, 56], "formula": [18, 21, 32, 35, 55, 58, 66, 72], "forum": [12, 25], "forward": [68, 70], "found": [1, 7, 14, 17, 19, 21, 27, 30, 33, 35, 41, 42, 44, 48, 51, 54, 56, 58, 62, 64, 65, 71, 73, 77, 79, 80], "foundat": [1, 9, 11, 20, 21, 23, 35, 37, 39, 48, 57, 58, 60, 69], "foundation_brktil": [21, 35, 58], "foundation_cblock": [21, 35, 58], "foundation_pconc": [21, 35, 58], "foundation_slab": [21, 35, 58], "foundation_ston": [21, 35, 58], "foundation_wood": [21, 35, 58], "fountain": 66, "four": [13, 14, 24, 26, 40, 50, 51, 61, 63, 70, 73], "fourth": 63, "foxhound": [12, 25, 49, 66], "foyer": [21, 35, 48, 58], "fp": [20, 34, 47, 57], "fpr": [20, 34, 47, 57], "fpr_lr": [20, 34, 47, 57], "fpr_svc": [20, 34, 47, 57], "frac": [13, 18, 20, 21, 26, 32, 34, 35, 47, 48, 50, 55, 57, 58, 62, 65, 66], "fractal": [24, 40, 61], "fraction": [17, 20, 30, 34, 47, 54, 57, 64], "fragasso": 46, "fragment": 75, "frame": [16, 17, 20, 21, 24, 29, 30, 34, 35, 40, 53, 54, 57, 58, 61, 67, 68, 69, 70], "framework": [19, 33, 50, 56], "franco": 46, "frank": 46, "fraud": [13, 20, 21, 26, 34, 35, 47, 48, 50, 57, 58, 62, 67, 78], "fraudul": [13, 20, 26, 34, 47, 50, 57, 69, 78], "frederick": [1, 80], "free": [0, 5, 17, 21, 30, 35, 54, 58, 65, 68, 70], "freedom": [0, 71], "french": [16, 29, 53, 65], "freq": 67, "frequenc": [17, 30, 54, 65, 67, 68, 73], "frequent": [13, 16, 26, 29, 50, 53, 64, 65, 68], "fresh": [46, 64, 65], "fri": [12, 67], "fridai": [14, 25, 80], "fridg": 46, "friend": [13, 14, 20, 23, 26, 37, 39, 46, 50, 51, 57, 60, 63, 64, 70, 73, 80], "from": [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80], "from_block": 68, "from_estim": [20, 34, 47, 57, 78], "front": 80, "fruit": 65, "frustrat": [4, 6, 19, 33, 56], "fu": 1, "fulci": 46, "full": [19, 22, 31, 33, 36, 38, 42, 56, 59, 66, 67, 68, 80], "full_pip": 44, "fullbath": [21, 23, 35, 37, 39, 48, 58, 60, 69], "fulli": [48, 63], "fun": [20, 46, 57, 65, 66], "func": [8, 17, 18, 21, 30, 32, 35, 48, 54, 55, 58, 69], "function": [2, 12, 13, 14, 15, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 33, 34, 36, 37, 38, 39, 40, 43, 47, 49, 50, 51, 52, 54, 56, 57, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 75, 77, 78], "functiontransform": [17, 30, 44, 54, 68], "fund": 71, "fundament": [1, 2, 9, 11, 16, 18, 19, 21, 24, 29, 32, 33, 35, 40, 48, 53, 55, 56, 58, 61, 66, 68, 80], "funni": [12, 22, 36, 46, 49, 59, 71], "furnish": 0, "furnitur": 73, "further": [20, 22, 24, 34, 40, 42, 57, 59, 61, 62, 65, 66, 68, 70, 75, 77, 78, 80], "furthermor": 69, "fusion": 44, "futur": [11, 14, 19, 21, 25, 27, 29, 33, 35, 47, 51, 53, 56, 58, 68, 71, 73, 77], "futurewarn": [21, 23, 29, 35, 37, 38, 39, 47, 48, 51, 53, 58, 60, 71, 72], "fuyi": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 80], "fyi": 68, "g": [6, 7, 8, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 47, 48, 50, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 77], "g26r0dcx4b35vf3nk31216hc0000gr": [53, 60, 71], "gain": [6, 11, 13, 20, 22, 23, 26, 34, 36, 37, 38, 39, 50, 57, 59, 60, 78], "game": [13, 23, 26, 37, 39, 50, 60, 65], "gamma": [18, 19, 22, 32, 33, 36, 38, 43, 55, 56, 59, 69, 75, 77], "gamma_log": [15, 28, 43, 52, 75], "gamma_widget": [15, 28, 43, 52, 75], "gap": [14, 27, 42, 51, 67, 68, 69, 73, 75], "garagearea": [21, 23, 35, 37, 39, 48, 58, 60, 69], "garagecar": [21, 23, 35, 37, 39, 48, 58, 60, 69], "garagecond": [21, 23, 35, 37, 39, 48, 58, 60, 69], "garagefinish": [21, 23, 35, 37, 39, 58, 60, 69], "garagefinish_fin": [21, 35, 58], "garagefinish_miss": [21, 35, 58], "garagefinish_rfn": [21, 35, 58], "garagefinish_unf": [21, 35, 58], "garagequ": [21, 23, 35, 37, 39, 48, 58, 60, 69], "garagetyp": [21, 23, 35, 37, 39, 58, 60, 69], "garagetype_2typ": [21, 35, 58], "garagetype_attchd": [21, 35, 58], "garagetype_bas": [21, 35, 58], "garagetype_builtin": [21, 35, 58], "garagetype_carport": [21, 35, 58], "garagetype_detchd": [21, 35, 58], "garagetype_miss": [21, 35, 58], "garageyrblt": [21, 23, 35, 37, 39, 48, 58, 60, 69], "garlic": 62, "gaudenzi": 46, "gaurav": [1, 80], "gauss": 65, "gaussian": 63, "gaussianmixtur": 63, "gave": [44, 46, 64, 67], "gbr": 8, "gca": [62, 63, 68], "gd": [12, 21, 23, 25, 35, 37, 39, 48, 49, 58, 60, 69], "gdprv": [21, 23, 35, 37, 39, 48, 58, 60, 69], "gdwo": [21, 23, 35, 37, 39, 48, 58, 60, 69], "gelbart": [0, 1, 26, 50, 65, 77], "gender": [12, 17, 20, 25, 34, 49, 54, 57, 65, 67, 68, 78], "gender_femal": 68, "gender_mal": 68, "gener": [7, 9, 12, 13, 16, 17, 19, 20, 21, 23, 26, 29, 30, 33, 34, 35, 37, 39, 42, 44, 46, 50, 53, 54, 56, 57, 58, 60, 63, 65, 66, 67, 68, 69, 70, 72, 73, 75, 77, 78, 80], "genet": [24, 40, 61], "genom": [24, 38, 61], "genr": 64, "gensim": 65, "gentl": 11, "geog": [1, 80], "geograph": [18, 32, 55, 70], "geometr": [13, 50], "georg": 65, "geq": [18, 32, 55], "ger": 8, "german": 65, "get": [1, 4, 5, 6, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78, 79, 80], "get_avg_word_length": 71, "get_cmap": [16, 29, 53], "get_depth": [42, 75], "get_dummi": [16, 29, 53], "get_featur": [43, 66], "get_feature_nam": 31, "get_feature_names_out": [16, 17, 20, 21, 22, 23, 24, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 48, 53, 54, 57, 58, 59, 60, 61, 65, 67, 68, 69, 71, 78], "get_length_in_word": 71, "get_lr_data_per_us": 64, "get_param": [19, 43], "get_permutation_import": [23, 37, 39, 60], "get_relative_length": 71, "get_season": 67, "get_senti": 71, "get_stat": 64, "get_tag": 44, "get_user_profil": 64, "getattr": 68, "ghassemi": [1, 80], "gif": [62, 63], "gift": 71, "gigaword": 65, "gini": [13, 23, 26, 37, 39, 50, 60, 69], "git": [3, 8, 12, 25], "github": [0, 1, 7, 9, 10, 12, 16, 17, 19, 20, 21, 22, 23, 24, 25, 29, 30, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 49, 53, 54, 56, 57, 58, 59, 60, 61, 66, 69, 70, 71, 77, 78], "githubusercont": 8, "gitlf": [20, 34, 47, 57], "giulia": [0, 1, 80], "give": [0, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 78], "given": [0, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 78], "gladwel": 62, "glass": 69, "glob": [12, 25, 43, 49, 66], "global": [16, 20, 22, 29, 34, 36, 38, 47, 53, 57, 59, 62, 65, 73], "global_skip_valid": 44, "glove": [11, 65], "glq": [21, 23, 35, 37, 39, 48, 58, 60, 69], "gmail": [12, 25, 49, 62], "go": [1, 5, 7, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78, 79], "goal": [2, 11, 15, 16, 19, 20, 28, 29, 33, 34, 47, 52, 53, 56, 57, 62, 63, 64, 65, 70, 71, 77, 79], "goe": [2, 12, 14, 15, 17, 20, 22, 23, 25, 27, 28, 30, 34, 37, 39, 46, 47, 51, 52, 54, 57, 59, 60, 63, 64, 66, 69, 70], "gold": 8, "goldcoast": 67, "golden": [15, 31, 42, 45, 46, 52, 70, 73, 75], "good": [9, 10, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 33, 35, 36, 37, 38, 39, 40, 42, 44, 46, 47, 48, 50, 51, 52, 53, 54, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79], "good_serv": 44, "goodarzvand": [1, 80], "googl": [1, 4, 12, 13, 22, 25, 26, 36, 47, 49, 50, 59, 60, 61, 62, 65, 69, 71], "google_news_vector": 65, "gore": 46, "gorgeou": 46, "gori": 46, "got": [15, 18, 19, 20, 21, 28, 31, 32, 33, 35, 45, 46, 48, 52, 55, 56, 57, 58, 66], "gotten": [68, 79], "gov": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60], "govern": [65, 80], "gpe": 65, "gpt": [64, 65], "gpu": [22, 36, 38, 59, 65, 66], "grad": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "grade": [1, 3, 7, 12, 14, 16, 17, 19, 27, 30, 33, 38, 42, 46, 49, 51, 54, 56, 69, 73, 75, 76, 77, 78, 79], "grader": 6, "grades_df": 73, "gradescop": [1, 6, 12, 13, 25, 80], "gradient": [70, 73], "gradientboostingclassifi": [22, 36, 38, 59], "gradientboostingregressor": [22, 36, 38, 59, 69], "gradientexplain": [23, 37, 39, 60], "grading_concern": 6, "graduat": 66, "grai": 66, "grain": [18, 23, 32, 37, 39, 55, 60], "gram": 65, "grammat": 65, "grandma": [24, 40, 61], "grandmoth": [20, 57, 70], "grant": 0, "grant_macewan": 65, "granular": 63, "graph": [1, 43, 66, 67], "graphic": 66, "graphic_design": 65, "graphviz": [13, 26, 50, 74], "grasp": [11, 73], "grass": 46, "grave": 46, "grayscal": 66, "great": [12, 15, 17, 18, 23, 24, 25, 27, 28, 30, 32, 37, 39, 40, 44, 46, 49, 50, 52, 54, 55, 60, 61, 65, 66, 67, 69, 71], "greater": [10, 24, 40, 61, 62], "greater_is_bett": [21, 35, 48, 58], "greedili": 63, "green": [15, 19, 28, 33, 46, 52, 56, 62, 69, 72], "grei": 80, "grid": [18, 21, 32, 35, 48, 55, 58, 67, 68, 73, 77], "grid_result": 69, "grid_search": [19, 33, 56, 69, 77], "gridsearchcv": [15, 22, 23, 28, 36, 37, 38, 39, 52, 59, 60, 77, 79], "gridsearchcvifittedgridsearchcv": [19, 33, 56], "grinberg": 70, "grip": 65, "grlivarea": [21, 23, 35, 37, 39, 48, 58, 60, 69], "groak": 65, "groceri": [66, 71], "groin": 66, "ground": [14, 24, 27, 32, 40, 46, 51, 61, 63, 64, 80], "ground_truth_categori": [20, 57, 70], "group": [7, 11, 13, 15, 16, 17, 18, 22, 24, 26, 28, 32, 36, 38, 40, 43, 46, 50, 52, 54, 55, 59, 61, 73, 75, 76, 79], "groupbi": 67, "grow": [19, 22, 24, 33, 36, 38, 40, 56, 59, 61], "grow_polici": [22, 36, 38, 59], "growth": [67, 68], "groyn": 66, "grv": [21, 23, 35, 58], "gsc": 69, "gt": [17, 18, 19, 20, 21, 22, 30, 32, 33, 34, 35, 36, 38, 46, 54, 55, 56, 57, 58, 59], "gtl": [23, 37, 39, 60], "gtoti": [26, 30], "guam": 39, "guarante": [19, 20, 22, 33, 34, 36, 38, 40, 47, 56, 57, 59, 62, 66], "guenon": 66, "guess": [15, 16, 28, 29, 52, 53, 65, 71], "gui": 46, "guid": [1, 7, 9, 12, 24, 25, 40, 61, 66, 70, 80], "guidanc": [23, 37, 39, 60], "guidelin": [16, 23, 24, 37, 39, 40, 60, 61, 70], "guido": 1, "gun": 46, "h": [20, 22, 23, 34, 36, 37, 38, 39, 42, 57, 59, 60, 62, 65, 66, 68, 70, 71, 78], "ha": [1, 2, 5, 6, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 50, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 75, 78, 79, 80], "hab": 65, "habit": [17, 30, 54, 69, 70], "hacki": [66, 72], "had": [12, 16, 17, 18, 20, 24, 25, 29, 30, 32, 46, 49, 53, 54, 55, 57, 64, 65, 66, 67, 68, 70], "hadn": [65, 68], "haidilao": 44, "hal": 1, "half": [1, 6, 12, 13, 18, 24, 25, 26, 32, 40, 46, 50, 55, 61, 63], "halfbath": [21, 23, 35, 37, 39, 48, 58, 60, 69], "halvingrandomsearchcv": [19, 33, 56], "halvingrandomsearchcvifittedhalvingrandomsearchcv": [19, 33, 56], "ham": [12, 25, 49], "hand": [4, 9, 11, 20, 34, 44, 46, 47, 57, 64, 78, 80], "handi": [20, 34, 47, 57], "handl": [11, 22, 23, 36, 37, 38, 39, 42, 44, 46, 59, 60, 63, 68, 70, 72, 73, 75], "handle_unknow": [17, 30, 54], "handle_unknown": [16, 17, 19, 20, 21, 22, 23, 29, 30, 33, 34, 35, 36, 37, 38, 39, 44, 48, 53, 54, 56, 57, 58, 59, 60, 67, 68, 69, 73, 77, 78, 79], "handler": [20, 23, 34, 37, 57, 60], "handrail": 66, "handwritten": [20, 57, 69], "hang": [20, 57], "happen": [4, 6, 12, 15, 17, 19, 22, 23, 24, 28, 30, 33, 36, 37, 38, 39, 40, 44, 46, 47, 48, 49, 52, 54, 56, 59, 60, 61, 64, 67, 68, 69, 73, 80], "happi": [20, 34, 42, 44, 47, 57, 62, 68], "happier": [70, 80], "happydb": [20, 57, 70], "hard": [8, 12, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 38, 40, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 69, 70, 71, 73, 79], "hardi": [1, 80], "hardli": 64, "hardwar": 66, "harmon": [20, 34, 47, 57], "harri": [1, 65, 80], "has_emoji": 71, "has_nan_error": 44, "hasn": [4, 64, 65, 68], "hassl": [8, 23, 37, 39, 60, 67], "hat": [18, 21, 22, 32, 35, 38, 40, 48, 55, 58, 59], "have": [0, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80], "haven": [14, 27, 44, 51, 65, 68, 69, 70, 73], "haylei": [26, 50], "hazard": 11, "hc_truncation_toy_demo": 63, "hdbscan": 63, "he": [14, 17, 27, 30, 46, 51, 54, 65], "head": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 77, 78, 79], "header": 70, "headlin": [65, 69], "health": 65, "healthcar": [23, 37, 39, 60], "healthi": [65, 69], "heard": [14, 27, 51], "heart": [13, 26, 46, 50, 71, 79], "heart_df": 79, "heartdiseas": 79, "hearti": 44, "heat": [19, 21, 23, 33, 35, 37, 39, 56, 58, 60, 69, 77], "heating_floor": [21, 35, 58], "heating_gasa": [21, 35, 58], "heating_gasw": [21, 35, 58], "heating_grav": [21, 35, 58], "heating_othw": [21, 23, 35, 39, 58, 60], "heating_wal": [21, 35, 58], "heatingqc": [21, 23, 35, 37, 39, 48, 58, 60, 69], "heatmap": [23, 37, 39, 60], "heavi": [22, 36, 38, 59, 71], "heavili": [46, 64, 66, 67, 78], "heeren": 65, "hei": [45, 46], "height": [13, 14, 20, 26, 27, 34, 43, 50, 51, 57, 65, 71, 74], "helicopt": 46, "hell": 71, "help": [3, 7, 10, 12, 14, 16, 19, 20, 23, 25, 27, 29, 33, 34, 37, 39, 44, 46, 47, 49, 51, 53, 54, 56, 57, 60, 62, 63, 64, 65, 67, 68, 69, 70, 71, 74, 75, 76, 80], "henc": [5, 20, 21, 23, 34, 35, 37, 39, 47, 57, 58, 60, 62], "her": [12, 25, 46, 49, 64, 65], "here": [1, 4, 5, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80], "herebi": 0, "herself": [65, 71], "herta": [15, 52], "hesist": 69, "hesit": 69, "heurist": [13, 19, 26, 33, 50, 56], "hi": [46, 65, 75], "hidden": [24, 40, 61, 65, 66, 69], "hide": [8, 46, 66], "hier_label": 63, "hier_labels1": 63, "hier_labels2": 63, "hierarch": [11, 73], "hierarchi": [13, 26, 50, 63], "high": [6, 11, 14, 15, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 47, 48, 51, 52, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70], "high_corr": [23, 37, 39, 60], "higher": [13, 14, 15, 18, 20, 21, 22, 23, 24, 26, 27, 28, 32, 34, 35, 36, 37, 38, 39, 40, 47, 48, 50, 51, 52, 55, 57, 58, 59, 60, 61, 62, 64, 68, 69, 70, 75, 77, 78], "highest": [22, 23, 31, 36, 37, 38, 39, 45, 46, 59, 60, 64, 65, 66, 69, 72, 75, 78], "highland": 71, "highli": [1, 10, 16, 23, 29, 31, 37, 39, 45, 46, 53, 60, 64], "highlight": [4, 66, 69, 73], "highwai": [18, 32, 55], "him": [46, 65], "himself": [46, 65], "hinder": 80, "hindi": [16, 29, 53], "hint": [23, 37, 39, 60, 75], "hist": [16, 19, 21, 24, 29, 33, 35, 40, 44, 48, 53, 56, 58, 61, 68], "histgradientboostingclassifi": [22, 36, 38, 44, 59], "histgradientboostingregressor": [22, 36, 38, 59], "histogram": 68, "histor": 73, "histori": [18, 32, 55, 64, 67, 80], "hit": [12, 19, 25, 33, 49, 56], "hitter": 71, "hl": [21, 23, 35, 37, 58, 60, 69], "hmid": [20, 57, 70], "hmmm": 68, "hockei": 65, "hold": [44, 46, 69, 70, 77], "holder": 0, "holdout": [20, 34, 57], "holi": 69, "holidai": [64, 80], "home": [13, 18, 20, 26, 32, 43, 44, 50, 55, 57, 66, 70], "homemak": 65, "homepag": 1, "homework": [1, 3, 4, 6, 8, 10, 15, 19, 33, 52, 55, 56, 65, 70, 73, 80], "honest": 69, "honour": 80, "hood": [14, 27, 44, 51, 70], "hook": 46, "hope": [14, 27, 46, 51, 69, 70], "hopefulli": [70, 77], "hopeless": [24, 40, 61], "hopelessli": [15, 28, 52], "horizont": [13, 17, 26, 30, 44, 50, 54], "horror": 46, "host": [5, 68, 70], "hot": [14, 17, 23, 27, 30, 37, 39, 44, 46, 51, 54, 60, 73], "hound": [12, 25, 49, 66], "hour": [1, 4, 10, 12, 20, 22, 23, 24, 34, 36, 37, 38, 39, 40, 46, 57, 59, 60, 61, 64, 67, 70, 73, 78, 80], "hourli": [68, 73], "hous": [21, 23, 24, 26, 35, 37, 39, 40, 42, 48, 58, 60, 61, 68, 69, 75], "houseag": [18, 32, 55], "household": [16, 18, 24, 29, 32, 40, 53, 54, 55, 61, 76], "housestyl": [21, 23, 35, 37, 39, 48, 58, 60, 69], "housestyle_1": [21, 35, 58], "housestyle_1stori": [21, 35, 58], "housestyle_2": [21, 35, 58], "housestyle_2stori": [21, 35, 58], "housestyle_sfoy": [21, 35, 58], "housestyle_slvl": [21, 35, 58], "housewif": 65, "housing_df": [13, 16, 24, 29, 40, 42, 50, 53, 54, 61, 75, 76], "housing_median_ag": [16, 24, 29, 40, 53, 54, 61, 76], "houston": 71, "how": [0, 3, 8, 10, 11, 12, 17, 19, 20, 21, 25, 30, 31, 33, 34, 35, 42, 43, 46, 47, 48, 49, 54, 56, 57, 58, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80], "howard": 62, "howev": [2, 8, 16, 17, 20, 21, 23, 29, 30, 34, 35, 37, 39, 43, 46, 53, 54, 57, 58, 60, 62, 64, 67, 68, 70, 72, 75, 78], "hsjcy": 68, "hstack": 67, "html": [7, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 68, 69, 70, 71, 74, 76, 78], "htrz": [38, 39, 40, 80], "http": [0, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 57, 58, 59, 66, 67, 68, 69, 70, 71, 78, 80], "hue": 40, "hug": 64, "huge": [17, 21, 30, 35, 48, 54, 58, 65, 66, 67, 68], "human": [0, 12, 15, 16, 17, 18, 19, 20, 23, 24, 25, 29, 30, 32, 33, 34, 37, 39, 40, 46, 49, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66, 78], "humidity3pm": 67, "humidity3pm_lag1": 67, "humidity9am": 67, "hummu": [62, 65], "humour": [1, 65], "hundr": [18, 32, 55], "hungri": 44, "hurrai": 79, "hurrican": [12, 49], "husband": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60], "hussar": [12, 25, 49, 66], "hw": [12, 16, 20, 49], "hw1": [1, 4, 13, 14, 16, 17, 74], "hw2": [1, 14, 15, 16, 29, 52, 53, 77], "hw3": [1, 16, 17, 18], "hw4": 1, "hw5": [1, 38, 39, 40], "hw6": 1, "hw6a": 7, "hw6b": 7, "hw7": 1, "hw8": 1, "hw9": 1, "hybrid": 64, "hyper": 69, "hyperband": [19, 33, 56], "hyperopt": [19, 33, 56], "hyperparamet": [1, 14, 20, 27, 31, 34, 43, 45, 46, 47, 51, 57, 63, 64, 65, 66, 69, 70, 77], "hyperparameter_": 69, "hyperparamt": [14, 19, 27, 33, 51, 56, 68], "hyperparlan": [18, 32, 55], "hyperplan": [18, 32, 55], "hypothesi": [65, 68, 70], "hypothet": [18, 32, 55, 62], "i": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 18, 21, 26, 28, 31, 32, 35, 42, 43, 44, 45, 46, 48, 50, 52, 55, 58, 63, 66, 67, 68, 72, 73, 74, 75, 76, 77, 78, 79, 80], "i1": [22, 38, 59], "i2": [22, 38, 59], "ia": 71, "ibm": 71, "ic": 65, "icc": [1, 80], "iclick": 1, "id": [12, 13, 21, 23, 25, 35, 37, 39, 42, 48, 49, 50, 58, 60, 64, 69, 75], "idea": [8, 13, 14, 16, 19, 23, 26, 27, 29, 33, 37, 39, 42, 43, 44, 46, 47, 50, 51, 53, 56, 60, 62, 63, 64, 65, 66, 67, 68, 70, 73, 75], "ideal": [4, 16, 20, 22, 24, 34, 36, 38, 40, 44, 47, 57, 59, 61, 64, 68, 70], "ident": [43, 65, 66], "identif": [12, 25, 49, 71], "identifi": [11, 13, 14, 15, 16, 19, 20, 21, 26, 27, 29, 31, 33, 34, 35, 39, 42, 45, 46, 47, 48, 50, 51, 52, 53, 56, 57, 58, 62, 63, 65, 66, 67, 69, 70, 73, 78], "idf": [17, 30, 54], "idli": 65, "idx": [43, 66], "idxmax": [15, 28, 42, 45, 46, 52], "if_binari": [17, 20, 22, 23, 30, 34, 36, 37, 38, 39, 44, 54, 57, 59, 60, 73, 76, 78, 79], "ifram": [14, 20, 27, 34, 51, 57], "igloo": 65, "ignor": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 44, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 65, 67, 68, 69, 73, 77, 78, 79], "ignore_index": 8, "ii": [20, 34, 47, 57], "iii": 1, "ij": [18, 31, 32, 45, 46, 55, 64], "ik": [22, 38, 59], "ill": 80, "illus": [20, 34, 57, 78], "illustr": [40, 63, 67], "iloc": [8, 13, 14, 15, 16, 17, 22, 23, 26, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 45, 46, 50, 51, 52, 53, 54, 59, 60, 65, 67, 71, 74, 79], "im": 71, "imag": [7, 11, 14, 20, 23, 24, 27, 29, 34, 37, 39, 40, 46, 47, 51, 57, 60, 61, 62, 63, 67, 69, 73, 78], "image_dataset": [43, 66], "image_datasets_bw": 66, "image_fil": 43, "image_s": [43, 66], "imagefold": [43, 66], "imagenet": 72, "imagenet1k_v1": [43, 66], "imagenet_class": [12, 25, 49, 66], "imagin": [12, 13, 14, 16, 18, 20, 23, 24, 25, 26, 27, 29, 32, 34, 37, 39, 40, 47, 49, 50, 51, 53, 55, 57, 60, 61, 62, 65, 68, 69, 70, 73, 74, 78], "imaginari": [14, 27, 51, 65], "imbal": [47, 62, 68, 78], "imbalanc": [20, 21, 34, 35, 47, 48, 57, 58, 72], "imblearn": [20, 57], "imdb": [31, 45, 46], "imdb_df": [31, 45, 46], "imdb_mast": [31, 45, 46], "img": [12, 25, 43, 49, 66], "img_classifi": [12, 25, 49], "img_ind": 43, "img_path": [12, 25, 49], "img_t": 66, "immedi": [23, 37, 39, 44, 60, 64, 80], "imp": [16, 29, 53, 54, 67], "impact": [7, 11, 17, 18, 22, 23, 30, 32, 36, 37, 39, 54, 55, 59, 60, 63, 67, 69, 75, 80], "implement": [2, 4, 12, 16, 20, 21, 22, 24, 25, 29, 35, 36, 38, 40, 49, 53, 57, 58, 59, 61, 63, 64, 65, 68, 69, 70, 72], "impli": [0, 68], "implic": [11, 16, 29, 53, 70, 73], "implicit": 65, "import": [8, 11, 31, 40, 48, 72, 76, 77, 78, 79, 80], "importance_typ": [22, 36, 38, 59], "importances_mean": [23, 37, 39, 60], "impos": [16, 29, 53], "imposs": 62, "impress": [23, 37, 39, 60], "improv": [11, 19, 20, 21, 22, 24, 33, 34, 35, 36, 38, 40, 42, 44, 47, 56, 57, 58, 59, 61, 62, 63, 64, 67, 68, 69, 70, 73, 77, 80], "impur": [13, 22, 26, 36, 38, 42, 50, 59], "imput": [14, 17, 18, 19, 20, 21, 22, 23, 24, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 48, 51, 54, 55, 56, 57, 58, 59, 60, 61, 62, 67, 68, 69, 70, 73, 76, 77, 78, 79], "imread": 66, "imshow": [12, 25, 43, 49, 66], "inabl": 25, "inbox": [14, 27, 51], "inc": [23, 37, 39, 60, 65], "incept": [64, 66], "inception": 66, "incl": [21, 35, 48, 58], "includ": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 20, 21, 23, 24, 25, 26, 29, 30, 34, 35, 37, 40, 43, 47, 48, 50, 53, 54, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 73, 75, 76, 77, 78, 79, 80], "include_bia": [24, 40, 61, 67], "incom": [14, 18, 20, 22, 23, 27, 32, 34, 36, 37, 38, 39, 51, 55, 57, 59, 60, 78], "incomplet": 68, "inconsist": [17, 30, 54], "incorpor": [19, 21, 24, 33, 35, 40, 48, 56, 58, 61, 68, 70, 73], "incorrect": [68, 69], "incorrectli": [12, 20, 25, 34, 47, 49, 57], "increament": 70, "increas": [8, 14, 15, 17, 18, 22, 23, 24, 27, 28, 30, 31, 32, 36, 37, 38, 39, 40, 42, 45, 46, 51, 52, 54, 55, 59, 60, 61, 62, 63, 66, 75, 77], "increasingli": [12, 25, 49], "incred": 66, "incredibli": 46, "increment": 70, "inde": [23, 37, 39, 60], "independ": [8, 9, 13, 19, 21, 22, 24, 25, 26, 33, 35, 36, 38, 40, 48, 50, 56, 58, 59, 61, 67, 80], "index": [12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 71, 75, 78, 79], "index_col": [8, 15, 16, 19, 20, 29, 33, 52, 53, 56, 57, 64, 70, 77], "india": 65, "indian": [20, 34, 44, 57], "indian_liver_pati": [12, 25, 49], "indic": [0, 17, 30, 31, 44, 45, 46, 54, 62, 64, 65, 66, 67, 68], "indirectli": 69, "individu": [22, 23, 36, 37, 38, 39, 44, 59, 60, 62, 64, 65, 68, 70, 79, 80], "industri": [22, 24, 36, 38, 40, 59, 61, 65, 66], "inept": 46, "ineptli": 46, "inequ": [20, 34, 57, 78], "inertia_": 62, "inertia_valu": 62, "inf": [15, 28, 52, 68], "infeas": [19, 33, 56], "infer": [13, 50, 65, 66, 67, 70, 74], "infin": [15, 28, 52, 69], "infinit": [19, 33, 56], "inflamm": 9, "inflat": [23, 37, 39, 60], "inflect": [62, 65], "influenc": [13, 14, 19, 23, 26, 27, 31, 33, 37, 39, 50, 51, 56, 60, 62, 64, 68, 75], "info": [1, 3, 8, 16, 17, 20, 21, 24, 29, 30, 34, 35, 40, 47, 48, 53, 54, 57, 58, 61, 65, 67, 68, 75, 79], "infom": 65, "infor_m": 65, "inform": [1, 4, 7, 10, 12, 13, 16, 17, 18, 19, 20, 21, 22, 24, 26, 29, 30, 32, 33, 34, 35, 36, 38, 40, 43, 47, 50, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 75, 78, 79, 80], "informa_t": 65, "informaion": 65, "informaiton": 65, "informationabout": 65, "informationon": 65, "ingrid": 46, "inhabit": 80, "inher": [20, 26, 34, 57, 67, 68, 78], "initi": [43, 63, 66], "initj": [23, 37, 39, 60], "inject": [24, 40, 61, 64, 73], "ink": 69, "inland": [16, 24, 29, 40, 53, 54, 61, 76], "inlin": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 74, 75, 77, 78, 79], "inner": [17, 19, 30, 33, 54, 56, 65], "inplac": [8, 12, 13, 19, 25, 31, 33, 49, 50, 56], "input": [8, 13, 16, 18, 22, 23, 26, 29, 32, 36, 37, 38, 39, 43, 44, 50, 53, 55, 59, 60, 63, 65, 66, 67, 70, 71, 73], "input_img": 66, "input_nam": 44, "input_tag": 44, "inputs_bw": 66, "insid": [9, 17, 20, 30, 34, 46, 47, 54, 57], "insight": [2, 11, 15, 20, 23, 28, 34, 37, 39, 47, 52, 57, 60, 62], "inspct": [20, 34, 57], "inspect": [23, 37, 39, 48, 60, 63], "inspir": [13, 20, 22, 36, 38, 50, 57, 59], "inst": 48, "instal": [12, 15, 20, 21, 22, 23, 25, 34, 35, 36, 37, 38, 39, 43, 44, 47, 49, 52, 57, 58, 59, 60, 62, 65, 66, 68, 70, 71], "instanc": [12, 13, 14, 17, 18, 20, 25, 26, 27, 30, 31, 32, 34, 43, 44, 47, 49, 50, 51, 54, 55, 57, 62, 63, 64, 65, 66, 67, 72], "instanti": [19, 33, 42, 56, 75], "instead": [5, 8, 10, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 26, 29, 30, 32, 33, 34, 35, 36, 38, 40, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 72, 75, 77, 78, 79], "institut": [65, 71], "instruct": [3, 4, 5, 10, 12, 15, 16, 25, 52, 69, 70, 80], "instructor": [4, 6, 12, 25, 38, 39, 40, 49, 69, 70, 80], "instrument": [15, 16, 19, 29, 33, 52, 53, 56, 77], "int": [16, 17, 20, 22, 23, 29, 30, 34, 36, 37, 38, 39, 53, 54, 57, 59, 60, 65, 67, 71, 78, 79], "int32": [15, 28, 52, 62, 63, 67], "int64": [13, 15, 16, 17, 19, 20, 21, 26, 30, 34, 35, 42, 44, 46, 50, 52, 54, 57, 58, 64, 65, 67, 68, 70, 71], "integ": [8, 16, 19, 22, 23, 29, 33, 36, 37, 38, 39, 51, 53, 56, 59, 60, 67, 71], "integr": [11, 70], "intellig": [1, 65], "intelligen": 65, "intend": [0, 69, 80], "intens": [46, 65], "inter": 71, "interact": [9, 12, 15, 19, 20, 23, 25, 28, 33, 34, 37, 39, 43, 47, 52, 56, 57, 60, 62, 63, 64, 67, 70, 71, 75], "interaction_constraint": [22, 36, 38, 59], "interaction_onli": [24, 40, 61, 67], "interactive_plot": [15, 28, 43, 52, 75], "intercept": [23, 37, 39, 60, 66, 72], "intercept_": [18, 22, 32, 36, 38, 55, 59, 66, 72], "intercept_sc": [20, 34, 57], "interest": [2, 12, 14, 19, 20, 21, 22, 23, 24, 25, 27, 33, 34, 35, 36, 37, 38, 39, 40, 44, 47, 48, 49, 51, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 75, 77, 79], "interestingli": 40, "interfac": [22, 36, 38, 59, 70], "intermedi": [63, 66], "intern": [0, 1, 13, 26, 50, 66, 67, 68], "internet": [68, 69, 70], "internetservic": 68, "internetservice_dsl": 68, "internetservice_fib": 68, "internetservice_no": 68, "internship": [12, 25, 49], "interpret": [1, 10, 11, 15, 16, 20, 21, 22, 24, 28, 29, 34, 35, 36, 38, 40, 42, 47, 48, 52, 53, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 78], "interv": [11, 67, 68, 73, 77], "interweb": 70, "intestin": 46, "intrins": 67, "intro": [1, 65, 66], "introduc": [17, 20, 30, 54, 57, 68], "introduct": [1, 9, 10, 11, 42, 67, 68, 75], "intslid": [15, 28, 43, 52, 75], "intuit": [11, 15, 16, 17, 19, 21, 23, 28, 29, 30, 33, 35, 37, 39, 48, 52, 53, 54, 56, 58, 60, 62, 63, 68, 71], "invalid": 56, "inventori": 73, "invers": [18, 21, 32, 35, 48, 55, 58], "inverse_func": [21, 35, 48, 58, 69], "investig": [15, 23, 28, 37, 39, 43, 52, 60, 75], "involv": [2, 4, 19, 21, 22, 33, 35, 36, 38, 48, 56, 58, 59, 63, 65, 66], "io": [9, 16, 29, 41, 53, 66, 68, 71], "ipykernel_13054": 71, "ipykernel_19402": 60, "ipykernel_22611": 44, "ipykernel_32469": 53, "ipykernel_4311": 39, "ipykernel_70329": 29, "ipykernel_79734": 51, "ipynb": [7, 8, 12, 25], "ipython": [12, 13, 14, 15, 16, 17, 18, 20, 25, 26, 27, 28, 29, 30, 31, 32, 34, 47, 49, 50, 51, 52, 53, 54, 55, 57, 65, 74, 76, 78], "ipywidget": [15, 28, 52, 75], "ir1": [21, 23, 35, 37, 39, 58, 60, 69], "ir2": [21, 23, 35, 37, 58, 60, 69], "iri": [15, 28, 43, 52, 75], "iris_df": [15, 28, 43, 52, 75], "irregular": 11, "irregularli": 73, "irrelev": [15, 24, 28, 40, 52, 61, 65], "irrelevant_po": 65, "irrespect": [14, 18, 27, 32, 51, 55, 80], "is_avail": [43, 66], "is_classifi": 44, "is_leap_year": 67, "is_stop": 65, "is_year_end": 67, "isinst": [44, 68], "island": [16, 29, 53, 54], "isn": [14, 15, 20, 21, 22, 28, 34, 35, 36, 46, 51, 52, 57, 58, 59, 65, 69], "isna": 31, "isnul": [16, 29, 44, 53], "iso": [31, 45, 46], "isol": [10, 20, 21, 23, 35, 37, 39, 48, 57, 58, 60, 69], "issu": [4, 6, 7, 12, 22, 25, 36, 38, 42, 59, 64, 68, 73, 77, 80], "issubclass": 68, "isupp": 71, "itali": 65, "italian": [44, 46], "item": [12, 22, 23, 25, 36, 37, 38, 39, 43, 49, 59, 60, 62, 64, 65, 66, 68, 73, 79], "item_inverse_mapp": 64, "item_kei": 64, "item_mapp": 64, "iter": [19, 24, 33, 40, 43, 56, 61, 62, 63, 66, 70], "iterable_with_config": [17, 30, 54], "iterrow": 64, "its": [8, 11, 12, 14, 15, 17, 18, 20, 23, 25, 28, 29, 30, 32, 34, 37, 39, 43, 44, 49, 51, 52, 54, 55, 57, 60, 62, 63, 65, 66, 67, 68, 71, 72, 75, 77, 80], "itself": [7, 20, 22, 34, 36, 38, 57, 59, 63, 65], "j": [8, 18, 23, 24, 32, 37, 39, 40, 55, 60, 61, 62, 64, 66], "jackin": [33, 56], "jackpot": [17, 30, 54], "jaguar": [12, 25, 49, 66], "jake": 46, "jalebi": 65, "jam": [33, 56], "jame": [65, 68, 71], "jan": [1, 12, 13, 16], "januari": [12, 25, 67], "japan": 65, "jargon": [13, 26, 50], "jason": [1, 24, 40, 61], "javascript": [23, 37, 39, 60], "jazz_musician": 65, "jellyfish": 66, "jennif": 71, "jerri": 64, "jet": [16, 29, 53], "jetti": 66, "jieba": 65, "jim": 64, "jmlr": [19, 33, 56], "joan_baez": 65, "joanna": 46, "job": [17, 30, 46, 54, 67, 68], "joblib": [17, 30, 54, 70], "joei": 44, "john": [22, 36, 38, 46, 59], "johnny_cash": 65, "join": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75, 77, 78, 79, 80], "jointli": 67, "joke": [12, 25, 49, 64], "jolen": 71, "jon": 46, "joni_mitchel": 65, "joss": 46, "journal": 65, "journei": [1, 63, 80], "jpg": [43, 66], "json": 70, "ju": [12, 25, 49], "jubatu": [12, 25, 49, 66], "judg": [24, 40, 61], "judgment": 69, "juic": 65, "juli": 67, "jump": 46, "june": 67, "jupyt": [1, 7, 8, 9, 10, 16, 17, 19, 20, 21, 22, 23, 24, 29, 30, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 49, 53, 54, 56, 57, 58, 59, 60, 61, 66, 69, 70, 71], "jupyter_notebook": 68, "jupyterlab": [23, 37, 39, 60], "jurafski": 65, "jurisdict": 65, "just": [4, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 73, 75, 79, 80], "justic": [23, 37, 39, 60, 65], "justif": 79, "k": [1, 7, 11, 14, 18, 19, 20, 21, 22, 24, 27, 31, 32, 35, 38, 40, 43, 44, 45, 46, 48, 51, 55, 57, 58, 59, 61, 65, 66, 68, 70, 71, 72, 75], "k_neighbor": [20, 57], "k_valu": [15, 28, 52], "kaggl": [13, 16, 20, 21, 22, 23, 24, 29, 34, 35, 36, 37, 39, 40, 43, 47, 48, 50, 53, 57, 58, 59, 60, 61, 66, 69, 78, 79], "kaggler": [24, 40, 61], "kangaroo": 66, "kaplan": 11, "kaplanmeierfitt": 68, "kazmi": [1, 80], "kb": [17, 21, 30, 35, 54, 58, 68], "kbinsdiscret": [24, 40, 61], "kbinsdiscretizer__latitude_0": [24, 40, 61], "kbinsdiscretizer__latitude_1": [24, 40, 61], "kbinsdiscretizer__latitude_2": [24, 40, 61], "kbinsdiscretizer__latitude_3": [24, 40, 61], "kbinsdiscretizer__latitude_4": [24, 40, 61], "kbinsdiscretizer__latitude_5": [24, 40, 61], "kbinsdiscretizer__latitude_6": [24, 40, 61], "kbinsdiscretizer__latitude_7": [24, 40, 61], "kbinsdiscretizer__latitude_8": [24, 40, 61], "kbinsdiscretizer__latitude_9": [24, 40, 61], "kbinsdiscretizer__longitude_11": [24, 40, 61], "kbinsdiscretizer__longitude_12": [24, 40, 61], "kbinsdiscretizer__longitude_13": [24, 40, 61], "kbinsdiscretizer__longitude_14": [24, 40, 61], "kbinsdiscretizer__longitude_15": [24, 40, 61], "kbinsdiscretizer__longitude_16": [24, 40, 61], "kbinsdiscretizer__longitude_17": [24, 40, 61], "kbinsdiscretizer__longitude_18": [24, 40, 61], "kbinsdiscretizer__longitude_19": [24, 40, 61], "kbinsdiscretizerkbinsdiscret": [24, 61], "kc_house_data": [12, 13, 25, 42, 49, 50, 75], "kdtree": 44, "keep": [1, 14, 15, 16, 17, 20, 22, 23, 24, 27, 28, 29, 30, 34, 36, 37, 38, 39, 40, 42, 46, 47, 51, 52, 53, 54, 57, 59, 60, 61, 62, 64, 65, 68, 70, 75, 76, 80], "keep_empty_featur": 64, "kei": [9, 11, 13, 15, 16, 19, 20, 21, 22, 26, 28, 29, 33, 34, 35, 36, 38, 47, 48, 50, 51, 52, 53, 56, 57, 58, 59, 64, 65, 68, 71, 77, 79], "kelbowvisu": 62, "kellei": [18, 32, 55], "ken": 46, "kenni": 46, "kept": [14, 27, 51], "kera": [23, 37, 39, 60], "kernel": [1, 7, 16, 18, 19, 23, 24, 29, 32, 33, 37, 39, 40, 43, 53, 55, 56, 60, 61, 69, 75], "kernelexplain": [23, 37, 39, 60], "keyword": [4, 19, 33, 56, 71], "kfold": [20, 34, 57], "kick": 65, "kiddi": [45, 46], "kilian": [23, 37, 39, 60], "kill": [46, 68], "killer": 46, "kimia": [1, 80], "kind": [0, 12, 13, 14, 16, 17, 18, 20, 21, 23, 25, 26, 27, 29, 30, 32, 34, 35, 37, 39, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 60, 62, 63, 64, 66, 67, 68, 70, 72], "king": [42, 64, 65, 75], "kitchenabvgr": [21, 23, 35, 37, 39, 48, 58, 60, 69], "kitchenqu": [21, 23, 35, 37, 39, 48, 58, 60, 69], "kiwi": 65, "kk": 62, "km": [68, 69, 73], "km_label": 62, "kmean": [62, 63, 73], "kmf": 68, "kmqfw": 68, "kneighbor": 43, "kneighborregressor": [16, 29, 53], "kneighborsclassifi": [16, 17, 18, 24, 29, 30, 32, 40, 44, 53, 54, 55, 61, 75, 76], "kneighborsclassifierifittedkneighborsclassifi": 44, "kneighborsregressor": [16, 17, 18, 29, 30, 32, 53, 54, 55, 76], "kneighborsregressorkneighborsregressor": [16, 29, 53, 54], "knew": 62, "knn": [2, 14, 15, 16, 18, 23, 24, 27, 28, 29, 32, 37, 39, 40, 51, 52, 53, 54, 55, 60, 61, 64, 66, 70, 72, 73, 79], "knn1": [15, 28, 52], "knn100": [15, 28, 52], "knn_pipe": 54, "knn_scale": [16, 29, 53], "knn_unscal": [16, 29, 53], "knn_valid_accuraci": [15, 28, 52], "knnimput": 64, "knob": [13, 26, 50, 69], "know": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 35, 36, 37, 39, 40, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80], "knowledg": [8, 12, 13, 17, 19, 24, 25, 26, 30, 33, 40, 50, 54, 56, 61, 62, 65, 69, 73], "knowleg": 73, "known": [43, 64, 65, 68], "koala": 66, "kolhatkar": [0, 1, 26, 65], "kr9rkqfj4w78h49djkz8yy9r0000gp": 51, "ksatr": 68, "kvarada": [10, 50, 51, 54, 56, 60, 65, 66, 68, 71, 72], "kvarada01": 10, "kwantlen": 65, "kwarg": [14, 16, 17, 27, 29, 30, 40, 44, 51, 53, 54, 68, 71], "l": 10, "l1": 68, "l123": 4, "l17": 4, "l1_ratio": [20, 34, 57], "l2": [20, 34, 57, 65, 68], "l9": 4, "la": 69, "lab": [10, 12, 13, 14, 25, 27, 50, 51, 62, 64], "lab1": [13, 14, 17, 26, 27, 30, 50, 51, 54, 73], "lab2": [13, 14, 17, 26, 27, 30, 50, 51, 54, 73], "lab3": [13, 14, 17, 26, 27, 30, 50, 51, 54, 73], "lab4": [13, 14, 17, 26, 27, 30, 50, 51, 54, 73], "label": [7, 8, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 34, 35, 37, 38, 39, 40, 42, 43, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 71, 76], "label_": [65, 71], "label_encod": [22, 23, 36, 37, 38, 39, 59, 60], "label_n_clust": 63, "labelencod": [22, 23, 36, 37, 38, 39, 59, 60], "labels": [20, 34, 47, 57, 62], "labels_": [62, 63], "lack": [14, 27, 46, 51, 64, 69], "lag": [68, 73], "lag_df": 67, "lakehead_univers": 65, "lakeshor": 66, "lakesid": 66, "lamb": 44, "lambda": [8, 13, 18, 26, 32, 44, 50, 55, 63, 66, 67, 68, 71], "land": 68, "landcontour": [21, 23, 35, 37, 39, 58, 60, 69], "landcontour_bnk": [21, 35, 39, 58], "landcontour_hl": [21, 35, 39, 58], "landcontour_low": [21, 35, 39, 58], "landcontour_lvl": [21, 35, 39, 58], "landmark": 73, "landown": 71, "landscap": [62, 65], "landslop": [21, 23, 35, 37, 39, 58, 60, 69], "landslope_gtl": [21, 23, 35, 37, 39, 58, 60], "landslope_mod": [21, 23, 35, 37, 39, 58, 60], "landslope_sev": [21, 23, 35, 37, 39, 58, 60], "langara_colleg": 65, "languag": [2, 9, 16, 17, 29, 30, 46, 53, 54, 64, 66, 70, 71], "language_enc": [16, 29, 53], "language_english": [16, 29, 53], "language_french": [16, 29, 53], "language_hindi": [16, 29, 53], "language_mandarin": [16, 29, 53], "language_spanish": [16, 29, 53], "language_vietnames": [16, 29, 53], "laptop": [12, 25, 49, 70], "lar": [12, 25, 49], "larg": [12, 14, 15, 16, 18, 20, 21, 25, 27, 28, 29, 31, 32, 34, 35, 40, 42, 45, 46, 47, 48, 49, 51, 52, 53, 55, 57, 58, 62, 63, 65, 66, 70, 73, 75, 78], "larger": [13, 14, 15, 16, 18, 19, 21, 22, 23, 27, 28, 29, 32, 33, 35, 36, 37, 38, 39, 50, 51, 52, 53, 55, 56, 58, 59, 60, 62, 63, 68], "largest": [21, 35, 48, 58], "larvatu": [12, 25, 49, 66], "last": [8, 12, 13, 14, 15, 16, 17, 20, 23, 25, 26, 27, 29, 30, 37, 39, 43, 44, 46, 47, 50, 51, 52, 53, 54, 57, 60, 64, 66, 67, 68, 69, 70, 75, 77, 79, 80], "last_row": 8, "lastp": 63, "lat": [12, 13, 25, 42, 49, 50], "late": [19, 20, 25, 46, 57, 80], "latent": [64, 65, 66], "latentdirichletalloc": 65, "later": [10, 13, 17, 20, 26, 30, 34, 47, 50, 54, 57, 66, 67, 70, 75], "latest": [17, 23, 30, 39, 54, 60, 68], "latex": [4, 7, 12, 25], "latin": [12, 20, 25, 34, 47, 49, 57, 78], "latitud": [14, 15, 16, 18, 24, 27, 28, 29, 32, 40, 51, 52, 53, 54, 55, 61, 76], "latitude_0": [24, 40, 61], "latitude_1": [24, 40, 61], "latitude_10": [24, 61], "latitude_11": [24, 61], "latitude_12": [24, 61], "latitude_13": [24, 61], "latitude_14": [24, 61], "latitude_15": [24, 61], "latitude_16": [24, 61], "latitude_17": [24, 61], "latitude_18": [24, 61], "latitude_19": [24, 61], "latitude_2": [24, 40, 61], "latitude_3": [24, 61], "latitude_4": [24, 61], "latitude_5": [24, 61], "latitude_6": [24, 61], "latitude_7": [24, 61], "latitude_8": [24, 40, 61], "latitude_9": [24, 61], "latter": [21, 35, 48, 58], "laugh": 46, "launch": [12, 25], "lauvagrand": 71, "law": [44, 65], "lawsuit": 65, "layer": [43, 66], "layout": [15, 28, 43, 52, 75], "lazi": [15, 28, 52], "lbfg": [20, 34, 57], "lda": 66, "ldot": [19, 33, 56], "lead": [1, 8, 14, 18, 21, 27, 32, 35, 51, 55, 58, 63, 64, 65, 68, 69], "leaf": [13, 26, 50, 63, 65], "leagu": 65, "leak": [16, 29, 53, 68, 73], "leakag": 73, "leaner": [14, 27, 51], "learn": [2, 9, 10, 44, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "learner": [14, 15, 22, 27, 28, 36, 38, 51, 52, 59], "learning_method": 65, "learning_r": [22, 36, 38, 59], "learnxinyminut": 9, "least": [1, 4, 14, 15, 20, 21, 23, 24, 27, 28, 31, 34, 35, 37, 39, 40, 45, 46, 47, 48, 51, 52, 57, 58, 60, 61, 62, 63, 69, 79], "least_confident_i": [18, 32, 55], "least_confident_x": [18, 32, 55], "leav": [7, 13, 26, 50, 63, 66, 68, 69, 72], "lectur": [5, 7, 8, 10, 41, 73, 78], "lecun": [23, 37, 39, 60], "lecuy": 1, "lee": [23, 37, 39, 46, 60], "left": [7, 12, 19, 20, 21, 25, 33, 34, 35, 47, 48, 49, 56, 57, 58, 62, 63, 65, 67, 68, 69, 80], "leg": 46, "legal": [0, 65], "legend": [7, 8, 15, 18, 20, 21, 24, 28, 32, 34, 35, 40, 47, 48, 52, 55, 57, 58, 61, 62, 66, 67, 68, 69, 72], "legendari": 71, "legless": 46, "leisur": [20, 57, 70], "lemma": 65, "lemma_": 65, "lemmat": 65, "lemon": 62, "len": [12, 14, 16, 19, 20, 21, 22, 23, 27, 29, 33, 35, 36, 37, 38, 39, 40, 43, 47, 48, 51, 53, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 69, 71], "length": [13, 14, 15, 18, 21, 23, 26, 27, 28, 32, 35, 37, 39, 42, 43, 50, 51, 52, 55, 58, 60, 62, 63, 65, 67, 68, 71, 75], "leo": [22, 36, 38, 59], "leopard": [12, 25, 49, 66], "leq": [24, 40, 61, 62], "less": [1, 5, 6, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 48, 49, 52, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 68, 69, 73, 75, 78], "lesson": [9, 16, 29, 53, 71], "lesssim": [14, 27, 51], "let": [12, 13, 14, 18, 19, 22, 24, 25, 26, 27, 31, 32, 33, 36, 38, 39, 40, 42, 43, 45, 46, 48, 49, 50, 51, 55, 56, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "letter": [18, 32, 55, 71], "lev": [21, 35, 48, 58], "level": [11, 15, 18, 20, 21, 22, 23, 24, 28, 32, 34, 35, 37, 38, 39, 40, 46, 48, 52, 55, 57, 58, 59, 60, 61, 63, 65, 66, 67, 69, 70, 78], "leverag": [23, 37, 39, 60, 64], "lewi": 71, "lexic": 65, "lexicon": 71, "lgbm": [11, 22, 23, 36, 37, 38, 59, 60, 73], "lgbmclassifi": [12, 22, 23, 25, 36, 37, 38, 39, 49, 59, 60, 79], "lgbmclassifierifittedlgbmclassifi": [12, 23, 25, 37, 39, 49, 60], "lgbmclassifierlgbmclassifi": [22, 36, 38, 59], "lgbmregressor": [12, 22, 25, 36, 38, 49, 59], "li": [1, 18, 32, 55, 80], "lia": 46, "liabil": 0, "liabl": 0, "liao": [12, 25, 49], "lib": [17, 26, 30, 43, 44, 50, 51, 54, 56, 60, 68, 72], "liblinear": 40, "librari": [4, 8, 10, 14, 20, 23, 24, 27, 37, 39, 40, 42, 44, 51, 57, 60, 61, 65, 66, 67, 69, 71, 75], "licensor": 0, "life": [13, 18, 32, 40, 44, 50, 55, 62, 64, 69, 70, 74, 80], "lifeless": 46, "lifelin": [11, 68], "lifetim": 68, "light": 46, "lighter": [19, 33, 56], "lightgbm": [12, 23, 25, 37, 39, 49, 60, 70, 79], "lightgbmcolumntransform": [22, 36, 38], "lightweight": 65, "likabl": 46, "like": [1, 2, 4, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78, 79, 80], "likelihood": [47, 68], "likewis": 7, "lime": [23, 37, 60], "limit": [0, 12, 13, 14, 17, 22, 23, 25, 27, 30, 36, 37, 38, 39, 49, 50, 51, 54, 59, 60, 69, 70, 71, 73, 74, 77, 80], "linalg": 65, "line": [4, 8, 10, 12, 13, 17, 18, 19, 20, 21, 25, 26, 30, 32, 33, 35, 44, 46, 48, 50, 54, 55, 56, 57, 58, 62, 65, 66, 67, 68, 69, 75, 77], "line2d": 8, "linear": [1, 19, 20, 22, 24, 33, 34, 36, 38, 47, 48, 56, 57, 59, 61, 63, 64, 66, 67, 68, 69, 70, 72, 73], "linear_model": [12, 18, 20, 21, 22, 23, 24, 25, 31, 32, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 49, 55, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 72, 78, 79], "linear_svc": [18, 32, 55], "linearli": [18, 24, 32, 40, 55, 61, 67], "linearregress": [18, 21, 24, 32, 35, 40, 48, 55, 58, 61, 68], "linestyl": [62, 67], "linewidth": [67, 69], "linger": [15, 52], "lingual": 65, "linguist": [17, 30, 54], "link": [0, 4, 5, 7, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 49, 50, 54, 55, 58, 59, 63, 68, 69, 70, 80], "linkag": 63, "linkage_arrai": 63, "linkage_typ": 63, "linkedin": 64, "linspac": [18, 19, 21, 24, 32, 33, 35, 48, 55, 56, 58, 61, 69, 77], "lion": 64, "list": [4, 7, 8, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 79, 80], "listedcolormap": [18, 32, 55], "liter": 46, "literatur": [22, 36, 38, 59], "littl": [8, 19, 20, 34, 46, 47, 57, 66, 69, 70], "live": [1, 10, 12, 15, 16, 17, 19, 25, 29, 30, 33, 52, 53, 54, 56, 62, 68, 69, 70, 77], "liver": [13, 26, 50], "livestream": 80, "ll": [1, 6, 7, 10, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 80], "llazx": 68, "lo": 71, "load": [8, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 47, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 66, 69, 71, 75, 76, 78], "load_breast_canc": [24, 40, 61], "load_citibik": 67, "load_digit": 69, "load_iri": [15, 28, 43, 52, 75], "loan": [20, 34, 57, 78], "loc": [8, 15, 18, 20, 23, 28, 32, 34, 37, 39, 40, 47, 52, 55, 57, 60, 64, 67, 68, 69], "local": [5, 7, 10, 20, 22, 23, 24, 34, 36, 37, 38, 39, 40, 43, 44, 47, 57, 59, 60, 61, 66, 71], "locat": [8, 17, 30, 43, 46, 54, 62, 64, 65, 67, 71, 79, 80], "location_katherin": 67, "location_mountginini": 67, "location_townsvil": 67, "location_witchcliff": 67, "location_wollongong": 67, "lock": [14, 27, 51], "log": [12, 13, 15, 21, 22, 28, 35, 36, 38, 43, 44, 52, 58, 59, 68, 69, 70, 75, 79], "log10": [21, 35, 48, 58], "log1p": [21, 35, 48, 58, 69], "log2": 68, "log_likelihood_ratio_test": 68, "log_loss": 69, "logarithm": [15, 28, 43, 52, 75], "logic": [24, 40, 61], "logical_xor": [24, 40, 61], "login": 64, "logisit": 66, "logist": [22, 23, 31, 36, 37, 38, 39, 45, 46, 59, 60, 67, 68, 69, 70, 71, 72, 73, 78, 79], "logisticregress": [12, 18, 21, 22, 23, 24, 25, 31, 32, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 49, 55, 58, 59, 60, 61, 65, 66, 70, 71, 72, 78, 79], "logisticregressionifittedlogisticregress": 66, "logisticregressionlogisticregress": [20, 22, 34, 36, 38, 46, 57, 59, 66, 71], "logloss": [23, 37, 39, 60], "lognorm": [19, 33, 56], "logspac": [19, 33, 43, 56, 77], "loguniform": [19, 33, 56, 77], "lol": [17, 30, 54], "london": 71, "lone": 63, "long": [0, 12, 13, 18, 20, 22, 25, 26, 32, 36, 42, 49, 50, 55, 57, 59, 63, 64, 68, 70, 73, 80], "longer": [7, 19, 20, 33, 34, 56, 57, 66, 68, 69, 70], "longest": [13, 26, 50], "longitud": [14, 15, 16, 18, 24, 27, 28, 29, 32, 40, 51, 52, 53, 54, 55, 61, 76], "longitude_0": [24, 40, 61], "longitude_1": [24, 40, 61], "longitude_10": [24, 61], "longitude_11": [24, 61], "longitude_12": [24, 61], "longitude_13": [24, 61], "longitude_14": [24, 61], "longitude_15": [24, 61], "longitude_16": [24, 61], "longitude_17": [24, 61], "longitude_18": [24, 61], "longitude_19": [24, 61], "longitude_2": [24, 40, 61], "longitude_3": [24, 40, 61], "longitude_4": [24, 40, 61], "longitude_5": [24, 61], "longitude_6": [24, 61], "longitude_7": [24, 61], "longitude_8": [24, 61], "longitude_9": [24, 61], "look": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 77, 78, 79], "lookatm": [12, 25, 49], "loop": [19, 22, 33, 38, 56, 59, 67, 72, 73], "loos": [63, 70], "lose": [6, 17, 30, 54], "loss": [2, 20, 21, 22, 23, 34, 35, 36, 37, 38, 39, 48, 57, 58, 59, 60, 65, 68, 78], "lot": [5, 9, 12, 13, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 37, 39, 40, 44, 46, 47, 49, 50, 52, 54, 55, 56, 57, 58, 60, 61, 63, 66, 67, 68, 69, 70, 77, 80], "lotarea": [21, 23, 35, 37, 39, 48, 58, 60, 69], "lotconfig": [21, 23, 35, 37, 39, 58, 60, 69], "lotconfig_corn": [21, 35, 58], "lotconfig_culdsac": [21, 35, 58], "lotconfig_fr2": [21, 35, 58], "lotconfig_fr3": [21, 35, 58], "lotconfig_insid": [21, 35, 58], "lotfrontag": [21, 23, 35, 37, 39, 48, 58, 60, 69], "lotshap": [21, 23, 35, 37, 39, 58, 60, 69], "lotshape_ir1": [21, 35, 58, 69], "lotshape_ir2": [21, 35, 58, 69], "lotshape_ir3": [21, 35, 37, 58, 69], "lotshape_reg": [21, 35, 37, 58, 69], "loud": [15, 16, 19, 29, 33, 44, 52, 53, 56, 73, 77], "loui": 67, "lourenzutti": [19, 33, 56], "love": [46, 70, 71], "low": [6, 14, 15, 19, 20, 21, 23, 24, 27, 28, 33, 34, 35, 37, 39, 40, 44, 47, 48, 51, 52, 56, 57, 58, 60, 61, 62, 63, 68, 69, 70], "lower": [14, 15, 20, 21, 23, 27, 28, 34, 35, 37, 39, 47, 48, 51, 52, 57, 58, 60, 62, 64, 65, 68, 69, 77], "lowerbound_peopl": 44, "lowercas": [16, 17, 29, 30, 53, 54], "lowest": [75, 80], "lowqualfinsf": [21, 23, 35, 37, 39, 48, 58, 60, 69], "lr": [18, 20, 21, 23, 32, 34, 35, 37, 39, 45, 46, 47, 48, 55, 57, 58, 60, 66, 67, 68, 71, 72], "lr_1": [24, 40, 61], "lr_2": [24, 40, 61], "lr_3": [24, 40, 61], "lr_coef": [23, 37, 39, 60, 67, 68], "lr_coefs_landslop": [23, 37, 39, 60], "lr_flatten_pip": 66, "lr_item": 64, "lr_l1_pipe": 40, "lr_l2_pipe": 40, "lr_pipe": [21, 23, 35, 37, 39, 48, 58, 60, 67], "lr_pred": [20, 21, 34, 35, 47, 48, 57, 58], "lr_scale": [23, 37, 39, 60], "lr_schedul": 66, "lr_x": 64, "lr_y": 64, "ls15hb": [12, 25, 49], "lstm": 67, "lt": [14, 16, 17, 19, 20, 21, 22, 23, 24, 27, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 46, 51, 53, 54, 56, 57, 58, 59, 60, 61, 68], "ltorgo": [18, 32, 55], "lucio": 46, "luck": 70, "lucki": [15, 19, 28, 33, 52, 56], "luckili": [77, 79], "lundberg": [23, 37, 39, 60], "luster": 63, "lvert": 65, "lvl": [21, 23, 35, 37, 39, 58, 60, 69], "lwq": [21, 23, 35, 37, 39, 48, 58, 60, 69], "lynx": [12, 25, 49, 66], "l\u00e9cuyer": [65, 80], "m": [10, 12, 14, 19, 21, 22, 23, 24, 25, 27, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 48, 49, 51, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "m_neighbor": [20, 57], "ma": [56, 65], "macaqu": [12, 25, 49, 66], "macbook": 10, "mach": 65, "machet": 46, "machin": [2, 9, 10, 11, 16, 17, 19, 21, 22, 23, 24, 29, 30, 33, 35, 36, 37, 38, 39, 40, 43, 44, 46, 48, 53, 54, 56, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 71, 73, 75, 80], "machine_learn": 69, "mackworth": 1, "made": [0, 6, 7, 8, 12, 13, 20, 22, 23, 25, 26, 34, 37, 38, 39, 47, 49, 50, 57, 59, 60, 64, 65, 66, 67, 69, 70, 77], "magazin": 65, "magnitud": [19, 21, 23, 29, 31, 33, 35, 37, 39, 45, 46, 48, 56, 58, 60, 65, 67], "maguir": 64, "mahsa": [1, 80], "mai": [0, 1, 7, 8, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 44, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 67, 68, 70, 74, 75, 76, 77, 78, 79, 80], "mail": 68, "main": [8, 10, 12, 13, 15, 17, 22, 25, 26, 28, 30, 36, 38, 40, 42, 50, 52, 54, 59, 62, 63, 73, 80], "mainland": [18, 32, 55], "mainli": 80, "maintain": [22, 36, 38, 59, 64, 69, 73], "mainten": [22, 36, 38, 59], "maissan": [1, 80], "maj1": [21, 23, 35, 37, 39, 48, 58, 60, 69], "maj2": [21, 23, 35, 37, 39, 48, 58, 60, 69], "major": [2, 14, 15, 16, 17, 27, 28, 29, 30, 51, 52, 53, 54, 65, 73, 74, 79], "major_biologi": [17, 30, 54], "major_comput": [17, 30, 54], "major_econom": [17, 30, 54], "major_linguist": [17, 30, 54], "major_mathemat": [17, 30, 54], "major_mechan": [17, 30, 54], "major_phys": [17, 30, 54], "major_psychologi": [17, 30, 54], "make": [2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 78, 79, 80], "make_blob": [15, 28, 52, 62, 63, 66, 72], "make_circl": 63, "make_classif": [15, 20, 28, 52, 57], "make_column_transform": [19, 20, 21, 22, 23, 24, 33, 34, 35, 36, 37, 38, 39, 40, 44, 48, 56, 57, 58, 59, 60, 61, 67, 68, 69, 71, 76, 77, 78, 79], "make_forg": [15, 28, 52], "make_grid": [43, 66], "make_imb_pipelin": [20, 57], "make_moon": 63, "make_num_tree_plot": [22, 36, 38, 59], "make_pipelin": [12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 49, 54, 55, 56, 57, 58, 59, 60, 61, 65, 66, 67, 68, 69, 70, 71, 76, 77, 78, 79], "make_scor": [21, 24, 35, 40, 48, 58, 61], "maker": [46, 69], "malcolm": [62, 64], "malcom": 62, "male": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 68, 78], "male_cm": [20, 34, 57, 78], "male_pr": [20, 34, 57, 78], "malkovich": 46, "mall": 71, "mamba": [43, 44], "man": [46, 64, 65], "manag": [5, 11, 67, 68, 69, 73], "mandarin": [16, 29, 53], "mango": 65, "mani": [1, 2, 5, 8, 12, 13, 14, 15, 16, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 77, 79, 80], "manipul": 69, "manner": [0, 22, 36, 38, 59], "manual": [10, 12, 17, 20, 24, 25, 26, 30, 34, 40, 43, 47, 48, 49, 54, 57, 61, 62, 63, 65, 77], "manual_se": 43, "manufactur": [19, 66], "map": [1, 13, 14, 17, 19, 26, 27, 30, 31, 33, 45, 46, 50, 51, 54, 56, 64, 77], "mape": [70, 73], "mape_scor": [21, 35, 48, 58], "maple_leaf": 65, "mapper": 64, "mar": 1, "march": [38, 39, 40, 67], "marit": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "mark": [6, 7, 19, 20, 25, 33, 34, 40, 47, 56, 57, 63, 80], "markdown": [12, 25], "marker": [15, 18, 28, 32, 52, 55, 62], "markers": [18, 20, 32, 34, 47, 55, 57], "market": [12, 25, 49, 62, 66, 67, 69, 70], "markov": 65, "marri": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60], "martin": 65, "mask": [19, 33, 56], "massiv": [17, 19, 30, 33, 54, 56], "master": [8, 19, 20, 22, 23, 33, 34, 36, 37, 38, 39, 47, 56, 57, 59, 60, 65, 78], "masvnrarea": [21, 23, 35, 37, 39, 48, 58, 60, 69], "masvnrtyp": [21, 23, 35, 37, 39, 58, 60, 69], "masvnrtype_brkcmn": [21, 35, 58], "masvnrtype_brkfac": [21, 35, 58], "masvnrtype_miss": [21, 35, 58], "masvnrtype_ston": [21, 35, 58], "match": [17, 18, 20, 22, 23, 30, 32, 34, 36, 37, 39, 47, 54, 55, 57, 59, 60, 67, 79], "materi": [8, 10, 12, 13, 14, 15, 20, 25, 28, 49, 50, 51, 52, 62, 65, 68, 70, 73, 80], "matern": [24, 40, 61], "math": [2, 40, 62, 64, 68], "mathcal": [15, 52], "mathemat": [2, 17, 22, 30, 36, 38, 54, 59, 70, 73], "mathematician": 65, "mathia": [1, 17, 80], "matlab": 8, "matplotlib": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 73, 74, 75, 76, 77, 78, 79], "matplotlibdeprecationwarn": [39, 60], "matric": [12, 15, 20, 25, 28, 34, 52, 57, 64, 78], "matrix": [17, 30, 44, 46, 54, 63, 65, 70, 73, 78], "mattei": 46, "matter": [16, 17, 20, 22, 29, 30, 34, 36, 38, 53, 54, 57, 59, 63, 69, 73, 80], "max": [8, 14, 16, 18, 19, 20, 21, 22, 27, 29, 31, 32, 33, 34, 35, 36, 38, 42, 44, 45, 46, 48, 51, 53, 55, 56, 57, 58, 59, 62, 63, 67], "max_bin": [22, 36, 38, 59], "max_cat_threshold": [22, 36, 38, 59], "max_cat_to_onehot": [22, 36, 38, 59], "max_clust": 63, "max_colwidth": [12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 63, 64, 74, 75, 76, 77, 78], "max_delta_step": [22, 36, 38, 59], "max_depth": [14, 15, 19, 22, 23, 27, 28, 33, 36, 37, 38, 39, 42, 43, 51, 52, 56, 59, 60, 69, 74, 75], "max_depth_widget": [15, 28, 43, 52, 75], "max_df": [17, 30, 54], "max_displai": [23, 37, 39, 60], "max_featur": [12, 17, 19, 22, 25, 30, 31, 33, 36, 38, 44, 45, 46, 49, 54, 56, 59, 69, 77], "max_it": [12, 20, 22, 23, 24, 25, 31, 34, 36, 37, 38, 39, 40, 46, 47, 49, 57, 59, 60, 61, 65, 66, 67, 68, 69, 70, 71, 72, 78], "max_leaf_nod": [13, 26, 50, 69], "max_leav": [22, 36, 38, 59], "max_opt": [15, 20, 28, 34, 47, 52, 57, 62, 63], "max_row": 68, "max_sampl": 69, "maxabsscal": 44, "maxclust": 63, "maxent": 72, "maxhr": 79, "maxim": [12, 20, 21, 25, 34, 35, 48, 49, 57, 58, 62], "maximum": [13, 16, 21, 22, 26, 29, 31, 35, 36, 38, 44, 45, 46, 48, 50, 53, 58, 59, 62, 63, 75], "maxosx": 10, "maxtemp": 67, "may": 1, "mayb": [20, 23, 34, 37, 39, 57, 60, 67, 69, 80], "maybe_coerce_valu": 68, "mb": [16, 20, 24, 29, 34, 40, 53, 54, 57, 61, 67, 68], "mcld": 80, "mcml": [1, 80], "md": [10, 12, 13, 50, 65], "me": [8, 12, 19, 25, 33, 46, 49, 56, 65, 69, 70, 71], "mean": [5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 79, 80], "mean_absolute_error": 70, "mean_absolute_percentage_error": [21, 35, 48, 58], "mean_cv_error": [14, 27, 51], "mean_cv_scor": [15, 18, 19, 28, 31, 32, 33, 43, 45, 46, 52, 55, 56], "mean_fit_tim": [19, 21, 33, 35, 48, 56, 58], "mean_scor": [14, 16, 19, 27, 29, 33, 40, 51, 53, 56, 71], "mean_score_tim": [19, 21, 33, 35, 56, 58], "mean_squared_error": [21, 24, 35, 40, 48, 58, 61], "mean_std_cross_val_scor": [14, 16, 22, 23, 27, 29, 36, 37, 38, 39, 40, 51, 53, 54, 59, 60, 68, 71], "mean_test_neg_mean_squared_error": [21, 35, 58], "mean_test_scor": [19, 21, 33, 35, 48, 56, 58, 77], "mean_train_error": [14, 27, 51], "mean_train_neg_mean_squared_error": [21, 35, 58], "mean_train_scor": [15, 18, 19, 21, 28, 31, 32, 33, 35, 43, 45, 46, 48, 52, 55, 56, 58], "meaning": [11, 15, 17, 20, 23, 28, 30, 34, 37, 39, 43, 47, 52, 54, 57, 60, 62, 65, 76], "meaningless": 63, "measur": [0, 12, 13, 14, 15, 20, 21, 23, 24, 25, 26, 27, 28, 34, 35, 37, 39, 40, 47, 48, 49, 50, 51, 52, 57, 58, 60, 62, 63, 64, 65, 67, 68, 69, 70, 73, 75, 79], "meat": 44, "mechan": [17, 30, 54, 73], "mechanical_engin": 65, "medal": 8, "media": 69, "median": [13, 16, 18, 21, 23, 24, 26, 29, 32, 35, 37, 39, 40, 44, 48, 50, 53, 54, 55, 58, 60, 61, 67, 68, 69], "median_house_valu": [16, 24, 29, 40, 53, 54, 61, 76], "median_incom": [16, 24, 29, 40, 53, 54, 61, 76], "mediat": 69, "medic": [20, 34, 57, 62, 80], "medinc": [18, 32, 55], "medit": [20, 57, 70], "medium": [0, 15, 28, 44, 52, 68, 73], "meet": 65, "meier": 11, "melbourneairport": 67, "member": [18, 22, 32, 36, 38, 55, 59, 80], "membership": [17, 30, 54, 62, 63], "memori": [8, 16, 17, 20, 21, 22, 24, 29, 30, 34, 35, 36, 38, 40, 44, 53, 54, 57, 58, 59, 61, 66, 67, 68, 73], "men": 46, "mental": 69, "mention": [0, 4, 18, 32, 46, 55, 68, 69], "menu": [10, 70], "merchant": 0, "merg": [0, 5, 10, 63], "meshgrid": [24, 61], "mess": [46, 64, 68], "messag": [4, 6, 10, 14, 17, 27, 30, 44, 51, 54], "messi": [24, 40, 61, 65], "met": 80, "meta": [22, 36, 38, 59], "metacademi": 1, "metal": 46, "method": [2, 11, 13, 15, 16, 18, 20, 22, 23, 26, 28, 29, 31, 32, 34, 36, 37, 38, 39, 42, 43, 45, 46, 47, 50, 52, 53, 55, 57, 59, 60, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 79], "methodologi": [16, 29, 53, 67], "metric": [1, 11, 15, 17, 22, 23, 24, 28, 30, 36, 37, 38, 39, 40, 44, 52, 54, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 78, 79], "mexican": 44, "mexico": [20, 34, 57], "mglearn": [13, 14, 15, 16, 17, 18, 19, 20, 26, 27, 28, 29, 30, 31, 32, 33, 34, 43, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 62, 65, 66, 67, 72, 74, 75, 77, 78], "mi": [12, 20, 25, 33, 34, 47, 49, 56, 57, 69], "microsoft": 71, "middl": [31, 45, 46], "midnight": 67, "midterm": [1, 6, 12, 18, 25], "might": [1, 6, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 69, 70, 71, 73, 75, 80], "mightn": 65, "miguel": 70, "mike": [0, 1, 9, 26, 50, 70, 77], "mikolov": 65, "milk": 65, "mill": [22, 36, 38, 59], "millennia": 80, "million": 66, "min": [1, 18, 21, 29, 32, 34, 35, 42, 44, 48, 55, 58, 63, 67], "min1": [21, 23, 35, 37, 39, 48, 58, 60, 69], "min2": [21, 23, 35, 37, 39, 48, 58, 60, 69], "min_child_weight": [22, 36, 38, 59], "min_df": [17, 30, 54], "min_impurity_decreas": 69, "min_impurity_split": 69, "min_sampl": 63, "min_samples_leaf": [13, 26, 50, 69], "min_samples_split": [13, 26, 50, 69], "min_token_len": 65, "min_token_length": 65, "min_weight_fraction_leaf": 69, "mind": [14, 16, 17, 22, 23, 27, 29, 36, 37, 38, 39, 51, 53, 54, 59, 60, 64, 68, 69, 70, 73, 80], "mine": 1, "minibatchkmean": 63, "miniconda": 10, "miniconda3": [10, 17, 71], "miniforge3": [50, 51, 54, 56, 60, 68, 72], "minim": [5, 13, 21, 26, 35, 40, 50, 58, 62, 63, 69], "minimum": [8, 14, 16, 27, 29, 46, 51, 53, 63, 65], "minmaxscal": [16, 17, 29, 30, 44, 53, 54, 69], "minor": [6, 68], "mintemp": 67, "minut": [4, 12, 13, 24, 25, 26, 40, 46, 50, 61, 68, 73], "miracl": 71, "miscalcul": 1, "miscfeatur": [21, 23, 35, 37, 39, 58, 60, 69], "miscfeature_gar2": [21, 35, 58], "miscfeature_miss": [21, 35, 58], "miscfeature_othr": [21, 35, 58], "miscfeature_sh": [21, 35, 58], "miscfeature_tenc": [21, 35, 58], "misclassifi": 78, "misconduct": 80, "miscval": [21, 23, 35, 37, 39, 48, 58, 60, 69], "mishaal": [1, 80], "mislead": [14, 20, 27, 34, 47, 51, 57], "miss": [10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 44, 47, 48, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 67, 68, 69, 73, 75, 77, 78, 80], "mist": 46, "mistak": [16, 22, 29, 36, 38, 53, 59, 68, 69, 75], "mit": [0, 1], "mitig": [11, 64], "mitlp": 68, "mitt": 65, "mitten": 65, "mix": [12, 21, 25, 35, 48, 58, 69, 70], "mixtur": [63, 65, 66], "ml": [1, 2, 9, 11, 13, 16, 22, 26, 29, 33, 36, 38, 40, 50, 53, 59, 63, 65, 66, 70], "ml_experi": [13, 14, 17, 26, 27, 30, 50, 51, 54, 73], "mlpclassifi": 66, "mlpregressor": 66, "mm": 67, "mmsto": [12, 25, 49], "mn": [21, 23, 35, 37, 39, 48, 58, 60, 69], "mnprv": [21, 23, 35, 37, 39, 48, 58, 60, 69], "mnww": [21, 23, 35, 37, 39, 48, 58, 60, 69], "mo": 65, "mobil": [17, 30, 54, 66], "mobilenet": 66, "mod": [21, 23, 35, 37, 39, 48, 58, 60, 69], "mode": [15, 16, 19, 29, 33, 39, 52, 53, 56, 77], "model": [1, 2, 11, 19, 20, 28, 33, 34, 56, 57, 62, 63, 64, 67, 69, 72, 74, 77], "model_nam": 64, "model_select": [12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 64, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79], "modern": [1, 15, 28, 52, 65, 69], "modif": 68, "modifi": [0, 10, 20, 57, 68, 70, 80], "modul": [9, 14, 20, 26, 27, 34, 43, 44, 50, 51, 57, 71], "moe": [19, 33, 56], "mole": 66, "mom": [24, 40, 61], "moment": [20, 57, 77, 79, 80], "moment_predictor": 70, "mon": 67, "monarch": 65, "monarchi": 65, "mondai": [1, 18, 67, 80], "mone": 46, "monei": [8, 46, 68], "monitor": 65, "monkei": [12, 25, 49, 66], "monotone_constraint": [22, 36, 38, 59], "montani": 71, "month": [14, 17, 21, 30, 35, 48, 51, 54, 58, 68], "month_nam": [42, 67], "monthli": 68, "monthlycharg": 68, "montreal": [65, 71], "moon": 63, "moosvi": [0, 1, 65], "moral": [0, 62], "more": [1, 2, 5, 6, 7, 8, 10, 12, 14, 19, 22, 23, 25, 33, 36, 37, 38, 39, 43, 44, 46, 51, 56, 59, 60, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80], "morn": [12, 25, 49], "morpholog": 65, "morri": 46, "morton": 46, "moskowitz": 62, "mosold": [21, 23, 35, 37, 39, 48, 58, 60, 69], "mosold_1": [21, 35, 58], "mosold_10": [21, 35, 58], "mosold_11": [21, 35, 58], "mosold_12": [21, 35, 58], "mosold_2": [21, 35, 58], "mosold_3": [21, 35, 58], "mosold_4": [21, 35, 58], "mosold_5": [21, 35, 58], "mosold_6": [21, 35, 58], "mosold_7": [21, 35, 58], "mosold_8": [21, 35, 58], "mosold_9": [21, 35, 58], "most": [7, 8, 10, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 48, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 79, 80], "most_confident_i": [18, 32, 55], "most_confident_x": [18, 32, 55], "most_frequ": [13, 15, 16, 20, 21, 23, 26, 28, 29, 34, 35, 37, 39, 44, 47, 48, 50, 52, 53, 57, 58, 60, 69, 74], "most_neg": 31, "most_negative_id": [45, 46], "most_posit": 31, "most_positive_id": [45, 46], "most_similar": 65, "mostli": [8, 17, 30, 54, 67], "motiv": [12, 17, 25, 30, 49, 54], "mountginini": 67, "move": [7, 18, 23, 24, 31, 32, 37, 39, 40, 45, 46, 55, 60, 61, 74, 79, 80], "movi": [18, 31, 32, 45, 46, 55, 65, 71], "movie_feats_df": 64, "movie_id": 64, "movie_nam": 64, "movies_rated_by_pat": 64, "movies_to_pr": 64, "movieto": 71, "mpimg": 66, "mr": 46, "mri": 73, "mrtssm448usn": 67, "mse": [13, 26, 50, 64, 70, 73], "msg": [17, 30, 54, 68], "msg_dtype": 44, "msg_err": 44, "mssubclass": [21, 23, 35, 37, 39, 48, 58, 60, 69], "mssubclass_120": [21, 35, 39, 58], "mssubclass_160": [21, 35, 39, 58], "mssubclass_180": [21, 35, 39, 58], "mssubclass_190": [21, 35, 39, 58], "mssubclass_20": [21, 35, 58], "mssubclass_30": [21, 35, 58], "mssubclass_40": [21, 35, 58], "mssubclass_45": [21, 35, 58], "mssubclass_50": [21, 35, 58], "mssubclass_60": [21, 35, 58], "mssubclass_70": [21, 35, 58], "mssubclass_75": [21, 35, 58], "mssubclass_80": [21, 35, 58], "mssubclass_85": [21, 35, 39, 58], "mssubclass_90": [21, 35, 39, 58], "mszone": [21, 23, 35, 37, 39, 58, 60, 69], "mszoning_c": [21, 23, 35, 39, 58, 60], "mszoning_fv": [21, 35, 58], "mszoning_rh": [21, 35, 58], "mszoning_rl": [21, 35, 58], "mszoning_rm": [21, 35, 58], "mt1": [38, 40], "much": [4, 5, 8, 13, 14, 15, 16, 17, 20, 22, 23, 26, 27, 28, 29, 30, 34, 36, 37, 38, 39, 40, 46, 47, 50, 51, 52, 53, 54, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 75, 77, 80], "mueller": 1, "multi": [21, 23, 34, 35, 37, 39, 48, 58, 60, 62, 65, 67, 70], "multi_class": [20, 34, 57, 72], "multi_output": 44, "multi_strategi": [22, 36, 38, 59], "multiclass": [66, 70, 72], "multicoliniar": [23, 37, 39, 60], "multicultur": 65, "multilevel": [21, 35, 48, 58], "multimod": 62, "multinomi": 72, "multipl": [7, 8, 14, 18, 19, 22, 23, 27, 32, 33, 36, 38, 42, 51, 55, 56, 59, 60, 65, 66, 67, 68], "multiplelin": 68, "multiplelines_no": 68, "multiplelines_y": 68, "multipli": [18, 19, 20, 22, 24, 32, 33, 36, 38, 40, 48, 55, 56, 57, 59, 61, 68], "murder": 46, "music": [44, 46, 64, 71], "musqueam": 80, "must": [0, 6, 7, 8, 12, 13, 14, 16, 23, 25, 26, 29, 36, 37, 39, 46, 50, 51, 53, 60, 63, 65, 68], "mustn": 65, "mutual": 63, "my": [6, 10, 12, 20, 25, 33, 34, 46, 49, 56, 57, 62, 65, 69, 70, 71, 80], "my_heatmap": [19, 33, 56, 77], "my_map": [21, 35, 48, 58], "mypreprocessor": 65, "myself": [50, 65, 69], "m\u00fcller": 9, "n": [1, 13, 15, 18, 19, 21, 22, 23, 24, 26, 28, 31, 32, 33, 35, 36, 37, 39, 40, 43, 44, 45, 46, 48, 50, 52, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 69, 71, 72, 75], "n_bin": [24, 40, 61], "n_class": [15, 20, 28, 34, 52, 57, 78], "n_cluster": [62, 63], "n_clusters_per_class": [20, 57], "n_compon": 65, "n_constitu": [22, 36, 38, 59], "n_estim": [24, 40, 61, 67, 68, 69], "n_estimators_valu": 69, "n_exampl": 62, "n_feat": [15, 28, 52], "n_featur": [15, 20, 28, 52, 57, 62, 77], "n_features_to_select": [24, 40, 61], "n_imag": 43, "n_inform": [20, 57], "n_init": 62, "n_iter": 77, "n_job": [17, 20, 21, 22, 30, 34, 35, 36, 38, 48, 54, 57, 58, 59, 69, 77], "n_neighbor": [43, 64, 75], "n_neighbors_selector": [15, 28, 52], "n_neighbors_widget": [15, 28, 43, 52, 75], "n_peopl": 44, "n_redund": [20, 57], "n_rental": 67, "n_rentalsin3hour": 67, "n_rentalsin6hour": 67, "n_repeat": [23, 37, 39, 60], "n_resourc": [19, 33, 56], "n_sampl": [15, 20, 28, 34, 52, 57, 62, 63, 66, 72, 78], "n_split": 67, "n_threshold": [20, 47, 57], "n_top_feat": [45, 46], "n_top_featur": [31, 45, 46], "n_topic": 65, "n_train": 67, "n_word": [65, 71], "na": [21, 23, 35, 37, 39, 48, 58, 60, 69], "nafter": 65, "nah": [17, 30, 54], "naiv": 63, "name": [1, 4, 5, 6, 7, 8, 10, 13, 15, 16, 17, 19, 20, 22, 23, 24, 26, 28, 29, 30, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 50, 52, 53, 54, 56, 57, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 75, 79, 80], "named_estimators_": [22, 36, 38, 59], "named_step": [18, 20, 21, 22, 23, 24, 31, 32, 34, 35, 36, 37, 38, 39, 40, 45, 46, 48, 55, 57, 58, 59, 60, 61, 67, 69, 71], "named_transformers_": [17, 20, 21, 22, 23, 24, 30, 34, 35, 36, 37, 38, 39, 40, 44, 48, 54, 57, 58, 59, 60, 61, 67, 68, 69, 71, 78], "namespac": 44, "nan": [16, 17, 20, 21, 22, 23, 24, 29, 30, 34, 35, 36, 37, 38, 39, 44, 53, 54, 57, 58, 59, 60, 61, 64, 67, 68, 69, 71, 73, 78], "nanmean": 64, "nanosecond": 67, "narr": 65, "narrat": 46, "narrow": [12, 25, 64, 69], "nasali": [12, 25, 49, 66], "nation": 80, "nativ": [20, 22, 23, 34, 36, 37, 38, 39, 44, 57, 59, 60, 66, 72, 78], "natur": [2, 11, 12, 17, 20, 22, 24, 30, 36, 40, 44, 49, 54, 57, 59, 61, 66, 70, 72], "navig": [7, 10, 70], "nbsp": [12, 25, 49, 53, 54, 56, 58, 59, 60, 61, 66, 69, 71], "nbviewer": [12, 16, 17, 19, 20, 21, 22, 23, 24, 25, 29, 30, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 49, 53, 54, 56, 57, 58, 59, 60, 61, 66, 69, 71], "nc": 1, "ncol": [18, 32, 55], "ndarrai": [8, 17, 30, 44, 54], "ndate": 71, "ndframe": [24, 61, 68], "ndim": [8, 44], "ne": 67, "nearbi": [15, 28, 52, 62], "nearest": [20, 43, 44, 57, 63, 75], "nearestneighbor": 43, "nearestneighborsifittednearestneighbor": 43, "nearli": [42, 46], "necessari": [0, 7, 13, 19, 32, 33, 44, 50, 56, 73, 76], "necessarili": [14, 21, 22, 27, 35, 36, 38, 51, 58, 59, 64, 70], "neck": 46, "necvq": 68, "need": [5, 7, 8, 10, 12, 13, 15, 17, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 76, 77, 79, 80], "needn": 65, "neg": [13, 14, 15, 18, 21, 22, 23, 26, 27, 28, 32, 35, 36, 37, 38, 39, 48, 50, 51, 52, 55, 58, 59, 60, 65, 67, 68, 71, 75, 78], "neg_mean_absolute_percentage_error": [21, 35, 48, 58], "neg_mean_squared_error": [21, 35, 48, 58, 69], "neg_prob": [31, 45, 46], "neg_root_mean_square_error": [21, 35, 48, 58], "neg_root_mean_squared_error": [21, 35, 48, 58], "neigh": [15, 28, 43, 52], "neighbor": [15, 16, 17, 18, 20, 24, 28, 29, 30, 32, 40, 43, 44, 52, 53, 54, 55, 57, 61, 63, 75, 76], "neighborhood": [18, 21, 23, 32, 35, 37, 39, 55, 58, 60, 69], "neighborhood_blmngtn": [21, 35, 58], "neighborhood_bluest": [21, 35, 58], "neighborhood_brdal": [21, 35, 58], "neighborhood_brksid": [21, 35, 58], "neighborhood_clearcr": [21, 35, 58], "neighborhood_collgcr": [21, 35, 58], "neighborhood_crawfor": [21, 35, 58], "neighborhood_edward": [21, 35, 58], "neighborhood_gilbert": [21, 35, 58], "neighborhood_idotrr": [21, 35, 58], "neighborhood_meadowv": [21, 35, 58], "neighborhood_mitchel": [21, 35, 58], "neighborhood_nam": [21, 35, 58], "neighborhood_noridg": [21, 35, 58, 60], "neighborhood_npkvil": [21, 35, 58], "neighborhood_nridght": [21, 23, 35, 39, 58, 60], "neighborhood_nwam": [21, 35, 58], "neighborhood_oldtown": [21, 35, 58, 60], "neighborhood_sawy": [21, 35, 58, 60], "neighborhood_sawyerw": [21, 35, 58, 60], "neighborhood_somerst": [21, 35, 58, 60], "neighborhood_stonebr": [21, 23, 35, 39, 58, 60], "neighborhood_swisu": [21, 35, 58, 60], "neighborhood_timb": [21, 35, 58, 60], "neighborhood_veenk": [21, 35, 58, 60], "neighborsbas": 44, "neighbour": [14, 39, 43, 51, 60, 62, 63, 65, 75], "neighbourhood": [18, 24, 32, 40, 55, 61, 63, 76], "neither": [14, 17, 27, 30, 51, 54, 64], "neo": [1, 80], "neq": [23, 37, 39, 60, 64], "ner": 65, "nervou": [13, 26, 50], "nest": [19, 33, 56, 73], "net": [40, 66, 68], "netflix": [38, 64, 71], "netherland": 39, "network": [1, 11, 12, 17, 22, 24, 25, 30, 36, 38, 40, 49, 54, 59, 61, 62, 64, 65, 67, 70], "neu": 71, "neural": [1, 11, 24, 40, 61, 67], "neutral": 71, "never": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 64, 66, 68], "nevertheless": 80, "new": [1, 10, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 73, 76, 77, 79], "new_cent": 62, "new_column": [21, 23, 35, 37, 39, 48, 58, 60, 67, 68, 69], "new_data": 68, "new_df": 67, "new_exampl": [13, 26, 50, 62], "new_feature_nam": 67, "new_valu": 68, "newaxi": 8, "newcastl": 71, "newer": [21, 35, 48, 58], "newli": [16, 21, 24, 29, 35, 40, 53, 58, 61, 63], "newsgroup": 65, "newswir": 65, "next": [1, 10, 13, 14, 15, 16, 18, 20, 21, 22, 26, 28, 29, 33, 34, 35, 36, 38, 43, 44, 47, 50, 51, 52, 53, 54, 57, 58, 59, 65, 66, 67, 69, 76, 77, 78, 79, 80], "nfeat": [15, 28, 52], "nfeats_accuraci": [15, 28, 52], "ng": [1, 9, 19, 24, 33, 40, 56, 61], "ngram": [24, 40, 61], "ngram_rang": [17, 30, 54], "nhl": 65, "nhqxu": 68, "nice": [4, 12, 19, 20, 22, 23, 25, 34, 36, 37, 38, 39, 46, 47, 48, 56, 57, 59, 60, 63, 66, 68, 69, 70], "nicki": [33, 56], "night": [20, 57, 67, 70], "nightmar": 69, "niki": [1, 80], "nlemma": 65, "nlp": [17, 30, 54, 66, 71], "nltk": [65, 71], "nltk_data": [65, 71], "nmax": 69, "nn": [1, 16, 29, 31, 43, 45, 46, 53, 66, 75], "nne": 67, "nnw": 67, "nnz": [17, 30, 54], "no_grad": [43, 66], "no_val_x": 44, "nobodi": [12, 49], "node": [13, 22, 26, 36, 38, 50, 59, 63, 66, 74], "nois": [63, 73, 75], "noise_cat": 44, "noise_level": 44, "non": [1, 8, 12, 13, 14, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 32, 33, 34, 35, 36, 37, 38, 40, 47, 49, 50, 51, 53, 55, 56, 57, 58, 59, 61, 63, 64, 66, 67, 68, 70, 73, 78, 80], "noncommerci": 1, "none": [1, 14, 16, 17, 18, 19, 20, 22, 24, 27, 29, 30, 32, 33, 34, 36, 38, 40, 44, 46, 51, 53, 54, 55, 56, 57, 59, 61, 63, 67, 68, 69, 79], "noninfring": 0, "nonzero": [17, 30, 54], "noodl": 44, "noqa": [19, 33, 56], "nor": [7, 14, 17, 27, 30, 51, 54, 65], "norg": [65, 71], "norm": [19, 33, 40, 44, 56, 65], "normal": [6, 20, 21, 22, 23, 29, 34, 35, 36, 37, 38, 39, 43, 44, 47, 48, 57, 58, 59, 60, 62, 63, 65, 66, 67, 69, 71, 78, 79], "north": 65, "north_america": 44, "norvig": 1, "notat": [15, 52], "note": [0, 1, 3, 7, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 47, 48, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 64, 70, 72, 73, 77, 78, 80], "notebook": [5, 7, 9, 10, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 27, 29, 30, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 66, 69, 71, 76], "noth": 46, "notic": [0, 17, 18, 20, 21, 24, 30, 32, 34, 35, 40, 44, 46, 48, 54, 55, 57, 58, 61], "notion": [15, 19, 28, 33, 52, 56, 62, 64], "notna": 67, "noun": [65, 71], "nov": 67, "novel": 73, "novemb": 67, "novic": 9, "now": [8, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 74, 75, 76, 77, 78, 79], "np": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 73, 74, 75, 76, 77, 78, 79], "nperson": 71, "npie": 8, "npo": 65, "npr": [24, 40, 61, 65, 73], "npt": 44, "nsubj": 65, "ntest": [15, 19, 28, 33, 43, 52, 56, 75], "ntoken": 65, "ntree": [22, 36, 59], "null": [16, 17, 20, 21, 24, 29, 30, 34, 35, 40, 53, 54, 57, 58, 61, 67, 68], "null_distribut": 68, "num": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "num_output_channel": 66, "num_parallel_tre": [22, 36, 38, 59], "num_sent": [20, 57, 70], "num_work": [43, 66], "number": [1, 4, 6, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 39, 40, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 66, 68, 70, 73, 75, 77, 80], "number_test": [19, 33, 56], "numberbatch": 65, "numer": [2, 13, 16, 17, 18, 20, 21, 22, 26, 29, 30, 32, 34, 35, 36, 38, 43, 44, 47, 48, 50, 53, 54, 55, 57, 58, 59, 64, 65, 67, 68, 69, 75, 76, 78], "numeric_feat": [17, 19, 24, 30, 33, 40, 44, 54, 56, 61, 73, 77], "numeric_featur": [20, 21, 22, 23, 34, 35, 36, 37, 38, 39, 48, 54, 57, 58, 59, 60, 67, 68, 69, 71, 78, 79], "numeric_looking_column": [21, 35, 48, 58], "numeric_transform": [20, 21, 22, 23, 34, 35, 36, 37, 38, 39, 44, 48, 54, 57, 58, 59, 60, 67, 69, 78, 79], "numpi": [9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 76, 77, 78, 79], "numpy_dtyp": 68, "nuniqu": 42, "nutrit": 65, "nw": 67, "nwith": [15, 28, 52], "ny": 71, "nyre": 46, "nyt": 69, "o": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79], "obelisk": 66, "object": [14, 16, 17, 18, 19, 20, 21, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 37, 40, 42, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 71, 73, 74, 75, 77, 78], "observ": [12, 13, 14, 15, 22, 23, 25, 26, 27, 28, 36, 37, 38, 39, 40, 43, 49, 50, 51, 52, 59, 60, 62, 63, 67, 68, 75, 78, 79], "obtain": [0, 18, 31, 32, 43, 45, 46, 55, 62, 63, 64, 68, 75, 77], "obviou": [63, 65], "obvious": 46, "occasion": [20, 34, 47, 57], "occup": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "occupation_arm": 39, "occupation_farm": [23, 37, 39, 60], "occupation_miss": [23, 37, 39, 60], "occupation_priv": [23, 37, 39, 60], "occupi": 80, "occur": [8, 13, 14, 17, 26, 27, 30, 50, 51, 54, 65, 68], "occurr": [65, 68], "ocean": [16, 24, 29, 40, 53, 54, 61, 76], "ocean_proxim": [16, 24, 29, 40, 53, 54, 61, 76], "ocean_proximity_": [16, 29, 53, 54], "ocean_proximity_inland": [16, 29, 53, 54], "ocean_proximity_island": [16, 29, 53, 54], "ocean_proximity_near": [16, 29, 53, 54], "oct": 55, "octob": [42, 67], "oe": [17, 30, 54, 73], "oe_encod": 73, "off": [11, 18, 19, 20, 21, 24, 32, 33, 34, 35, 40, 43, 46, 47, 48, 55, 56, 57, 58, 61, 62, 65, 66, 68, 69, 73, 77], "off_shelf": 79, "offens": 4, "offer": [8, 22, 36, 38, 46, 59, 64, 65, 68, 80], "offic": [1, 4, 10, 12, 73, 80], "offici": [65, 80], "offlin": 64, "offset": [18, 32, 55], "often": [8, 12, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 47, 49, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 75], "ogunrind": [12, 25, 49], "oh": [23, 24, 37, 39, 40, 44, 60, 61, 66, 67, 68, 70, 73, 77, 80], "ohe_column": [21, 23, 35, 37, 39, 48, 58, 60, 69], "ohe_enc": [17, 30, 54], "ohe_encod": 73, "ohe_feat": 44, "ohe_feat_nam": 44, "ohe_feature_nam": [23, 37, 39, 60, 67], "ohehotencod": [17, 30, 54], "ois": 63, "ok": [12, 15, 21, 25, 28, 35, 46, 48, 49, 52, 58, 67, 68, 70, 73], "okai": [62, 70], "ola": 65, "old": [9, 22, 38, 39, 46, 59, 60], "old_cent": 62, "older": [21, 35, 48, 58], "oldpeak": 79, "olymp": 8, "omit": [23, 37, 39, 60], "omw": 65, "onc": [6, 7, 8, 10, 13, 14, 16, 17, 19, 24, 26, 27, 29, 30, 33, 40, 43, 50, 51, 53, 54, 56, 61, 63, 64, 65, 66, 70, 77, 78, 79, 80], "onca": [12, 25, 49, 66], "one": [6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 77, 78, 79, 80], "one_c": [15, 28, 52], "one_ex_preprocess": [23, 37, 39, 60], "one_ex_preprocessed_perturb": [23, 37, 39, 60], "one_exampl": [23, 37, 39, 60], "one_example_perturb": [23, 37, 39, 60], "onehot": [17, 24, 30, 40, 54, 61], "onehotencod": [16, 18, 19, 20, 21, 22, 23, 24, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 48, 53, 55, 56, 57, 58, 59, 60, 61, 67, 68, 69, 73, 76, 77, 78, 79], "onehotencoder__major_biologi": [17, 30, 54], "onehotencoder__major_comput": [17, 30, 54], "onehotencoder__major_econom": [17, 30, 54], "onehotencoder__major_linguist": [17, 30, 54], "onehotencoder__major_mathemat": [17, 30, 54], "onehotencoder__major_mechan": [17, 30, 54], "onehotencoder__major_phys": [17, 30, 54], "onehotencoder__major_psychologi": [17, 30, 54], "onehotencoderonehotencod": [17, 19, 21, 22, 30, 33, 35, 36, 38, 44, 54, 56, 58, 59, 69], "ones": [8, 12, 15, 16, 22, 23, 25, 28, 29, 36, 37, 38, 39, 42, 43, 49, 52, 53, 59, 60, 62, 64, 65, 75, 79], "onevsoneclassifi": 72, "onevsrestclassifi": 72, "onli": [2, 4, 8, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 73, 75, 76, 78, 80], "onlin": [3, 5, 7, 10, 26, 50, 65, 80], "onlinebackup": 68, "onlinebackup_no": 68, "onlinebackup_y": 68, "onlinesecur": 68, "onlinesecurity_no": 68, "onlinesecurity_y": 68, "onrend": 70, "ontario": 65, "ontonot": 65, "oob_scor": 69, "op": [20, 34, 57], "open": [5, 6, 10, 12, 25, 40, 49, 66, 70, 80], "openporchsf": [21, 23, 35, 37, 39, 48, 58, 60, 69], "oper": [4, 8, 10, 17, 24, 30, 54, 61, 65, 70], "opera": 46, "operand": 8, "opinion": [22, 36, 38, 59], "opportun": [42, 64], "oppos": [21, 22, 35, 36, 38, 48, 58, 59], "opposit": [8, 21, 22, 23, 35, 36, 37, 39, 48, 58, 59, 60], "opt": [10, 22, 36, 43, 44, 59], "optic": 68, "optim": [1, 2, 13, 14, 15, 20, 22, 23, 24, 26, 27, 28, 31, 34, 36, 37, 38, 39, 40, 43, 45, 46, 47, 50, 51, 52, 54, 57, 59, 60, 61, 62, 63, 66, 68, 69, 70, 77], "optimist": [19, 33, 56], "optimized_c": [31, 45, 46], "option": [1, 7, 8, 13, 21, 25, 26, 35, 36, 50, 58, 62, 65, 69, 77, 79], "orang": [18, 32, 55], "orch": 80, "order": [5, 7, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 69, 70, 73], "ordering_ordinal_oth": [21, 23, 35, 37, 39, 48, 58, 60, 69], "ordering_ordinal_reg": [21, 23, 35, 37, 39, 48, 58, 60, 69], "ordin": [21, 35, 48, 58, 73, 76], "ordinal_feat": [17, 30, 44, 54], "ordinal_featur": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "ordinal_features_oth": [21, 23, 35, 37, 39, 48, 58, 60, 69], "ordinal_features_reg": [21, 23, 35, 37, 39, 48, 58, 60, 69], "ordinal_transform": [20, 22, 23, 34, 36, 37, 38, 39, 44, 57, 59, 60, 78], "ordinal_transformer_oth": [21, 23, 35, 37, 39, 48, 58, 60, 69], "ordinal_transformer_reg": [21, 23, 35, 37, 39, 48, 58, 60, 69], "ordinalencod": [16, 17, 20, 21, 22, 23, 24, 29, 30, 34, 35, 36, 37, 38, 39, 40, 44, 48, 53, 54, 57, 58, 59, 60, 61, 67, 68, 69, 73, 76, 78, 79], "ordinalencoderordinalencod": [17, 21, 22, 30, 35, 36, 38, 44, 54, 58, 59, 69], "ordinari": [21, 35, 58], "oreilli": [66, 67], "org": [9, 12, 14, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 49, 51, 53, 54, 56, 57, 58, 59, 60, 61, 65, 66, 69, 71], "organ": [12, 13, 16, 25, 26, 29, 49, 50, 53, 65, 69, 70], "orgin": 8, "orig_featur": 67, "orig_pr": [23, 37, 39, 60], "orig_scor": [20, 34, 57], "origin": [12, 16, 17, 20, 22, 23, 24, 25, 29, 30, 34, 36, 37, 38, 39, 40, 53, 54, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 71, 75, 77, 80], "original_hm": [20, 57, 70], "originaltweet": 71, "ornithorhynchu": 66, "oscar": [18, 32, 55], "ostblom": 65, "other": [0, 1, 4, 5, 6, 7, 10, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 29, 30, 32, 33, 34, 36, 37, 38, 39, 42, 43, 44, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 59, 60, 63, 64, 66, 70, 71, 72, 73, 75, 77, 78, 79, 80], "otherwis": [0, 7, 17, 30, 54], "ounc": [12, 25, 49, 66], "our": [5, 6, 8, 10, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 73, 74, 75, 77, 78, 79, 80], "ourselv": [13, 20, 26, 34, 47, 50, 57, 65, 66, 67], "out": [0, 1, 4, 7, 8, 10, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 33, 34, 35, 36, 37, 38, 39, 42, 44, 46, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 67, 68, 71, 73, 75, 77, 79, 80], "out_col": [14, 16, 27, 29, 40, 51, 53, 71], "out_step": [20, 57], "outer": 71, "outlier": [21, 35, 44, 48, 58, 63, 70, 73], "outlook": 68, "output": [7, 8, 10, 12, 13, 14, 17, 18, 20, 22, 23, 25, 26, 27, 30, 32, 34, 36, 37, 38, 39, 44, 47, 49, 50, 51, 54, 55, 57, 59, 60, 65, 66, 67, 69, 70, 73, 79, 80], "outsid": [7, 20, 22, 23, 34, 36, 37, 38, 39, 47, 57, 59, 60, 64, 65, 67, 68], "over": [14, 19, 21, 33, 34, 35, 48, 51, 56, 58, 65, 66, 67, 68, 69, 70, 73, 80], "over_confident_i": [18, 32, 55], "over_confident_x": [18, 32, 55], "over_sampl": [20, 57], "overal": [10, 20, 23, 31, 34, 37, 39, 44, 45, 46, 57, 60, 62, 65, 66, 69, 73, 78, 79, 80], "overallcond": [21, 23, 35, 37, 39, 48, 58, 60, 69], "overallqu": [21, 23, 35, 37, 39, 48, 58, 60, 69], "overconfid": [23, 24, 37, 39, 40, 60, 61, 70], "overcrowd": 80, "overfit": [1, 11, 15, 18, 21, 22, 24, 28, 31, 32, 35, 36, 38, 40, 42, 43, 45, 46, 48, 52, 55, 58, 59, 61, 66, 70, 75, 77, 79], "overflow": 7, "overhead": [17, 30, 54], "overlap": [2, 14, 27, 32, 51, 62, 70], "overli": [15, 19, 28, 33, 43, 52, 56, 75], "overload": [64, 68], "overpredict": [21, 35, 58], "oversampl": 34, "oversample_pip": [20, 57], "overshadow": 65, "overst": 69, "overus": [22, 36, 38, 59], "overview": [62, 63, 64, 65], "overwhelm": 62, "overzeal": 6, "own": [4, 5, 8, 12, 14, 16, 20, 21, 23, 24, 25, 29, 34, 35, 37, 39, 40, 46, 47, 51, 53, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72], "oz": 46, "p": [18, 19, 32, 33, 46, 55, 56, 63, 65, 68, 70], "p_i": 62, "p_value_threshold": 68, "pace": [18, 32, 46, 55, 62, 65, 80], "packag": [5, 8, 11, 17, 19, 20, 23, 26, 30, 33, 34, 37, 39, 43, 44, 47, 50, 51, 54, 56, 57, 60, 62, 63, 64, 65, 66, 68, 70, 71, 72], "pad": [43, 66], "page": [1, 4, 7, 12, 16, 17, 19, 20, 21, 22, 23, 24, 25, 29, 30, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 49, 53, 54, 56, 57, 58, 59, 60, 61, 65, 66, 69, 71, 79, 80], "pai": [23, 37, 39, 60, 70], "pain": [4, 66, 67, 69], "pair": [63, 65, 72], "pairwis": [15, 28, 52, 63], "panda": [9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79], "pandas_profil": 48, "pane": [15, 28, 43, 52, 75], "panel": [15, 20, 23, 28, 34, 37, 39, 43, 47, 52, 57, 60, 62, 63, 75], "panic": 71, "panther": [12, 25, 49, 66], "panthera": [12, 25, 49, 66], "paper": [7, 23, 24, 37, 39, 40, 60, 61, 65, 66, 68, 70, 71], "paperlessbil": 68, "paperlessbilling_no": 68, "paperlessbilling_y": 68, "paradigm": [12, 13, 25, 26, 49, 50, 62, 65], "paradox": 64, "paragraph": 65, "paraleg": 65, "parallel": [17, 19, 22, 30, 33, 36, 38, 54, 56, 59], "param": [15, 17, 19, 21, 28, 30, 33, 35, 43, 52, 54, 56, 58, 75], "param_columntransformer__countvectorizer__max_featur": [19, 33, 56], "param_columntransformer__pipeline__polynomialfeatures__degre": 19, "param_dist": [19, 33, 56, 77], "param_distribut": [19, 33, 56, 77], "param_grid": [14, 15, 19, 21, 27, 28, 33, 35, 48, 51, 52, 56, 58, 69, 77], "param_grid1": [19, 33, 56, 77], "param_grid2": [19, 33, 56, 77], "param_grid3": [19, 33, 56], "param_grid4": [19, 33, 56], "param_ridge__alpha": [21, 35, 48, 58], "param_svc__c": [19, 33, 56], "param_svc__gamma": [19, 33, 56], "param_svc__kernel": 19, "paramet": [15, 16, 17, 21, 22, 28, 29, 30, 36, 38, 39, 40, 43, 44, 52, 53, 54, 58, 59, 60, 62, 63, 65, 67, 68, 69, 71, 74, 75, 77, 78, 79], "parametr": 63, "params_": 68, "params_str": [19, 33, 56], "paramter": [15, 28, 52], "pardu": [12, 25, 49, 66], "parent": [46, 63], "park": [24, 40, 61, 66, 70, 71], "pars": 65, "parse_d": [8, 67], "parser": 65, "part": [1, 4, 9, 10, 16, 17, 18, 19, 20, 22, 23, 24, 29, 32, 33, 34, 36, 37, 38, 39, 40, 46, 47, 53, 54, 55, 56, 57, 59, 60, 61, 63, 65, 67, 69, 70, 71, 79, 80], "part1": 64, "part2": 64, "parti": 65, "partial": [4, 68, 69], "particip": 80, "particular": [0, 9, 10, 16, 17, 19, 20, 22, 23, 24, 29, 30, 33, 34, 36, 37, 38, 39, 40, 53, 54, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 75, 78], "particularli": [22, 36, 38, 46, 59, 64, 80], "partit": [17, 30, 54, 62, 63], "partner": [68, 80], "partner_no": 68, "partner_y": 68, "parton": 71, "pass": [8, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 40, 43, 44, 47, 48, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 65, 66, 75, 80], "passthrough": [17, 19, 30, 33, 54, 56, 68, 71, 77, 79], "passthrough__ml_experi": [17, 30, 54], "passthrough_feat": [17, 19, 30, 33, 54, 56, 73, 77], "passthrough_featur": [68, 71, 79], "passthroughpassthrough": [17, 19, 30, 33, 54, 56, 71], "past": [13, 14, 26, 27, 36, 38, 50, 51, 59, 67, 68, 69, 73], "pat": 64, "pat_i": 64, "pat_model": 64, "pat_x": 64, "pata": [12, 25, 49, 66], "path": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79], "patial": 63, "patient": [13, 26, 50, 70, 79], "patio": 66, "patric": [23, 37, 39, 60], "patricia": 46, "patrick": [1, 80], "pattern": [12, 13, 14, 17, 19, 24, 25, 26, 27, 30, 33, 40, 42, 49, 50, 51, 54, 56, 61, 62, 65, 67, 69, 75], "paus": 46, "pav_bhaji": 65, "pave": [21, 23, 35, 37, 39, 58, 60, 69], "paveddr": [21, 23, 35, 37, 39, 58, 60, 69], "paveddrive_i": [21, 35, 58], "paveddrive_n": [21, 35, 58], "paveddrive_p": [21, 35, 58], "paymentmethod": 68, "paymentmethod_bank": 68, "paymentmethod_credit": 68, "paymentmethod_electron": 68, "paymentmethod_mail": 68, "pca": [20, 34, 47, 57, 63, 64], "pcarter": 9, "pd": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79], "pdf": [7, 9], "peac": 65, "peck": 46, "pedest": 66, "pedro": [1, 14, 24, 40, 51, 61], "peer": [70, 73, 80], "pembrok": [12, 25, 49, 66], "penal": [6, 68], "penalti": [20, 34, 57, 65, 80], "peopl": [4, 13, 14, 16, 18, 20, 26, 27, 29, 32, 34, 36, 38, 46, 50, 51, 53, 55, 57, 59, 62, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 78, 80], "per": [8, 18, 20, 21, 22, 23, 32, 34, 35, 36, 37, 38, 39, 48, 55, 57, 58, 59, 60, 64, 66, 67, 69, 72, 73, 77, 78], "perceiv": 6, "percent": [21, 35, 48, 58], "percent_error": [21, 35, 48, 58], "percentag": [13, 20, 26, 34, 50, 57, 64, 69], "perfect": [6, 13, 14, 20, 21, 23, 26, 27, 34, 35, 37, 39, 42, 46, 47, 48, 50, 51, 57, 58, 60, 64, 68, 71], "perfectli": [2, 64, 65], "perform": [11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 46, 47, 48, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 69, 70, 71, 73, 74, 76, 77, 78, 79], "performac": [14, 27, 51], "perhap": [21, 35, 48, 58, 67, 72], "perimet": [24, 40, 61], "period": [65, 67, 68, 71, 80], "perm_sorted_idx": [23, 37, 39, 60], "perman": 8, "permiss": [0, 80], "permit": [0, 16, 20, 29, 34, 53, 57, 80], "permut": [23, 37, 39, 60], "persist": 64, "person": [0, 1, 4, 6, 12, 20, 25, 34, 47, 49, 57, 62, 65, 66, 67, 68, 70, 71, 80], "perspect": [22, 36, 38, 59, 64], "pertain": 5, "perthairport": 67, "perturb": [23, 37, 39, 44, 60, 63], "perturbed_pr": [23, 37, 39, 60], "pertwe": 46, "pete_seeg": 65, "peter": [1, 46], "petter": 46, "ph": 65, "pharma": 70, "phascolarcto": 66, "phase": [14, 27, 51], "phd": 65, "phdei": 68, "phenomenon": [64, 68, 75], "philippin": [46, 71], "philosoph": 65, "phone": [12, 25, 49, 68, 80], "phoneservic": 68, "phoneservice_no": 68, "phoneservice_y": 68, "photo": [71, 73], "photograph": 80, "phrase": 65, "physic": [17, 30, 54, 67], "pi": 8, "piazza": [1, 6, 7, 12, 13, 25, 40], "pick": [13, 18, 20, 22, 23, 24, 26, 32, 34, 37, 38, 39, 40, 42, 46, 47, 50, 55, 57, 59, 60, 61, 62, 63, 66, 69, 70, 72, 74, 75, 77, 78, 79], "pictur": [22, 23, 36, 37, 38, 39, 59, 60, 63, 65, 67, 69], "pie": 8, "piec": [18, 32, 46, 55, 68], "pil": [12, 25, 43, 49, 66], "pile": 46, "pin": [7, 66], "pineappl": 65, "pip": [10, 23, 37, 60, 65, 66, 70, 71], "pipe": [16, 17, 18, 19, 20, 29, 30, 32, 33, 34, 36, 47, 53, 54, 55, 56, 57, 59, 65, 66, 71, 77, 78], "pipe_bestalpha": [21, 35, 48, 58], "pipe_bigalpha": [21, 35, 48, 58], "pipe_catboost": [36, 38, 59], "pipe_dt": [22, 23, 36, 37, 38, 39, 59, 60, 79], "pipe_forward": [24, 40, 61], "pipe_knn": [44, 79], "pipe_lgbm": [22, 23, 36, 37, 38, 39, 59, 60, 79], "pipe_lr": [20, 22, 23, 31, 34, 36, 37, 38, 39, 45, 46, 47, 57, 59, 60, 70, 78, 79], "pipe_lr_all_feat": [24, 61], "pipe_lr_balanc": [20, 34, 57, 78], "pipe_lr_model_bas": [24, 40, 61], "pipe_lr_weight": [20, 34, 57, 78], "pipe_ohe_knn": 44, "pipe_ordinal_knn": 44, "pipe_rf": [22, 23, 36, 37, 38, 39, 59, 60, 79], "pipe_rf_demo": [22, 36, 38, 59], "pipe_ridg": [18, 21, 32, 35, 48, 55, 58], "pipe_sklearn_gb": [22, 36, 38, 59], "pipe_sklearn_histgb": [22, 36, 38, 59], "pipe_smallalpha": [21, 35, 48, 58], "pipe_svc": [20, 34, 44, 47, 57], "pipe_svm": [19, 33, 56, 77], "pipe_xgb": [22, 23, 36, 37, 38, 39, 59, 60], "pipe_xor": [24, 40, 61], "pipelin": [1, 2, 11, 12, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 49, 51, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 68, 69, 70, 71, 76, 77, 78, 79], "pipeline__lab1": [17, 30, 54], "pipeline__lab2": [17, 30, 54], "pipeline__lab3": [17, 30, 54], "pipeline__lab4": [17, 30, 54], "pipeline__quiz1": [17, 30, 54], "pipeline__rooms_per_household": [24, 40, 61], "pipeline__university_year": [17, 30, 54], "pipelineifittedpipelin": [16, 17, 19, 20, 24, 29, 30, 33, 34, 46, 53, 54, 56, 57, 61, 66, 71], "pipelineinot": [19, 21, 33, 35, 54, 56, 58], "pipelinepipelin": [19, 33, 56], "pitch": 69, "pitfal": [67, 69], "pitt": 46, "pixel": [23, 37, 39, 60], "pizza": 65, "pkg": 10, "pla": 65, "place": [5, 65, 67, 80], "plagiar": 80, "plagu": 46, "plai": [13, 15, 19, 23, 26, 28, 33, 37, 39, 46, 50, 52, 56, 60, 63, 65, 74, 75], "plain": 62, "plan": [10, 12, 21, 24, 25, 35, 40, 48, 49, 58, 61, 68, 70, 71, 76, 79, 80], "plane": [18, 26, 32, 55], "plant": 73, "plastic": 65, "platform": 4, "platypu": 66, "player": [23, 37, 39, 60, 65, 66], "pleas": [1, 4, 7, 10, 12, 16, 17, 19, 20, 21, 22, 23, 24, 25, 29, 30, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 49, 53, 54, 56, 57, 58, 59, 60, 61, 66, 69, 70, 71, 77, 80], "plenti": 46, "plinth": 66, "plot": [7, 13, 14, 15, 16, 18, 19, 20, 21, 24, 26, 27, 28, 29, 32, 33, 34, 35, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 55, 56, 57, 58, 61, 63, 64, 65, 66, 67, 69, 70, 75, 77, 78], "plot_2d_scor": [18, 32, 55], "plot_2d_separ": [15, 18, 28, 32, 43, 52, 55, 75], "plot_coeff_exampl": [31, 45, 46], "plot_confusion_matrix": [20, 34, 57], "plot_confusion_matrix_exampl": [20, 34, 47, 57], "plot_cross_valid": [14, 27, 51, 67], "plot_dbscan": 63, "plot_dbscan_with_label": 63, "plot_dendrogram_clust": 63, "plot_elbow": 62, "plot_example_dist": 62, "plot_fruit_tre": [13, 50], "plot_grid_search_overview": [19, 33, 56], "plot_improper_process": 44, "plot_k_means_dbscan_comparison": 63, "plot_km_initi": 62, "plot_km_it": 62, "plot_km_iter": 62, "plot_kmean": 63, "plot_knn_clf": [15, 28, 52], "plot_knn_decision_boundari": [15, 28, 52], "plot_knn_regress": [15, 28, 52], "plot_lda_w_vector": 65, "plot_linkage_criteria": 63, "plot_logistic_regress": [18, 32, 55], "plot_logistic_regression_graph": 66, "plot_loss_diagram": 69, "plot_multiclass_lr_ovr": 72, "plot_original_clust": 63, "plot_partial_effects_on_outcom": 68, "plot_proper_process": 44, "plot_result": [15, 28, 43, 52, 75], "plot_sample_img": 43, "plot_scal": [16, 29, 53], "plot_silhouette_dist": 62, "plot_single_hidden_layer_graph": 66, "plot_support_vector": [15, 28, 52], "plot_survival_funct": 68, "plot_svc_c": [15, 28, 52], "plot_svc_gamma": [15, 28, 52], "plot_time_spacing_distribut": 67, "plot_train_test_point": [15, 28, 52], "plot_tre": 42, "plot_tree_decision_boundari": [14, 27, 51], "plot_tree_decision_boundary_and_tre": [13, 14, 26, 27, 50, 51, 74], "plot_two_hidden_layer_graph": 66, "plot_typ": [23, 37, 39, 60], "plot_x_dendrogram": 63, "plotli": [24, 40, 61, 65], "plotting_funct": [13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 62, 63, 64, 66, 69, 72, 74, 75, 76, 77, 78, 79], "plotting_functions_unsup": [62, 63, 64, 65], "plt": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 72, 73, 74, 75, 76, 77, 78, 79], "plu": [18, 32, 46, 55, 66], "plural": [17, 30, 54], "pm": [1, 12, 16, 18, 25, 67, 80], "pmltt": 1, "pn": [15, 20, 28, 34, 43, 47, 52, 57, 62, 63, 75], "po": [18, 21, 23, 29, 31, 32, 35, 37, 39, 45, 46, 48, 51, 53, 55, 58, 60, 65, 69, 71], "pobox": [12, 25, 49], "poet": 65, "point": [1, 4, 11, 12, 13, 14, 16, 17, 18, 19, 21, 24, 25, 26, 29, 30, 32, 33, 35, 40, 42, 44, 48, 49, 50, 51, 53, 54, 55, 56, 58, 61, 63, 68, 69, 70, 72, 73, 75, 78, 80], "point_ind": 62, "point_index": 62, "pointless": 77, "polarity_scor": 71, "pole": 66, "poli": 19, "polici": [3, 4, 7, 25, 80], "polit": [64, 65, 66], "poly_transform": 67, "polynomialfeatur": [19, 24, 40, 61, 67], "pomegran": 66, "pool": [1, 45, 46], "poolarea": [21, 23, 35, 37, 39, 48, 58, 60, 69], "poolqc": [21, 23, 35, 37, 39, 48, 58, 60, 69], "poor": [17, 21, 24, 30, 35, 39, 40, 46, 48, 54, 58, 61, 73, 76], "poorli": [15, 21, 28, 35, 52, 58, 63, 67], "pope": 65, "popul": [16, 18, 24, 29, 32, 40, 53, 54, 55, 61, 67, 76], "popular": [8, 11, 14, 15, 16, 17, 18, 20, 21, 22, 23, 28, 29, 30, 32, 34, 35, 36, 38, 39, 47, 48, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 69, 71], "population_per_household": [16, 29, 53, 54, 76], "port": 70, "porter": [46, 65], "porterstemm": 65, "portion": [0, 14, 16, 19, 21, 23, 27, 29, 31, 33, 35, 37, 45, 46, 48, 51, 53, 56, 58, 60, 69, 79, 80], "portrait": 46, "portug": [20, 23, 34, 37, 57, 60], "pos_": [65, 71], "pos_label": [21, 58], "pos_prob": [31, 45, 46], "posit": [13, 14, 15, 18, 21, 22, 23, 27, 28, 29, 32, 35, 36, 37, 38, 39, 48, 50, 51, 52, 53, 55, 58, 59, 60, 65, 67, 68, 71, 78], "posix": 68, "possess": 69, "possibl": [4, 5, 6, 8, 12, 13, 14, 16, 19, 20, 22, 23, 24, 25, 26, 27, 29, 31, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 53, 56, 57, 59, 60, 61, 63, 64, 65, 66, 68, 69, 73, 75, 76, 77, 78, 80], "possibli": [7, 65], "post": [1, 4, 6, 7, 8, 12, 17, 25, 37, 40, 65, 67, 70, 80], "postprocess": 66, "potenti": [11, 15, 16, 28, 29, 42, 52, 53, 62, 65, 69, 70], "powder": 65, "power": [8, 14, 22, 27, 36, 38, 40, 44, 51, 59, 64, 65, 66, 69], "pplicat": 63, "pr": 73, "practic": [0, 1, 6, 9, 12, 14, 16, 20, 24, 27, 29, 40, 51, 53, 61, 66, 69, 70, 73, 76, 77, 80], "practition": 69, "prairielearn": [1, 12, 17, 25, 80], "pre": [1, 10, 12, 22, 24, 25, 36, 38, 40, 43, 49, 59, 61, 65, 69, 70, 71, 73], "precipit": 70, "precis": [11, 21, 35, 58, 69, 70, 73, 78], "precision_lr": [20, 34, 47, 57], "precision_recall_curv": [20, 34, 47, 57], "precision_scor": [20, 34, 47, 57], "precision_svc": [20, 34, 47, 57], "precisionrecallcurvedisplai": [20, 34, 47, 57], "precisionrecalldisplai": [20, 34, 47, 57], "pred": [20, 21, 34, 35, 47, 48, 57, 58, 64, 67, 68], "pred_df": [12, 25, 49, 64], "pred_dict": [12, 25, 49], "pred_g": 64, "pred_lin_reg": 64, "pred_train": [21, 35, 48, 58], "pred_x": 64, "prediciton": 68, "predict": [2, 11, 14, 15, 16, 19, 20, 21, 24, 27, 28, 29, 30, 31, 33, 34, 35, 36, 40, 42, 44, 45, 46, 47, 48, 51, 52, 53, 56, 57, 58, 61, 62, 63, 65, 67, 69, 70, 71, 73, 75, 76, 77, 78, 79], "predict_expect": 68, "predict_for_usr": 64, "predict_proba": [20, 22, 23, 31, 34, 36, 37, 38, 39, 45, 46, 47, 57, 59, 60, 66, 72, 79], "predict_survival_funct": 68, "predicted_categori": [20, 57, 70], "predicted_n_rent": 67, "predicted_quiz2": [13, 26, 50], "predicted_sal": 67, "predicted_target": [12, 25, 49], "predictor": [13, 26, 50, 73], "prefer": [12, 22, 25, 36, 49, 59, 62, 64, 77], "prefer_skip_nested_valid": 44, "prefix": 8, "pregnant": 46, "preliminari": [16, 24, 29, 40, 53, 61], "prepar": [16, 24, 29, 40, 53, 61, 66], "prepend": 10, "preprocess": [1, 11, 14, 15, 18, 19, 20, 22, 23, 24, 27, 28, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 47, 51, 52, 55, 56, 57, 59, 60, 61, 63, 64, 66, 68, 75, 76, 77, 79], "preprocess_featur": 67, "preprocessing_fin": 68, "preprocessing_notenur": 68, "preprocessor": [19, 20, 21, 22, 23, 33, 34, 35, 36, 37, 38, 39, 44, 48, 54, 56, 57, 58, 59, 60, 67, 68, 69, 71, 76, 77, 78, 79], "preprocessor1": [24, 40, 61], "preprocessor2": [24, 40, 61], "preprocessor3": [24, 40, 61], "prereq": 70, "prerequisit": [2, 68, 80], "preschool": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "presenc": [17, 23, 30, 34, 37, 39, 54, 60, 68], "present": [7, 14, 20, 27, 31, 40, 43, 45, 46, 51, 57, 64, 65, 66, 67, 68, 69, 70, 73, 75], "preserv": [20, 34, 57, 62], "pressure3pm": 67, "pressure9am": 67, "pretend": [13, 14, 27, 50, 51, 67], "pretrain": [65, 66, 71], "pretti": [13, 18, 20, 22, 26, 32, 34, 36, 38, 44, 47, 50, 54, 55, 57, 59, 62, 65, 67, 68], "prevent": [19, 33, 56, 65, 68, 80], "previou": [12, 13, 21, 22, 25, 26, 35, 36, 38, 42, 50, 58, 59, 62, 63, 67, 68, 69, 73, 77, 78], "previous": [64, 66, 67], "price": [8, 16, 18, 21, 23, 24, 26, 29, 32, 35, 37, 39, 40, 42, 44, 48, 53, 55, 58, 60, 61, 68, 69, 75], "primari": [8, 15, 28, 31, 45, 46, 52], "primarili": [12, 13, 23, 25, 26, 37, 39, 50, 60, 66, 70], "prime": [12, 25, 49], "princ": 65, "princess": 65, "principl": [9, 11, 13, 50, 73], "print": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 78], "print_top": 65, "prior": [62, 67, 73], "priorit": [24, 40, 61, 73], "privaci": [0, 11, 62, 70], "privat": [7, 20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60], "privileg": 6, "prize": [17, 30, 38, 54], "pro": [62, 66, 69], "prob": [18, 22, 32, 36, 38, 55, 59], "proba": 66, "probabilist": [2, 65], "probabl": [12, 15, 16, 20, 21, 22, 23, 24, 25, 28, 29, 31, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 49, 52, 53, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 73, 78, 79], "problem": [1, 4, 6, 11, 12, 17, 18, 20, 21, 22, 23, 25, 30, 32, 34, 35, 36, 37, 38, 39, 42, 44, 46, 47, 48, 49, 54, 55, 57, 58, 59, 60, 62, 63, 65, 66, 68, 69, 72, 73, 75, 77, 78, 79, 80], "problemat": [20, 23, 34, 37, 39, 57, 60, 68], "probosci": [12, 25, 49, 66], "proce": [43, 80], "procedur": [22, 38, 59], "proceed": [14, 51], "process": [2, 5, 7, 11, 13, 15, 16, 17, 19, 24, 26, 28, 29, 30, 33, 40, 42, 43, 50, 52, 53, 54, 56, 61, 62, 63, 66, 69, 70, 71, 75, 77], "procfil": 70, "prod": [17, 19, 30, 33, 54, 56], "produc": [2, 7, 21, 23, 26, 35, 37, 39, 44, 46, 58, 60, 63, 68, 69, 73, 75], "product": [5, 19, 33, 46, 56, 64, 65, 69, 71], "prof": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "profession": [64, 70], "profil": [21, 35, 58], "profile_df": 64, "profilereport": [21, 35, 58], "profit": 69, "program": [0, 4, 9, 10, 12, 25, 49, 65, 80], "programm": 65, "progress": 62, "project": [10, 16, 24, 29, 36, 38, 40, 53, 59, 61, 66, 69, 70, 73, 80], "promin": 65, "promis": [12, 25, 38, 42, 49, 65, 67, 70], "promot": 68, "prompt": [10, 12, 80], "pron": [65, 71], "prone": [19, 33, 56], "proper": [66, 74], "properli": [7, 12, 25, 68, 69], "properti": [13, 21, 23, 24, 26, 35, 37, 39, 48, 50, 58, 60, 61], "prophet": 67, "propn": [65, 71], "proport": [11, 13, 14, 17, 18, 20, 21, 22, 23, 26, 27, 30, 32, 34, 35, 36, 37, 38, 39, 48, 50, 51, 54, 55, 57, 58, 59, 60, 69, 78], "proportional_hazard_test": 68, "prostitut": 65, "protocol": 70, "prototyp": [70, 73], "prove": [20, 57], "provid": [0, 5, 7, 10, 11, 13, 14, 17, 18, 19, 20, 21, 23, 24, 26, 27, 30, 32, 33, 34, 35, 37, 39, 40, 43, 47, 48, 50, 51, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 69, 73, 77, 78, 79, 80], "provinc": [17, 30, 54, 65], "provinci": 65, "proxi": [14, 27, 51], "proxim": [18, 32, 55, 65, 80], "prune": [24, 40, 61], "psychiatr": 46, "psychologi": [17, 30, 54, 73], "pt": [18, 32, 33, 55, 56, 66], "public": [0, 4, 7, 65, 71], "publish": [0, 1, 18, 32, 55, 65], "puck": 65, "pud": [21, 35, 48, 58], "pull": [10, 18, 32, 55, 65], "punct": [65, 71], "punctuat": [17, 30, 54, 65], "punish": 69, "punkt": 71, "punkt_tab": 71, "purchas": [12, 25, 43, 49, 64, 70], "pure": [13, 26, 50, 67], "purpos": [0, 13, 14, 16, 26, 27, 29, 31, 40, 45, 46, 50, 51, 53, 64, 65, 67, 70, 73, 74, 75, 79, 80], "pursuit": 69, "push": [7, 23, 37, 39, 60], "put": [7, 8, 10, 13, 14, 16, 17, 24, 27, 29, 30, 31, 40, 43, 44, 45, 46, 50, 51, 53, 54, 61, 62, 63, 64, 70, 77], "px": [24, 40, 61, 65], "py": [13, 17, 22, 26, 29, 30, 36, 38, 39, 43, 44, 50, 51, 53, 54, 56, 59, 60, 62, 63, 68, 70, 71, 72], "pybo": [19, 33, 56], "pydata": [24, 40, 61], "pyplot": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 73, 74, 75, 76, 77, 78, 79], "pysurviv": 68, "python": [1, 3, 4, 11, 19, 21, 33, 35, 49, 56, 58, 64, 65, 66, 67, 68, 69, 70, 71, 80], "python3": [9, 17, 26, 30, 43, 44, 50, 51, 54, 56, 60, 68, 72], "pythonwarn": [21, 35, 47, 58], "pytorch": [12, 25, 49, 66], "pyviz": [20, 34, 47, 57], "q": 1, "qualit": 44, "qualiti": [20, 23, 24, 34, 37, 39, 40, 47, 57, 60, 62, 63, 69], "quantifi": [20, 34, 57, 78], "quantil": 44, "quantit": 44, "quebecoi": 44, "queen": 65, "queen_consort": 65, "queri": [16, 20, 22, 29, 34, 36, 38, 43, 53, 57, 59, 62, 64, 65, 67, 68, 78, 80], "query_img": 43, "query_point": [15, 28, 52], "quest": [24, 40, 61], "question": [1, 6, 7, 40, 48, 80], "queuepredictor": 70, "quick": [4, 12, 25, 65, 70, 80], "quickli": [13, 15, 16, 19, 26, 28, 29, 33, 50, 52, 53, 56, 63, 68, 73, 80], "quickstart": 9, "quirk": [14, 27, 51], "quit": [6, 12, 13, 16, 19, 20, 21, 23, 24, 26, 29, 33, 34, 35, 37, 39, 40, 43, 46, 48, 49, 50, 53, 56, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 71], "quiz": [1, 12, 16, 25, 65, 80], "quiz1": [13, 14, 17, 26, 27, 30, 50, 51, 54, 73], "quiz2": [14, 17, 27, 30, 51, 54, 73], "quizz": [13, 15, 17, 26, 50], "r": [11, 13, 17, 18, 20, 26, 30, 32, 34, 45, 46, 47, 50, 54, 55, 57, 67, 69, 79], "r1": [22, 36, 38, 59], "r2": [21, 22, 35, 36, 38, 42, 48, 58, 59, 73, 75], "r2_score": [21, 24, 35, 40, 48, 58, 61], "r4": [36, 59], "race": [17, 20, 22, 23, 34, 36, 37, 38, 39, 54, 57, 59, 60, 78, 80], "radial": [15, 28, 52], "radiu": [24, 40, 61, 63], "rail": 66, "rain": 67, "rain_df": 67, "rain_df_modifi": 67, "rainfal": 67, "rainfall_lag1": 67, "rainfall_lag2": 67, "rainfall_lag3": 67, "raintodai": 67, "raintoday_miss": 67, "raintoday_no": 67, "raintoday_y": 67, "raintomorrow": 67, "rais": [6, 17, 19, 20, 25, 30, 34, 44, 47, 54, 57, 67, 68], "rand": [8, 22, 36, 38, 59], "randint": [19, 33, 56, 77], "randn": [18, 24, 32, 40, 55, 61], "random": [6, 8, 11, 14, 15, 18, 20, 24, 27, 28, 32, 34, 40, 43, 47, 51, 52, 55, 57, 61, 62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 77, 79], "random_forest_data": [22, 36, 59], "random_search": [19, 33, 56, 77], "random_st": [12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79], "randomforest": 40, "randomforestclassifi": [23, 24, 37, 39, 40, 60, 61, 67, 69, 79], "randomforestclassifierrandomforestclassifi": [22, 36, 38, 59], "randomforestregressor": [21, 22, 23, 24, 35, 36, 37, 38, 39, 40, 48, 58, 59, 60, 61, 67, 68, 69, 70, 79], "randomhorizontalflip": 66, "randomizedsearchcv": [15, 22, 23, 28, 36, 37, 38, 39, 52, 59, 60, 69, 77, 79], "randomizedsearchcvifittedrandomizedsearchcv": [19, 33, 56], "randomli": [14, 18, 19, 20, 22, 27, 32, 33, 34, 36, 38, 47, 51, 55, 56, 57, 59, 68, 78], "randomoversampl": [20, 57], "randomresizedcrop": 66, "randomst": [24, 40, 61, 63], "randomundersampl": [20, 57], "rang": [4, 8, 11, 14, 15, 16, 17, 18, 22, 27, 28, 29, 30, 32, 36, 38, 40, 44, 51, 52, 53, 54, 55, 59, 62, 64, 65, 66, 67, 68, 69, 71, 77], "rangeindex": [17, 24, 30, 40, 54, 61, 67, 68], "rank": [20, 24, 34, 40, 47, 57, 61, 64, 65, 68, 78], "rank_test_mape_scor": [21, 35, 48, 58], "rank_test_neg_mean_squared_error": [21, 35, 58], "rank_test_scor": [19, 21, 33, 35, 48, 56, 58], "ranking_": [24, 40, 61], "rare": [17, 20, 21, 34, 35, 40, 48, 54, 57, 58, 62, 65, 73], "rate": [12, 18, 20, 22, 25, 32, 34, 36, 38, 47, 49, 55, 57, 59, 62, 68, 69, 73, 78], "rated_item": 64, "rather": [12, 17, 19, 20, 21, 22, 23, 25, 30, 33, 34, 35, 36, 37, 38, 39, 44, 46, 48, 49, 54, 56, 57, 58, 59, 60, 62, 65, 66, 80], "ratings_df": 64, "ratio": [20, 22, 36, 38, 57, 59, 65, 68], "ravel": [20, 31, 34, 43, 45, 46, 47, 57, 73], "raw": [8, 17, 20, 23, 24, 30, 34, 37, 39, 40, 47, 54, 57, 60, 61, 65, 66, 69, 72, 78], "raw_model_output": [18, 32, 55], "raw_scor": [23, 37, 39, 60], "rbf": [1, 14, 16, 18, 19, 22, 23, 24, 27, 29, 32, 33, 36, 37, 38, 39, 40, 51, 53, 55, 56, 59, 60, 61, 69, 70, 73, 75, 77], "rcparam": [12, 13, 14, 20, 25, 26, 27, 34, 47, 49, 50, 51, 57, 62, 63, 64, 66, 67, 68, 69, 74], "re": [4, 7, 8, 10, 12, 13, 14, 17, 19, 20, 21, 22, 23, 25, 26, 27, 30, 31, 33, 34, 35, 36, 37, 38, 39, 45, 46, 48, 49, 50, 51, 54, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 70, 73, 74], "reach": [1, 6, 62, 80], "read": [1, 4, 7, 12, 15, 16, 17, 20, 21, 22, 23, 25, 28, 29, 30, 35, 36, 37, 38, 40, 43, 47, 48, 52, 53, 54, 57, 58, 59, 60, 65, 67, 69, 70, 79], "read_csv": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79], "read_excel": 8, "read_html": 8, "read_img_dataset": 43, "read_json": 8, "readabl": [0, 8], "reader": 11, "readi": [7, 12, 14, 15, 16, 18, 27, 28, 29, 32, 51, 52, 53, 55], "readlin": 66, "readm": 68, "readthedoc": 68, "real": [14, 15, 16, 17, 18, 20, 23, 26, 27, 28, 29, 30, 32, 34, 37, 38, 39, 40, 44, 51, 52, 53, 54, 55, 57, 60, 62, 63, 64, 65, 66, 69, 71, 73], "realdonaldtrump": 71, "realism": 46, "realist": [16, 29, 53, 67, 70], "realiti": [14, 21, 27, 35, 51, 58, 68], "realiz": 69, "realli": [8, 14, 18, 19, 22, 24, 27, 32, 33, 38, 40, 46, 51, 55, 56, 59, 61, 63, 64, 66, 67, 68, 70], "reanim": 46, "reason": [0, 2, 4, 8, 11, 14, 16, 19, 20, 21, 23, 27, 29, 33, 34, 35, 37, 39, 46, 47, 48, 51, 53, 56, 57, 58, 60, 62, 64, 65, 67, 68, 69, 70, 73, 80], "rec": [21, 23, 35, 37, 39, 48, 58, 60, 69], "recal": [11, 13, 14, 15, 16, 17, 18, 21, 27, 29, 30, 32, 35, 40, 44, 48, 50, 51, 52, 53, 54, 55, 58, 62, 67, 70, 73, 78], "recall_lr": [20, 34, 47, 57], "recall_scor": [20, 34, 47, 57], "recall_svc": [20, 34, 47, 57], "receiv": [6, 7, 17, 25, 30, 54, 63, 66, 67, 70], "recent": [8, 10, 12, 17, 24, 25, 30, 40, 44, 49, 54, 61, 64, 65, 67, 68], "recip": [14, 27, 51], "recogn": [11, 14, 27, 46, 51, 63, 67, 69, 80], "recognit": [12, 13, 15, 20, 25, 49, 50, 52, 57, 65, 80], "recommend": [1, 2, 4, 8, 10, 11, 14, 15, 19, 20, 27, 31, 33, 34, 37, 43, 45, 46, 49, 51, 52, 56, 57, 62, 65, 66, 69, 70, 79], "record": [13, 26, 50, 68], "rectangular": 62, "recurr": 67, "recurs": 11, "red": [13, 15, 20, 23, 24, 26, 28, 34, 37, 39, 40, 47, 50, 52, 57, 60, 61, 62, 67], "redbon": [19, 33, 56], "redefin": 68, "redistribut": 0, "reduc": [7, 8, 12, 15, 19, 20, 21, 22, 23, 24, 25, 28, 33, 34, 35, 36, 37, 38, 39, 40, 49, 52, 56, 57, 58, 59, 60, 61, 64, 65, 66, 72, 75, 78, 80], "reduct": [2, 20, 22, 24, 34, 36, 38, 40, 47, 57, 59, 61, 62], "redund": [18, 23, 32, 37, 39, 55, 60], "ref": [20, 34, 47, 57, 68, 78], "refer": [8, 12, 13, 14, 15, 16, 17, 18, 20, 23, 25, 26, 27, 28, 29, 30, 32, 34, 37, 39, 50, 51, 52, 53, 54, 55, 57, 60, 62, 64, 65, 66, 75, 80], "referenc": 80, "referenti": 65, "refin": [15, 28, 43, 52, 75], "refit": [21, 35, 48, 58], "reflect": [15, 21, 23, 28, 35, 37, 39, 48, 52, 58, 60, 65, 75, 77, 80], "reflection_period": [20, 57, 70], "refus": 46, "reg": [13, 22, 26, 36, 38, 50, 59, 79], "reg_model": [13, 26, 50], "regard": [31, 80], "regardless": 7, "regex": 65, "regim": 70, "region": [13, 20, 26, 50, 57, 63, 67, 70, 72, 77], "region_data": 67, "regist": [12, 25, 70, 80], "registered_nurs": 65, "registr": 40, "regrad": [6, 25], "regress": [1, 2, 11, 12, 16, 17, 23, 24, 25, 29, 30, 31, 36, 37, 39, 42, 45, 46, 49, 53, 54, 60, 61, 64, 67, 68, 69, 70, 71, 72, 73, 75, 78, 79], "regression_df": [13, 26, 50], "regressioncolumntransform": [22, 36, 38], "regressor": [13, 16, 17, 21, 26, 29, 30, 35, 42, 44, 50, 53, 54, 58, 67, 79], "regular": [15, 17, 18, 22, 28, 30, 32, 38, 40, 52, 54, 55, 59, 65, 67, 68, 69, 73], "regularli": 46, "regulatori": [23, 37, 39, 60], "reinforc": [12, 25, 49, 62], "reject": [20, 34, 57, 78], "rel": [18, 23, 27, 32, 37, 39, 44, 55, 60, 63, 65, 71, 72, 78], "rel_char_len": 71, "relabel": 62, "relat": [2, 6, 10, 12, 18, 20, 21, 22, 23, 24, 25, 32, 35, 36, 37, 38, 39, 40, 46, 48, 49, 55, 57, 58, 59, 60, 61, 62, 64, 65, 67, 68, 71, 79, 80], "relationship": [11, 20, 22, 23, 24, 34, 36, 37, 38, 39, 40, 57, 59, 60, 61, 65, 67, 69, 71, 73, 74, 75, 78, 80], "relationship_husband": [23, 37, 39, 60], "relationship_own": [23, 37, 39, 60], "releas": [1, 7, 14, 15, 16, 17], "relev": [1, 4, 8, 11, 13, 15, 16, 19, 23, 26, 28, 29, 33, 37, 39, 50, 52, 53, 56, 60, 67, 80], "reli": [14, 15, 24, 27, 28, 40, 43, 51, 52, 61, 63, 64, 67, 75], "reliabl": [12, 25, 27, 49, 62], "religi": 65, "remain": [5, 21, 24, 35, 40, 58, 61, 64, 67, 69], "remaind": 6, "rememb": [7, 15, 17, 19, 20, 23, 24, 25, 28, 30, 31, 33, 34, 37, 39, 40, 45, 46, 47, 48, 52, 54, 56, 57, 60, 61, 63, 66, 67, 68, 74, 75, 77], "remind": 74, "remix": 0, "remov": [7, 16, 20, 22, 23, 24, 29, 34, 36, 37, 38, 39, 40, 43, 53, 57, 59, 60, 61, 65, 66, 68, 72, 77, 78], "renam": [12, 20, 25, 39, 49, 57, 60, 67, 70], "render": [4, 7, 12, 16, 17, 19, 20, 21, 22, 23, 24, 25, 29, 30, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 49, 53, 54, 56, 57, 58, 59, 60, 61, 62, 65, 66, 69, 71], "rent": 67, "rental": [67, 70], "rentals_df": 67, "rentals_lag5": 67, "rentals_lag5_i": 67, "rentals_lag5_x": 67, "rentals_model": 67, "repair": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60], "repeat": [8, 24, 40, 61, 62, 63, 66, 70, 77, 78, 79], "repeatedli": 6, "repetit": 46, "rephras": 69, "replac": [12, 16, 20, 22, 23, 25, 29, 31, 34, 36, 37, 38, 39, 40, 44, 45, 46, 49, 53, 57, 59, 60, 64, 68, 78], "replace_tag": [31, 45, 46], "replic": 70, "repo": [1, 20, 34, 47, 57, 70], "report": [6, 13, 19, 21, 24, 26, 33, 35, 40, 50, 56, 58, 61, 67, 71, 78], "repositori": [0, 1, 5, 10, 12, 18, 20, 25, 32, 34, 43, 44, 47, 55, 57, 70, 80], "repres": [13, 14, 15, 16, 17, 18, 20, 23, 24, 26, 27, 28, 29, 30, 32, 34, 36, 37, 39, 40, 47, 50, 51, 52, 53, 54, 55, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 73, 79], "represent": [12, 13, 16, 19, 20, 21, 22, 23, 24, 25, 26, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 49, 50, 53, 56, 57, 58, 59, 60, 61, 62, 63, 65, 69, 70, 71, 73], "reproduc": [4, 14, 19, 22, 27, 33, 36, 51, 56, 59, 70, 80], "republ": [23, 37, 39, 60], "request": [6, 25, 65, 80], "requir": [5, 7, 15, 16, 19, 20, 22, 23, 24, 28, 29, 33, 34, 36, 37, 38, 39, 40, 43, 44, 47, 52, 53, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 73, 75, 80], "rerun": [12, 16, 17, 19, 20, 21, 22, 23, 24, 25, 29, 30, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 49, 53, 54, 56, 57, 58, 59, 60, 61, 66, 69, 71], "res_mean": [14, 27, 51], "resampl": [20, 57], "research": [12, 14, 19, 25, 27, 33, 49, 51, 56, 64, 65, 70], "reserv": [67, 80], "reset": 44, "reset_index": [12, 25, 49], "reshap": [8, 18, 19, 32, 33, 44, 55, 56, 66, 67, 77], "reshape_transform": 44, "resid": [18, 32, 55], "residu": [22, 38, 59], "resiz": [43, 66], "resnet": 66, "resolut": 65, "resolv": 80, "resort": [18, 32, 55], "resourc": [1, 3, 5, 22, 23, 36, 37, 39, 50, 59, 60, 65, 66, 70, 73], "respect": [18, 19, 20, 22, 23, 32, 33, 36, 37, 38, 39, 47, 55, 56, 57, 59, 60, 77], "respons": [4, 7, 13, 26, 46, 50, 62, 65, 69, 80], "rest": [18, 19, 32, 33, 46, 55, 56, 66, 68, 70, 73], "restart": [7, 10], "restaur": [44, 64, 70], "restaurant_df": 44, "restaurant_nam": 44, "restingbp": 79, "restingecg": 79, "restrict": [0, 21, 22, 35, 36, 38, 58, 59, 65], "resubmit": 25, "result": [1, 2, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 66, 67, 68, 70, 71, 75, 77, 78, 79, 80], "result_block": 68, "result_img": 66, "results_df": [14, 15, 18, 27, 28, 31, 32, 42, 43, 45, 46, 51, 52, 55, 75], "results_dict": [14, 15, 16, 19, 27, 28, 29, 33, 43, 51, 52, 53, 54, 56], "results_single_valid_df": [42, 75], "retail": [71, 73], "retail_df": 67, "retail_df_test": 67, "retail_df_train": 67, "retail_lag_5": 67, "retail_model": 67, "retail_test_5": 67, "retail_test_5_pr": 67, "retail_train_5": 67, "retail_train_5_d": 67, "retail_train_5_i": 67, "retail_train_5_x": 67, "retent": 68, "retrain": [19, 33, 56, 70, 77], "return": [5, 8, 10, 13, 14, 15, 16, 17, 20, 21, 24, 26, 27, 28, 29, 30, 31, 34, 35, 40, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 75, 77], "return_gener": [17, 30, 54], "return_predict": 70, "return_train_scor": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 67, 68, 71, 75, 77, 79], "reus": [20, 34, 57, 80], "revenu": 64, "revers": [17, 21, 30, 35, 54, 58], "review": [1, 4, 18, 32, 55, 62, 69, 71, 73, 77, 78, 79, 80], "review_pp": [31, 45, 46], "revisit": [20, 34, 57, 73], "revok": 0, "reward": [12, 17, 25, 30, 49, 54, 62], "rf": [67, 68], "rf_imp_df": [23, 37, 60], "rfe_cv": [24, 40, 61], "rfe_pip": [24, 40, 61], "rfecv": [24, 40, 61], "rgb": [12, 25, 49], "rhode_island": 65, "rich": [23, 37, 39, 60, 65, 68, 69, 73], "richard": [46, 69], "rico": [22, 23, 37, 39, 60], "rid": [10, 17, 22, 23, 30, 36, 37, 38, 39, 44, 54, 59, 60, 65, 68], "ridg": [23, 24, 37, 39, 60, 61, 64, 67, 68, 69, 70], "ridge__alpha": [21, 35, 48, 58], "ridge_pr": [21, 35, 48, 58], "ridge_tun": [21, 35, 48, 58], "ridgecv": [24, 40, 61], "ridgecv_pip": [21, 35, 48, 58], "ridgeridg": [21, 24, 35, 58, 61], "rifl": 46, "right": [0, 1, 11, 12, 18, 19, 20, 21, 24, 25, 32, 33, 34, 35, 40, 42, 44, 46, 47, 48, 49, 55, 56, 57, 58, 61, 62, 63, 64, 65, 69, 70, 73, 77, 78], "rightarrow": [13, 15, 18, 20, 21, 22, 28, 32, 34, 35, 36, 38, 47, 48, 50, 52, 55, 57, 58, 59, 62, 63, 64, 65, 69, 70, 73], "rindfleischetikettierungs\u00fcberwachungsaufgaben\u00fcbertragungsgesetz": 65, "ring": 46, "rip": 46, "rise": [24, 61, 65], "risk": [1, 20, 24, 34, 40, 47, 57, 61, 69, 75, 79], "riti": [25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 80], "river": [18, 32, 55], "rl": [21, 23, 35, 37, 39, 58, 60, 69], "rmse": [64, 73], "rng": [24, 40, 61, 63], "rnn": 67, "ro": [20, 57], "roast": 62, "robot": [64, 65], "robust": [12, 14, 15, 16, 19, 22, 25, 27, 28, 29, 33, 36, 44, 49, 51, 52, 53, 56, 59, 63, 75, 77], "robustscal": 44, "roc": [11, 70, 73], "roc_auc": [20, 34, 47, 57], "roc_auc_scor": [20, 34, 47, 57], "roc_curv": [20, 34, 47, 57], "roc_lr": [20, 34, 47, 57], "roc_svc": [20, 34, 47, 57], "roccurvedisplai": [20, 34, 47, 57], "rock": 46, "rodolfo": [19, 33, 56], "rodr\u00edguez": 65, "roger": [24, 40, 46, 61], "role": [18, 19, 23, 32, 33, 37, 39, 46, 55, 56, 60, 66], "roman": 64, "romanc": 64, "romant": 64, "ronald": [18, 32, 55], "roof": [23, 39, 60], "roofmatl": [21, 23, 35, 37, 39, 58, 60, 69], "roofmatl_clytil": [21, 23, 35, 39, 58, 60], "roofmatl_compshg": [21, 23, 35, 39, 58, 60], "roofmatl_membran": [21, 23, 35, 58], "roofmatl_met": [21, 23, 35, 58], "roofmatl_rol": [21, 23, 35, 58], "roofmatl_tar": [21, 23, 35, 58], "roofmatl_wdshak": [21, 23, 35, 58], "roofmatl_wdshngl": [21, 23, 35, 39, 58, 60], "roofstyl": [21, 23, 35, 37, 39, 58, 60, 69], "roofstyle_flat": [21, 35, 58], "roofstyle_g": [21, 35, 58], "roofstyle_gambrel": [21, 35, 58], "roofstyle_hip": [21, 35, 58], "roofstyle_mansard": [21, 35, 58], "roofstyle_sh": [21, 35, 58], "room": [12, 13, 18, 21, 24, 25, 26, 32, 35, 40, 44, 49, 50, 55, 58, 61, 70, 71, 80], "room_row": 40, "rooms_per_household": [16, 24, 29, 40, 53, 54, 61, 76], "rooms_per_household_0": [24, 40, 61], "rooms_per_household_1": [24, 40, 61], "rooms_per_household_10": [24, 40, 61], "rooms_per_household_11": [24, 40, 61], "rooms_per_household_12": [24, 40, 61], "rooms_per_household_13": [24, 40, 61], "rooms_per_household_14": [24, 40, 61], "rooms_per_household_15": [24, 40, 61], "rooms_per_household_16": [24, 40, 61], "rooms_per_household_17": [24, 40, 61], "rooms_per_household_18": [24, 40, 61], "rooms_per_household_19": [24, 40, 61], "rooms_per_household_2": [24, 40, 61], "rooms_per_household_3": [24, 40, 61], "rooms_per_household_4": [24, 40, 61], "rooms_per_household_5": [24, 40, 61], "rooms_per_household_6": [24, 40, 61], "rooms_per_household_7": [24, 40, 61], "rooms_per_household_8": [24, 40, 61], "rooms_per_household_9": [24, 40, 61], "root": [10, 13, 15, 26, 28, 43, 50, 52, 64, 66, 73], "rose": 65, "rostin": [1, 80], "rotat": 67, "roth": [1, 38, 39, 40, 80], "rough": [4, 48], "roughli": [5, 14, 51, 65, 70, 73], "round": [8, 15, 16, 19, 20, 22, 28, 29, 33, 34, 36, 38, 43, 47, 52, 53, 56, 57, 59, 63, 66, 75], "rout": [5, 13, 26, 50, 67], "row": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75, 79, 80], "rry": 65, "rsh": [19, 33, 56], "ru": [8, 20, 57], "rubric": [18, 25, 32, 55], "rule": [1, 8, 12, 13, 15, 18, 20, 22, 25, 26, 31, 32, 34, 42, 45, 46, 49, 50, 52, 55, 57, 59, 65, 70, 73, 75, 78], "run": [1, 4, 5, 7, 10, 12, 14, 15, 17, 19, 20, 21, 23, 25, 27, 30, 33, 34, 35, 37, 39, 43, 46, 47, 48, 49, 51, 52, 54, 56, 57, 58, 60, 62, 63, 65, 66, 70, 71, 72, 74, 75, 77, 79], "runtimewarn": 56, "ruscorpora": 65, "rush": [24, 40, 61], "russel": 1, "rv": [19, 33, 56], "rv_continuous_frozen": [19, 33, 56], "rv_discrete_frozen": [19, 33, 56], "rvert_2": 65, "s1": [8, 65], "s19": [16, 29, 53], "s2": [8, 65], "s_lag": 67, "sa": 1, "sabr": 65, "sabrina": 1, "sadli": 65, "safe": [16, 29, 53], "safeti": 66, "sai": [8, 13, 15, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 34, 35, 36, 37, 39, 46, 50, 52, 53, 54, 57, 58, 59, 60, 65, 67, 69, 73, 78], "said": [14, 16, 18, 23, 27, 29, 32, 37, 40, 51, 53, 55, 60, 63, 64, 65, 69], "sal": [21, 23, 35, 37, 39, 48, 58, 60, 69], "sale": [8, 20, 21, 34, 35, 42, 48, 57, 58, 67, 69, 75], "salecondit": [21, 23, 35, 37, 39, 58, 60, 69], "salecondition_abnorml": [21, 35, 58], "salecondition_adjland": [21, 35, 58], "salecondition_alloca": [21, 35, 58], "salecondition_famili": [21, 35, 58], "salecondition_norm": [21, 35, 58], "salecondition_parti": [21, 35, 58], "salepric": [21, 23, 35, 37, 39, 48, 58, 60, 69], "sales_data": 67, "salesforc": 71, "saleswoman": 65, "saletyp": [21, 23, 35, 37, 39, 58, 60, 69], "saletype_cod": [21, 35, 58], "saletype_con": [21, 35, 58], "saletype_conld": [21, 35, 58], "saletype_conli": [21, 35, 58], "saletype_conlw": [21, 35, 58], "saletype_cwd": [21, 35, 58], "saletype_new": [21, 35, 58], "saletype_oth": [21, 35, 58], "saletype_wd": [21, 35, 58], "salt": [18, 23, 32, 37, 39, 55, 60], "sam": 64, "same": [6, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 40, 42, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 73, 74, 75, 78], "samosa": 65, "sampl": [12, 13, 15, 16, 18, 19, 23, 26, 27, 28, 29, 32, 33, 34, 37, 39, 43, 44, 50, 52, 53, 55, 56, 60, 63, 66, 67, 68, 69, 70, 74, 75, 78, 79], "sample_df": [20, 57, 70], "sample_text": 71, "sampling_strategi": [20, 57], "samuel": [12, 25, 49], "sand": 66, "sandbar": 66, "saniti": [13, 26, 50, 68], "sarafian": 46, "sarah": 1, "sat": 67, "satisfactori": 62, "satisfi": 62, "satur": 69, "saturdai": 67, "sauc": 44, "save": [7, 8, 17, 19, 23, 30, 33, 37, 39, 46, 54, 56, 60, 65, 66, 67, 69, 71, 76, 77], "saw": [16, 18, 19, 20, 29, 32, 33, 34, 40, 53, 55, 56, 57, 63, 73], "sb": [24, 40, 61], "scalabl": [12, 25, 49, 63], "scalar": 8, "scale": [14, 15, 17, 19, 20, 21, 22, 24, 27, 28, 30, 33, 34, 35, 36, 38, 40, 42, 43, 47, 48, 51, 52, 54, 56, 57, 58, 59, 61, 63, 66, 68, 69, 70, 73, 75, 76, 77], "scale_pos_weight": [22, 36, 38, 59], "scaler": [16, 23, 24, 29, 37, 39, 40, 44, 53, 60, 61], "scan": 73, "scari": 70, "scatter": [16, 21, 23, 24, 29, 35, 37, 39, 40, 48, 53, 58, 60, 61], "scatter_3d": [24, 40, 61], "scatterplot": [24, 40, 61, 70], "scc": 65, "scenario": [11, 14, 17, 23, 24, 27, 30, 36, 37, 38, 39, 40, 51, 54, 59, 60, 61, 63, 67, 68, 70, 73], "scene": 46, "schafer": 70, "schedul": [68, 73, 80], "schmidt": [19, 33, 56], "school": [12, 20, 22, 23, 25, 34, 36, 37, 38, 39, 49, 57, 59, 60, 64, 78], "schoolteach": 65, "scienc": [1, 2, 9, 10, 11, 17, 30, 54, 62, 67, 69, 73, 75], "scientif": [64, 65], "scientist": [1, 9, 63], "scikit": [9, 10, 11, 13, 15, 18, 19, 20, 22, 26, 28, 32, 33, 34, 36, 38, 40, 44, 47, 50, 52, 55, 56, 57, 59, 62, 63, 66, 67, 69, 71, 72, 77, 78], "scipi": [10, 19, 33, 56, 63, 65, 77], "scm": 5, "scope": [12, 25, 65, 67], "score": [11, 12, 15, 16, 17, 22, 23, 25, 28, 29, 30, 31, 36, 37, 38, 39, 42, 43, 44, 45, 46, 49, 52, 53, 54, 59, 60, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80], "score_func": [21, 35, 48, 58], "score_gb_test": 69, "score_gb_train": 69, "score_lr_print_coeff": 67, "score_param": [17, 30, 54], "score_rf_test": 69, "score_rf_train": 69, "score_tim": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 67, 68, 71], "scorer": [17, 21, 30, 35, 48, 54, 58], "scores_averag": 79, "scores_dict": [18, 31, 32, 45, 46, 55], "scores_imag": [18, 32, 55], "scores_stack": 79, "scoring_method": 68, "scoring_metr": [22, 23, 36, 37, 38, 39, 59, 60, 71], "scotland": 65, "scott": 69, "scratch": [2, 66, 70], "screen": [7, 45, 46], "screennam": 71, "screenplai": 65, "screenporch": [21, 23, 35, 37, 39, 48, 58, 60, 69], "screenshot": 69, "script": [10, 46], "scroog": 71, "sdng": [21, 35, 58, 69], "se": [67, 68], "sea": 66, "seaborn": [23, 24, 37, 39, 40, 60, 61, 62, 63, 64], "seacoast": 66, "search": [4, 5, 10, 21, 35, 48, 58, 65, 73, 77], "search_multi": [21, 35, 48, 58], "seashor": 66, "season_autumn": 67, "season_fal": 67, "season_summ": 67, "season_wint": 67, "seat": [66, 80], "seattl": 71, "seawal": 66, "second": [4, 6, 13, 18, 22, 23, 25, 26, 32, 36, 37, 38, 39, 46, 50, 55, 59, 60, 63, 66, 67, 69], "secondari": [12, 25, 49], "secpompeo": 71, "section": [1, 7, 10, 14, 24, 26, 40, 50, 51, 61, 79, 80], "secur": [23, 37, 39, 60, 70, 80], "see": [1, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 73, 74, 75, 77, 78, 79, 80], "seed": [18, 19, 32, 33, 43, 55, 56, 62, 63, 70], "seem": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 45, 46, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 67, 68, 71, 72, 75, 77, 78], "seemingli": [20, 34, 57, 78], "seen": [8, 12, 14, 15, 16, 17, 18, 24, 25, 27, 28, 29, 30, 32, 40, 46, 48, 49, 51, 52, 53, 54, 55, 61, 63, 64, 68, 73, 75, 77, 79], "segment": [11, 20, 57, 65, 66, 68, 70, 73], "segmentspher": 70, "selction": 40, "select": [1, 5, 6, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 42, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 66, 67, 68, 69, 70], "select_dtyp": [21, 35, 48, 58], "select_knn": [24, 40, 61], "select_rf": [24, 40, 61], "select_svc": [24, 40, 61], "selectfrommodel": [24, 40, 61], "self": [12, 17, 25, 30, 44, 49, 54, 68, 80], "sell": [0, 8, 13, 26, 48, 50, 69], "semant": [11, 62, 63, 65], "semest": [12, 25, 80], "semi": [1, 12, 65], "semicolon": 8, "semilogx": [21, 35, 48, 58], "send": [4, 12, 25, 49], "senior": 68, "seniorcitizen": 68, "sens": [6, 14, 17, 18, 20, 21, 23, 24, 27, 30, 31, 32, 34, 35, 37, 39, 40, 45, 46, 51, 54, 55, 57, 58, 60, 61, 62, 64, 65, 67, 68, 70, 72], "sensibl": [7, 70], "sensit": [14, 16, 19, 20, 21, 27, 29, 33, 34, 35, 47, 51, 53, 56, 57, 58, 62, 68], "sent": [12, 25, 49, 65], "sent_token": 65, "sentenc": [65, 69], "sentiment": [13, 18, 31, 32, 45, 46, 50, 55, 65, 71], "sentimentintensityanalyz": 71, "sepal": [15, 28, 43, 52, 75], "separ": [13, 14, 16, 17, 18, 20, 24, 26, 27, 29, 30, 32, 34, 40, 44, 47, 50, 51, 53, 54, 55, 57, 61, 62, 64, 65, 67, 72, 73, 74, 75, 76, 77, 78], "septemb": 67, "sequel": 46, "sequenc": [14, 17, 27, 30, 51, 54, 66, 67], "sequenti": [13, 22, 26, 36, 38, 40, 50, 59, 67, 68, 73], "sequentialfeatureselector": [24, 40, 61], "ser": [29, 51, 53, 68, 71], "seri": [1, 2, 11, 14, 16, 17, 20, 24, 27, 29, 30, 34, 40, 47, 51, 53, 54, 57, 61, 66, 68, 70, 71], "serial": [22, 36, 38, 59], "seriou": [6, 20, 57, 64, 65, 68, 70, 80], "serv": [5, 11, 13, 23, 26, 37, 39, 46, 50, 60, 80], "server": 5, "servic": [22, 23, 36, 37, 38, 39, 44, 59, 60, 64, 68, 71], "session": [12, 13, 62, 73, 80], "set": [1, 7, 8, 9, 13, 15, 16, 17, 18, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 43, 46, 47, 48, 49, 50, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 73, 75, 76, 77, 78, 79], "set_config": [19, 22, 33, 36, 38, 56, 59], "set_index": [14, 15, 19, 20, 21, 27, 28, 33, 34, 35, 43, 47, 48, 51, 52, 56, 57, 58], "set_opt": [12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 63, 64, 74, 75, 76, 77, 78], "set_properti": [12, 25, 49], "set_se": 43, "set_titl": [15, 18, 20, 28, 32, 34, 43, 52, 55, 57, 66, 75, 78], "set_xlabel": [15, 18, 28, 32, 43, 52, 55, 62, 75], "set_ylabel": [15, 18, 28, 32, 43, 52, 55, 62, 75], "settl": [77, 78], "setup": [3, 7, 10, 12, 25, 74], "sev": [21, 23, 35, 37, 39, 48, 58, 60, 69], "sever": [10, 16, 18, 29, 32, 46, 53, 55, 62, 63, 65, 66, 67, 72, 80], "sex": [20, 22, 23, 24, 34, 36, 37, 38, 39, 40, 57, 59, 60, 61, 78, 79], "sexual": 80, "sfu": 65, "shall": [0, 65], "shallow": [22, 36, 38, 45, 46, 59], "shan": 65, "shap": 70, "shape": [13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 78], "shape_df": [14, 27, 51], "shape_dict": [14, 27, 51], "share": [0, 24, 40, 44, 61, 70, 80], "sharealik": 1, "sharex": [16, 29, 53], "she": [12, 25, 46, 49, 64, 65, 71], "shed": [21, 23, 35, 37, 39, 58, 60, 69], "sheet": [9, 70, 73], "shelf": [22, 36, 38, 59, 65, 77], "shell": [5, 9, 12, 25], "shelv": 71, "shift": 67, "shipyard": 44, "shit": 71, "shng": [21, 35, 58, 69], "shock": 46, "shoot": 46, "shop": 64, "short": [1, 10, 14, 19, 22, 33, 36, 51, 56, 59, 65, 80], "shorter": 68, "shorthand": [16, 29, 53], "shortli": 70, "shot": [24, 40, 46, 61], "should": [5, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 20, 23, 24, 26, 27, 28, 29, 30, 32, 34, 37, 39, 40, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 57, 60, 61, 62, 65, 66, 67, 68, 70, 71, 73, 74, 75, 76, 77, 79, 80], "shouldn": [20, 22, 34, 36, 38, 47, 57, 59, 65, 75], "show": [4, 7, 10, 12, 14, 16, 17, 19, 20, 21, 22, 24, 25, 27, 29, 30, 33, 34, 35, 36, 38, 40, 42, 43, 44, 46, 49, 51, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 70, 71, 73, 75, 77, 79], "show_nearest_neighbor": 43, "show_plot": 68, "showcas": 65, "shown": [7, 10, 12, 13, 15, 20, 22, 25, 26, 28, 34, 36, 38, 47, 49, 50, 52, 57, 59, 62, 63, 67, 69], "shrink": [19, 24, 33, 40, 56, 61, 69], "shuffl": [14, 27, 43, 46, 51, 66, 67], "si": [12, 25, 49], "sibl": [24, 40, 61], "sick": [62, 71], "sid": 71, "side": [6, 66, 69], "sift": 64, "sigma": [40, 66], "sigmoid": 40, "sign": [4, 21, 23, 31, 35, 37, 39, 45, 46, 48, 58, 60, 66, 75, 77, 79, 80], "signal": [14, 27, 51, 65], "signific": [11, 16, 29, 44, 53, 66, 69], "significantli": [17, 20, 30, 34, 54, 57, 64], "sigoptsearchcv": [19, 33, 56], "silhouett": 63, "silhouettevisu": [62, 63], "sim": [23, 37, 39, 60], "sim_word": 65, "simard": [23, 37, 39, 60], "similar": [1, 10, 13, 14, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 30, 32, 33, 34, 35, 36, 38, 40, 43, 47, 50, 51, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 68, 69, 72], "similarity_": 65, "similarli": [23, 35, 37, 39, 60, 62, 68], "simon_fras": 65, "simp": 67, "simpl": [1, 13, 15, 16, 20, 21, 22, 23, 24, 26, 28, 29, 34, 35, 36, 37, 38, 39, 40, 48, 50, 52, 53, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 73, 74, 78], "simplefilt": [22, 23, 36, 37, 38, 39, 48, 59, 60], "simpleimput": [16, 17, 18, 19, 20, 21, 22, 23, 24, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 48, 53, 54, 55, 56, 57, 58, 59, 60, 61, 67, 68, 69, 73, 76, 77, 78, 79], "simpleimputersimpleimput": [16, 17, 21, 22, 24, 29, 30, 35, 36, 38, 44, 53, 54, 58, 59, 61, 69], "simpler": [18, 19, 32, 33, 42, 55, 56, 70, 75], "simplest": [17, 30, 54], "simpli": [16, 24, 29, 40, 46, 53, 61, 62, 65], "simplic": [13, 17, 26, 30, 50, 54, 64], "simplist": [15, 23, 28, 37, 39, 43, 46, 52, 60, 75], "simul": [24, 40, 61], "sin": 8, "sinc": [5, 12, 18, 21, 23, 24, 25, 32, 35, 37, 39, 40, 43, 46, 48, 55, 58, 60, 61, 62, 64, 66, 67, 68, 69, 72, 73, 74], "singer_songwriter_bob_dylan": 65, "singl": [8, 15, 16, 18, 19, 20, 22, 23, 28, 29, 32, 33, 34, 36, 37, 38, 39, 40, 43, 47, 52, 53, 55, 56, 57, 59, 60, 63, 67, 68, 73, 74, 75, 77, 78], "sit": [44, 46, 80], "sitarist_ravi_shankar": 65, "site": [5, 12, 17, 26, 30, 43, 44, 50, 51, 54, 56, 60, 68, 72, 80], "situat": [6, 12, 20, 22, 25, 34, 38, 46, 47, 49, 57, 59, 62, 66, 68, 80], "six": [14, 22, 36, 38, 51, 59, 67, 70], "size": [12, 13, 14, 15, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 33, 34, 36, 37, 38, 39, 40, 43, 47, 49, 50, 51, 52, 54, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 73, 74, 75, 79, 80], "skeleton": 69, "skeptic": 69, "skew": [21, 35, 48, 58], "skill": [11, 36, 38, 59, 70], "skin": 71, "skip": [48, 78], "skip_check_arrai": 44, "skip_parameter_valid": 44, "skipna": 68, "sklearn": [1, 12, 14, 15, 18, 21, 24, 25, 27, 28, 31, 32, 35, 40, 42, 43, 45, 46, 47, 48, 49, 51, 52, 55, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79], "sklearn_gb": [22, 36, 38, 59], "sklearn_histgb": [22, 36, 38, 59], "sktime": 67, "skyblu": 67, "skyscrap": 67, "sl": 65, "slice": 8, "slide": [1, 9, 16, 29, 41, 53, 66, 80], "slightli": [17, 18, 20, 22, 30, 32, 34, 36, 38, 43, 44, 47, 54, 55, 57, 59, 68], "slipper": 69, "slope": [18, 32, 55], "sloppi": [16, 29, 53], "slot": 80, "slow": [15, 22, 24, 28, 36, 38, 40, 46, 52, 59, 61, 66], "slower": [22, 36, 38, 46, 59, 62], "slowest": 79, "sm": [12, 17, 25, 30, 49, 54], "smac": [19, 33, 56], "small": [10, 14, 15, 17, 19, 20, 21, 22, 23, 24, 27, 28, 30, 33, 35, 36, 37, 38, 39, 40, 43, 44, 48, 51, 52, 54, 56, 58, 59, 60, 61, 62, 64, 66, 68, 73, 75, 77, 79], "small_citi": [15, 28, 52], "small_train_df": [15, 28, 52], "smallalpha_coeff": [21, 35, 48, 58], "smaller": [15, 16, 17, 18, 20, 21, 22, 23, 24, 28, 29, 30, 32, 35, 36, 37, 39, 40, 42, 47, 48, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 67, 68, 69, 75, 77], "smallest": [18, 21, 32, 35, 48, 55, 58, 62, 63], "smart": [62, 69, 71], "smile": 71, "smooth": [15, 28, 40, 52, 75], "smoothli": 10, "smote": 34, "smote_pip": [20, 57], "sms_df": [12, 25, 49], "sn": [23, 37, 39, 60, 62, 63], "snake": [18, 32, 55, 66], "snake_length": [18, 32, 55], "snakes_df": [18, 32, 55], "snbf": 59, "snippet": [7, 12, 25], "snow": [12, 25, 49, 66], "snp": [24, 40, 61], "so": [0, 1, 4, 5, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80], "soap": 46, "social": [62, 63, 64, 67], "societ": 11, "societi": [20, 34, 57, 65, 78], "sofist": 75, "soft": [18, 22, 32, 36, 38, 44, 55, 59, 79], "softmax": 73, "softwar": [1, 5, 10, 68], "solar": 64, "sold": [8, 21, 35, 48, 58], "sole": [20, 34, 57, 63], "solid": 46, "solidifi": 73, "solut": [12, 14, 22, 25, 26, 27, 49, 50, 51, 59, 62, 68, 69, 70, 73, 80], "solv": [4, 12, 13, 15, 24, 25, 26, 27, 28, 40, 49, 50, 52, 61, 65, 69, 70, 75, 80], "solver": [20, 34, 40, 57], "some": [4, 6, 7, 8, 10, 12, 14, 15, 16, 17, 18, 21, 23, 25, 27, 28, 29, 30, 31, 32, 34, 35, 37, 39, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 76, 77, 78, 80], "someon": [12, 13, 14, 24, 25, 26, 27, 40, 46, 49, 50, 51, 61, 68, 69], "someth": [4, 7, 10, 13, 17, 20, 21, 22, 23, 26, 30, 34, 35, 37, 39, 46, 47, 48, 50, 54, 57, 58, 59, 60, 62, 67, 68, 69, 70, 73, 80], "sometim": [6, 13, 14, 17, 18, 19, 22, 23, 26, 27, 30, 32, 33, 36, 37, 39, 46, 50, 51, 54, 55, 56, 59, 60, 65, 69, 70], "somewhat": [21, 35, 46, 48, 58], "somewher": [12, 21, 25, 35, 49, 58], "song": [15, 16, 29, 52, 53, 64, 71, 77], "song_titl": [15, 16, 19, 29, 33, 52, 53, 56, 77], "soon": [12, 15, 16, 25, 28, 29, 46, 49, 52, 53, 67, 70], "sopha": [12, 25, 49], "sophist": [19, 23, 33, 37, 39, 56, 60, 65], "sorri": 46, "sort": [1, 5, 13, 14, 16, 23, 27, 29, 31, 33, 37, 39, 45, 46, 47, 50, 51, 53, 60, 64, 65, 66, 67, 70], "sort_index": [8, 19, 21, 33, 35, 48, 56, 58, 67], "sort_valu": [16, 17, 18, 19, 21, 22, 23, 24, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 45, 46, 48, 53, 54, 55, 56, 58, 59, 60, 61, 67, 68, 71, 79], "sound": [23, 24, 37, 39, 40, 46, 60, 61], "soundtrack": 65, "sourc": [10, 12, 13, 14, 15, 16, 17, 19, 22, 23, 24, 25, 26, 27, 29, 30, 33, 36, 38, 39, 40, 44, 49, 50, 51, 52, 53, 54, 56, 59, 60, 61, 62, 63, 64, 65, 66, 71, 74, 77, 80], "south": [17, 54], "space": [15, 18, 19, 24, 26, 28, 32, 33, 40, 52, 55, 56, 61, 62, 63, 65, 71, 80], "spaci": [24, 40, 61], "spacymoji": 71, "spam": [14, 20, 27, 34, 47, 51, 57, 62], "spam_predict": [12, 25, 49], "span": [65, 67], "spanish": [16, 29, 53], "spars": [12, 15, 18, 22, 25, 28, 32, 36, 38, 44, 46, 52, 55, 59, 64, 65, 73], "sparse_output": [16, 17, 20, 21, 22, 23, 29, 30, 34, 35, 36, 37, 38, 39, 44, 48, 53, 54, 57, 58, 59, 60, 67, 68, 69, 73, 78, 79], "spatial": [18, 32, 55], "speak": [5, 46, 70], "spearmint": [19, 33, 56], "speci": [15, 28, 43, 52, 73, 75], "special": [11, 12, 17, 25, 30, 46, 49, 54, 64, 65, 66, 67, 68, 75], "specialti": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60], "specif": [8, 11, 13, 14, 19, 20, 23, 26, 27, 33, 34, 37, 39, 44, 50, 51, 56, 57, 60, 62, 64, 65, 66, 67, 68, 69, 70, 73, 75, 77, 79], "specifi": [8, 13, 14, 17, 19, 20, 26, 27, 30, 33, 34, 43, 50, 51, 54, 56, 57, 62, 63, 66, 69, 70, 77, 79], "spectrogram": [24, 40, 61], "speech": [24, 40, 61, 65, 71], "speechi": [15, 16, 19, 29, 33, 52, 53, 56, 77], "speed": [8, 13, 22, 26, 31, 36, 38, 45, 46, 50, 59, 66, 70], "spell": [12, 25, 49], "spend": [12, 16, 24, 25, 29, 40, 44, 46, 49, 53, 61, 69, 71, 80], "spent": [6, 16, 24, 29, 40, 53, 61], "spheric": [63, 73], "spici": 62, "spini": 66, "spit": 66, "split": [11, 13, 15, 17, 18, 19, 21, 22, 24, 26, 28, 30, 31, 32, 33, 35, 36, 38, 45, 46, 47, 48, 50, 52, 54, 55, 56, 58, 59, 61, 64, 65, 68, 70, 71, 73, 78, 79], "split0_test_r2": [21, 35, 58], "split0_test_scor": [19, 33, 56], "split0_train_neg_mean_squared_error": [21, 35, 58], "split0_train_scor": [19, 33, 56], "split1_test_r2": [21, 35, 58], "split1_test_scor": [19, 33, 56], "split1_train_neg_mean_squared_error": [21, 35, 58], "split1_train_scor": [19, 33, 56], "split2_test_r2": [21, 35, 58], "split2_test_scor": [19, 33, 56], "split2_train_neg_mean_squared_error": [21, 35, 58], "split2_train_scor": [19, 33, 56], "split3_test_r2": [21, 35, 58], "split3_test_scor": [19, 33, 56], "split3_train_neg_mean_squared_error": [21, 35, 58], "split3_train_scor": [19, 33, 56], "split4_test_scor": [19, 33, 56], "split4_train_neg_mean_squared_error": [21, 35, 58], "split4_train_scor": [19, 33, 56], "spoil": 46, "spoken": [17, 30, 54], "sport": [65, 66, 67], "spot": [20, 21, 34, 35, 47, 48, 57, 58, 70, 75], "spotifi": [15, 52, 64, 77], "spotify_df": [15, 16, 19, 29, 33, 52, 53, 56, 77], "spotlight": [5, 10], "spous": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60], "spread": [46, 63], "spring": 46, "spring_month": 67, "sqft": [23, 37, 39, 60], "sqft_abov": [12, 13, 25, 42, 49, 50], "sqft_basement": [12, 13, 25, 42, 49, 50], "sqft_live": [12, 13, 25, 42, 49, 50], "sqft_living15": [12, 13, 25, 42, 49, 50], "sqft_lot": [12, 13, 25, 42, 49, 50], "sqft_lot15": [12, 13, 25, 42, 49, 50], "sqrt": [15, 21, 23, 28, 35, 37, 39, 48, 52, 58, 60, 64, 65], "squar": [8, 11, 13, 15, 18, 23, 26, 28, 32, 37, 39, 40, 50, 52, 55, 60, 64, 68, 69, 71, 73], "squash": [18, 32, 55, 66], "squeez": [8, 44, 68], "src": [20, 27, 34, 51, 57], "sse": 67, "ssw": 67, "st": [67, 71], "st_slope": 79, "stabil": 10, "stabl": [14, 20, 22, 27, 34, 36, 38, 44, 51, 57, 59, 75], "stack": [7, 11, 39, 44, 70, 73], "stack_method": 79, "stacking_model": [22, 36, 38, 59, 79], "stacking_model_tre": [22, 36, 38, 59], "stackingclassifi": [22, 36, 38, 59, 79], "stackingregressor": [22, 36, 38, 59], "staff": 6, "stai": [12, 20, 25, 34, 47, 57, 68], "stakehold": [11, 69, 70], "stale": 62, "stand": [15, 19, 28, 33, 46, 52, 56, 65, 70], "standard": [4, 6, 14, 16, 19, 22, 23, 24, 27, 29, 33, 36, 37, 38, 39, 40, 51, 53, 56, 59, 60, 61, 65, 70], "standardscal": [17, 18, 19, 20, 21, 22, 23, 24, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 47, 48, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 71, 73, 76, 77, 78, 79], "standardscalerstandardscal": [16, 17, 19, 20, 21, 22, 24, 29, 30, 33, 34, 35, 36, 38, 44, 53, 54, 56, 57, 58, 59, 61, 66, 69, 71], "stanford": 65, "star": [15, 28, 52, 62, 64, 71], "start": [7, 8, 10, 13, 14, 15, 20, 22, 23, 24, 26, 27, 28, 34, 36, 37, 38, 39, 40, 43, 44, 46, 47, 50, 51, 52, 57, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 73, 74, 75, 76, 77, 78], "startswith": [23, 31, 37, 39, 40, 47, 60], "starttim": 67, "stat": [19, 33, 56, 68, 77], "state": [6, 8, 14, 20, 22, 23, 27, 34, 36, 37, 38, 39, 51, 57, 59, 60, 64, 65, 70, 71, 78], "statement": [7, 14, 15, 16, 17, 18, 19, 20, 21, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 40, 51, 52, 53, 54, 55, 56, 57, 58, 61, 66, 68, 69], "static": [12, 25, 70], "station": [46, 67], "statist": [1, 9, 11, 13, 18, 23, 26, 32, 37, 50, 55, 60, 64, 65, 68], "statistician": [15, 28, 52], "statlib": [18, 32, 55], "statsmodel": [67, 68], "statu": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "status_marri": [23, 37, 39, 60], "status_nev": [23, 37, 39, 60], "status_separ": [23, 37], "std": [14, 15, 16, 20, 21, 27, 28, 29, 34, 35, 40, 42, 43, 44, 51, 52, 53, 57, 58, 66, 67, 71, 72], "std_cv_error": [14, 27, 51], "std_cv_score": [15, 28, 43, 52], "std_fit_tim": [19, 21, 33, 35, 56, 58], "std_score": [14, 16, 27, 29, 40, 51, 53, 71], "std_score_tim": [19, 21, 33, 35, 56, 58], "std_test_neg_mean_squared_error": [21, 35, 58], "std_test_scor": [14, 19, 27, 33, 51, 56], "std_train_error": [14, 27, 51], "std_train_neg_mean_squared_error": [21, 35, 58], "std_train_scor": [14, 15, 19, 27, 28, 33, 43, 51, 52, 56], "stdki": 68, "steal": 46, "stem": 65, "step": [7, 12, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 75, 77, 79, 80], "stereotyp": 65, "steroid": 46, "stick": [13, 45, 46, 67], "still": [4, 10, 19, 20, 21, 22, 24, 26, 33, 34, 35, 36, 38, 40, 46, 56, 57, 58, 59, 61, 62, 67, 68, 71, 75, 76, 77, 78], "stipul": 69, "stochast": [24, 40, 61, 62], "stock": [12, 25, 49, 67], "stomach": 46, "stop": [8, 42, 44, 46, 62, 65, 66, 68, 75], "stop_word": [19, 20, 31, 33, 44, 45, 46, 56, 57, 65, 70, 71, 77], "stopword": 65, "storag": [15, 52], "store": [7, 8, 15, 16, 17, 19, 20, 22, 23, 28, 29, 30, 33, 34, 36, 37, 46, 47, 52, 53, 54, 56, 57, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71], "stori": [21, 22, 35, 36, 46, 48, 58, 59, 71], "storylin": 65, "str": [19, 23, 31, 33, 37, 39, 43, 47, 56, 60, 65, 67, 68, 71], "straight": [46, 68, 70], "straightforward": [23, 37, 39, 60], "strain": 7, "strang": [23, 37, 39, 48, 60, 68], "strata": 68, "strategi": [13, 15, 16, 17, 20, 21, 23, 26, 28, 29, 30, 34, 35, 37, 39, 44, 47, 48, 50, 52, 53, 54, 57, 58, 60, 62, 64, 67, 68, 69, 70, 73, 74, 78], "stratif": 68, "stratifi": 68, "stratifiedkfold": [14, 20, 27, 34, 51, 57], "stream": 68, "streamingmovi": 68, "streamingmovies_no": 68, "streamingmovies_y": 68, "streamingtv": 68, "streamingtv_no": 68, "streamingtv_y": 68, "street": [21, 23, 35, 37, 39, 58, 60, 69], "street_grvl": [21, 35, 37, 58], "street_pav": [21, 35, 37, 58], "strength": [40, 65, 73], "stress": 62, "strftime": [67, 68], "string": [8, 10, 15, 20, 21, 22, 23, 28, 34, 35, 36, 37, 38, 39, 44, 47, 48, 52, 57, 58, 59, 60, 65, 67, 68, 75, 79], "strip": [23, 37, 39, 60, 66], "stroke": 46, "strong": [22, 36, 38, 59, 68, 73], "stronger": [22, 36, 38, 59], "strongli": [22, 36, 38, 59], "struck": 46, "structur": [8, 62, 65, 66], "struggl": [62, 67], "stuart": [1, 22, 36, 38, 59], "stuck": [4, 8], "student": [1, 4, 5, 6, 7, 11, 12, 13, 18, 20, 21, 23, 24, 25, 26, 32, 34, 35, 37, 39, 40, 48, 49, 50, 55, 57, 58, 60, 61, 62, 63, 64, 66, 70, 71, 80], "studi": [12, 17, 24, 25, 30, 40, 49, 54, 61, 65, 68], "stuff": [15, 28, 43, 46, 52, 66, 68], "stump": [13, 14, 15, 22, 26, 27, 28, 38, 42, 50, 51, 52, 59, 74], "stun": 46, "stunningli": 46, "stupid": [46, 71], "style": [21, 24, 35, 40, 48, 49, 58, 61, 62, 64, 65, 66, 70, 71], "sub": [31, 33, 45, 46, 56, 62, 65, 68, 70, 73], "subdirectori": [23, 37, 60, 70], "subgroup": 68, "subject": [0, 1, 68, 80], "sublicens": 0, "submiss": [3, 80], "submit": [1, 8, 16, 25, 70, 80], "subplot": [14, 15, 18, 20, 27, 28, 32, 34, 43, 51, 52, 55, 57, 62, 66, 68, 69, 75, 78], "subplot_kw": [14, 27, 43, 51], "subprocess": [21, 35, 47, 58], "subscrib": 68, "subscript": [67, 68], "subset": [13, 14, 19, 22, 26, 27, 33, 36, 38, 43, 50, 51, 56, 59, 66, 67, 72, 75], "substanti": 0, "substitut": 0, "subtl": 65, "subtleti": [14, 21, 27, 35, 51, 58], "subtract": [15, 20, 23, 25, 28, 37, 39, 47, 52, 57, 60], "suburb": 71, "subword": 65, "succe": [24, 40, 46, 61, 80], "success": [5, 8, 10, 12, 20, 22, 25, 36, 38, 49, 57, 59, 64, 65, 66, 67, 70], "successfulli": [10, 12, 25, 49, 71], "suddenl": 46, "suddenli": 46, "sudo": 5, "suei": [33, 56], "suffer": [19, 33, 46, 56], "suffici": [7, 65], "suggest": [0, 1, 13, 26, 45, 46, 48, 50, 64, 68, 70], "suicid": 65, "suit": [29, 46, 64], "suitabl": [10, 11, 12, 25, 42, 49, 62, 64, 70, 73, 79], "sultan": 65, "sum": [8, 15, 16, 17, 18, 22, 23, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 44, 52, 53, 54, 55, 59, 60, 62, 66, 71], "sum_": [15, 21, 28, 35, 48, 52, 58, 62, 65, 66], "sum_i": [23, 37, 39, 40, 60, 65], "sum_j": 40, "sum_prob_ex1_class_0": [22, 36, 38, 59], "sum_prob_ex1_class_1": [22, 36, 38, 59], "summar": [1, 12, 18, 20, 21, 25, 32, 34, 35, 47, 49, 55, 57, 58, 62, 65, 70], "summari": [0, 72, 73, 75], "summary_plot": [23, 37, 39, 60], "summat": [36, 38, 59, 69], "summer": [46, 64, 67], "summer_month": 67, "sun": [65, 67], "sundai": 67, "sundial": 66, "sunshin": [19, 67], "sunstrum": [1, 80], "super": [17, 30, 54, 73], "superfici": [15, 28, 52], "superior": 11, "supermarket": 71, "supervis": [11, 16, 17, 19, 20, 21, 24, 29, 30, 33, 34, 35, 40, 44, 47, 48, 53, 54, 56, 57, 58, 61, 63, 65, 67, 68, 73, 80], "suppli": 80, "support": [10, 13, 16, 20, 22, 23, 24, 26, 29, 34, 36, 37, 38, 39, 40, 43, 44, 50, 53, 57, 59, 60, 61, 63, 65, 69, 71, 72, 75, 80], "support_": [15, 24, 28, 40, 52, 61], "suppos": [12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 69, 73, 74], "suppress": 8, "suprem": 65, "supr\u00eam": 65, "sure": [4, 7, 8, 10, 13, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 34, 35, 36, 37, 38, 47, 51, 52, 54, 57, 58, 59, 60, 63, 66, 67, 69, 70, 75, 78, 79, 80], "surfac": 26, "surgeri": 68, "surpris": [23, 37, 39, 46, 60, 64], "surprisingli": [17, 18, 30, 32, 54, 55], "surround": [4, 11, 46, 69], "survei": [44, 62], "surviv": [1, 2, 11, 69, 70], "survival_function_": 68, "suscept": [63, 70], "suspect": [19, 33, 56], "suspens": 46, "svc": [15, 16, 17, 18, 19, 22, 23, 24, 28, 29, 30, 32, 33, 36, 37, 38, 39, 40, 43, 44, 52, 53, 54, 55, 56, 59, 60, 61, 66, 75, 76, 77, 79], "svc__c": [19, 33, 56, 77], "svc__degre": 19, "svc__gamma": [19, 33, 56, 77], "svc__kernel": 19, "svc_pipe": [19, 33, 56], "svc_pred": [20, 34, 47, 57], "svcsvc": [17, 19, 20, 30, 33, 34, 54, 56, 57], "svm": [1, 14, 16, 17, 19, 22, 23, 24, 27, 29, 30, 33, 36, 37, 38, 39, 40, 44, 51, 53, 54, 56, 59, 60, 61, 66, 67, 69, 70, 72, 73, 75, 76, 77, 79], "svm_estim": [20, 57], "svr": [15, 23, 28, 37, 39, 52, 54, 60, 69], "svr_c_pipe": 54, "svr_pipe": 54, "sw": 67, "swai": [12, 49], "swamp": [15, 28, 52], "swan": 66, "swcarpentri": 9, "sweep": [20, 34, 47, 57], "sweet": [46, 71], "switch": [13, 23, 37, 39, 60, 62, 67, 68, 69], "swng": [1, 80], "sy": [12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79], "sydnei": 67, "syllabu": [3, 7, 12, 13, 15, 16, 17, 25], "symbol": [26, 50], "symmetri": [24, 40, 61], "sync": 5, "synonym": 65, "synopsi": 65, "syntact": 65, "syntax": [4, 8, 12, 24, 25, 40, 49, 61, 68], "synthet": [24, 40, 61, 72], "system": [1, 2, 4, 5, 6, 10, 11, 12, 14, 15, 17, 20, 23, 25, 27, 34, 37, 39, 43, 47, 49, 51, 52, 54, 57, 60, 62, 67, 69, 70, 78], "systemat": [13, 19, 23, 26, 33, 37, 39, 50, 54, 56, 60, 65], "t": [1, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 79], "t2a": 80, "t2b": 80, "t2c": 80, "t2d": 80, "t2e": 80, "t2f": 80, "t2g": 80, "t2h": 80, "t2i": 80, "t2j": 80, "t2k": 80, "ta": [7, 12, 21, 23, 25, 35, 37, 39, 48, 49, 58, 60, 69, 70, 74, 75, 76, 77, 78, 79], "tab": [12, 25], "tabbi": [12, 25, 49, 66], "tabl": [7, 36, 44, 79], "tabular": [8, 12, 25, 43, 49, 66, 67], "tackl": [14, 16, 20, 27, 29, 51, 53, 57, 63, 75], "taco": [24, 40, 61], "tag": [4, 65, 71], "tail": [8, 67], "tailor": [11, 62, 69, 70], "take": [2, 4, 5, 6, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 79, 80], "taken": [67, 72, 77, 80], "talk": [13, 14, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 47, 48, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 70, 71, 72, 73, 80], "tall": 65, "target": [14, 15, 16, 18, 19, 20, 22, 23, 24, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 43, 44, 45, 46, 51, 52, 53, 55, 56, 57, 59, 60, 61, 64, 66, 67, 68, 69, 70, 73, 75, 76, 77, 78, 79], "target_column": [22, 23, 36, 37, 38, 39, 59, 60, 68, 79], "target_nam": [20, 34, 47, 57], "target_names_toi": [20, 57], "target_tag": 44, "tariff": 65, "task": [11, 16, 17, 18, 19, 23, 24, 29, 30, 32, 33, 37, 39, 40, 42, 43, 53, 54, 55, 56, 60, 61, 62, 64, 66, 67, 68, 69, 70, 71, 73, 77], "tast": [44, 62, 64], "tasti": 44, "taught": [17, 30, 54, 65, 80], "tax": 69, "tba": 1, "teach": [4, 12, 16, 25, 29, 49, 53, 65, 73], "team": [4, 8, 12, 23, 25, 36, 37, 38, 39, 49, 59, 60, 65, 79], "tech": [15, 20, 23, 34, 37, 52, 57, 60], "technic": [46, 69, 70, 80], "techniqu": [1, 11, 12, 15, 19, 24, 28, 33, 34, 40, 46, 47, 52, 56, 61, 64, 66, 68, 70, 72, 73], "technolog": 0, "technologi": 65, "techsupport": 68, "techsupport_no": 68, "techsupport_y": 68, "ted": 62, "tediou": 63, "telco": 68, "telecom": 68, "telephon": 65, "tell": [14, 15, 16, 18, 20, 23, 24, 27, 29, 32, 34, 37, 39, 40, 46, 47, 51, 52, 53, 55, 57, 60, 61, 64, 65, 67, 68, 69, 70, 75, 77], "temp3pm": 67, "temp9am": 67, "temperatur": [13, 26, 50], "templat": 70, "tempo": [15, 16, 19, 29, 33, 52, 53, 56, 77], "tempor": [68, 73], "tend": [14, 15, 18, 22, 24, 27, 28, 32, 36, 38, 40, 51, 52, 55, 59, 61, 64, 67, 68, 80], "tendenc": [14, 27, 51], "tensor": [43, 66], "tensorflow": [10, 23, 37, 39, 60, 66], "tent": 12, "tenur": [68, 69, 73], "tenure_lm": 68, "tenure_predict": 68, "term": [0, 2, 13, 15, 17, 18, 20, 23, 24, 26, 28, 30, 32, 34, 37, 39, 40, 47, 50, 52, 54, 55, 57, 60, 61, 64, 65, 68, 69, 70, 73], "termin": [5, 10, 13, 50, 62, 70], "terminologi": [14, 20, 47, 51, 57, 73, 74], "terrac": 66, "terribl": [21, 35, 46, 48, 58, 64], "terribli": 46, "territori": 80, "tesoro": [33, 56], "test": [1, 7, 8, 10, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 63, 68, 69, 70, 72, 73, 75, 77, 78, 79, 80], "test_accuraci": [20, 34, 57], "test_average_precis": [20, 34, 57], "test_df": [12, 16, 18, 20, 21, 22, 23, 24, 25, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 49, 53, 54, 55, 57, 58, 59, 60, 61, 67, 68, 69, 70, 71, 76, 78, 79], "test_df_churn": 68, "test_df_nan": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "test_df_sort": 67, "test_df_surv": 68, "test_exampl": [22, 36, 38, 59], "test_f1": [20, 34, 57], "test_format": [15, 28, 52], "test_g50k": [22, 36, 38, 59], "test_idx": 43, "test_imag": [12, 25, 49, 66], "test_l50k": [22, 36, 38, 59], "test_mape_scor": [21, 35, 58], "test_nam": 68, "test_neg_mean_squared_error": [21, 35, 58], "test_neg_root_mean_square_error": [21, 35, 58], "test_point": [15, 28, 52, 72], "test_precis": [20, 34, 57], "test_r2": [21, 35, 58], "test_recal": [20, 34, 57], "test_roc_auc": [20, 34, 57], "test_sampl": 79, "test_scor": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 67, 68, 71, 75], "test_shap_valu": [23, 37, 39, 60], "test_siz": [12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 66, 67, 69, 70, 71, 72, 75, 76, 77, 78, 79], "test_sklearn": [21, 35, 58], "test_statist": 68, "test_x": 68, "testabl": 25, "text": [1, 7, 11, 12, 13, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 49, 50, 55, 56, 57, 58, 59, 60, 61, 64, 66, 69, 70, 73, 77], "text_feat": [19, 33, 56, 77], "text_featur": 71, "text_pip": 44, "text_pp": 65, "text_transform": 44, "textbook": [3, 9, 69], "textrm": [14, 27, 51], "textual": 11, "textur": [24, 40, 61], "tf": [17, 30, 54], "tfidfvector": [18, 32, 45, 46, 55], "th": [12, 18, 25, 32, 55, 64], "thai": 44, "than": [6, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 34, 35, 36, 37, 38, 39, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 72, 74, 75, 78, 79, 80], "thank": [12, 25, 46, 49, 65, 75], "thankfulli": 67, "theater": 46, "thei": [1, 7, 8, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 37, 39, 40, 44, 46, 47, 48, 50, 51, 52, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75, 77, 78, 79, 80], "theirs": 65, "them": [1, 2, 4, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 46, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75, 77, 78, 79, 80], "theme": 65, "themselv": [46, 62, 63, 65], "theoret": [16, 20, 22, 29, 34, 36, 38, 53, 57, 59, 73], "theori": [23, 37, 39, 60], "thepopbreak": 71, "therefor": [25, 46, 75], "thermostat": [13, 26, 50], "thi": [0, 1, 2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 18, 19, 20, 21, 22, 24, 26, 27, 28, 31, 32, 33, 34, 35, 36, 38, 40, 43, 45, 46, 48, 50, 51, 52, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "thick": [44, 46, 62], "thicker": 46, "thin": 46, "thing": [1, 5, 7, 8, 12, 13, 14, 15, 19, 20, 23, 24, 25, 26, 27, 28, 31, 33, 34, 37, 39, 40, 45, 46, 47, 48, 50, 51, 52, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 75, 79], "think": [4, 12, 13, 14, 15, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 30, 32, 34, 35, 37, 39, 40, 44, 46, 48, 49, 50, 51, 52, 54, 55, 57, 58, 60, 61, 62, 64, 66, 67, 68, 69, 70, 73, 74, 75, 77, 78], "third": 63, "thk": [12, 25, 49], "thorough": [10, 79], "thoroughli": 73, "those": [5, 8, 10, 11, 12, 16, 21, 22, 23, 25, 29, 35, 36, 37, 38, 39, 48, 53, 58, 59, 60, 64, 65, 68, 69, 70, 80], "though": [14, 17, 18, 26, 27, 30, 32, 38, 44, 46, 51, 54, 55, 62, 63, 64, 70, 71], "thought": [4, 15, 28, 46, 52, 60, 68, 73], "thousand": [18, 32, 55, 63, 64], "thrasher": 65, "threahold": [24, 61], "threaten": 71, "three": [8, 13, 16, 18, 20, 22, 23, 24, 29, 32, 34, 36, 37, 38, 39, 40, 43, 47, 50, 53, 55, 57, 59, 60, 61, 62, 63, 65, 66, 67, 72, 73, 78, 80], "thresh": 8, "threshold": [13, 18, 22, 24, 26, 32, 36, 38, 40, 50, 55, 59, 61, 63, 65, 68], "thresholds_lr": [20, 34, 47, 57], "thresholds_svc": [20, 34, 47, 57], "through": [1, 7, 10, 12, 13, 20, 21, 24, 25, 26, 34, 35, 40, 46, 47, 48, 50, 57, 58, 61, 63, 64, 65, 66, 69, 80], "throughout": [14, 27, 46, 51, 69], "throught": [25, 80], "throw": [17, 30, 54, 66, 68, 69, 73], "thu": [1, 6, 12, 19, 33, 56, 67, 68, 80], "thumb": [13, 26, 50, 71], "thursdai": [12, 80], "ti": [17, 30, 54], "tianyu": [1, 80], "tick": 67, "tick_label": [39, 60], "tick_param": 62, "tiffin": 65, "tiger": [12, 25, 49, 66], "tight": [15, 28, 43, 52, 63, 75], "tight_layout": [66, 69], "tightrop": [15, 28, 43, 52, 75], "tile": [23, 39, 60], "till": [15, 28, 52, 65, 68], "timber": 65, "time": [1, 2, 4, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 74, 75, 77, 78, 79, 80], "time_diff": 67, "time_signatur": [15, 16, 19, 29, 33, 52, 53, 56, 77], "timedelta": 67, "timeit": [8, 72], "timelin": 69, "timeseri": [66, 67], "timeseriessplit": [67, 68, 73], "timestamp": 67, "timezon": [1, 68], "tinder": 64, "tini": [7, 14, 20, 27, 34, 47, 51, 57, 63], "tip": 65, "tire": 71, "titan": 64, "titi": [12, 25, 49], "titl": [7, 14, 15, 18, 21, 24, 27, 28, 32, 35, 40, 42, 43, 46, 51, 52, 55, 58, 61, 63, 66, 67, 68, 69, 75], "tldr": [12, 25], "tmp": [39, 44], "tn": [20, 34, 47, 57], "to_datetim": [42, 67], "to_html": [12, 13, 14, 25, 27, 49, 50, 51], "to_list": 47, "to_notebook_ifram": [21, 35, 58], "to_numpi": [15, 23, 28, 52, 64, 67], "to_str": [12, 25, 49, 66], "toarrai": [17, 23, 30, 31, 37, 39, 45, 46, 54, 60, 67], "tobago": [22, 23, 36, 37, 38, 39, 59, 60], "todai": [13, 26, 40, 50, 64, 66, 67, 68, 70, 73, 79], "todens": [23, 24, 37, 39, 40, 60, 61], "togeth": [5, 8, 12, 13, 15, 16, 17, 25, 26, 28, 29, 30, 44, 50, 52, 53, 54, 62, 65, 75], "toi": [8, 14, 15, 24, 27, 28, 40, 51, 52, 61, 62, 63, 64, 67, 73], "toilet": [66, 71], "token": [7, 25, 71, 80], "token_pattern": [17, 30, 54], "tol": [20, 24, 34, 40, 57, 61, 69], "told": [5, 80], "tolist": [12, 13, 14, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 30, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 54, 55, 57, 58, 59, 60, 61, 62, 64, 67, 68, 71], "tom": 46, "tomasbeuzen": 8, "tomorrow": [13, 16, 17, 26, 50, 67, 68, 73], "ton": [19, 33, 46, 56], "tone": 71, "too": [6, 7, 14, 15, 17, 19, 21, 22, 23, 27, 28, 29, 30, 33, 35, 36, 37, 38, 39, 43, 46, 48, 51, 52, 54, 56, 58, 59, 60, 65, 67, 68, 69, 70, 75, 77, 80], "took": [46, 67], "tool": [1, 7, 8, 10, 11, 17, 18, 20, 21, 23, 30, 31, 32, 34, 35, 37, 39, 45, 46, 47, 48, 54, 55, 57, 58, 60, 63, 64, 66, 67, 68, 70, 73, 80], "toolbox": [15, 22, 28, 36, 38, 52, 59, 65], "toolkit": 65, "top": [13, 17, 19, 20, 26, 30, 31, 33, 34, 45, 46, 47, 50, 54, 56, 57, 63, 67, 69, 70], "topi": 65, "topic": [1, 2, 8, 11, 13, 20, 21, 26, 35, 48, 50, 57, 58, 62, 64, 66, 70, 73, 80], "topic2vec": 65, "topics_per_chunk": 65, "topn": [12, 25, 49, 66], "torch": [43, 66], "torchvis": [12, 25, 43, 49, 66], "toronto": [65, 69, 71], "tort": 0, "total": [1, 8, 13, 16, 17, 20, 21, 22, 23, 24, 26, 29, 30, 34, 35, 36, 37, 38, 39, 40, 47, 48, 50, 53, 54, 57, 58, 59, 60, 61, 65, 67, 68, 69], "total_bedroom": [16, 24, 29, 40, 53, 54, 61, 76], "total_bilirubin": [12, 25, 49], "total_protien": [12, 25, 49], "total_room": [16, 24, 29, 40, 53, 54, 61, 76], "total_second": 67, "totalbsmtsf": [21, 23, 35, 37, 39, 48, 58, 60, 69], "totalcharg": 68, "totem": 66, "totensor": [43, 66], "toti": [0, 1, 65, 80], "totrmsabvgrd": [21, 23, 35, 37, 39, 48, 58, 60, 69], "touch": 70, "toward": [18, 23, 31, 32, 37, 39, 45, 46, 55, 60, 65, 78, 80], "towardsdatasci": [66, 68], "town": 71, "townsvil": 67, "toy_clust": 65, "toy_clust_df": 62, "toy_df": [17, 30, 54, 65], "toy_lda_data": 65, "toy_movie_feat": 64, "toy_rat": 64, "toy_spam": [17, 30, 54], "toy_x": 65, "tp": [20, 34, 47, 57], "tpot": [19, 33, 56], "tpr": [20, 34, 47, 57], "tpr_lr": [20, 34, 47, 57], "tpr_svc": [20, 34, 47, 57], "tr_score": [42, 75], "traceback": [4, 8, 17, 30, 44, 54, 68], "track": [1, 17, 30, 54, 70, 80], "trade": [11, 18, 20, 24, 32, 34, 40, 47, 55, 57, 61, 62, 73], "tradeoff": [15, 16, 18, 21, 24, 28, 29, 32, 35, 40, 42, 48, 52, 53, 55, 58, 61, 62, 66], "tradit": [12, 25, 49, 64, 66, 68, 80], "tradition": 80, "trail": 8, "train": [7, 15, 16, 19, 21, 22, 23, 24, 28, 29, 31, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 52, 53, 56, 58, 59, 60, 61, 62, 64, 65, 68, 71, 72, 73, 74, 75, 76, 77, 79], "train_accuraci": [20, 34, 57], "train_dataload": 66, "train_df": [12, 16, 18, 20, 21, 22, 23, 24, 25, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 49, 53, 54, 55, 57, 58, 59, 60, 61, 67, 68, 69, 70, 71, 76, 78, 79], "train_df_churn": 68, "train_df_nan": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "train_df_ord": 67, "train_df_sort": 67, "train_df_surv": 68, "train_df_surv_not_churn": 68, "train_dir": 43, "train_f1": [20, 34, 57], "train_flatten": 66, "train_for_usr": 64, "train_load": 66, "train_mape_scor": [21, 35, 58], "train_mat": 64, "train_mat_imp": 64, "train_neg_mean_squared_error": [21, 35, 58], "train_neg_root_mean_square_error": [21, 35, 58], "train_precis": [20, 34, 57], "train_r2": [21, 35, 58], "train_recal": [20, 34, 57], "train_scor": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 67, 68, 71, 75], "train_shap_valu": [23, 37, 39, 60], "train_sklearn": [21, 35, 58], "train_test_split": [12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79], "train_x": 64, "transact": [13, 20, 26, 34, 47, 50, 57, 67, 69, 78], "transfer": [68, 70], "transfer_learning_tutori": 66, "transform": [0, 15, 19, 20, 22, 23, 28, 31, 33, 34, 36, 37, 38, 39, 43, 44, 45, 46, 47, 52, 56, 57, 59, 60, 63, 65, 66, 67, 68, 70, 71, 73, 75, 76], "transformed_exampl": [22, 36, 38, 59], "transformed_oh": [16, 29, 53], "transformedtargetregressor": [21, 24, 35, 40, 48, 58, 61, 69, 73], "transformedtargetregressortransformedtargetregressor": [21, 35, 58], "translat": [1, 9, 12, 25, 49], "transpar": [20, 34, 47, 57, 73], "transpos": [24, 40, 43, 61, 66], "trasform": [16, 29, 53], "trash": 74, "traumat": 80, "treat": [8, 16, 17, 20, 21, 29, 30, 34, 35, 48, 51, 53, 54, 57, 58, 64, 67, 68, 69, 71, 73, 78], "treati": 80, "treatment": [17, 30, 54], "tree": [1, 2, 14, 15, 16, 17, 18, 19, 21, 24, 27, 28, 29, 30, 31, 32, 33, 35, 40, 43, 45, 46, 48, 51, 52, 53, 54, 55, 56, 58, 61, 63, 66, 67, 68, 70, 72, 73, 74, 76, 77, 79], "tree1": [22, 36, 59], "tree2": [22, 36, 59], "tree3": [22, 36, 59], "tree_numeric_transform": [23, 37, 39, 60], "treecolumntransform": [22, 36, 38], "treeexplain": [23, 37, 39, 60], "trend": [11, 68, 73], "tri": [22, 23, 26, 36, 37, 38, 39, 40, 46, 59, 60, 69, 72, 77, 78, 79], "trial": [19, 33, 56, 68], "triangl": [15, 28, 52, 62], "trick": [5, 21, 35, 48, 58], "tricki": [17, 19, 23, 30, 33, 37, 39, 54, 56, 60, 64], "trigger": [15, 28, 52], "trigram": 65, "trivial": 63, "troubl": [10, 46], "true": [8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 78, 79], "truli": [21, 35, 58, 65], "truncat": 63, "truncate_mod": 63, "truncation_mod": 63, "trust": [12, 16, 17, 19, 20, 21, 22, 23, 24, 25, 29, 30, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 49, 53, 54, 56, 57, 58, 59, 60, 61, 64, 66, 69, 71], "trustworthi": [63, 79], "truth": [22, 24, 32, 36, 38, 40, 59, 61, 62, 63, 64, 67], "try": [1, 4, 5, 8, 10, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 73, 74, 75, 77, 78, 79, 80], "tsa": 67, "tscv": 67, "tslearn": 67, "tsunami": [12, 49], "ttr": [21, 35, 48, 58], "ttr_pipe": [21, 35, 48, 58], "tue": [1, 12, 13, 67, 80], "tuesdai": [1, 12, 24, 25, 40, 61, 67, 80], "tuggeranong": 67, "tumor": 73, "tune": [14, 19, 22, 27, 33, 36, 38, 40, 42, 51, 56, 59, 63, 64, 66, 69, 70, 77, 79], "turn": [4, 14, 27, 43, 46, 51, 65, 66, 68, 76, 77, 80], "tusker": 66, "tutori": [1, 4, 5, 9, 10, 12, 25, 64, 66, 70, 73, 80], "tweak": [15, 28, 43, 52, 75], "tweet": [65, 71], "tweetat": 71, "twice": [8, 14, 17, 18, 30, 32, 51, 54, 55], "twinx": 69, "twist": [46, 65], "twitter": 65, "twitter_allowed_char": 71, "two": [4, 6, 7, 8, 9, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 36, 37, 38, 39, 40, 44, 47, 50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 76, 78, 80], "two_citi": [15, 28, 52], "two_song": [16, 29, 53], "two_songs_subset": [16, 29, 53], "tx": [18, 32, 55, 71], "tx_i": 69, "txt": [12, 25, 49, 66, 70], "typ": [21, 23, 35, 37, 39, 48, 58, 60, 69], "type": [4, 8, 10, 11, 13, 15, 16, 17, 19, 22, 24, 26, 29, 30, 31, 33, 36, 38, 40, 44, 50, 52, 53, 54, 56, 59, 61, 63, 64, 65, 66, 70, 73, 75, 76, 77], "typeerror": 68, "typic": [2, 7, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 62, 64, 67, 69, 70, 77], "u": [4, 10, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 74, 75, 76, 77, 79], "u6": [13, 26, 50], "u_1": [15, 28, 52], "u_2": [15, 28, 52], "u_i": [15, 28, 52], "u_n": [15, 28, 52], "ubc": [0, 4, 5, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 74, 75, 76, 77, 78, 79, 80], "ubc_img": 66, "ubc_okanagan": 65, "ubco": 65, "ubyssei": 65, "ucsb": 9, "ud036": 9, "udac": 9, "ufunc": [21, 35, 58], "ufv": 65, "uint8": 43, "ultim": [4, 14, 27, 51, 69], "ultralyt": 66, "uluru": 67, "umbrella": 64, "un": [21, 35, 48, 58, 68], "unabl": [12, 16, 17, 19, 20, 21, 22, 23, 24, 25, 29, 30, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 49, 53, 54, 56, 57, 58, 59, 60, 61, 63, 66, 68, 69, 71, 80], "unambigu": 65, "unassign": [62, 63], "unassum": 46, "unbalanc": 78, "unbias": [20, 34, 57, 78], "unced": 80, "uncertain": [18, 32, 55, 79], "uncertain_indic": 79, "uncertainti": [18, 20, 32, 34, 47, 55, 57, 69, 70], "unchang": [23, 37, 39, 60], "uncia": [12, 25, 49, 66], "uncomfort": 64, "uncorrel": [23, 37, 39, 60], "undead": 46, "under": [0, 1, 7, 13, 14, 21, 27, 35, 44, 46, 48, 50, 51, 58, 65, 66, 68, 70], "under_sampl": [20, 57], "underestim": 68, "underfit": [15, 18, 19, 28, 32, 33, 42, 43, 52, 55, 56, 66, 75, 77], "underli": [2, 23, 24, 37, 39, 40, 60, 61, 62], "underneath": 7, "underpredict": [21, 35, 58], "underr": 46, "undersampl": 34, "undersample_pip": [20, 57], "understand": [0, 1, 4, 7, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 28, 30, 32, 34, 35, 36, 37, 39, 40, 42, 43, 46, 47, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 73, 74, 78, 80], "understood": [20, 57], "unemploi": 68, "unexpect": [17, 18, 19, 30, 32, 33, 54, 55, 56, 65], "unexplain": [21, 35, 48, 58], "unf": [21, 23, 35, 37, 39, 48, 58, 60, 69], "unfinish": [21, 35, 48, 58], "unfortun": [6, 19, 23, 33, 39, 56, 60, 62, 63, 77], "unfunni": 46, "uniform": [19, 20, 33, 34, 56, 57, 63, 77], "unimport": [19, 23, 33, 37, 39, 56, 60], "uninstal": 10, "unintent": 46, "uninterpret": [23, 37, 39, 60], "unintuit": 8, "union": 8, "uniqu": [16, 17, 20, 21, 22, 23, 29, 30, 34, 35, 36, 37, 38, 39, 47, 48, 53, 54, 57, 58, 59, 60, 64, 65, 67, 68, 78], "unit": [18, 20, 21, 22, 23, 32, 34, 35, 36, 37, 38, 39, 44, 46, 48, 55, 57, 58, 59, 60, 65, 66, 68, 71], "unitless": [21, 35, 48, 58], "univers": [1, 9, 65], "university_year": [17, 30, 54, 73], "unix": [5, 67], "unknown": [6, 65, 73], "unlabel": [12, 14, 25, 27, 49, 51, 63], "unless": [7, 25, 80], "unlik": [8, 12, 14, 15, 17, 21, 23, 25, 27, 28, 30, 35, 37, 39, 48, 51, 52, 54, 58, 60, 62, 63], "unlimit": 67, "unlucki": [14, 27, 51], "unmarri": [22, 23, 36, 37, 38, 39, 59, 60], "unnam": [12, 25, 31, 49], "uno": 44, "unoffici": 80, "unpredict": 46, "unqualifi": [20, 34, 57, 78], "unreason": [6, 21, 25, 35, 48, 58], "unrecogniz": [12, 25], "unreli": [14, 27, 51], "unrespond": [12, 25], "unscal": [16, 29, 53], "unseen": [13, 24, 40, 50, 61, 62, 66, 70, 75], "unsqueez": 66, "unstructur": 65, "unsupervis": [12, 25, 40, 49, 64, 65, 66, 70, 80], "unsur": [7, 69], "until": [4, 13, 14, 19, 24, 26, 27, 33, 40, 50, 51, 56, 61, 62, 63, 65, 68, 69, 70], "unus": 75, "unusu": 44, "unwieldi": [13, 16, 26, 29, 50, 53], "unzip": [23, 37, 60, 71], "uoft": 65, "up": [7, 8, 13, 16, 17, 18, 19, 20, 23, 24, 26, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 73, 74, 77, 80], "uparrow": 63, "upcom": 62, "updat": [10, 15, 16, 17, 22, 28, 29, 30, 36, 38, 43, 52, 53, 54, 59, 62, 75], "update_cent": 62, "update_plot": [15, 28, 43, 52, 75], "update_z": 62, "upei": 65, "upgrad": 65, "upload": 7, "upon": [0, 13, 14, 17, 20, 22, 23, 24, 26, 27, 30, 34, 36, 37, 38, 39, 40, 50, 51, 54, 57, 59, 60, 61, 62, 63, 65], "upper": [20, 34, 47, 57, 68], "upperbound_pric": 44, "uppercas": 71, "upto": 67, "ur": [12, 25, 49], "urgent": [17, 30, 54, 65], "url": [4, 14, 20, 27, 34, 47, 51, 57, 68, 70, 78], "us": [0, 1, 2, 4, 5, 10, 11, 18, 19, 23, 31, 32, 33, 34, 37, 39, 42, 44, 45, 46, 47, 55, 56, 60, 63, 64, 67, 68, 70, 71, 73, 75, 76, 77, 78, 79], "usa": [8, 14, 15, 18, 27, 28, 32, 51, 52, 55, 65], "usabl": 70, "usag": [16, 17, 20, 21, 24, 29, 30, 34, 35, 40, 53, 54, 57, 58, 61, 65, 67, 68], "usec_": 68, "useless": [19, 23, 24, 33, 37, 39, 40, 56, 60, 61], "user": [10, 12, 16, 17, 19, 22, 23, 25, 26, 29, 30, 33, 36, 37, 38, 39, 43, 49, 50, 51, 53, 54, 56, 59, 60, 62, 63, 65, 66, 68, 69, 70, 71, 72, 73, 77], "user_id": 64, "user_inverse_mapp": 64, "user_kei": 64, "user_mapp": 64, "user_nam": 64, "usernam": 71, "userwarn": [17, 22, 26, 30, 36, 38, 43, 50, 51, 54, 59, 60], "usf": [17, 30, 54], "using_copy_on_writ": [44, 68], "using_cow": 68, "usual": [1, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 44, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 80], "usvi": 39, "utc": [67, 68], "utcnow": 68, "util": [5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 66, 68, 69, 73, 74, 75, 76, 77, 79], "utilities_allpub": [21, 35, 58], "utilities_nosewa": [21, 35, 58], "utility_mat": 64, "uvic": 65, "v": [1, 3, 7, 17, 18, 30, 42, 43, 54, 55, 63, 65, 67, 68, 69, 73], "v1": [12, 20, 25, 34, 49, 57], "v10": [20, 34, 57], "v11": [20, 34, 57], "v12": [20, 34, 57], "v13": [20, 34, 57], "v14": [20, 34, 57], "v15": [20, 34, 57], "v16": [20, 34, 57], "v17": [20, 34, 57], "v18": [20, 34, 57], "v19": [20, 34, 57], "v2": [12, 20, 25, 34, 49, 57], "v20": [20, 34, 57], "v21": [20, 34, 57], "v22": [20, 34, 57], "v23": [20, 34, 57], "v24": [20, 34, 57], "v25": [20, 34, 57], "v26": [20, 34, 57], "v27": [20, 34, 57], "v28": [20, 34, 57], "v3": [20, 34, 57], "v4": [20, 34, 57], "v5": [20, 34, 57], "v6": [20, 34, 57], "v7": [20, 34, 57], "v8": [20, 34, 57], "v9": [20, 34, 57], "v_1": [15, 28, 52], "v_2": [15, 28, 52], "v_i": [15, 28, 52], "v_n": [15, 28, 52], "vacat": [18, 32, 55], "vaccin": [69, 71], "vada_pav": 65, "vader": 71, "vader_lexicon": 71, "vader_senti": 71, "vain": [33, 56], "val": [64, 68], "valenc": [15, 16, 19, 29, 33, 52, 53, 56, 71, 77], "valid": [1, 15, 17, 21, 22, 23, 24, 26, 28, 30, 31, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 48, 50, 52, 54, 58, 59, 60, 61, 62, 64, 66, 68, 69, 70, 71, 73, 76, 77, 78, 79], "valid_dataload": 66, "valid_dir": 43, "valid_flatten": 66, "valid_load": 66, "valid_mat": 64, "valid_sample_df": [22, 36, 38, 59], "valid_sample_i": [22, 36, 38, 59], "valid_sample_x": [22, 36, 38, 59], "valid_scor": [42, 75], "valid_x": 64, "validate_data": 44, "validate_separ": 44, "valu": [7, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78], "valuabl": [11, 24, 40, 61, 63, 80], "value_count": [13, 17, 20, 22, 23, 26, 30, 34, 36, 37, 38, 39, 42, 44, 46, 47, 48, 50, 54, 57, 59, 60, 67, 68, 70, 71, 78, 79], "value_throttl": [15, 28, 43, 52, 75], "valueerror": [8, 16, 17, 29, 30, 44, 53, 54, 68], "values_format": [20, 34, 47, 57, 78], "vampir": 46, "vancouv": [65, 69], "vancouver_canuck": 65, "vanilla": [18, 32, 55], "var": [29, 51, 53, 60, 71, 77], "var_": [23, 37, 39, 60], "varada": [0, 1, 26], "vari": [11, 13, 19, 26, 33, 36, 38, 40, 50, 56, 59, 63, 68, 75], "variabl": [7, 8, 13, 16, 17, 18, 19, 21, 23, 24, 26, 29, 30, 32, 33, 35, 37, 39, 40, 42, 48, 50, 53, 54, 55, 56, 58, 60, 61, 67, 68, 69, 75], "varianc": [21, 23, 35, 37, 39, 48, 58, 60, 63, 67, 75], "variant": [23, 37, 39, 60, 63], "variat": [14, 18, 20, 21, 24, 27, 32, 34, 35, 40, 51, 55, 57, 58, 61], "varieti": [12, 22, 25, 36, 38, 49, 59, 65], "variou": [11, 12, 15, 21, 23, 25, 28, 35, 37, 39, 43, 49, 52, 58, 60, 66, 67, 68, 69, 70, 73, 75, 77], "vault": [14, 27, 51], "ve": [7, 8, 12, 14, 15, 20, 21, 23, 25, 27, 28, 34, 35, 37, 39, 42, 43, 47, 49, 51, 52, 57, 58, 60, 64, 65, 66, 67, 69, 70, 72], "vec": [17, 30, 31, 45, 46, 54, 65, 66], "vec1": 65, "vec1_i": 65, "vec2": 65, "vec2_i": 65, "vec8": [17, 30, 54], "vec8_binari": [17, 30, 54], "vec_binari": [17, 30, 54], "vecom": [19, 33, 56], "vector": [13, 18, 20, 26, 29, 32, 43, 50, 55, 57, 64, 66, 69, 75, 79], "verb": [65, 71], "verbos": [12, 20, 22, 23, 25, 34, 36, 37, 38, 39, 49, 57, 59, 60, 69], "veri": [2, 4, 5, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 75, 80], "verifi": 78, "versa": [21, 35, 48, 58, 75, 78], "version": [1, 4, 5, 7, 8, 10, 12, 18, 21, 23, 26, 29, 32, 33, 35, 37, 39, 44, 46, 48, 51, 53, 55, 56, 58, 60, 63, 65, 67, 68, 71, 72, 78], "versu": 9, "vert": [23, 37, 39, 60], "vertic": [13, 20, 26, 50, 57, 67], "vgg": 66, "vgg16": [43, 66], "vgg16_weight": 66, "via": [4, 7, 10, 12, 20, 24, 25, 40, 57, 61, 80], "vibe": 44, "vice": [21, 35, 48, 58, 75, 78], "victim": 46, "video": [1, 7, 8, 9, 10, 42, 64, 66, 68, 69, 70, 75, 78, 80], "vietnames": [16, 29, 53], "view": [6, 7, 10, 12, 13, 23, 25, 37, 39, 40, 42, 49, 50, 60, 63, 66, 67, 68, 69], "viewpoint": 64, "vif": [23, 37, 39, 60], "vikski": 65, "violat": [16, 17, 29, 30, 53, 54, 68, 70, 80], "virginia": 66, "viridi": [19, 33, 56, 77], "visibl": 77, "vision": [1, 70, 72], "visit": [8, 80], "visual": [1, 11, 13, 14, 15, 17, 18, 20, 21, 22, 23, 26, 27, 28, 30, 31, 32, 35, 36, 37, 38, 42, 45, 46, 47, 48, 50, 51, 52, 54, 55, 57, 58, 59, 60, 62, 63, 66, 67, 68, 71, 73, 76, 77], "visualize_coeffici": [31, 45, 46], "viu": 65, "vivid": 46, "viz": 69, "voc": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "vocab": [31, 45, 46, 65], "vocabulari": [17, 18, 30, 32, 54, 55, 65], "vocabulary_": [17, 30, 54], "voic": [12, 25, 49], "volcano": [12, 49], "volum": 70, "vote": [15, 16, 22, 28, 29, 36, 38, 52, 53, 59, 72, 79], "voting_ndt": [22, 36, 38, 59], "votingclassifi": [22, 36, 38, 59, 79], "votingclassifierinot": [22, 36, 38, 59], "votingregressor": [22, 36, 38, 59], "vulner": 46, "vyfj": [36, 49, 50, 54, 55, 58, 59], "w": [10, 17, 18, 21, 30, 32, 35, 48, 54, 55, 58, 62, 65, 67, 69, 70], "w_0": [18, 32, 55], "w_1": [18, 32, 55], "w_1x_1": [18, 32, 55], "w_2x_2": [18, 32, 55], "w_3x_3": [18, 32, 55], "w_4x_4": [18, 32, 55], "w_d": [18, 32, 55], "w_dx_d": [18, 32, 55], "w_j": [18, 31, 32, 40, 45, 46, 55], "wa": [4, 5, 10, 14, 16, 17, 18, 20, 22, 23, 25, 26, 27, 29, 31, 32, 34, 36, 37, 38, 39, 43, 44, 45, 46, 50, 51, 53, 55, 57, 59, 60, 64, 65, 66, 68, 69, 71, 72, 74, 75, 77, 80], "wa_fn": 68, "wai": [0, 2, 6, 8, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 75, 77, 78, 80], "wait": [4, 12, 15, 17, 25, 26, 28, 30, 49, 50, 52, 54, 68, 70, 80], "waitlist": [13, 80], "walk": [15, 20, 28, 43, 52, 57, 70, 75], "walker": [12, 25, 49, 66], "wallabi": 66, "wang": [1, 80], "want": [4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 38, 40, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 73, 76, 77, 78, 80], "war": 64, "ward": 63, "warm": [16, 29, 53], "warm_start": [20, 34, 57, 69], "warn": [6, 12, 15, 17, 21, 22, 23, 25, 27, 28, 30, 35, 36, 37, 38, 39, 43, 47, 48, 51, 52, 54, 58, 59, 60, 68, 72, 79], "warranti": 0, "washington": 71, "washroom": 80, "wasn": [44, 46, 65], "wast": [4, 17, 30, 46, 54, 69], "watch": [1, 10, 12, 15, 18, 25, 32, 46, 52, 55, 64, 65, 73], "watchfil": 43, "water": 69, "waterfal": [23, 37, 60], "waterfront": [12, 13, 25, 42, 49, 50], "wavelet": [24, 40, 61], "waxwork": 46, "wb": 70, "wd": [21, 23, 35, 37, 39, 58, 60, 69], "we": [1, 4, 5, 6, 7, 10, 12, 13, 15, 25, 26, 28, 31, 43, 44, 45, 46, 47, 49, 50, 52, 63, 65, 66, 67, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "weak": [46, 73], "weather": [13, 26, 50, 67, 70], "weatherau": 67, "web": [5, 12, 25, 65, 73], "web_api": 70, "web_appl": 70, "weblog": 65, "websit": [4, 10], "wed": 67, "wednesdai": [67, 80], "week": [1, 6, 14, 15, 16, 17, 20, 21, 22, 23, 25, 28, 29, 30, 34, 35, 36, 37, 38, 39, 51, 52, 53, 54, 57, 58, 59, 60, 64, 65, 67, 69, 78, 80], "weekdai": 67, "weekend": [8, 46, 67, 69], "weekli": [12, 71], "weight": [15, 22, 24, 25, 28, 36, 38, 40, 43, 52, 59, 61, 64, 65, 66, 78, 80], "weighted_averag": [20, 57], "weinberg": [23, 37, 39, 60], "weird": [21, 35, 48, 58], "welcom": [74, 80], "well": [4, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 73, 77, 80], "wellyanto": [1, 80], "welsh": [12, 25, 49, 66], "went": [21, 35, 58, 71, 77, 79], "were": [0, 6, 12, 18, 20, 21, 25, 32, 34, 35, 44, 47, 48, 54, 55, 57, 58, 65, 66, 67, 68, 69, 77, 79, 80], "weren": 65, "what": [7, 8, 9, 13, 15, 19, 26, 28, 31, 33, 42, 43, 44, 45, 46, 50, 52, 56, 63, 66, 67, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "whatev": [24, 40, 61], "whatsoev": 46, "when": [4, 6, 7, 10, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 74, 76, 78, 79, 80], "wher": 71, "where": [0, 1, 7, 10, 13, 14, 15, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 44, 45, 46, 47, 48, 50, 51, 52, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 69, 70, 73, 75, 78], "wherea": [2, 13, 18, 19, 21, 23, 26, 32, 33, 35, 37, 39, 44, 50, 55, 56, 58, 60, 63, 69], "whether": [0, 4, 7, 8, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 44, 48, 50, 51, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 67, 68, 70, 71, 74, 79, 80], "which": [4, 6, 8, 10, 14, 15, 16, 17, 18, 19, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 39, 40, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54, 55, 56, 58, 60, 61, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "whichev": [22, 36, 38, 59], "while": [14, 18, 19, 20, 22, 23, 26, 27, 29, 32, 33, 34, 36, 37, 38, 39, 46, 47, 50, 51, 55, 56, 57, 59, 60, 62, 64, 65, 68, 71, 77], "white": [20, 22, 23, 34, 36, 37, 38, 39, 46, 57, 59, 60, 63, 65], "whitespac": [65, 68], "who": [4, 5, 6, 12, 20, 23, 25, 37, 39, 46, 49, 57, 60, 62, 63, 65, 67, 68, 69, 70, 71, 73, 80], "whole": [14, 19, 21, 23, 27, 33, 35, 37, 39, 46, 48, 51, 56, 58, 60, 64, 70, 77], "whom": [0, 65, 71], "whose": 4, "why": [8, 14, 15, 20, 21, 22, 26, 28, 34, 35, 36, 38, 42, 44, 46, 51, 52, 57, 58, 59, 62, 63, 65, 67, 68, 73, 74, 75, 76, 77], "wid": [20, 57, 70], "wide": [10, 18, 19, 22, 24, 32, 33, 36, 38, 40, 55, 56, 59, 61, 64, 66, 69], "wider": [15, 28, 43, 52, 75], "widespread": 65, "widget": [15, 20, 28, 34, 43, 47, 52, 57, 62, 63, 75], "width": [13, 14, 15, 20, 26, 27, 28, 34, 43, 50, 51, 52, 57, 65, 74, 75], "wife": [12, 20, 22, 23, 34, 36, 37, 38, 39, 46, 49, 57, 59, 60], "wiki": [65, 69], "wiki_df": 65, "wiki_dict": 65, "wikipedia": [65, 66, 69], "wikipedia2vec": 65, "wild": [12, 14, 25, 27, 43, 49, 51, 66], "willing": [20, 34, 47, 57], "win": [15, 17, 22, 23, 24, 28, 30, 31, 36, 37, 39, 40, 45, 46, 52, 54, 59, 60, 61, 64, 72], "wind": [13, 26, 50], "winddir3pm": 67, "winddir3pm_miss": 67, "winddir3pm_ss": 67, "winddir3pm_ssw": 67, "winddir3pm_sw": 67, "winddir3pm_w": 67, "winddir3pm_wnw": 67, "winddir3pm_wsw": 67, "winddir9am": 67, "windgustdir": 67, "windgustspe": 67, "window": 68, "windsor": 71, "windspeed3pm": 67, "windspeed9am": 67, "wine_1": 8, "winter": 67, "winter_month": 67, "wire": 64, "wisdom": [22, 36, 38, 59], "wish": [12, 13, 25, 26, 46, 49, 50, 62, 69, 80], "within": [13, 16, 18, 22, 24, 26, 29, 32, 38, 40, 43, 46, 50, 53, 55, 59, 61, 62, 63, 68, 70, 73, 77], "without": [0, 7, 12, 13, 20, 22, 23, 24, 25, 26, 34, 36, 37, 38, 39, 40, 47, 49, 50, 57, 59, 60, 61, 64, 66, 67, 68, 69, 70, 77, 80], "wnw": 67, "wolf": 46, "wolv": 63, "woman": [46, 65], "wombat": 66, "won": [5, 10, 12, 13, 14, 15, 17, 18, 24, 25, 26, 27, 28, 30, 32, 40, 50, 51, 52, 54, 55, 61, 64, 65, 66, 67, 68, 70, 71], "wonder": [12, 14, 25, 46, 49, 51], "wooddecksf": [21, 23, 35, 37, 39, 48, 58, 60, 69], "word": [11, 12, 18, 19, 20, 24, 25, 31, 32, 33, 34, 40, 42, 44, 45, 46, 47, 49, 55, 56, 57, 61, 62, 63, 64, 66, 67, 68, 69, 73, 77, 80], "word1": 65, "word2": 65, "word2vec": [11, 65, 66], "word3": 65, "word_coeff_df": [31, 45, 46], "word_pair": 65, "word_token": [65, 71], "wordnet": 65, "wordnetlemmat": 65, "words_in_ex": [31, 45, 46], "work": [0, 4, 5, 7, 8, 10, 12, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 28, 29, 30, 32, 33, 34, 35, 37, 39, 40, 44, 46, 47, 48, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 73, 77, 79, 80], "workclass": [20, 22, 23, 34, 36, 37, 38, 39, 57, 59, 60, 78], "workclass_feder": [22, 23, 36, 37, 39, 59, 60], "workclass_loc": [22, 23, 36, 37, 39, 59, 60], "workclass_miss": [23, 37, 39, 60], "workclass_nev": [22, 23, 36, 37, 39, 59, 60], "workclass_priv": [22, 23, 36, 37, 39, 59, 60], "workclass_self": [23, 37, 39, 60], "workclass_st": [23, 37, 39, 60], "workclass_without": [23, 37, 39, 60], "workflow": [13, 26, 50, 70, 80], "worksheet": 70, "world": [15, 16, 17, 18, 19, 20, 23, 24, 27, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 46, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 73], "worm": 66, "worri": [12, 25, 49, 62, 63, 64, 79], "wors": [13, 19, 21, 22, 26, 33, 35, 36, 38, 48, 50, 56, 58, 59, 68, 74, 77, 78], "worst": [20, 24, 34, 40, 46, 47, 57, 61, 62], "worth": [13, 15, 20, 21, 26, 28, 34, 35, 48, 50, 52, 57, 58, 78], "worthi": [18, 32, 55], "would": [4, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 77, 78, 79, 80], "wouldn": [17, 19, 30, 33, 54, 56, 65, 68], "wound": 46, "wow": [23, 37, 39, 60], "wrangl": 44, "wrap": [17, 30, 54], "wrapper": [24, 40, 44, 61], "write": [4, 7, 11, 12, 19, 25, 33, 36, 39, 49, 56, 60, 61, 62, 65, 69, 70, 71, 75, 79, 80], "writer": 46, "written": [7, 17, 23, 30, 37, 39, 46, 54, 60, 67, 69], "wrong": [10, 14, 18, 21, 24, 27, 32, 35, 40, 44, 46, 48, 51, 55, 58, 61, 62, 68, 69, 77], "wrote": [65, 67], "wsw": 67, "wtf": 70, "www": [9, 18, 32, 55], "x": [4, 8, 10, 14, 15, 16, 17, 18, 20, 22, 24, 27, 28, 29, 30, 32, 34, 36, 38, 39, 40, 42, 43, 44, 47, 51, 52, 53, 54, 55, 57, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 78], "x0": [24, 40, 61], "x0_male": [20, 34, 57], "x1": [24, 40, 61, 64], "x1_x2": 40, "x1x2": [24, 40, 61], "x2": [24, 40, 61, 63, 64], "x27": [16, 17, 19, 20, 21, 22, 24, 29, 30, 33, 34, 35, 36, 38, 44, 46, 53, 54, 56, 57, 58, 59, 61, 66, 69, 71], "x_": [18, 31, 32, 40, 45, 46, 55], "x_1": [18, 24, 32, 40, 55, 61, 62], "x_1x_2": [24, 61], "x_2": [18, 24, 32, 40, 55, 61, 62], "x_anim_train": 43, "x_anim_valid": 43, "x_binari": [13, 26, 50], "x_citi": [15, 28, 52], "x_count": [17, 30, 54], "x_d": [18, 32, 55], "x_femal": [20, 34, 57, 78], "x_hour": 67, "x_hour_week": 67, "x_hour_week_onehot": 67, "x_hour_week_onehot_poli": 67, "x_hour_week_onehot_poly_lag": 67, "x_i": [18, 32, 55, 64], "x_imp_ohe_train": [16, 29, 53], "x_init": 62, "x_int": [17, 30, 54], "x_label": [13, 14, 15, 26, 27, 28, 50, 51, 52, 74], "x_lag_featur": 67, "x_lag_features_imp": 67, "x_male": [20, 34, 57, 78], "x_mask": [17, 30, 54], "x_multi": 72, "x_n": [24, 40, 61], "x_orig": 63, "x_re": [20, 57], "x_small_citi": [15, 28, 52], "x_spotifi": [15, 19, 33, 52, 56, 77], "x_subset": [13, 14, 26, 27, 50, 51], "x_test": [12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 68, 69, 71, 72, 75, 76, 77, 78, 79], "x_test_big": [19, 33, 56], "x_test_cat": 44, "x_test_cat_oh": 44, "x_test_enc": [23, 37, 39, 60, 67, 68, 69], "x_test_happi": [20, 57, 70], "x_test_imp": [16, 29, 53], "x_test_multi": 72, "x_test_num": 44, "x_test_num_imp": 44, "x_test_num_imp_sc": 44, "x_test_pr": 67, "x_test_predict": [16, 29, 53], "x_test_scal": [16, 29, 53], "x_test_transform": [16, 29, 53], "x_toi": [15, 16, 17, 28, 29, 30, 52, 53, 54, 67], "x_toy_oh": [16, 29, 53], "x_toy_ord": [16, 17, 29, 30, 53, 54], "x_tr": [42, 75], "x_train": [12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 66, 67, 68, 69, 71, 72, 75, 76, 77, 78, 79], "x_train_big": [20, 34, 47, 57, 78], "x_train_cat": 44, "x_train_cat_oh": 44, "x_train_enc": [20, 21, 23, 34, 35, 37, 39, 48, 57, 58, 60, 67, 68, 69, 78], "x_train_happi": [20, 57, 70], "x_train_hous": [24, 40, 61], "x_train_imp": [16, 29, 53], "x_train_imp_sc": [16, 29, 53], "x_train_multi": 72, "x_train_num": 44, "x_train_num_imp": 44, "x_train_num_imp_sc": 44, "x_train_oversampl": [20, 57], "x_train_perm": [23, 37, 39, 60], "x_train_pp": 54, "x_train_predict": [16, 29, 53], "x_train_scal": [16, 24, 29, 40, 53, 61], "x_train_subsampl": [20, 57], "x_train_tini": [19, 33, 56], "x_train_transform": [16, 29, 53], "x_train_usr": 64, "x_transform": [17, 30, 54], "x_valid": [20, 34, 42, 43, 47, 57, 64, 75, 78], "x_vari": 63, "x_xor": [24, 61], "xanni": [19, 33, 56], "xavier": [24, 40, 61, 64], "xcode": 5, "xgbclassifi": [22, 23, 36, 37, 38, 39, 59, 60], "xgbclassifierxgbclassifi": [22, 36, 38, 59], "xgboost": [23, 37, 39, 60], "xgboostcolumntransform": [22, 36, 38], "xgbregressor": [12, 22, 25, 36, 38, 49, 59], "xlabel": [8, 13, 14, 15, 18, 19, 20, 21, 23, 26, 27, 28, 32, 33, 34, 35, 37, 39, 40, 43, 47, 48, 50, 51, 52, 55, 56, 57, 58, 60, 63, 66, 67, 68, 69, 72, 74, 77], "xlim": 68, "xor": [18, 24, 32, 40, 55, 61], "xp": 44, "xt": [17, 30, 54], "xtick": [14, 20, 27, 34, 43, 47, 51, 57, 67], "xticklabel": [19, 33, 56, 77], "xticks_rot": [20, 57], "xwm\u0259\u03b8kw\u0259y": 80, "xx": [24, 61, 62], "y": [8, 14, 15, 16, 17, 18, 19, 20, 22, 24, 27, 28, 29, 30, 32, 33, 34, 36, 38, 39, 40, 42, 43, 44, 47, 51, 52, 53, 54, 55, 56, 57, 59, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 78], "y_": 64, "y_citi": [15, 28, 52], "y_femal": [20, 34, 57, 78], "y_hat": [18, 22, 32, 38, 55, 59], "y_i": [21, 22, 24, 35, 38, 40, 48, 58, 59, 61, 64], "y_init": 62, "y_label": [13, 14, 15, 26, 27, 28, 50, 51, 52, 74], "y_male": [20, 34, 57, 78], "y_mat": 64, "y_multi": 72, "y_numer": 44, "y_pred": [20, 34, 47, 57, 67], "y_pred_lower_threshold": [20, 34, 57], "y_pred_toi": [20, 57], "y_pred_train": 67, "y_re": [20, 57], "y_small_citi": [15, 28, 52], "y_spotifi": [19, 33, 56, 77], "y_test": [12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 68, 69, 71, 72, 75, 76, 77, 78, 79], "y_test_big": [19, 33, 56], "y_test_happi": [20, 57, 70], "y_test_multi": 72, "y_test_num": [22, 23, 36, 37, 38, 39, 59, 60], "y_toi": [15, 28, 52, 67], "y_tr": [42, 75], "y_train": [12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 66, 67, 68, 69, 71, 72, 75, 76, 77, 78, 79], "y_train_big": [20, 34, 47, 57, 78], "y_train_happi": [20, 57, 70], "y_train_hous": [24, 40, 61], "y_train_multi": 72, "y_train_num": [22, 23, 36, 37, 38, 39, 59, 60], "y_train_ord": 67, "y_train_oversampl": [20, 57], "y_train_subsampl": [20, 57], "y_train_tini": [19, 33, 56], "y_train_usr": 64, "y_true": 69, "y_true_toi": [20, 57], "y_valid": [20, 34, 42, 43, 47, 57, 64, 66, 75, 78], "y_vari": 63, "y_xor": [24, 61], "yale": 65, "yan": [1, 80], "yann": [23, 37, 39, 60], "ycxmx": 68, "ye": [4, 12, 13, 16, 17, 23, 25, 26, 29, 30, 37, 39, 44, 49, 50, 53, 54, 60, 62, 63, 64, 66, 67, 69, 70, 71, 73], "year": [12, 13, 25, 26, 50, 64, 65, 66, 67, 68], "yearbuilt": [21, 23, 35, 37, 39, 48, 58, 60, 69], "yearremodadd": [21, 23, 35, 37, 39, 48, 58, 60, 69], "yellow": [19, 33, 56], "yellowbrick": [62, 63], "yesterdai": 67, "yet": [1, 10, 11, 18, 23, 32, 37, 39, 44, 46, 55, 60, 64, 67, 68, 75], "yield": 77, "yifei": [1, 80], "ylabel": [8, 13, 14, 15, 18, 19, 20, 21, 26, 27, 28, 32, 33, 34, 35, 40, 42, 43, 47, 48, 50, 51, 52, 55, 56, 57, 58, 63, 66, 67, 68, 69, 72, 74, 75, 77], "ylim": [68, 69], "yml": 10, "yolo": 66, "yolo8": 66, "yolo_input": 66, "yolo_result": 66, "yolo_test": 66, "yolov8n": 66, "york": [67, 71], "you": [0, 1, 4, 5, 6, 7, 8, 10, 23, 37, 39, 42, 43, 47, 48, 60, 65, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "young": 46, "your": [0, 1, 2, 4, 6, 7, 8, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "your_miniconda_path": 71, "your_nam": 10, "yourself": [4, 11, 17, 20, 30, 34, 54, 57, 64, 65, 69, 80], "yourselv": 65, "youtub": [1, 12, 25, 64, 65, 69, 80], "yr_built": [12, 13, 25, 42, 49, 50], "yr_renov": [12, 13, 25, 42, 49, 50], "yrpxn": 68, "yrsold": [21, 23, 35, 37, 39, 48, 58, 60, 69], "ytick": [14, 20, 27, 34, 43, 47, 51, 57], "yticklabel": [19, 33, 56, 77], "yy": [24, 61, 67], "yyyi": 67, "z": [8, 18, 24, 32, 40, 43, 55, 61, 62, 63, 64, 66, 68], "z_i": 66, "z_j": 66, "z_km": 62, "z_train": [43, 66], "z_valid": [43, 66], "zachari": 68, "zarei": [1, 80], "zefeng": [1, 80], "zeng": [1, 80], "zero": [8, 14, 17, 19, 27, 30, 33, 39, 40, 51, 54, 56, 64, 65, 69], "zero_divis": [20, 34, 47, 57], "zhiyanov": [1, 80], "zip": [15, 18, 28, 32, 43, 52, 55, 64, 71, 75], "zipcod": [12, 13, 25, 42, 49, 50, 75], "zombi": 46, "zone": [46, 67], "zoo": 46, "zoom": [7, 77], "zorro": 46, "zu": 46, "zucco": 46, "\u0259m": 80, "\u03bc": 72}, "titles": ["LICENSE", "UBC CPSC 330: Applied Machine Learning (2024W2)", "CPSC 330 vs. CPSC 340", "CPSC 330 Documents", "How to ask for help", "What are git and GitHub?", "CPSC 330 grading policies", "Homework info &amp; submission guidelines", "CPSC 330 Python notes", "Reference material", "Setting up coding environment", "Course Learning Objectives", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 12: Ensembles", "Lecture 13: Feature importances and model transparency", "Lecture 14: Feature engineering and feature selection", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Class demo", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 12: Ensembles", "Lecture 13: Feature importances and model transparency", "Lecture 12: Ensembles", "Lecture 13: Feature importances and model transparency", "Lecture 14: Feature engineering and feature selection", "&lt;no title&gt;", "Lecture 3: ML Fundamentals Class Demo", "Lecture 4: Class demo", "Lecture 5 and 6: Class demo", "Lectures 7: Class demo", "Lectures 7: Class demo", "Lecture 9: Class demo", "Lecture 10: Regression metrics", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 12: Ensembles", "Lecture 13: Feature importances and model transparency", "Lecture 14: Feature engineering and feature selection", "Lecture 15: K-Means Clustering", "Lecture 16: More Clustering", "Lecture 17: Recommender Systems", "Lecture 18: Introduction to natural language processing", "Lecture 19: Multi-class classification and introduction to computer vision", "Lecture 20: Time series", "Lecture 21: Survival analysis", "Lecture 22: Communication", "Lecture 24: Deployment and conclusion", "Appendix A: Demo of feature engineering for text data", "Appendix B: Multi-class, meta-strategies", "Final exam preparation: guiding questions", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Tutorial 4", "Tutorial 5", "Tutorial 6", "Syllabus"], "titleterms": {"": [12, 14, 15, 16, 17, 20, 21, 23, 25, 28, 29, 30, 34, 35, 37, 39, 44, 47, 49, 51, 52, 53, 54, 57, 58, 60, 67, 69], "0": [36, 38, 59], "1": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 68, 69, 73, 74, 75, 76, 77, 78, 79], "10": [21, 35, 48, 58, 79], "12": [22, 36, 38, 59], "13": [23, 37, 39, 60], "14": [24, 40, 61], "15": [62, 69, 70], "16": 63, "17": 64, "18": 65, "19": 66, "2": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 39, 40, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 62, 63, 64, 68, 69, 73, 74, 75, 76, 77, 78, 79], "20": [67, 69, 70], "2024w2": 1, "21": 68, "22": 69, "24": 70, "3": [12, 13, 14, 16, 25, 26, 27, 29, 32, 40, 42, 49, 50, 51, 53, 61, 62, 63, 68, 74, 75, 76, 77, 78, 79], "330": [1, 2, 3, 6, 8, 12, 25, 70], "340": [2, 12, 25, 70], "4": [13, 14, 15, 26, 27, 28, 43, 50, 51, 52, 69, 74, 75, 76, 77, 78, 79], "5": [8, 12, 13, 14, 15, 16, 17, 20, 23, 24, 25, 26, 27, 28, 29, 30, 37, 39, 44, 50, 51, 52, 53, 54, 57, 60, 61, 62, 65, 66, 68, 69, 75, 76, 77, 78, 79], "6": [17, 30, 44, 54, 75, 77, 78, 79], "7": [18, 31, 32, 45, 46, 55, 77, 79], "8": [19, 33, 56, 77, 79], "9": [20, 34, 47, 57, 79], "A": [4, 20, 34, 47, 57, 63, 67, 71], "No": 8, "Not": 73, "One": [16, 29, 53, 67, 72], "The": [1, 14, 18, 19, 22, 24, 27, 32, 33, 36, 38, 40, 51, 55, 56, 59, 61, 62, 79], "__": [19, 33, 56], "about": [8, 12, 24, 25, 40, 61, 64, 69], "academ": 80, "access": [7, 18, 32, 55, 80], "accommod": 80, "acknowledg": 80, "activ": [12, 20, 23, 25, 34, 37, 39, 42, 57, 60, 61, 62, 65, 69, 78], "actual": [17, 54], "ad": 8, "addit": [7, 23, 37, 39, 60], "address": [20, 34, 47, 57], "advantag": [19, 33, 56], "advic": [24, 40, 61], "ai": 80, "aka": 69, "algorithm": [13, 15, 24, 26, 28, 40, 50, 52, 61, 62], "all": [12, 13, 16, 18, 20, 25, 32, 34, 47, 49, 50, 53, 55, 57, 62, 63, 64, 69], "alpha": [18, 21, 32, 35, 48, 55, 58], "alreadi": 70, "altern": [13, 16, 26, 29, 44, 50, 53], "an": [22, 36, 38, 59, 69, 71], "analogi": [15, 52], "analysi": [42, 44, 67, 68, 70, 73, 75], "angl": 69, "announc": [12, 13, 14, 15, 16, 17, 18, 20, 22, 28, 30, 32, 36, 38, 39, 40, 50, 52, 54, 55, 59], "answer": 68, "ap": [20, 34, 47, 57], "api": [16, 29, 53, 70], "app": 70, "appendix": [71, 72], "appli": [1, 8, 16, 17, 21, 29, 30, 35, 48, 53, 54, 58, 69], "applic": 62, "applymap": 8, "approach": [64, 67, 68, 69, 70, 72], "approxim": [14, 27, 51], "ar": [5, 12, 13, 16, 18, 20, 25, 29, 32, 34, 48, 49, 50, 53, 55, 57, 62, 63, 64], "area": [20, 34, 47, 57], "argument": [14, 15, 27, 28, 51, 52], "around": 69, "arrai": 8, "articl": 9, "asap": 69, "ask": 4, "assess": 42, "assign": [7, 80], "associ": [18, 32, 55], "assum": 68, "attent": [13, 15, 26, 28, 50, 52], "attribut": [23, 37, 39, 60, 69], "auc": [20, 34, 47, 57], "autom": [19, 33, 56], "averag": [20, 22, 34, 36, 38, 57, 59, 64, 79], "avoid": [14, 27, 51], "b": [62, 72], "backward": [24, 40, 61], "bad": [19, 33, 56], "bag": [17, 30, 54, 71], "balanc": [20, 34, 57], "bank": 47, "base": [15, 22, 24, 36, 38, 40, 52, 59, 61, 64, 67], "baselin": [13, 16, 20, 22, 23, 26, 29, 34, 36, 37, 38, 39, 42, 47, 48, 50, 53, 57, 59, 60, 64, 75], "basic": 65, "befor": [12, 16, 25, 29, 53], "best": [24, 40, 61], "better": [14, 19, 20, 24, 27, 33, 34, 40, 47, 51, 56, 57, 61, 69], "between": [13, 15, 28, 50, 52, 70, 74], "beyond": [23, 37, 39, 60, 64], "bia": [14, 19, 27, 33, 51, 56], "big": [13, 14, 16, 26, 27, 29, 50, 51, 53], "binari": [20, 34, 47, 57], "book": 1, "boost": [22, 36, 38, 59, 69], "bootstrap": [22, 36, 38, 59], "bottom": 69, "boundari": [13, 15, 18, 26, 28, 32, 43, 50, 52, 55, 74], "bow": [17, 30, 54], "box": 66, "break": [8, 12, 13, 14, 15, 16, 17, 24, 25, 26, 27, 28, 30, 50, 51, 52, 53, 54, 61, 65, 66, 68, 69, 70], "broadcast": 8, "browser": [12, 25], "build": [12, 13, 21, 25, 26, 31, 35, 42, 45, 46, 49, 50, 58, 64, 70], "c": [15, 19, 28, 33, 52, 56], "calcul": [18, 32, 55], "california": [18, 32, 54, 55, 76], "can": [8, 14, 16, 22, 23, 27, 29, 36, 37, 38, 39, 51, 53, 59, 60, 61, 62], "canada": [13, 50, 74], "care": [64, 69], "carri": [16, 24, 29, 40, 53, 61], "case": [17, 18, 30, 32, 54, 55, 63], "catboost": [22, 36, 38, 59], "categor": [16, 17, 23, 29, 30, 37, 39, 44, 53, 54, 60, 67], "categori": [17, 30, 54], "censor": 68, "centr": 80, "certain": [17, 54], "cfa": 80, "chang": [20, 34, 57], "charact": [12, 25, 49], "characterist": [20, 34, 47, 57], "cheatsheet": 8, "checklist": [12, 25], "choos": [15, 28, 52, 62], "chunk": 69, "churn": 68, "cite": 7, "citi": [18, 32, 55], "claim": 69, "class": [12, 19, 20, 21, 22, 23, 25, 31, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 56, 57, 58, 59, 60, 64, 66, 72, 80], "class_attend": [17, 30, 54], "class_weight": [20, 34, 57], "classif": [13, 20, 26, 34, 43, 47, 50, 57, 66, 70, 73], "classifi": [13, 18, 22, 26, 31, 32, 36, 38, 44, 45, 46, 50, 55, 59, 71], "clearli": [24, 40, 61], "cluster": [62, 63, 73], "co": [1, 80], "code": [10, 80], "coeffici": [18, 23, 31, 32, 37, 39, 45, 46, 55, 60], "color": [74, 75, 76, 77, 78, 79], "column": [8, 16, 17, 29, 30, 53, 54, 67], "columntransform": [17, 30, 54, 76], "com": [15, 24], "combin": [22, 36, 38, 59], "come": [14, 15, 27, 28, 51, 52], "command": 5, "comment": [13, 19, 20, 21, 26, 33, 34, 35, 47, 48, 50, 56, 57, 58, 62, 63, 64], "common": [16, 29, 53, 62], "commonli": 65, "commun": [12, 25, 69, 73], "compact": [16, 29, 53], "companion": 9, "complet": 64, "complex": [14, 27, 51], "complic": 67, "compon": [18, 32, 55], "comprehens": 76, "comput": [12, 25, 66, 73], "con": [15, 28, 52, 63, 73], "concept": [42, 69], "concern": 6, "concess": 80, "conclus": 70, "conda": 10, "conduct": 80, "confid": [18, 32, 55, 69], "confus": [20, 34, 47, 57, 69], "consid": 68, "construct": [22, 36, 38, 59], "content": 64, "context": 65, "continu": [13, 26, 50], "conveni": [17, 30, 54], "corpu": 70, "correct": 62, "correl": [23, 37, 39, 60], "countri": [13, 50, 74], "countvector": [17, 30, 54], "cours": [1, 9, 11, 12, 25, 49, 70, 80], "cover": [64, 68, 70], "cox": 68, "cpsc": [1, 2, 3, 6, 8, 12, 25], "creat": [7, 13, 14, 17, 26, 27, 30, 50, 51, 54, 64, 70], "credit": 10, "critic": 47, "cross": [14, 16, 20, 24, 27, 29, 34, 40, 42, 47, 51, 53, 57, 61, 67, 75], "cross_val_scor": [14, 27, 51], "cross_valid": [14, 21, 27, 35, 48, 51, 58], "csv": 8, "curs": [15, 28, 52], "curv": [20, 34, 47, 57, 68], "custom": [62, 68], "cv": [19, 33, 56], "dai": 67, "data": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 32, 33, 35, 36, 37, 38, 39, 42, 44, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 69, 70, 71, 75], "datafram": [8, 17, 30, 54], "dataset": [7, 13, 16, 18, 19, 20, 21, 26, 29, 31, 32, 33, 34, 35, 45, 46, 47, 48, 50, 53, 54, 55, 56, 57, 58, 66, 67, 69, 76, 79], "date": [1, 67], "datetim": 67, "dbscan": 63, "deal": [17, 20, 30, 34, 54, 57], "debug": 10, "decis": [13, 15, 18, 23, 26, 28, 32, 37, 39, 42, 43, 50, 52, 55, 60, 69, 75], "decisiontreeclassifi": [13, 22, 26, 36, 38, 50, 59], "decreas": [20, 34, 47, 57], "deep": [66, 67], "defin": [24, 40, 61], "definit": [12, 25, 49], "deliver": [1, 12, 25], "demo": [24, 31, 40, 42, 43, 44, 45, 46, 47, 61, 67, 70, 71], "demonstr": [20, 34, 47, 57], "dendrogram": 63, "depend": [24, 39, 40, 61], "deploi": 70, "deploy": [14, 27, 51, 70, 73], "descript": 80, "desktop": 5, "detail": [20, 21, 27, 35, 47, 48, 57, 58, 63], "detect": 66, "df": 8, "did": [14, 16, 17, 20, 21, 27, 29, 30, 34, 35, 48, 51, 53, 54, 57, 58, 64, 68, 69, 70], "differ": [16, 19, 20, 21, 23, 29, 33, 34, 35, 37, 39, 47, 48, 53, 56, 57, 58, 60, 70, 73], "dimens": [15, 28, 52], "dimension": [15, 28, 52], "directori": 70, "discuss": [19, 20, 33, 34, 42, 44, 56, 57, 64, 65, 69, 70, 78], "diseas": [12, 25, 49], "distanc": [15, 28, 52, 62], "distribut": [19, 33, 56], "do": [16, 17, 19, 20, 22, 23, 24, 29, 33, 34, 36, 37, 38, 39, 40, 44, 47, 53, 54, 56, 57, 59, 60, 61, 69, 70], "document": [3, 8, 62], "doe": [13, 18, 26, 27, 32, 50, 55, 63, 69], "domain": [24, 40, 61], "drop": 8, "due": 1, "dummi": [43, 44, 71], "dummyclassifi": [13, 22, 26, 36, 38, 50, 59, 67, 68], "dummyregressor": [13, 16, 21, 26, 29, 35, 50, 53, 58], "eda": [16, 20, 21, 29, 34, 35, 47, 48, 53, 57, 58, 70, 75], "effect": [22, 36, 38, 59, 69], "elbow": 62, "element": 8, "elimin": [24, 40, 61], "embed": 65, "encod": [16, 17, 24, 29, 30, 40, 53, 54, 61, 67], "engin": [24, 40, 61, 67, 71, 73], "ensembl": [22, 36, 38, 59, 73], "enter": 44, "environ": [10, 70], "equal": 69, "error": [14, 19, 20, 21, 27, 33, 34, 35, 47, 48, 51, 56, 57, 58, 64], "estim": [16, 22, 29, 36, 38, 53, 59], "ethic": 73, "euclidean": [15, 28, 52], "eva": [12, 14, 25, 49, 51], "evalu": [20, 34, 47, 57, 63, 64, 68, 73, 78], "evalut": [20, 34, 47, 57], "event": 68, "everyon": 68, "exactli": [18, 32, 55], "exam": [73, 80], "examin": [17, 21, 30, 31, 35, 45, 46, 48, 54, 58, 69, 73], "exampl": [12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 65, 68, 69, 71], "exercis": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 40, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 66, 68, 74], "exhaust": [19, 33, 56], "experi": 69, "explain": [23, 37, 39, 60, 69], "explan": [23, 37, 39, 60, 69], "explor": [15, 28, 48, 52, 62], "exploratori": [42, 44, 67, 75], "extract": [17, 30, 54, 67], "extractor": 66, "f1": [20, 34, 47, 57], "failur": 63, "fair": [20, 34, 57, 78], "fancier": [19, 33, 56], "farewel": 70, "faster": 8, "fastest": 8, "featur": [12, 13, 15, 16, 17, 18, 21, 23, 24, 25, 26, 28, 29, 30, 32, 35, 37, 39, 40, 44, 48, 49, 50, 52, 53, 54, 55, 58, 60, 61, 64, 66, 67, 69, 71, 73], "feature_importances_": [23, 37, 39, 60], "few": [20, 34, 47, 57, 63, 69], "fictiti": [12, 25, 49], "figur": 7, "filter": [8, 64], "final": [13, 19, 26, 33, 50, 56, 62, 63, 64, 67, 73, 75, 80], "find": [15, 24, 28, 40, 52, 61], "first": [12, 16, 25, 29, 53], "fit": [13, 16, 22, 26, 29, 38, 50, 53, 59], "flatten": 66, "follow": [12, 13, 14, 25, 27, 42, 49, 50, 51, 62, 63, 64], "font": [74, 75, 76, 77, 78, 79], "forc": 39, "forecast": 67, "forest": [22, 23, 36, 37, 38, 39, 59, 60, 69], "format": [7, 8, 12, 25], "formul": 64, "forward": [24, 40, 61], "from": [8, 69, 71], "full": 70, "function": [8, 18, 21, 32, 35, 48, 55, 58], "fundament": [14, 15, 22, 27, 28, 36, 38, 42, 51, 52, 59, 73], "further": [67, 71], "futur": 67, "fuyi": [15, 24], "gamma": [15, 28, 52], "garbag": [24, 40, 61], "gb": 69, "gener": [4, 6, 14, 15, 18, 22, 24, 27, 28, 32, 36, 38, 40, 51, 52, 55, 59, 61], "genom": 40, "geometr": [15, 28, 52], "get": [23, 39, 48, 60], "git": [5, 10], "github": 5, "given": [12, 13, 25, 26, 49, 50], "global": 64, "goal": [14, 27, 51], "golden": [14, 16, 17, 27, 29, 30, 51, 53, 54], "good": [20, 34, 57, 69], "grade": [4, 6, 13, 25, 26, 50, 80], "gradescop": 7, "gradient": [22, 36, 38, 59, 69], "grid": [19, 33, 56, 69], "gridsearchcv": [19, 21, 33, 35, 48, 56, 58, 69], "group": [20, 34, 42, 57, 62, 78], "guid": 73, "guidelin": [4, 6, 7], "ha": [12, 25, 49], "halv": [19, 33, 56], "handl": [20, 34, 57], "have": [22, 23, 36, 37, 38, 39, 59, 60, 69], "hazard": 68, "heatmap": [19, 33, 56], "help": [4, 24, 40, 61], "here": [14, 27, 51], "hierarch": 63, "home": 63, "homework": [7, 12, 25], "hot": [16, 24, 29, 40, 53, 61, 67], "hous": [12, 13, 16, 18, 25, 29, 32, 49, 50, 53, 54, 55, 76], "how": [4, 7, 13, 14, 15, 16, 18, 22, 23, 24, 26, 27, 28, 29, 32, 36, 37, 38, 39, 40, 44, 50, 51, 52, 53, 55, 59, 60, 61, 63, 69], "http": [15, 24], "hyper": [19, 33, 56], "hyperparamet": [13, 15, 17, 18, 19, 21, 22, 26, 28, 30, 32, 33, 35, 36, 38, 42, 48, 50, 52, 54, 55, 56, 58, 59, 62, 73, 75], "i": [12, 14, 16, 17, 19, 20, 22, 23, 24, 25, 27, 29, 30, 33, 34, 36, 37, 38, 39, 40, 47, 49, 51, 53, 54, 56, 57, 59, 60, 61, 62, 64, 65, 69, 70, 71], "iclick": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 68, 80], "idea": [15, 20, 22, 24, 28, 34, 36, 38, 40, 52, 57, 59, 61, 69], "identifi": [17, 23, 30, 37, 54, 60], "imag": [12, 25, 43, 49, 66], "imagenet": 66, "imbal": [20, 21, 22, 23, 34, 35, 36, 37, 38, 39, 48, 57, 58, 59, 60], "import": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75], "improv": 71, "imput": [16, 29, 53, 64], "incorpor": [17, 30, 44, 54], "increas": [20, 34, 47, 57], "index": 8, "inertia": 62, "info": 7, "inform": [23, 37, 39, 60, 67], "initi": [62, 70], "inject": [22, 36, 38, 59], "input": [12, 25, 49, 62], "instal": [5, 10], "instruct": [0, 7], "instructor": 1, "interact": [24, 40, 61], "intercept": [18, 32, 55], "interest": 69, "interim": [20, 23, 24, 34, 37, 39, 40, 47, 57, 60, 61, 67], "interpret": [18, 23, 31, 32, 37, 39, 45, 46, 55, 60, 70], "intra": 62, "intro": 64, "introduct": [8, 12, 23, 24, 25, 37, 39, 40, 49, 60, 61, 62, 63, 65, 66, 69, 73], "intuit": [18, 32, 55], "involv": [67, 69], "issu": 69, "join": [15, 24], "jupyt": [12, 25], "jupyterlab": 10, "k": [15, 16, 28, 29, 52, 53, 62, 63, 64], "kaplan": 68, "kei": [23, 37, 39, 60, 69, 70], "kernel": [15, 28, 52], "kind": [22, 36, 38, 59], "kneighborsclassifi": [15, 28, 43, 52], "knn": [43, 44], "l1": 40, "l2": 40, "label": [12, 25, 49, 62, 69], "lag": 67, "land": 80, "languag": 65, "larg": [19, 33, 56], "lasso": 40, "late": 7, "latitud": [13, 50, 74], "lda": 65, "learn": [1, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70], "least": [18, 32, 55], "lectur": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 80], "let": [15, 16, 17, 20, 21, 23, 28, 29, 30, 34, 35, 37, 44, 47, 52, 53, 54, 57, 58, 60, 69], "lgbm": 39, "licens": [0, 1], "lightgbm": [22, 36, 38, 59], "limit": [6, 18, 32, 55, 63], "line": 5, "linear": [18, 21, 23, 31, 32, 35, 37, 39, 40, 45, 46, 55, 58, 60], "link": 1, "list": 9, "liver": [12, 25, 49], "ll": [14, 27, 51], "lo": [14, 16, 17, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 64, 66, 67, 70], "load": 70, "local": 70, "localhost": 70, "log": 48, "logist": [18, 20, 32, 34, 40, 47, 55, 57, 66], "logisticregress": [20, 34, 57, 67, 68, 69], "longitud": [13, 50, 74], "look": [20, 34, 47, 57, 62], "loop": 8, "loss": 69, "lower": [19, 33, 56], "mac": 5, "machin": [1, 12, 13, 14, 15, 20, 25, 26, 27, 28, 34, 42, 47, 49, 50, 51, 52, 57, 62, 70], "maco": 10, "macro": [20, 34, 57], "magnitud": [18, 32, 55], "mai": [24, 40, 61], "main": [18, 32, 55, 64, 69], "make": [8, 18, 32, 55, 69], "make_column_transform": [17, 30, 54], "make_pipelin": [16, 29, 53], "mani": [17, 19, 33, 54, 56], "manual": [19, 33, 56], "mape": [21, 35, 48, 58], "materi": [0, 1, 9], "matplotlib": 8, "matric": [17, 30, 54], "matrix": [20, 34, 47, 57, 64], "matter": 27, "max_depth": [13, 26, 50], "mean": [21, 35, 48, 58, 62, 63, 65, 69], "measur": 61, "media": 65, "meet": [12, 25, 49, 80], "meier": 68, "messag": [12, 25, 49, 63], "meta": 72, "method": [8, 19, 24, 33, 40, 44, 56, 61, 62], "metric": [20, 21, 34, 35, 47, 48, 57, 58, 73], "midterm": [62, 80], "might": 68, "min": [8, 12, 13, 14, 15, 16, 17, 20, 23, 24, 25, 26, 27, 28, 30, 37, 39, 50, 51, 52, 53, 54, 57, 60, 61, 62, 65, 66, 68, 69, 70], "minor": [20, 57], "misc": [1, 9], "miscellan": 64, "mislead": 69, "ml": [12, 14, 15, 20, 23, 25, 27, 28, 34, 37, 39, 42, 49, 51, 52, 57, 60, 69, 73, 78], "model": [12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 65, 66, 68, 70, 71, 73, 75, 78], "model_select": [19, 33, 56], "moment": 70, "month": 67, "more": [13, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 30, 32, 34, 35, 40, 47, 48, 50, 52, 53, 54, 55, 57, 58, 61, 63, 67], "most": [18, 31, 32, 45, 46, 47, 55], "motiv": [14, 15, 16, 18, 19, 20, 22, 23, 24, 27, 28, 29, 32, 33, 34, 36, 37, 39, 40, 47, 51, 52, 53, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 67, 69], "movi": 64, "mse": [21, 35, 48, 58], "much": [19, 33, 56], "multi": [20, 57, 66, 72], "multiclass": 73, "multipl": [15, 17, 21, 28, 30, 35, 39, 48, 52, 54, 58], "multipli": 8, "n_estim": [22, 36, 38, 59], "n_iter": [19, 33, 56], "n_job": [19, 33, 56], "n_neighbor": [15, 28, 52], "name": [14, 21, 27, 35, 51, 58, 64], "natur": 65, "nearest": [15, 16, 28, 29, 52, 53, 62, 64], "need": [16, 19, 29, 33, 53, 56], "neg": [20, 31, 34, 45, 46, 47, 57], "neighbour": [15, 16, 28, 29, 52, 53, 64], "nest": 8, "netflix": [22, 36, 59], "network": 66, "neural": 66, "new": [69, 70], "next": [12, 25, 70], "nlp": [65, 73], "nn": [15, 28, 52], "non": [15, 17, 23, 28, 30, 39, 52, 54, 60], "notat": 8, "note": [8, 14, 51, 67, 75], "notebook": [12, 25], "now": 68, "number": [22, 36, 38, 59, 62, 67], "numer": [23, 24, 37, 39, 40, 60, 61], "numpi": 8, "object": [11, 13, 22, 26, 36, 38, 50, 59, 65, 66, 67, 68, 69, 70], "observ": [20, 34, 47, 57], "occasion": [16, 29, 53], "off": [14, 15, 22, 27, 28, 36, 38, 51, 52, 59], "oh": [16, 17, 29, 30, 53, 54], "ok": [16, 17, 29, 30, 53, 54], "onc": [20, 34, 47, 57], "one": [17, 24, 30, 40, 54, 61], "onehotencod": [17, 30, 54], "onli": [17, 30, 54, 68], "onlin": [1, 9], "oper": [20, 34, 47, 57], "optim": [19, 33, 42, 56, 73], "option": [10, 15, 16, 19, 20, 22, 24, 28, 29, 33, 34, 38, 40, 47, 52, 53, 56, 57, 59, 61, 68, 70], "ordin": [1, 16, 17, 23, 29, 30, 37, 39, 44, 53, 54, 60, 80], "other": [8, 15, 21, 24, 28, 35, 40, 52, 58, 61, 62, 65, 67, 68, 69], "our": [7, 14, 16, 27, 29, 51, 53, 69, 70, 71], "out": [16, 24, 29, 40, 53, 61, 66, 69, 70], "outcom": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 39, 40, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64], "outlin": [74, 75, 76, 77, 78, 79], "output": 62, "over": [8, 15, 18, 20, 28, 32, 52, 55, 57], "overfit": [14, 19, 27, 33, 51, 56], "oversampl": [20, 57], "overview": [15, 20, 28, 34, 47, 52, 57], "ovo": 72, "ovr": 72, "packag": [10, 67], "panda": 8, "pandas_profil": [21, 35, 58], "paper": [20, 22, 34, 36, 38, 57, 59], "paradigm": [16, 29, 53], "paramet": [13, 18, 19, 20, 26, 32, 33, 34, 50, 55, 56, 57, 73], "parametr": [15, 28, 52], "pars": 67, "part": 73, "pass": [19, 33, 56], "patient": [12, 25, 49], "penalti": 40, "perfect": 62, "perhap": 69, "permutation_import": [23, 37, 39, 60], "persona": [12, 25, 49], "piazza": 4, "pick": [14, 19, 27, 33, 51, 56], "pictur": [13, 14, 16, 26, 27, 29, 50, 51, 53], "piec": 69, "pipelin": [16, 29, 44, 53, 65], "plan": 63, "playground": [15, 28, 43, 52, 75], "plot": [8, 23, 37, 39, 60, 62, 68], "point": [15, 20, 23, 28, 34, 37, 39, 47, 52, 57, 60, 62, 67], "polici": 6, "poll": 62, "ponder": [31, 45, 46], "popular": [12, 25, 49], "posit": [20, 31, 34, 45, 46, 47, 57], "posix": 67, "possibl": [17, 21, 30, 35, 54, 58, 62, 71], "post": 9, "pr": [20, 34, 47, 57], "practic": [15, 26, 50, 52], "pre": 66, "precis": [20, 34, 47, 57], "predict": [12, 13, 17, 18, 22, 23, 25, 26, 32, 37, 38, 39, 49, 50, 54, 55, 59, 60, 64, 66, 68, 72, 74], "predict_proba": [18, 32, 55, 69], "predictor": 70, "prefer": 69, "prepar": [7, 73], "preprocess": [16, 17, 21, 29, 30, 35, 48, 53, 54, 58, 65, 67, 69, 70, 73, 78], "prerequisit": [12, 25], "preval": [12, 25, 49], "price": [12, 13, 25, 49, 50], "principl": 69, "prize": [22, 36, 59], "pro": [15, 28, 52, 63, 73], "probabl": [18, 19, 32, 33, 55, 56], "problem": [13, 14, 15, 16, 19, 24, 26, 27, 28, 29, 33, 40, 50, 51, 52, 53, 56, 61, 64, 67, 70, 71], "procedur": [20, 34, 57], "process": 65, "product": [12, 25, 49], "profil": 64, "program": [13, 26, 50], "project": 71, "properli": 44, "proport": 68, "python": [8, 9, 10, 12, 25], "q": 4, "qualiti": 61, "queri": [8, 15, 28, 52], "question": [4, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79], "quick": [15, 52], "quiz": [13, 26, 50], "quiz2": [13, 26, 50], "quot": [24, 40, 61], "r": [21, 35, 48, 58], "random": [19, 22, 23, 33, 36, 37, 38, 39, 56, 59, 60, 69], "random_st": [14, 27, 51], "randomforestclassifi": [22, 36, 38, 59, 68], "randomizedsearchcv": [19, 21, 33, 35, 48, 56, 58], "rang": [19, 33, 56], "rate": 64, "raw": [18, 32, 55], "rbf": [15, 28, 43, 52], "re": 69, "read": [8, 13, 19, 26, 33, 50, 56, 66], "reader": 69, "real": [13, 50, 70, 74], "realist": [17, 30, 54], "reason": 6, "recal": [20, 34, 47, 57], "recap": [13, 15, 26, 40, 50, 52, 63, 68, 69, 74, 76], "receiv": [20, 34, 47, 57], "recip": 70, "recommend": [12, 16, 25, 29, 53, 64, 73], "record": 80, "recurs": [24, 40, 61], "red": [74, 75, 76, 77, 78, 79], "refer": [1, 9, 68], "reflect": [13, 14, 26, 27, 50, 51, 62, 63], "registr": [12, 25, 80], "regress": [13, 15, 18, 20, 21, 22, 26, 28, 32, 34, 35, 38, 40, 47, 48, 50, 52, 55, 57, 58, 59, 66], "regressor": [15, 28, 52], "relat": [4, 13, 15, 26, 28, 50, 52, 69], "relev": [9, 20, 22, 24, 34, 36, 38, 40, 57, 59, 61], "remark": 67, "rememb": 62, "remind": [13, 50, 64], "remov": 8, "renam": 8, "render": 70, "report": [7, 20, 34, 47, 57], "repositori": 7, "represent": [17, 30, 54, 66], "request": 70, "requir": [12, 25, 70], "rescu": [14, 27, 51], "resourc": [9, 12, 19, 20, 24, 25, 33, 34, 40, 56, 57, 61, 62, 63, 64], "rest": 72, "result": [19, 33, 56, 69], "retail": 67, "reus": 69, "review": [31, 45, 46, 70], "revis": 42, "rf": 69, "rfe": [24, 40, 61], "ridg": [18, 21, 32, 35, 40, 48, 55, 58], "ridgecv": [21, 35, 48, 58], "right": 68, "rmse": [21, 35, 48, 58], "roc": [20, 34, 47, 57], "root": [21, 35, 48, 58], "row": 8, "rule": [14, 16, 17, 27, 29, 30, 51, 53, 54], "run": [16, 29, 53, 69], "same": [8, 48], "sampl": [20, 22, 36, 38, 57, 59, 62], "sauc": 62, "save": [12, 25, 49, 70], "scale": [12, 16, 18, 23, 25, 29, 32, 37, 39, 44, 49, 53, 55, 60], "scenario": 47, "schedul": 1, "scheme": 80, "scikit": [14, 16, 17, 21, 27, 29, 30, 35, 48, 51, 53, 54, 58], "score": [13, 14, 18, 19, 20, 21, 24, 26, 27, 32, 33, 34, 35, 40, 47, 48, 50, 51, 55, 56, 57, 58, 61, 62, 71], "search": [15, 19, 24, 28, 33, 40, 52, 56, 61, 69], "season": 67, "segment": 62, "select": [12, 13, 24, 25, 40, 49, 50, 61, 62, 63, 64, 73], "send": 70, "separ": [21, 23, 35, 37, 48, 58, 60, 69], "seri": [8, 67, 73], "server": 70, "servic": 70, "set": [5, 10, 12, 14, 19, 20, 25, 27, 33, 34, 42, 51, 56, 57, 70], "set_config": [17, 30, 54], "shap": [23, 37, 39, 60], "shape": [8, 63], "shaplei": [23, 37, 39, 60], "short": 9, "should": [22, 36, 38, 59, 64, 69], "show": [23, 37, 39, 60, 69], "sigmoid": [18, 32, 55, 66], "sign": [18, 32, 55], "silhouett": 62, "similar": [15, 28, 52], "simpl": [14, 27, 51, 71], "simplefeatur": [23, 37, 39, 60], "simpleimput": 44, "simul": 79, "singl": [14, 27, 42, 51], "size": 8, "sklearn": [13, 16, 17, 19, 20, 22, 23, 26, 29, 30, 33, 34, 36, 37, 38, 39, 44, 50, 53, 54, 56, 57, 59, 60], "slowest": 8, "small": 69, "smote": [20, 57], "social": 65, "softmax": 66, "softwar": [0, 66, 67], "solut": 36, "solv": [19, 33, 56], "some": [13, 19, 20, 22, 24, 26, 33, 36, 38, 40, 47, 50, 56, 57, 59, 61, 70], "sort": 8, "sort_valu": 8, "sourc": [7, 37], "space": 67, "spaci": [65, 71], "spaghetti": 62, "spam": [12, 17, 25, 30, 49, 54], "spars": [17, 30, 54], "specif": [4, 24, 40, 61], "split": [14, 16, 20, 27, 29, 34, 42, 44, 51, 53, 57, 67, 75], "spotifi": [16, 19, 29, 33, 53, 56], "squar": [21, 35, 48, 58], "stack": [22, 36, 38, 59, 79], "standardscal": [16, 29, 53], "statement": [12, 13, 25, 49, 50, 62, 63, 64], "statist": 70, "step": [13, 26, 42, 50, 65, 76], "strategi": [22, 36, 38, 59, 72], "stratifi": [20, 34, 57], "strength": [18, 22, 32, 36, 38, 55, 59], "structur": 70, "studi": 73, "style": [12, 25], "submiss": 7, "submit": 7, "success": [19, 33, 56], "summari": [8, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 36, 37, 38, 39, 40, 47, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "supervis": [12, 13, 14, 15, 25, 26, 27, 28, 42, 49, 50, 51, 52, 62, 64, 70], "support": [15, 28, 52], "surviv": [68, 73], "svc": [20, 34, 47, 57], "svm": [15, 18, 28, 32, 43, 52, 55], "syllabu": [1, 80], "syntax": [16, 17, 19, 29, 30, 33, 53, 54, 56], "synthet": [20, 57], "system": [64, 73], "ta": [1, 80], "tabular": [13, 15, 26, 28, 50, 52, 70], "tackl": [21, 35, 48, 58], "take": 63, "takeawai": 70, "target": [12, 13, 17, 21, 25, 26, 30, 35, 48, 49, 50, 54, 58, 62], "task": 65, "teach": [1, 80], "team": [1, 80], "techniqu": [16, 20, 29, 53, 57], "templat": 7, "tempor": 67, "tent": 1, "terminologi": [13, 26, 50, 66], "test": [5, 14, 19, 27, 33, 42, 51, 56, 67], "test_df": [14, 27, 51], "test_siz": [14, 27, 51], "text": [17, 30, 44, 54, 65, 71], "than": [17, 19, 24, 30, 33, 40, 54, 56, 61, 69], "thei": [22, 36, 38, 59], "them": 8, "thi": [8, 12, 16, 17, 23, 25, 29, 30, 37, 39, 42, 44, 47, 49, 53, 54, 60, 69, 70], "thing": [16, 29, 53, 69], "threshold": [20, 34, 47, 57], "time": [6, 12, 25, 49, 67, 68, 73], "tip": 73, "todai": [14, 16, 17, 20, 21, 27, 29, 30, 34, 35, 48, 51, 53, 54, 57, 58, 69], "toi": [13, 17, 20, 26, 30, 34, 47, 50, 54, 57, 65], "token": 65, "tool": 65, "topic": 65, "trade": [14, 15, 22, 27, 28, 36, 38, 51, 52, 59], "tradeoff": [14, 20, 22, 27, 34, 36, 38, 47, 51, 57, 59], "tradit": [13, 26, 50, 67], "train": [12, 13, 14, 17, 18, 20, 25, 26, 27, 30, 32, 34, 49, 50, 51, 54, 55, 57, 66, 67, 69, 70, 78], "train_df": [14, 27, 51], "train_siz": [14, 27, 51], "transfer": 66, "transform": [16, 17, 21, 24, 29, 30, 35, 40, 48, 53, 54, 58, 61, 69], "transpar": [23, 37, 39, 60, 70], "tree": [13, 22, 23, 26, 36, 37, 38, 39, 42, 50, 59, 60, 69, 75], "trend": 67, "true": [12, 25, 49, 62, 63, 64], "try": [16, 21, 29, 35, 44, 53, 58, 69, 70], "tune": [21, 35, 48, 58, 62, 75], "tutori": [28, 34, 74, 75, 76, 77, 78, 79], "two": [17, 30, 54], "type": [12, 14, 20, 21, 23, 25, 27, 34, 35, 37, 47, 48, 49, 51, 57, 58, 60, 62, 67, 68, 69], "typic": [14, 27, 42, 51, 65], "u": 69, "ubc": 1, "ubuntu": 5, "under": [20, 34, 47, 57], "underfit": [14, 27, 51], "undersampl": [20, 57], "understand": 70, "unequ": 67, "unknown": [17, 30, 54], "unlabel": 62, "unseen": [12, 14, 25, 27, 49, 51], "unsupervis": [13, 26, 50, 62], "up": [5, 10, 12, 14, 15, 25, 27, 28, 51, 52, 69, 70], "updat": 7, "url": 8, "us": [7, 8, 12, 13, 14, 15, 16, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 35, 36, 38, 40, 43, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 61, 62, 65, 66, 69, 72, 74, 80], "usa": [13, 50, 74], "user": [5, 64], "usual": [24, 40, 61], "util": 64, "v": [2, 12, 13, 14, 15, 20, 23, 25, 26, 27, 28, 34, 37, 39, 40, 47, 50, 51, 52, 57, 60, 62, 66, 70, 72], "valid": [14, 16, 19, 20, 27, 29, 33, 34, 42, 47, 51, 53, 56, 57, 67, 75], "varianc": [14, 27, 51], "vector": [8, 15, 28, 52, 65], "video": [12, 13, 14, 15, 16, 18, 20, 21, 22, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 38, 49, 50, 51, 52, 53, 55, 57, 58, 59, 62, 63, 65], "view": [15, 17, 28, 30, 52, 54], "violat": [14, 27, 51], "virtual": 10, "vision": [66, 73], "visual": [9, 19, 33, 39, 56, 69], "vocabulari": [31, 45, 46], "wai": [19, 24, 33, 40, 56, 61, 69], "waitlist": [12, 25], "want": [17, 23, 30, 37, 39, 54, 60, 68], "warn": [13, 24, 26, 40, 50, 61], "watch": 69, "waterfal": 39, "we": [8, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 68, 69, 70], "weak": [22, 36, 38, 59], "web": 70, "websit": [12, 25], "weight": [18, 20, 32, 34, 55, 57], "what": [5, 10, 12, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 68, 69, 70], "when": [8, 16, 19, 29, 33, 53, 56, 69], "where": [17, 30, 54, 68], "whether": [12, 25, 49], "which": [12, 13, 20, 22, 25, 34, 36, 38, 47, 49, 50, 57, 59, 62, 63, 64], "why": [10, 12, 17, 19, 23, 24, 25, 27, 30, 33, 37, 39, 40, 49, 54, 56, 60, 61, 64, 66, 69], "window": [5, 10], "wise": 8, "without": 62, "word": [17, 30, 54, 65, 71], "work": [13, 22, 26, 36, 38, 50, 59, 63, 69], "workflow": [12, 14, 20, 27, 34, 47, 49, 51, 57], "would": [14, 27, 44, 47, 51, 70], "wrapper": 72, "write": [13, 26, 50], "x": [12, 13, 21, 23, 25, 26, 35, 37, 48, 49, 50, 58, 60, 69], "xgboost": [22, 36, 38, 59], "y": [12, 13, 21, 23, 25, 26, 35, 37, 48, 49, 50, 58, 60, 69], "ye": 68, "yield": [19, 33, 56], "you": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70], "your": [5, 12, 13, 25, 26, 42, 50, 69]}})