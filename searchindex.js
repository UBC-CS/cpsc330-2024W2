Search.setIndex({"alltitles": {"": [[63, "id1"]], "(Optional)": [[54, "optional"]], "(Optional) Changing the data": [[20, "optional-changing-the-data"], [79, "optional-changing-the-data"]], "(Optional) Evaluation": [[31, "optional-evaluation"], [61, "optional-evaluation"], [90, "optional-evaluation"]], "(Optional) Evaluation metrics for multi-class classification": [[20, "optional-evaluation-metrics-for-multi-class-classification"], [79, "optional-evaluation-metrics-for-multi-class-classification"]], "(Optional) Example 1: Optimization bias": [[19, "optional-example-1-optimization-bias"], [40, "optional-example-1-optimization-bias"], [78, "optional-example-1-optimization-bias"]], "(Optional) Example 2: Optimization bias": [[19, "optional-example-2-optimization-bias"], [40, "optional-example-2-optimization-bias"], [78, "optional-example-2-optimization-bias"]], "(Optional) Fancier methods": [[19, "optional-fancier-methods"], [40, "optional-fancier-methods"], [78, "optional-fancier-methods"]], "(Optional) Fitting in boosted regression trees.": [[22, "optional-fitting-in-boosted-regression-trees"], [52, "optional-fitting-in-boosted-regression-trees"], [81, "optional-fitting-in-boosted-regression-trees"]], "(Optional) Forward or backward selection": [[24, "optional-forward-or-backward-selection"], [45, "optional-forward-or-backward-selection"], [54, "optional-forward-or-backward-selection"], [83, "optional-forward-or-backward-selection"]], "(Optional) Macro average and weighted average": [[20, "optional-macro-average-and-weighted-average"], [41, "optional-macro-average-and-weighted-average"], [79, "optional-macro-average-and-weighted-average"]], "(Optional) Parametric vs non parametric": [[15, "optional-parametric-vs-non-parametric"], [35, "optional-parametric-vs-non-parametric"], [74, "optional-parametric-vs-non-parametric"]], "(Optional) Passing probability distributions to random search": [[19, "optional-passing-probability-distributions-to-random-search"], [40, "optional-passing-probability-distributions-to-random-search"], [78, "optional-passing-probability-distributions-to-random-search"]], "(Optional) Prediction in boosted regression trees": [[22, "optional-prediction-in-boosted-regression-trees"], [52, "optional-prediction-in-boosted-regression-trees"], [81, "optional-prediction-in-boosted-regression-trees"]], "(Optional) Problems with feature selection": [[24, "optional-problems-with-feature-selection"], [45, "optional-problems-with-feature-selection"], [54, "optional-problems-with-feature-selection"], [83, "optional-problems-with-feature-selection"]], "(Optional) Search and score": [[24, "optional-search-and-score"], [45, "optional-search-and-score"], [54, "optional-search-and-score"], [83, "optional-search-and-score"]], "(Optional) Searching for optimal parameters with successive halving\u00b6": [[19, "optional-searching-for-optimal-parameters-with-successive-halving"], [40, "optional-searching-for-optimal-parameters-with-successive-halving"], [78, "optional-searching-for-optimal-parameters-with-successive-halving"]], "(Optional) Setting up a directory structure and environment": [[92, "optional-setting-up-a-directory-structure-and-environment"]], "(Optional) Some more details": [[20, "optional-some-more-details"], [68, "optional-some-more-details"], [79, "optional-some-more-details"]], "(Supervised) machine learning: popular definition": [[12, "supervised-machine-learning-popular-definition"], [32, "supervised-machine-learning-popular-definition"], [71, "supervised-machine-learning-popular-definition"]], "(iClicker) Exercise 14.1": [[83, "id1"]], "(iClicker) Exercise 14.1 https://join.iclicker.com/FUYI": [[24, "id1"]], "(iClicker) Exercise 14.2": [[54, "iclicker-exercise-14-2"]], "(iClicker) Exercise 14.3": [[54, "iclicker-exercise-14-3"]], "(iClicker) Exercise 21.1": [[61, "iclicker-exercise-21-1"], [90, "iclicker-exercise-21-1"]], "(iClicker) Exercise 21.1 https://join.iclicker.com/FUYI": [[31, "iclicker-exercise-21-1-https-join-iclicker-com-fuyi"]], "(iClicker) Exercise 21.2": [[61, "iclicker-exercise-21-2"], [90, "iclicker-exercise-21-2"]], "(iClicker) Exercise 21.2 https://join.iclicker.com/FUYI": [[31, "iclicker-exercise-21-2-https-join-iclicker-com-fuyi"]], "(iClicker) Exercise 4.1": [[35, "iclicker-exercise-4-1"], [74, "iclicker-exercise-4-1"]], "(iClicker) Exercise 4.1 https://join.iclicker.com/FUYI": [[15, "iclicker-exercise-4-1-https-join-iclicker-com-fuyi"]], "(iClicker) Exercise 4.2": [[35, "iclicker-exercise-4-2"], [74, "iclicker-exercise-4-2"]], "(iClicker) Exercise 4.2 https://join.iclicker.com/FUYI": [[15, "iclicker-exercise-4-2-https-join-iclicker-com-fuyi"]], "(iClicker) Exercise 5.1": [[16, "iclicker-exercise-5-1"], [36, "iclicker-exercise-5-1"], [75, "iclicker-exercise-5-1"]], "(iClicker) Exercise 5.2": [[16, "iclicker-exercise-5-2"], [36, "iclicker-exercise-5-2"], [75, "iclicker-exercise-5-2"]], "(iClicker) Exercise 5.3": [[16, "iclicker-exercise-5-3"], [36, "iclicker-exercise-5-3"], [75, "iclicker-exercise-5-3"]], "(iClicker) Exercise 6.1": [[17, "iclicker-exercise-6-1"], [37, "iclicker-exercise-6-1"], [76, "iclicker-exercise-6-1"]], "(iClicker) Exercise 6.2": [[17, "iclicker-exercise-6-2"], [37, "iclicker-exercise-6-2"], [76, "iclicker-exercise-6-2"]], "(iClicker) Exercise 7.1": [[18, "iclicker-exercise-7-1"], [39, "iclicker-exercise-7-1"], [77, "iclicker-exercise-7-1"]], "(iClicker) Exercise 7.2": [[18, "iclicker-exercise-7-2"], [39, "iclicker-exercise-7-2"], [77, "iclicker-exercise-7-2"]], "(iClicker) Exercise 7.3": [[39, "iclicker-exercise-7-3"]], "(iClicker) Exercise 8.1": [[19, "iclicker-exercise-8-1"], [40, "iclicker-exercise-8-1"], [78, "iclicker-exercise-8-1"]], "(iClicker) Midterm poll": [[84, "iclicker-midterm-poll"]], "15.1 Select all of the following statements which are True (iClicker)": [[46, "select-all-of-the-following-statements-which-are-true-iclicker"], [55, "select-all-of-the-following-statements-which-are-true-iclicker"], [84, "select-all-of-the-following-statements-which-are-true-iclicker"]], "15.1 Select all of the following statements which are True (iClicker) https://join.iclicker.com/FUYI": [[25, "select-all-of-the-following-statements-which-are-true-iclicker-https-join-iclicker-com-fuyi"]], "15.2 Select all of the following statements which are True (iClicker)": [[46, "id1"], [55, "id1"], [84, "id1"]], "15.2 Select all of the following statements which are True (iClicker) https://join.iclicker.com/FUYI": [[25, "id1"]], "15.3 Select all of the following statements which are True (iClicker)": [[46, "id3"], [55, "id2"], [84, "id3"]], "15.3 Select all of the following statements which are True (iClicker) https://join.iclicker.com/FUYI": [[25, "id3"]], "16.1 Select all of the following statements which are True (iClicker)": [[47, "select-all-of-the-following-statements-which-are-true-iclicker"], [56, "select-all-of-the-following-statements-which-are-true-iclicker"], [85, "select-all-of-the-following-statements-which-are-true-iclicker"]], "16.1 Select all of the following statements which are True https://join.iclicker.com/FUYI": [[26, "select-all-of-the-following-statements-which-are-true-https-join-iclicker-com-fuyi"]], "16.2 Select all of the following statements which are True (iClicker)": [[47, "id2"], [56, "id2"], [85, "id2"]], "16.2 Select all of the following statements which are True https://join.iclicker.com/FUYI": [[26, "id2"]], "16.3 Select all of the following statements which are True": [[26, "select-all-of-the-following-statements-which-are-true"], [47, "select-all-of-the-following-statements-which-are-true"], [56, "select-all-of-the-following-statements-which-are-true"], [85, "select-all-of-the-following-statements-which-are-true"]], "330 vs. 340": [[92, "vs-340"]], "<font color='red'>Question 10</font>": [[101, "question-10"]], "<font color='red'>Question 1</font>": [[96, "question-1"], [97, "question-1"], [99, "question-1"], [100, "question-1"], [101, "question-1"], [102, "question-1"]], "<font color='red'>Question 2: Baseline model</font>": [[97, "question-2-baseline-model"]], "<font color='red'>Question 2</font>": [[96, "question-2"], [99, "question-2"], [100, "question-2"], [101, "question-2"], [102, "question-2"]], "<font color='red'>Question 3: Decision tree</font>": [[97, "question-3-decision-tree"]], "<font color='red'>Question 3</font>": [[96, "question-3"], [99, "question-3"], [100, "question-3"], [101, "question-3"], [102, "question-3"]], "<font color='red'>Question 4: Hyperparameter tuning</font>": [[97, "question-4-hyperparameter-tuning"]], "<font color='red'>Question 4</font>": [[96, "question-4"], [99, "question-4"], [100, "question-4"], [101, "question-4"], [102, "question-4"]], "<font color='red'>Question 5: Cross-validation</font>": [[97, "question-5-cross-validation"]], "<font color='red'>Question 5</font>": [[99, "question-5"], [100, "question-5"], [101, "question-5"], [102, "question-5"]], "<font color='red'>Question 6: Hyperparameters playground</font>": [[97, "question-6-hyperparameters-playground"]], "<font color='red'>Question 6</font>": [[99, "question-6"], [100, "question-6"], [101, "question-6"], [102, "question-6"]], "<font color='red'>Question 7</font>": [[99, "question-7"], [101, "question-7"]], "<font color='red'>Question 8</font>": [[99, "question-8"], [101, "question-8"]], "<font color='red'>Question 9</font>": [[101, "question-9"]], "<font color='red'>Recap Questions</font>": [[96, "recap-questions"]], "<font color='red'>Recap/comprehension questions</font>": [[98, "recap-comprehension-questions"]], "A caution about word embeddings": [[58, "a-caution-about-word-embeddings"]], "A comment on initialization": [[55, "a-comment-on-initialization"]], "A corpus of scientific articles": [[58, "a-corpus-of-scientific-articles"]], "A few comments on PR curve": [[20, "a-few-comments-on-pr-curve"], [41, "a-few-comments-on-pr-curve"], [68, "a-few-comments-on-pr-curve"], [79, "a-few-comments-on-pr-curve"]], "A few comments on clustering evaluation": [[26, "a-few-comments-on-clustering-evaluation"], [47, "a-few-comments-on-clustering-evaluation"], [56, "a-few-comments-on-clustering-evaluation"], [85, "a-few-comments-on-clustering-evaluation"]], "A regression model for Eva": [[57, "a-regression-model-for-eva"]], "A regression model for Pat": [[57, "a-regression-model-for-pat"]], "AP score": [[20, "ap-score"], [41, "ap-score"], [68, "ap-score"], [79, "ap-score"]], "AP vs. F1-score": [[20, "ap-vs-f1-score"], [41, "ap-vs-f1-score"], [68, "ap-vs-f1-score"], [79, "ap-vs-f1-score"]], "API on the localhost": [[92, "api-on-the-localhost"]], "AUC or AP?": [[41, "auc-or-ap"]], "About this course": [[12, "about-this-course"], [32, "about-this-course"]], "About this document": [[8, "about-this-document"]], "Academic concessions": [[103, "academic-concessions"]], "Accessing homework assignments": [[7, "accessing-homework-assignments"]], "Accessing learned parameters": [[18, "accessing-learned-parameters"], [39, "accessing-learned-parameters"], [77, "accessing-learned-parameters"]], "Activity": [[12, "activity"], [32, "activity"]], "Activity (~5 mins)": [[23, "activity-5-mins"], [23, "id3"], [44, "activity-5-mins"], [44, "id3"], [53, "activity-5-mins"], [53, "id3"], [82, "activity-5-mins"], [82, "id3"]], "Activity: Context and word meaning": [[28, "activity-context-and-word-meaning"], [49, "activity-context-and-word-meaning"], [58, "activity-context-and-word-meaning"], [87, "activity-context-and-word-meaning"]], "Activity: Discuss the following questions in your group": [[63, "activity-discuss-the-following-questions-in-your-group"]], "Activity: How can you measure quality of the data? (~3 mins)": [[83, "activity-how-can-you-measure-quality-of-the-data-3-mins"]], "Activity: explaining GridSearchCV (15 min)": [[91, "activity-explaining-gridsearchcv-15-min"]], "Adding/removing columns with [] and drop()": [[8, "adding-removing-columns-with-and-drop"]], "Adding/removing rows with [] and drop()": [[8, "adding-removing-rows-with-and-drop"]], "Additional sources": [[44, "additional-sources"]], "Additional submission instructions": [[7, "additional-submission-instructions"]], "Addressing class imbalance": [[20, "addressing-class-imbalance"], [41, "addressing-class-imbalance"], [79, "addressing-class-imbalance"]], "Advantages of RandomizedSearchCV": [[19, "advantages-of-randomizedsearchcv"], [19, "id1"], [40, "advantages-of-randomizedsearchcv"], [40, "id1"], [78, "advantages-of-randomizedsearchcv"], [78, "id1"]], "Advantages of content-based filtering": [[57, "advantages-of-content-based-filtering"]], "Alternative and more compact syntax: make_pipeline": [[16, "alternative-and-more-compact-syntax-make-pipeline"], [36, "alternative-and-more-compact-syntax-make-pipeline"], [75, "alternative-and-more-compact-syntax-make-pipeline"]], "Alternative methods for scaling": [[65, "alternative-methods-for-scaling"]], "Alternative terminology for examples, features, targets, and training": [[13, "alternative-terminology-for-examples-features-targets-and-training"], [33, "alternative-terminology-for-examples-features-targets-and-training"], [72, "alternative-terminology-for-examples-features-targets-and-training"]], "Ambiguous news headlines": [[58, "ambiguous-news-headlines"]], "An effective strategy": [[22, "an-effective-strategy"], [43, "an-effective-strategy"], [52, "an-effective-strategy"], [81, "an-effective-strategy"]], "An example from a project": [[93, "an-example-from-a-project"]], "An example of a bootstrap samples": [[22, "an-example-of-a-bootstrap-samples"], [43, "an-example-of-a-bootstrap-samples"], [52, "an-example-of-a-bootstrap-samples"], [81, "an-example-of-a-bootstrap-samples"]], "An introduction to Grid Search": [[91, "an-introduction-to-grid-search"]], "Analogy-based algorithms in practice": [[15, "analogy-based-algorithms-in-practice"], [74, "analogy-based-algorithms-in-practice"]], "Analogy-based models": [[15, "analogy-based-models"], [74, "analogy-based-models"]], "Announcements": [[12, "announcements"], [13, "announcements"], [14, "announcements"], [16, "announcements"], [17, "announcements"], [18, "announcements"], [20, "announcements"], [52, "announcements"], [53, "announcements"], [54, "announcements"], [77, "announcements"]], "Appendix A: Demo of feature engineering for text data": [[93, null]], "Appendix B: Multi-class, meta-strategies": [[94, null]], "Applicatiion - testing a lymphoma biomarker": [[61, "applicatiion-testing-a-lymphoma-biomarker"]], "Applying feature transformations": [[21, "applying-feature-transformations"], [42, "applying-feature-transformations"], [69, "applying-feature-transformations"], [80, "applying-feature-transformations"], [91, "applying-feature-transformations"]], "Applying functions to a dataframe with df.apply() and df.applymap()": [[8, "applying-functions-to-a-dataframe-with-df-apply-and-df-applymap"]], "Approach 1: Only consider the examples where \u201cChurn\u201d=Yes": [[31, "approach-1-only-consider-the-examples-where-churn-yes"], [61, "approach-1-only-consider-the-examples-where-churn-yes"], [90, "approach-1-only-consider-the-examples-where-churn-yes"]], "Approach 2: Assume everyone churns right now": [[31, "approach-2-assume-everyone-churns-right-now"], [61, "approach-2-assume-everyone-churns-right-now"], [90, "approach-2-assume-everyone-churns-right-now"]], "Approach 3: Survival analysis": [[31, "approach-3-survival-analysis"], [61, "approach-3-survival-analysis"], [90, "approach-3-survival-analysis"]], "Approach from all angles": [[91, "approach-from-all-angles"]], "Are we doing better with class_weight=\"balanced\"?": [[20, "are-we-doing-better-with-class-weight-balanced"], [41, "are-we-doing-better-with-class-weight-balanced"], [79, "are-we-doing-better-with-class-weight-balanced"]], "Are we getting the same alpha with mape?": [[69, "are-we-getting-the-same-alpha-with-mape"]], "Area under the curve (AUC)": [[20, "area-under-the-curve-auc"], [41, "area-under-the-curve-auc"], [68, "area-under-the-curve-auc"], [79, "area-under-the-curve-auc"]], "Assessing on the test set": [[63, "assessing-on-the-test-set"]], "Assignments": [[103, "assignments"]], "Attention": [[13, null], [13, null], [15, null], [33, null], [33, null], [35, null], [72, null], [72, null], [72, null], [74, null]], "Attribution": [[91, "attribution"]], "Automated hyperparameter optimization": [[19, "automated-hyperparameter-optimization"], [19, "id3"], [40, "automated-hyperparameter-optimization"], [40, "id3"], [78, "automated-hyperparameter-optimization"], [78, "id3"]], "Average embeddings with": [[58, "average-embeddings-with"]], "Averaging": [[22, "averaging"], [43, "averaging"], [52, "averaging"], [81, "averaging"]], "Averaging embeddings": [[58, "averaging-embeddings"]], "Averaging simulation": [[101, "averaging-simulation"]], "Bad range for hyperparameters": [[19, "bad-range-for-hyperparameters"], [40, "bad-range-for-hyperparameters"], [78, "bad-range-for-hyperparameters"]], "Bag of words (BOW) representation": [[17, "bag-of-words-bow-representation"], [37, "bag-of-words-bow-representation"], [76, "bag-of-words-bow-representation"]], "Bag-of-words model": [[93, "bag-of-words-model"]], "Baseline": [[20, "baseline"], [23, "baseline"], [41, "baseline"], [44, "baseline"], [53, "baseline"], [68, "baseline"], [69, "baseline"], [79, "baseline"], [82, "baseline"]], "Baseline Approaches": [[27, "baseline-approaches"], [48, "baseline-approaches"], [57, "baseline-approaches"], [86, "baseline-approaches"]], "Baseline model": [[63, "baseline-model"]], "Baselines": [[13, "baselines"], [22, "baselines"], [33, "baselines"], [43, "baselines"], [52, "baselines"], [59, "baselines"], [72, "baselines"], [81, "baselines"]], "Baselines [video]": [[13, "baselines-video"], [33, "baselines-video"], [72, "baselines-video"]], "Basic text preprocessing [video]": [[28, "basic-text-preprocessing-video"], [49, "basic-text-preprocessing-video"], [58, "basic-text-preprocessing-video"], [87, "basic-text-preprocessing-video"]], "Better features usually help more than a better model.": [[24, "better-features-usually-help-more-than-a-better-model"], [45, "better-features-usually-help-more-than-a-better-model"], [54, "better-features-usually-help-more-than-a-better-model"], [83, "better-features-usually-help-more-than-a-better-model"]], "Beyond error rate in recommendation systems": [[27, "beyond-error-rate-in-recommendation-systems"], [48, "beyond-error-rate-in-recommendation-systems"], [57, "beyond-error-rate-in-recommendation-systems"], [86, "beyond-error-rate-in-recommendation-systems"]], "Bias vs variance tradeoff": [[14, "bias-vs-variance-tradeoff"], [34, "bias-vs-variance-tradeoff"], [73, "bias-vs-variance-tradeoff"]], "Big picture and datasets": [[13, "big-picture-and-datasets"], [33, "big-picture-and-datasets"], [72, "big-picture-and-datasets"]], "Big picture and motivation": [[14, "big-picture-and-motivation"], [34, "big-picture-and-motivation"], [73, "big-picture-and-motivation"]], "Books": [[1, "books"]], "Bottom-up explanations": [[91, "bottom-up-explanations"]], "Break (5 min)": [[8, "break-5-min"], [12, "break-5-min"], [13, "break-5-min"], [14, "break-5-min"], [15, "break-5-min"], [16, "break-5-min"], [17, "break-5-min"], [24, "break-5-min"], [28, "break-5-min"], [29, "break-5-min"], [31, "break-5-min"], [32, "break-5-min"], [33, "break-5-min"], [34, "break-5-min"], [35, "break-5-min"], [37, "break-5-min"], [49, "break-5-min"], [50, "break-5-min"], [58, "break-5-min"], [59, "break-5-min"], [61, "break-5-min"], [72, "break-5-min"], [73, "break-5-min"], [74, "break-5-min"], [75, "break-5-min"], [76, "break-5-min"], [83, "break-5-min"], [87, "break-5-min"], [88, "break-5-min"], [90, "break-5-min"], [91, "break-5-min"]], "Break (~15 min)": [[92, "break-15-min"]], "Broadcasting in numpy": [[8, "broadcasting-in-numpy"]], "Building a model": [[92, "building-a-model"]], "Building a supervise machine learning model": [[12, "building-a-supervise-machine-learning-model"], [32, "building-a-supervise-machine-learning-model"], [71, "building-a-supervise-machine-learning-model"]], "Building and deploying a web app": [[92, "building-and-deploying-a-web-app"]], "Building decision trees with sklearn": [[13, "building-decision-trees-with-sklearn"], [33, "building-decision-trees-with-sklearn"], [72, "building-decision-trees-with-sklearn"]], "Building user profiles": [[27, "building-user-profiles"], [48, "building-user-profiles"], [57, "building-user-profiles"], [86, "building-user-profiles"]], "CPSC 330 Documents": [[3, null]], "CPSC 330 Python notes": [[8, null]], "CPSC 330 grading policies": [[6, null]], "CPSC 330 vs. 340": [[12, "cpsc-330-vs-340"], [32, "cpsc-330-vs-340"]], "CPSC 330 vs. CPSC 340": [[2, null]], "Can we get feature importances for non-linear models?": [[53, "can-we-get-feature-importances-for-non-linear-models"]], "Can we learn without targets?": [[25, "can-we-learn-without-targets"], [46, "can-we-learn-without-targets"], [55, "can-we-learn-without-targets"], [84, "can-we-learn-without-targets"]], "Can we use this feature in the model?": [[16, "can-we-use-this-feature-in-the-model"], [36, "can-we-use-this-feature-in-the-model"], [75, "can-we-use-this-feature-in-the-model"]], "Cases where it\u2019s OK to break the golden rule": [[17, "cases-where-it-s-ok-to-break-the-golden-rule"], [37, "cases-where-it-s-ok-to-break-the-golden-rule"], [76, "cases-where-it-s-ok-to-break-the-golden-rule"]], "CatBoost": [[22, "catboost"], [43, "catboost"], [52, "catboost"], [81, "catboost"]], "Categorical features": [[23, "categorical-features"], [44, "categorical-features"], [53, "categorical-features"], [65, "categorical-features"], [82, "categorical-features"]], "Categorical features [video]": [[16, "categorical-features-video"], [36, "categorical-features-video"], [75, "categorical-features-video"]], "Categorical features with only two possible categories": [[17, "categorical-features-with-only-two-possible-categories"], [37, "categorical-features-with-only-two-possible-categories"], [76, "categorical-features-with-only-two-possible-categories"]], "Censoring and survival analysis": [[31, "censoring-and-survival-analysis"], [61, "censoring-and-survival-analysis"], [90, "censoring-and-survival-analysis"]], "Centre for Accessibility (CfA) Exam Accommodations": [[103, "centre-for-accessibility-cfa-exam-accommodations"]], "Changing the training procedure": [[20, "changing-the-training-procedure"], [41, "changing-the-training-procedure"], [79, "changing-the-training-procedure"]], "Characters in this course?": [[12, "characters-in-this-course"], [32, "characters-in-this-course"], [71, "characters-in-this-course"]], "Checklist for you before next class": [[12, "checklist-for-you-before-next-class"], [32, "checklist-for-you-before-next-class"]], "Choosing K": [[55, "choosing-k"]], "Choosing K [video]": [[25, "choosing-k-video"], [46, "choosing-k-video"], [84, "choosing-k-video"]], "Choosing n_neighbors": [[15, "choosing-n-neighbors"], [35, "choosing-n-neighbors"], [74, "choosing-n-neighbors"]], "Citing sources": [[7, "citing-sources"]], "Class imbalance in training sets": [[20, "class-imbalance-in-training-sets"], [41, "class-imbalance-in-training-sets"], [79, "class-imbalance-in-training-sets"]], "Class meetings": [[103, "class-meetings"]], "Classification report": [[20, "classification-report"], [41, "classification-report"], [68, "classification-report"], [79, "classification-report"]], "Classification vs. Regression": [[13, "classification-vs-regression"], [33, "classification-vs-regression"], [72, "classification-vs-regression"]], "Classification with KNeighborsClassifier": [[64, "classification-with-kneighborsclassifier"]], "Clustering": [[95, "clustering"]], "Clustering Activity (~5 mins)": [[25, "clustering-activity-5-mins"], [46, "clustering-activity-5-mins"], [55, "clustering-activity-5-mins"], [84, "clustering-activity-5-mins"]], "Clustering motivation [video]": [[25, "clustering-motivation-video"], [46, "clustering-motivation-video"], [84, "clustering-motivation-video"]], "Clustering: Input and (possible) output": [[25, "clustering-input-and-possible-output"], [46, "clustering-input-and-possible-output"], [55, "clustering-input-and-possible-output"], [84, "clustering-input-and-possible-output"]], "Code of conduct": [[103, "code-of-conduct"]], "Coefficients and intercept": [[18, "coefficients-and-intercept"], [39, "coefficients-and-intercept"], [77, "coefficients-and-intercept"]], "ColumnTransformer example": [[17, "columntransformer-example"], [37, "columntransformer-example"], [76, "columntransformer-example"]], "ColumnTransformer on the California housing dataset": [[76, "columntransformer-on-the-california-housing-dataset"], [98, "columntransformer-on-the-california-housing-dataset"]], "ColumnTransformer: Transformed data": [[17, "columntransformer-transformed-data"], [37, "columntransformer-transformed-data"], [76, "columntransformer-transformed-data"]], "Coming up \u2026": [[14, "coming-up"], [34, "coming-up"], [73, "coming-up"]], "Coming up:": [[15, "coming-up"], [35, "coming-up"], [74, "coming-up"]], "Command-line git": [[5, "command-line-git"]], "Common applications": [[25, "common-applications"], [46, "common-applications"], [55, "common-applications"], [84, "common-applications"]], "Common preprocessing techniques": [[16, "common-preprocessing-techniques"], [36, "common-preprocessing-techniques"], [75, "common-preprocessing-techniques"]], "Communication": [[95, "communication"]], "Communications": [[12, "communications"], [32, "communications"]], "Completing the utility matrix with content-based filtering": [[27, "completing-the-utility-matrix-with-content-based-filtering"], [48, "completing-the-utility-matrix-with-content-based-filtering"], [57, "completing-the-utility-matrix-with-content-based-filtering"], [86, "completing-the-utility-matrix-with-content-based-filtering"]], "Components of a linear classifier": [[18, "components-of-a-linear-classifier"], [39, "components-of-a-linear-classifier"], [77, "components-of-a-linear-classifier"]], "Computer vision problems": [[59, "computer-vision-problems"]], "Concepts then labels, not the other way around": [[91, "concepts-then-labels-not-the-other-way-around"]], "Concepts we revised in this demo": [[63, "concepts-we-revised-in-this-demo"]], "Conclusion & farewell": [[92, "conclusion-farewell"]], "Confidence and predict_proba (20 min)": [[91, "confidence-and-predict-proba-20-min"]], "Confusing and perhaps misleading visualization of results": [[91, "confusing-and-perhaps-misleading-visualization-of-results"]], "Confusion matrix": [[20, "confusion-matrix"], [68, "confusion-matrix"]], "Confusion matrix (video)": [[41, "confusion-matrix-video"], [79, "confusion-matrix-video"]], "Confusion matrix with cross-validation": [[20, "confusion-matrix-with-cross-validation"], [41, "confusion-matrix-with-cross-validation"], [68, "confusion-matrix-with-cross-validation"], [79, "confusion-matrix-with-cross-validation"]], "Cons of k-NNs for supervised learning": [[15, "cons-of-k-nns-for-supervised-learning"], [35, "cons-of-k-nns-for-supervised-learning"], [74, "cons-of-k-nns-for-supervised-learning"]], "Content-based filtering": [[27, "content-based-filtering"], [48, "content-based-filtering"], [57, "content-based-filtering"], [86, "content-based-filtering"]], "Convenient make_column_transformer syntax": [[17, "convenient-make-column-transformer-syntax"], [37, "convenient-make-column-transformer-syntax"], [76, "convenient-make-column-transformer-syntax"]], "Cosine similarity:": [[58, "cosine-similarity"]], "Course Learning Objectives": [[11, null]], "Course co-ordinator": [[1, "course-co-ordinator"], [103, "course-co-ordinator"]], "Course description": [[103, "course-description"]], "Course format": [[12, "course-format"], [32, "course-format"]], "Course review / conclusion (~20 min)": [[92, "course-review-conclusion-20-min"]], "Course website": [[12, "course-website"], [32, "course-website"]], "Cox proportional hazards model": [[31, "cox-proportional-hazards-model"], [61, "cox-proportional-hazards-model"], [90, "cox-proportional-hazards-model"]], "Create X and y": [[13, "create-x-and-y"], [33, "create-x-and-y"], [72, "create-x-and-y"]], "Create a classifier object": [[13, "create-a-classifier-object"], [33, "create-a-classifier-object"], [72, "create-a-classifier-object"]], "Create a column transformer": [[17, "create-a-column-transformer"], [37, "create-a-column-transformer"], [76, "create-a-column-transformer"]], "Creating dendrogram with single linkage": [[56, "creating-dendrogram-with-single-linkage"]], "Creating train_df and test_df": [[14, "creating-train-df-and-test-df"], [34, "creating-train-df-and-test-df"], [73, "creating-train-df-and-test-df"]], "Creating utility matrix": [[27, "creating-utility-matrix"], [48, "creating-utility-matrix"], [57, "creating-utility-matrix"], [57, "id3"], [57, "id4"], [57, "id5"], [86, "creating-utility-matrix"]], "Creating utility matrix (slightly simpler)": [[57, "creating-utility-matrix-slightly-simpler"]], "Creating utility matrix recap": [[57, "creating-utility-matrix-recap"]], "Credit": [[10, "credit"]], "Cross validation with different metrics": [[20, "cross-validation-with-different-metrics"], [41, "cross-validation-with-different-metrics"], [68, "cross-validation-with-different-metrics"], [79, "cross-validation-with-different-metrics"]], "Cross-validation": [[30, "cross-validation"], [30, "id4"], [51, "cross-validation"], [60, "cross-validation"], [63, "cross-validation"], [89, "cross-validation"], [89, "id4"]], "Cross-validation [video]": [[14, "cross-validation-video"], [34, "cross-validation-video"], [73, "cross-validation-video"]], "Cross-validation to the rescue!!": [[14, "cross-validation-to-the-rescue"], [34, "cross-validation-to-the-rescue"], [73, "cross-validation-to-the-rescue"]], "Cross-validation using scikit-learn": [[14, "cross-validation-using-scikit-learn"], [34, "cross-validation-using-scikit-learn"], [73, "cross-validation-using-scikit-learn"]], "Curse of dimensionality": [[15, "curse-of-dimensionality"], [35, "curse-of-dimensionality"], [74, "curse-of-dimensionality"]], "Customer churn": [[31, "customer-churn"], [61, "customer-churn"], [90, "customer-churn"]], "Customer segmentation": [[25, "customer-segmentation"], [46, "customer-segmentation"], [55, "customer-segmentation"], [84, "customer-segmentation"]], "DBSCAN [video]": [[26, "dbscan-video"], [47, "dbscan-video"], [56, "dbscan-video"], [85, "dbscan-video"]], "DBSCAN algorithm": [[56, "dbscan-algorithm"]], "DBSCAN introduction": [[26, "dbscan-introduction"], [47, "dbscan-introduction"], [56, "dbscan-introduction"], [85, "dbscan-introduction"]], "DBSCAN: failure cases": [[26, "dbscan-failure-cases"], [26, "id1"], [47, "dbscan-failure-cases"], [47, "id1"], [56, "dbscan-failure-cases"], [56, "id1"], [85, "dbscan-failure-cases"], [85, "id1"]], "Data": [[17, "data"], [18, "data"], [22, "data"], [23, "data"], [23, "id1"], [37, "data"], [39, "data"], [43, "data"], [44, "data"], [44, "id1"], [52, "data"], [53, "data"], [53, "id1"], [58, "data"], [76, "data"], [77, "data"], [81, "data"], [82, "data"], [82, "id1"]], "Data Splitting [video]": [[14, "data-splitting-video"], [34, "data-splitting-video"], [73, "data-splitting-video"]], "Data and main approaches": [[27, "data-and-main-approaches"], [48, "data-and-main-approaches"], [86, "data-and-main-approaches"]], "Data and splitting": [[65, "data-and-splitting"]], "Data exploration": [[25, "data-exploration"], [46, "data-exploration"], [55, "data-exploration"], [84, "data-exploration"]], "Data splitting": [[57, "data-splitting"], [63, "data-splitting"], [97, "data-splitting"]], "Dataframe summaries": [[8, "dataframe-summaries"]], "Dataset": [[29, "dataset"], [50, "dataset"], [59, "dataset"], [69, "dataset"], [88, "dataset"], [91, "dataset"]], "Dataset [video]": [[21, "dataset-video"], [42, "dataset-video"], [80, "dataset-video"]], "Dataset for demonstration": [[20, "dataset-for-demonstration"], [41, "dataset-for-demonstration"], [68, "dataset-for-demonstration"], [79, "dataset-for-demonstration"]], "Dataset, splitting, and baseline": [[16, "dataset-splitting-and-baseline"], [36, "dataset-splitting-and-baseline"], [75, "dataset-splitting-and-baseline"]], "Datasets": [[7, "datasets"]], "Dealing with class imbalance (video)": [[41, "dealing-with-class-imbalance-video"], [79, "dealing-with-class-imbalance-video"]], "Dealing with class imbalance [video]": [[20, "dealing-with-class-imbalance-video"]], "Dealing with unknown categories": [[17, "dealing-with-unknown-categories"], [37, "dealing-with-unknown-categories"], [76, "dealing-with-unknown-categories"]], "Debugging": [[10, "debugging"]], "Decision boundaries playground": [[64, "decision-boundaries-playground"]], "Decision boundary": [[13, "decision-boundary"], [33, "decision-boundary"], [72, "decision-boundary"]], "Decision boundary for max_depth=1": [[13, "decision-boundary-for-max-depth-1"], [33, "decision-boundary-for-max-depth-1"], [72, "decision-boundary-for-max-depth-1"]], "Decision boundary for max_depth=2": [[13, "decision-boundary-for-max-depth-2"], [33, "decision-boundary-for-max-depth-2"], [72, "decision-boundary-for-max-depth-2"]], "Decision boundary for max_depth=5": [[13, "decision-boundary-for-max-depth-5"], [33, "decision-boundary-for-max-depth-5"], [72, "decision-boundary-for-max-depth-5"]], "Decision boundary of SVMs": [[15, "decision-boundary-of-svms"], [35, "decision-boundary-of-svms"], [74, "decision-boundary-of-svms"]], "Decision boundary of logistic regression": [[18, "decision-boundary-of-logistic-regression"], [39, "decision-boundary-of-logistic-regression"], [77, "decision-boundary-of-logistic-regression"]], "Decision tree algorithm": [[13, "decision-tree-algorithm"], [33, "decision-tree-algorithm"], [72, "decision-tree-algorithm"]], "Decision tree feature importances": [[23, "decision-tree-feature-importances"], [44, "decision-tree-feature-importances"], [53, "decision-tree-feature-importances"], [82, "decision-tree-feature-importances"]], "Decision tree for regression problems": [[13, "decision-tree-for-regression-problems"], [33, "decision-tree-for-regression-problems"], [72, "decision-tree-for-regression-problems"]], "Decision tree model": [[63, "decision-tree-model"]], "Decision tree with max_depth=1": [[13, "decision-tree-with-max-depth-1"], [33, "decision-tree-with-max-depth-1"], [72, "decision-tree-with-max-depth-1"]], "Decision tree with max_depth=3": [[13, "decision-tree-with-max-depth-3"], [33, "decision-tree-with-max-depth-3"], [72, "decision-tree-with-max-depth-3"]], "Decision trees [video]": [[13, "decision-trees-video"], [33, "decision-trees-video"], [72, "decision-trees-video"]], "Decision trees with continuous features": [[13, "decision-trees-with-continuous-features"], [33, "decision-trees-with-continuous-features"], [72, "decision-trees-with-continuous-features"]], "DecisionTreeClassifier baseline": [[22, "decisiontreeclassifier-baseline"], [43, "decisiontreeclassifier-baseline"], [52, "decisiontreeclassifier-baseline"], [81, "decisiontreeclassifier-baseline"]], "DecisionTreeClassifier on quiz2 grade prediction toy dataset": [[13, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"], [33, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"], [72, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"]], "Decisions involve a few key pieces": [[91, "decisions-involve-a-few-key-pieces"]], "Decreasing the threshold": [[20, "decreasing-the-threshold"], [41, "decreasing-the-threshold"], [68, "decreasing-the-threshold"], [79, "decreasing-the-threshold"]], "Deep learning": [[30, "deep-learning"], [51, "deep-learning"], [60, "deep-learning"], [89, "deep-learning"]], "Deep learning frameworks": [[59, "deep-learning-frameworks"]], "Deep learning software": [[29, "deep-learning-software"], [50, "deep-learning-software"], [59, "deep-learning-software"], [88, "deep-learning-software"]], "Deep networks as feature extractor/engineers": [[59, "deep-networks-as-feature-extractor-engineers"]], "Defining distances": [[56, "defining-distances"]], "Deliverable due dates (tentative)": [[1, "deliverable-due-dates-tentative"]], "Demo of creating a new web service": [[92, "demo-of-creating-a-new-web-service"]], "Demo of feature engineering with numeric features": [[24, "demo-of-feature-engineering-with-numeric-features"], [45, "demo-of-feature-engineering-with-numeric-features"], [54, "demo-of-feature-engineering-with-numeric-features"], [83, "demo-of-feature-engineering-with-numeric-features"]], "Demo: A more complicated dataset": [[89, "demo-a-more-complicated-dataset"]], "Demo: Deploying moment classification model": [[92, "demo-deploying-moment-classification-model"]], "Demo: Model interpretation of linear classifiers": [[38, "demo-model-interpretation-of-linear-classifiers"], [66, "demo-model-interpretation-of-linear-classifiers"], [67, "demo-model-interpretation-of-linear-classifiers"]], "Dendrogram": [[26, "dendrogram"], [47, "dendrogram"], [56, "dendrogram"], [85, "dendrogram"]], "Dependency parsing using spaCy": [[58, "dependency-parsing-using-spacy"]], "Deploying the API on a server (not covered)": [[92, "deploying-the-api-on-a-server-not-covered"]], "Deployment (Not examinable)": [[95, "deployment-not-examinable"]], "Difference between Statistics and Machine Learning": [[92, "difference-between-statistics-and-machine-learning"]], "Different models": [[23, "different-models"], [44, "different-models"], [53, "different-models"], [82, "different-models"]], "Different range for hyperparameters yields better results!": [[19, "different-range-for-hyperparameters-yields-better-results"], [40, "different-range-for-hyperparameters-yields-better-results"], [78, "different-range-for-hyperparameters-yields-better-results"]], "Different scoring functions with cross_validate": [[21, "different-scoring-functions-with-cross-validate"], [42, "different-scoring-functions-with-cross-validate"], [69, "different-scoring-functions-with-cross-validate"], [80, "different-scoring-functions-with-cross-validate"]], "Dimensions in ML problems": [[15, "dimensions-in-ml-problems"], [35, "dimensions-in-ml-problems"], [74, "dimensions-in-ml-problems"]], "Disadvantages of content-based filtering": [[57, "disadvantages-of-content-based-filtering"]], "Discuss the following questions in your group": [[63, "discuss-the-following-questions-in-your-group"]], "Discussion": [[92, "discussion"]], "Discussion question": [[28, "discussion-question"], [49, "discussion-question"], [58, "discussion-question"], [87, "discussion-question"]], "Discussion questions": [[65, "discussion-questions"]], "Discussion questions:": [[91, "discussion-questions"]], "Distance between feature vectors": [[15, "distance-between-feature-vectors"], [35, "distance-between-feature-vectors"], [74, "distance-between-feature-vectors"]], "Diversity": [[57, "diversity"]], "Do we actually want to use certain features for prediction?": [[17, "do-we-actually-want-to-use-certain-features-for-prediction"], [76, "do-we-actually-want-to-use-certain-features-for-prediction"]], "Do we have class imbalance?": [[22, "do-we-have-class-imbalance"], [23, "do-we-have-class-imbalance"], [43, "do-we-have-class-imbalance"], [44, "do-we-have-class-imbalance"], [52, "do-we-have-class-imbalance"], [53, "do-we-have-class-imbalance"], [81, "do-we-have-class-imbalance"], [82, "do-we-have-class-imbalance"]], "Do we have correlated features?": [[23, "do-we-have-correlated-features"], [44, "do-we-have-correlated-features"], [53, "do-we-have-correlated-features"], [82, "do-we-have-correlated-features"]], "Document clustering": [[25, "document-clustering"], [46, "document-clustering"], [55, "document-clustering"], [84, "document-clustering"]], "Domain-specific transformations": [[24, "domain-specific-transformations"], [45, "domain-specific-transformations"], [54, "domain-specific-transformations"], [83, "domain-specific-transformations"]], "Domain-specific transformations (Genomics)": [[54, "domain-specific-transformations-genomics"], [54, "id1"]], "Dot product similarity": [[58, "dot-product-similarity"]], "Downside of using pretrained models directly": [[59, "downside-of-using-pretrained-models-directly"]], "Dummy Classifier": [[65, "dummy-classifier"]], "Dummy classifier": [[93, "dummy-classifier"]], "Dummy model": [[64, "dummy-model"]], "DummyClassifier": [[13, "dummyclassifier"], [30, "dummyclassifier"], [31, "dummyclassifier"], [33, "dummyclassifier"], [61, "dummyclassifier"], [72, "dummyclassifier"], [89, "dummyclassifier"], [90, "dummyclassifier"]], "DummyClassifier baseline": [[22, "dummyclassifier-baseline"], [43, "dummyclassifier-baseline"], [52, "dummyclassifier-baseline"], [81, "dummyclassifier-baseline"]], "DummyClassifier on quiz2 grade prediction toy dataset": [[13, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"], [33, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"], [72, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"]], "DummyRegressor": [[13, "dummyregressor"], [21, "dummyregressor"], [33, "dummyregressor"], [42, "dummyregressor"], [72, "dummyregressor"], [80, "dummyregressor"]], "EDA": [[16, "eda"], [20, "eda"], [21, "eda"], [36, "eda"], [41, "eda"], [42, "eda"], [60, "eda"], [68, "eda"], [69, "eda"], [75, "eda"], [79, "eda"], [80, "eda"]], "EDA: Exploratory Data Analysis": [[97, "eda-exploratory-data-analysis"]], "Effect of eps hyperparameter": [[56, "effect-of-eps-hyperparameter"]], "Effect of min_samples hyperparameter": [[56, "effect-of-min-samples-hyperparameter"]], "Encoding text data": [[17, "encoding-text-data"], [37, "encoding-text-data"], [76, "encoding-text-data"]], "Encoding time as a number": [[30, "encoding-time-as-a-number"], [89, "encoding-time-as-a-number"]], "Encoding time of day as a categorical feature": [[30, "encoding-time-of-day-as-a-categorical-feature"], [51, "encoding-time-of-day-as-a-categorical-feature"], [60, "encoding-time-of-day-as-a-categorical-feature"], [89, "encoding-time-of-day-as-a-categorical-feature"]], "Ensemble models": [[43, "ensemble-models"]], "Ensembles": [[95, "ensembles"]], "Equally good": [[91, "equally-good"]], "Ethics": [[95, "ethics"]], "Euclidean distance": [[15, "euclidean-distance"], [35, "euclidean-distance"], [58, "euclidean-distance"], [74, "euclidean-distance"]], "Evaluating DBSCAN clusters": [[26, "evaluating-dbscan-clusters"], [47, "evaluating-dbscan-clusters"], [56, "evaluating-dbscan-clusters"], [85, "evaluating-dbscan-clusters"]], "Evaluation": [[27, "evaluation"], [27, "id2"], [48, "evaluation"], [48, "id3"], [57, "evaluation"], [57, "id6"], [57, "id7"], [57, "id8"], [57, "id9"], [86, "evaluation"], [86, "id3"]], "Evaluation metrics": [[95, "evaluation-metrics"]], "Evaluation metrics for binary classification: Motivation": [[20, "evaluation-metrics-for-binary-classification-motivation"], [41, "evaluation-metrics-for-binary-classification-motivation"], [68, "evaluation-metrics-for-binary-classification-motivation"], [79, "evaluation-metrics-for-binary-classification-motivation"]], "Evalution metrics overview": [[20, "evalution-metrics-overview"], [41, "evalution-metrics-overview"], [68, "evalution-metrics-overview"], [79, "evalution-metrics-overview"]], "Eva\u2019s profile": [[57, "eva-s-profile"]], "Everyday NLP applications": [[58, "everyday-nlp-applications"]], "Examining learned coefficients": [[38, "examining-learned-coefficients"], [66, "examining-learned-coefficients"], [67, "examining-learned-coefficients"]], "Examining the preprocessed data": [[21, "examining-the-preprocessed-data"], [42, "examining-the-preprocessed-data"], [69, "examining-the-preprocessed-data"], [80, "examining-the-preprocessed-data"], [91, "examining-the-preprocessed-data"]], "Examining the vocabulary": [[38, "examining-the-vocabulary"], [66, "examining-the-vocabulary"], [67, "examining-the-vocabulary"]], "Examining user profiles": [[57, "examining-user-profiles"]], "Example": [[18, "example"], [22, "example"], [39, "example"], [43, "example"], [52, "example"], [77, "example"], [81, "example"]], "Example 1": [[53, "example-1"]], "Example 1: Predicting whether a patient has a liver disease or not": [[12, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"], [32, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"], [71, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"]], "Example 1: What is \u201ccorrect\u201d grouping?": [[25, "example-1-what-is-correct-grouping"], [46, "example-1-what-is-correct-grouping"], [55, "example-1-what-is-correct-grouping"], [84, "example-1-what-is-correct-grouping"]], "Example 1: quiz 2 grade prediction": [[13, "example-1-quiz-2-grade-prediction"], [33, "example-1-quiz-2-grade-prediction"], [72, "example-1-quiz-2-grade-prediction"]], "Example 2": [[53, "example-2"]], "Example 2: Predicting country using the longitude and latitude": [[13, "example-2-predicting-country-using-the-longitude-and-latitude"], [72, "example-2-predicting-country-using-the-longitude-and-latitude"]], "Example 2: Predicting the label of a given image": [[12, "example-2-predicting-the-label-of-a-given-image"], [32, "example-2-predicting-the-label-of-a-given-image"], [71, "example-2-predicting-the-label-of-a-given-image"]], "Example 3: Predicting housing prices": [[12, "example-3-predicting-housing-prices"], [32, "example-3-predicting-housing-prices"], [71, "example-3-predicting-housing-prices"]], "Example showing how can we interpret coefficients of scaled features.": [[23, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"], [44, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"], [53, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"], [82, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"]], "Example: A corpus of food magazines": [[58, "example-a-corpus-of-food-magazines"]], "Example: A corpus of news articles": [[58, "example-a-corpus-of-news-articles"]], "Example: Bad initialization": [[55, "example-bad-initialization"]], "Example: Better initialization": [[55, "example-better-initialization"]], "Example: Is \u201cRelevance\u201d clearly defined?": [[24, "example-is-relevance-clearly-defined"], [45, "example-is-relevance-clearly-defined"], [54, "example-is-relevance-clearly-defined"], [83, "example-is-relevance-clearly-defined"]], "Example: Lexical ambiguity": [[58, "example-lexical-ambiguity"]], "Example: Predict whether a message is spam or not": [[12, "example-predict-whether-a-message-is-spam-or-not"], [32, "example-predict-whether-a-message-is-spam-or-not"], [71, "example-predict-whether-a-message-is-spam-or-not"]], "Example: Recommender Systems": [[57, "example-recommender-systems"]], "Example: Referential ambiguity": [[58, "example-referential-ambiguity"]], "Example: Supervised vs unsupervised learning": [[25, "example-supervised-vs-unsupervised-learning"], [46, "example-supervised-vs-unsupervised-learning"], [55, "example-supervised-vs-unsupervised-learning"], [84, "example-supervised-vs-unsupervised-learning"]], "Example: Tabular data for grade prediction": [[13, "example-tabular-data-for-grade-prediction"], [33, "example-tabular-data-for-grade-prediction"], [72, "example-tabular-data-for-grade-prediction"]], "Example: Tabular data for the housing price prediction": [[13, "example-tabular-data-for-the-housing-price-prediction"], [72, "example-tabular-data-for-the-housing-price-prediction"]], "Example: class_weight parameter of sklearn LogisticRegression": [[20, "example-class-weight-parameter-of-sklearn-logisticregression"], [41, "example-class-weight-parameter-of-sklearn-logisticregression"], [79, "example-class-weight-parameter-of-sklearn-logisticregression"]], "Example: k-nearest neighbours on the Spotify dataset": [[16, "example-k-nearest-neighbours-on-the-spotify-dataset"], [36, "example-k-nearest-neighbours-on-the-spotify-dataset"], [75, "example-k-nearest-neighbours-on-the-spotify-dataset"]], "Examples": [[12, "examples"], [32, "examples"], [71, "examples"]], "Examples of semantic and syntactic relationships": [[58, "examples-of-semantic-and-syntactic-relationships"]], "Exercise 17.1 Select all of the following statements which are True (https://join.iclicker.com/FUYI)": [[27, "exercise-17-1-select-all-of-the-following-statements-which-are-true-https-join-iclicker-com-fuyi"]], "Exercise 17.1 Select all of the following statements which are True (iClicker)": [[48, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"], [57, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"], [86, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 17.2 Select all of the following statements which are True (https://join.iclicker.com/FUYI)": [[27, "exercise-17-2-select-all-of-the-following-statements-which-are-true-https-join-iclicker-com-fuyi"]], "Exercise 17.2 Select all of the following statements which are True (iClicker)": [[48, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"], [57, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"], [86, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 2.1 Select all of the following statements which are examples of supervised machine learning": [[13, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"], [72, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"]], "Exercise 2.3": [[33, "exercise-2-3"]], "Exercise 2.4": [[13, "exercise-2-4"], [72, "exercise-2-4"]], "Exercise 8.2": [[19, "exercise-8-2"], [40, "exercise-8-2"], [78, "exercise-8-2"]], "Exercise for you": [[58, "exercise-for-you"]], "Exercise: Predicting country using the longitude and latitude": [[96, "exercise-predicting-country-using-the-longitude-and-latitude"]], "Exhaustive grid search: sklearn.model_selection.GridSearchCV": [[19, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"], [40, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"], [78, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"]], "Explaining a prediction": [[23, "explaining-a-prediction"], [44, "explaining-a-prediction"], [53, "explaining-a-prediction"], [82, "explaining-a-prediction"]], "Explanation 1": [[91, "explanation-1"]], "Explanation 2": [[91, "explanation-2"]], "Exploratory Data Analysis": [[63, "exploratory-data-analysis"]], "Exploratory data analysis": [[30, "exploratory-data-analysis"], [65, "exploratory-data-analysis"], [89, "exploratory-data-analysis"], [102, "exploratory-data-analysis"]], "Exploring data": [[56, "exploring-data"]], "Exploring the model": [[69, "exploring-the-model"]], "Extracting BOW features using scikit-learn": [[17, "extracting-bow-features-using-scikit-learn"], [37, "extracting-bow-features-using-scikit-learn"], [76, "extracting-bow-features-using-scikit-learn"]], "Extracting date and time information": [[30, "extracting-date-and-time-information"], [51, "extracting-date-and-time-information"], [60, "extracting-date-and-time-information"], [89, "extracting-date-and-time-information"]], "Extracting named-entities using spaCy": [[58, "extracting-named-entities-using-spacy"]], "F1-score": [[20, "f1-score"], [41, "f1-score"], [68, "f1-score"], [79, "f1-score"]], "Faster method: vectorize the loop over rows": [[8, "faster-method-vectorize-the-loop-over-rows"]], "Fastest method: broadcasting": [[8, "fastest-method-broadcasting"]], "Feature crosses for one-hot encoded features": [[24, "feature-crosses-for-one-hot-encoded-features"], [45, "feature-crosses-for-one-hot-encoded-features"], [54, "feature-crosses-for-one-hot-encoded-features"], [83, "feature-crosses-for-one-hot-encoded-features"]], "Feature engineering": [[30, "feature-engineering"], [51, "feature-engineering"], [54, "feature-engineering"], [60, "feature-engineering"], [89, "feature-engineering"]], "Feature engineering and selection": [[95, "feature-engineering-and-selection"]], "Feature engineering for date/time columns": [[30, "feature-engineering-for-date-time-columns"], [51, "feature-engineering-for-date-time-columns"], [60, "feature-engineering-for-date-time-columns"], [89, "feature-engineering-for-date-time-columns"]], "Feature engineering: Encoding date/time as feature(s)": [[30, "feature-engineering-encoding-date-time-as-feature-s"], [89, "feature-engineering-encoding-date-time-as-feature-s"]], "Feature engineering: Motivation": [[24, "feature-engineering-motivation"], [45, "feature-engineering-motivation"], [54, "feature-engineering-motivation"], [83, "feature-engineering-motivation"]], "Feature extraction": [[59, "feature-extraction"]], "Feature importances": [[23, "feature-importances"], [44, "feature-importances"], [53, "feature-importances"], [82, "feature-importances"], [95, "feature-importances"]], "Feature importances in linear models": [[23, "feature-importances-in-linear-models"], [23, "id2"], [44, "feature-importances-in-linear-models"], [44, "id2"], [53, "feature-importances-in-linear-models"], [53, "id2"], [82, "feature-importances-in-linear-models"], [82, "id2"]], "Feature interactions and feature crosses": [[24, "feature-interactions-and-feature-crosses"], [45, "feature-interactions-and-feature-crosses"], [54, "feature-interactions-and-feature-crosses"], [83, "feature-interactions-and-feature-crosses"]], "Feature names of transformed data": [[21, "feature-names-of-transformed-data"], [42, "feature-names-of-transformed-data"], [80, "feature-names-of-transformed-data"]], "Feature selection: Introduction and motivation": [[24, "feature-selection-introduction-and-motivation"], [45, "feature-selection-introduction-and-motivation"], [54, "feature-selection-introduction-and-motivation"], [83, "feature-selection-introduction-and-motivation"]], "Feature transformations and the golden rule": [[16, "feature-transformations-and-the-golden-rule"], [36, "feature-transformations-and-the-golden-rule"], [75, "feature-transformations-and-the-golden-rule"]], "Feature types": [[21, "feature-types"], [21, "id1"], [42, "feature-types"], [42, "id1"], [69, "feature-types"], [80, "feature-types"], [80, "id1"], [91, "feature-types"]], "Feature vectors": [[15, "feature-vectors"], [74, "feature-vectors"]], "Figures": [[7, "figures"]], "Filling int the matrix": [[57, "filling-int-the-matrix"]], "Filtering a dataframe with [] and df.query()": [[8, "filtering-a-dataframe-with-and-df-query"]], "Final comments and summary": [[19, "final-comments-and-summary"], [27, "final-comments-and-summary"], [40, "final-comments-and-summary"], [48, "final-comments-and-summary"], [57, "final-comments-and-summary"], [78, "final-comments-and-summary"], [86, "final-comments-and-summary"]], "Final comments, summary, and reflection": [[13, "final-comments-summary-and-reflection"], [25, "final-comments-summary-and-reflection"], [26, "final-comments-summary-and-reflection"], [33, "final-comments-summary-and-reflection"], [46, "final-comments-summary-and-reflection"], [47, "final-comments-summary-and-reflection"], [55, "final-comments-summary-and-reflection"], [56, "final-comments-summary-and-reflection"], [72, "final-comments-summary-and-reflection"], [84, "final-comments-summary-and-reflection"], [85, "final-comments-summary-and-reflection"]], "Final exam": [[103, "final-exam"]], "Final exam preparation: guiding questions": [[95, null]], "Final note": [[97, "final-note"]], "Final remarks": [[30, "final-remarks"], [51, "final-remarks"], [60, "final-remarks"], [89, "final-remarks"]], "Finding cell types in tumours": [[55, "finding-cell-types-in-tumours"]], "Finding mutations in cancer genomes": [[55, "finding-mutations-in-cancer-genomes"]], "Finding similar words": [[58, "finding-similar-words"]], "Finding similarity scores between words": [[58, "finding-similarity-scores-between-words"]], "Finding the distances to a query point": [[15, "finding-the-distances-to-a-query-point"], [35, "finding-the-distances-to-a-query-point"], [74, "finding-the-distances-to-a-query-point"]], "Finding the nearest neighbour": [[15, "finding-the-nearest-neighbour"], [35, "finding-the-nearest-neighbour"], [74, "finding-the-nearest-neighbour"]], "Fine-tuning your regression models": [[57, "fine-tuning-your-regression-models"]], "First deliverables": [[12, "first-deliverables"], [32, "first-deliverables"]], "Flat clusters": [[56, "flat-clusters"]], "Forecasting further into the future": [[30, "forecasting-further-into-the-future"], [51, "forecasting-further-into-the-future"], [60, "forecasting-further-into-the-future"], [89, "forecasting-further-into-the-future"]], "Forecasting further into the future on a retail dataset": [[30, "forecasting-further-into-the-future-on-a-retail-dataset"], [51, "forecasting-further-into-the-future-on-a-retail-dataset"], [60, "forecasting-further-into-the-future-on-a-retail-dataset"], [89, "forecasting-further-into-the-future-on-a-retail-dataset"]], "Formulating the problem of recommender systems": [[27, "formulating-the-problem-of-recommender-systems"], [48, "formulating-the-problem-of-recommender-systems"], [57, "formulating-the-problem-of-recommender-systems"], [86, "formulating-the-problem-of-recommender-systems"]], "Freshness": [[57, "freshness"]], "GB better than RF": [[91, "gb-better-than-rf"]], "Garbage in, garbage out.": [[24, "garbage-in-garbage-out"], [45, "garbage-in-garbage-out"], [54, "garbage-in-garbage-out"], [83, "garbage-in-garbage-out"]], "General advice on finding relevant features": [[24, "general-advice-on-finding-relevant-features"], [45, "general-advice-on-finding-relevant-features"], [54, "general-advice-on-finding-relevant-features"], [83, "general-advice-on-finding-relevant-features"]], "General guidelines": [[6, "general-guidelines"]], "General idea": [[22, "general-idea"], [43, "general-idea"], [52, "general-idea"], [81, "general-idea"]], "General idea of k-nearest neighbours algorithm": [[15, "general-idea-of-k-nearest-neighbours-algorithm"], [35, "general-idea-of-k-nearest-neighbours-algorithm"], [74, "general-idea-of-k-nearest-neighbours-algorithm"]], "General idea of search and score methods": [[24, "general-idea-of-search-and-score-methods"], [45, "general-idea-of-search-and-score-methods"], [54, "general-idea-of-search-and-score-methods"], [83, "general-idea-of-search-and-score-methods"]], "General questions": [[4, "general-questions"]], "Generalization [video]": [[14, "generalization-video"], [34, "generalization-video"], [73, "generalization-video"]], "Generalization: Fundamental goal of ML": [[14, "generalization-fundamental-goal-of-ml"], [34, "generalization-fundamental-goal-of-ml"], [73, "generalization-fundamental-goal-of-ml"]], "Generalizing to more features": [[18, "generalizing-to-more-features"], [39, "generalizing-to-more-features"], [77, "generalizing-to-more-features"]], "Generalizing to unseen data": [[14, "generalizing-to-unseen-data"], [34, "generalizing-to-unseen-data"], [73, "generalizing-to-unseen-data"]], "Generalizing with pre-trained models": [[59, "generalizing-with-pre-trained-models"]], "Geometric view of tabular data and dimensions": [[15, "geometric-view-of-tabular-data-and-dimensions"], [35, "geometric-view-of-tabular-data-and-dimensions"], [74, "geometric-view-of-tabular-data-and-dimensions"]], "Git": [[10, "git"]], "GitHub Desktop": [[5, "github-desktop"]], "Global average baseline": [[27, "global-average-baseline"], [48, "global-average-baseline"], [57, "global-average-baseline"], [86, "global-average-baseline"]], "Going deeper": [[59, "going-deeper"]], "Golden rule violation: Example 1": [[14, "golden-rule-violation-example-1"], [73, "golden-rule-violation-example-1"]], "Golden rule violation: Example 2": [[14, "golden-rule-violation-example-2"], [73, "golden-rule-violation-example-2"]], "Grades": [[32, "grades"]], "Gradient boosted trees [video]": [[22, "gradient-boosted-trees-video"], [43, "gradient-boosted-trees-video"], [52, "gradient-boosted-trees-video"], [81, "gradient-boosted-trees-video"]], "Gradient boosting in sklearn": [[22, "gradient-boosting-in-sklearn"], [43, "gradient-boosting-in-sklearn"], [52, "gradient-boosting-in-sklearn"], [81, "gradient-boosting-in-sklearn"]], "Grading concerns: time limit": [[6, "grading-concerns-time-limit"]], "Grading scheme": [[103, "grading-scheme"]], "Grading-related questions": [[4, "grading-related-questions"]], "HDBSCAN clustering of cancer cells": [[56, "hdbscan-clustering-of-cancer-cells"]], "Handling imbalance": [[20, "handling-imbalance"], [41, "handling-imbalance"], [79, "handling-imbalance"]], "Here is the workflow we\u2019ll generally follow.": [[14, "here-is-the-workflow-we-ll-generally-follow"], [34, "here-is-the-workflow-we-ll-generally-follow"], [73, "here-is-the-workflow-we-ll-generally-follow"]], "Hierarchical clustering [video]": [[26, "hierarchical-clustering-video"], [47, "hierarchical-clustering-video"], [56, "hierarchical-clustering-video"], [85, "hierarchical-clustering-video"]], "Hierarchical clustering input and output": [[56, "hierarchical-clustering-input-and-output"]], "Homework info & submission guidelines": [[7, null]], "How are we making predictions?": [[18, "how-are-we-making-predictions"], [39, "how-are-we-making-predictions"], [77, "how-are-we-making-predictions"]], "How are word embeddings related to unsupervised learning?": [[58, "how-are-word-embeddings-related-to-unsupervised-learning"]], "How can we avoid violating golden rule?": [[14, "how-can-we-avoid-violating-golden-rule"], [34, "how-can-we-avoid-violating-golden-rule"], [73, "how-can-we-avoid-violating-golden-rule"]], "How can we get feature importances for non sklearn models?": [[23, "how-can-we-get-feature-importances-for-non-sklearn-models"], [53, "how-can-we-get-feature-importances-for-non-sklearn-models"], [82, "how-can-we-get-feature-importances-for-non-sklearn-models"]], "How do they work?": [[22, "how-do-they-work"], [43, "how-do-they-work"], [52, "how-do-they-work"], [81, "how-do-they-work"]], "How do we carry out feature selection?": [[24, "how-do-we-carry-out-feature-selection"], [45, "how-do-we-carry-out-feature-selection"], [54, "how-do-we-carry-out-feature-selection"], [83, "how-do-we-carry-out-feature-selection"]], "How do you do topic modeling?": [[58, "how-do-you-do-topic-modeling"]], "How does fit work?": [[13, "how-does-fit-work"], [13, "id2"], [33, "how-does-fit-work"], [72, "how-does-fit-work"], [72, "id2"]], "How does it work?": [[26, "how-does-it-work"], [47, "how-does-it-work"], [56, "how-does-it-work"], [85, "how-does-it-work"], [91, "how-does-it-work"]], "How does logistic regression calculate these probabilities?": [[18, "how-does-logistic-regression-calculate-these-probabilities"], [39, "how-does-logistic-regression-calculate-these-probabilities"], [77, "how-does-logistic-regression-calculate-these-probabilities"]], "How does predict work?": [[13, "how-does-predict-work"], [33, "how-does-predict-work"], [72, "how-does-predict-work"]], "How often do you search everyday?": [[58, "how-often-do-you-search-everyday"]], "How to approximate generalization error?": [[14, "how-to-approximate-generalization-error"], [34, "how-to-approximate-generalization-error"], [73, "how-to-approximate-generalization-error"]], "How to ask for help": [[4, null]], "How to carry out cross-validation?": [[16, "how-to-carry-out-cross-validation"], [36, "how-to-carry-out-cross-validation"], [75, "how-to-carry-out-cross-validation"]], "How to choose n_neighbors?": [[15, "how-to-choose-n-neighbors"], [35, "how-to-choose-n-neighbors"], [74, "how-to-choose-n-neighbors"]], "How to find closest centers?": [[55, "how-to-find-closest-centers"]], "How to pick a model that would generalize better?": [[14, "how-to-pick-a-model-that-would-generalize-better"], [34, "how-to-pick-a-model-that-would-generalize-better"], [73, "how-to-pick-a-model-that-would-generalize-better"]], "How to submit": [[7, "how-to-submit"]], "How to use pretrained embeddings": [[58, "how-to-use-pretrained-embeddings"]], "How would you do it properly? Enter sklearn pipelines!!": [[65, "how-would-you-do-it-properly-enter-sklearn-pipelines"]], "Hyperparameter alpha of Ridge": [[18, "hyperparameter-alpha-of-ridge"], [39, "hyperparameter-alpha-of-ridge"], [77, "hyperparameter-alpha-of-ridge"]], "Hyperparameter optimization": [[63, "hyperparameter-optimization"], [95, "hyperparameter-optimization"]], "Hyperparameter optimization motivation": [[19, "hyperparameter-optimization-motivation"], [78, "hyperparameter-optimization-motivation"]], "Hyperparameter optimization motivation (video)": [[40, "hyperparameter-optimization-motivation-video"]], "Hyperparameter tuning for the number of clusters": [[25, "hyperparameter-tuning-for-the-number-of-clusters"], [46, "hyperparameter-tuning-for-the-number-of-clusters"], [55, "hyperparameter-tuning-for-the-number-of-clusters"], [84, "hyperparameter-tuning-for-the-number-of-clusters"]], "Hyperparameters of SVM": [[15, "hyperparameters-of-svm"], [35, "hyperparameters-of-svm"], [74, "hyperparameters-of-svm"]], "Hyperparameters: the problem": [[19, "hyperparameters-the-problem"], [40, "hyperparameters-the-problem"], [78, "hyperparameters-the-problem"]], "Identify the transformations we want to apply": [[17, "identify-the-transformations-we-want-to-apply"], [37, "identify-the-transformations-we-want-to-apply"], [76, "identify-the-transformations-we-want-to-apply"]], "Illustration of hyperparameters eps and min_samples": [[56, "illustration-of-hyperparameters-eps-and-min-samples"]], "Image classification using KNNs and SVM RBF": [[64, "image-classification-using-knns-and-svm-rbf"]], "ImageNet": [[29, "imagenet"], [59, "imagenet"], [88, "imagenet"]], "Implicit biases and stereotypes in word embeddings": [[58, "implicit-biases-and-stereotypes-in-word-embeddings"]], "Import": [[93, "import"]], "Importance of scaling": [[18, "importance-of-scaling"], [39, "importance-of-scaling"], [77, "importance-of-scaling"]], "Important hyperparameters": [[22, "important-hyperparameters"], [43, "important-hyperparameters"], [52, "important-hyperparameters"], [81, "important-hyperparameters"]], "Important hyperparameters of CountVectorizer": [[17, "important-hyperparameters-of-countvectorizer"], [37, "important-hyperparameters-of-countvectorizer"], [76, "important-hyperparameters-of-countvectorizer"]], "Important links": [[1, "important-links"]], "Important points to remember": [[25, "important-points-to-remember"], [46, "important-points-to-remember"], [55, "important-points-to-remember"], [84, "important-points-to-remember"]], "Imports": [[12, "imports"], [13, "imports"], [14, "imports"], [15, "imports"], [15, "id1"], [16, "imports"], [17, "imports"], [18, "imports"], [19, "imports"], [20, "imports"], [21, "imports"], [22, "imports"], [23, "imports"], [24, "imports"], [25, "imports"], [26, "imports"], [27, "imports"], [28, "imports"], [29, "imports"], [30, "imports"], [31, "imports"], [32, "imports"], [33, "imports"], [34, "imports"], [35, "imports"], [36, "imports"], [37, "imports"], [39, "imports"], [40, "imports"], [41, "imports"], [42, "imports"], [43, "imports"], [44, "imports"], [45, "imports"], [46, "imports"], [47, "imports"], [48, "imports"], [49, "imports"], [50, "imports"], [51, "imports"], [63, "imports"], [64, "imports"], [65, "imports"], [66, "imports"], [67, "imports"], [68, "imports"], [71, "imports"], [72, "imports"], [73, "imports"], [74, "imports"], [75, "imports"], [76, "imports"], [77, "imports"], [78, "imports"], [79, "imports"], [80, "imports"], [81, "imports"], [82, "imports"], [83, "imports"], [84, "imports"], [85, "imports"], [86, "imports"], [87, "imports"], [88, "imports"], [89, "imports"], [90, "imports"], [91, "imports"], [92, "imports"], [95, "imports"], [96, "imports"], [97, "imports"], [102, "imports"]], "Imports and LO": [[19, "imports-and-lo"], [21, "imports-and-lo"], [29, "imports-and-lo"], [30, "imports-and-lo"], [40, "imports-and-lo"], [42, "imports-and-lo"], [50, "imports-and-lo"], [51, "imports-and-lo"], [78, "imports-and-lo"], [80, "imports-and-lo"], [88, "imports-and-lo"], [89, "imports-and-lo"]], "Imports and LOs": [[20, "imports-and-los"], [41, "imports-and-los"], [79, "imports-and-los"], [92, "imports-and-los"]], "Imports and learning outcomes": [[25, "imports-and-learning-outcomes"], [46, "imports-and-learning-outcomes"], [84, "imports-and-learning-outcomes"]], "Imports, Announcements, LOs": [[72, "imports-announcements-los"]], "Imports, Announcements, and LO": [[37, "imports-announcements-and-lo"], [39, "imports-announcements-and-lo"], [76, "imports-announcements-and-lo"], [77, "imports-announcements-and-lo"]], "Imports, LOs": [[14, "imports-los"], [16, "imports-los"], [23, "imports-los"], [34, "imports-los"], [36, "imports-los"], [44, "imports-los"], [73, "imports-los"], [75, "imports-los"], [82, "imports-los"]], "Imports, and LO": [[17, "imports-and-lo"], [18, "imports-and-lo"]], "Imports, announcements, LOs": [[22, "imports-announcements-los"], [43, "imports-announcements-los"], [81, "imports-announcements-los"]], "Imports, announcements, and LOs": [[35, "imports-announcements-and-los"], [74, "imports-announcements-and-los"]], "Imputation": [[16, "imputation"], [36, "imputation"], [75, "imputation"]], "Imputation and scaling [video]": [[16, "imputation-and-scaling-video"], [36, "imputation-and-scaling-video"], [75, "imputation-and-scaling-video"]], "In classification or regression:": [[57, "in-classification-or-regression"]], "In rating prediction": [[57, "in-rating-prediction"]], "Incorporating ordinal feature class_attendance": [[17, "incorporating-ordinal-feature-class-attendance"], [37, "incorporating-ordinal-feature-class-attendance"], [76, "incorporating-ordinal-feature-class-attendance"]], "Incorporating text features": [[65, "incorporating-text-features"]], "Increasing the threshold": [[20, "increasing-the-threshold"], [41, "increasing-the-threshold"], [68, "increasing-the-threshold"], [79, "increasing-the-threshold"]], "Indexing Dataframes": [[8, "indexing-dataframes"]], "Indexing cheatsheet": [[8, "indexing-cheatsheet"]], "Inertia": [[25, "inertia"], [46, "inertia"], [84, "inertia"]], "Initial analysis, EDA, preprocessing": [[92, "initial-analysis-eda-preprocessing"]], "Initialization": [[55, "initialization"]], "Initialization of K-Means": [[25, "initialization-of-k-means"], [46, "initialization-of-k-means"], [84, "initialization-of-k-means"]], "Inject randomness in the classifier construction": [[22, "inject-randomness-in-the-classifier-construction"], [43, "inject-randomness-in-the-classifier-construction"], [52, "inject-randomness-in-the-classifier-construction"], [81, "inject-randomness-in-the-classifier-construction"]], "Input data": [[12, "input-data"], [32, "input-data"], [71, "input-data"]], "Input features X and target y": [[12, "input-features-x-and-target-y"], [32, "input-features-x-and-target-y"], [71, "input-features-x-and-target-y"]], "Installing Python packages": [[10, "installing-python-packages"]], "Instructional Material": [[0, "instructional-material"]], "Instructors": [[1, "instructors"]], "Interesting to you != useful to the reader (aka it\u2019s not about you)": [[91, "interesting-to-you-useful-to-the-reader-aka-it-s-not-about-you"]], "Interim summary": [[20, "interim-summary"], [23, "interim-summary"], [24, "interim-summary"], [30, "interim-summary"], [41, "interim-summary"], [44, "interim-summary"], [45, "interim-summary"], [51, "interim-summary"], [53, "interim-summary"], [54, "interim-summary"], [60, "interim-summary"], [68, "interim-summary"], [79, "interim-summary"], [82, "interim-summary"], [83, "interim-summary"], [89, "interim-summary"]], "Interpretation of coefficients": [[18, "interpretation-of-coefficients"], [39, "interpretation-of-coefficients"], [77, "interpretation-of-coefficients"]], "Interpretation of coefficients in linear models": [[18, "interpretation-of-coefficients-in-linear-models"], [39, "interpretation-of-coefficients-in-linear-models"], [77, "interpretation-of-coefficients-in-linear-models"]], "Interpreting coefficients of numeric features": [[23, "interpreting-coefficients-of-numeric-features"], [44, "interpreting-coefficients-of-numeric-features"], [53, "interpreting-coefficients-of-numeric-features"], [82, "interpreting-coefficients-of-numeric-features"]], "Introduction": [[26, "introduction"], [47, "introduction"], [58, "introduction"], [85, "introduction"], [95, "introduction"]], "Introduction to NLP": [[95, "introduction-to-nlp"]], "Introduction to computer vision": [[29, "introduction-to-computer-vision"], [50, "introduction-to-computer-vision"], [59, "introduction-to-computer-vision"], [88, "introduction-to-computer-vision"]], "Introduction to neural networks": [[29, "introduction-to-neural-networks"], [50, "introduction-to-neural-networks"], [59, "introduction-to-neural-networks"], [88, "introduction-to-neural-networks"]], "Introduction to pandas": [[8, "introduction-to-pandas"]], "Introduction to unsupervised learning": [[25, "introduction-to-unsupervised-learning"], [46, "introduction-to-unsupervised-learning"], [55, "introduction-to-unsupervised-learning"], [84, "introduction-to-unsupervised-learning"]], "Is it possible to further improve the scores?": [[93, "is-it-possible-to-further-improve-the-scores"]], "Is stratifying a good idea?": [[20, "is-stratifying-a-good-idea"], [41, "is-stratifying-a-good-idea"], [79, "is-stratifying-a-good-idea"]], "Is this a realistic representation of text data?": [[17, "is-this-a-realistic-representation-of-text-data"], [37, "is-this-a-realistic-representation-of-text-data"], [76, "is-this-a-realistic-representation-of-text-data"]], "Is this misleading?": [[91, "is-this-misleading"]], "Is \u201cRelevance\u201d clearly defined?": [[24, "is-relevance-clearly-defined"], [24, "id2"], [24, "id3"], [24, "id4"], [24, "id5"], [24, "id6"], [24, "id7"], [45, "is-relevance-clearly-defined"], [45, "id1"], [45, "id2"], [45, "id3"], [45, "id4"], [45, "id5"], [45, "id6"], [54, "is-relevance-clearly-defined"], [54, "id2"], [54, "id3"], [54, "id4"], [54, "id5"], [54, "id6"], [54, "id7"], [83, "is-relevance-clearly-defined"], [83, "id2"], [83, "id3"], [83, "id4"], [83, "id5"], [83, "id6"], [83, "id7"]], "Iterative process": [[55, "iterative-process"]], "K-Means algorithm": [[25, "k-means-algorithm"], [46, "k-means-algorithm"], [84, "k-means-algorithm"]], "K-Means algorithm: Main idea": [[55, "k-means-algorithm-main-idea"]], "K-Means clustering [video]": [[25, "k-means-clustering-video"], [46, "k-means-clustering-video"], [55, "k-means-clustering-video"], [84, "k-means-clustering-video"]], "K-Means clustering algorithm": [[55, "k-means-clustering-algorithm"]], "K-Means example": [[25, "k-means-example"], [46, "k-means-example"], [84, "k-means-example"]], "K-Means limitations": [[26, "k-means-limitations"], [47, "k-means-limitations"], [56, "k-means-limitations"], [85, "k-means-limitations"]], "K-Means limitations: Shape of K-Means clusters": [[26, "k-means-limitations-shape-of-k-means-clusters"], [47, "k-means-limitations-shape-of-k-means-clusters"], [56, "k-means-limitations-shape-of-k-means-clusters"], [85, "k-means-limitations-shape-of-k-means-clusters"]], "K-Means recap": [[26, "k-means-recap"], [47, "k-means-recap"], [56, "k-means-recap"], [85, "k-means-recap"]], "K-Means using sklearn": [[55, "k-means-using-sklearn"]], "K-Means vs. DBSCAN": [[56, "k-means-vs-dbscan"]], "K-Means: failure case 1": [[26, "k-means-failure-case-1"], [47, "k-means-failure-case-1"], [56, "k-means-failure-case-1"], [85, "k-means-failure-case-1"]], "K-Means: failure case 2": [[26, "k-means-failure-case-2"], [47, "k-means-failure-case-2"], [56, "k-means-failure-case-2"], [85, "k-means-failure-case-2"]], "K-Means: failure case 3": [[26, "k-means-failure-case-3"], [47, "k-means-failure-case-3"], [56, "k-means-failure-case-3"], [85, "k-means-failure-case-3"]], "Kaplan-Meier survival curve": [[31, "kaplan-meier-survival-curve"], [61, "kaplan-meier-survival-curve"], [90, "kaplan-meier-survival-curve"]], "Key point": [[23, "key-point"], [44, "key-point"], [53, "key-point"], [82, "key-point"]], "L1 vs L2 penalty summary (Optional)": [[54, "l1-vs-l2-penalty-summary-optional"]], "LDA topics in Yale Law Journal": [[58, "lda-topics-in-yale-law-journal"]], "LDA topics in social media": [[28, "lda-topics-in-social-media"], [49, "lda-topics-in-social-media"], [58, "lda-topics-in-social-media"], [87, "lda-topics-in-social-media"]], "LICENSE": [[0, null]], "Labeled vs. Unlabeled data": [[25, "labeled-vs-unlabeled-data"], [46, "labeled-vs-unlabeled-data"], [55, "labeled-vs-unlabeled-data"], [84, "labeled-vs-unlabeled-data"]], "Lag-based features": [[30, "lag-based-features"], [30, "id5"], [51, "lag-based-features"], [60, "lag-based-features"], [89, "lag-based-features"], [89, "id5"], [102, "lag-based-features"]], "Land acknowledgement": [[103, "land-acknowledgement"]], "Large datasets solve many of these problems": [[19, "large-datasets-solve-many-of-these-problems"], [40, "large-datasets-solve-many-of-these-problems"], [78, "large-datasets-solve-many-of-these-problems"]], "Lasso regression (L1 penalty) (Optional)": [[54, "lasso-regression-l1-penalty-optional"]], "Late submissions": [[7, "late-submissions"]], "Layers and hidden units": [[59, "layers-and-hidden-units"]], "Learned coefficients associated with all features": [[18, "learned-coefficients-associated-with-all-features"], [39, "learned-coefficients-associated-with-all-features"], [77, "learned-coefficients-associated-with-all-features"]], "Learned model": [[63, "learned-model"]], "Learning git": [[5, "learning-git"]], "Learning objectives": [[28, "learning-objectives"], [29, "learning-objectives"], [30, "learning-objectives"], [31, "learning-objectives"], [49, "learning-objectives"], [50, "learning-objectives"], [51, "learning-objectives"], [58, "learning-objectives"], [59, "learning-objectives"], [60, "learning-objectives"], [61, "learning-objectives"], [87, "learning-objectives"], [88, "learning-objectives"], [89, "learning-objectives"], [90, "learning-objectives"], [91, "learning-objectives"], [92, "learning-objectives"]], "Learning outcomes": [[12, "learning-outcomes"], [13, "learning-outcomes"], [14, "learning-outcomes"], [15, "learning-outcomes"], [16, "learning-outcomes"], [17, "learning-outcomes"], [18, "learning-outcomes"], [19, "learning-outcomes"], [20, "learning-outcomes"], [21, "learning-outcomes"], [23, "learning-outcomes"], [24, "learning-outcomes"], [25, "learning-outcomes"], [26, "learning-outcomes"], [32, "learning-outcomes"], [33, "learning-outcomes"], [34, "learning-outcomes"], [35, "learning-outcomes"], [36, "learning-outcomes"], [37, "learning-outcomes"], [39, "learning-outcomes"], [40, "learning-outcomes"], [41, "learning-outcomes"], [42, "learning-outcomes"], [44, "learning-outcomes"], [45, "learning-outcomes"], [46, "learning-outcomes"], [47, "learning-outcomes"], [53, "learning-outcomes"], [54, "learning-outcomes"], [55, "learning-outcomes"], [56, "learning-outcomes"], [69, "learning-outcomes"], [71, "learning-outcomes"], [72, "learning-outcomes"], [73, "learning-outcomes"], [74, "learning-outcomes"], [75, "learning-outcomes"], [76, "learning-outcomes"], [77, "learning-outcomes"], [78, "learning-outcomes"], [79, "learning-outcomes"], [80, "learning-outcomes"], [82, "learning-outcomes"], [83, "learning-outcomes"], [84, "learning-outcomes"], [85, "learning-outcomes"]], "Learning outcomes <a name=\"lo\"></a>": [[27, "learning-outcomes"], [48, "learning-outcomes"], [57, "learning-outcomes"], [86, "learning-outcomes"]], "Least confident cases": [[18, "least-confident-cases"], [39, "least-confident-cases"], [77, "least-confident-cases"]], "Lecture 10: Regression metrics": [[21, null], [42, null], [69, null], [80, null]], "Lecture 12: Ensembles": [[22, null], [43, null], [52, null], [81, null]], "Lecture 13: Feature importances and model transparency": [[23, null], [44, null], [53, null], [82, null]], "Lecture 14: Feature engineering and feature selection": [[24, null], [45, null], [54, null], [83, null]], "Lecture 15: Class demo": [[70, null]], "Lecture 15: K-Means Clustering": [[25, null], [46, null], [55, null], [84, null]], "Lecture 16: More Clustering": [[26, null], [47, null], [56, null], [85, null]], "Lecture 17: Recommender Systems": [[27, null], [48, null], [57, null], [86, null]], "Lecture 18: Introduction to natural language processing": [[28, null], [49, null], [58, null], [87, null]], "Lecture 19: Multi-class classification and introduction to computer vision": [[29, null], [50, null], [59, null], [88, null]], "Lecture 1: Course Introduction": [[12, null], [32, null], [71, null]], "Lecture 20: Time series": [[30, null], [51, null], [60, null], [89, null]], "Lecture 21: Survival analysis": [[31, null], [61, null], [90, null]], "Lecture 22: Communication": [[91, null]], "Lecture 24: Deployment and conclusion": [[92, null]], "Lecture 2: Terminology, Baselines, Decision Trees": [[13, null], [33, null], [72, null]], "Lecture 3: ML Fundamentals Class Demo": [[63, null]], "Lecture 3: Machine Learning Fundamentals": [[14, null], [34, null], [73, null]], "Lecture 4: Class demo": [[64, null]], "Lecture 4: k-Nearest Neighbours and SVM RBFs": [[15, null], [35, null], [74, null]], "Lecture 5 and 6: Class demo": [[65, null]], "Lecture 5: Preprocessing and sklearn pipelines": [[16, null], [36, null], [75, null]], "Lecture 6: sklearn ColumnTransformer and Text Features": [[17, null], [37, null], [76, null]], "Lecture 7: Class demo": [[38, null]], "Lecture 7: Linear Models": [[18, null], [39, null], [77, null]], "Lecture 8: Hyperparameter Optimization and Optimization Bias": [[19, null], [40, null], [78, null]], "Lecture 9: Class demo": [[68, null]], "Lecture 9: Classification metrics": [[20, null], [41, null], [79, null]], "Lecture and homework format: Jupyter notebooks": [[12, "lecture-and-homework-format-jupyter-notebooks"], [32, "lecture-and-homework-format-jupyter-notebooks"]], "Lecture learning objectives": [[22, "lecture-learning-objectives"], [43, "lecture-learning-objectives"], [52, "lecture-learning-objectives"], [81, "lecture-learning-objectives"]], "Lecture plan and learning outcomes": [[26, "lecture-plan-and-learning-outcomes"], [47, "lecture-plan-and-learning-outcomes"], [85, "lecture-plan-and-learning-outcomes"]], "Lecture recordings": [[103, "lecture-recordings"]], "Lecture schedule (tentative)": [[1, "lecture-schedule-tentative"]], "Lecture style": [[12, "lecture-style"], [32, "lecture-style"]], "Lectures 7: Class demo": [[66, null], [67, null]], "Lemmatization": [[58, "lemmatization"]], "Let\u2019s build a profile for Pat": [[57, "let-s-build-a-profile-for-pat"]], "Let\u2019s cluster images!!": [[70, "let-s-cluster-images"]], "Let\u2019s do it on our housing data": [[16, "let-s-do-it-on-our-housing-data"], [36, "let-s-do-it-on-our-housing-data"], [75, "let-s-do-it-on-our-housing-data"]], "Let\u2019s examine the transformed data": [[17, "let-s-examine-the-transformed-data"], [37, "let-s-examine-the-transformed-data"], [76, "let-s-examine-the-transformed-data"]], "Let\u2019s explore SVM RBFs": [[15, "let-s-explore-svm-rbfs"], [35, "let-s-explore-svm-rbfs"], [74, "let-s-explore-svm-rbfs"]], "Let\u2019s first run our baseline model DummyRegressor": [[16, "let-s-first-run-our-baseline-model-dummyregressor"], [36, "let-s-first-run-our-baseline-model-dummyregressor"], [75, "let-s-first-run-our-baseline-model-dummyregressor"]], "Let\u2019s identify feature types": [[23, "let-s-identify-feature-types"], [44, "let-s-identify-feature-types"], [82, "let-s-identify-feature-types"]], "Let\u2019s look at all the scores at once": [[20, "let-s-look-at-all-the-scores-at-once"], [41, "let-s-look-at-all-the-scores-at-once"], [68, "let-s-look-at-all-the-scores-at-once"], [79, "let-s-look-at-all-the-scores-at-once"]], "Let\u2019s separate X and y": [[21, "let-s-separate-x-and-y"], [23, "let-s-separate-x-and-y"], [42, "let-s-separate-x-and-y"], [44, "let-s-separate-x-and-y"], [80, "let-s-separate-x-and-y"], [82, "let-s-separate-x-and-y"], [91, "let-s-separate-x-and-y"]], "Let\u2019s try KNN on this data": [[65, "let-s-try-knn-on-this-data"]], "Let\u2019s try a linear model: Ridge": [[21, "let-s-try-a-linear-model-ridge"], [42, "let-s-try-a-linear-model-ridge"], [80, "let-s-try-a-linear-model-ridge"]], "Let\u2019s try cross-validation with our pipeline": [[16, "let-s-try-cross-validation-with-our-pipeline"], [36, "let-s-try-cross-validation-with-our-pipeline"], [75, "let-s-try-cross-validation-with-our-pipeline"]], "License": [[1, "license"]], "LightGBM": [[22, "lightgbm"], [43, "lightgbm"], [52, "lightgbm"], [81, "lightgbm"]], "Limitations of linear models": [[18, "limitations-of-linear-models"], [39, "limitations-of-linear-models"], [77, "limitations-of-linear-models"]], "Linear SVM": [[18, "linear-svm"], [39, "linear-svm"], [77, "linear-svm"]], "Linear models [video]": [[18, "linear-models-video"], [39, "linear-models-video"], [77, "linear-models-video"]], "Linear models recap (Optional)": [[54, "linear-models-recap-optional"]], "Linear regression": [[18, "linear-regression"], [39, "linear-regression"], [77, "linear-regression"]], "Lists of resources": [[9, "lists-of-resources"]], "Loading our saved model": [[92, "loading-our-saved-model"]], "Log transform": [[69, "log-transform"]], "Logisitic regression": [[59, "logisitic-regression"]], "Logistic regression (L1 and L2) (Optional)": [[54, "logistic-regression-l1-and-l2-optional"]], "Logistic regression [video]": [[18, "logistic-regression-video"], [39, "logistic-regression-video"], [77, "logistic-regression-video"]], "Logistic regression intuition": [[18, "logistic-regression-intuition"], [39, "logistic-regression-intuition"], [77, "logistic-regression-intuition"]], "Logistic regression on the cities data": [[18, "logistic-regression-on-the-cities-data"], [39, "logistic-regression-on-the-cities-data"], [77, "logistic-regression-on-the-cities-data"]], "Logistic regression with flattened representation of images": [[29, "logistic-regression-with-flattened-representation-of-images"], [50, "logistic-regression-with-flattened-representation-of-images"], [59, "logistic-regression-with-flattened-representation-of-images"], [88, "logistic-regression-with-flattened-representation-of-images"]], "LogisticRegression": [[30, "logisticregression"], [31, "logisticregression"], [61, "logisticregression"], [89, "logisticregression"], [90, "logisticregression"]], "MAPE": [[21, "mape"], [42, "mape"], [69, "mape"], [80, "mape"]], "ML and decision-making (5 min)": [[91, "ml-and-decision-making-5-min"]], "ML fairness activity": [[100, "ml-fairness-activity"]], "ML fairness activity (tutorial)": [[41, "ml-fairness-activity-tutorial"]], "ML fairness activity (~5 mins)": [[20, "ml-fairness-activity-5-mins"], [79, "ml-fairness-activity-5-mins"]], "ML fundamentals": [[95, "ml-fundamentals"]], "Mac Users": [[5, "mac-users"]], "Machine learning workflow": [[12, "machine-learning-workflow"], [20, "machine-learning-workflow"], [41, "machine-learning-workflow"], [68, "machine-learning-workflow"], [71, "machine-learning-workflow"], [79, "machine-learning-workflow"]], "Magnitude of the coefficients": [[18, "magnitude-of-the-coefficients"], [39, "magnitude-of-the-coefficients"], [77, "magnitude-of-the-coefficients"]], "Main approaches": [[57, "main-approaches"]], "Main hyperparameter of logistic regression": [[18, "main-hyperparameter-of-logistic-regression"], [39, "main-hyperparameter-of-logistic-regression"], [77, "main-hyperparameter-of-logistic-regression"]], "Main hyperparameters": [[18, "main-hyperparameters"], [39, "main-hyperparameters"], [77, "main-hyperparameters"]], "Main idea": [[56, "main-idea"]], "Main issues in ML-related communication": [[91, "main-issues-in-ml-related-communication"]], "Manual hyperparameter optimization": [[19, "manual-hyperparameter-optimization"], [40, "manual-hyperparameter-optimization"], [78, "manual-hyperparameter-optimization"]], "Many other things possible": [[58, "many-other-things-possible"]], "Mean intra-cluster distance (a)": [[25, "mean-intra-cluster-distance-a"], [46, "mean-intra-cluster-distance-a"], [55, "mean-intra-cluster-distance-a"], [84, "mean-intra-cluster-distance-a"]], "Mean nearest-cluster distance (b)": [[25, "mean-nearest-cluster-distance-b"], [46, "mean-nearest-cluster-distance-b"], [55, "mean-nearest-cluster-distance-b"], [84, "mean-nearest-cluster-distance-b"]], "Mean squared error (MSE)": [[21, "mean-squared-error-mse"], [42, "mean-squared-error-mse"], [69, "mean-squared-error-mse"], [80, "mean-squared-error-mse"]], "Meet Eva (a fictitious persona)!": [[12, "meet-eva-a-fictitious-persona"], [32, "meet-eva-a-fictitious-persona"], [71, "meet-eva-a-fictitious-persona"]], "Method 1: The Elbow method": [[25, "method-1-the-elbow-method"], [46, "method-1-the-elbow-method"], [55, "method-1-the-elbow-method"], [84, "method-1-the-elbow-method"]], "Method 2: The Silhouette method": [[25, "method-2-the-silhouette-method"], [46, "method-2-the-silhouette-method"], [55, "method-2-the-silhouette-method"], [84, "method-2-the-silhouette-method"]], "Midterms": [[103, "midterms"]], "Misc": [[1, "misc"], [9, "misc"]], "Miscellaneous comments on content-based filtering": [[27, "miscellaneous-comments-on-content-based-filtering"], [48, "miscellaneous-comments-on-content-based-filtering"], [57, "miscellaneous-comments-on-content-based-filtering"], [86, "miscellaneous-comments-on-content-based-filtering"]], "Model building": [[21, "model-building"], [42, "model-building"], [80, "model-building"], [92, "model-building"]], "Model building on the dataset": [[38, "model-building-on-the-dataset"], [66, "model-building-on-the-dataset"], [67, "model-building-on-the-dataset"]], "Model complexity and training error": [[14, "model-complexity-and-training-error"], [34, "model-complexity-and-training-error"], [73, "model-complexity-and-training-error"]], "Model deployment": [[92, "model-deployment"], [92, "id1"]], "Model interpretability beyond linear models": [[23, "model-interpretability-beyond-linear-models"], [44, "model-interpretability-beyond-linear-models"], [53, "model-interpretability-beyond-linear-models"], [82, "model-interpretability-beyond-linear-models"]], "Model predictions on unseen data": [[12, "model-predictions-on-unseen-data"], [32, "model-predictions-on-unseen-data"], [71, "model-predictions-on-unseen-data"]], "Model training and evaluation": [[100, "model-training-and-evaluation"]], "Model transparency and interpretation": [[92, "model-transparency-and-interpretation"]], "Model-based selection": [[24, "model-based-selection"], [45, "model-based-selection"], [54, "model-based-selection"], [83, "model-based-selection"]], "Modeling": [[65, "modeling"]], "More comments on tackling class imbalance": [[21, "more-comments-on-tackling-class-imbalance"], [42, "more-comments-on-tackling-class-imbalance"], [69, "more-comments-on-tackling-class-imbalance"], [80, "more-comments-on-tackling-class-imbalance"]], "More details": [[34, "more-details"]], "More details on DBSCAN": [[26, "more-details-on-dbscan"], [47, "more-details-on-dbscan"], [56, "more-details-on-dbscan"], [85, "more-details-on-dbscan"]], "More on feature transformations": [[17, "more-on-feature-transformations"], [37, "more-on-feature-transformations"], [76, "more-on-feature-transformations"]], "More on k-NNs [video]": [[15, "more-on-k-nns-video"], [35, "more-on-k-nns-video"], [74, "more-on-k-nns-video"]], "More terminology [video]": [[13, "more-terminology-video"], [33, "more-terminology-video"], [72, "more-terminology-video"]], "More than one ordinal columns?": [[17, "more-than-one-ordinal-columns"], [37, "more-than-one-ordinal-columns"], [76, "more-than-one-ordinal-columns"]], "Most confident cases": [[18, "most-confident-cases"], [39, "most-confident-cases"], [77, "most-confident-cases"]], "Most negative review": [[38, "most-negative-review"], [66, "most-negative-review"], [67, "most-negative-review"]], "Most positive review": [[38, "most-positive-review"], [66, "most-positive-review"], [67, "most-positive-review"]], "Motivating example": [[18, "motivating-example"], [39, "motivating-example"], [77, "motivating-example"]], "Motivation": [[19, "motivation"], [30, "motivation"], [40, "motivation"], [51, "motivation"], [56, "motivation"], [60, "motivation"], [78, "motivation"], [89, "motivation"], [91, "motivation"]], "Motivation [video]": [[22, "motivation-video"], [43, "motivation-video"], [81, "motivation-video"]], "Motivation and big picture [video]": [[16, "motivation-and-big-picture-video"], [36, "motivation-and-big-picture-video"], [75, "motivation-and-big-picture-video"]], "Motivation and context": [[28, "motivation-and-context"], [49, "motivation-and-context"], [58, "motivation-and-context"], [87, "motivation-and-context"]], "Motivation and distances [video]": [[15, "motivation-and-distances-video"], [35, "motivation-and-distances-video"], [74, "motivation-and-distances-video"]], "Movie features": [[27, "movie-features"], [48, "movie-features"], [57, "movie-features"], [86, "movie-features"]], "Multi-class classification": [[29, "multi-class-classification"], [50, "multi-class-classification"], [59, "multi-class-classification"], [59, "id4"], [88, "multi-class-classification"]], "Multi-class classification approaches": [[59, "multi-class-classification-approaches"]], "Multiclass classification and computer vision": [[95, "multiclass-classification-and-computer-vision"]], "Multiple transformations in a transformer": [[17, "multiple-transformations-in-a-transformer"], [37, "multiple-transformations-in-a-transformer"], [76, "multiple-transformations-in-a-transformer"]], "NLP in news": [[58, "nlp-in-news"]], "NOTE:": [[8, "note"]], "Neural networks": [[59, "neural-networks"]], "Neural networks intuition": [[59, "neural-networks-intuition"]], "New ideas in small chunks": [[91, "new-ideas-in-small-chunks"]], "No-loop method: make them the same size, and multiply element-wise": [[8, "no-loop-method-make-them-the-same-size-and-multiply-element-wise"]], "Non-linearity": [[59, "non-linearity"]], "Note": [[14, null], [14, null], [30, null], [51, null], [73, null], [73, null], [89, null]], "Number of trees and fundamental trade-off": [[22, "number-of-trees-and-fundamental-trade-off"], [43, "number-of-trees-and-fundamental-trade-off"], [52, "number-of-trees-and-fundamental-trade-off"], [81, "number-of-trees-and-fundamental-trade-off"]], "Numpy array shapes": [[8, "numpy-array-shapes"]], "Numpy arrays": [[8, "numpy-arrays"]], "OHE with many categories": [[17, "ohe-with-many-categories"], [76, "ohe-with-many-categories"]], "Object detection": [[29, "object-detection"], [50, "object-detection"], [59, "object-detection"], [88, "object-detection"]], "Observations": [[20, "observations"], [41, "observations"], [56, "observations"], [68, "observations"], [79, "observations"]], "One Vs. One approach": [[94, "one-vs-one-approach"]], "One Vs. One prediction": [[94, "one-vs-one-prediction"]], "One vs. Rest": [[94, "one-vs-rest"]], "One-hot encoding (OHE)": [[16, "one-hot-encoding-ohe"], [36, "one-hot-encoding-ohe"], [75, "one-hot-encoding-ohe"]], "One-hot encoding of the month": [[30, "one-hot-encoding-of-the-month"], [89, "one-hot-encoding-of-the-month"]], "One-hot encoding seasons": [[30, "one-hot-encoding-seasons"], [89, "one-hot-encoding-seasons"]], "OneHotEncoder and sparse features": [[17, "onehotencoder-and-sparse-features"], [37, "onehotencoder-and-sparse-features"], [76, "onehotencoder-and-sparse-features"]], "Online courses": [[1, "online-courses"], [9, "online-courses"]], "Operating point": [[20, "operating-point"], [41, "operating-point"], [68, "operating-point"], [79, "operating-point"]], "Optimization bias of hyper-parameter learning": [[19, "optimization-bias-of-hyper-parameter-learning"], [40, "optimization-bias-of-hyper-parameter-learning"], [78, "optimization-bias-of-hyper-parameter-learning"]], "Optimization bias of parameter learning": [[19, "optimization-bias-of-parameter-learning"], [40, "optimization-bias-of-parameter-learning"], [78, "optimization-bias-of-parameter-learning"]], "Optimization bias on the Spotify dataset": [[19, "optimization-bias-on-the-spotify-dataset"], [40, "optimization-bias-on-the-spotify-dataset"], [78, "optimization-bias-on-the-spotify-dataset"]], "Optimization bias/Overfitting of the validation set": [[19, "optimization-bias-overfitting-of-the-validation-set"], [78, "optimization-bias-overfitting-of-the-validation-set"]], "Optimization bias/Overfitting of the validation set (video)": [[40, "optimization-bias-overfitting-of-the-validation-set-video"]], "Optional readings and resources": [[19, "optional-readings-and-resources"], [40, "optional-readings-and-resources"], [78, "optional-readings-and-resources"]], "Ordinal encoding (occasionally recommended)": [[16, "ordinal-encoding-occasionally-recommended"], [36, "ordinal-encoding-occasionally-recommended"], [75, "ordinal-encoding-occasionally-recommended"]], "Ordinal features": [[23, "ordinal-features"], [44, "ordinal-features"], [53, "ordinal-features"], [65, "ordinal-features"], [82, "ordinal-features"]], "Other applications": [[25, "other-applications"], [46, "other-applications"], [55, "other-applications"], [84, "other-applications"]], "Other approaches / what did we not cover?": [[31, "other-approaches-what-did-we-not-cover"], [61, "other-approaches-what-did-we-not-cover"], [90, "other-approaches-what-did-we-not-cover"]], "Other commonly used preprocessing steps": [[28, "other-commonly-used-preprocessing-steps"], [49, "other-commonly-used-preprocessing-steps"], [58, "other-commonly-used-preprocessing-steps"], [87, "other-commonly-used-preprocessing-steps"]], "Other popular methods to get embeddings": [[58, "other-popular-methods-to-get-embeddings"]], "Other possible preprocessing?": [[21, "other-possible-preprocessing"], [42, "other-possible-preprocessing"], [80, "other-possible-preprocessing"]], "Other software package": [[30, "other-software-package"], [51, "other-software-package"], [60, "other-software-package"], [89, "other-software-package"]], "Other tools for preprocessing": [[28, "other-tools-for-preprocessing"], [49, "other-tools-for-preprocessing"], [58, "other-tools-for-preprocessing"], [87, "other-tools-for-preprocessing"]], "Other typical NLP tasks": [[28, "other-typical-nlp-tasks"], [49, "other-typical-nlp-tasks"], [58, "other-typical-nlp-tasks"], [87, "other-typical-nlp-tasks"]], "Other useful arguments of KNeighborsClassifier": [[15, "other-useful-arguments-of-kneighborsclassifier"], [35, "other-useful-arguments-of-kneighborsclassifier"], [74, "other-useful-arguments-of-kneighborsclassifier"]], "Other ways to search": [[24, "other-ways-to-search"], [45, "other-ways-to-search"], [54, "other-ways-to-search"], [83, "other-ways-to-search"]], "Our typical supervised learning set up is as follows:": [[14, "our-typical-supervised-learning-set-up-is-as-follows"], [34, "our-typical-supervised-learning-set-up-is-as-follows"], [73, "our-typical-supervised-learning-set-up-is-as-follows"]], "Outline": [[96, "outline"], [97, "outline"], [98, "outline"], [99, "outline"], [100, "outline"], [101, "outline"], [102, "outline"]], "Over confident cases": [[18, "over-confident-cases"], [39, "over-confident-cases"], [77, "over-confident-cases"]], "Overall goal": [[58, "overall-goal"]], "Overfitting": [[14, "overfitting"], [34, "overfitting"], [73, "overfitting"]], "Overfitting of the validation data": [[19, "overfitting-of-the-validation-data"], [40, "overfitting-of-the-validation-data"], [78, "overfitting-of-the-validation-data"]], "Overfitting of the validation error": [[19, "overfitting-of-the-validation-error"], [40, "overfitting-of-the-validation-error"], [78, "overfitting-of-the-validation-error"]], "Oversampling": [[20, "oversampling"], [79, "oversampling"]], "Overview": [[15, "overview"], [35, "overview"], [57, "overview"], [74, "overview"]], "Overview of dot product and cosine similarity": [[58, "overview-of-dot-product-and-cosine-similarity"]], "POSIX time feature": [[30, "posix-time-feature"], [51, "posix-time-feature"], [60, "posix-time-feature"], [89, "posix-time-feature"]], "PR curves for logistic regression and SVC": [[20, "pr-curves-for-logistic-regression-and-svc"], [41, "pr-curves-for-logistic-regression-and-svc"], [68, "pr-curves-for-logistic-regression-and-svc"], [79, "pr-curves-for-logistic-regression-and-svc"]], "Pandas DataFrames": [[8, "pandas-dataframes"]], "Pandas Series": [[8, "pandas-series"]], "Parameters": [[13, "parameters"], [33, "parameters"], [72, "parameters"]], "Parameters and hyperparameters: Summary": [[13, "parameters-and-hyperparameters-summary"], [33, "parameters-and-hyperparameters-summary"], [72, "parameters-and-hyperparameters-summary"]], "Parsing datetimes": [[30, "parsing-datetimes"], [89, "parsing-datetimes"], [102, "parsing-datetimes"]], "Part 1": [[95, "part-1"]], "Part 2": [[95, "part-2"]], "Pat\u2019s profile": [[57, "pat-s-profile"]], "Persistence": [[57, "persistence"]], "Piazza-specific Q&A guidelines": [[4, "piazza-specific-q-a-guidelines"]], "Pipeline analogy": [[59, "pipeline-analogy"]], "Pipelines": [[16, "pipelines"], [36, "pipelines"], [75, "pipelines"]], "Playground": [[15, "playground"], [74, "playground"]], "Playground (in tutorial)": [[35, "playground-in-tutorial"]], "Plotting with matplotlib": [[8, "plotting-with-matplotlib"]], "Practice exercises": [[33, "practice-exercises"], [72, "practice-exercises"]], "Pre-trained embeddings": [[58, "pre-trained-embeddings"]], "Precision": [[20, "precision"], [41, "precision"], [68, "precision"], [79, "precision"]], "Precision and recall: toy example": [[20, "precision-and-recall-toy-example"], [41, "precision-and-recall-toy-example"], [68, "precision-and-recall-toy-example"], [79, "precision-and-recall-toy-example"]], "Precision, recall, f1 score": [[20, "precision-recall-f1-score"], [68, "precision-recall-f1-score"]], "Precision, recall, f1 score (video)": [[41, "precision-recall-f1-score-video"], [79, "precision-recall-f1-score-video"]], "Precision-recall curve": [[20, "precision-recall-curve"], [20, "id1"], [41, "precision-recall-curve"], [41, "id1"], [68, "precision-recall-curve"], [68, "id1"], [79, "precision-recall-curve"], [79, "id1"]], "Precision/Recall tradeoff": [[20, "precision-recall-tradeoff"], [41, "precision-recall-tradeoff"], [68, "precision-recall-tradeoff"], [79, "precision-recall-tradeoff"]], "Predicting on unseen data using the trained model": [[12, "predicting-on-unseen-data-using-the-trained-model"], [32, "predicting-on-unseen-data-using-the-trained-model"], [71, "predicting-on-unseen-data-using-the-trained-model"]], "Predicting probability scores [video]": [[18, "predicting-probability-scores-video"], [39, "predicting-probability-scores-video"], [77, "predicting-probability-scores-video"]], "Predicting ratings for Eva": [[57, "predicting-ratings-for-eva"]], "Predicting ratings for Pat": [[57, "predicting-ratings-for-pat"]], "Predicting with learned weights": [[18, "predicting-with-learned-weights"], [39, "predicting-with-learned-weights"], [77, "predicting-with-learned-weights"]], "Prediction": [[31, "prediction"], [61, "prediction"], [90, "prediction"]], "Prediction of linear regression": [[18, "prediction-of-linear-regression"], [39, "prediction-of-linear-regression"], [77, "prediction-of-linear-regression"]], "Prediction with learned parameters": [[18, "prediction-with-learned-parameters"], [39, "prediction-with-learned-parameters"], [77, "prediction-with-learned-parameters"]], "Predictions": [[29, "predictions"], [50, "predictions"], [59, "predictions"], [88, "predictions"]], "Preferences in LogisticRegression": [[91, "preferences-in-logisticregression"]], "Preparation": [[7, "preparation"]], "Preprocessing": [[17, "preprocessing"], [30, "preprocessing"], [37, "preprocessing"], [76, "preprocessing"], [89, "preprocessing"], [95, "preprocessing"], [100, "preprocessing"], [102, "preprocessing"]], "Preprocessing the corpus": [[58, "preprocessing-the-corpus"]], "Preprocessing the targets?": [[17, "preprocessing-the-targets"], [37, "preprocessing-the-targets"], [76, "preprocessing-the-targets"]], "Prevalence of ML": [[12, "prevalence-of-ml"], [32, "prevalence-of-ml"], [71, "prevalence-of-ml"]], "Principles of effective communication": [[91, "principles-of-effective-communication"]], "Principles of good explanations (~15 min)": [[91, "principles-of-good-explanations-15-min"]], "Probabilistic programming languages": [[59, "probabilistic-programming-languages"]], "Problem formulation": [[27, "problem-formulation"], [48, "problem-formulation"], [57, "problem-formulation"], [86, "problem-formulation"]], "Problem: Different transformations on different columns": [[16, "problem-different-transformations-on-different-columns"], [36, "problem-different-transformations-on-different-columns"], [75, "problem-different-transformations-on-different-columns"]], "Problems with exhaustive grid search": [[19, "problems-with-exhaustive-grid-search"], [40, "problems-with-exhaustive-grid-search"], [78, "problems-with-exhaustive-grid-search"]], "Problems with single train/validation split": [[14, "problems-with-single-train-validation-split"], [34, "problems-with-single-train-validation-split"], [73, "problems-with-single-train-validation-split"]], "Pros of k-NNs for supervised learning": [[15, "pros-of-k-nns-for-supervised-learning"], [35, "pros-of-k-nns-for-supervised-learning"], [74, "pros-of-k-nns-for-supervised-learning"]], "Pros, cons, parameters and hyperparameters of different ML models": [[95, "pros-cons-parameters-and-hyperparameters-of-different-ml-models"]], "Punctuation and stopword removal": [[58, "punctuation-and-stopword-removal"]], "Python and Conda": [[10, "python-and-conda"]], "Python requirements/resources": [[12, "python-requirements-resources"], [32, "python-requirements-resources"]], "Python resources": [[9, "python-resources"]], "Question": [[15, "question"], [35, "question"], [74, "question"]], "Question for you": [[26, "question-for-you"], [47, "question-for-you"], [56, "question-for-you"], [85, "question-for-you"]], "Question for you to ponder on": [[38, "question-for-you-to-ponder-on"], [66, "question-for-you-to-ponder-on"], [67, "question-for-you-to-ponder-on"]], "Questions for class discussion": [[27, "questions-for-class-discussion"], [48, "questions-for-class-discussion"], [86, "questions-for-class-discussion"]], "Questions for class discussion (hyperparameter optimization)": [[19, "questions-for-class-discussion-hyperparameter-optimization"], [40, "questions-for-class-discussion-hyperparameter-optimization"], [78, "questions-for-class-discussion-hyperparameter-optimization"]], "Quick recap": [[15, "quick-recap"], [74, "quick-recap"]], "RF better than GB": [[91, "rf-better-than-gb"]], "RFE algorithm": [[24, "rfe-algorithm"], [45, "rfe-algorithm"], [54, "rfe-algorithm"], [83, "rfe-algorithm"]], "R^2 (not in detail)": [[21, "r-2-not-in-detail"], [42, "r-2-not-in-detail"], [69, "r-2-not-in-detail"], [80, "r-2-not-in-detail"]], "Random cool stuff": [[59, "random-cool-stuff"]], "Random forest feature importances": [[23, "random-forest-feature-importances"], [44, "random-forest-feature-importances"], [53, "random-forest-feature-importances"], [82, "random-forest-feature-importances"]], "Random forests": [[22, "random-forests"], [43, "random-forests"], [52, "random-forests"], [81, "random-forests"]], "Random forests: number of trees (n_estimators) and the fundamental tradeoff": [[22, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"], [43, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"], [52, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"], [81, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"]], "RandomForestClassifier": [[22, "randomforestclassifier"], [31, "randomforestclassifier"], [43, "randomforestclassifier"], [52, "randomforestclassifier"], [61, "randomforestclassifier"], [81, "randomforestclassifier"], [90, "randomforestclassifier"]], "Randomized hyperparameter search": [[19, "randomized-hyperparameter-search"], [40, "randomized-hyperparameter-search"], [78, "randomized-hyperparameter-search"]], "Range of C": [[19, "range-of-c"], [40, "range-of-c"], [78, "range-of-c"]], "Raw scores": [[18, "raw-scores"], [39, "raw-scores"], [77, "raw-scores"]], "Reading from .csv": [[8, "reading-from-csv"]], "Reading from other formats": [[8, "reading-from-other-formats"]], "Reading from url": [[8, "reading-from-url"]], "Reading the data": [[13, "reading-the-data"], [29, "reading-the-data"], [33, "reading-the-data"], [50, "reading-the-data"], [59, "reading-the-data"], [72, "reading-the-data"], [88, "reading-the-data"]], "Real boundary between Canada and USA": [[13, "real-boundary-between-canada-and-usa"], [72, "real-boundary-between-canada-and-usa"], [96, "real-boundary-between-canada-and-usa"]], "Reasonable grading concerns": [[6, "reasonable-grading-concerns"]], "Recall": [[20, "recall"], [41, "recall"], [68, "recall"], [79, "recall"]], "Recap": [[31, "recap"], [61, "recap"], [90, "recap"], [91, "recap"]], "Recap and motivation [video]": [[26, "recap-and-motivation-video"], [47, "recap-and-motivation-video"], [85, "recap-and-motivation-video"]], "Recap: Supervised machine learning": [[13, "recap-supervised-machine-learning"], [33, "recap-supervised-machine-learning"], [72, "recap-supervised-machine-learning"]], "Receiver Operating Characteristic (ROC) curve": [[20, "receiver-operating-characteristic-roc-curve"], [41, "receiver-operating-characteristic-roc-curve"], [68, "receiver-operating-characteristic-roc-curve"], [79, "receiver-operating-characteristic-roc-curve"]], "Recipe to approach a supervised learning problem with tabular data": [[92, "recipe-to-approach-a-supervised-learning-problem-with-tabular-data"]], "Recommended browser": [[12, "recommended-browser"], [32, "recommended-browser"]], "Recommender systems": [[95, "recommender-systems"]], "Recommender systems intro and motivation": [[27, "recommender-systems-intro-and-motivation"], [48, "recommender-systems-intro-and-motivation"], [86, "recommender-systems-intro-and-motivation"]], "Recommender systems motivation": [[57, "recommender-systems-motivation"]], "Recommender systems problem": [[27, "recommender-systems-problem"], [48, "recommender-systems-problem"], [57, "recommender-systems-problem"], [86, "recommender-systems-problem"]], "Recursive feature elimination (RFE)": [[24, "recursive-feature-elimination-rfe"], [45, "recursive-feature-elimination-rfe"], [54, "recursive-feature-elimination-rfe"], [83, "recursive-feature-elimination-rfe"]], "Reference Material": [[1, "reference-material"]], "Reference material": [[9, null]], "References": [[31, "references"], [61, "references"], [90, "references"]], "Registration": [[103, "registration"]], "Registration, waitlist and prerequisites": [[12, "registration-waitlist-and-prerequisites"], [32, "registration-waitlist-and-prerequisites"]], "Regression scoring functions": [[21, "regression-scoring-functions"], [42, "regression-scoring-functions"], [69, "regression-scoring-functions"], [80, "regression-scoring-functions"]], "Regression with k-nearest neighbours (k-NNs)": [[15, "regression-with-k-nearest-neighbours-k-nns"], [35, "regression-with-k-nearest-neighbours-k-nns"], [74, "regression-with-k-nearest-neighbours-k-nns"]], "Relation of C and the fundamental trade-off": [[15, "relation-of-c-and-the-fundamental-trade-off"], [35, "relation-of-c-and-the-fundamental-trade-off"], [74, "relation-of-c-and-the-fundamental-trade-off"]], "Relation of gamma and the fundamental trade-off": [[15, "relation-of-gamma-and-the-fundamental-trade-off"], [35, "relation-of-gamma-and-the-fundamental-trade-off"], [74, "relation-of-gamma-and-the-fundamental-trade-off"]], "Relevant companion materials": [[9, "relevant-companion-materials"]], "Relevant papers": [[22, "relevant-papers"], [43, "relevant-papers"], [52, "relevant-papers"], [81, "relevant-papers"]], "Relevant papers and resources": [[20, "relevant-papers-and-resources"], [41, "relevant-papers-and-resources"], [79, "relevant-papers-and-resources"]], "Relevant resources": [[24, "relevant-resources"], [45, "relevant-resources"], [54, "relevant-resources"], [83, "relevant-resources"]], "Reminder": [[27, "reminder"], [48, "reminder"], [57, "reminder"], [86, "reminder"]], "Renaming columns with df.rename()": [[8, "renaming-columns-with-df-rename"]], "Render set-up (I already did these):": [[92, "render-set-up-i-already-did-these"]], "Report format": [[7, "report-format"]], "Representing documents using word embeddings": [[58, "representing-documents-using-word-embeddings"]], "Representing images for ML": [[59, "representing-images-for-ml"], [59, "id3"]], "Requirements (I already did these)": [[92, "requirements-i-already-did-these"]], "Resources": [[25, "resources"], [26, "resources"], [27, "resources"], [46, "resources"], [47, "resources"], [48, "resources"], [84, "resources"], [85, "resources"], [86, "resources"]], "Reuse your running examples": [[91, "reuse-your-running-examples"]], "Ridge": [[18, "ridge"], [39, "ridge"], [77, "ridge"]], "Ridge on the California housing dataset": [[18, "ridge-on-the-california-housing-dataset"], [39, "ridge-on-the-california-housing-dataset"], [77, "ridge-on-the-california-housing-dataset"]], "Ridge regression": [[69, "ridge-regression"]], "Ridge regression (L2 penalty) (Optional)": [[54, "ridge-regression-l2-penalty-optional"]], "RidgeCV": [[21, "ridgecv"], [42, "ridgecv"], [69, "ridgecv"], [80, "ridgecv"]], "Root mean squared error or RMSE": [[21, "root-mean-squared-error-or-rmse"], [42, "root-mean-squared-error-or-rmse"], [69, "root-mean-squared-error-or-rmse"], [80, "root-mean-squared-error-or-rmse"]], "SHAP  (SHapley Additive exPlanations) introduction": [[23, "shap-shapley-additive-explanations-introduction"], [44, "shap-shapley-additive-explanations-introduction"], [53, "shap-shapley-additive-explanations-introduction"], [82, "shap-shapley-additive-explanations-introduction"]], "SHAP Dependence plot": [[53, "shap-dependence-plot"]], "SHAP Force plot": [[53, "shap-force-plot"]], "SHAP on LGBM model": [[53, "shap-on-lgbm-model"]], "SHAP plots": [[23, "shap-plots"], [44, "shap-plots"], [53, "shap-plots"], [82, "shap-plots"]], "SHAP summary plot": [[53, "shap-summary-plot"]], "SHAP waterfall plot": [[53, "shap-waterfall-plot"]], "SHAP: visualizing multiple predictions": [[53, "shap-visualizing-multiple-predictions"]], "SMOTE idea": [[20, "smote-idea"], [79, "smote-idea"]], "SMOTE: Synthetic Minority Over-sampling Technique": [[20, "smote-synthetic-minority-over-sampling-technique"], [79, "smote-synthetic-minority-over-sampling-technique"]], "SVM Regressor": [[15, "svm-regressor"], [35, "svm-regressor"], [74, "svm-regressor"]], "Saving the model": [[92, "saving-the-model"]], "Saving time and scaling products": [[12, "saving-time-and-scaling-products"], [32, "saving-time-and-scaling-products"], [71, "saving-time-and-scaling-products"]], "Scaling": [[16, "scaling"], [36, "scaling"], [75, "scaling"]], "Scaling using scikit-learn\u2019s StandardScaler": [[16, "scaling-using-scikit-learn-s-standardscaler"], [36, "scaling-using-scikit-learn-s-standardscaler"], [75, "scaling-using-scikit-learn-s-standardscaler"]], "Search over multiple hyperparameters": [[15, "search-over-multiple-hyperparameters"], [35, "search-over-multiple-hyperparameters"], [74, "search-over-multiple-hyperparameters"]], "Seasonality and trends": [[30, "seasonality-and-trends"], [51, "seasonality-and-trends"], [60, "seasonality-and-trends"], [89, "seasonality-and-trends"]], "Select all of the following statements which are True (iClicker)": [[12, "select-all-of-the-following-statements-which-are-true-iclicker"], [32, "select-all-of-the-following-statements-which-are-true-iclicker"], [71, "select-all-of-the-following-statements-which-are-true-iclicker"]], "Sending a request to the API": [[92, "sending-a-request-to-the-api"]], "Sentence segmentation": [[58, "sentence-segmentation"]], "Separate X and y": [[69, "separate-x-and-y"]], "Setting up": [[5, "setting-up"]], "Setting up a virtual environment: Conda environments": [[10, "setting-up-a-virtual-environment-conda-environments"]], "Setting up coding environment": [[10, null]], "Setting up your computer for the course": [[12, "setting-up-your-computer-for-the-course"], [32, "setting-up-your-computer-for-the-course"]], "Short posts/articles": [[9, "short-posts-articles"]], "Sigmoid vs. Softmax": [[29, "sigmoid-vs-softmax"], [50, "sigmoid-vs-softmax"], [59, "sigmoid-vs-softmax"], [88, "sigmoid-vs-softmax"]], "Sign of the coefficients": [[18, "sign-of-the-coefficients"], [39, "sign-of-the-coefficients"], [77, "sign-of-the-coefficients"]], "Silhouette distance for a sample": [[25, "silhouette-distance-for-a-sample"], [46, "silhouette-distance-for-a-sample"], [55, "silhouette-distance-for-a-sample"], [84, "silhouette-distance-for-a-sample"]], "Similarity between examples": [[15, "similarity-between-examples"], [35, "similarity-between-examples"], [74, "similarity-between-examples"]], "Simple feature engineering for our problem.": [[93, "simple-feature-engineering-for-our-problem"]], "Simple train/test split": [[14, "simple-train-test-split"], [34, "simple-train-test-split"], [73, "simple-train-test-split"]], "SimpleFeature correlations": [[23, "simplefeature-correlations"], [44, "simplefeature-correlations"], [53, "simplefeature-correlations"], [82, "simplefeature-correlations"]], "Single analysis of lymphoma": [[56, "single-analysis-of-lymphoma"]], "Single validation set": [[63, "single-validation-set"]], "Slowest method: nested loop": [[8, "slowest-method-nested-loop"]], "Social recommendation": [[57, "social-recommendation"]], "Software": [[0, "software"]], "Solution": [[43, "solution"]], "Some important hyperparameters:": [[22, "some-important-hyperparameters"], [43, "some-important-hyperparameters"], [52, "some-important-hyperparameters"], [81, "some-important-hyperparameters"]], "Some key takeaways": [[92, "some-key-takeaways"]], "Some quotes on feature engineering": [[24, "some-quotes-on-feature-engineering"], [45, "some-quotes-on-feature-engineering"], [54, "some-quotes-on-feature-engineering"], [83, "some-quotes-on-feature-engineering"]], "Some terminology related to trees": [[13, "some-terminology-related-to-trees"], [33, "some-terminology-related-to-trees"], [72, "some-terminology-related-to-trees"]], "Some ways to pick hyperparameters:": [[19, "some-ways-to-pick-hyperparameters"], [40, "some-ways-to-pick-hyperparameters"], [78, "some-ways-to-pick-hyperparameters"]], "Sorting a dataframe with df.sort_values()": [[8, "sorting-a-dataframe-with-df-sort-values"]], "Spam/non spam toy example": [[17, "spam-non-spam-toy-example"], [37, "spam-non-spam-toy-example"], [76, "spam-non-spam-toy-example"]], "Sparsity of utility matrix": [[57, "sparsity-of-utility-matrix"]], "Specific questions": [[4, "specific-questions"]], "Stacking": [[22, "stacking"], [43, "stacking"], [52, "stacking"], [81, "stacking"], [101, "stacking"]], "Stemming": [[58, "stemming"]], "Step 1": [[98, "step-1"]], "Step 2": [[98, "step-2"]], "Step 3": [[98, "step-3"]], "Step 4": [[98, "step-4"]], "Step 5": [[98, "step-5"]], "Steps to train a classifier using sklearn": [[13, "steps-to-train-a-classifier-using-sklearn"], [33, "steps-to-train-a-classifier-using-sklearn"], [72, "steps-to-train-a-classifier-using-sklearn"]], "Stratified Splits": [[20, "stratified-splits"], [41, "stratified-splits"], [79, "stratified-splits"]], "Strengths": [[52, "strengths"]], "Strengths and weaknesses": [[22, "strengths-and-weaknesses"], [43, "strengths-and-weaknesses"], [81, "strengths-and-weaknesses"]], "Strengths of linear models": [[18, "strengths-of-linear-models"], [39, "strengths-of-linear-models"], [77, "strengths-of-linear-models"]], "Study tips": [[95, "study-tips"]], "Submitting on Gradescope": [[7, "submitting-on-gradescope"]], "Success of word2vec": [[58, "success-of-word2vec"]], "Summary": [[12, "summary"], [15, "summary"], [22, "summary"], [28, "summary"], [29, "summary"], [31, "summary"], [32, "summary"], [35, "summary"], [43, "summary"], [49, "summary"], [50, "summary"], [52, "summary"], [58, "summary"], [59, "summary"], [61, "summary"], [71, "summary"], [74, "summary"], [81, "summary"], [87, "summary"], [88, "summary"], [90, "summary"]], "Summary and reflection": [[14, "summary-and-reflection"], [34, "summary-and-reflection"], [73, "summary-and-reflection"]], "Summary of linear models": [[18, "summary-of-linear-models"], [39, "summary-of-linear-models"], [77, "summary-of-linear-models"]], "Summary of train, validation, test, and deployment data": [[14, "summary-of-train-validation-test-and-deployment-data"], [34, "summary-of-train-validation-test-and-deployment-data"], [73, "summary-of-train-validation-test-and-deployment-data"]], "Summary: Pros and cons": [[26, "summary-pros-and-cons"], [47, "summary-pros-and-cons"], [56, "summary-pros-and-cons"], [85, "summary-pros-and-cons"]], "Supervised approach to rating prediction": [[27, "supervised-approach-to-rating-prediction"], [48, "supervised-approach-to-rating-prediction"], [57, "supervised-approach-to-rating-prediction"], [86, "supervised-approach-to-rating-prediction"]], "Supervised learning": [[25, "supervised-learning"], [46, "supervised-learning"], [55, "supervised-learning"], [84, "supervised-learning"]], "Supervised learning (Reminder)": [[13, "supervised-learning-reminder"], [72, "supervised-learning-reminder"]], "Supervised learning vs. Unsupervised learning": [[13, "supervised-learning-vs-unsupervised-learning"], [33, "supervised-learning-vs-unsupervised-learning"], [72, "supervised-learning-vs-unsupervised-learning"]], "Supervised machine learning": [[12, "supervised-machine-learning"], [32, "supervised-machine-learning"], [71, "supervised-machine-learning"]], "Support Vector Machines (SVMs) with RBF kernel [video]": [[15, "support-vector-machines-svms-with-rbf-kernel-video"], [35, "support-vector-machines-svms-with-rbf-kernel-video"], [74, "support-vector-machines-svms-with-rbf-kernel-video"]], "Support vectors": [[15, "support-vectors"], [35, "support-vectors"], [74, "support-vectors"]], "Survival analysis": [[95, "survival-analysis"]], "Survival plots": [[31, "survival-plots"], [61, "survival-plots"], [90, "survival-plots"]], "Syllabus": [[1, "syllabus"], [103, null]], "TAs": [[1, "tas"], [103, "tas"]], "Tabular data": [[13, "tabular-data"], [33, "tabular-data"], [72, "tabular-data"]], "Take-home message": [[26, "take-home-message"], [47, "take-home-message"], [56, "take-home-message"], [85, "take-home-message"]], "Teaching Team": [[103, "teaching-team"]], "Terminology": [[29, "terminology"], [50, "terminology"], [59, "terminology"], [88, "terminology"]], "Terminology [video]": [[13, "terminology-video"], [33, "terminology-video"], [72, "terminology-video"]], "Testing your git installation": [[5, "testing-your-git-installation"]], "The Netflix prize": [[22, "the-netflix-prize"], [43, "the-netflix-prize"], [81, "the-netflix-prize"]], "The __ syntax": [[19, "the-syntax"], [40, "the-syntax"], [78, "the-syntax"]], "The best features may be dependent on the model you use.": [[24, "the-best-features-may-be-dependent-on-the-model-you-use"], [54, "the-best-features-may-be-dependent-on-the-model-you-use"], [83, "the-best-features-may-be-dependent-on-the-model-you-use"]], "The dataset": [[101, "the-dataset"]], "The golden rule <a name=\"4\"></a>": [[14, "the-golden-rule"], [34, "the-golden-rule"], [73, "the-golden-rule"]], "The random forests classifier": [[22, "the-random-forests-classifier"], [43, "the-random-forests-classifier"], [52, "the-random-forests-classifier"], [81, "the-random-forests-classifier"]], "The sigmoid function": [[18, "the-sigmoid-function"], [39, "the-sigmoid-function"], [77, "the-sigmoid-function"]], "The teaching team": [[1, "the-teaching-team"]], "The \u201cfundamental tradeoff\u201d of supervised learning:": [[14, "the-fundamental-tradeoff-of-supervised-learning"], [34, "the-fundamental-tradeoff-of-supervised-learning"], [73, "the-fundamental-tradeoff-of-supervised-learning"]], "The \u201cperfect\u201d spaghetti sauce": [[25, "the-perfect-spaghetti-sauce"], [46, "the-perfect-spaghetti-sauce"], [84, "the-perfect-spaghetti-sauce"]], "Things to watch out for": [[91, "things-to-watch-out-for"]], "Thresholding": [[68, "thresholding"]], "Time series": [[95, "time-series"]], "Time series analysis on a more complicated dataset": [[102, "time-series-analysis-on-a-more-complicated-dataset"]], "Time to event and censoring": [[31, "time-to-event-and-censoring"], [61, "time-to-event-and-censoring"], [90, "time-to-event-and-censoring"]], "Today\u2019s plan": [[58, "today-s-plan"]], "Tokenization": [[28, "tokenization"], [49, "tokenization"], [58, "tokenization"], [87, "tokenization"]], "Tokenization: sentence segmentation": [[58, "tokenization-sentence-segmentation"]], "Topic modeling": [[28, "topic-modeling"], [49, "topic-modeling"], [58, "topic-modeling"], [87, "topic-modeling"]], "Topic modeling examples": [[58, "topic-modeling-examples"]], "Topic modeling introduction activity (~5 mins)": [[58, "topic-modeling-introduction-activity-5-mins"]], "Topic modeling motivation": [[28, "topic-modeling-motivation"], [49, "topic-modeling-motivation"], [58, "topic-modeling-motivation"], [87, "topic-modeling-motivation"]], "Topic modeling pipeline": [[28, "topic-modeling-pipeline"], [49, "topic-modeling-pipeline"], [58, "topic-modeling-pipeline"], [87, "topic-modeling-pipeline"]], "Topic modeling toy example": [[28, "topic-modeling-toy-example"], [49, "topic-modeling-toy-example"], [58, "topic-modeling-toy-example"], [87, "topic-modeling-toy-example"]], "Topic modeling with sklearn": [[58, "topic-modeling-with-sklearn"]], "Topic modeling: Example": [[58, "topic-modeling-example"], [58, "id3"]], "Topic modeling: Input": [[58, "topic-modeling-input"]], "Topic modeling: Input and output": [[58, "topic-modeling-input-and-output"]], "Topic modeling: Some applications": [[58, "topic-modeling-some-applications"]], "Topic modeling: output": [[58, "topic-modeling-output"]], "Topic modeling: output with interpretation": [[58, "topic-modeling-output-with-interpretation"]], "Topic modelline outside NLP": [[58, "topic-modelline-outside-nlp"]], "Toy datasets": [[13, "toy-datasets"], [72, "toy-datasets"]], "Toy example: Movie recommendation": [[57, "toy-example-movie-recommendation"]], "Traditional time series approaches": [[30, "traditional-time-series-approaches"], [51, "traditional-time-series-approaches"], [60, "traditional-time-series-approaches"], [89, "traditional-time-series-approaches"]], "Train/test split for temporal data": [[30, "train-test-split-for-temporal-data"], [51, "train-test-split-for-temporal-data"], [60, "train-test-split-for-temporal-data"], [89, "train-test-split-for-temporal-data"]], "Train/test splits": [[30, "train-test-splits"], [89, "train-test-splits"]], "Train/validation/test split": [[14, "train-validation-test-split"], [34, "train-validation-test-split"], [73, "train-validation-test-split"]], "Training a supervised machine learning model with X and y": [[12, "training-a-supervised-machine-learning-model-with-x-and-y"], [32, "training-a-supervised-machine-learning-model-with-x-and-y"], [71, "training-a-supervised-machine-learning-model-with-x-and-y"]], "Training data for the motivating example": [[18, "training-data-for-the-motivating-example"], [39, "training-data-for-the-motivating-example"], [77, "training-data-for-the-motivating-example"]], "Training error vs. Generalization error": [[14, "training-error-vs-generalization-error"], [34, "training-error-vs-generalization-error"], [73, "training-error-vs-generalization-error"]], "Training models with transformed data": [[17, "training-models-with-transformed-data"], [37, "training-models-with-transformed-data"], [76, "training-models-with-transformed-data"]], "Training on the full corpus": [[92, "training-on-the-full-corpus"]], "Training our own classifier": [[59, "training-our-own-classifier"]], "Training random forests and gradient boosted trees": [[91, "training-random-forests-and-gradient-boosted-trees"]], "Transfer learning": [[29, "transfer-learning"], [50, "transfer-learning"], [59, "transfer-learning"], [88, "transfer-learning"]], "Transfer learning intuition": [[59, "transfer-learning-intuition"]], "Transformations on the toy data": [[17, "transformations-on-the-toy-data"], [37, "transformations-on-the-toy-data"], [76, "transformations-on-the-toy-data"]], "Transforming the targets": [[21, "transforming-the-targets"], [42, "transforming-the-targets"], [69, "transforming-the-targets"], [80, "transforming-the-targets"]], "Transparency and explainability of ML models: Motivation": [[23, "transparency-and-explainability-of-ml-models-motivation"], [44, "transparency-and-explainability-of-ml-models-motivation"], [53, "transparency-and-explainability-of-ml-models-motivation"], [82, "transparency-and-explainability-of-ml-models-motivation"]], "Tree-based ensemble models": [[22, "tree-based-ensemble-models"], [52, "tree-based-ensemble-models"], [81, "tree-based-ensemble-models"]], "Tree-based models": [[22, "tree-based-models"], [43, "tree-based-models"], [52, "tree-based-models"], [81, "tree-based-models"]], "Truncation": [[56, "truncation"]], "Trust": [[57, "trust"]], "Try out this moment predictor": [[92, "try-out-this-moment-predictor"]], "Tuning alpha hyperparameter of Ridge": [[21, "tuning-alpha-hyperparameter-of-ridge"], [42, "tuning-alpha-hyperparameter-of-ridge"], [69, "tuning-alpha-hyperparameter-of-ridge"], [80, "tuning-alpha-hyperparameter-of-ridge"]], "Tutorial 1": [[96, null]], "Tutorial 2": [[97, null]], "Tutorial 3": [[98, null]], "Tutorial 4": [[99, null]], "Tutorial 5": [[100, null]], "Tutorial 6": [[101, null]], "Tutorial 7": [[102, null]], "Tutorial this week: A more complicated dataset": [[30, "tutorial-this-week-a-more-complicated-dataset"]], "Two main hyperparameters": [[56, "two-main-hyperparameters"]], "Types and tokens": [[58, "types-and-tokens"]], "Types of censoring": [[31, "types-of-censoring"], [61, "types-of-censoring"], [90, "types-of-censoring"]], "Types of errors": [[14, "types-of-errors"], [34, "types-of-errors"], [73, "types-of-errors"]], "Types of machine learning": [[12, "types-of-machine-learning"], [25, "types-of-machine-learning"], [32, "types-of-machine-learning"], [46, "types-of-machine-learning"], [55, "types-of-machine-learning"], [71, "types-of-machine-learning"], [84, "types-of-machine-learning"]], "Types of problems involving time series": [[30, "types-of-problems-involving-time-series"], [51, "types-of-problems-involving-time-series"], [60, "types-of-problems-involving-time-series"], [89, "types-of-problems-involving-time-series"]], "Types of questions we might want to answer:": [[31, "types-of-questions-we-might-want-to-answer"], [61, "types-of-questions-we-might-want-to-answer"], [90, "types-of-questions-we-might-want-to-answer"]], "Typical steps to build a supervised machine learning model": [[63, "typical-steps-to-build-a-supervised-machine-learning-model"]], "UBC CPSC 330: Applied Machine Learning (2024W2)": [[1, null]], "Ubuntu Users": [[5, "ubuntu-users"]], "Underfitting": [[14, "underfitting"], [34, "underfitting"], [73, "underfitting"]], "Underfitting, overfitting, the fundamental trade-off, the golden rule [video]": [[14, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"], [34, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"], [73, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"]], "Undersampling": [[20, "undersampling"], [79, "undersampling"]], "Understanding the problem": [[92, "understanding-the-problem"]], "Unequally spaced time points": [[30, "unequally-spaced-time-points"], [51, "unequally-spaced-time-points"], [60, "unequally-spaced-time-points"], [89, "unequally-spaced-time-points"]], "Unsupervised learning": [[25, "unsupervised-learning"], [46, "unsupervised-learning"], [55, "unsupervised-learning"], [84, "unsupervised-learning"]], "Updates to assignments": [[7, "updates-to-assignments"]], "Use of AI in the course": [[103, "use-of-ai-in-the-course"]], "Use our template to create a repository": [[7, "use-our-template-to-create-a-repository"]], "Using OVR and OVO as wrappers": [[94, "using-ovr-and-ovo-as-wrappers"]], "Using SMOTE": [[20, "using-smote"], [79, "using-smote"]], "Using Silhouette scores to select the number of clusters": [[25, "using-silhouette-scores-to-select-the-number-of-clusters"], [46, "using-silhouette-scores-to-select-the-number-of-clusters"], [55, "using-silhouette-scores-to-select-the-number-of-clusters"], [84, "using-silhouette-scores-to-select-the-number-of-clusters"]], "Using multiple metrics in GridSearchCV or RandomizedSearchCV": [[21, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"], [42, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"], [69, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"], [80, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"]], "Using pre-trained models as feature extractor": [[29, "using-pre-trained-models-as-feature-extractor"], [50, "using-pre-trained-models-as-feature-extractor"], [59, "using-pre-trained-models-as-feature-extractor"], [88, "using-pre-trained-models-as-feature-extractor"]], "Using pre-trained models out-of-the-box": [[29, "using-pre-trained-models-out-of-the-box"], [50, "using-pre-trained-models-out-of-the-box"], [59, "using-pre-trained-models-out-of-the-box"], [88, "using-pre-trained-models-out-of-the-box"]], "Using regression metrics with scikit-learn": [[21, "using-regression-metrics-with-scikit-learn"], [42, "using-regression-metrics-with-scikit-learn"], [69, "using-regression-metrics-with-scikit-learn"], [80, "using-regression-metrics-with-scikit-learn"]], "Utility matrix": [[57, "utility-matrix"], [57, "id2"]], "Viewing the transformed data as a dataframe": [[17, "viewing-the-transformed-data-as-a-dataframe"], [37, "viewing-the-transformed-data-as-a-dataframe"], [76, "viewing-the-transformed-data-as-a-dataframe"]], "Virtual environment": [[10, "virtual-environment"]], "Visualization": [[9, "visualization"]], "Visualizing hierarchical clustering": [[56, "visualizing-hierarchical-clustering"]], "Visualizing the parameter grid as a heatmap": [[19, "visualizing-the-parameter-grid-as-a-heatmap"], [40, "visualizing-the-parameter-grid-as-a-heatmap"], [78, "visualizing-the-parameter-grid-as-a-heatmap"]], "Visualizing your results": [[91, "visualizing-your-results"]], "Warning": [[13, null], [33, null], [72, null]], "Warnings about feature selection": [[24, "warnings-about-feature-selection"], [24, "id8"], [45, "warnings-about-feature-selection"], [45, "id7"], [54, "warnings-about-feature-selection"], [83, "warnings-about-feature-selection"], [83, "id8"]], "Weaknesses": [[22, "weaknesses"], [43, "weaknesses"], [52, "weaknesses"], [81, "weaknesses"]], "Web app on a real server": [[92, "web-app-on-a-real-server"]], "Web app on local server": [[92, "web-app-on-local-server"]], "What all transformations we need to apply on the dataset?": [[16, "what-all-transformations-we-need-to-apply-on-the-dataset"], [75, "what-all-transformations-we-need-to-apply-on-the-dataset"]], "What and Why": [[10, "what-and-why"]], "What are git and GitHub?": [[5, null]], "What are the options?": [[16, "what-are-the-options"], [36, "what-are-the-options"], [75, "what-are-the-options"]], "What are we exactly learning?": [[18, "what-are-we-exactly-learning"], [39, "what-are-we-exactly-learning"], [77, "what-are-we-exactly-learning"]], "What can we do about it?": [[55, "what-can-we-do-about-it"]], "What can we do with these word vectors?": [[58, "what-can-we-do-with-these-word-vectors"]], "What did we cover?": [[27, "what-did-we-cover"], [48, "what-did-we-cover"], [57, "what-did-we-cover"], [86, "what-did-we-cover"], [92, "what-did-we-cover"]], "What did we learn today?": [[14, "what-did-we-learn-today"], [16, "what-did-we-learn-today"], [17, "what-did-we-learn-today"], [20, "what-did-we-learn-today"], [21, "what-did-we-learn-today"], [34, "what-did-we-learn-today"], [36, "what-did-we-learn-today"], [37, "what-did-we-learn-today"], [41, "what-did-we-learn-today"], [42, "what-did-we-learn-today"], [69, "what-did-we-learn-today"], [73, "what-did-we-learn-today"], [75, "what-did-we-learn-today"], [76, "what-did-we-learn-today"], [79, "what-did-we-learn-today"], [80, "what-did-we-learn-today"], [91, "what-did-we-learn-today"]], "What do we predict?": [[57, "what-do-we-predict"]], "What does this have to do with applied ML?": [[91, "what-does-this-have-to-do-with-applied-ml"]], "What does this mean for us, when we\u2019re trying to make claims about our data?": [[91, "what-does-this-mean-for-us-when-we-re-trying-to-make-claims-about-our-data"]], "What if we apply OHE?": [[17, "what-if-we-apply-ohe"], [37, "what-if-we-apply-ohe"], [76, "what-if-we-apply-ohe"]], "What is Natural Language Processing (NLP)?": [[28, "what-is-natural-language-processing-nlp"], [58, "what-is-natural-language-processing-nlp"], [58, "id1"], [58, "id2"], [87, "what-is-natural-language-processing-nlp"]], "What is Natural Language Processing (NLP)? (Video)": [[49, "what-is-natural-language-processing-nlp-video"]], "What is a recommender system?": [[27, "what-is-a-recommender-system"], [48, "what-is-a-recommender-system"], [57, "what-is-a-recommender-system"], [86, "what-is-a-recommender-system"]], "What is clustering?": [[25, "what-is-clustering"], [46, "what-is-clustering"], [55, "what-is-clustering"], [84, "what-is-clustering"]], "What is content-based filtering?": [[57, "what-is-content-based-filtering"]], "What is deployment?": [[92, "what-is-deployment"]], "What is feature engineering?": [[24, "what-is-feature-engineering"], [45, "what-is-feature-engineering"], [54, "what-is-feature-engineering"], [83, "what-is-feature-engineering"]], "What is feature selection?": [[24, "what-is-feature-selection"], [45, "what-is-feature-selection"], [54, "what-is-feature-selection"], [83, "what-is-feature-selection"]], "What is grid search?": [[91, "what-is-grid-search"]], "What is model interpretability?": [[23, "what-is-model-interpretability"], [44, "what-is-model-interpretability"], [53, "what-is-model-interpretability"], [82, "what-is-model-interpretability"]], "What is supervised machine learning (ML)?": [[12, "what-is-supervised-machine-learning-ml"], [32, "what-is-supervised-machine-learning-ml"], [71, "what-is-supervised-machine-learning-ml"]], "What is \u201cpositive\u201d and \u201cnegative\u201d?": [[20, "what-is-positive-and-negative"], [41, "what-is-positive-and-negative"], [68, "what-is-positive-and-negative"], [79, "what-is-positive-and-negative"]], "What kind of data we need to build recommendation systems?": [[57, "what-kind-of-data-we-need-to-build-recommendation-systems"]], "What kind of estimators can we combine?": [[22, "what-kind-of-estimators-can-we-combine"], [43, "what-kind-of-estimators-can-we-combine"], [52, "what-kind-of-estimators-can-we-combine"], [81, "what-kind-of-estimators-can-we-combine"]], "What next?": [[92, "what-next"]], "What should be the loss? (Activity: 4 mins)": [[91, "what-should-be-the-loss-activity-4-mins"]], "What to do with predictions?": [[57, "what-to-do-with-predictions"]], "What to look for in these plots?": [[25, "what-to-look-for-in-these-plots"], [46, "what-to-look-for-in-these-plots"], [55, "what-to-look-for-in-these-plots"], [84, "what-to-look-for-in-these-plots"]], "What transformations do we need to apply on the dataset?": [[36, "what-transformations-do-we-need-to-apply-on-the-dataset"]], "What would I do differently?": [[92, "what-would-i-do-differently"]], "What\u2019s the problem?": [[16, "what-s-the-problem"], [36, "what-s-the-problem"], [75, "what-s-the-problem"]], "When can we use broadcasting?": [[8, "when-can-we-use-broadcasting"]], "When experimenting, show the results asap": [[91, "when-experimenting-show-the-results-asap"]], "When is it OK to do things before splitting?": [[16, "when-is-it-ok-to-do-things-before-splitting"], [36, "when-is-it-ok-to-do-things-before-splitting"], [75, "when-is-it-ok-to-do-things-before-splitting"]], "When test score is much lower than CV score": [[19, "when-test-score-is-much-lower-than-cv-score"], [40, "when-test-score-is-much-lower-than-cv-score"], [78, "when-test-score-is-much-lower-than-cv-score"]], "When to stop?": [[55, "when-to-stop"]], "Which model is doing better in this scenario: SVC or Logistic Regression?": [[68, "which-model-is-doing-better-in-this-scenario-svc-or-logistic-regression"]], "Which model should I use?": [[22, "which-model-should-i-use"], [43, "which-model-should-i-use"], [52, "which-model-should-i-use"], [81, "which-model-should-i-use"]], "Which type of error is more important?": [[20, "which-type-of-error-is-more-important"], [41, "which-type-of-error-is-more-important"], [79, "which-type-of-error-is-more-important"]], "Which types of errors would be most critical for the bank to address?": [[68, "which-types-of-errors-would-be-most-critical-for-the-bank-to-address"]], "Why do we need a test set?": [[19, "why-do-we-need-a-test-set"], [40, "why-do-we-need-a-test-set"], [78, "why-do-we-need-a-test-set"]], "Why do we want this information?": [[23, "why-do-we-want-this-information"], [44, "why-do-we-want-this-information"], [53, "why-do-we-want-this-information"], [82, "why-do-we-want-this-information"]], "Why does it matter": [[34, "why-does-it-matter"]], "Why feature selection?": [[24, "why-feature-selection"], [45, "why-feature-selection"], [54, "why-feature-selection"], [83, "why-feature-selection"]], "Why is NLP hard?": [[58, "why-is-nlp-hard"]], "Why machine learning (ML)? [video]": [[12, "why-machine-learning-ml-video"], [32, "why-machine-learning-ml-video"], [71, "why-machine-learning-ml-video"]], "Why model transparency/interpretability?": [[23, "why-model-transparency-interpretability"], [44, "why-model-transparency-interpretability"], [53, "why-model-transparency-interpretability"], [82, "why-model-transparency-interpretability"]], "Why neural networks?": [[29, "why-neural-networks"], [29, "id1"], [50, "why-neural-networks"], [50, "id1"], [59, "why-neural-networks"], [59, "id1"], [88, "why-neural-networks"], [88, "id1"]], "Why not neural networks?": [[29, "why-not-neural-networks"], [50, "why-not-neural-networks"], [50, "id2"], [59, "why-not-neural-networks"], [59, "id2"], [88, "why-not-neural-networks"], [88, "id2"]], "Why should I use it?": [[91, "why-should-i-use-it"]], "Why should we care about effective communication?": [[91, "why-should-we-care-about-effective-communication"]], "Why should we care about recommendation systems?": [[27, "why-should-we-care-about-recommendation-systems"], [48, "why-should-we-care-about-recommendation-systems"], [57, "why-should-we-care-about-recommendation-systems"], [57, "id1"], [86, "why-should-we-care-about-recommendation-systems"]], "Why sparse matrices?": [[17, "why-sparse-matrices"], [37, "why-sparse-matrices"], [76, "why-sparse-matrices"]], "Why topic modeling?": [[58, "why-topic-modeling"]], "Windows": [[10, "windows"]], "Windows Users": [[5, "windows-users"]], "Word embeddings": [[28, "word-embeddings"], [49, "word-embeddings"], [58, "word-embeddings"], [87, "word-embeddings"]], "Word meaning": [[58, "word-meaning"]], "Word meaning: ML and Natural Language Processing (NLP) view": [[58, "word-meaning-ml-and-natural-language-processing-nlp-view"]], "Word representations: intro": [[58, "word-representations-intro"]], "Word segmentation": [[58, "word-segmentation"]], "Word similarity": [[58, "word-similarity"]], "Word tokenization": [[58, "word-tokenization"], [58, "id4"]], "Word vectors with spaCy": [[28, "word-vectors-with-spacy"], [49, "word-vectors-with-spacy"], [58, "word-vectors-with-spacy"], [87, "word-vectors-with-spacy"]], "Writing a traditional program to predict quiz2 grade": [[13, "writing-a-traditional-program-to-predict-quiz2-grade"], [33, "writing-a-traditional-program-to-predict-quiz2-grade"], [72, "writing-a-traditional-program-to-predict-quiz2-grade"]], "XGBoost": [[22, "xgboost"], [43, "xgboost"], [52, "xgboost"], [81, "xgboost"]], "[Optional] Jupyterlab and Python": [[10, "optional-jupyterlab-and-python"]], "[] notation": [[8, "notation"]], "announcements": [[15, "announcements"]], "average linkage": [[56, "average-linkage"]], "class_weight=\"balanced\"": [[20, "class-weight-balanced"], [41, "class-weight-balanced"], [79, "class-weight-balanced"]], "complete linkage": [[56, "complete-linkage"]], "cross_val_score": [[14, "cross-val-score"], [34, "cross-val-score"], [73, "cross-val-score"]], "cross_validate": [[14, "cross-validate"], [34, "cross-validate"], [73, "cross-validate"]], "fit and transform paradigm for transformers": [[16, "fit-and-transform-paradigm-for-transformers"], [36, "fit-and-transform-paradigm-for-transformers"], [75, "fit-and-transform-paradigm-for-transformers"]], "fit the classifier": [[13, "fit-the-classifier"], [33, "fit-the-classifier"], [72, "fit-the-classifier"]], "fit, predict , and score summary": [[13, "fit-predict-and-score-summary"], [33, "fit-predict-and-score-summary"], [72, "fit-predict-and-score-summary"]], "iClicker": [[53, "iclicker"], [103, "iclicker"]], "iClicker Exercise 10.1": [[21, "iclicker-exercise-10-1"], [42, "iclicker-exercise-10-1"], [80, "iclicker-exercise-10-1"]], "iClicker Exercise 10.2": [[21, "iclicker-exercise-10-2"], [42, "iclicker-exercise-10-2"], [80, "iclicker-exercise-10-2"]], "iClicker Exercise 12.0": [[43, "iclicker-exercise-12-0"], [52, "iclicker-exercise-12-0"], [81, "iclicker-exercise-12-0"]], "iClicker Exercise 12.1": [[22, "iclicker-exercise-12-1"], [43, "iclicker-exercise-12-1"], [52, "iclicker-exercise-12-1"], [81, "iclicker-exercise-12-1"]], "iClicker Exercise 14.1": [[45, "iclicker-exercise-14-1"], [54, "iclicker-exercise-14-1"], [83, "iclicker-exercise-14-1"]], "iClicker Exercise 14.1 https://join.iclicker.com/FUYI": [[24, "iclicker-exercise-14-1-https-join-iclicker-com-fuyi"]], "iClicker Exercise 19.1": [[50, "iclicker-exercise-19-1"], [59, "iclicker-exercise-19-1"], [88, "iclicker-exercise-19-1"]], "iClicker Exercise 19.1 https://join.iclicker.com/FUYI": [[29, "iclicker-exercise-19-1-https-join-iclicker-com-fuyi"]], "iClicker Exercise 2.1 Supervised vs unsupervised": [[33, "iclicker-exercise-2-1-supervised-vs-unsupervised"]], "iClicker Exercise 2.2 Classification vs regression": [[33, "iclicker-exercise-2-2-classification-vs-regression"]], "iClicker Exercise 2.2 Supervised vs unsupervised": [[13, "iclicker-exercise-2-2-supervised-vs-unsupervised"], [72, "iclicker-exercise-2-2-supervised-vs-unsupervised"]], "iClicker Exercise 2.3 Classification vs regression": [[13, "iclicker-exercise-2-3-classification-vs-regression"], [72, "iclicker-exercise-2-3-classification-vs-regression"]], "iClicker Exercise 2.4: Baselines and decision trees": [[33, "iclicker-exercise-2-4-baselines-and-decision-trees"]], "iClicker Exercise 2.5: Baselines and decision trees": [[13, "iclicker-exercise-2-5-baselines-and-decision-trees"], [72, "iclicker-exercise-2-5-baselines-and-decision-trees"]], "iClicker Exercise 3.1": [[14, "iclicker-exercise-3-1"], [34, "iclicker-exercise-3-1"], [73, "iclicker-exercise-3-1"]], "iClicker Exercise 3.2": [[14, "iclicker-exercise-3-2"], [34, "iclicker-exercise-3-2"], [73, "iclicker-exercise-3-2"]], "iClicker Exercise 9.1": [[20, "iclicker-exercise-9-1"], [41, "iclicker-exercise-9-1"], [79, "iclicker-exercise-9-1"]], "iClicker Exercise 9.2": [[20, "iclicker-exercise-9-2"], [41, "iclicker-exercise-9-2"], [79, "iclicker-exercise-9-2"]], "k-Nearest Neighbours (k-NNs) [video]": [[15, "k-nearest-neighbours-k-nns-video"], [35, "k-nearest-neighbours-k-nns-video"], [74, "k-nearest-neighbours-k-nns-video"]], "k-nearest neighbours imputation": [[27, "k-nearest-neighbours-imputation"], [48, "k-nearest-neighbours-imputation"], [57, "k-nearest-neighbours-imputation"], [86, "k-nearest-neighbours-imputation"]], "macOS": [[10, "macos"]], "n_iter": [[19, "n-iter"], [40, "n-iter"], [78, "n-iter"]], "n_jobs=-1": [[19, "n-jobs-1"], [40, "n-jobs-1"], [78, "n-jobs-1"]], "pandas_profiler": [[21, "pandas-profiler"], [42, "pandas-profiler"], [80, "pandas-profiler"]], "predict the target of given examples": [[13, "predict-the-target-of-given-examples"], [33, "predict-the-target-of-given-examples"], [72, "predict-the-target-of-given-examples"]], "predict_proba": [[18, "predict-proba"], [39, "predict-proba"], [77, "predict-proba"]], "random_state argument": [[14, "random-state-argument"], [34, "random-state-argument"], [73, "random-state-argument"]], "score your model": [[13, "score-your-model"], [33, "score-your-model"], [72, "score-your-model"]], "single linkage": [[56, "single-linkage"]], "sklearn API summary: estimators": [[16, "sklearn-api-summary-estimators"], [36, "sklearn-api-summary-estimators"], [75, "sklearn-api-summary-estimators"]], "sklearn API summary: transformers": [[16, "sklearn-api-summary-transformers"], [36, "sklearn-api-summary-transformers"], [75, "sklearn-api-summary-transformers"]], "sklearn set_config": [[17, "sklearn-set-config"], [37, "sklearn-set-config"], [76, "sklearn-set-config"]], "sklearn\u2019s ColumnTransformer": [[17, "sklearn-s-columntransformer"], [37, "sklearn-s-columntransformer"], [76, "sklearn-s-columntransformer"]], "sklearn\u2019s SimpleImputer": [[65, "sklearn-s-simpleimputer"]], "sklearn\u2019s feature_importances_ and permutation_importance": [[23, "sklearn-s-feature-importances-and-permutation-importance"], [44, "sklearn-s-feature-importances-and-permutation-importance"], [82, "sklearn-s-feature-importances-and-permutation-importance"]], "sklearn\u2019s feature_importances_ attribute vs permutation_importance": [[23, "sklearn-s-feature-importances-attribute-vs-permutation-importance"], [44, "sklearn-s-feature-importances-attribute-vs-permutation-importance"], [53, "sklearn-s-feature-importances-attribute-vs-permutation-importance"], [82, "sklearn-s-feature-importances-attribute-vs-permutation-importance"]], "spaCy": [[58, "spacy"], [93, "spacy"]], "test score vs. cross-validation score": [[14, "test-score-vs-cross-validation-score"], [34, "test-score-vs-cross-validation-score"], [73, "test-score-vs-cross-validation-score"]], "test_size, train_size arguments": [[14, "test-size-train-size-arguments"], [34, "test-size-train-size-arguments"], [73, "test-size-train-size-arguments"]], "ward linkage": [[56, "ward-linkage"]], "\u201cDeployment\u201d data": [[14, "deployment-data"], [34, "deployment-data"], [73, "deployment-data"]], "\u2753\u2753 Questions for group discussion": [[20, "questions-for-group-discussion"], [41, "questions-for-group-discussion"], [79, "questions-for-group-discussion"], [100, "questions-for-group-discussion"]], "\u2753\u2753 Questions for you": [[12, "questions-for-you"], [13, "questions-for-you"], [13, "id1"], [13, "id3"], [14, "questions-for-you"], [14, "id1"], [15, "questions-for-you"], [15, "id2"], [16, "questions-for-you"], [16, "id1"], [16, "id2"], [17, "questions-for-you"], [17, "id1"], [18, "questions-for-you"], [18, "id1"], [18, "id2"], [19, "questions-for-you"], [19, "id2"], [20, "questions-for-you"], [20, "id2"], [21, "questions-for-you"], [21, "id2"], [22, "questions-for-you"], [22, "id1"], [24, "questions-for-you"], [25, "questions-for-you"], [25, "id2"], [26, "questions-for-you"], [27, "questions-for-you"], [27, "id1"], [29, "questions-for-you"], [30, "questions-for-you"], [30, "id1"], [30, "id2"], [30, "id3"], [31, "questions-for-you"], [31, "id1"], [31, "id2"], [31, "id3"], [31, "id4"], [32, "questions-for-you"], [33, "questions-for-you"], [33, "id1"], [34, "questions-for-you"], [34, "id1"], [35, "questions-for-you"], [35, "id1"], [36, "questions-for-you"], [36, "id1"], [36, "id2"], [37, "questions-for-you"], [37, "id1"], [38, "questions-for-you"], [39, "questions-for-you"], [39, "id1"], [40, "questions-for-you"], [40, "id2"], [41, "questions-for-you"], [41, "id2"], [42, "questions-for-you"], [42, "id2"], [43, "questions-for-you"], [43, "id1"], [43, "id2"], [45, "questions-for-you"], [46, "questions-for-you"], [46, "id2"], [47, "questions-for-you"], [47, "id3"], [48, "questions-for-you"], [48, "id1"], [48, "id2"], [50, "questions-for-you"], [51, "questions-for-you"], [51, "id1"], [51, "id2"], [52, "questions-for-you"], [57, "questions-for-you"], [60, "questions-for-you"], [60, "id1"], [60, "id2"], [61, "questions-for-you"], [61, "id1"], [61, "id2"], [66, "questions-for-you"], [67, "questions-for-you"], [71, "questions-for-you"], [72, "questions-for-you"], [72, "id1"], [72, "id3"], [73, "questions-for-you"], [73, "id1"], [74, "questions-for-you"], [74, "id1"], [75, "questions-for-you"], [75, "id1"], [75, "id2"], [76, "questions-for-you"], [76, "id1"], [77, "questions-for-you"], [77, "id1"], [77, "id2"], [78, "questions-for-you"], [78, "id2"], [79, "questions-for-you"], [79, "id2"], [80, "questions-for-you"], [80, "id2"], [81, "questions-for-you"], [81, "id1"], [81, "id2"], [83, "questions-for-you"], [84, "questions-for-you"], [84, "id2"], [85, "questions-for-you"], [85, "id3"], [86, "questions-for-you"], [86, "id1"], [86, "id2"], [88, "questions-for-you"], [89, "questions-for-you"], [89, "id1"], [89, "id2"], [89, "id3"], [90, "questions-for-you"], [90, "id1"], [90, "id2"], [90, "id3"], [90, "id4"], [91, "questions-for-you"], [91, "id1"], [92, "questions-for-you"], [92, "id2"]], "\u2753\u2753 Questions for you https://join.iclicker.com/FUYI": [[26, "questions-for-you-https-join-iclicker-com-fuyi"], [27, "questions-for-you-https-join-iclicker-com-fuyi"]], "\ud83e\udd14 Eva\u2019s questions": [[12, "eva-s-questions"], [14, "eva-s-questions"], [32, "eva-s-questions"], [71, "eva-s-questions"], [73, "eva-s-questions"]]}, "docnames": ["LICENSE", "README", "docs/330_vs_340", "docs/README", "docs/asking_for_help", "docs/git_installation", "docs/grades", "docs/homework_instructions", "docs/python_notes", "docs/resources", "docs/setup", "learning-objectives", "lectures/201-Lecuyer-lectures/01_intro", "lectures/201-Lecuyer-lectures/02_terminology-decision-trees", "lectures/201-Lecuyer-lectures/03_ml-fundamentals", "lectures/201-Lecuyer-lectures/04_kNNs-SVM-RBF", "lectures/201-Lecuyer-lectures/05_preprocessing-pipelines", "lectures/201-Lecuyer-lectures/06_column-transformer-text-feats", "lectures/201-Lecuyer-lectures/07_linear-models", "lectures/201-Lecuyer-lectures/08_hyperparameter-optimization", "lectures/201-Lecuyer-lectures/09_classification-metrics", "lectures/201-Lecuyer-lectures/10_regression-metrics", "lectures/201-Lecuyer-lectures/12_ensembles", "lectures/201-Lecuyer-lectures/13_feat-importances", "lectures/201-Lecuyer-lectures/14_feature-engineering-selection", "lectures/201-Lecuyer-lectures/15_K-Means", "lectures/201-Lecuyer-lectures/16_DBSCAN-hierarchical", "lectures/201-Lecuyer-lectures/17_recommender-systems", "lectures/201-Lecuyer-lectures/18_natural-language-processing", "lectures/201-Lecuyer-lectures/19_intro_to_computer-vision", "lectures/201-Lecuyer-lectures/20_time-series", "lectures/201-Lecuyer-lectures/21_survival-analysis", "lectures/202-203-Giulia-lectures/01_intro", "lectures/202-203-Giulia-lectures/02_terminology-decision-trees", "lectures/202-203-Giulia-lectures/03_ml-fundamentals", "lectures/202-203-Giulia-lectures/04_kNNs-SVM-RBF", "lectures/202-203-Giulia-lectures/05_preprocessing-pipelines", "lectures/202-203-Giulia-lectures/06_column-transformer-text-feats", "lectures/202-203-Giulia-lectures/07_class-demo", "lectures/202-203-Giulia-lectures/07_linear-models", "lectures/202-203-Giulia-lectures/08_hyperparameter-optimization", "lectures/202-203-Giulia-lectures/09_classification-metrics", "lectures/202-203-Giulia-lectures/10_regression-metrics", "lectures/202-203-Giulia-lectures/12_ensembles", "lectures/202-203-Giulia-lectures/13_feat-importances", "lectures/202-203-Giulia-lectures/14_feature-engineering-selection", "lectures/202-203-Giulia-lectures/15_K-Means", "lectures/202-203-Giulia-lectures/16_DBSCAN-hierarchical", "lectures/202-203-Giulia-lectures/17_recommender-systems", "lectures/202-203-Giulia-lectures/18_natural-language-processing", "lectures/202-203-Giulia-lectures/19_intro_to_computer-vision", "lectures/202-203-Giulia-lectures/20_time-series", "lectures/204-Andy-lectures/12_ensembles", "lectures/204-Andy-lectures/13_feature_importance", "lectures/204-Andy-lectures/14_feature_selection", "lectures/204-Andy-lectures/15_clustering_intro_kmeans", "lectures/204-Andy-lectures/16_dbscan", "lectures/204-Andy-lectures/17_reccomender_systems", "lectures/204-Andy-lectures/18_intro_nlp", "lectures/204-Andy-lectures/19_intro_to_computer-vision", "lectures/204-Andy-lectures/20_time_series", "lectures/204-Andy-lectures/21_survival", "lectures/204-Andy-lectures/README", "lectures/204-Andy-lectures/class_demos/demo_03-ml-fundamentals", "lectures/204-Andy-lectures/class_demos/demo_04-kNNs-SVMs", "lectures/204-Andy-lectures/class_demos/demo_05-06-preprocessing", "lectures/204-Andy-lectures/class_demos/demo_07-linear-models_clean", "lectures/204-Andy-lectures/class_demos/demo_07-linear-models_filled", "lectures/204-Andy-lectures/class_demos/demo_09-classification-metrics", "lectures/204-Andy-lectures/class_demos/demo_10-regression-metrics", "lectures/204-Andy-lectures/class_demos/demo_15-kmeans", "lectures/notes/01_intro", "lectures/notes/02_terminology-decision-trees", "lectures/notes/03_ml-fundamentals", "lectures/notes/04_kNNs-SVM-RBF", "lectures/notes/05_preprocessing-pipelines", "lectures/notes/06_column-transformer-text-feats", "lectures/notes/07_linear-models", "lectures/notes/08_hyperparameter-optimization", "lectures/notes/09_classification-metrics", "lectures/notes/10_regression-metrics", "lectures/notes/12_ensembles", "lectures/notes/13_feat-importances", "lectures/notes/14_feature-engineering-selection", "lectures/notes/15_K-Means", "lectures/notes/16_DBSCAN-hierarchical", "lectures/notes/17_recommender-systems", "lectures/notes/18_natural-language-processing", "lectures/notes/19_intro_to_computer-vision", "lectures/notes/20_time-series", "lectures/notes/21_survival-analysis", "lectures/notes/22_communication", "lectures/notes/24_deployment-conclusion", "lectures/notes/appendixA_feature-engineering-text-data", "lectures/notes/appendixB_multiclass-strategies", "lectures/notes/final-exam-review-guiding-question", "lectures/tutorials/01_decision_boundaries", "lectures/tutorials/02_ML_fundamentals", "lectures/tutorials/03_Preprocessing", "lectures/tutorials/04_Hyperparameter_optimization", "lectures/tutorials/05_Classification_metrics", "lectures/tutorials/06_Ensembles", "lectures/tutorials/07_Time_series", "syllabus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["LICENSE.md", "README.md", "docs/330_vs_340.md", "docs/README.md", "docs/asking_for_help.md", "docs/git_installation.md", "docs/grades.md", "docs/homework_instructions.md", "docs/python_notes.ipynb", "docs/resources.md", "docs/setup.md", "learning-objectives.md", "lectures/201-Lecuyer-lectures/01_intro.ipynb", "lectures/201-Lecuyer-lectures/02_terminology-decision-trees.ipynb", "lectures/201-Lecuyer-lectures/03_ml-fundamentals.ipynb", "lectures/201-Lecuyer-lectures/04_kNNs-SVM-RBF.ipynb", "lectures/201-Lecuyer-lectures/05_preprocessing-pipelines.ipynb", "lectures/201-Lecuyer-lectures/06_column-transformer-text-feats.ipynb", "lectures/201-Lecuyer-lectures/07_linear-models.ipynb", "lectures/201-Lecuyer-lectures/08_hyperparameter-optimization.ipynb", "lectures/201-Lecuyer-lectures/09_classification-metrics.ipynb", "lectures/201-Lecuyer-lectures/10_regression-metrics.ipynb", "lectures/201-Lecuyer-lectures/12_ensembles.ipynb", "lectures/201-Lecuyer-lectures/13_feat-importances.ipynb", "lectures/201-Lecuyer-lectures/14_feature-engineering-selection.ipynb", "lectures/201-Lecuyer-lectures/15_K-Means.ipynb", "lectures/201-Lecuyer-lectures/16_DBSCAN-hierarchical.ipynb", "lectures/201-Lecuyer-lectures/17_recommender-systems.ipynb", "lectures/201-Lecuyer-lectures/18_natural-language-processing.ipynb", "lectures/201-Lecuyer-lectures/19_intro_to_computer-vision.ipynb", "lectures/201-Lecuyer-lectures/20_time-series.ipynb", "lectures/201-Lecuyer-lectures/21_survival-analysis.ipynb", "lectures/202-203-Giulia-lectures/01_intro.ipynb", "lectures/202-203-Giulia-lectures/02_terminology-decision-trees.ipynb", "lectures/202-203-Giulia-lectures/03_ml-fundamentals.ipynb", "lectures/202-203-Giulia-lectures/04_kNNs-SVM-RBF.ipynb", "lectures/202-203-Giulia-lectures/05_preprocessing-pipelines.ipynb", "lectures/202-203-Giulia-lectures/06_column-transformer-text-feats.ipynb", "lectures/202-203-Giulia-lectures/07_class-demo.ipynb", "lectures/202-203-Giulia-lectures/07_linear-models.ipynb", "lectures/202-203-Giulia-lectures/08_hyperparameter-optimization.ipynb", "lectures/202-203-Giulia-lectures/09_classification-metrics.ipynb", "lectures/202-203-Giulia-lectures/10_regression-metrics.ipynb", "lectures/202-203-Giulia-lectures/12_ensembles.ipynb", "lectures/202-203-Giulia-lectures/13_feat-importances.ipynb", "lectures/202-203-Giulia-lectures/14_feature-engineering-selection.ipynb", "lectures/202-203-Giulia-lectures/15_K-Means.ipynb", "lectures/202-203-Giulia-lectures/16_DBSCAN-hierarchical.ipynb", "lectures/202-203-Giulia-lectures/17_recommender-systems.ipynb", "lectures/202-203-Giulia-lectures/18_natural-language-processing.ipynb", "lectures/202-203-Giulia-lectures/19_intro_to_computer-vision.ipynb", "lectures/202-203-Giulia-lectures/20_time-series.ipynb", "lectures/204-Andy-lectures/12_ensembles.ipynb", "lectures/204-Andy-lectures/13_feature_importance.ipynb", "lectures/204-Andy-lectures/14_feature_selection.ipynb", "lectures/204-Andy-lectures/15_clustering_intro_kmeans.ipynb", "lectures/204-Andy-lectures/16_dbscan.ipynb", "lectures/204-Andy-lectures/17_reccomender_systems.ipynb", "lectures/204-Andy-lectures/18_intro_nlp.ipynb", "lectures/204-Andy-lectures/19_intro_to_computer-vision.ipynb", "lectures/204-Andy-lectures/20_time_series.ipynb", "lectures/204-Andy-lectures/21_survival.ipynb", "lectures/204-Andy-lectures/README.md", "lectures/204-Andy-lectures/class_demos/demo_03-ml-fundamentals.ipynb", "lectures/204-Andy-lectures/class_demos/demo_04-kNNs-SVMs.ipynb", "lectures/204-Andy-lectures/class_demos/demo_05-06-preprocessing.ipynb", "lectures/204-Andy-lectures/class_demos/demo_07-linear-models_clean.ipynb", "lectures/204-Andy-lectures/class_demos/demo_07-linear-models_filled.ipynb", "lectures/204-Andy-lectures/class_demos/demo_09-classification-metrics.ipynb", "lectures/204-Andy-lectures/class_demos/demo_10-regression-metrics.ipynb", "lectures/204-Andy-lectures/class_demos/demo_15-kmeans.ipynb", "lectures/notes/01_intro.ipynb", "lectures/notes/02_terminology-decision-trees.ipynb", "lectures/notes/03_ml-fundamentals.ipynb", "lectures/notes/04_kNNs-SVM-RBF.ipynb", "lectures/notes/05_preprocessing-pipelines.ipynb", "lectures/notes/06_column-transformer-text-feats.ipynb", "lectures/notes/07_linear-models.ipynb", "lectures/notes/08_hyperparameter-optimization.ipynb", "lectures/notes/09_classification-metrics.ipynb", "lectures/notes/10_regression-metrics.ipynb", "lectures/notes/12_ensembles.ipynb", "lectures/notes/13_feat-importances.ipynb", "lectures/notes/14_feature-engineering-selection.ipynb", "lectures/notes/15_K-Means.ipynb", "lectures/notes/16_DBSCAN-hierarchical.ipynb", "lectures/notes/17_recommender-systems.ipynb", "lectures/notes/18_natural-language-processing.ipynb", "lectures/notes/19_intro_to_computer-vision.ipynb", "lectures/notes/20_time-series.ipynb", "lectures/notes/21_survival-analysis.ipynb", "lectures/notes/22_communication.ipynb", "lectures/notes/24_deployment-conclusion.ipynb", "lectures/notes/appendixA_feature-engineering-text-data.ipynb", "lectures/notes/appendixB_multiclass-strategies.ipynb", "lectures/notes/final-exam-review-guiding-question.ipynb", "lectures/tutorials/01_decision_boundaries.ipynb", "lectures/tutorials/02_ML_fundamentals.ipynb", "lectures/tutorials/03_Preprocessing.ipynb", "lectures/tutorials/04_Hyperparameter_optimization.ipynb", "lectures/tutorials/05_Classification_metrics.ipynb", "lectures/tutorials/06_Ensembles.ipynb", "lectures/tutorials/07_Time_series.ipynb", "syllabus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 4, 5, 7, 8, 9, 10, 13, 18, 19, 22, 24, 25, 26, 27, 28, 29, 31, 33, 34, 38, 39, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 59, 60, 61, 63, 64, 66, 67, 69, 72, 77, 78, 81, 83, 84, 85, 86, 87, 88, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "0": [0, 1, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "00": [1, 12, 13, 15, 17, 18, 19, 20, 23, 26, 27, 29, 30, 31, 32, 37, 39, 40, 41, 44, 47, 48, 51, 53, 54, 56, 57, 60, 61, 63, 65, 67, 71, 72, 74, 76, 77, 78, 79, 82, 85, 86, 89, 90, 91, 102, 103], "000": [12, 14, 15, 16, 18, 19, 21, 22, 23, 28, 29, 31, 32, 34, 35, 36, 39, 40, 42, 43, 44, 49, 50, 52, 53, 58, 59, 61, 67, 69, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 87, 88, 90, 93], "0000": [16, 18, 20, 28, 36, 39, 41, 49, 58, 67, 75, 77, 79, 87, 93], "00000": [19, 30, 40, 67, 78, 89, 102], "000000": [13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 51, 52, 53, 54, 56, 57, 60, 61, 63, 64, 65, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 85, 86, 89, 90, 102], "00000000e": [23, 44, 53, 82], "000000e": [19, 40, 65, 78], "000001": [19, 21, 42, 80], "000004": 53, "000009": 19, "00000e": [15, 74], "000010": [19, 21, 42, 80], "000011": [20, 41, 79], "000012": 53, "000013": 53, "000015": 19, "000021": [16, 36, 75], "000025": 53, "000036": [20, 41, 79], "000051": 19, "000057": [16, 36, 75], "000065": [19, 78], "000067": 78, "000075": 19, "000077": 78, "000087": [19, 77], "000089": 77, "0001": [18, 20, 21, 31, 39, 41, 42, 61, 77, 79, 80, 90, 91], "000100": [16, 19, 21, 36, 40, 42, 75, 80], "000101": 18, "000102": 18, "000102e": 63, "000106": 40, "000108": 77, "000109": [19, 40], "000113": [20, 41, 79], "000114": 78, "000116": 18, "000117": [21, 42, 80], "000124": [39, 40], "000128": 64, "000130": 77, "000134": 39, "000136": 88, "000137": 78, "000140": 18, "000142": [18, 40], "000144": 64, "000145": 78, "000146": 77, "000147": 78, "000149": [16, 36, 64, 75], "000150": 77, "000151": 78, "000153": 18, "000154": 64, "000155": [16, 20, 36, 41, 75, 79], "000156": 64, "000159": 78, "000161": [19, 39], "000162": 64, "000163": [59, 64, 78], "000165": [19, 39], "000166": [18, 77, 78], "000167": 19, "000170": 39, "000171": [19, 21], "000173": 40, "000175": 64, "000177": [59, 75, 89], "000178": [19, 21], "000179": 64, "000180": 75, "000181": 78, "000182": 77, "000183": [19, 77], "000184": 21, "000186": 21, "000187": [19, 40, 64, 77], "000188": 75, "000190": [19, 89], "000191": [21, 40], "000192": [16, 89], "000193": [40, 50], "000194": [30, 77], "000195": 75, "000196": 18, "000197": [16, 39], "000198": [20, 41, 79], "000200": 40, "000201": 78, "000202": 30, "000203": [16, 19], "000206": 78, "000207": 39, "000208": [16, 36, 75], "000209": 21, "000210": 78, "000212": [21, 50, 83], "000213": 77, "000215": 40, "000218": [36, 77], "000220": 40, "000221": 80, "000222": 36, "000223": 42, "000225": 16, "000226": [42, 80], "000227": [20, 41, 42, 79], "000228": 36, "000229": 42, "000231": [42, 75], "000232": 88, "000233": [29, 50], "000234": [15, 19, 40, 74, 78], "000235": [20, 41, 42, 50, 64, 75, 79], "000236": 64, "000237": 21, "000238": 42, "000239": [18, 40], "000240": [18, 75], "000241": [36, 64], "000242": 29, "000245": [19, 40, 60, 78], "000247": [42, 88], "000248": [16, 60, 64], "000252": 59, "000255": 77, "000256": [18, 89], "000258": 29, "000259": 75, "000260": 75, "000261": [16, 60], "000262": 40, "000263": 21, "000265": [60, 64], "000267": [16, 30], "000270": 64, "000271": [30, 89], "000273": [29, 88], "000274": [50, 88], "000278": [18, 36], "000279": [36, 59], "000280": 18, "000281": [50, 64, 77], "000282": 19, "000283": 77, "000285": [30, 36, 77], "000286": [40, 78], "000287": 31, "000289": [16, 36, 75], "000294": 78, "000296": 64, "000302": 21, "000304": 16, "000306": 36, "000307": 40, "000309": 29, "000310": 64, "000312": [20, 41, 65, 79], "000313": [42, 64], "000316": 64, "000318": 18, "000321": 64, "000322": 21, "000326": 50, "000328": 64, "000329": [40, 64], "000332": [65, 80], "000336": [39, 88], "000337": [50, 59], "000338": [50, 59], "000339": [65, 78], "000341": 59, "000342": 36, "000348": 78, "000351": 18, "000353": [18, 40, 78], "000354": [19, 78], "000357": 21, "000358": 59, "000359": 29, "000360": 50, "000363": [50, 88], "000366": [20, 41, 79], "000368": 29, "000370": 78, "000371": 77, "000373": [42, 80], "000374": [24, 64], "000378": 77, "00038": [19, 40, 78], "000382": 60, "000384": 39, "000386": 39, "000387": 64, "000397": [18, 21, 42, 80], "000399": 88, "000402": 18, "000403": 45, "000405": [29, 59], "000411": 29, "000412": 18, "000415": [39, 65], "000416": 18, "000419": 39, "000420": 64, "000422": 29, "000423": 64, "000428": 64, "000432": [64, 65], "000433": 80, "000434": [14, 39], "000435": [14, 88], "000436": 59, "000437": 88, "000438": 14, "000439": 59, "000441": [14, 64], "000445": 14, "000448": 14, "000450": 65, "000451": 14, "000452": 75, "000456": 30, "000459": [14, 77], "000460": 64, "000463": 14, "000471": [14, 89], "000472": [21, 88], "000474": 21, "000475": 64, "000477": [21, 34], "000479": 30, "000480": [34, 64], "000489": 78, "000492": [20, 29, 41, 79], "000496": 34, "000498": 89, "0005": 91, "000500": 14, "000502": [34, 36], "000503": [15, 19, 21, 40, 78], "000507": 65, "000508": [19, 40, 78], "000511": [14, 29], "000512": 59, "000517": 60, "000520": [64, 80], "000524": 14, "000526": 29, "000528": 15, "000531": 21, "000533": 21, "000534": 34, "000536": 59, "000540": 64, "000542": [50, 64], "000545": 15, "000546": 60, "000548": 15, "000549": 15, "000551": 34, "000556": 65, "000558": [34, 65], "000561": [15, 64], "000567": 21, "000570": 20, "000573": 60, "000575": 89, "000579": 67, "00058": [19, 40, 78], "000580": 74, "000582": 42, "000586": 21, "000587": 16, "000590": [21, 39], "000598": 60, "000602": 15, "000607": 15, "000608": 42, "000609": 67, "000610": [34, 39, 50], "000612": 15, "000616": 42, "000619": 67, "000623": 42, "000625": 15, "000626": 14, "000629": 42, "000630": [20, 41, 79], "000633": [42, 74], "000636": 14, "000637": [14, 88], "000639": 14, "000640": 15, "000642": 14, "000644": 14, "000645": 64, "000646": 14, "000647": 74, "000650": 74, "000651": [42, 74], "000652": [14, 80], "000654": [42, 67], "000655": [14, 74], "000657": 14, "000661": 74, "000664": 14, "000666": 15, "000671": 74, "000675": [14, 35], "000678": 78, "000683": 15, "000685": 64, "000686": 14, "000691": 34, "000696": 34, "000697": 15, "000700": 35, "000701": [15, 34], "000707": 34, "000710": 35, "000711": 34, "000712": 34, "000713": [64, 80], "000714": 35, "000720": 34, "000722": 14, "000723": 19, "000726": [20, 41, 79], "000727": 67, "000728": 35, "000736": 35, "000737": 89, "000739": 35, "000740": 64, "000742": 15, "000744": 29, "000746": 15, "000747": [40, 78], "000748": 75, "000752": [15, 54, 74], "000757": 14, "000758": 88, "000761": 30, "000765": 75, "000768": 59, "000774": [54, 75], "000786": [20, 41, 79], "000787": 74, "000789": [40, 65], "00079": [19, 40, 78], "000794": 74, "000795": 74, "000796": 50, "000797": 74, "000800": 14, "000803": 80, "000805": [15, 60], "000812": [14, 64], "000815": 15, "000816": 34, "000820": 15, "000823": 34, "000829": [64, 74], "000831": 74, "000832": 80, "000839": [34, 35, 64], "000842": 15, "000848": 21, "000851": [35, 50], "000867": 75, "000868": 54, "000869": 89, "000870": 34, "000873": 74, "000875": 19, "000878": 40, "000881": 36, "000889": 74, "000890": 64, "000891": [20, 41, 79], "000894": 36, "000902": 16, "000917": [19, 40, 78], "000925": 21, "000927": [20, 41, 79], "000934": 64, "000935": 59, "000936": 74, "000939": 30, "000944": 15, "000945": 83, "000950": 35, "000952": 36, "000954": 54, "000956": 29, "000960": 88, "000964": 83, "000967": 35, "000969": 35, "000975": [14, 29], "000976": [19, 40, 78], "000977": 74, "000982": [19, 40, 78], "000989": 67, "000997": 16, "001": [12, 14, 15, 16, 18, 19, 21, 22, 23, 29, 31, 32, 35, 36, 39, 40, 42, 43, 44, 50, 52, 53, 59, 61, 67, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 88, 90, 91, 93], "0010": [18, 39, 77], "00100": [19, 78], "001000": [19, 21, 40, 42, 78, 80], "001002": 73, "001003": [51, 67], "001006": 73, "001009": 51, "001010": [51, 67, 73], "001011": [14, 74, 80], "001014": [16, 73], "001016": 73, "001017": 73, "001021": 14, "001026": 73, "001027": 73, "001029": 73, "001031": 67, "001034": 29, "001038": 73, "001040": 79, "001043": 75, "001057": [73, 78], "001060": [16, 36, 75], "001063": 73, "001064": 88, "001068": [23, 44, 53, 82], "001070": 59, "001071": 73, "001078": 73, "001079": 36, "001082": 34, "001084": 39, "001086": 73, "001087": 83, "001091": 42, "001097": 40, "001103": 73, "001109": 64, "001111": 73, "001113": 34, "001116": 35, "001126": 35, "001139": 74, "001144": 14, "001145": 15, "001146": 35, "001149": 73, "001155": 83, "001162": [19, 40, 78, 83], "001166": 40, "001171": 19, "001174": 73, "001178": 64, "001179": 15, "001188": 19, "001195": 24, "001200": 16, "001201": 24, "001204": 15, "001205": [20, 41, 79], "001220": 77, "001224": 74, "001226": 88, "001230": 64, "001236": 78, "001237": 59, "001239": [20, 41, 54, 79], "001253": 24, "001256": 29, "001260": 15, "001266": [21, 42, 80], "001271": 15, "001272": 16, "001274": 24, "001279": 83, "001282": [15, 21], "001283": 39, "001286": [20, 41, 79], "001294": 73, "001299": [41, 73], "001302": 35, "001305": 73, "001307": 73, "001314": 29, "001315": 73, "001317": 73, "001321": 59, "001322": 73, "001323": 73, "001325": 74, "001329": 73, "001334": 45, "001337": 73, "001338": [35, 45, 77], "001344": 15, "001345": 45, "001347": 78, "001352": 73, "001361": 77, "001362": 77, "001363": 42, "001365": 74, "001371": 76, "001372": 40, "001375": [29, 64], "001383": [40, 45], "001389": 24, "001390": 73, "001391": 73, "001392": 74, "001395": 21, "001400": 76, "001406": 80, "001407": 73, "001412": 78, "001414": 74, "001416": 15, "001419": 64, "001422": [42, 80], "001423": 78, "001429": 73, "001433": 80, "001439": 67, "001441": 73, "001448": 76, "001453": 73, "00146": 78, "001466": 76, "001467": 78, "001492": 78, "001495": 74, "001501": 21, "001506": 51, "001509": 54, "001511": 64, "001519": 15, "001521": 35, "001541": 35, "001563": 76, "001566": [64, 80], "001580": 35, "001585": 78, "001586": [21, 74], "001591": 76, "001594": [19, 40, 78], "001595": 74, "001600": 74, "001604": [54, 76], "001606": 76, "001608": 78, "001611": 29, "001616": 78, "001620": 78, "001629": 78, "001635": 54, "001641": 88, "001645": 77, "001647": 76, "001660": 29, "001661": 21, "001676": 50, "001679": 78, "001682": 78, "001687": [45, 64], "001691": 21, "001693": 83, "001699": 73, "0017": [20, 41, 79], "001700": [20, 41, 79], "001703": 19, "001710": 77, "001715": 76, "001730": 15, "001740": [18, 21, 42, 80], "001748": 50, "001759": 59, "001762": 18, "001769": 78, "001773": 74, "001776": 73, "001790": 80, "001792": [19, 40, 78], "001793": 50, "001794": 19, "001799": 19, "001800": 19, "001803": 19, "001805": 15, "001807": [15, 59], "001819": 21, "001834": 54, "001836": 15, "001843": 54, "001847": 83, "001848": 19, "001850": 77, "001873": 15, "001877": 74, "001882": 64, "001883": 17, "001885": 19, "001888": 35, "001894": 80, "001900": 74, "001906": 21, "001920": 76, "001922": 76, "001929": 17, "001933": [42, 80], "001938": 19, "001943": 50, "001949": [50, 83], "001952": 74, "001957": 19, "001960": 17, "001962787": 58, "0019627884": 28, "0019627889": [49, 87], "001968": 73, "001985": 19, "001994": 83, "001997": 51, "002": [14, 18, 22, 23, 28, 31, 39, 43, 44, 49, 52, 58, 61, 73, 77, 81, 82, 87, 90], "002003": 78, "002011": 51, "002017": 45, "002021": 37, "002022": 76, "002030": 74, "002035": 37, "002045": 78, "002057": [16, 36, 75, 76], "002059": 37, "002069": 37, "002070": 37, "002073": 21, "002077": 40, "002082": 19, "002083": 74, "002088": 17, "002092": 17, "002096": 88, "002102": 40, "002105": [19, 40, 78], "002108": 24, "002114": 18, "002116": 76, "002118": 74, "002120": 40, "002121": 18, "002123": 78, "002124": 19, "002137": 39, "002143": 73, "002146": 78, "002147": 40, "002151": 40, "002158": 83, "002159": 78, "002169": 19, "002181": 29, "002189": 17, "002197": [40, 78], "002200": 50, "002218": 17, "002221": 80, "002224": 35, "002225": 35, "002226": 24, "002231": 17, "002238": 17, "00224": 19, "002251": 15, "002268": 40, "002272": 17, "002274": 39, "002283": 19, "002292": 39, "002294": 21, "002313": 29, "002317": 37, "002321": [64, 77], "00234": 78, "002351": 17, "002353": 24, "002355": 83, "002359": 24, "002367": 37, "002372": 59, "002376": 40, "002384": 19, "002385": 80, "002388": 40, "002397": 24, "002402": 50, "002409": 59, "002410": 54, "002411": 24, "002418": 64, "002425": 19, "002441": 83, "002459": 40, "002460": 88, "002477": [39, 64], "002478": 37, "002479": 29, "002481": 18, "002499": 19, "002512": 37, "002516": 35, "002523": 59, "002525": 88, "002535": 45, "002542": 40, "002544": 50, "002549": 37, "002561": [19, 40, 78], "002564": 37, "002571": 37, "002618": 39, "002643": 64, "002646": 83, "002654": 19, "002664": 83, "002675": 78, "002682": 88, "002690": [16, 36, 75], "002692": 78, "002701": 24, "002703": 18, "002704": [24, 78], "002711": 88, "002716": 35, "002720": 35, "002730": 24, "002736": 20, "002741": 19, "002742": 54, "002746": 80, "002748": 19, "002761": 18, "002769": 24, "002783": 78, "002788": 76, "002789": 76, "002792": 19, "002802": 64, "002807": 76, "002814": 36, "002818": 17, "002835": [50, 78], "002842": 17, "002844": 24, "002845": 37, "002847": 45, "002848": 64, "002858": 76, "00286": 19, "002867": 83, "002871": 19, "002873": 24, "002877": 19, "002878": 24, "002881": 19, "002886": 45, "002889": [20, 41, 79], "0029": [31, 61, 90], "002902": 17, "002910": 76, "002912": 45, "002921": 64, "002928": 16, "002929": [19, 40], "002931": 19, "002934": [45, 77], "002935": 19, "002940": 88, "002946": 45, "002948": 74, "002949": 35, "002952": 30, "002962": 88, "002965": 64, "002968": 54, "002974": [19, 39], "002975": 40, "002976": 19, "002986": 88, "002987": 64, "002996": 24, "002999": 78, "003": [22, 31, 40, 43, 52, 78, 81], "003003": 45, "003013": 76, "003014": 78, "003015": [37, 78], "003021": 19, "003026": 18, "003027": [19, 78], "003029": 59, "003037": 24, "003038": [64, 78], "003044": 64, "003046": 40, "003052": 16, "003066": 16, "003068": 21, "003083": 78, "003086": 76, "003088": 64, "003098": 45, "003103": 18, "003106": 16, "003113": 16, "003115": 76, "003124": [19, 42, 80], "003125": 19, "003127": 21, "003133": [21, 42, 80], "003139": 45, "003146": 76, "003148": 77, "003149": 29, "003151": 51, "003153": 45, "003165": 39, "003166": [75, 83], "003170": 19, "003181": 75, "003183": 83, "003185": [31, 61, 90], "003186": 76, "003188": [75, 76], "003189": 50, "003192": 19, "003193": 45, "003194": [18, 39, 77], "003195": 45, "003196": 54, "003199": 40, "003210": 64, "003212": 75, "003215": 54, "003218": 35, "003221": 54, "003224": 35, "003227": 29, "003228": 40, "003232": 17, "003237": 21, "003242": 88, "003247": 54, "003249": 19, "003257": 88, "00326": 19, "00327": 40, "003272": 64, "003273": 73, "003278": 54, "003283": 88, "003284": 35, "003288": [42, 80], "003292": 24, "003294": 45, "003300": [16, 36, 75], "003303": 19, "003316": 36, "003318": 29, "00332": 78, "003324": 75, "003326": 54, "003361": 41, "003363": 59, "003365": [54, 76], "003376": 50, "003388": 36, "003401": 83, "003415": 29, "003421": 78, "003422": 50, "003423": 83, "003427": 83, "003433": 54, "003442": 36, "003444": 21, "003457": 21, "003463": 64, "003468": 19, "003472": 78, "003477": 88, "003479": [36, 39, 78], "003483": 78, "003489": 54, "003493": 83, "003507": 17, "003519": 37, "003528": 78, "003529": 78, "003540": 64, "003547": [21, 40, 42, 80], "003561": [14, 34], "003563": 78, "003565": 37, "003569": 40, "003586": 37, "003593": 64, "003600": 45, "003601": 19, "003606": 29, "003609": 59, "003616": 40, "003628": 19, "003629": 19, "003633": 78, "003647": 88, "003650": 40, "003652": 39, "003663": 64, "003665": [17, 19], "003666": [17, 36], "003669": 40, "003680": 40, "003681": [23, 44], "003685": 19, "003687": 19, "00369": 78, "003693": 19, "003694": 29, "003710": 50, "003715": 19, "003717": 51, "003733": 40, "003736": [37, 54, 59], "003739": 19, "003748": 78, "003749": 17, "003757": 78, "003758": 19, "003764": 54, "003769": 54, "003784": 45, "003785": [21, 42, 64, 80], "003814": 19, "003820": 37, "00384": 19, "00385": 19, "003865": 50, "003877": 64, "003885": 78, "003887": 40, "003894": 19, "003898": 35, "003902": 17, "003904": [37, 40], "003906": 59, "003910": 64, "003913": 17, "003919": [19, 40, 64, 78], "003919287722401839": [19, 40, 78], "00392157": 88, "003923": 76, "003924": 83, "003933": 78, "003936": 17, "003949": 37, "003951": 17, "003952": 50, "00396": 19, "003968": 17, "003978": 19, "003979": 19, "003998": 78, "004": [15, 19, 22, 23, 29, 40, 43, 44, 50, 52, 53, 59, 61, 74, 78, 81, 82, 88], "004001": 59, "004008": 19, "004057": 78, "004065": [30, 51, 60, 89], "004081": 17, "004082": [30, 50, 51, 60, 89], "004086": 54, "004102": 54, "004121": [42, 80], "004143": 80, "004175": 54, "004203": 37, "004220": 21, "004221": 40, "004225": 40, "004251": 19, "004259": 50, "004262": 37, "004264": [14, 34, 73], "004293": 78, "004301": 40, "004305": 78, "004337": [19, 40, 78], "004338": 19, "004345": 40, "00435173": [25, 46, 84], "004352": [25, 46, 84], "004358": 37, "004373": 17, "004385": 50, "004386": 40, "004388": 40, "004398": [40, 82], "004402": 78, "004424": 59, "004438": 18, "004447": 19, "004461": 64, "004462": [35, 59], "004466": 78, "004469": 64, "004496": 78, "004521": 80, "004529": 82, "004533": 19, "004556": 78, "004574": 80, "004585": [19, 40], "004594": 64, "004602": [42, 80], "004607": 40, "00461": 78, "00462": 19, "004653": 40, "004660": 24, "004665": 39, "004685": 40, "004696": 21, "004713": 17, "004714": 78, "004723": 82, "004727": 40, "004745": 37, "004761": 82, "004769": [14, 34], "004770": [16, 36, 75], "004798": 29, "004801": [16, 36, 75, 76], "004807": 76, "004816": 40, "004826": 80, "004829": [42, 80], "004848": 16, "004852": 64, "004854": 80, "004862": 21, "00488": 40, "004884": 88, "004892": 29, "004899": 19, "004919": 78, "004934": 79, "004952": 78, "004959": 78, "00496": 78, "004961": 40, "004963": 19, "004964": 17, "004965": 19, "004972": 54, "004996": 21, "005": [12, 22, 23, 31, 32, 43, 44, 52, 53, 61, 71, 81, 82, 90, 91], "005004": 21, "005012": 21, "005023": 54, "005041": 21, "005067": 75, "005071": 37, "005074": 88, "005078": 21, "005093": [29, 50, 75], "005098": [42, 80], "005102": 21, "005103": 16, "005114": [42, 80], "005126": 78, "005136": 63, "005149": 19, "005151": [19, 40, 78], "005157": 75, "005161": 21, "005167": 80, "005191": 16, "005196": 78, "005204": [16, 24], "005205": 59, "005208": 40, "005241": [42, 80], "005247": 40, "00525962": [16, 36, 75], "005269": [21, 80], "005270": 64, "005273": 24, "005288": 76, "005290": 16, "005309": 35, "005313": 35, "005335": 78, "005336": [42, 80], "005373": 36, "005377": 36, "005387": [20, 41, 79], "005388": 40, "005398": 36, "005423": 78, "005425": 40, "005426": [19, 40, 78], "00543825": [16, 36, 75], "005440": 88, "005443": 35, "005478": 82, "00548": 78, "005508": 37, "005520": 40, "005525": 67, "005538": [42, 80], "005562": 19, "005563": 34, "005574": 21, "005579": 80, "005590": 54, "005593": 35, "005597": 40, "005608": 17, "005616": 19, "005622": [36, 45], "005625": 21, "005641": [42, 80], "005674": [42, 80], "005699": [14, 34, 73], "005708": 78, "005716": 40, "005725": 50, "00573": [19, 40, 78], "005734": 78, "005735": 78, "005736": 19, "005758": 19, "005767": 78, "005799": 19, "005809": [30, 51, 60, 89], "005815": 40, "005817": 19, "005834": 78, "005836": 75, "005837": 19, "005862": 19, "005868": 37, "005883": [19, 40], "005888": [16, 36, 75], "005898": 59, "005911": 21, "005934": 42, "005944": 45, "005967": 19, "006": [22, 23, 43, 44, 52, 53, 81, 82, 90], "006011": 19, "006012": 78, "006046": 80, "006055": 78, "006067": [42, 80], "006068": 54, "006070": 64, "006073": 59, "006086": 19, "006104": 19, "006106": [67, 78], "006110": [15, 19, 40, 42, 74, 78, 80], "006118": 21, "006125": 19, "006195": 21, "006200": 21, "006208": 64, "006236": [42, 64, 80], "006244": 78, "006246": 19, "006250": 64, "006262": 19, "006275": 21, "006282": 19, "006321": 23, "006382": 59, "006434": 21, "006435": 78, "006438": 39, "00644254": 67, "006452": [18, 39, 77], "006455": 40, "006465": 35, "006476": 80, "006505": 88, "006522": 40, "006526": 21, "006531": [14, 34, 73], "006536": 19, "006545": [19, 40, 78], "006546893270012566": [18, 39, 77], "006553": 23, "006557": [18, 39, 77], "006570": 36, "006578": [16, 36, 75, 76], "006636": 59, "006649": 35, "006652": 78, "006661": 59, "006667": [64, 78], "00667": 78, "00671": 40, "006734": 40, "006737": 37, "006744": [21, 42, 80], "00676": 40, "006770": 64, "006778": 19, "006801": 21, "006805": [14, 34, 73], "006843": 23, "006861": 78, "006875": 20, "006889": 19, "006904": 78, "006905": 40, "006909": 19, "00691": 78, "006917": 42, "006973": 75, "006981": 21, "006991": 17, "007": [22, 36, 43, 52, 61, 67, 75, 81, 82, 90, 93], "007023": 44, "007064": 19, "007068": 83, "007074": 39, "007096": 44, "007100": 23, "007116": 37, "007119": 40, "00715": 78, "007194": 40, "00720988e": [23, 44, 53, 82], "007228": [42, 80], "007236": 40, "007263": 40, "007269": 21, "007291": 76, "007299": 23, "007316": [14, 34, 73], "007333": 53, "007361": 79, "007362": 78, "007379": 50, "007424": 21, "007434": [23, 44, 82], "007458": [16, 36, 75, 76], "007465": 19, "00746667": [28, 49, 58], "007482": 40, "007511": 21, "007515": 53, "007517": [42, 80], "007542": 63, "007544": 78, "007563": 78, "007587": 44, "007588": [25, 46, 84], "00758803": [25, 46, 84], "00759438": [23, 44, 53, 82], "007655": 78, "007666": [20, 41, 79], "00767": 78, "007689": 40, "007714": 44, "007717": 53, "007737": 80, "007776": [42, 80], "007785": 20, "007794": 65, "007818": 78, "007867": 19, "007911": 40, "007926": 35, "007938": [14, 73], "007986": [42, 80], "008": [16, 22, 31, 81, 82, 93], "008040": [30, 89], "008112": 20, "008120": [42, 80], "008147": 41, "008150": 44, "008153": 78, "008167": [16, 36, 75, 76], "008222": 40, "008259": 53, "008286": 64, "00830586": [17, 37, 76], "008306": [17, 37, 76], "008322e": [61, 90], "008333": 76, "008342": 19, "008346": [42, 80], "008355": 20, "008377": 78, "008408": 21, "008425": 21, "008426": 21, "008455": 19, "008472": [42, 80], "008498": 64, "008565": 20, "008577": 88, "008581": 80, "008589": 20, "008606": [42, 80], "008617": [42, 80], "008661": 40, "008667": [19, 40, 78], "00871": 78, "008735": [15, 35, 74], "008780": 21, "008783": 40, "008785": [42, 80], "008933": 21, "008936": 40, "008962": 19, "008975": 31, "009": [22, 23, 43, 76, 81, 90], "009006": 20, "009014": 40, "009059": [14, 34, 73], "009063": [19, 40, 78], "009082": 78, "009090": [42, 80], "009131": 64, "009132": 78, "009140": [42, 80], "009198": 21, "009260": 34, "009294": 40, "009297": 78, "009305": 78, "009326": 53, "009331": 19, "009339": [42, 80], "009397": 21, "009422": [14, 73], "009441": 21, "009491": 21, "009512": 78, "009514e": [21, 42, 80], "00952": 19, "009573": [22, 43], "009605": 40, "009655": 40, "009664": [42, 80], "009668": 19, "009692": 88, "009703": 64, "009710": 19, "009724": 83, "009786": 29, "009853": 19, "009932": 21, "009940": 24, "009952": 24, "009963": 40, "00pm": 1, "01": [15, 16, 18, 19, 20, 21, 23, 29, 30, 31, 35, 36, 39, 40, 41, 42, 44, 50, 51, 53, 59, 60, 61, 65, 69, 74, 75, 77, 78, 79, 80, 82, 88, 89, 90, 91, 94, 102, 103], "010": [12, 18, 19, 22, 32, 39, 40, 43, 44, 53, 67, 71, 77, 78, 90, 93], "0100": [18, 39, 77], "01000": [19, 40, 78], "010000": [16, 19, 21, 36, 40, 42, 75, 78, 80], "010027": [18, 39, 77], "010065": 40, "010183": [16, 36, 75, 76], "010191": 24, "0102": [15, 19, 40, 74, 78], "010205": 40, "010208": 83, "010294": [14, 34, 73], "010340": 20, "010344": 40, "010456": 45, "010463": 19, "010547": 34, "010595": 45, "010643": 45, "010650": [14, 34, 73], "010673": 40, "010679": [14, 73], "010681": 40, "010688": 83, "010715": [19, 40, 78], "010741": 24, "010750": 83, "010824": 20, "010920": 24, "010954": 24, "010955": 40, "011": [12, 23, 29, 31, 32, 50, 52, 59, 71, 76, 88, 90], "011036": 40, "01109": 40, "011110": 21, "011193": 59, "011194": 45, "011210": 83, "011234": [20, 41, 79], "011246": 24, "011248": [42, 80], "011252": 83, "011269e": [21, 42, 80], "011281": 40, "011287": 83, "011316": 24, "011332": [31, 61, 90], "011336": [15, 35, 74], "011363": 21, "011379": 24, "011415": 64, "011440": [42, 80], "011471": 45, "011504": 21, "011617": 78, "011678": [20, 41, 79], "011767": [21, 42, 80], "011773": 81, "011993": 45, "012": [16, 29, 36, 43, 50, 52, 59, 61, 75, 76, 81, 82, 88, 90, 93], "012019": [34, 73], "012030": 83, "012065": 14, "012100": 45, "012232": [42, 80], "012240": 83, "012247": 64, "012252": 78, "012300": 19, "012308": 45, "012385": 45, "012472": 24, "012584": 54, "012616": [19, 40, 78], "012624": [42, 80], "012707": 79, "012758": [42, 80], "012788": 42, "012841": 19, "012858": 42, "012912": 54, "012924": 42, "012995": 40, "013": [16, 22, 44], "013004": 19, "013031": [42, 80], "01311996044": 42, "01311996051": 21, "01311996071": 80, "013120": [23, 53, 82], "013143": 19, "013157": 78, "013161": [19, 40, 78], "013189": 42, "013244": 40, "013303": 40, "01336": 19, "013433": [15, 35, 74], "013462": 54, "013504": 54, "013567": 40, "013622": 19, "013628": 19, "013629": 78, "013672": 54, "013706928443177698": [19, 40, 78], "013707": [19, 40, 78], "013726": 40, "013863": 78, "013888": 78, "014": [16, 23, 31, 36, 43, 44, 52, 61, 73, 75, 81, 82, 90], "014030": [42, 80], "014081e": [21, 42, 80], "01409912": [28, 49, 58, 87], "0141": 40, "014227": 54, "014284": 19, "014305": [42, 80], "014306": 19, "014321": 40, "01432486e": [23, 44, 53, 82], "014337": 64, "014339": 19, "014462": 50, "014481": 78, "014503": 78, "014581": 19, "014638": 40, "014650": [61, 90], "014696": 19, "014730": 76, "01473536": [15, 35, 74], "014758": [61, 90], "014891": 40, "014906": 19, "014957": 19, "014958": 19, "014990": 64, "014992": 19, "015": [12, 16, 22, 31, 32, 36, 71, 75, 76, 81, 90, 93], "015003": 78, "015026": 19, "015039": [20, 41, 79], "015056": 78, "015165": [42, 80], "015372": 78, "015383": 54, "015541": 54, "015580": [23, 44], "015639": 64, "015708": 40, "015724": 83, "015755": 78, "015764": 19, "015783": 19, "015794": 42, "015819": 78, "015825": 19, "015861": 40, "015864": 19, "015917": 19, "015954": 19, "015966": 41, "016": [22, 52], "01612": 19, "016138": 40, "016238": 19, "016263": 78, "016325": 19, "016330": 64, "016356": 41, "016372": 78, "016417": 50, "016459": 40, "016469": 40, "01647": [19, 40, 78], "016525": [21, 23, 42, 44, 53, 80, 82, 91], "016555": [18, 39, 77], "016566": 19, "016575": 19, "016587": [20, 41, 79], "016598": 78, "016602": 78, "016607": 78, "016660": 65, "016676": [25, 46, 55, 84], "016688": [16, 24, 36, 45, 75, 83], "016693": [42, 80], "016751": 19, "016764": 19, "016765": 19, "0168": 40, "016807": [18, 39, 77], "016814": 19, "016815": 78, "016918": [20, 41, 79], "016944": [15, 35, 74], "016945": 40, "017": [29, 43, 44, 50, 59, 76, 88], "017034": 45, "017054": 40, "017068": 40, "017074": 40, "017134": 19, "017185": 78, "017226": [42, 80], "017273": 59, "017308": 78, "017425": 19, "017427": 78, "017455": 20, "017561": 40, "017610": 82, "017655": 19, "017696": 82, "017737": 82, "017741": 82, "017795": 64, "017829": [30, 89, 102], "017837": 78, "01784": 78, "017878": 40, "017927": 78, "017951": 64, "017959e": [21, 42, 80], "017972": [16, 36, 75], "018": [52, 53, 81], "018014": 82, "018022": 40, "018046": 79, "018077": 78, "018137": 40, "018178": [15, 35, 74], "018243": 78, "018246": 19, "018267": 54, "01831": 40, "018310": [15, 35, 74], "018434": [30, 89, 102], "018439": 42, "018456": 40, "018459e": [21, 42, 80], "018474": 19, "018487": [18, 39, 77], "0185": [18, 39, 77], "018505": 78, "018507e": [21, 42, 80], "018533": 42, "018558": 78, "018581": [42, 80], "018613": 40, "018622": 65, "018636": 40, "018653": 78, "018659": 40, "018745": [12, 32, 71], "018763": 40, "018789": 78, "018846": 78, "018854": [20, 41, 79], "018894": 19, "018927": 19, "018944": 42, "019": [52, 81], "019012": 78, "019071": 20, "019097": 21, "019129": 21, "019158": 40, "019163": 78, "019293": 64, "019324": 31, "019381838999846482": [19, 40, 78], "019382": [19, 40, 78], "019396": [40, 78], "019444": 76, "019446": 78, "019531": [20, 41, 79], "019556": [31, 61, 90], "0195598": [18, 39, 77], "019574": 78, "019722": 19, "019794": 40, "019802": 21, "019816": 21, "019839": [19, 40, 78], "019890": 20, "019924": 21, "019971": 21, "019976": 67, "02": [15, 16, 18, 19, 21, 23, 24, 30, 31, 36, 39, 40, 42, 44, 45, 51, 53, 54, 60, 61, 63, 65, 74, 75, 76, 77, 78, 80, 82, 83, 89, 90, 98, 102, 103], "020": [53, 61], "020000": 64, "02000e": [15, 74], "020058": 21, "020118": 19, "020123": [42, 80], "020125": 21, "020215": [21, 40], "020381": 21, "020403": 78, "020414": [19, 40, 78], "020545": 21, "020641": 82, "020648": [42, 80], "020653": [14, 34, 73], "02074": 54, "020808": 54, "020833": [27, 48, 57, 86], "020853": 40, "020862": [42, 80], "020873": [16, 36, 75], "020888": 40, "021": [43, 81, 93], "021043": 79, "021082": 64, "021100": [16, 36, 75], "021244": 53, "021250": 21, "021269": 40, "021279": 21, "02128": 40, "021281": 78, "021289": 40, "021305": [15, 35, 74], "021345": [19, 40, 78], "021396": 20, "021402": 53, "021435": 21, "021505": 21, "021523": 79, "021549": 40, "021603": 88, "021623": 21, "021705": 40, "021712": 53, "021721": 78, "021746": 78, "021750": 23, "021813": 79, "021862": 78, "021891": 21, "021900": [15, 19, 40, 74, 78], "022": [22, 43, 61], "022012": 21, "022039": [20, 41, 79], "022140": 54, "022146": 21, "022156": 40, "022264": 41, "022331": [23, 44, 82], "022337": 23, "022367": 40, "022375": 31, "022433": 78, "022467": 53, "022559": 40, "022597": 44, "022610": 21, "022629": [19, 40, 78], "022652": 40, "022658": 40, "022663": 44, "022686": 78, "022691": 21, "022730": 64, "022833": 21, "022848": [14, 34, 73], "022866": [20, 41, 79], "022902": 21, "022999": 40, "023": [23, 29, 50, 52, 59, 81, 88], "023029": 21, "023086": [31, 61, 90], "023105": [30, 89, 102], "023235": 40, "023279": 65, "023305": [42, 80], "023366": [24, 45, 83], "023367": 79, "023404": 21, "023511": 78, "023554": [42, 80], "023588": 23, "023636": [20, 41, 79], "023663": 29, "023666": 78, "023681": 21, "023810": 93, "023839": 42, "023972": 44, "023983": 23, "02398696": 67, "024": [52, 81], "024026": 21, "024028": [19, 40, 78], "024122": [19, 40, 78], "024291": [30, 51, 60, 89], "024315": 21, "024351e": [21, 42, 80], "024384": 21, "024388": 40, "024390": [24, 45, 54, 83], "02446630e": [23, 44, 53, 82], "024540": [16, 36, 75], "024687": 40, "024722": 21, "024751": 21, "024867": 40, "024900": 21, "024937": 21, "024944": 64, "025": [20, 41, 61, 68, 75, 79], "025017": 23, "025026": 29, "025157": 40, "025178": 21, "025225": 42, "025338": 42, "025377": 42, "025381": [23, 44, 53, 82, 91], "025391": [16, 36, 75, 76], "025396": [19, 40, 78], "025460": 64, "025489": [23, 44, 82], "025689": [19, 40, 78], "025713": 21, "025807": 41, "025871": 40, "025898": 44, "025910": [15, 35, 74], "025928": 31, "025998": [16, 36, 75, 76], "026": [31, 43, 52, 90], "0261": [15, 19, 40, 74, 78], "026110": 21, "026149": 54, "026222": 54, "026232": 21, "026553": 40, "026598": 40, "026616": 64, "026620": [19, 40, 78], "026667": 64, "026777": [19, 40, 78], "02677733855112973": [19, 40, 78], "026793": [21, 23, 42, 44, 53, 80, 82, 91], "02681": 54, "026878": 21, "026969": 21, "026972": 80, "026984": 42, "027": 53, "027070": [42, 80], "027079": 64, "027112": [30, 89, 102], "027172": 40, "027309": 40, "027321": [24, 45, 54, 83], "027336": 21, "027357": 40, "027427": 21, "027484": [42, 80], "027578": 80, "027740": 21, "027752": 40, "028": [22, 53], "028000": 21, "028023": [20, 41, 79], "028043": 40, "02807617": [28, 49, 58, 87], "028186": 64, "028337": [19, 40, 78], "028351": [19, 40, 78], "028420": [42, 80], "0285": 19, "028532": 21, "028626": 44, "028672": [24, 45, 54, 83], "028772": [42, 80], "028830": 52, "029": [28, 49, 58, 87], "029137": 79, "029146": [20, 41, 79], "029164": [30, 89, 102], "029198": [19, 40, 78], "029264": 80, "029396": 64, "029409": 80, "029475": [42, 80], "029898": 41, "029909": [14, 73], "029947": 40, "029950e": [21, 42, 80], "02d": [30, 51, 60, 89], "03": [1, 16, 18, 19, 21, 23, 29, 30, 31, 39, 40, 42, 44, 50, 51, 53, 59, 60, 61, 63, 77, 78, 80, 82, 88, 89, 90, 93, 102, 103], "030": [23, 52, 82], "03003": 54, "03017665e": [23, 44, 53, 82], "030200": [16, 36, 75], "030343": [42, 80], "030349": [42, 80], "030408": [15, 35, 74], "03049217": [15, 35, 74], "0305": [15, 35, 74], "030618": 34, "030739733331869412": [18, 39, 77], "030786": [42, 80], "030805": [42, 80], "031": 76, "031070": 80, "0312": 19, "031385": [15, 35, 74], "031483": [42, 80], "031564": [16, 36, 75], "031794": [21, 42, 80], "031863": 80, "0319": 87, "031994": 80, "032": [19, 43], "032000": 64, "032140": [42, 80], "032161": 31, "032280": 79, "032320": 67, "032324": [19, 40, 78], "032404": [19, 40, 78], "03251": 54, "032566": [17, 37, 76], "03256625": [17, 37, 76], "032656": [15, 35, 74], "032660": 64, "032813": 53, "032874": [15, 35, 74], "033149": [22, 43], "033165": [42, 80], "033222": [61, 90], "033267": [30, 51, 60, 89], "033279": [23, 44, 82], "033305": 88, "033322": 80, "033459": [15, 35, 74], "0335": [40, 78], "033723": 80, "033739": [42, 80], "033780": [61, 90], "033833": [20, 41, 79], "0339": [16, 36, 75], "033993": 64, "034": 44, "034071": [20, 41, 79], "03411038e": [23, 44, 53, 82], "034132": [42, 80], "0344": [15, 19, 40, 74, 78], "034894": 82, "034977": [42, 80], "034979e": [21, 42, 80], "035": [29, 43, 50, 52, 59, 88], "0351": [16, 36, 75], "035105": 40, "0351607": 53, "03516073": [23, 44, 53, 82], "035161": [23, 44, 53, 82], "035223": [42, 80], "035230": [30, 89, 102], "03546": 54, "035722": [42, 80], "036": [14, 16, 29, 36, 50, 59, 75, 81, 88], "036136": [24, 45, 54, 83], "0362": [16, 36, 75], "036646": [21, 42, 80], "036749": 79, "036764": [20, 41, 79], "036837": 53, "036886": 81, "037": 22, "0370": [16, 36, 75], "03710": 54, "037116": 19, "037153": 59, "0373": [16, 36, 75], "037414": [30, 89, 102], "037785": [20, 41, 79], "0378": [16, 31, 36, 75, 90], "03796467": [28, 49, 58], "038102": [18, 39, 77], "038453": 40, "038609": [42, 80], "038707": [23, 44, 82], "038873": 64, "038948": [42, 80], "039": [29, 50, 59, 88], "039335": 59, "0394": 19, "039498": [18, 39, 77], "039716": 50, "039739": 64, "039741": 74, "039858": 29, "0399": [16, 36, 75], "04": [16, 19, 21, 23, 30, 31, 36, 40, 42, 44, 51, 53, 54, 60, 61, 63, 65, 75, 76, 78, 80, 82, 89, 90, 98, 102, 103], "040": 81, "040000": 64, "040000e": 63, "040129": [31, 61, 90], "040497": [20, 41, 79], "040563": 64, "040634": 67, "040698e": [21, 42, 80], "040954": [61, 90], "040984": [30, 51, 60, 89], "041": [29, 43, 50, 52, 59, 81, 88], "041031": [20, 41, 79], "04108378": [18, 39, 77], "041084": [18, 39, 77], "041129": [15, 35, 74], "041201": [20, 41, 79], "041488": [42, 80], "041704": [23, 53, 82], "041769": [42, 80], "042": [22, 31, 52], "042081": [23, 44, 53, 82], "042382": [24, 45, 83], "042722": 40, "042743": [42, 80], "042957": [16, 36, 75, 76], "043": [40, 78], "043257": 76, "043319": [23, 44, 82], "043509": [19, 40, 78], "043527": 29, "043643": 67, "043686": [28, 49, 58], "0437": [13, 14, 15, 34, 35, 72, 73, 74, 96], "043890": [15, 35, 74], "044": [15, 19, 40, 74, 78], "044029": [16, 36, 75, 76], "044166": [18, 39, 77], "044199": 42, "044222e": 19, "044253": [23, 44, 82], "044313": [16, 36, 75], "044409": 80, "044614": 78, "044873": [14, 34, 73], "044948": 53, "045": [13, 19, 22, 29, 50, 59, 63, 72, 88], "045267": [30, 51, 60, 89], "045280": 79, "045304": [15, 35, 74], "045415": 75, "045481": [30, 89, 102], "046": [29, 50, 52, 59, 88], "04600e": [15, 74], "046020": [15, 35, 74], "046114": 64, "046116": [19, 40, 78], "046193e": [21, 42, 80], "046216": 78, "046638": 76, "046702": 31, "046787": 19, "0468": [31, 61, 90], "0469": [16, 36, 75], "046917": 41, "046945": 78, "047": 52, "04704666": [28, 49, 58], "04709519e": [23, 44, 53, 82], "047397": 54, "0474": [18, 39, 77], "047424": 19, "047567": [42, 80], "047577": 16, "04774884": [25, 46, 84], "047749": [25, 46, 84], "047810": 31, "047851": 36, "048": [14, 34, 73, 76], "048378": [14, 34, 73], "04861878": [25, 46, 55, 84], "048630": [30, 51, 89], "048860": [16, 36, 75], "048889": [21, 42, 80], "048940": 14, "049": [29, 44, 50, 59, 76, 88], "049007": 60, "049097": 64, "049117": 42, "049945": 41, "05": [15, 16, 19, 20, 21, 26, 30, 31, 36, 40, 41, 42, 47, 51, 56, 60, 61, 63, 65, 68, 74, 75, 78, 79, 80, 85, 89, 90, 91, 102, 103], "050": [12, 29, 31, 32, 50, 59, 71, 88], "050110e": [42, 80], "050132": [16, 36, 75, 76], "050254": 19, "051": [29, 50, 59, 88], "051269": [16, 36, 75, 76], "051359": 29, "05137470e": [23, 44, 53, 82], "051392": 88, "051472": [15, 35, 74], "051620": [16, 36, 75], "051824": [42, 80], "051925": [19, 40, 78], "052": [16, 36, 75], "052106": 40, "052244": 40, "052270e": 40, "052349": [16, 36, 75], "052607": [20, 41, 79], "052790": [20, 41, 79], "052819": [20, 41, 79], "05290827e": [23, 44, 53, 82], "053": 53, "053156": [25, 46, 55, 84], "05350962": 94, "05361": 54, "0537": [40, 78], "053763": [14, 34, 73], "053918": [19, 40, 78], "054": [43, 52], "054054": [20, 41, 79], "054225": 65, "054461": [20, 41, 79], "054616": 41, "054653": [17, 37, 76], "05465323": [17, 37, 76], "054654": 67, "054669": [21, 23, 42, 44, 53, 80, 82, 91], "054784": [17, 37, 76], "05478443": [17, 37, 76], "055": [16, 22, 36, 73, 75, 76], "055100": [40, 78], "05529": 54, "055398": 15, "055857": 67, "055915e": [21, 42, 80], "05598498": [17, 37, 76], "055985": [17, 37, 76], "056": [29, 50, 59, 88], "05603": 40, "056478": [16, 36, 75, 76], "056480": 19, "05656664": 87, "056599": 64, "056703": [20, 41, 79], "057": [16, 29, 36, 50, 59, 75, 88], "057003": [15, 35, 74], "057073": 19, "057082": [42, 80], "057254": [31, 61, 90], "057267": [31, 61], "057296": [20, 41, 79], "057331": [42, 80], "057609": 67, "05764": 54, "057646": [15, 35, 74], "057689": 50, "057719": 59, "057729": [20, 41, 79], "057732e": [61, 90], "057793": [16, 36, 75, 76], "057910": [16, 36, 75, 76], "057944": 19, "058": [52, 81], "0580": [14, 18, 34, 39, 73, 77], "058176": 91, "058298": [42, 80], "058311": 79, "058546": 19, "058711": 19, "058903": 19, "059": [12, 16, 32, 36, 43, 71, 75], "059077": [20, 41, 79], "0591": [16, 36, 75], "059242": [16, 36, 75, 76], "059360": 88, "059588": 78, "05961": 19, "059863": [15, 35, 74], "06": [16, 19, 21, 26, 28, 29, 30, 31, 36, 40, 42, 47, 49, 50, 51, 54, 56, 59, 60, 61, 63, 75, 78, 80, 85, 87, 88, 89, 90, 94, 102, 103], "060": [29, 50, 59, 88], "06042": 54, "060477": [42, 80], "060543": 83, "060716": 19, "0608": 19, "061100": [16, 36, 75], "06113": 19, "061206": [20, 41, 79], "061241": [15, 35, 74], "061312": [42, 80], "061313": 88, "061582": 19, "061724": 67, "061794": 19, "061937": [15, 35, 74], "062": [12, 15, 19, 32, 40, 71, 74, 78], "062043": 78, "062277": 20, "062449": [31, 61, 90], "06246": 54, "062658e": [21, 42, 80], "062713": 19, "062723": [34, 73], "062792": [15, 35, 74], "062793": 87, "063004": 83, "063090": 52, "063110": [16, 36, 75, 76], "063173": [23, 44, 82], "063730": 31, "063896": 19, "064": [40, 78, 82], "06405": 78, "064050": 78, "0642": 19, "06420": 19, "064200": [15, 35, 74], "064205": 14, "064307": [24, 45, 54, 83], "064322": 67, "064363": 19, "064452": [15, 35, 74], "064921": 19, "065": [22, 29, 50, 59, 88], "065018": 16, "065169": 78, "065176": 19, "065195": 19, "065199": 79, "065449": [21, 42, 80], "065463": [20, 41, 79], "065532": 19, "065805": 31, "066": 52, "06606": 54, "06609": 54, "066148": 67, "066166": [61, 90], "066251": [34, 73], "066512": 64, "066605": 78, "066667": [16, 36, 75], "0667579112160865": [18, 39, 77], "066768": [22, 43], "066810": [61, 90], "066879": 19, "066944": [19, 40, 78], "066960": 14, "067085": 29, "067099": 64, "067112": 67, "067119": 75, "067120": [34, 73], "067264": 59, "067499": 31, "06754": 54, "067600": 67, "06767839": 67, "06772": 54, "067735": 19, "067860": 24, "06797961": [21, 42, 80], "067991": [16, 36, 75], "068": [12, 23, 32, 71], "068042": 31, "068116": 54, "068161": 19, "068214": [18, 39, 77, 78], "068291": 88, "068428": 64, "068453": 19, "068498": 78, "06859333": [28, 49, 58], "068689": 31, "06871": 19, "068710": 19, "068775": 78, "068800e": 63, "068891": 78, "069": 63, "069058": 19, "069119": 24, "069150": [23, 44, 53, 82], "06915047": [23, 44, 53, 82], "069188": 90, "069284": 40, "0694": [15, 19, 40, 74, 78], "069530": [15, 35, 74], "069621": 19, "069644": 61, "069767": 19, "069895": 40, "07": [1, 19, 21, 24, 27, 30, 31, 40, 42, 45, 51, 54, 60, 61, 65, 78, 80, 83, 89, 90, 102], "070047": 36, "070081": 78, "070195": 78, "070755": 29, "07079": 54, "070850": [20, 41, 79], "070898": [31, 78], "070907": [14, 34, 73], "070929": [20, 41, 79], "071": [29, 44, 50, 53, 59, 88], "071330": [30, 89, 102], "071447": 54, "071468": 19, "071515": 31, "071541": [16, 36, 75, 76], "071654": [24, 45, 83], "071670": 50, "07174469097": 42, "07174469222": 80, "07174469272": 21, "071745": [23, 53, 82], "071761": 40, "0719": 19, "07190": 19, "071975": [24, 45, 54, 83], "072": [16, 43, 81], "072043": 78, "0721": 19, "072243": [23, 44, 82], "072286": 31, "0723": [16, 36, 75], "072333": 40, "072354": 19, "072396": 78, "07245741": [21, 42, 80], "072565": 56, "072567": 67, "072595": [45, 78], "072707": [14, 73], "072739": 50, "07287": 54, "072881": 61, "072966": 16, "073016": 91, "073058": 75, "073233": [18, 39, 77], "073290": 19, "073353": 19, "073366": 75, "073848": 19, "074": [16, 36, 75, 81], "074076": 19, "0741": [15, 35, 74], "074141": [15, 35, 74], "07418": 78, "074327": 81, "074418": 88, "074475": 75, "074556": 16, "074719": [17, 37, 76], "07471942": [17, 37, 76], "074773": 34, "074835": 16, "074853": 91, "074957": 19, "074997": 19, "075000": [27, 48, 57, 86], "075170": [30, 89], "075343": 67, "075428": 19, "075453": [31, 61, 90], "075467": [31, 61, 90], "075668": 64, "075747": 78, "076018": 64, "076076": 40, "076104": [21, 42, 80], "0762": [16, 36, 75], "076284": [25, 46, 55, 84], "076358": 36, "07639": 78, "076533": [21, 42, 80], "076798": [15, 35, 74], "076938": 36, "077": [29, 50, 52, 59, 81, 88], "077189": 19, "077204": [23, 44, 82], "077214": 40, "077296": 29, "077749": 87, "077761": [61, 90], "077803": 78, "077861": 19, "077887": 53, "078": [18, 39, 77, 81], "0780": [13, 14, 34, 72, 73, 96], "078052": [20, 41, 79], "07808506982896266": [42, 80], "07808506982896271": 21, "078243": 78, "078387": [31, 61, 90], "07839": 54, "078397": 59, "078552": 78, "078740": 78, "07877994e": 94, "078880": 76, "079": [40, 52, 78], "07911": 54, "079150": 19, "079181": 36, "07927": 40, "079282": 78, "079377": [31, 61, 90], "0794": [15, 19, 40, 74, 78], "079471e": [21, 42, 80], "079554": 19, "079618": 19, "079852e": [21, 42, 80], "07987": 54, "08": [16, 19, 21, 24, 26, 29, 30, 31, 36, 40, 42, 45, 47, 50, 51, 54, 56, 59, 60, 61, 75, 78, 80, 83, 85, 88, 89, 90, 102], "080": [19, 29, 50, 59, 88], "08002986030": [17, 37, 76], "080084": 78, "080101": 40, "080165": 78, "080181": 19, "080200": 19, "080319": [17, 37, 76], "08031924": [17, 37, 76], "0804": 19, "08045": 54, "080623": 19, "080629": 54, "080647": 19, "080694": [23, 44, 82], "080734": 73, "0808": [40, 78], "080847": 14, "080999": 20, "081": [12, 32, 71], "081069": 59, "08116": 78, "081167": [61, 90], "081292": [30, 89], "08151507e": [23, 44, 53, 82], "081835": 19, "081837": [31, 61, 90], "082": 75, "082100": [40, 78], "082251": [18, 39, 77], "082265e": [61, 90], "08233": 40, "082593": 19, "082628": 50, "082749": [15, 35, 74], "082835": [23, 44, 82], "082862": 29, "082924": 19, "082949": [15, 35, 74], "083": [15, 19, 40, 74, 78, 81], "083110": 19, "083123": [16, 36, 75, 76], "083338": [14, 34, 73], "083372": 50, "08338644": [28, 49, 58, 87], "083545": [20, 41, 79], "083615": 78, "083638": 19, "083665": 19, "083813": [16, 36, 75, 76], "083836": 14, "084101": 20, "084173": 20, "084288": 78, "084490": 91, "0846": 54, "084683": 64, "084746": [16, 36, 75, 76], "084870": 34, "084909": 20, "084951": 40, "085150": [30, 51, 60, 89], "08523": 54, "085415": [23, 44, 53, 82, 91], "085458": 19, "085477": [20, 41, 79], "085508": [21, 42, 80], "085546": [21, 42, 80], "085550": [21, 42, 80], "085551": [21, 42, 80], "085693": 78, "085698": [21, 42, 80], "085707": 19, "085716": 19, "085727": 19, "085734": 19, "085991": 20, "086078": 64, "08613": 78, "08629": 19, "08642578": [28, 49, 58, 87], "086461": [24, 45, 54, 83], "086517": 63, "086595": 40, "086606": 67, "086656": 67, "086825": 67, "086932": 73, "087": 76, "087022": 19, "087076": 40, "087128": 78, "087306": 59, "08740234": [28, 49, 58, 87], "087668": [40, 78], "087703": 67, "087809": 40, "08791477": [28, 49, 58, 87], "087996e": 78, "088": [29, 50, 59, 88], "0880": [16, 36, 75], "088015": 19, "088129": 67, "088151": 67, "088161": 29, "088192": 40, "088373": 14, "088543": 78, "088855": 29, "088948": [15, 35, 74], "089021": 40, "089136": 34, "089294": 78, "089313": 78, "089317": 40, "089354": [14, 34], "089425": 50, "089485": [34, 73], "089606": 29, "089692": 67, "089892": 34, "09": [14, 19, 21, 30, 31, 34, 40, 42, 51, 60, 61, 63, 73, 76, 78, 80, 89, 90, 102], "090000": [20, 41, 79], "09009799": [21, 42, 80], "090231": [23, 44, 82], "090368": 29, "090376e": [21, 42, 80], "090453": [20, 41, 79], "090473": 78, "090579": 64, "09058097218": [12, 32, 71], "090749": 19, "090785": [21, 42, 80], "090951": 35, "090971": 20, "090978": 63, "090998": 19, "091": [29, 50, 59, 88], "091243": 78, "091397": 19, "091625": [24, 45, 54, 83], "091632": 64, "091713": 19, "091819": 73, "091945": 19, "091985": 40, "092": 81, "092072": 78, "092123": 78, "0922": [15, 19, 40, 74, 78], "092204": [14, 73], "09221": 54, "092331": 14, "09245358900622544": [19, 40, 78], "092454": [19, 40, 78], "092499": 54, "092604": [14, 34, 73], "092660": [31, 61, 90], "092669": 34, "092670": 78, "092729": 78, "092906": 29, "092930": [17, 37, 76], "092964": 19, "093": 52, "093051": 78, "0931": [40, 78], "093228": [24, 45, 83], "093283": 19, "093308": 19, "093350": 91, "093390": [15, 35, 74], "09345386": [17, 37, 76], "093454": [17, 37, 76], "093464": 50, "093624": 73, "093687": 19, "093787": 78, "093893": 78, "094": [12, 28, 32, 49, 58, 71, 87], "0942": 54, "094290": [31, 61, 90], "09430199": [17, 37, 76], "094302": [17, 37, 76], "094581": [17, 37, 76], "094586": [20, 41, 79], "094595": 50, "094725": 78, "094863": 78, "095018": 78, "09503409246217484": [42, 80], "09503409246217492": 21, "095141": 19, "095177": 78, "095273": 19, "095345": 78, "095445": 40, "095499": 20, "09573445": [19, 40, 78], "095812": 40, "096": 22, "096094": 40, "09619141": [28, 49, 58, 87], "096426": 34, "096462": [21, 42, 80], "096692": [16, 36, 75], "096722": 78, "096858": 78, "096927": [20, 41, 79], "096960": [21, 42, 80], "096990": 73, "096997": 88, "097": [22, 29, 50, 59, 88], "09706504": [29, 50, 59, 88], "097088": [31, 61, 90], "097184": 78, "097293": [16, 36, 75, 76], "097366": 29, "097403": 40, "097446": 40, "097502": 29, "097516": [16, 36, 75], "097707": 78, "097763": 78, "097816": 50, "097880": 40, "097917e": 21, "097938": 34, "098": [18, 29, 39, 50, 59, 77, 88], "098019": 14, "098133": 40, "098152": 78, "098307": [21, 42, 80], "098322": 40, "098324": 54, "098326": [15, 35, 74, 88], "098559": 78, "098606": 19, "098629e": 78, "098663": 78, "098787": 64, "09891476780532049": [18, 39], "0989147678053208": 77, "098915": [18, 39, 77], "098950": 78, "098966": [16, 36, 75], "099": [22, 43, 81], "099141": 40, "099230": [23, 44, 82], "099240": [16, 36, 75, 76], "099269": 59, "099454": 78, "099558": [16, 36, 75, 76], "099685": [21, 42, 80], "099723": [16, 36, 75], "099729": 78, "099749": [30, 89, 102], "099763": 40, "099802": 78, "099869": 78, "0x10d8eb4d0": 19, "0x1227a36e0": 8, "0x14fd573b0": 19, "0x14fe7e120": 19, "0x1577111f0": 78, "0x16888d4c0": 78, "0x168921100": 78, "0x30888e660": 40, "0x308dc0470": 40, "0x308df5c40": 40, "1": [1, 7, 8, 9, 10, 23, 28, 30, 38, 44, 49, 51, 58, 60, 63, 64, 65, 66, 67, 68, 69, 70, 82, 87, 89, 92, 93, 94, 103], "10": [1, 4, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 99, 102, 103], "100": [12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 30, 31, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 54, 55, 56, 59, 60, 61, 63, 64, 65, 67, 69, 72, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 87, 88, 89, 90, 91, 99, 102], "1000": [12, 14, 15, 18, 19, 20, 21, 23, 24, 29, 30, 31, 34, 35, 38, 39, 40, 41, 42, 45, 50, 53, 54, 59, 61, 67, 68, 69, 73, 74, 76, 77, 78, 79, 80, 82, 83, 88, 89, 90, 91, 93, 94, 99, 100], "10000": [12, 13, 18, 19, 21, 30, 38, 39, 40, 42, 63, 66, 67, 72, 76, 77, 78, 80, 89, 102], "100000": [12, 15, 17, 18, 19, 21, 30, 35, 37, 39, 40, 42, 74, 76, 77, 78, 80, 89, 102], "1000000": [40, 65, 78], "1001": 61, "100103": [30, 89], "100105": 78, "100139": [17, 37, 76], "100146": [30, 89], "1002": 61, "100248": [15, 35, 74], "100253": 40, "100261": 40, "100275": [24, 45, 83], "1003": 61, "1004": [15, 35, 74], "1005": [30, 89, 102], "1006": [30, 89, 102], "1007": [30, 89, 102], "10070": 54, "1008": [30, 89, 102], "10083": 63, "100835": 40, "100882": [20, 41, 79], "100892": 40, "1009": [30, 89, 102], "10092665203438746": [42, 80], "10092665203438747": 21, "100970": [31, 61], "101": [1, 9, 25, 29, 31, 46, 50, 55, 59, 67, 70, 84, 88, 90, 103], "1010": [30, 89, 102], "1012": [30, 89, 102], "101259": [21, 42, 80], "101387": 34, "1014": [19, 29, 40, 50, 59, 64, 78, 88], "1015": [29, 30, 50, 59, 64, 88, 89, 102], "1016": [29, 30, 50, 59, 64, 88, 89], "101688": [19, 40, 78], "1017": [29, 30, 50, 59, 64, 88, 89, 102], "101772": 14, "101796": [21, 42, 80], "1018": [29, 30, 50, 59, 64, 88, 89, 102], "101810": 73, "101832": 78, "101894": [20, 41, 79], "1019": [29, 30, 50, 59, 64, 88, 89, 102], "102": [20, 21, 41, 42, 65, 79, 80, 101], "1020": [24, 29, 30, 40, 45, 50, 54, 59, 63, 64, 78, 83, 88, 89, 102], "102044": [24, 45, 54, 83], "1021": [29, 30, 50, 59, 64, 88, 89, 102], "102135": [20, 41, 79], "1022": [29, 30, 50, 59, 64, 88, 89, 102], "1023": [29, 30, 50, 59, 64, 88, 89, 102], "102363": 59, "1024": [29, 30, 50, 59, 64, 70, 76, 88, 89], "102435": [15, 21, 35, 42, 74, 80], "102474": [17, 37, 76], "10247431": [17, 37, 76], "1025": [30, 89, 102], "10254": [30, 51, 60, 89], "1026": [18, 30, 39, 77, 89], "1027": [30, 89, 102], "10273": [21, 42, 80], "10274": [20, 41, 79], "102796": 29, "1028": [30, 89, 102], "102865": 31, "1029": [30, 89, 102], "103": 90, "103023": 78, "1031": [30, 89], "103116": 29, "103219": [24, 45, 83], "103222": 88, "1034": [24, 45, 54, 83], "103428": 42, "103439": [17, 37, 76], "103474": 40, "10360": 54, "103619": 65, "10361902": 65, "103797": 40, "1039": [30, 89, 102], "104": [15, 16, 25, 29, 35, 36, 46, 50, 55, 59, 74, 75, 81, 84, 88], "1040": [16, 19, 36, 75], "104070": [21, 42, 80], "1041": [21, 23, 30, 42, 44, 80, 82, 89, 93, 102], "10416666666666667": [27, 48, 57, 86], "1042": [19, 40, 78], "1043": [17, 37], "104353": 40, "104393": 40, "1044": [12, 32, 71], "104499": 40, "104596": 78, "104643": [21, 42, 80], "104701": 59, "105": [19, 22, 63, 81], "1050": [13, 63, 72], "105080": [24, 45, 83], "105089": [17, 37, 76], "10513": [30, 51, 60, 89], "1052": [61, 65], "1053": [61, 65, 93], "105314": [30, 89], "105340": 40, "1054": [61, 65], "1055": [61, 65], "10556679": [25, 46, 55, 84], "1056": [61, 65], "105656": [23, 53, 82], "1057": [61, 65], "1058": [61, 65], "10584063": [29, 50, 59, 88], "1059": [61, 65], "105995": 40, "106": 65, "106000": [16, 36, 75], "106023": [21, 42, 80], "106112": [30, 89], "106177": 19, "106180": [30, 89], "106319": [30, 89], "106322": [30, 89], "106424": [30, 89], "10644531": [28, 49, 58, 87], "106452": [15, 35, 74], "10645223": [15, 35, 74], "106485": 40, "10653": [30, 89, 102], "1066": 54, "106705": [30, 89], "106764": 78, "1068": 93, "106816": [30, 89], "106832": 40, "1069": 93, "10693359": [28, 49, 58, 87], "106996": 78, "107": [22, 81], "1070": [24, 45, 54, 83], "107050": [30, 89], "107292": [30, 89], "107360": 40, "107374": 40, "1075": 93, "107502": [30, 89, 102], "1076": [63, 76], "107623": 40, "107711": 50, "107718": 78, "10781": [22, 23, 43, 44, 52, 53, 81, 82], "107867": 40, "107917": [30, 89, 102], "10793260e": [29, 50, 59, 88], "107947": [21, 42, 80], "107985": [21, 42, 80], "107991": [20, 41, 79], "108": [12, 32, 43, 71], "1080": [12, 32, 71], "10800": [12, 32, 71], "1085": [18, 39, 77], "10868": [30, 51, 60, 89], "108681": [15, 35, 74], "108780": 40, "1089": [21, 42, 80], "108914": 19, "109000": 19, "10910": [30, 51, 60, 89], "109242": 42, "10931": 76, "1095": 54, "109526": [20, 41, 79], "109539": 59, "109580": 64, "1099": [21, 42, 80], "10_000": [31, 38, 61, 90], "10th": [19, 20, 22, 23, 40, 41, 43, 44, 52, 53, 54, 78, 79, 81, 82, 100], "10x": [20, 41, 79], "11": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 93, 95, 97, 102, 103], "110": [18, 29, 39, 50, 59, 77, 88], "110000": 19, "1101": [17, 37, 65], "1102": 65, "1103": 65, "110316": [30, 89, 102], "110319": [30, 89, 102], "1104": [15, 35, 65, 74], "11057": [30, 51, 60, 89], "1106": [24, 45, 54, 65, 83], "110645": [21, 42, 80], "1107": 65, "1108": 65, "1109": 65, "110911": 40, "110915e": [21, 42, 80], "110985": 31, "111": [16, 19, 20, 21, 31, 36, 40, 41, 42, 61, 68, 75, 78, 79, 80, 90, 100], "1110": 65, "1111": 65, "111111": 16, "111182": 40, "1112": 65, "11121453": [25, 46, 84], "111215": [25, 46, 84], "111220": [30, 51, 60, 89], "1114": 65, "11140": 54, "111438": [24, 45, 83], "1115": 65, "111543": [21, 42, 80], "111546": 40, "1116": 65, "112": [15, 16, 19, 35, 43, 74], "112164": 40, "1122": [21, 23, 42, 44, 80, 82, 93], "1123": [40, 78, 93], "112356": 40, "112409": 40, "112441": 78, "112490": 78, "112519": 31, "112527": 82, "112848": [21, 42, 80], "112915": 40, "1131": 63, "113175": 40, "11331": 93, "11336331e": [23, 44, 53, 82], "113381": 53, "113600": [16, 36, 75, 76, 98], "113782": 40, "1138": [24, 45, 54, 83], "113815": 53, "113831": 40, "113837": [21, 42, 80], "1139": [21, 23, 42, 44, 80, 82, 91], "113949e": [61, 90], "113993": 40, "114": [16, 36, 43, 75], "1140": [12, 21, 23, 32, 42, 44, 71, 80, 82, 91], "114000": [16, 24, 36, 45, 54, 75, 83], "114079": 78, "114214": 78, "114502": 19, "114507": 88, "114521": 53, "11457": [21, 23, 42, 44, 80, 82, 91], "114757": 63, "114766": [23, 44, 82], "1148": 54, "114836": [24, 45, 83], "114966": [23, 44, 82], "115": 76, "1150": [12, 32, 71], "115083": [16, 36, 75], "115089": [30, 89], "11509": [21, 42, 80], "115090": [30, 89], "115091": [30, 89], "115092": [30, 89], "115183": 78, "11520": 54, "115276": [61, 90], "115401": [21, 42, 80], "115406": [15, 35, 74], "115428": [30, 89, 102], "115956": [18, 39, 77], "116": [16, 36, 75], "116145": [24, 45, 83], "116167": [18, 39, 77], "116418e": 21, "116443": [24, 45, 83], "116497": [21, 42, 80], "11664": 93, "11670": 54, "11693": [21, 42, 80], "116963": 40, "117": [16, 18, 24, 36, 39, 45, 65, 75, 76, 77, 83, 98], "117058": [18, 39, 77], "117378": 31, "117379": 78, "117380": [16, 36, 75], "117412": [21, 42, 80], "117528": [24, 45, 54, 83], "11758": [30, 89, 102], "117612": 88, "117647": 40, "117712": [30, 89], "117816": [16, 36, 75], "117899e": [21, 42, 80], "1179": [16, 36, 75], "118": [16, 18, 21, 23, 24, 36, 39, 42, 44, 45, 53, 54, 65, 75, 76, 77, 80, 82, 83, 91], "1180": [13, 63, 72], "118182": [16, 36, 75, 76], "118258": 29, "118347": [21, 42, 80], "118450": [20, 41, 79], "118518": 40, "118563": [24, 45, 83], "11886432": [19, 40, 78], "118874": [21, 42, 80], "118934": [20, 41, 79], "11898": [20, 41, 79], "118997": 29, "119": [16, 18, 24, 30, 36, 39, 43, 45, 75, 76, 77, 83, 89, 98, 102], "1190": [16, 36, 63, 75], "119049": [30, 89, 102], "119094": 31, "11909976": [25, 46, 84], "119100": [25, 46, 84], "119121": 64, "11914062": [28, 49, 58, 87], "119189": 64, "119368": 52, "119400": [16, 36, 75], "1195": [17, 37], "119570": [24, 45, 83], "119911": [30, 89, 102], "11th": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "12": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 60, 61, 64, 65, 67, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 89, 90, 91, 93, 94, 95, 96, 97, 101, 102, 103], "120": [15, 16, 18, 21, 29, 30, 35, 36, 39, 42, 50, 51, 59, 60, 65, 67, 69, 74, 75, 77, 80, 81, 88, 89, 94], "1204": [15, 35, 74], "120769e": [21, 42, 80], "121": [12, 16, 18, 19, 22, 24, 30, 32, 36, 39, 40, 43, 45, 51, 52, 60, 63, 65, 71, 75, 76, 77, 78, 81, 83, 89], "1210": [40, 78], "121056e": [21, 42, 80], "121084e": [21, 42, 80], "121351": 82, "12138": [16, 36, 75], "1214": [21, 42, 80], "121438": [31, 61, 90], "12150684": [18, 39, 77], "121531": [20, 41, 79], "121599": [23, 44, 82], "121628": [15, 35, 74], "121655": 40, "1217": [61, 90], "12178": [24, 45, 54, 83], "121846": [23, 44, 82], "121985": [21, 42, 80], "122": [12, 13, 14, 16, 24, 29, 32, 34, 36, 45, 50, 54, 59, 63, 65, 71, 72, 73, 75, 76, 83, 88, 96, 101], "1220": [12, 16, 32, 36, 40, 71, 75, 78], "1222": [19, 40, 78], "122210": 53, "122307": [16, 36, 75, 76], "122331": [21, 42, 80], "122403": 40, "12266": [28, 49, 58], "122668": 78, "123": [4, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 50, 51, 52, 53, 54, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100], "123049e": 63, "1231": 54, "123322": 42, "123367": [21, 42, 80], "1235387316046016": [19, 40, 78], "123539": [19, 40, 78], "123785": 40, "124": [16, 28, 36, 49, 58, 65, 75, 87], "1240": [12, 32, 71], "1241": [21, 24, 42, 45, 80, 83], "1243": [16, 36, 75], "12436984": [17, 37, 76], "124370": [17, 37, 76], "1247": [19, 40, 61, 78], "1248": 61, "1249": 61, "12498": [23, 44, 82], "124982": [24, 45, 83], "125": [8, 21, 42, 65, 80], "1250": [16, 36, 61, 75, 76, 98], "125000": 63, "12508": [21, 23, 42, 44, 53, 80, 82, 91], "1252": 61, "1253": 61, "1254": 61, "125440e": [21, 42, 80], "125476": [15, 35, 74], "1255": 61, "125523": [30, 89, 102], "1256": [61, 94], "125617": [30, 89, 102], "125644": [21, 42, 80], "1257": 61, "1258": [31, 61, 90], "1259": 61, "126": [24, 45, 54, 65, 83], "1260": 61, "1261": 61, "126238": [24, 45, 54, 83], "1263": 61, "126398": [16, 36, 75, 76], "1264": 61, "126488": [25, 46, 55, 84], "12649": [16, 36, 75], "126500": [16, 36, 75], "126563": [19, 40, 78], "126808": [16, 36, 75, 76], "127": [14, 16, 18, 34, 36, 39, 40, 54, 65, 73, 75, 77, 78, 92], "127086": [16, 36, 75], "127087": [61, 90], "1271": [22, 43, 52, 81], "127107": [23, 44, 82], "127226": 76, "127242": [21, 42, 80], "1273": [23, 44, 82], "127326": [21, 42, 80], "1274": [24, 45, 54, 83], "127418": [21, 42, 80], "127439": [21, 42, 80], "127441": [21, 42, 80], "127614": [21, 42, 80], "12761659": [21, 42, 80], "12768": 63, "127754": 50, "127878": [15, 35, 74], "1279": [21, 42, 80], "128": 93, "1280": [16, 19, 21, 36, 40, 42, 75, 78, 80], "1281": [21, 42, 80], "128188": [16, 36, 75, 76], "128384": [21, 42, 80], "128432": 53, "128528": [21, 42, 80], "128692": [23, 44], "1287": 63, "128820": [30, 89], "128828": [30, 89], "128829": [30, 89], "128830": [30, 89], "12890625": [28, 49, 58, 87], "128984": [21, 42, 80], "129": [15, 18, 24, 31, 35, 39, 45, 52, 54, 61, 74, 77, 83, 90, 101], "1290": [16, 36, 75, 76], "12906": [12, 32, 71], "129257": [21, 42, 80], "12927": [12, 32, 71], "129300": [16, 36, 75, 76, 98], "129459": [24, 45, 54, 83], "12960": 54, "129600": [21, 42, 80], "129746": 40, "129900": [20, 41, 79], "129904": [21, 42, 80], "129985": [16, 36, 75], "12th": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "13": [1, 8, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 40, 41, 42, 43, 45, 47, 48, 49, 51, 52, 54, 56, 57, 58, 60, 61, 63, 64, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 83, 85, 86, 87, 89, 90, 93, 95, 98, 102], "130": [12, 13, 14, 15, 16, 21, 23, 24, 32, 34, 35, 36, 40, 42, 44, 45, 71, 72, 73, 74, 75, 76, 78, 80, 82, 83, 91, 96, 98], "1300": [21, 23, 42, 44, 53, 80, 82, 91], "1302": [20, 79], "130395": [30, 89, 102], "1304": [15, 31, 35, 61, 74, 90, 91], "130432": [30, 89, 102], "1306": 92, "130690e": [21, 42, 80], "1307": [21, 42, 80], "13071": 40, "130710": 40, "130855": [23, 44], "131": [16, 30, 31, 36, 61, 65, 75, 81, 89, 90], "131000": [21, 42, 80], "13107": [30, 51, 60, 89], "131275": [20, 41, 79], "1313": [21, 42, 80], "1314": [21, 23, 42, 44, 80, 82, 91], "131607": [21, 23, 42, 44, 80, 82, 91], "131693": 67, "131773": [31, 61, 90], "13179824": 67, "1319796954314723": [22, 43, 52, 81], "132": [16, 31, 61, 90], "1320": [24, 45, 54, 83], "1321": [12, 32, 71], "132158": [21, 42, 80], "1322": 54, "132292": [24, 45, 54, 83], "13229595e": [23, 44, 53, 82], "132368": 29, "13255": [30, 51, 60, 89], "132875": [16, 36, 75, 76], "132886": [30, 89], "133": [31, 40, 61, 78, 90], "133000": [21, 42, 80], "133210": 78, "133270": [21, 42, 80], "133302": 40, "133337": [21, 42, 80], "133552": 59, "133562": [31, 61, 90], "1337": 19, "13392236": [29, 50, 59, 88], "134": [13, 14, 18, 34, 39, 72, 73, 76, 77, 96], "1340": [13, 63, 72], "134061": [24, 45, 54, 83], "13407": [23, 44, 82], "13418": 16, "134287": [20, 41, 79], "134431": 59, "13452": 67, "1346": [16, 21, 23, 24, 31, 36, 42, 44, 45, 54, 75, 80, 82, 83, 90, 93], "134615": [18, 39, 77], "134658": [16, 36, 75], "1347": 93, "13470568": [28, 49, 58], "13476562": [28, 49, 58, 87], "134894": [30, 89, 102], "135": [30, 31, 61, 89, 90, 102], "1350": 63, "135134": [30, 89, 102], "135197": [30, 89, 102], "13521135": [23, 44, 82], "135299": [24, 45, 54, 83], "135305": [16, 36, 75, 76], "135335e": 19, "135384": [21, 42, 80], "13540": 63, "135422": [21, 42, 80], "1357": [12, 32, 63, 71], "135853": 54, "136": [16, 36, 53, 61, 75, 76], "1360": [13, 63, 72], "136301": 40, "1364": 65, "1365": 65, "1366": 65, "13665": [16, 36, 75, 76, 98], "1367": 65, "136714": [20, 41, 79], "1368": 65, "1369": [61, 65], "137": 61, "1370": [12, 15, 19, 31, 32, 40, 61, 65, 71, 74, 78, 90], "13704": [21, 23, 42, 44, 53, 80, 82, 91], "1371": [61, 65], "1372": [65, 91], "1373": 65, "1374": 65, "137410": [25, 46, 55, 84], "1375": 65, "137500": [16, 36, 75, 76, 98], "137553": 40, "1376": 65, "1377": 65, "1378": [21, 42, 61, 65, 80], "1379": [61, 65], "138": [61, 93], "1380": [12, 32, 61, 65, 71], "1381": [61, 65], "138103": 88, "1382": [61, 65], "1383": [19, 40, 61, 65, 78], "1384": [61, 65], "1385": [61, 65], "138503": [24, 45, 54, 83], "138528": [18, 39, 77], "138564": 63, "1386": [61, 65], "1387": [61, 65], "1388": [61, 65], "138836": 67, "138876": [61, 90], "1389": [16, 21, 23, 36, 42, 44, 61, 65, 75, 80, 82], "139": [16, 17, 36, 37, 61, 75, 93], "1390": [12, 32, 71], "1391": 61, "1392": 61, "139297": [20, 41, 79], "1393": 61, "139317": [20, 79], "139322": [20, 41, 79], "139349": [20, 41, 79], "1394": 61, "13941": [20, 41, 79], "139554": [20, 79], "1396": [40, 78], "1397": [19, 40, 78], "14": [1, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 40, 41, 42, 44, 47, 48, 49, 50, 51, 56, 57, 58, 59, 60, 61, 64, 65, 71, 72, 73, 74, 75, 76, 78, 79, 80, 82, 85, 86, 87, 88, 89, 90, 95, 102], "140": [16, 36, 75], "140185": [24, 45, 83], "140371": 64, "1404": [15, 31, 35, 61, 74, 90], "140465": 59, "1405": [24, 45, 54, 83], "140561": 42, "1406": [16, 21, 23, 36, 42, 44, 75, 80, 82], "140610": 59, "140631": [31, 61], "140641": [30, 89, 102], "1407": 54, "140828": 63, "140953": [30, 89, 102], "141": [16, 18, 36, 39, 75, 77], "1410": 63, "141232": [30, 89, 102], "14159265358979323": 8, "14160": [20, 41, 79], "141636": 40, "141851": [30, 89, 102], "142": [53, 81], "142051e": 63, "142193": [30, 89, 102], "142199": [30, 89, 102], "1423": [20, 79], "142397": 50, "142398": [30, 89, 102], "1424": 54, "142467": [14, 34, 73], "1427": [63, 91], "14280": 54, "142806": [30, 89, 102], "142857": 76, "14289": [16, 36, 75, 76, 98], "143": [20, 40, 41, 78, 79], "143693": [30, 89, 102], "143774": 50, "143803": [24, 45, 83], "1438387200": [30, 51, 60, 89], "1438398000": [30, 51, 60, 89], "1438408800": [30, 51, 60, 89], "1438419600": [30, 51, 60, 89], "1438430400": [30, 51, 60, 89], "1438441200": [30, 51, 60, 89], "1438452000": [30, 51, 60, 89], "1438462800": [30, 51, 60, 89], "1438473600": [30, 51, 60, 89], "1438484400": [30, 51, 60, 89], "143975": [30, 89, 102], "144": [12, 19, 32, 40, 54, 71, 78], "144000": [21, 23, 42, 44, 80, 82, 91], "1441": 93, "144199": [30, 89, 102], "144221": 40, "144686": [23, 44, 82], "14471": [16, 36, 75, 76, 98], "144729": [30, 89], "144730": [30, 89], "144731": [30, 89], "144732": [30, 89], "144733": [30, 89, 102], "144750": [15, 35, 74], "14485": [21, 42, 80], "145": [23, 30, 54, 64, 89, 102], "145186": 64, "1452": [24, 45, 54, 83], "145425": [21, 42, 80], "145454": [30, 89, 102], "145455": [30, 89, 102], "145456": [30, 89, 102], "145457": [30, 89, 102], "145458": [30, 89, 102], "145459": [30, 89, 102], "145460": [30, 89, 102], "1457": [16, 31, 36, 75, 76, 90, 98], "14579": [24, 45, 83], "1458": [16, 36, 75, 76, 98], "145833": [27, 48, 57, 86], "145915": [22, 43], "146": [12, 32, 64, 71, 81, 91], "1460": [21, 31, 42, 80, 90], "14648438": [28, 49, 58, 87], "1465": [16, 36, 75, 76, 98], "146656": [30, 89, 102], "1467": [24, 45, 54, 83], "146767": [20, 23, 41, 44, 79, 82], "146809": [20, 41, 79], "146830": [20, 41, 79], "14690": 76, "147": [23, 44, 53, 64, 82, 91], "147166": [22, 23, 43, 44, 52, 53, 81, 82], "14716638": [23, 44, 53, 82], "1472": 65, "147226": 64, "147487": 40, "147641": [21, 42, 80], "1477": 93, "147737": 88, "147893": [16, 36, 75], "147898": [20, 41, 79], "147979": 40, "148": [15, 19, 23, 40, 44, 64, 65, 74, 78, 82, 94], "14813": [30, 51, 60, 89], "148141": 81, "148343": [21, 42, 80], "148349": [31, 61, 90], "14841": [20, 41, 79], "148556": 59, "149": [31, 61, 64, 90], "1490": 63, "149036": 50, "149122": 92, "14970": [16, 36, 75], "149761": 59, "149788": [23, 44, 82], "149822": [16, 36, 75, 76], "14999": [16, 36, 75], "14th": [12, 13, 32], "15": [1, 8, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 60, 61, 63, 64, 65, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 85, 86, 87, 89, 90, 93, 95, 96, 100, 102, 103], "150": [15, 19, 21, 29, 40, 42, 50, 55, 59, 64, 69, 74, 78, 80, 88, 91], "1500": [19, 65], "15000": 19, "150000": [20, 27, 41, 48, 57, 79, 86], "150115": [19, 40, 78], "1502": 54, "15026771": [21, 42, 80], "150395": [15, 35, 74], "1504": [15, 35, 74], "1505": [16, 36, 75], "1509": 63, "150999": [31, 61], "150mb": [20, 41, 68, 79], "150p": [12, 32, 71], "151357": [24, 45, 83], "1514": 92, "152": [30, 51, 60, 65, 89], "1520": [19, 40, 78], "1523300141": 63, "1523300157": 63, "152401": [20, 41, 79], "1524625640014508": 52, "152691": 64, "15278": 16, "152859": [20, 41, 79], "1529": 61, "152998": 40, "153": 65, "1530": [12, 32, 61, 63, 71], "1531": [17, 37, 61], "1534": [16, 36, 61, 75], "1535": 61, "1536": 61, "1537": 61, "15377": [16, 24, 36, 45, 75, 83], "1538": 61, "1539": 61, "154": 65, "1540": [12, 32, 61, 71], "154076": [20, 23, 41, 44, 79, 82], "1541": 61, "154105": [24, 45, 54, 83], "1542": 61, "15429": [30, 51, 60, 89], "1543": 61, "154386": [16, 36, 75, 76], "1544": 61, "1545": [24, 45, 61, 83], "1546": 61, "1547": 61, "154733": 40, "154795": [21, 23, 42, 44, 53, 80, 82, 91], "154842": [31, 61, 90], "154883": 64, "155": [12, 19, 32, 40, 65, 71, 78], "15500": [21, 42, 80], "155178e": [21, 42, 80], "1553": 54, "15559528e": [23, 44, 53, 82], "155624": [21, 42, 80], "155900": 63, "156": [16, 19, 20, 36, 40, 41, 65, 75, 78, 79], "1560": 63, "1562": [19, 40, 78], "15620": 54, "156311e": [21, 42, 80], "1564": [19, 40, 78], "15661": [30, 51, 60, 89], "157": [12, 19, 29, 32, 40, 50, 59, 65, 71, 78, 88], "157008": [21, 42, 80], "157157": 93, "157234": [24, 45, 54, 83], "15725": [16, 24, 36, 45, 75, 83], "157307e": 21, "157572": 64, "15775": [30, 51, 60, 89], "1578": [23, 44, 82], "15795": [20, 23, 41, 44, 79, 82], "158": [19, 40, 78], "1580": [12, 32, 71], "1582": [23, 44, 53, 82], "158867": [30, 89, 102], "158982": [21, 42, 80], "159": [19, 40, 52, 78], "1590": [15, 19, 40, 74, 78], "15915": [30, 51, 60, 89], "159751": 64, "15992": [23, 44, 82], "15pm": 1, "16": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 45, 48, 49, 51, 52, 54, 57, 58, 60, 61, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 86, 87, 89, 90, 92, 93, 95, 96, 102], "160": [14, 15, 18, 19, 21, 34, 39, 40, 42, 67, 69, 73, 74, 77, 78, 80, 82], "1600": 63, "160000": [21, 23, 42, 44, 53, 80, 82, 91], "160258": [14, 34, 73], "160282": [24, 45, 54, 83], "1604": [15, 35, 74], "160506": [20, 41, 79], "160634": 88, "16063983": [17, 37, 76], "160640": [17, 37, 76], "160727": [23, 44, 53, 82], "160729": [30, 89, 102], "161": [16, 36, 65, 75], "161001": 31, "1610243052583633": [18, 39], "1610243052583638": 77, "16111330565237114": [18, 39], "16111330565237164": 77, "1613": [16, 36, 75], "161300e": 63, "161429": 64, "16153": [30, 51, 60, 89], "161559": 29, "16157": [30, 51, 60, 89], "16160": [30, 51, 60, 89], "161606": [16, 36, 75, 76], "161782": [20, 41, 79], "1619": [19, 40, 78], "161931": [21, 23, 42, 44, 80, 82, 91], "162": [12, 32, 71], "162000": [21, 42, 80], "162007": 93, "162214": 91, "162330": [20, 41, 79], "162628": 40, "162667": [20, 23, 41, 44, 79, 82], "16269": 16, "1627": [24, 45, 54, 83], "162904": [61, 90], "163": 63, "1631": [19, 40, 78], "163195": [16, 36, 75, 76], "163397": [16, 36, 75, 76], "1634": [16, 19, 36, 40, 75, 76, 78, 98], "16358": [30, 51, 60, 89], "164": [24, 29, 45, 50, 54, 59, 83, 88], "1641": 54, "1645": [18, 39, 77], "164556": 59, "16460": [24, 45, 54, 83], "164679": [20, 41, 79], "165": [18, 21, 39, 42, 77, 80], "1650": [15, 19, 40, 74, 78], "16507": [18, 24, 39, 45, 54, 77, 83], "16508": [18, 24, 39, 45, 54, 77, 83], "16509": [18, 24, 39, 45, 54, 77, 83], "16510": [18, 24, 39, 45, 54, 77, 83], "16511": [18, 24, 39, 45, 54, 77, 83], "16512": [18, 24, 39, 45, 54, 77, 83], "165145": 60, "165198e": [42, 80], "1652": [14, 18, 34, 39, 73, 77], "16533": [30, 51, 60, 89], "165485": [23, 44, 82], "165617": [30, 51, 89], "165811": [19, 40, 78], "166": [34, 52, 54], "16630": [24, 45, 54, 83], "166379": 59, "166631": [16, 36, 75, 76], "16686": 16, "167": [14, 34, 65, 73], "167214": [15, 35, 74], "167241": 93, "16736": [28, 49, 58], "167540": 20, "167600": [24, 45, 83], "167620": 88, "167739": 50, "168": [21, 42, 65, 80], "1680": [13, 63, 72], "168151": 88, "168196": [16, 36, 75, 76], "168244": [23, 44, 82], "1687": [40, 78], "1688": 54, "169": [14, 18, 24, 34, 39, 45, 54, 65, 73, 77, 83], "1690": [12, 13, 32, 63, 71, 72], "169269e": 90, "169421": 78, "169693": [15, 35, 74], "169748": [18, 39, 77], "16991815": 8, "1699181533555938": 8, "17": [1, 4, 8, 13, 15, 16, 17, 18, 19, 20, 21, 24, 28, 30, 31, 35, 36, 37, 39, 40, 41, 42, 45, 49, 51, 54, 58, 60, 61, 63, 65, 68, 72, 74, 75, 76, 77, 78, 79, 80, 83, 87, 89, 90, 95, 98, 102], "170": [16, 26, 36, 47, 56, 75, 85], "1700": 19, "170100": [16, 36, 75, 76, 98], "170277": [22, 23, 43, 44, 52, 53, 81, 82], "1704": [15, 35, 74], "17054987": [29, 50, 59, 88], "170670": [21, 42, 80], "17080": 54, "170928": 54, "170931": 88, "171": [12, 29, 32, 50, 59, 71, 88], "17144": [30, 51, 60, 89], "171468": [21, 23, 42, 44, 80, 82, 91], "1715": [19, 40, 78], "171657": [14, 34, 73], "171899": [61, 90], "172": 54, "1720": [16, 36, 75], "17205": [30, 51, 60, 89], "1724668": 87, "172792": [20, 41, 79], "17290": 63, "173": [15, 19, 40, 74, 78], "173025": [19, 40, 78], "17347071": 67, "173483": 67, "17393037": 8, "1739787032867638": [19, 40, 78], "173979": [19, 40, 78], "173981": 50, "174": [12, 15, 19, 32, 40, 71, 74, 78], "174590": [20, 41, 79], "174652": 61, "17476": 16, "174766": [24, 45, 83], "1750": [16, 36, 75, 92], "175000": [21, 23, 42, 44, 80, 82, 91], "17518": [30, 51, 60, 89], "175459": 63, "176": [16, 36, 75], "176026": 64, "1766": [21, 42, 80], "1767": 54, "176924": [61, 90], "177": [24, 45, 54, 83], "17730": [16, 24, 36, 45, 75, 83], "177413": 29, "177709": [61, 90], "178": [12, 21, 32, 42, 71, 80], "17847": 16, "178494": [21, 42, 80], "178603": 50, "1788": 63, "17896": [30, 51, 60, 89], "179": [22, 31, 43, 52, 61, 81, 90], "179080": [20, 41, 79], "179123": [15, 35, 74], "179152": 65, "179300": [16, 36, 75], "179631": 63, "179730": [19, 40, 78], "17973005068132514": [19, 40, 78], "179802": [21, 42, 80], "18": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 27, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 45, 46, 48, 51, 54, 55, 57, 60, 61, 65, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 86, 89, 90, 91, 93, 95, 98, 102], "180": [19, 21, 29, 40, 42, 50, 59, 69, 78, 80, 88], "1800": [12, 13, 15, 19, 32, 40, 63, 71, 72, 74, 78], "18000": [30, 51, 60, 89], "180000": [13, 63, 72], "180279e": [21, 42, 80], "180388": [15, 35, 74], "1804": [15, 35, 74], "18066406": [28, 49, 58, 87], "180900": [24, 45, 83], "180926": 64, "18096": [30, 51, 60, 89], "181": [22, 31, 61, 90], "18113": [30, 51, 60, 89], "18116": [30, 51, 60, 89], "1813": [19, 40, 78], "182": [30, 31, 51, 60, 61, 89, 90], "18201414": [23, 44, 53, 82], "182382": 64, "18245": [30, 51, 60, 89], "182639": [21, 42, 80], "182648": [21, 42, 80], "1830": 63, "18311": [30, 51, 60, 89], "18313": [30, 51, 60, 89], "18317085": 8, "183179": [31, 61, 90], "183423": [15, 35, 74], "183471e": [21, 42, 80], "18365": 76, "18391": [16, 36, 75, 76], "184": [30, 31, 51, 60, 61, 89, 90], "1840": [12, 32, 63, 71], "184282": 67, "184405": [23, 44, 82], "1847": [17, 37, 76], "185": [14, 31, 34, 44, 61, 90], "185000": 14, "185155": [23, 44, 82], "185175": [31, 61, 90], "18533": [30, 51, 60, 89], "1854": [19, 40, 78], "1857": 61, "185707": [15, 19, 40, 74, 78], "18571": [16, 36, 75, 76], "18572": [16, 36, 75, 76], "18573": [16, 36, 75, 76], "18574": [16, 36, 75, 76], "18575": [16, 36, 75, 76], "18576": [16, 36, 75, 76], "1858": [24, 45, 54, 61, 83], "185868": [24, 45, 83], "1859": 61, "185975": [23, 44, 53, 82], "18597545": [23, 44, 53, 82], "186": [61, 65], "1860": 61, "186024": [12, 32, 71], "1861": 61, "186814": [20, 41, 79], "186869": 31, "186899": [20, 41, 79], "187": [14, 18, 34, 39, 73, 77, 81], "1870": [40, 78], "187000": [16, 36, 75], "1872": [21, 42, 80], "18747167": [28, 49, 58], "1875": [18, 28, 39, 49, 58, 77, 87], "187502": 61, "187503": [30, 89], "187663": [15, 35, 74], "187700": [16, 36, 75], "188": [12, 14, 18, 32, 34, 39, 71, 73, 77], "1880": [19, 40, 78], "1886": [18, 39, 77], "1887": [20, 23, 41, 44, 79, 82], "188748": 59, "189": [52, 65], "18955": [30, 51, 60, 89], "1896": 19, "189981": [21, 42, 80], "19": [1, 8, 12, 13, 14, 15, 17, 19, 20, 21, 24, 27, 28, 30, 31, 32, 35, 37, 40, 41, 42, 45, 48, 49, 51, 54, 57, 58, 60, 61, 63, 71, 72, 73, 74, 76, 78, 79, 80, 83, 86, 87, 89, 90, 93, 95, 102], "190": [14, 21, 24, 34, 42, 45, 54, 69, 73, 80, 83], "1900": 63, "19000e": [15, 74], "1901": [12, 32, 71], "190319": [24, 45, 54, 83], "19032": [30, 51, 89], "1904": [15, 35, 74], "190617": [16, 36, 75, 76], "190832": 61, "190833": 34, "191": [16, 34, 36, 73, 75], "1910": 63, "1911": [24, 45, 83], "191169": [21, 23, 42, 53, 80, 82], "191204": [24, 45, 54, 83], "191250": [14, 34, 73], "191396": [15, 35, 74], "1914": 61, "1915": 61, "1916": 61, "1917": 61, "191700": [24, 45, 54, 83], "1918": [17, 37, 61, 76], "1919": 61, "191k": [23, 53, 82], "192": 52, "1920": [12, 32, 61, 71], "1921": 61, "19213263": [17, 37, 76], "192133": [17, 37, 76], "19266": [30, 51, 60, 89], "1927": 93, "1928": 93, "192943": 29, "193": [22, 29, 50, 59, 88], "1930": [12, 32, 71], "193021": [20, 41, 79], "193122": [20, 41, 79], "193247": [24, 45, 83], "1933": [13, 63, 72], "193346": [23, 53, 82], "1934": 63, "193427": [40, 78], "19365": [30, 51, 60, 89], "193704": [30, 89, 102], "19380": [30, 51, 60, 89], "194": 19, "1940": [17, 37, 76], "194002": [15, 35, 74], "194034": [30, 89, 102], "194040": [16, 36, 75], "19422": [23, 53, 82], "19433594": [28, 49, 58, 87], "1944": 63, "1945": [21, 42, 69, 80], "194519": 67, "1946": [12, 21, 32, 42, 69, 71, 80], "194710": [21, 42, 80], "1948": 63, "19485": [16, 36, 75], "194914": 64, "194985": [21, 42, 80], "195": [16, 36, 52, 75], "1950": [21, 42, 80], "1951": [13, 63, 72], "195228": 76, "1953": [19, 21, 28, 40, 42, 49, 58, 78, 80], "19536": [20, 41, 79], "1954": [28, 49, 58, 87], "1954400510": 63, "1955": [13, 63, 72], "195564": [24, 45, 83], "1957": [28, 49, 58, 87], "1959": [12, 32, 63, 71], "19591": [24, 45, 54, 83], "1960": [13, 63, 72], "1962": [28, 49, 58, 87], "1963": [19, 40, 78], "196385": [23, 44, 53, 82], "196442": 40, "1965": [13, 63, 72], "196599": [21, 42, 80], "1966": [21, 42, 80], "196717": 88, "196739": [30, 51, 60, 89], "1968": [12, 32, 71], "196963": 64, "1970": [18, 21, 30, 39, 42, 51, 60, 77, 80, 89], "197083": 14, "197087": 29, "1971": 63, "1972": [21, 42, 80], "1975": 63, "197500": 34, "197617": 54, "197649": [24, 45, 54, 83], "1977": [12, 31, 32, 71, 90], "19777": [22, 23, 43, 44, 52, 53, 81, 82], "19781": [30, 51, 60, 89], "197884": 65, "1979": 67, "198": [54, 88, 93], "198127": [21, 42, 80], "1982": 54, "1984": [21, 42, 80], "1985": [21, 42, 80], "198585": 59, "1986": 63, "198629": 88, "198645": [31, 61, 90], "1987": [12, 13, 32, 63, 71, 72], "1989": [12, 32, 71], "198924": [16, 36, 75, 76], "199": [12, 15, 20, 32, 35, 41, 68, 71, 74, 79], "1990": [15, 18, 19, 39, 40, 74, 77, 78], "1991": [13, 22, 43, 52, 63, 72, 81], "1992": [30, 51, 60, 89, 93], "1993": [21, 42, 80], "199364": [20, 41, 79], "1994": [12, 32, 71], "199412": [61, 64, 90], "199413": [15, 19, 40, 74, 78], "1995": 54, "19966": [16, 24, 36, 45, 75, 76, 83], "1997": [18, 19, 39, 40, 63, 77, 78], "199771": [23, 44, 53, 82], "1_000_000_000": 78, "1d": [29, 50, 59, 61, 65, 88], "1e": [19, 21, 40, 42, 78, 80, 99], "1e3": [19, 40, 78, 99], "1e4": [19, 40, 78], "1h": [16, 24, 36, 45, 54, 75, 76, 83], "1st": [8, 20, 22, 23, 30, 41, 43, 44, 51, 52, 53, 60, 67, 79, 81, 82, 89, 100], "1stflrsf": [21, 23, 42, 44, 53, 69, 80, 82, 91], "1v": 94, "1v2": 94, "1v3": 94, "2": [1, 4, 7, 8, 9, 10, 22, 23, 24, 28, 29, 30, 43, 44, 45, 49, 50, 51, 52, 58, 59, 60, 63, 64, 65, 67, 68, 70, 81, 82, 83, 87, 88, 89, 92, 93, 94, 103], "20": [1, 4, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 52, 53, 54, 55, 57, 58, 61, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 90, 93, 94, 95, 97, 98, 102, 103], "200": [12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 26, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 47, 49, 50, 52, 54, 56, 59, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 85, 87, 88, 91, 96, 97, 98, 99, 100], "2000": [15, 19, 20, 21, 22, 23, 24, 29, 35, 38, 40, 42, 43, 44, 45, 50, 52, 53, 54, 59, 65, 67, 74, 78, 79, 80, 81, 82, 83, 88, 92, 94, 99], "200000": [19, 30, 40, 78, 89, 102], "200000e": 63, "2003": [54, 63], "200326e": [21, 42, 80], "2004": [21, 42, 63, 80], "200458": 64, "200475": [20, 41, 79], "2005": 63, "2006": [21, 23, 42, 44, 53, 80, 82, 91], "2007": [21, 23, 30, 42, 44, 63, 80, 82, 89, 91, 102], "2008": [21, 23, 30, 42, 44, 53, 63, 80, 82, 89, 91, 102], "200876": [17, 37, 76], "20087625": [17, 37, 76], "2009": [21, 23, 30, 42, 44, 63, 80, 82, 89, 91], "200978": [15, 35, 74], "200k": 100, "201": [1, 15, 35, 74, 103], "2010": [21, 23, 30, 38, 42, 44, 67, 80, 82, 89], "20113": [16, 36, 75, 76, 98], "2012": [8, 16, 19, 36, 40, 75, 78, 103], "2013": [28, 30, 49, 58, 63, 87, 89, 102], "201332": [26, 47, 85], "2014": [12, 22, 30, 32, 43, 52, 63, 71, 81, 89], "20140521t000000": 63, "20140623t000000": 63, "20141013t000000": 63, "20141015t000000": 63, "20141209t000000": 63, "2015": [29, 30, 50, 51, 59, 60, 63, 88, 89, 102], "20150116t000000": 63, "20150218t000000": 63, "20150223t000000": 63, "20150225t000000": 63, "20150630": [30, 89, 102], "2016": [8, 29, 30, 50, 51, 59, 60, 88, 89], "20160101": [30, 51, 60, 89], "2017": [23, 30, 44, 53, 82, 89, 102], "201810": [20, 41, 79], "201862": [24, 45, 54, 83], "202": [1, 15, 35, 74, 76, 103], "2020": 93, "2022": [30, 51, 60, 89], "202247": 64, "2022w2": [12, 32], "2023": [1, 30, 51, 60, 89], "2024": [0, 1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 100, 101, 102], "20248": [16, 36, 75], "2024w1": [0, 10, 12, 88], "2024w2": [10, 12, 29, 32, 50, 59], "2025": [1, 53, 54, 55, 56, 57, 58, 59, 60, 61], "20274": [30, 51, 89], "20277493": 65, "202775": 65, "202839": [20, 41, 79], "203": [1, 15, 35, 74, 103], "20310": [30, 51, 60, 89], "20311": [24, 45, 83], "20319": [30, 51, 60, 89], "203265": [23, 44, 82], "20334": [30, 51, 60, 89], "203421": [21, 42, 80], "203500": [16, 36, 75], "20357847293371834": [18, 39], "20357847293371892": 77, "204": [1, 13, 14, 15, 34, 35, 40, 72, 73, 74, 78, 87, 96, 103], "204000": 19, "204167": [14, 34, 73], "2043": [31, 90], "204302": [30, 89, 102], "20433": [24, 45, 54, 83], "204583": [14, 34, 73], "2046": 76, "204600": [15, 19, 40, 74, 78], "204692": [21, 42, 80], "204734": [20, 41, 79], "20485": [30, 51, 60, 89], "205": [13, 14, 15, 34, 35, 53, 65, 72, 73, 74, 93, 96], "205000": [16, 21, 23, 36, 42, 44, 53, 75, 76, 80, 82, 91, 98], "205059": [24, 45, 54, 83], "20509": [30, 51, 60, 89], "20514": [30, 51, 89], "205144": [24, 45, 83], "205323": [30, 89, 102], "205470": 31, "205479": [18, 39, 77], "205527": 31, "205597": [21, 42, 80], "20564": [30, 51, 60, 89], "205839": 29, "206": [13, 14, 15, 19, 20, 34, 35, 40, 72, 73, 74, 78, 79, 92, 96], "206019": 64, "206041": 82, "206073": [20, 41, 79], "206099": [19, 40, 78], "20620": [30, 51, 60, 89], "206292": [16, 36, 75], "20639": [24, 45, 54, 83], "2064": [16, 36, 75], "20640": [18, 24, 39, 45, 54, 77, 83], "206724": [31, 61, 90], "20683258": [18, 39, 77], "20694": [30, 51, 60, 89], "206962": 50, "20699": 63, "207": [13, 14, 15, 16, 19, 29, 34, 35, 36, 40, 50, 59, 72, 73, 74, 75, 78, 87, 88, 96], "207039e": [21, 42, 80], "2071": [24, 45, 54, 83], "207814e": [21, 42, 80], "2079": 63, "20794": [30, 51, 60, 89], "208": [13, 14, 15, 18, 19, 22, 34, 35, 39, 40, 43, 72, 73, 74, 77, 78, 96], "2081": 54, "20870": 54, "208990e": 21, "209": [12, 13, 14, 15, 19, 32, 34, 35, 40, 71, 72, 73, 74, 78, 96], "209221": 91, "209583": 73, "209746": [20, 41, 79], "209903": [24, 45, 54, 83], "209978": 41, "20analysi": [31, 61, 90], "20assumpt": [31, 61, 90], "20hazard": [31, 61, 90], "20intro": [31, 61, 90], "20learn": [29, 50, 59, 88], "20lifelin": [31, 61, 90], "20with": [31, 61, 90], "21": [1, 12, 13, 15, 16, 17, 20, 21, 24, 25, 27, 28, 30, 32, 33, 34, 35, 36, 37, 41, 42, 45, 46, 48, 49, 51, 54, 55, 57, 58, 60, 63, 65, 71, 72, 74, 75, 76, 79, 80, 83, 84, 86, 87, 89, 93, 102, 103], "210": [19, 40, 78], "210000": 14, "210001": [20, 41, 79], "210240": [40, 78], "210272": [24, 45, 54, 83], "210286": 64, "210417": 34, "210591": [16, 36, 75, 76], "210779": [30, 89], "21086181023099465": [18, 39], "21086181023099526": 77, "210954": 29, "211": [19, 40, 78], "2110": [16, 36, 75], "211250": [14, 34, 73], "211343": [24, 45, 54, 83], "211429": 50, "211544": [20, 41, 79], "211724": 64, "211892": [16, 36, 75, 76], "211946": 29, "212": [1, 14, 19, 40, 52, 73, 78, 103], "212385": [23, 44, 53, 82], "212405e": 21, "212581": [24, 45, 54, 83], "21274": [30, 51, 60, 89], "212870": [21, 42, 80], "212975": [21, 42, 80], "213": [14, 19, 29, 30, 40, 50, 51, 59, 60, 78, 88, 89], "2130": [12, 32, 71], "21353": [30, 51, 60, 89], "21382972": 81, "21389": [30, 51, 60, 89], "213896": 63, "2139": [16, 36, 75, 76, 98], "214": [12, 19, 32, 40, 71, 76, 78], "21405": [30, 51, 60, 89], "21413528": [22, 43], "21436": 63, "2144": [19, 40, 78], "21450": 63, "214740": [16, 36, 75], "214769": 88, "214821": [30, 51, 89], "214852": [20, 41, 79], "2149": [61, 65], "215": [19, 40, 78], "2150": [61, 65], "2151": [61, 65], "215167": 64, "2152": [61, 65], "215227": 60, "215245": [21, 42, 80], "2153": [61, 65], "21530": [30, 51, 60, 89], "2154": [61, 65], "215412": [21, 42, 80], "21549": [30, 51, 60, 89], "2155": [61, 65], "215573": 19, "2156": [61, 65], "215641": 59, "21571": [30, 51, 60, 89], "21581": [30, 51, 89], "21582031": [28, 49, 58, 87], "215865": [23, 44, 82], "21596": [30, 51, 60, 89], "216": [19, 40, 78], "21603": [30, 51, 60, 89], "21605": [30, 51, 60, 89], "21608": 63, "21609": 63, "21610": 63, "21611": 63, "21612": 63, "216123": [31, 61, 90], "21613": [13, 63, 72], "21616484": 94, "21617": [30, 51, 60, 89], "2162": 54, "216250": 34, "216346": [23, 44, 53, 82], "21634631": [23, 44, 53, 82], "216585": [16, 36, 75], "216596": [30, 89, 102], "21668": [30, 51, 60, 89], "21670": [30, 51, 60, 89], "216718": [20, 41, 79], "216728": [16, 36, 75], "21694": [30, 51, 60, 89], "21697": [30, 51, 60, 89], "217": [52, 65, 92], "2170": [13, 63, 72], "217083": 14, "217334": [17, 37, 76], "21733442": [17, 37, 76], "2173627": [28, 49, 58, 87], "21739617": 52, "217417": 19, "217500": 14, "21767954": [23, 44, 53, 82], "21768": [22, 23, 30, 44, 51, 53, 60, 82, 89], "217680": [23, 43, 44, 52, 81, 82], "21774": [30, 51, 89], "218": [17, 37, 65], "218207": [16, 36, 75, 76], "21847": [30, 51, 60, 89], "21872": [21, 23, 42, 44, 80, 82, 91], "218760": [23, 44, 53, 82], "218830": [16, 36, 75], "218867": 64, "219": [24, 45, 54, 65, 83], "2190": [16, 36, 75], "219141": 53, "2192": [19, 40, 78], "219500e": 63, "219512": [24, 45, 54, 59, 83], "219700": [24, 45, 54, 83], "219714": 64, "21972656": [28, 49, 58, 87], "219845e": [21, 42, 80], "22": [15, 16, 19, 20, 21, 22, 23, 24, 28, 30, 31, 35, 36, 40, 41, 42, 43, 44, 45, 49, 51, 52, 53, 54, 58, 60, 61, 65, 74, 75, 76, 78, 79, 80, 81, 82, 83, 87, 89, 90, 93, 94, 98, 102, 103], "220": [65, 73], "2200": 65, "22001": [23, 53, 82], "220392": [31, 61, 90], "22057": [30, 51, 60, 89], "2206": [31, 61, 90], "22078": [30, 51, 60, 89], "221": 65, "2210": [12, 32, 63, 71], "221070": 54, "22114": [30, 51, 60, 89], "221329": [21, 42, 80], "221348": [30, 89, 102], "2214": 93, "22154": [30, 51, 60, 89], "221622": [16, 36, 75, 76], "22168237": 94, "221720": 19, "221760": 64, "22187945": 52, "221900": [13, 63, 72], "222": [1, 65, 103], "22219": [30, 51, 60, 89], "22221894": [21, 42, 80], "222222": [16, 36, 75], "22225": [30, 51, 60, 89], "222307": [16, 36, 75], "222500": [34, 73], "22260": [30, 51, 60, 89], "222647": [21, 23, 42, 44, 53, 80, 82, 91], "22283835": [22, 43], "2229": [18, 39, 77], "222963e": [42, 80], "223": [43, 65], "22305705": 81, "22320": [30, 51, 60, 89], "223333": [34, 73], "223460": [31, 61, 90], "223750": [34, 73], "223804": [23, 53, 82], "224": [19, 29, 40, 50, 59, 65, 78, 88], "224012": 50, "224072": 67, "224258": 29, "22452": [30, 51, 60, 89], "2246468746": 73, "224662": [21, 42, 80], "22471154513694652": [18, 39], "22471154513694713": 77, "224865": [21, 23, 42, 44, 53, 80, 82], "224887": 40, "225": [29, 50, 59, 88], "225301e": [21, 42, 80], "2254": [16, 36, 75], "22550": [30, 51, 60, 89], "225646": 67, "226": [19, 23, 40, 53, 78], "226111": 54, "226415": [16, 36, 75], "226789": [31, 61, 90], "2268": [22, 43, 52, 81], "22697768": [17, 37, 76], "226978": [17, 37, 76], "227": 50, "2270": [40, 78], "227143": [16, 36, 75], "2272": [20, 79, 92], "227289": 31, "227304": [30, 89], "22741": [24, 45, 83], "227559": [21, 23, 42, 44, 80, 82, 91], "227836": [20, 41, 79], "22788": [30, 51, 60, 89], "228": [29, 50], "228053": 29, "22811601": [18, 39, 77], "22826": [30, 51, 60, 89], "228329": [20, 41, 79], "2285": [30, 89], "22851562": [28, 49, 58, 87], "228603": [21, 42, 80], "228750": [14, 34, 73], "229": [29, 50, 59, 88], "229000": [16, 36, 75], "22910": [30, 51, 60, 89], "229102": [23, 44, 53, 82], "229167": 14, "2293467570951035": 81, "2295": [30, 89], "229583": [14, 34, 73], "229718": [23, 44, 82], "22974": [28, 49, 58], "23": [1, 15, 16, 18, 19, 20, 21, 24, 28, 30, 31, 35, 36, 39, 40, 41, 42, 45, 49, 51, 54, 58, 60, 61, 63, 65, 74, 75, 76, 77, 78, 79, 80, 83, 87, 89, 90, 98, 102], "230": [15, 19, 40, 74, 78], "2300": [12, 32, 71], "230000": 63, "2300778984319707": [22, 43], "23011": [23, 44, 82], "230412": 53, "2305": [23, 44, 82], "2307": [14, 18, 34, 39, 73, 77], "23087929": [22, 43], "2309": [30, 89], "23091772": 81, "231": [1, 103], "2310": [30, 63, 89], "2311": [30, 89], "2312": [30, 89], "2313": [30, 89], "23175": [30, 51, 60, 89], "231815": [23, 44, 53, 82], "23182687": 52, "232": 65, "232075": 64, "232143": 76, "232751": [31, 61, 90], "23290": [30, 51, 60, 89], "233": [13, 63, 72], "2334": 16, "234": [31, 61, 90], "234040": [20, 41, 79], "234303": 63, "234436": [61, 90], "234648": 54, "235": [24, 45, 54, 65, 83], "235096": [16, 36, 75, 76], "235152": [15, 35, 74], "23529412": 50, "235417": 73, "235706": [24, 45, 54, 83], "235833": 14, "236": [15, 19, 31, 40, 61, 65, 74, 78, 90], "2360": 63, "236096": 88, "236174": [24, 45, 83], "236210": [25, 46, 84], "23621041": [25, 46, 84], "23640124": [18, 39, 77], "236456": [16, 36, 75], "23654": [20, 23, 41, 44, 79, 82], "236960": [40, 78], "237": [20, 31, 61, 65, 79, 90], "237895": 79, "237935": [23, 44, 82], "238": [20, 31, 41, 61, 65, 79, 90], "238192": [20, 23, 41, 44, 79, 82], "2388": 63, "2389": 76, "239": [31, 61, 65, 90], "23902": [30, 51, 60, 89], "239082": 64, "239323": [28, 49, 58], "23941": [30, 51, 60, 89], "239676": 67, "239944e": [21, 42, 80], "24": [1, 10, 12, 15, 16, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 35, 36, 41, 42, 43, 44, 45, 49, 50, 51, 52, 53, 54, 58, 59, 60, 61, 64, 65, 70, 71, 74, 75, 79, 80, 81, 82, 83, 87, 88, 89, 90, 102], "240": [31, 61, 90], "2401": [24, 45, 54, 83], "240602": 59, "240893": [24, 45, 83], "241": [31, 61, 90], "241363": 50, "241489": [31, 61, 90], "241620": [20, 41, 79], "24182": [30, 89], "242015": [22, 23, 43, 44, 52, 53, 81, 82], "242083": 73, "242169": [20, 41, 79], "24220": 54, "242208e": 21, "242381": [30, 89], "242740": 64, "24295676": [17, 37, 76], "242957": [17, 37, 76], "242996": [16, 36, 75, 76], "243": [30, 50, 51, 60, 89], "2431": 16, "24313726": 50, "243243": [21, 42, 80], "243447": [23, 44], "2435": [24, 45, 83], "2436": [24, 45, 83], "24395": [22, 23, 43, 44, 52, 53, 81, 82], "24397122221206388": [30, 89], "244": [30, 51, 60, 89], "244344": 31, "244592": [15, 35, 74], "2447": [22, 43, 52, 81], "244814": [31, 61, 90], "245": [30, 51, 60, 89], "2451": [19, 40, 78], "245329": [21, 42, 80], "245521": [20, 41, 79], "245635": 64, "245686": [20, 41, 79], "246": [30, 51, 60, 89], "246332": [21, 42, 80], "246486": 65, "246646": [19, 40, 78], "246646103936": [19, 40, 78], "246653": [40, 78], "247": [30, 51, 60, 89], "247119": [30, 89], "2471338": 67, "247439": [25, 46, 84], "24743939": [25, 46, 84], "247563": 59, "247596": [22, 43], "247690828913": [19, 40, 78], "247691": [19, 40, 78], "248": [30, 51, 60, 89], "2483": 67, "248328": 81, "248333": [34, 73], "2484": [12, 32, 71], "248400": 52, "248457": [21, 23, 42, 44, 53, 80, 82, 91], "248609": [21, 42, 80], "248664": [24, 45, 83], "2487200875": 63, "2488": [15, 35, 74], "248999": [31, 61, 90], "249": 93, "249044e": 21, "2496": [14, 18, 34, 39, 73, 77], "249601e": [21, 42, 80], "249618e": [21, 42, 80], "249720": [15, 35, 74], "249807": 53, "24h": [20, 79, 92], "24th": [12, 32], "25": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 56, 58, 60, 61, 63, 65, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102], "250": [52, 61], "2500": [8, 65, 93], "250000": [16, 19, 20, 21, 36, 41, 42, 63, 75, 79, 80], "25031": [30, 51, 60, 89], "25037": [30, 51, 60, 89], "250588": 65, "2506": [13, 14, 34, 72, 73, 96], "250900": [21, 42, 80], "251": 61, "251093": [40, 78], "251158e": [21, 42, 80], "251484": 59, "2516": [22, 43, 52, 81], "2517": [54, 67], "25176": [30, 51, 60, 89], "251769": 88, "252": [61, 92], "252042": [24, 45, 54, 83], "25214": [30, 51, 60, 89], "252160": [15, 35, 74], "2523": 54, "252859": 82, "253": 61, "2530": [12, 32, 71], "253188": 54, "2533": [14, 18, 34, 39, 73, 77], "253312": [16, 36, 75, 76], "253432": [23, 44, 82], "253724": [15, 35, 74], "253914": [21, 42, 80], "254": [19, 61], "254380": 90, "254443": [20, 41, 79], "25490198": 50, "25498295": 65, "254983": 65, "255": [16, 36, 64, 75], "2550": 63, "2551": 93, "255134": 88, "255165": [31, 61], "2556": [22, 43, 52, 81], "255751": [24, 45, 83], "255889": [30, 89, 102], "256": [12, 29, 32, 50, 59, 71, 88], "25622": [30, 51, 60, 89], "256263": [22, 23, 43, 44, 52, 53, 81, 82], "256333": [16, 36, 75], "256437": [24, 45, 83], "25658": [24, 45, 83], "256813": [15, 35, 74], "257": [13, 63, 72], "2570": [12, 13, 32, 63, 71, 72], "257024": [19, 40, 78], "257103": [20, 41, 79], "2574": [24, 45, 54, 83], "257787": 65, "2580": [12, 32, 71], "258225": [30, 51, 89], "25823": [20, 41, 79], "258387": [23, 44, 53, 82], "2584": 87, "258427": [15, 35, 74], "25882354": 50, "258886": 79, "258891": 60, "258897": 50, "258921": 59, "259": [21, 24, 42, 45, 54, 80, 83], "259026": 64, "25904": [30, 51, 60, 89], "2590575478171857": 39, "2590575478171884": [18, 77], "259085": 64, "259286": [15, 35, 74], "259500": [16, 36, 75], "259520": 64, "25m": 29, "26": [1, 8, 12, 15, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 35, 36, 40, 41, 42, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 58, 60, 61, 65, 71, 74, 75, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 102], "2600": [16, 36, 75, 76, 98], "260145": 67, "260258": [24, 45, 54, 83], "26048": [23, 44, 53, 82], "260572": [21, 42, 80], "26063": [30, 51, 60, 89], "260890": [21, 23, 42, 44, 53, 80, 82, 91], "261": 31, "261035": [21, 42, 80], "261775": 29, "261953": [30, 89, 102], "262": [21, 23, 42, 44, 53, 80, 82, 90, 91], "262079e": [21, 42, 80], "262156e": [21, 42, 80], "262269e": [21, 42, 80], "2623": [21, 42, 80], "262361": [24, 45, 83], "262500": [21, 42, 80], "263": [21, 42, 80], "2630": [16, 36, 75], "263000018": 63, "26307": [28, 49, 58], "263328": 19, "263541": [31, 61, 90], "263600": [16, 36, 75], "26370005": [18, 39, 77], "263736": [61, 90], "263742e": [21, 42, 80], "26376": [30, 51, 60, 89], "264": 22, "264042": 67, "264195": 90, "264283e": [21, 42, 80], "26447953": [17, 37, 76], "264480": [17, 37, 76], "265": 81, "265273": [18, 39, 77], "265483": 64, "265634": 59, "266120": [30, 89, 102], "266135": [16, 36, 75, 76], "266673": 50, "266702": 50, "2670": [40, 78], "267209": 19, "267612e": [21, 42, 80], "268": [19, 40, 78], "268171": 50, "2683": [20, 41, 79], "26831": [30, 51, 60, 89], "2691": [13, 14, 34, 72, 73, 96], "26919": [24, 45, 54, 83], "269347": 31, "269689": 79, "269880": [15, 35, 74], "269972": [21, 23, 42, 44, 53, 80, 82, 91], "27": [1, 8, 15, 16, 17, 19, 20, 21, 28, 30, 31, 35, 37, 40, 41, 42, 49, 51, 58, 60, 61, 63, 65, 74, 76, 78, 79, 80, 87, 89, 90, 102], "270093": [19, 40, 78], "270093376167": [19, 40, 78], "27021": [30, 51, 60, 89], "270270": [27, 48, 57, 86], "27048": [20, 41, 79], "2705": [19, 40, 78], "271037": [24, 45, 54, 83], "271287": [30, 89], "271476": 29, "271500": [24, 45, 54, 83], "271738e": [21, 42, 80], "2720": [13, 63, 72], "27206": [30, 51, 60, 89], "27263": [23, 53, 82], "272667": [16, 36, 75, 76], "2727": 54, "2730": [16, 36, 75], "27304": 63, "273382": [16, 36, 75, 76], "273573": 59, "273606": [16, 36, 75, 76], "273890": 88, "2739": [33, 64], "273962": [24, 45, 54, 83], "274": [16, 30, 36, 51, 60, 75, 76, 89, 98], "274223": 59, "274404": [16, 36, 75], "274730": 29, "275008": [30, 89, 102], "27502379069": 80, "27502379092": 21, "27502379118": 42, "275290": [20, 41, 79], "275352": [15, 35, 74], "275410": [18, 39, 77], "2759": [23, 44, 82], "276": [16, 36, 75], "27610132": 58, "27610135": [28, 49, 87], "27638": [30, 51, 60, 89], "27652": [20, 41, 79], "276687": [21, 42, 80], "27676": [20, 79, 92], "27678": [20, 79, 92], "276784": 31, "276943e": [21, 42, 80], "27697": [20, 79, 92], "277": 43, "2770": [40, 78], "27705": [20, 79, 92], "27715": [20, 79, 92], "277381": [15, 35, 74], "277384": 31, "2777": [31, 61, 90], "2784314": 50, "278441": [30, 89, 102], "278634": [20, 79], "27874871715903093": 77, "27874871715903127": [18, 39], "278755": [17, 37, 76], "27875502": [17, 37, 76], "2788": [14, 18, 34, 39, 73, 77], "27901526": 67, "2794": [18, 39, 77], "28": [1, 15, 16, 18, 19, 20, 21, 24, 25, 28, 30, 31, 35, 36, 39, 40, 41, 42, 45, 46, 49, 51, 54, 55, 58, 60, 61, 74, 75, 76, 77, 78, 79, 80, 83, 84, 87, 89, 90, 102], "280": [16, 24, 36, 45, 54, 75, 83, 93], "2800": 8, "280028": [24, 45, 54, 83], "280310": [16, 36, 75, 76], "2806": [19, 40, 78], "280618": [20, 41, 79], "2807": [31, 61, 90], "280801": [31, 61, 90], "281": [16, 36, 44, 75], "28100": 54, "281180": 31, "28122025532": 21, "28122025543": [42, 80], "281583": [21, 42, 80], "2817": [23, 44, 53, 82], "2820": 78, "282021e": [21, 42, 80], "2822": [23, 44, 82], "282600": [31, 61, 90], "283119e": [21, 42, 80], "28327": [30, 51, 60, 89], "283421": [21, 42, 80], "2836": [23, 44, 82], "28362": [30, 51, 60, 89], "283857": [15, 35, 74], "283921": [16, 36, 75], "284": [24, 30, 45, 51, 54, 60, 67, 83, 89], "2845": [31, 90], "2846": 93, "2847": 93, "285": [16, 30, 36, 51, 60, 75, 76, 89, 98], "285263": [23, 44, 53, 82], "28526302": [23, 44, 53, 82], "285467": [21, 23, 42, 44, 53, 80, 82, 91], "28571429": [13, 33, 72], "286": [14, 15, 19, 30, 34, 40, 51, 60, 73, 74, 78, 89], "286000": [40, 78], "286200": [24, 45, 83], "286326": 64, "286416": 76, "2865025": 94, "286821": [15, 35, 74], "287": [30, 51, 60, 61, 89], "287031": [30, 89, 102], "287079e": [42, 80], "287344": [16, 36, 75, 76], "287372": 29, "287500": [24, 45, 54, 83], "28753559": [28, 49, 58, 87], "288": [30, 51, 60, 61, 89], "288002": [30, 89, 102], "288462": [18, 39, 77], "28854": [30, 51, 60, 89], "28868": [20, 41, 79], "289": [30, 51, 60, 61, 89], "2890": [15, 19, 40, 74, 78], "289269": [23, 44], "28953": [30, 51, 60, 89], "289541": [21, 23, 42, 44, 80, 82, 91], "289799": [15, 35, 74], "289942": 50, "29": [8, 15, 16, 20, 21, 28, 30, 31, 35, 36, 41, 42, 49, 51, 58, 60, 61, 63, 65, 74, 75, 79, 80, 87, 89, 90, 93, 102], "290": [30, 51, 61, 63, 89], "290002": [20, 41, 79], "2901961": 50, "290424": [21, 42, 80], "29045704": [21, 42, 80], "290961e": [21, 42, 80], "291": [18, 30, 39, 51, 61, 63, 77, 89], "291310100": 63, "291667": [27, 48, 57, 86], "292": [30, 51, 61, 89], "292530": 54, "292587": [61, 90], "292621": 59, "293": [30, 51, 61, 89], "29324459": [29, 50, 59, 88], "293663": [20, 41, 79], "294": [16, 23, 28, 36, 49, 52, 58, 61, 75, 87], "2940": 61, "2941": 61, "294157": 41, "2942": 61, "294251": [17, 37, 76], "2943": 61, "2944": 61, "2945": 61, "2946": 61, "2947": 61, "2948": [16, 36, 75, 76, 98], "294855": [23, 44, 53, 82], "295": 61, "295193": 64, "2953863599856858": [18, 39], "2953863599856862": 77, "295397": [20, 41, 79], "29545": [21, 42, 80], "2957": 65, "29572402": [28, 49, 58, 87], "2958": 65, "2959": 65, "296": [16, 36, 61, 75, 93], "2960": 65, "2961": 65, "2961559258": 61, "2962": 65, "2963": 65, "2964": 65, "296601": [24, 45, 54, 83], "29691": [30, 51, 60, 89], "297": [18, 39, 61, 77], "298": 61, "29802": [20, 23, 41, 44, 79, 82], "298043": 64, "298436": 64, "298561": [31, 61, 90], "298612": [30, 89, 102], "29881": [30, 51, 60, 89], "298813": 79, "299": [29, 50, 59, 61, 63, 88], "299164": [24, 45, 83], "299504": 59, "2d": [29, 33, 50, 59, 61, 65, 88], "2d454e5fd9a5": [31, 61, 90], "2e": 1, "2f": [14, 19, 27, 30, 34, 38, 40, 48, 51, 57, 60, 66, 67, 73, 78, 86, 89], "2m": [29, 50, 59], "2m7m0lw97rvf654x1cwtdfmr0000gr": 36, "2nd": [67, 77], "2ndflrsf": [21, 23, 42, 44, 53, 69, 80, 82, 91], "2v": 94, "2v3": 94, "3": [1, 7, 8, 10, 15, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 35, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 57, 58, 59, 60, 64, 65, 66, 67, 68, 69, 70, 74, 76, 77, 78, 79, 80, 81, 82, 86, 87, 88, 89, 91, 92, 93, 94, 95, 103], "30": [1, 4, 12, 14, 15, 18, 20, 21, 22, 23, 24, 28, 30, 31, 32, 34, 35, 39, 41, 42, 43, 44, 45, 49, 51, 52, 53, 54, 58, 60, 61, 65, 69, 71, 73, 74, 77, 79, 80, 81, 82, 83, 87, 89, 90, 91, 93, 102, 103], "300": [15, 26, 28, 35, 47, 49, 56, 58, 61, 74, 85, 87, 91, 94], "3000": [29, 50, 59, 65, 88], "300000": [16, 19, 30, 36, 75, 76, 89, 102], "3000000": [28, 49, 58, 87], "300464": [24, 45, 54, 83], "300837": [20, 41, 79], "301": [31, 43, 61, 90], "3010": [24, 45, 54, 83], "301200": [19, 40, 78], "3014": [24, 45, 54, 83], "30146": [30, 51, 60, 89], "301563": [21, 42, 80], "30167": [30, 51, 60, 89], "301784": [61, 90], "3018": 103, "301838": 91, "3019": [13, 14, 18, 34, 39, 72, 73, 77, 96], "301952": [24, 45, 54, 83], "301997": 31, "302": [21, 23, 42, 44, 53, 61, 80, 82, 91], "302043": 64, "302131": [21, 42, 80], "302470": 29, "302679": 31, "30279": [30, 51, 60, 89], "302801": [31, 61, 90], "302844": [61, 90], "303": [21, 23, 42, 44, 53, 61, 80, 82, 91], "303000": [16, 36, 75], "303004": [24, 45, 54, 83], "303030": [18, 39, 77], "303109": [17, 37, 76], "303161": 67, "303694": 64, "303790": 78, "3038": 93, "3038344082": [53, 82], "303916": [15, 35, 74], "304": [15, 35, 61, 74], "3040": [30, 89], "3041": [30, 89], "3042": [30, 89], "3043": [30, 89], "304358": 67, "3044": [30, 89], "304784": [21, 42, 80], "305": [12, 32, 61, 71], "30504657": [25, 46, 84], "305047": [25, 46, 84], "30530902": [15, 35, 74], "305346": [15, 35, 74], "305674": [24, 45, 83], "3057": [14, 18, 34, 39, 73, 77], "30573": [24, 45, 54, 83], "305851": 67, "306": [61, 93], "306500": [15, 35, 74], "306564": 88, "306768": 59, "307": [16, 36, 75], "3075": 93, "307516": 88, "307521": [18, 39, 77], "307565": 59, "307920": 59, "30792853": [28, 49, 58, 87], "30798381": [28, 49, 58, 87], "308": 52, "308120": [16, 36, 75], "30815": [21, 42, 80], "308216": 88, "308220": 79, "308236": 64, "308448": [15, 35, 74], "308506": 54, "3089": [19, 40, 78], "308900e": 63, "309": [24, 45, 54, 61, 83], "3092": [13, 14, 34, 72, 73, 96], "309249": 88, "309859": [18, 39, 77], "30am": 12, "30pm": 1, "31": [12, 15, 16, 18, 20, 21, 22, 23, 25, 28, 30, 31, 32, 35, 36, 39, 41, 42, 43, 44, 46, 49, 51, 52, 53, 54, 55, 58, 60, 61, 63, 71, 74, 75, 76, 77, 79, 80, 81, 82, 84, 87, 89, 90, 93, 98, 102], "310000": [16, 36, 75], "31000e": [15, 74], "310284": [23, 44, 82], "31029469": 65, "310295": 65, "31038074": [28, 49, 58, 87], "310405": [20, 41, 79], "311": [16, 36, 75], "3110": [16, 36, 75], "31103996": 67, "311151": [31, 61, 90], "31127015": [23, 44, 53, 82], "311310": [12, 32, 71], "311769": [24, 45, 54, 83], "3119640638146517": [18, 39], "31196406381465247": 77, "3120": [16, 36, 75], "3125": [16, 36, 75], "312500": [16, 27, 48, 57, 86], "312501": [21, 23, 42, 44, 53, 80, 82, 91], "312696": 93, "3129": 93, "31297381": [17, 37, 76], "312974": [17, 37, 76], "31298589e": [29, 88], "31298590e": [50, 59], "313": [21, 42, 76, 80], "3130": 93, "313157": 29, "31384": [20, 41, 79], "314": [16, 36, 43, 75], "3140": [16, 36, 75], "314000": [40, 78], "31449687e": [23, 44, 53, 82], "31454": [24, 45, 54, 83], "314582": [23, 44, 82], "314840": [24, 45, 54, 83], "314929": [30, 89, 102], "315000": 63, "315134": [30, 89, 102], "315630": [20, 41, 79], "316164": [24, 45, 54, 83], "316230": [24, 45, 83], "31634363": [28, 49, 58, 87], "316363": [15, 35, 74], "316395e": [21, 42, 80], "316426": [24, 45, 83], "316552": [17, 37, 76], "31655231": [17, 37, 76], "316798": [24, 45, 54, 83], "317": [1, 16, 19, 23, 36, 44, 61, 75, 82, 103], "317005": 41, "317277": [24, 45, 54, 83], "317334": 54, "31767136668453344": 63, "317761": [20, 41, 79], "318": [16, 36, 61, 75], "3180": [40, 78], "3180174485124284": [16, 36, 75], "318937": [16, 36, 75, 76], "319": [13, 16, 17, 36, 37, 61, 63, 72, 75], "31908384": [29, 50, 59, 88], "3193": 54, "319481": 64, "319559": 63, "319630": [31, 61, 90], "31984311": [21, 42, 80], "31st": [30, 51, 60, 89], "32": [8, 15, 16, 18, 19, 21, 25, 28, 30, 31, 35, 36, 39, 40, 42, 46, 49, 51, 54, 55, 58, 60, 61, 64, 65, 70, 74, 75, 76, 77, 78, 80, 84, 87, 89, 90, 98, 102], "320": [16, 36, 61, 75], "320155": [20, 41, 79], "3202": 54, "320430": [21, 42, 80], "32064171": 81, "3209427041566191": 63, "321": [61, 82], "321050": 63, "3210656": 52, "32112113": [22, 43], "32127053": [21, 42, 80], "322": [24, 45, 54, 61, 83], "32240": [22, 23, 43, 44, 52, 53, 81, 82], "322465": 63, "32247597e": [23, 44, 53, 82], "322585": 67, "322755": [15, 35, 74], "323045": [16, 36, 75, 76], "32323": [12, 32, 71], "323612": 41, "32397724e": [23, 44, 53, 82], "324": 52, "3245": [12, 71], "324762": 64, "325000": 63, "3252": [24, 45, 54, 83], "325288": 29, "325319": [24, 45, 54, 83], "32561": [20, 41, 79], "326": [16, 24, 36, 45, 75, 83], "326616": 63, "326730": [20, 41, 79], "326741e": [61, 90], "326911": 67, "326933": [15, 19, 40, 74, 78], "327037": 31, "327188": [20, 41, 79], "327195": 54, "3272": [31, 61, 90], "327283": [21, 42, 80], "32734": [24, 45, 54, 83], "3274": [31, 61, 90], "327408": [20, 41, 79], "32791718": [28, 49, 58, 87], "328": [24, 45, 54, 83], "328000": 63, "328077e": [21, 42, 80], "328799": 79, "328944": 67, "328953": [15, 35, 74], "3298721": [29, 50, 59, 88], "3299": [87, 93], "33": [8, 12, 15, 16, 18, 19, 20, 21, 24, 28, 30, 31, 32, 35, 36, 39, 40, 41, 42, 45, 49, 54, 58, 61, 63, 71, 74, 75, 76, 77, 78, 79, 80, 83, 87, 89, 90, 102], "330": [9, 10, 13, 29, 30, 33, 51, 60, 65, 71, 72, 88, 89, 91, 93, 103], "33000e": [15, 74], "330237": 59, "330346": [31, 61, 90], "330942": 41, "330_vs_340": 12, "3310": [16, 36, 75], "331588": 64, "33191802": [28, 49, 58, 87], "332008": 29, "332095": 56, "332125": 79, "332130": [21, 42, 80], "33223002": [28, 49, 58, 87], "3322447": [28, 49, 58, 87], "33224516": [28, 49, 58, 87], "33224759": [28, 49, 58, 87], "332271": 59, "332671": [23, 44, 82], "3327": [30, 89], "332710": [21, 42, 80], "332746": [31, 61, 90], "332791": [61, 90], "332824": [21, 42, 80], "333": 65, "3330": [16, 36, 75], "33308783": [17, 37, 76], "333088": [17, 37, 76], "333139": [20, 41, 79], "333333": [13, 16, 19, 27, 33, 36, 40, 48, 57, 64, 72, 75, 78, 86], "3333333333333333": [27, 29, 48, 50, 57, 59, 86, 88], "333340": [15, 35, 74], "3334": 93, "33380649": [28, 49, 58, 87], "33380754": [28, 49, 58, 87], "33380761": [28, 49, 58, 87], "33381373": [28, 49, 58, 87], "33394593": [28, 49, 58, 87], "3339473": [28, 49, 58, 87], "33394769": [28, 49, 58, 87], "33395626": [28, 49, 58, 87], "33397112": [28, 49, 58, 87], "334": [24, 45, 83], "33400489": [28, 49, 58, 87], "33411086": [28, 49, 58, 87], "33425967": [28, 49, 58, 87], "33435326": [28, 49, 58, 87], "33439238": [28, 49, 58, 87], "33440682": [28, 49, 58, 87], "334411": [15, 35, 74], "334576": [21, 42, 80], "33462759": [28, 49, 58, 87], "334764": 64, "33476534": [28, 49, 58, 87], "335": 81, "335049": 50, "335309": [21, 42, 80], "3355": [16, 36, 75, 76, 98], "335649": 41, "3356700488_183566145b": [29, 50, 59, 88], "335702": 29, "33590": [30, 51, 60, 89], "336": 22, "336389": 82, "33641142": [23, 44, 53, 82], "3364114233677307": [23, 44, 53, 82], "336411423367732": [23, 44, 53, 82], "33643394": 65, "336434": 65, "336735": [19, 40, 78], "336826": [17, 37, 76], "33682642": [17, 37, 76], "33683087": [18, 39, 77], "336831": [18, 39, 77], "337034": 83, "33726089": [21, 42, 80], "33732465": [28, 49, 58, 87], "337625": 64, "33782315": [28, 49, 58, 87], "33797555": [28, 49, 58, 87], "338": [15, 19, 40, 74, 78], "33888659": 8, "339": [20, 41, 68, 79], "339368": [31, 61, 90], "339889": [61, 90], "34": [12, 15, 16, 18, 20, 21, 24, 28, 30, 31, 32, 35, 36, 39, 41, 42, 45, 49, 51, 54, 58, 60, 61, 65, 71, 74, 75, 76, 77, 79, 80, 83, 87, 89, 90, 98], "340": [1, 3, 13, 22, 24, 29, 30, 31, 33, 43, 45, 50, 51, 52, 54, 59, 60, 61, 72, 81, 83, 88, 89, 90], "34000e": [15, 74], "340480": 67, "340988": [20, 41, 79], "341028e": 40, "341109": [21, 42, 80], "341300": [24, 45, 54, 83], "341556": 67, "341571": [31, 61, 90], "34161762": [21, 23, 42, 44, 53, 80, 82], "341712": [30, 89, 102], "34182": [23, 53, 82], "3420": [16, 36, 75], "342200": [24, 45, 54, 83], "342605e": [21, 42, 80], "3436": [30, 89, 102], "343676": 41, "3437": 93, "3438": 93, "343943": 53, "344": [16, 36, 75], "3442": [31, 61, 90], "34426571": [21, 42, 80], "34441": [21, 42, 80], "345": [23, 44, 53, 82], "345136": [15, 35, 74], "345386e": [21, 42, 80], "3454": [31, 61, 90, 93], "3455": 93, "345831": [12, 32, 71], "345835": 41, "346": [16, 36, 63, 75, 76, 98], "346279": 59, "346850": [20, 41, 79], "34691": [30, 89], "346926": 29, "347001": 67, "347523": [19, 40, 78], "348": [16, 24, 36, 45, 75, 83], "34806": [21, 42, 80], "348283": 50, "348569": 91, "34900": [21, 42, 80], "34924955": [28, 49, 58, 87], "35": [15, 16, 18, 20, 21, 22, 23, 28, 30, 31, 35, 36, 39, 41, 42, 43, 44, 49, 52, 53, 58, 61, 63, 74, 75, 77, 79, 80, 81, 82, 87, 89, 90, 93, 97, 101, 102], "350": [12, 32, 71], "3500": [65, 97], "350000": [16, 36, 75], "351": 19, "351351": [27, 48, 57, 86], "351366": [20, 41, 79], "3515": [31, 61, 90], "3517": 93, "3518": 31, "351821": [31, 61, 90], "351883": 91, "3520": 90, "352062": 53, "3521": [12, 32, 71], "352100": [24, 45, 54, 83], "352114": [23, 44], "3529": 61, "352930": [16, 36, 75, 76], "353": [1, 19, 29, 50, 59, 88, 103], "353211": 29, "35375221": 94, "353957": 54, "353961": [19, 40, 78], "354114": [21, 23, 42, 44, 80, 82, 91], "354448": 29, "354467": 50, "354604": [20, 41, 79], "3547": [24, 45, 54, 83], "354759e": [21, 42, 80], "35561437": [28, 49, 58, 87], "356689": [22, 23, 43, 44, 52, 53, 81, 82], "35671794": [23, 44, 82], "356959": 54, "357": [16, 36, 75], "3573886": [28, 49, 58, 87], "357500": [16, 36, 75, 76], "357509": 50, "3576": [12, 32, 71], "3577": 93, "35771821": [28, 49, 58, 87], "357823": [12, 32, 71], "358": [12, 19, 32, 40, 71, 78], "358000": 19, "358032": 82, "3582": [31, 61, 90, 93], "358264": [21, 23, 42, 44, 80, 82, 91], "3583": 93, "358333": [15, 35, 74], "358500": [24, 45, 54, 83], "358896": 29, "358913": [17, 37, 76], "3589134": [17, 37, 76], "359": [15, 19, 40, 74, 78], "3590": [19, 40, 78], "359784": [19, 40, 78], "359887": [25, 46, 55, 84], "359992": [15, 35, 74], "35p": [12, 32, 71], "36": [15, 16, 18, 19, 20, 21, 22, 23, 24, 28, 30, 31, 35, 36, 39, 40, 41, 42, 43, 44, 45, 49, 51, 52, 53, 54, 58, 60, 61, 63, 65, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 87, 89, 90, 102], "360": [1, 76, 103], "360000": 63, "360172": 79, "360918": [30, 89, 102], "361": [31, 61, 90], "361622": 40, "361718": [20, 41, 79], "362": [31, 61, 63, 90, 93], "362009": [30, 51, 60, 89], "362185e": [21, 42, 80], "362553": [24, 45, 54, 83], "36269995": [17, 37, 76], "362700": [17, 37, 76], "362861": 59, "363": [31, 61, 90], "363192": [15, 35, 74], "363758": 54, "363913": [20, 41, 79], "363928": 29, "364": [30, 31, 51, 60, 61, 89, 90], "364352": [18, 39, 77], "364995": 61, "364998": [23, 44], "365": [30, 51, 60, 89], "3650": 19, "36525": [23, 53, 82], "365420": 93, "365603": [18, 39, 77], "365623": [15, 35, 74], "365898": 64, "365925": 64, "366": [17, 30, 31, 37, 51, 60, 61, 76, 89, 90], "366005": [20, 41, 79], "366071": 16, "3663": [31, 90], "366626": [15, 35, 74], "36695134": [28, 49, 58, 87], "367": [30, 51, 60, 89], "367329e": [61, 90], "367423": [19, 40, 78], "368": [30, 51, 60, 89, 93], "3681": [23, 44, 82], "368304": [18, 39, 77], "3684": [31, 61, 90], "368406": 65, "368922": [26, 47, 85], "369": [21, 42, 80], "369822": 67, "369875": [15, 35, 74], "369896": 88, "37": [16, 18, 21, 24, 28, 30, 31, 36, 39, 42, 45, 49, 51, 54, 58, 60, 61, 63, 65, 75, 76, 77, 80, 83, 87, 89, 90, 93, 98, 102], "37050406": 8, "370643": [20, 41, 79], "370842": 63, "371": [24, 30, 45, 54, 83, 89, 102], "3717": [23, 44, 82], "371722": [23, 53, 82], "372": [16, 36, 54, 75], "372572": 67, "372706": [30, 89, 102], "372763": [21, 23, 42, 44, 53, 80, 82, 91], "373031": [15, 35, 74], "373275": [30, 89, 102], "373318": 64, "373411": 63, "373623580": 65, "373656": [30, 51, 89], "373974": 60, "374": [16, 36, 75], "374584": 88, "37546": [23, 53, 82], "375836": 50, "375956": 50, "376": [16, 21, 36, 42, 65, 75, 80], "376089": [21, 42, 80], "37647072": 81, "37658964": [22, 43], "3768": 93, "3769": 93, "377": 52, "377032": [21, 42, 80], "377109": 31, "377619": [19, 40, 78], "377619120792": [19, 40, 78], "37797291": [17, 37, 76], "377973": [17, 37, 76], "37807203": [28, 49, 58, 87], "378159": [21, 42, 80], "378764": [15, 35, 74], "378971e": [21, 42, 80], "37903": 65, "37906": [20, 41, 79], "379416e": [21, 42, 80], "379793": 29, "379875e": [21, 42, 80], "38": [8, 15, 16, 18, 20, 21, 24, 28, 30, 31, 35, 36, 39, 41, 42, 45, 49, 51, 54, 58, 60, 61, 63, 74, 75, 77, 79, 80, 83, 87, 89, 90, 102], "3803": [31, 61, 90], "380436": [17, 37, 76], "38043616": [17, 37, 76], "380495": [15, 35, 74], "380504": [16, 36, 75, 76], "380643": [15, 35, 74], "380890e": 21, "381": 54, "381190": [24, 45, 54, 83], "3814": 76, "381416e": [61, 90], "381428": [21, 23, 42, 44, 53, 80, 82, 91], "381676": [15, 35, 74], "38192364": [25, 46, 84], "381924": [25, 46, 84], "382558": [20, 41, 79], "382733": 19, "3828": 54, "3828125": [28, 49, 58, 87], "382902": 29, "383": [16, 24, 36, 45, 54, 61, 75, 83], "384111": 93, "384127": [15, 35, 74], "384528": 64, "384613e": 78, "3851": [20, 41, 79], "3856": [15, 35, 74], "385639": [25, 46, 55, 84], "386": [19, 40, 78], "386071e": [21, 42, 80], "386467": 67, "3865": 54, "386530": [23, 44, 82, 91], "386772": 54, "386853": 31, "387": [19, 40, 78], "387502": 67, "388014": 67, "388023": [20, 41, 79], "388169": [24, 45, 54, 83], "38853": [21, 42, 80], "3889": 76, "389": [19, 24, 40, 45, 78, 83], "389065": [23, 44, 82], "389349": [24, 45, 83], "389655": 61, "389736": [16, 36, 75, 76], "39": [15, 19, 20, 21, 25, 28, 30, 35, 40, 41, 42, 46, 49, 51, 55, 58, 60, 74, 78, 79, 80, 84, 87, 89, 101, 102], "390428669205": [19, 40, 78], "390429": [19, 40, 78], "390691": 63, "390725": [21, 42, 80], "39095422e": [23, 44, 53, 82], "391": [16, 36, 75], "3912": [31, 61, 90], "391304": 63, "39163": [20, 41, 79], "391728": 20, "391892": 59, "391996": 88, "392": [12, 32, 71, 90], "392082": [23, 44, 53, 82], "392221": [18, 39, 77], "392385": [61, 90], "392612": [21, 42, 80], "392893": [15, 19, 40, 74, 78], "393": [13, 54, 63, 65, 72, 76], "3932": [31, 61, 90], "39375": [30, 51, 60, 89], "394": [22, 31], "394113e": [21, 42, 80], "394600e": 40, "394920": [16, 36, 75], "395": 54, "395282e": [21, 42, 80], "395686e": [21, 42, 80], "395688": [31, 61, 90], "395697e": [21, 42, 80], "396": [16, 31, 36, 61, 65, 75, 90], "396266": 88, "396752e": [21, 42, 80], "396991": [16, 36, 75, 76], "397": [31, 61, 90], "398": [24, 45, 54, 83], "398495": [30, 89, 102], "398915": 64, "39896994": [17, 37, 76], "398970": [17, 37, 76], "399": [16, 19, 36, 63, 75], "3990": [13, 14, 34, 72, 73, 96], "3991": [21, 42, 80], "39931": [23, 53, 82], "399827": [20, 41, 79], "39x15": [28, 49, 58, 87], "3blue1brown": [29, 50, 59, 88], "3d": [24, 29, 45, 50, 54, 59, 83, 88], "3f": [13, 14, 15, 16, 20, 21, 27, 28, 33, 34, 35, 36, 38, 41, 42, 48, 49, 54, 57, 58, 61, 66, 67, 68, 69, 72, 73, 74, 75, 79, 80, 86, 87, 93], "3h": [30, 51, 60, 89], "3m": 88, "3rd": [28, 49, 58, 67, 87], "3ssnporch": [21, 23, 42, 44, 53, 69, 80, 82, 91], "3v": 94, "4": [0, 1, 8, 9, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 68, 69, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 103], "40": [8, 12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 30, 31, 32, 35, 39, 40, 41, 42, 43, 44, 45, 47, 51, 52, 53, 54, 56, 60, 61, 64, 65, 69, 71, 74, 77, 78, 79, 80, 81, 82, 83, 85, 89, 90, 91, 97, 102, 103], "400": [13, 16, 19, 36, 40, 63, 72, 75, 78, 91, 99], "40000": [29, 30, 50, 59, 88, 89, 102], "400000": [16, 19, 30, 40, 63, 78, 89, 102], "400047": [31, 61, 90], "400157": [24, 45, 83], "400164": 88, "400649628005": [19, 40, 78], "400650": [19, 40, 78], "400881e": 63, "401": [15, 19, 40, 63, 74, 78], "4011": 87, "401102": [30, 89], "401541": [20, 41, 79], "401623": [21, 42, 80], "401729": 64, "4018": 103, "401830": [23, 44, 82], "401874": 59, "401895": [19, 40, 78], "402": [12, 32, 43, 71], "402101": 63, "402258": 63, "4024": [28, 49, 58], "402578": 29, "402808": [23, 44, 82], "404": [15, 24, 35, 45, 54, 74, 83], "405": [81, 103], "405227e": [21, 42, 80], "405415": [15, 35, 74], "405650": [21, 42, 80], "406": [29, 50, 59, 88], "406202": [19, 40, 78], "40689": [24, 45, 54, 83], "407": [20, 79], "40708132": [22, 43], "407234": 88, "40725012": [29, 50, 59, 88], "4074": 103, "407510": [20, 41, 79], "40756124": 81, "407862": [31, 61, 90], "4084": [31, 61, 90], "409": 103, "409430": 63, "40_000": [29, 50, 59, 88], "40b5a809b05a": [31, 61, 90], "41": [15, 16, 20, 21, 23, 24, 25, 27, 30, 31, 35, 36, 41, 42, 44, 45, 46, 48, 51, 54, 55, 57, 59, 60, 61, 74, 75, 79, 80, 82, 83, 84, 86, 89, 90, 102], "410": [16, 36, 75], "410240": [20, 23, 41, 44, 79, 82], "410599": [24, 45, 83], "410714": 16, "41128554": 52, "411412": [21, 42, 80], "41150573": [21, 42, 80], "411816e": 40, "412": [12, 15, 19, 32, 40, 71, 74, 78], "41210938": [28, 49, 58, 87], "412277": 29, "412500": [24, 45, 83], "413": 52, "413050": 88, "413232": 29, "413718": [31, 61, 90], "413796": [21, 42, 80], "413958": [20, 41, 79], "414": 93, "4143": [31, 90], "414405": 64, "415": 65, "4151": [22, 43, 52, 81], "4153": [24, 45, 83], "415383": 67, "4158382658": [36, 75], "415888": 67, "416": [43, 82], "4165": [22, 43, 52, 81], "4169": [31, 90], "417592": 20, "417982": 50, "418": [19, 28, 49, 58, 87], "418031": [15, 35, 74], "418069": [19, 40, 78], "41901484361": [19, 40, 78], "419015": [19, 40, 78], "419355": [18, 39, 77], "4195": [23, 44, 82], "4197": [13, 14, 18, 34, 39, 72, 73, 77, 96], "419973": 79, "42": [12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 64, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 94, 96, 97, 100, 101], "420": [40, 78], "420000": [12, 32, 71], "4203": [28, 49, 58], "42060": [24, 45, 54, 83], "420875": 29, "421": [29, 50, 59, 88], "42104086": [23, 44, 53, 82], "421215": [25, 46, 84], "42121526": [25, 46, 84], "421875": [18, 39, 77], "422": [21, 42, 80], "422201": 59, "422222": 16, "4234": [23, 44, 82], "4236": [23, 44, 53, 82], "4237": 53, "4238": [20, 79], "423852": [20, 41, 79], "424221": [21, 42], "424222": 80, "424337e": [21, 42, 80], "425": 81, "425047e": 40, "425365": [31, 61, 90], "42541681": 94, "425419": [21, 42, 80], "426067": [16, 36, 75], "426410": [15, 35, 74], "427": [31, 61, 90], "427516": 64, "4276": 92, "428": [19, 31, 61, 90], "428279": 64, "429": [21, 23, 42, 44, 80, 82, 91], "429217": [20, 41, 79], "429634": [31, 61, 90], "4296875": [28, 49, 58, 87], "43": [15, 18, 19, 20, 21, 30, 31, 35, 39, 40, 41, 42, 51, 60, 61, 74, 77, 78, 79, 80, 89, 90], "430": [21, 23, 31, 40, 42, 44, 61, 78, 80, 82, 90, 91], "430323": [16, 36, 75], "43049251": 52, "43049251280029016": 52, "430571": [20, 41, 79], "430704": [25, 46, 84], "4307043": [25, 46, 84], "430868": [18, 39, 77], "431": [31, 61, 73, 90], "4310": [15, 16, 19, 36, 40, 74, 75, 78], "431104": 64, "431137": [18, 39, 77], "4314": [20, 41, 79], "432": [31, 54, 61, 90], "433": [31, 61, 90], "433514": [30, 89, 102], "433814": [31, 61, 90], "434": [15, 18, 19, 31, 39, 40, 61, 74, 77, 78, 90], "43445": [24, 45, 54, 83], "435": [31, 61, 90], "435186": [15, 35, 74], "435489": [20, 41, 79], "435792": [19, 40, 78], "436": [31, 61, 90], "436492": [21, 42, 80], "43697758253484525": [18, 39], "43697758253484614": 77, "437": 93, "4372": [25, 46, 55, 84], "437367": [16, 36, 75, 76], "4375": [24, 27, 45, 48, 54, 57, 83, 86], "437500": [27, 48, 57, 86], "437684": [30, 51, 60, 89], "438": [27, 48, 57, 86], "438009": 29, "438231": 88, "438275": [17, 37, 76], "43827545": [17, 37, 76], "43833466": [21, 42, 80], "438592": [23, 44, 53, 82, 91], "438906": [23, 44, 82], "439": [16, 36, 75], "4390": [15, 19, 40, 74, 78], "439209": [20, 41, 79], "439254e": 65, "439360": [16, 36, 75], "439779": [20, 41, 79], "44": [14, 15, 16, 18, 20, 21, 24, 28, 30, 31, 34, 35, 36, 39, 41, 42, 45, 49, 51, 58, 60, 61, 73, 74, 75, 77, 79, 80, 83, 87, 89, 90, 93, 102], "440": [19, 30, 40, 51, 60, 78, 89], "440897": 63, "441": [21, 42, 80], "441404": 88, "441445": [24, 45, 54, 83], "441947": 54, "442": 63, "442377e": [21, 42, 80], "442806": [15, 35, 74], "442917": 64, "4430": [31, 90], "44311": [24, 45, 54, 83], "4432": [24, 45, 54, 83], "443317": [15, 35, 74], "443419": [21, 23, 42, 44, 80, 82, 91], "444297": [24, 45, 54, 83], "4443": 16, "444444": [16, 36, 75], "444497": 54, "4448": [24, 45, 54, 83], "445": [19, 40, 78], "445111e": [21, 42, 80], "445124e": [21, 42, 80], "445707": 54, "44586935": 81, "44586935141902073": 81, "44601557968639416": [22, 43], "44601558": [22, 43], "446216": [24, 45, 54, 83], "446284e": [21, 42, 80], "446869": [24, 45, 54, 83], "447": [16, 23, 36, 44, 54, 75, 82], "447461": [30, 89, 102], "447517": [23, 44, 53, 82], "447650": 61, "44787197": [28, 49, 58, 87], "4482": [12, 32, 71], "4484": [15, 35, 74], "448757": [31, 61, 90], "449": 93, "449262": 64, "449666": [15, 35, 74], "44966612": [15, 35, 74], "45": [8, 13, 14, 15, 16, 18, 20, 21, 28, 30, 31, 34, 35, 39, 41, 42, 49, 51, 58, 60, 61, 69, 72, 73, 74, 77, 79, 80, 87, 89, 90, 92, 96, 102], "450000": [27, 48, 57, 86], "450000e": 63, "450132": [30, 89, 102], "450739": [21, 42, 80], "450822": [24, 45, 54, 83], "451888": [20, 41, 79], "452600": [24, 45, 54, 83], "452765": 54, "453367": [24, 45, 54, 83], "4537": [31, 61, 90], "454427": [16, 36, 75, 76], "454677": [25, 46, 84], "45467725": [25, 46, 84], "454788": [23, 44, 82, 91], "454966": [20, 41, 79], "455": 76, "455026455026455": 65, "4552": [23, 44, 82], "455410": 67, "45555535": [23, 44, 82], "455652": 63, "45587": [30, 89, 102], "45588": [30, 89, 102], "45589": [30, 89, 102], "45590": [30, 89, 102], "45591": [30, 89, 102], "456": [29, 50, 59, 88], "456419": [24, 45, 54, 83], "45653693": [17, 37, 76], "456537": [17, 37, 76], "456904786": 93, "457435": [30, 89, 102], "45756": 93, "458": [16, 36, 75], "458063": 31, "458333": [27, 48, 57, 86], "458524": [31, 61, 90], "459": [21, 42, 65, 80], "4591": [16, 36, 75], "459214e": [21, 42, 80], "459873": 90, "459937": 87, "45a": [30, 89, 102], "45am": [30, 89, 102], "46": [8, 13, 14, 15, 16, 18, 20, 21, 30, 31, 34, 35, 36, 39, 42, 50, 51, 60, 61, 65, 72, 73, 74, 75, 76, 77, 79, 80, 89, 90, 93, 96, 98, 102], "460039": 29, "460047": [61, 90], "46019608e": [23, 44, 53, 82], "46021": 93, "46075": 93, "4608": [13, 14, 34, 72, 73, 96], "460950": [25, 46, 55, 84], "461": [16, 19, 36, 40, 75, 78], "462": 52, "462060": [61, 90], "462545": [23, 44, 82], "462963": [18, 39, 77], "46299": 93, "463": [20, 41, 79], "46357616": 65, "463582": [22, 43, 52, 81], "464": 44, "464104e": [42, 80], "465279e": [21, 42, 80], "46530779": [17, 37, 76], "465308": [17, 37, 76], "46534653465346537": 19, "466246": 88, "4664": [12, 32, 71], "466547": 50, "46666667": 65, "46729488": [21, 42, 80], "467379": [23, 44, 82], "467628": [24, 45, 54, 83], "467755": 61, "468": [15, 19, 23, 40, 44, 53, 74, 78, 82], "468232": [30, 89, 102], "4687": [24, 45, 83], "46880": 93, "468995": 64, "469": [16, 20, 36, 75, 79], "469383": [20, 41, 79], "4695": [20, 41, 79], "469571": [24, 45, 54, 83], "47": [1, 12, 13, 14, 15, 16, 18, 19, 21, 24, 32, 34, 35, 36, 39, 40, 42, 45, 54, 63, 71, 72, 73, 74, 75, 77, 78, 80, 83], "470": [16, 36, 75, 93], "4700": [40, 78], "470060": [21, 42, 80], "47058824": 59, "470666": [21, 42, 80], "471000": 63, "471032": [23, 44, 53, 82], "471111": 29, "472": [17, 37, 93], "47232": [28, 49, 58], "47242662": 94, "4726": [31, 61, 90], "472603": [21, 42, 80], "472790": [20, 41, 79], "473": [28, 43, 49, 58, 87], "473189": 61, "473691": [15, 35, 74], "474": [20, 43, 65, 79], "474552": [15, 35, 74], "47491": [20, 41, 79], "475": [19, 65], "475099": [23, 44, 82], "475540": [28, 49, 58, 87], "476": [13, 33, 65, 72], "4760": [40, 78], "47606": [24, 45, 54, 83], "476092": [21, 23, 42, 44, 53, 80, 82, 91], "476406": [23, 44, 53, 82], "476412": [25, 46, 84], "47641249": [25, 46, 84], "477": [19, 40, 65, 78], "477291": [24, 45, 54, 83], "47799": 93, "478": 65, "478060": [30, 89, 102], "47810154525386317": 65, "478358": 50, "47843137": 59, "478515": 64, "478582": 49, "479": 65, "479109": [15, 35, 74], "479132": [24, 45, 54, 83], "479773": [28, 49, 58, 87], "48": [13, 14, 15, 18, 20, 21, 30, 31, 34, 35, 39, 41, 42, 48, 51, 57, 60, 61, 72, 73, 74, 77, 79, 80, 86, 89, 90, 96, 102, 103], "480": [21, 42, 65, 80], "4800": [12, 32, 71], "480249": [15, 35, 74], "4806334": 87, "48073598": [25, 46, 55, 84], "4809": [19, 40, 78], "481": [16, 36, 65, 75], "4810": 92, "4813": [14, 18, 34, 39, 73, 77], "481484": 49, "481514": [21, 42, 80], "481793": [16, 36, 75], "481893": [20, 41, 79], "481960": [20, 41, 79], "482": 65, "4820": 63, "4822": [31, 90], "483": 65, "483317": 49, "483400": 50, "48344371": 65, "483751": [15, 35, 74], "48390": 93, "484": 65, "48407": 93, "484377": 59, "484937": [18, 39, 77], "485": [29, 50, 59, 65, 88], "485191": 64, "48535": 93, "4854": [23, 44, 82], "485722": [28, 49, 87], "486": [65, 82], "4861": [16, 36, 75, 76, 98], "486266": [16, 36, 75], "486664": [28, 49, 87], "487": [16, 36, 75], "487202": 49, "48721": 93, "487740": [28, 49, 87], "4879": 93, "488": [16, 36, 65, 75], "488163": [28, 49, 58, 87], "488753": [30, 89, 102], "489": 65, "489130": [18, 39, 77], "489593": [28, 49, 87], "49": [15, 16, 18, 20, 21, 24, 29, 30, 31, 35, 39, 41, 42, 45, 51, 54, 60, 61, 74, 77, 79, 80, 83, 89, 90, 101, 102], "490": [19, 24, 45, 65, 83, 94], "490000": [16, 36, 75], "490033": [21, 42, 80], "490568": [19, 40, 78], "490753": 58, "490797": [28, 49, 58, 87], "490930": [28, 49, 87], "491217": [20, 41, 79], "491366": [23, 44, 82, 91], "491379": [16, 24, 36, 45, 75, 83], "491968": [28, 49, 87], "492": [16, 20, 36, 75, 79], "492270": [17, 37, 76], "492307": [28, 49, 87], "492551": [28, 49, 58, 87], "493": [16, 36, 72, 73, 75], "493126": 58, "493489": [28, 49, 58, 87], "493544": [16, 36, 75], "493921": [17, 37, 76], "494": [15, 16, 19, 36, 40, 74, 75, 78], "4943": [19, 40, 78], "494309": 63, "495": 52, "495270": 58, "495524": 64, "49575": [20, 41, 79], "496": [24, 45, 54, 83], "496213": [21, 42, 80], "49668874": 65, "496757": [23, 44, 82], "497143": [28, 49, 87], "497386": [15, 35, 74], "497787": [21, 42, 80], "497949": [28, 49, 58, 87], "498": [19, 20, 22, 79, 92], "498133e": [21, 42, 80], "498164": 64, "498386": 49, "498499": 49, "498562": [15, 35, 74], "499900": [16, 36, 75], "4f": [15, 17, 20, 28, 35, 37, 38, 41, 49, 58, 66, 67, 68, 74, 76, 79, 87], "4m": 88, "4th": [20, 22, 23, 41, 43, 44, 52, 53, 67, 79, 81, 82, 100], "4x": 103, "5": [1, 4, 18, 19, 21, 22, 26, 27, 30, 38, 39, 40, 41, 42, 43, 45, 47, 48, 51, 52, 54, 56, 57, 60, 63, 64, 67, 68, 69, 70, 71, 77, 78, 80, 81, 85, 86, 89, 93, 94, 95, 96, 103], "50": [1, 12, 15, 16, 17, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 71, 74, 75, 76, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 99, 100, 102, 103], "500": [12, 14, 16, 20, 22, 23, 24, 32, 36, 38, 41, 43, 44, 45, 52, 54, 66, 67, 71, 75, 79, 81, 82, 83, 100], "5000": [12, 13, 32, 63, 67, 71, 72, 92], "50000": [30, 89, 102], "500000": [15, 16, 20, 21, 26, 30, 36, 41, 42, 47, 56, 63, 75, 76, 79, 80, 85, 89, 93, 102], "500000e": [19, 40, 63, 78], "500001": [16, 36, 75], "5002": [21, 42, 80], "500625": [15, 35, 74], "50062e": [15, 74], "500924": [16, 36, 75, 76], "501": [16, 36, 75, 93], "501071": 88, "501191": [28, 49, 87], "501250": [15, 35, 74], "501304e": [21, 42, 80], "5014": 12, "501540": 58, "501550": 58, "501835": 29, "501875": [15, 35, 74], "502351": 58, "5024752475247525": [40, 78], "502500": [15, 35, 74], "502705": 58, "502985": [20, 41, 79], "503": 67, "503000": [16, 36, 75], "503090": [20, 41, 79], "503125": [15, 74], "50325": 67, "503362": 49, "50350": 67, "503750": [15, 35, 74], "503807": [28, 49, 87], "504": [15, 24, 35, 45, 54, 67, 74, 83], "504018": 29, "504231": [61, 90], "504375": [35, 74], "504429": [17, 37, 76], "504644": [19, 40, 78], "50475372e": [23, 44, 53, 82], "504fde4fcf8": [31, 61, 90], "505000": 15, "505026": 63, "505180": [28, 49, 58, 87], "505335": [20, 41, 79], "505569": 50, "505592e": [21, 42, 80], "505625": [15, 35, 74], "5057": [21, 42, 80], "50596432e": 94, "506023": [22, 43, 52, 81], "506035e": [21, 42, 80], "506052": 67, "506079e": [21, 42, 80], "506084e": [21, 42, 80], "506211": [16, 19, 36, 40, 75, 78], "506250": 35, "506410": [18, 39, 77], "50666667": 65, "506875": [15, 35, 74], "507130": [19, 40, 78], "507359": [16, 19, 36, 40, 75, 78], "507500": [15, 74], "50774": [19, 40, 78], "507740": [16, 36, 75], "50775": [19, 40, 78], "507750": [19, 40, 78], "507752": [16, 19, 36, 40, 75, 78], "507995": [18, 39, 77], "508": [16, 21, 36, 42, 75, 80], "508125": [15, 35, 74], "508133": [16, 19, 36, 40, 75, 78], "508371": [19, 40, 78], "508534": [28, 87], "508741": [28, 49, 58, 87], "508750": 35, "50884": [24, 45, 54, 83], "508971": 20, "50899": [19, 40, 78], "509": 54, "509000": [12, 32, 71], "509001": [21, 42, 80], "509045": 63, "509317": [16, 19, 36, 40, 75, 78], "5098": [28, 49, 58, 87], "509859": [28, 49, 58, 87], "509930": [30, 89, 102], "50k": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "51": [15, 16, 19, 20, 21, 23, 25, 30, 31, 35, 36, 40, 41, 42, 44, 46, 51, 54, 55, 60, 61, 74, 75, 76, 78, 79, 80, 82, 84, 89, 90, 91, 98, 102], "5100": 63, "510000": [13, 15, 19, 40, 63, 72, 74, 78], "510421": [28, 49, 87], "510505": [28, 49, 58, 87], "5106": 93, "510625": 35, "510697e": 63, "5107": 63, "510723": 49, "510836": [19, 40, 78], "5109": [23, 44, 82], "511": 9, "5112": [13, 63, 72], "51137414e": [23, 44, 53, 82], "51143": [24, 45, 54, 83], "51150": [20, 41, 79], "511620e": [21, 42, 80], "5118": [23, 44, 53, 82], "511875": 35, "512": [29, 50, 59, 88], "5120": [12, 32, 71], "512000": [15, 19, 40, 74, 78], "512004": 49, "51226051": [25, 46, 55, 84], "5123": 87, "512319": [16, 36, 75], "512408": [21, 23, 42, 44, 53, 80, 82, 91], "512897": [15, 35, 74], "512x640": [29, 50, 59, 88], "513": [16, 36, 75], "5131": 87, "513125": 15, "513205": 59, "513333": 65, "513678": [31, 61, 90], "513750": 15, "514150": [28, 49, 87], "514155": [16, 21, 36, 42, 75, 76, 80], "514339": 29, "514347": [28, 87], "514598e": [21, 42, 80], "5146": [18, 39, 77], "514950": 65, "515000": 74, "515017": 59, "51503393": [17, 37, 76], "515034": [17, 37, 76], "515351e": [21, 42, 80], "515443": [23, 44], "5156": [16, 24, 36, 45, 75, 83], "515755": 65, "515848": [24, 45, 83], "516120": 59, "516199": [28, 87], "516394": [24, 45, 54, 83], "516556": 65, "516788": 64, "516858": [28, 87], "517273": [28, 49, 87], "517346": [20, 41, 79], "518018": 49, "518113": [28, 49, 58, 87], "519000": 63, "519029": [20, 41, 79], "519129": 64, "52": [15, 16, 18, 20, 21, 24, 30, 31, 35, 36, 39, 41, 42, 45, 51, 54, 60, 61, 74, 75, 77, 79, 80, 83, 89, 90, 93, 102], "520495": [28, 49, 87], "52061": [30, 89], "520700": [28, 87], "520765": 45, "520782": [28, 49, 87], "5208": [13, 63, 72], "520857": [20, 41, 79], "5209": [21, 42, 80], "5212": [21, 42, 80], "521284e": [21, 42, 80], "521567e": [21, 42, 80], "52156866": 59, "521578e": [21, 42, 80], "521743e": [21, 42, 80], "521772": [28, 87], "522": [21, 42, 80], "522563e": [21, 42, 80], "5227966": 87, "523595": [28, 49, 58, 87], "523684": [28, 49, 58, 87], "523754e": 19, "5238095238095238": [13, 33, 72], "52398": [24, 45, 83], "524": [13, 27, 33, 48, 57, 72, 86], "524364": [61, 90], "525": 65, "5253": [23, 44, 82], "525554": [24, 45, 83], "525757": [15, 35, 74], "526046": [28, 87], "526078": [16, 36, 75, 76], "526214": 82, "526442": 64, "526596": [24, 45, 83], "526602": [21, 42, 80], "526688": 50, "526783": 64, "5274": [31, 61, 90], "527500": [16, 36, 75], "528": [21, 42, 80], "5282": [31, 61, 90], "528403": [15, 35, 74], "52881619": [15, 35, 74], "529210": [20, 41, 79], "529388e": [21, 42, 80], "5294": [22, 43, 52, 81], "529412": [16, 36, 75], "52980132": 65, "53": [18, 21, 30, 39, 42, 51, 60, 61, 63, 77, 80, 89], "530052": [19, 40, 78], "530978": [20, 41, 79], "530991": 59, "531": 91, "5310": 16, "531116e": [21, 42, 80], "531192": 50, "531353": 88, "5315": [19, 40, 78], "53187": 92, "532030": 50, "532034": [21, 42, 80], "532694": 61, "533027": 64, "533333": 16, "53333336": 59, "533454": 88, "533498": [15, 35, 74], "534": 93, "534069": 67, "534114": [19, 40, 78], "534342": [24, 45, 54, 83], "5345": 63, "535": [16, 24, 36, 45, 54, 75, 83], "535014": [16, 36, 75], "53520104": [15, 35, 74], "535604": [16, 36, 75], "535622": [24, 45, 54, 83], "536362": [25, 46, 84], "53636249": [25, 46, 84], "537267": [16, 36, 75], "537732": [28, 49, 58, 87], "538000": [13, 63, 72], "538702": [15, 35, 74], "538816": [20, 41, 79], "5390": [20, 23, 41, 44, 79, 82], "5391": [16, 24, 36, 45, 75, 83], "539116": [30, 89, 102], "539258": 64, "539376": [61, 90], "539459": 93, "539965": 58, "539989": 63, "54": [21, 30, 31, 42, 51, 60, 61, 80, 89, 90, 101, 102], "540": [30, 51, 60, 89], "540000": [16, 36, 75], "540039": [28, 87], "540359": [24, 45, 54, 83], "541117": [21, 42, 80], "541347": [28, 49, 87], "541488": [24, 45, 54, 83], "54152": [20, 41, 79], "541667": 76, "541795": [20, 41, 79], "541916": 58, "542": 91, "542049": [23, 44], "54240": [20, 41, 79], "542624": [23, 44, 82], "542754": 58, "542873": [16, 36, 75, 76], "543297": [19, 40, 78], "543351": [23, 44, 53, 82], "543464": [28, 49, 87], "543678": 64, "544": [40, 78], "544079": 64, "544462": 82, "545": [21, 42, 80, 93], "546": [16, 36, 75], "5461": [21, 42, 80], "546150": 64, "546473": [18, 39, 77], "546610": [15, 35, 74], "54676006e": [23, 44, 53, 82], "547": [21, 40, 42, 78, 80, 82], "547090": [28, 87], "5471258278145695": 65, "547993": [20, 41, 79], "548831": [23, 44, 53, 82], "548849": 50, "549": [23, 93], "54901963": 59, "549475": 54, "54966887": 65, "549682": [20, 41, 79], "5498": [15, 35, 74], "549946": [28, 49, 58, 87], "55": [13, 14, 15, 18, 20, 21, 22, 23, 30, 31, 34, 35, 39, 41, 42, 43, 44, 51, 52, 53, 60, 61, 72, 73, 74, 77, 79, 80, 81, 82, 89, 90, 91, 96], "55000": 78, "550000": [16, 36, 40, 75, 76, 78], "550004": [22, 43, 52, 81], "550616": [20, 41, 79], "55101": [30, 89], "5513": [19, 40, 78], "5514": [22, 23, 43, 44, 52, 53, 81, 82], "5515": [31, 61, 90], "551579e": [42, 80], "551862e": [21, 42, 80], "551975": [21, 42, 80], "552": [16, 21, 36, 42, 75, 80], "552492": 63, "552721": [22, 43, 81], "553": 63, "553125": 15, "553965": [23, 44, 53, 82], "553979": [20, 41, 79], "55398442": [22, 43], "553984420313606": [22, 43], "5540": [31, 61, 90], "5541306485809793": 81, "55413065": 81, "554180": [30, 89, 102], "554463": [28, 87], "554621": [24, 45, 54, 83], "554823": 50, "5551": [18, 39, 77], "555180": 63, "555740": [15, 35, 74], "556352": 53, "5566": [16, 36, 75, 76, 98], "556716": 65, "557197": 88, "557242": [20, 41, 79], "557739": [21, 42, 80], "558": [21, 23, 24, 42, 44, 45, 54, 80, 82, 83, 91], "558564": [20, 41, 79], "55862988e": [23, 44, 53, 82], "55873324": [29, 50, 59, 88], "5588": [12, 32, 71], "558824": [20, 41, 79], "558889": [21, 42, 80], "559": [19, 21, 23, 40, 42, 44, 78, 80, 82, 91], "559284": 63, "56": [15, 20, 21, 30, 31, 35, 41, 42, 61, 74, 76, 79, 80, 89, 90, 101, 102], "560": 63, "560053": 63, "5601": 54, "560225": [16, 36, 75], "560625": 35, "560768": [21, 42, 80], "5609808539232339": 16, "560993e": 19, "561": [1, 15, 19, 23, 24, 40, 44, 45, 74, 78, 82, 83], "561467": [16, 36, 75, 76], "561602": [23, 44, 53, 82], "561645e": [21, 42, 80], "562112": [16, 36, 75], "5623061656951904": 49, "5623062252998352": [28, 87], "562712": [28, 49, 58, 87], "563": 1, "5630224174651539": 77, "5630224174651548": [18, 39], "5630921721458435": [28, 49, 87], "563125": 15, "563127": 29, "5631500400": 63, "563314": [21, 23, 42, 44, 80, 82, 91], "563467": [16, 36, 75], "5644": [21, 42, 80], "564483": [24, 45, 54, 83], "564631": 61, "56499": [28, 49, 58], "565": [24, 45, 54, 83], "5650": [13, 63, 72], "565062": [31, 61, 90], "56521734": 8, "565625": 35, "565679": [20, 41, 79], "565746": [61, 90], "565888": [16, 36, 75], "566": [16, 36, 75], "566092": [16, 36, 75], "566222": 88, "5667": [20, 41, 79], "567169": [31, 61], "567724": 88, "567856e": [21, 42, 80], "568": [29, 50, 59, 88], "568009": [15, 35, 74], "56804591": [21, 42, 80], "568125": 15, "568663": [21, 42, 80], "5690201394269164": 53, "5690201394302518": [23, 44, 82], "56902014": [23, 44, 82], "569375": 74, "5694": [24, 45, 54, 83], "5695074871997099": 52, "56950749": 52, "57": [15, 16, 20, 21, 23, 30, 31, 35, 36, 41, 42, 44, 51, 60, 61, 63, 74, 75, 76, 79, 80, 82, 89, 90, 91, 98, 102], "57000": [61, 90], "570015": [21, 42, 80], "570449": [20, 41, 79], "570473": [24, 45, 54, 83], "570599": 31, "570648": 67, "5707": [31, 61, 90], "570739": [24, 45, 54, 83], "571": [25, 46, 65, 84, 94], "571325": 59, "571431": [28, 49, 87], "571500": [24, 45, 54, 83], "571525": 29, "5717": 54, "571800": 63, "571875": 35, "571901e": [21, 42, 80], "571969": [24, 45, 54, 83], "572": 1, "572105": [15, 35, 74], "572500": 15, "572549": [16, 36, 75], "572962": [61, 90], "573": 94, "573050": [20, 41, 79], "573065": 29, "573125": 15, "573129": [21, 23, 42, 44, 53, 80, 82, 91], "5732": [20, 79, 92], "57333333": 65, "573542": [24, 45, 54, 83], "573818": [20, 41, 79], "574": 63, "57415": [30, 89, 102], "574260": [24, 45, 54, 83], "575000": [27, 48, 57, 86], "575043": 63, "575046357615894": 65, "57510": [24, 45, 83], "5755444169044495": [28, 49, 87], "575636": 65, "575907": [24, 45, 54, 83], "576": [16, 36, 53, 75], "57615894": 65, "57640869": [17, 37, 76], "576409": [17, 37, 76], "576921": [28, 49, 87], "577268": 50, "577500": 15, "578452": 64, "578523": [18, 39, 77], "578569": 64, "578654": [20, 41, 79], "578684": 53, "5789": [21, 42, 80], "579091": [24, 45, 54, 83], "579245": [28, 49, 87], "579432": [18, 39, 77], "579559e": [21, 42, 80], "57966": 22, "579660": [43, 52, 81], "5798": [22, 43, 52, 81], "57994": [20, 41, 79], "58": [13, 14, 15, 18, 21, 30, 31, 34, 35, 39, 42, 51, 60, 61, 72, 73, 74, 77, 80, 89, 90, 96], "580": [29, 50, 59, 88], "580302e": 63, "580311": 29, "5804311633110046": [28, 49, 87], "580539e": [21, 42, 80], "580625": 15, "581": [23, 44, 82], "5813": 63, "58137177": [17, 37, 76], "581372": [17, 37, 76], "5814": [12, 32, 71], "581597222222214": 58, "581687": [24, 45, 54, 83], "581787": 90, "582": [12, 22, 32, 43, 52, 71, 81], "582090": [20, 41, 79], "5824530124664307": 49, "5824530720710754": [28, 87], "582469": [21, 42, 80], "582570": 65, "583": 63, "583125": 15, "58387198": [25, 46, 84], "583872": [25, 46, 84], "583972": 64, "584": [16, 36, 75], "584615": [16, 24, 36, 45, 75, 83], "585": [16, 36, 75], "585157": 67, "585187": 65, "585513": [18, 39, 77], "5857": [31, 90], "586095": [16, 36, 75, 76], "586875": 35, "587773": [20, 41, 79], "588": [15, 19, 40, 74, 78], "588125": 74, "588235": [18, 39, 77], "588307": [16, 36, 75], "58871446": 52, "589": 19, "589286": 93, "59": [1, 12, 15, 16, 18, 21, 30, 31, 32, 35, 42, 61, 74, 80, 89, 90, 103], "590": 63, "590243": [28, 49, 58, 87], "59049": [20, 79], "59050": [20, 79], "590618": [24, 45, 54, 83], "590625": 15, "59082668": [17, 37, 76], "590827": [17, 37, 76], "591305": 50, "5915": 76, "591931": 29, "592": 93, "5921569": 59, "592401": [12, 32, 71], "59243876": 81, "592507": 64, "5925410985946655": [28, 49, 87], "592657": 50, "59291868": [22, 43], "59300": [24, 45, 83], "5931": [21, 42, 80], "593370": [21, 42, 80], "593508": [25, 46, 55, 84], "5938": [16, 36, 75], "594": [16, 36, 75], "5941": 63, "5944": 63, "594595": [15, 35, 74], "594982": [20, 41, 79], "594995": [20, 41, 79], "5950": [16, 36, 75], "595000": 35, "595427": 88, "595569e": [21, 42, 80], "595625": 15, "596088e": [42, 80], "596151": [24, 45, 54, 83], "596810": [15, 35, 74], "596864": [21, 42, 80], "596875": 35, "5970": [22, 43, 52, 81], "59700": [20, 79], "597015": [18, 39, 77], "59708": [20, 41, 79], "597161": 50, "597326": [20, 41, 79], "597555": [12, 32, 71], "597834": 59, "597924": [21, 23, 42, 44, 80, 82, 91], "598": [16, 36, 75], "598057": 65, "59810": [20, 41, 79], "598100": [18, 39, 77], "598149": [21, 23, 42, 44, 80, 82, 91], "598750": 74, "599": 93, "5993570685386658": [28, 87], "5993571281433105": 49, "599492": [18, 39, 77], "599860": [15, 35, 74], "599894": [30, 89, 102], "59pm": [12, 32], "5fin": [21, 42, 80], "5th": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "5unf": [21, 42, 80], "6": [1, 8, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 103], "60": [8, 12, 16, 20, 21, 23, 24, 25, 27, 28, 30, 31, 32, 36, 42, 44, 45, 46, 48, 49, 51, 54, 57, 58, 60, 61, 69, 71, 75, 79, 80, 82, 83, 84, 86, 87, 89, 90, 91], "600": [16, 18, 28, 36, 39, 49, 58, 75, 77, 87], "60000": [30, 89, 102], "600000": [14, 15, 19, 30, 35, 40, 73, 74, 78, 89, 102], "600193": [20, 41, 79], "60023631": [21, 42, 80], "600288": 64, "600625": 35, "600830": 54, "600k": [21, 42, 69, 80], "601": [19, 40, 78], "601042": [12, 32, 71], "601220": 24, "601504": [18, 39, 77], "601712": [20, 41, 79], "601790": [18, 39, 77], "602": [16, 36, 63, 75, 76, 98], "602000": [16, 36, 75], "602649": [15, 35, 74], "6028": [20, 41, 79], "602941": [20, 41, 79], "602954": [22, 43, 81], "603125": 35, "6031432151794434": [28, 49, 87], "60319915": 94, "603243": 63, "603684e": 78, "603739": 63, "603970": [61, 90], "604": [15, 35, 74], "6040": [15, 19, 40, 74, 78], "604000": [13, 63, 72], "604032": [20, 41, 79], "60429913": [21, 42, 80], "604320": [18, 39, 77], "604421": 67, "60455": [30, 89, 102], "604619": [18, 39, 77], "604797": [18, 39, 77], "6048": [30, 89], "604807": [61, 90], "60495488": [15, 35, 74], "605060": [20, 41, 79], "6051": [16, 36, 75, 76, 98], "605100": [18, 39, 77], "605101": [18, 39, 77], "605102": [18, 39, 50, 77], "605263": [15, 35, 74], "605364e": 19, "605625": 74, "605696": [18, 39, 77], "606": [16, 36, 75], "606061": [18, 39, 77], "6063088774681091": [28, 49, 58, 87], "606557": [18, 39, 77], "606567": [18, 39, 77], "606811": [19, 40, 78], "606875": 74, "606902": [18, 39, 77], "607062": [30, 89, 102], "607595": 59, "608": 61, "608050": [18, 39, 77], "608125": 74, "6082": [16, 36, 75], "608299": 52, "608468": [18, 39, 77], "608532": 88, "608565": [31, 61, 90], "60860": [16, 36, 75], "6086404323577881": 49, "6086405515670776": [28, 87], "609": [16, 36, 54, 61, 75], "6092": [12, 32, 71], "6093292236328125": [28, 58, 87], "6093292832374573": 49, "609375": 74, "60943": [20, 41, 79], "60k": [21, 42, 69, 80], "61": [15, 17, 18, 20, 21, 25, 30, 31, 35, 37, 39, 41, 42, 46, 54, 55, 61, 74, 76, 77, 79, 80, 84, 89, 90], "610": 61, "610000": 15, "610142": 64, "61029914": [21, 42, 80], "610407": [20, 41, 79], "610931": [26, 47, 85], "611": [61, 76], "611007": 88, "6111123561859131": [28, 49, 87], "611178": [30, 89, 102], "612": 61, "612349": [17, 37, 76], "61234944": [17, 37, 76], "6124": [31, 61, 90], "612500": 35, "612546": [20, 41, 79], "612621": [18, 39, 77], "612755": [15, 35, 74], "612998": 31, "613231": 65, "613507": [18, 39, 77], "613738": [19, 40, 78], "613738418384": [19, 40, 78], "614": [16, 36, 75], "61420598": [17, 37, 76], "614206": [17, 37, 76], "614567": [24, 45, 54, 83], "614872": 64, "614902": 50, "614940": 52, "615": [16, 36, 75], "615000": 35, "615124": [22, 43], "6154": [16, 24, 45, 54, 83], "615730": 81, "616": [19, 40, 78], "616099": [19, 40, 78], "6168": [13, 63, 72], "617234": 67, "617342": [61, 90], "617431": [26, 47, 85], "6176": [20, 41, 79], "617647": [20, 41, 79], "618": [16, 36, 75], "618000e": 63, "618012": [19, 40, 78], "6186580061912537": [28, 87], "6186580657958984": [49, 58], "618967": [28, 49, 58, 87], "619": [61, 93], "61912405": [23, 44, 82], "619375": 35, "62": [15, 16, 19, 20, 21, 30, 31, 35, 40, 41, 42, 51, 60, 61, 65, 74, 78, 79, 80, 89, 90, 102], "620": 61, "620726": 64, "621": 61, "6210": 63, "622": 61, "622255": [16, 36, 75], "622454": [19, 40, 78], "622500": [15, 74], "6226": [24, 45, 54, 83], "622612": [20, 41, 79], "622709": [18, 39, 77], "623": [19, 61], "623000": [16, 36, 75], "623012": 61, "62320": [30, 89], "62341036": [22, 43], "62352928": 81, "624": 61, "624049": [21, 42, 80], "6241": [12, 32, 71], "624375": 74, "624450e": [21, 42, 80], "624615": [21, 42, 80], "625": 61, "6250": [16, 36, 75], "625307": 54, "625387": [19, 40, 78], "6257": [31, 90], "626206": [21, 42, 80], "62657": [30, 89], "626875": 74, "62688064": [23, 44, 53, 82], "626946": 31, "627": 90, "6273": [19, 40, 78], "6275": [13, 14, 34, 72, 73, 96], "627722": [23, 44, 82], "627966": [16, 36, 75], "628032": [24, 45, 54, 83], "628139": [20, 41, 79], "62873917": [23, 44, 82], "629532": 52, "629792e": [21, 42, 80], "63": [15, 19, 20, 21, 30, 31, 35, 40, 41, 42, 51, 60, 61, 74, 78, 79, 80, 89, 90, 93, 102], "6303": [16, 36, 75, 76, 98], "6306": [16, 24, 36, 45, 75, 83], "630625": 15, "631122": 31, "631899": [61, 90], "632": 93, "6320": [18, 39, 77], "6320978999137878": 49, "6320979595184326": [28, 58, 87], "6322": [24, 45, 83], "632296": 64, "632353": [20, 41, 67, 79], "632786": [30, 89, 102], "63316788": 94, "63358": [28, 49, 58], "63362": [21, 42, 80], "633933424949646": [28, 49, 58, 87], "634397": [18, 39, 77], "634490": 76, "634686": [20, 41, 79], "634908": 29, "635": [16, 36, 75], "635200": [24, 45, 83], "635239": [16, 36, 75, 76], "635648": [18, 39, 77], "635815": [22, 43], "635831": 52, "636": [12, 16, 31, 32, 36, 61, 71, 75, 76, 90, 98], "636364": [16, 93], "636410": 81, "636849e": [21, 42, 80], "637": [29, 50, 59, 88], "637982": [15, 35, 74], "638169": [23, 44, 53, 82], "6389": [16, 24, 36, 45, 75, 83], "639": 31, "6391518364256": [31, 61, 90], "6392": [24, 45, 54, 83], "639754": [21, 42, 80], "64": [10, 15, 16, 18, 21, 29, 30, 31, 35, 39, 42, 50, 51, 59, 60, 61, 74, 77, 80, 88, 89, 90], "640": [19, 29, 40, 50, 59, 61, 78, 88, 93], "6400": [16, 36, 75], "640000": [20, 41, 79, 93], "640201": 41, "640266": [16, 36, 75, 76], "640625": 15, "640x480": [15, 35, 74], "641216": [30, 89], "6414100192": 63, "641538": [31, 61, 90], "641873": [21, 42, 80], "642071": 64, "642676": [30, 51, 60, 89], "642965": [20, 41, 79], "643": [40, 44, 78], "6431": [24, 45, 54, 83], "643311e": [21, 42, 80], "643315": 65, "643750": 15, "644106": [20, 41, 79], "644157": 50, "64417243": [29, 50, 59, 88], "644375": 35, "64454": [20, 41, 79], "644770": [26, 47, 85], "644886": 50, "6453951434878586": 65, "645519": [20, 41, 79], "6458": [13, 14, 34, 72, 73, 96], "645802": 56, "645963": [19, 40, 78], "646050": [23, 44, 82], "6464": [31, 61, 90], "646617": 91, "647796": [24, 45, 83], "648": [15, 16, 19, 36, 40, 74, 75, 78], "6480": [22, 43, 52, 81], "648195": [20, 41, 79], "648550": 88, "648555": 54, "649658": [23, 44, 53, 82], "64994": [30, 89, 102], "65": [13, 17, 21, 31, 37, 40, 42, 54, 61, 72, 76, 80, 90], "650": [20, 41, 79], "65000": [40, 78], "650000": [40, 78], "65000e": [15, 74], "65013704": [25, 46, 55, 84], "650743": 63, "6507517": 65, "650752": 65, "651": 63, "651250": 15, "65125032": 94, "6513": [23, 44, 82], "651359e": 63, "651446": [30, 89], "651875": 35, "65243": [21, 42, 80], "652487": [24, 45, 83], "6526853": [21, 42, 80], "652828": [19, 40, 78], "652986": [24, 45, 83], "653": [16, 36, 75], "653205": [19, 40, 78], "653205232272": [19, 40, 78], "653931e": 19, "654": [16, 36, 75], "65424895": [21, 42, 80], "654375": 35, "65486": 87, "655450": 29, "656297e": [21, 42, 80], "656349": [15, 35, 74], "656827": [20, 41, 79], "656873": 63, "657675": [24, 45, 83], "658047": [18, 39, 77], "658645": [18, 39, 77], "659056": [21, 42, 80], "66": [13, 14, 16, 18, 20, 21, 29, 30, 34, 36, 39, 41, 42, 50, 59, 72, 73, 75, 77, 79, 80, 88, 89, 96, 102], "6600060120": 63, "6601256728172302": [28, 87], "660125732421875": [49, 58], "660171": [15, 35, 74], "6604": [16, 36, 75, 76, 98], "660714": 76, "661023": [28, 49, 87], "662126": 52, "66214339": [15, 35, 74], "6622033": [28, 49, 58], "66221": [30, 89], "6622507572174072": [28, 49, 58, 87], "662450": [20, 41, 79], "662541e": [21, 42, 80], "662745": [16, 36, 75], "662853": [22, 43], "662879": 81, "66368": [23, 44, 53, 82], "663680": [21, 23, 42, 44, 53, 80, 82, 91], "6637": [31, 61, 90], "6638": [31, 61, 90], "663822": [23, 44, 53, 82], "6639": [31, 61, 90], "6639008522033691": 49, "6639009118080139": [28, 58, 87], "6641": [31, 61, 90], "6642": [31, 61, 90], "664207": [20, 41, 79], "6643": [31, 61, 90], "6644": [31, 61, 90], "6645": [31, 61, 90], "664625": [28, 49, 87], "664707": [18, 39, 77], "66473": [30, 89, 102], "665": [16, 36, 75], "665307": [28, 49, 87], "665351e": [21, 42, 80], "665625": 74, "665882": [22, 43, 52, 81], "666": [16, 36, 75, 76], "666166": [30, 89, 102], "6666666666666666": [29, 50, 59, 88], "666667": [14, 16, 27, 36, 48, 57, 73, 75, 86], "666754": 88, "667089e": 19, "667450": [30, 89], "668": [28, 49, 58, 87], "668457": 50, "668787": [15, 35, 74], "6688": [12, 32, 71], "66941678": 65, "669417": 65, "669614": [20, 41, 79], "669725": 79, "669805e": [21, 42, 80], "67": [13, 14, 17, 18, 20, 21, 30, 31, 34, 37, 39, 42, 51, 54, 60, 61, 72, 73, 76, 77, 79, 80, 89, 90], "67000": 31, "670344": [15, 35, 74], "6709133386611938": 49, "6709133982658386": [28, 87], "6709135174751282": 58, "671272e": 63, "6718650311": 42, "67186503136": 80, "67186503165": 21, "6731126308441162": [28, 58, 87], "673112690448761": 49, "673277": [19, 40, 78], "6733067729083665": 65, "6733849048614502": [28, 87], "673384964466095": [49, 58], "6734487414360046": [28, 49, 58, 87], "674": 65, "6744": [23, 44, 82], "674490": [19, 40, 78], "674721": 81, "675000": [12, 32, 71], "67501": [30, 89], "67512181": [21, 42, 80], "67562658": [17, 37, 76], "675627": [17, 37, 76], "675676": [27, 48, 57, 86], "675814": [15, 35, 74], "6759470198675496": 65, "676": 91, "676250": 74, "676373": 79, "67672595": [21, 42, 80], "677": [16, 36, 65, 75], "6770": 19, "677142858505249": 58, "6771429181098938": [28, 49, 87], "6772": [31, 61, 90], "677268": 90, "677567": 63, "677579": [15, 35, 74], "677601": [19, 40, 78], "677629": [15, 35, 74], "6778583526611328": [28, 49, 58, 87], "678": [15, 19, 40, 74, 78], "678000": 63, "678689": [18, 39, 77], "679240": 63, "679302": 52, "679478": [16, 36, 75], "679874": 54, "679877": [21, 23, 42, 44, 80, 82, 91], "68": [13, 14, 15, 17, 20, 21, 23, 25, 26, 30, 31, 34, 35, 37, 41, 42, 44, 46, 47, 51, 53, 55, 56, 60, 61, 72, 73, 74, 76, 79, 80, 82, 84, 85, 89, 90, 94, 102], "680000": [12, 32, 71], "680029571056366": [49, 58], "6800296306610107": [28, 87], "680657": [16, 36, 75], "681223": [15, 35, 74], "681428": 64, "681566": 67, "681716": [28, 49, 87], "682827": 54, "683015": [22, 43, 52, 81], "683171": [20, 41, 79], "68323": [19, 40, 78], "68339": [30, 89, 102], "684": 54, "684211": [15, 35, 74], "684447": [16, 36, 75], "684960": [16, 36, 75, 76], "685": [19, 63], "685006": 65, "685103e": [21, 42, 80], "68523": [30, 89], "685786": [22, 43, 52, 81], "6858": [18, 39, 77], "685841": 31, "686": [16, 36, 75], "686348e": [21, 42, 80], "687": [21, 42, 80], "687055": [20, 41, 79], "687307": [19, 40, 78], "687500": [14, 73], "687504": [28, 49, 87], "688": [19, 40, 78], "6880359361853475": 77, "6880359361853483": [18, 39], "688043475151062": [28, 49, 87], "6880435943603516": 58, "688135": [19, 40, 78], "688484": 63, "688620": [22, 43], "68896004": 67, "689338": [21, 23, 42, 44, 80, 82, 91], "69": [13, 14, 15, 17, 21, 25, 30, 31, 34, 35, 37, 42, 46, 51, 55, 60, 61, 72, 73, 74, 76, 80, 84, 89, 90, 102], "690": 93, "69027185e": [23, 44, 53, 82], "690402": [19, 40, 78], "690778": [23, 44, 82], "691241": [20, 41, 79], "691617": [28, 49, 87], "691640": [15, 35, 74], "691869": 59, "691877": [19, 40, 78], "691924": [25, 46, 84], "69192445": [25, 46, 84], "692131": 64, "692308": [16, 36, 75], "692500": 15, "693": [16, 36, 75], "6932538631346579": 65, "693498": [19, 40, 78], "693590": [17, 37, 76], "6938": [12, 30, 32, 51, 60, 71, 89], "693890": [30, 89], "693898": [30, 51, 60, 89], "693936": [17, 37, 76], "69393613": [17, 37, 76], "694": 65, "69411": [24, 45, 83], "694155": [15, 35, 74], "694334": [22, 43, 52, 81], "6950": [23, 44, 53, 82], "695532": [16, 36, 75], "695783": [28, 49, 87], "696": 65, "696034e": [21, 42, 80], "6962": [16, 36, 75], "6963": [23, 44, 82], "696373": [16, 36, 75], "696429": [20, 41, 79], "696712": [30, 51, 60, 89], "696859": [19, 40, 78], "696875": 74, "696970": [18, 39, 77], "69698010e": [23, 44, 53, 82], "697": [16, 24, 36, 45, 75, 83], "697248": [20, 41, 79], "6973": [16, 36, 75], "698": [16, 36, 75], "698125": 15, "698167": [30, 89, 102], "698192": 50, "698206": [21, 42, 80], "698384608345687": [19, 40, 78], "698385": [19, 40, 78], "6984": [24, 45, 54, 83], "698857": [19, 40, 78], "699224": [15, 35, 74], "6993": 63, "699706": 88, "699901396097971": [26, 47, 85], "699901396097973": 56, "6m": 29, "6th": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "6x6": 99, "7": [1, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 71, 72, 73, 74, 75, 76, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95], "70": [13, 14, 17, 20, 21, 25, 26, 30, 31, 34, 37, 42, 46, 47, 51, 53, 54, 55, 56, 60, 61, 63, 64, 67, 69, 70, 72, 73, 76, 79, 80, 84, 85, 89, 90, 91, 102], "70000": [30, 89, 102], "700000": [19, 30, 89, 102], "700000e": 63, "700855": [20, 41, 79], "701128": [30, 89, 102], "701173": [19, 40, 78], "701186e": [21, 42, 80], "70162085e": [23, 44, 53, 82], "7017": [31, 61, 90], "701863": [19, 40, 78], "702703": [15, 35, 74], "703406": [61, 90], "704": [15, 16, 21, 35, 36, 42, 74, 75, 80], "704099": [17, 37, 76], "7041": 87, "7042": [31, 90], "7043": [31, 90], "7046136400143138": 77, "7046136400143141": [18, 39], "70472": [24, 45, 54, 83], "704969": [19, 40, 78], "705000": [16, 36, 75], "7053": 54, "705470": [28, 87], "705471": 49, "705511": [19, 40, 78], "70560276": [17, 37, 76], "705603": [17, 37, 76], "70568": [21, 42, 80], "705696": [15, 35, 74], "705882": [14, 19, 34, 40, 73, 78], "70588235": [14, 34, 73], "705898": [24, 45, 83], "705995e": 61, "706": 76, "706128": [15, 35, 74], "706444": [20, 41, 79], "706489": 63, "706783": [17, 37, 76], "70678332": [17, 37, 76], "706966": [30, 89], "707681": [15, 35, 74], "707712": [31, 61, 90], "707850": 65, "707899": [25, 46, 84], "70789903": [25, 46, 84], "70799": [19, 40, 78], "708": [16, 19, 36, 40, 75, 76, 78, 81, 98], "708075": [19, 40, 78], "708527": [16, 36, 75], "7087": 19, "708954e": 21, "708978": [19, 40, 78], "709": 22, "709185": [15, 35, 74], "70978": [24, 45, 83], "709874": [19, 40, 78], "709880": [19, 40, 78], "709893": [30, 89], "7099": [24, 45, 54, 83], "71": [12, 13, 14, 17, 18, 20, 21, 25, 30, 31, 32, 34, 37, 39, 42, 46, 51, 55, 60, 61, 71, 72, 73, 76, 77, 79, 80, 84, 89, 90, 102], "710": 22, "710000": [16, 36, 75], "710031": [23, 44, 53, 82], "710526": [15, 35, 74], "710896": [20, 41, 79], "71096": [24, 45, 83], "711": [40, 76, 78], "711077": [16, 36, 75], "711086": [19, 40, 78], "711356": 63, "711717": [19, 40, 78], "711754": [16, 36, 75, 76], "711819": [28, 49, 58, 87], "711852": [24, 45, 54, 83], "71199006": [21, 42, 80], "712": [16, 36, 75], "712074": [19, 40, 78], "71219761": [17, 37, 76], "712198": [17, 37, 76], "712324": [19, 40, 78], "712402": [22, 43, 52, 81], "7129": [19, 40, 78], "7129300520": 63, "713": 76, "71327467": [21, 42, 80], "713733": 54, "714": [29, 50, 59, 88], "714077": [16, 36, 75, 76], "714286": [19, 40, 78], "714375": 35, "714402": 79, "714655": 20, "715072": 88, "71517": [19, 40, 78], "7153": [31, 61, 90], "715424": [19, 40, 78], "715456": 50, "715728": [20, 41, 79], "715845": 65, "715992": 88, "716157": [20, 41, 79], "716655": [19, 40, 78], "716657": [19, 40, 78], "716786": 59, "716792": [20, 41, 79], "716985": [15, 35, 74], "717289": [19, 40, 78], "717391": [19, 40, 78], "717829": [16, 36, 75], "718242": [19, 40, 78], "718266": [19, 40, 78], "718524": [30, 89], "71866979": [21, 42, 80], "718675": 61, "718750": 74, "7188": 76, "719": [12, 16, 24, 32, 36, 45, 71, 75, 83], "719056": [22, 43, 52, 81], "719146": 67, "719427e": [21, 42, 80], "719500": [15, 35, 74], "719747": [20, 41, 79], "719915905190645": 63, "72": [13, 14, 15, 20, 21, 30, 31, 34, 35, 41, 42, 51, 60, 61, 72, 73, 74, 79, 80, 89, 90, 96, 99], "720": 19, "7200": [19, 63], "720357": [30, 89, 102], "72036": [30, 89], "720497": [19, 40, 78], "720859": [16, 36, 75], "720893": [31, 61, 90], "720904": [30, 89], "72098474": 67, "7210": [13, 63, 72], "721006": [19, 40, 78], "721008": [19, 40, 78], "721250": 35, "7212512828409687": [18, 39], "7212512828409691": 77, "721616": [19, 40, 78], "721705": [16, 36, 75], "7218": [13, 14, 34, 72, 73, 96], "721818": [24, 45, 54, 83], "721917": 63, "721921": [16, 36, 75], "722": [16, 23, 36, 75], "722241": [19, 40, 78], "722249": [19, 40, 78], "722803": 63, "722873": 63, "723": [16, 36, 75], "72338": [28, 49, 58], "72345029": [21, 80], "7234503": 42, "723602": [19, 40, 78], "723613": [15, 35, 74], "723951": 63, "724068": 63, "7242": [13, 63, 72], "724410": 63, "724434": 67, "724458": [19, 40, 78], "724539": [30, 89, 102], "724891": [20, 41, 79], "725": [18, 39, 40, 77, 78], "7250894": 94, "726": [16, 20, 24, 36, 41, 45, 75, 79, 83], "726269": 64, "726412": [16, 36, 75, 76], "726441": 64, "726474": 88, "726573": [19, 40, 78], "726583": [19, 40, 78], "726634": [20, 41, 79], "726659": 63, "7266666666666667": 94, "726788": [21, 42, 80], "727014": [30, 89], "727198": [19, 40, 78], "727273": [15, 16, 35, 74], "727394": 31, "727554": [19, 40, 78], "7277854625841886": [61, 90], "727785462584189": 31, "727821": [19, 40, 78], "7278214718381631": [19, 40, 78], "727829": [19, 40, 78], "727992": 64, "728": [16, 20, 36, 41, 75, 79], "728235": [16, 36, 75, 76], "7283": [20, 41, 79], "728324": [20, 41, 79], "728777": [15, 35, 74], "729": [19, 40, 78], "729109": 93, "729143": [20, 41, 79], "7292": [24, 45, 54, 83], "729374": 63, "729814": [19, 40, 78], "73": [13, 14, 17, 18, 19, 20, 21, 26, 30, 31, 34, 37, 39, 40, 41, 42, 47, 51, 54, 56, 60, 61, 72, 73, 76, 77, 78, 79, 80, 85, 89, 90], "730": 61, "730025": 63, "730383": [20, 41, 79], "730704": 63, "7309347537642059": 40, "7309366767301886": 19, "731": 31, "731498": [31, 61, 90], "7315": [18, 39, 77], "7315558717766282": 78, "731572": [18, 39, 77], "731583": [15, 35, 74], "73183": 87, "732674": 31, "7328": [16, 36, 75], "732919": [19, 40, 78], "733102": [16, 36, 75, 76], "733199": 20, "733333": [14, 16, 36, 73, 75, 76], "733746": [19, 40, 78], "734": [21, 31, 40, 42, 61, 78, 80, 90], "734011": [19, 40, 78], "734048": 63, "734385": [20, 41, 79], "734816": [30, 89], "734986": 63, "735": [21, 42, 80], "735043": [20, 41, 79], "735261": [19, 40, 78], "7352614272253524": [19, 40, 78], "735637": 63, "7356574535369873": [49, 58], "7356575131416321": [28, 87], "735879": [19, 40, 78], "736285": 79, "7363681793212891": [28, 49, 58, 87], "736498": [19, 40, 78], "736900": [16, 36, 75], "737285": 63, "7379": [13, 63, 72], "738": [16, 21, 34, 36, 42, 75, 80], "738564": [30, 89], "738701": [16, 36, 75, 76], "738715": [61, 90], "738836": 31, "738839": [18, 39, 77], "738977": [19, 40, 78], "738984": 40, "739": 93, "739264": [16, 24, 36, 45, 75, 83], "7395977155164125": [19, 40, 78], "739598": [19, 40, 78], "739600": 40, "739938": [19, 40, 78], "74": [13, 14, 16, 17, 18, 19, 20, 21, 26, 34, 36, 37, 39, 40, 41, 42, 47, 54, 56, 61, 72, 73, 75, 76, 77, 78, 79, 80, 85, 98], "740319": 63, "740542": [12, 32, 71], "740840": 40, "740844": 78, "741": [31, 61, 90], "741037": [30, 89, 102], "741060": 63, "741250": 74, "741463": [19, 40, 78], "7418": [23, 44, 53, 82], "741935": 93, "742084": [19, 40, 78], "742086": 40, "742088": [19, 78], "742703": [19, 40, 78], "742981": [20, 41, 79], "742986": 52, "743": [15, 16, 19, 36, 40, 74, 75, 78, 90, 93], "743133": [15, 35, 74], "743135": [20, 41, 79], "743321": [40, 78], "743323": [40, 78], "743324": [19, 78], "743391": [15, 35, 74], "743555": [23, 44, 82], "7436": [13, 14, 34, 72, 73, 96], "743917": [16, 36, 75, 76], "743949": 19, "7440": [12, 32, 71], "744201": [20, 41, 79], "744565": [19, 78], "745": 81, "745178": [19, 78], "745925": 63, "746114": [22, 43, 81], "746328": [15, 35, 74], "747": [12, 32, 71], "74720920756": 21, "74720920774": [42, 80], "74798624e": [23, 44, 53, 82], "748": [19, 65], "748510": [20, 41, 79], "748725": 90, "748749e": 78, "748797": [18, 39, 77], "749": 65, "749118": [23, 44, 82], "749326": 54, "75": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 30, 31, 32, 34, 36, 37, 39, 40, 41, 42, 44, 46, 53, 54, 61, 63, 65, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 84, 89, 90, 91, 98, 102], "750": [12, 32, 65, 71], "7500": [21, 42, 80], "75000": 19, "750000": [16, 19, 21, 42, 63, 80], "7503": [13, 63, 72], "7504": 93, "750401": [28, 49, 87], "751": [65, 93], "752": [52, 65], "752169": 63, "7524": [30, 51, 60, 89], "752728": 63, "7528662": 67, "753": 65, "753286": [16, 36, 75, 76], "754": [16, 36, 75], "754165": 93, "754386": [20, 41, 79], "754620": 63, "754874": [24, 45, 83], "754938": 63, "755": [14, 31, 61, 90], "755000": [21, 42, 80], "7551": [19, 40, 78], "755364": [15, 35, 74], "755418": [19, 40, 78], "755477": [15, 35, 74], "756": [31, 61, 90], "7562": [12, 32, 71], "75625": [30, 89, 102], "757": [20, 41, 79], "7574257425742574": [19, 40, 78], "75745416": [25, 46, 55, 84], "757545": [21, 42, 80], "757591": [30, 51, 60, 89], "757799": 29, "757932": [31, 61, 90], "757985": [22, 23, 43, 44, 52, 53, 81, 82], "758": [22, 23, 31, 43, 44, 52, 53, 61, 81, 82, 90], "758029": 64, "758062e": [21, 42, 80], "758259": 63, "75826": [22, 23, 43, 44, 52, 53, 81, 82], "758514": [19, 40, 78], "7588186": [29, 50, 59, 88], "7588527798652649": [28, 87], "7588528394699097": [49, 58], "759561": [25, 46, 84], "75956122": [25, 46, 84], "7599": [18, 39, 77], "76": [14, 16, 18, 19, 20, 21, 23, 24, 31, 34, 36, 39, 40, 41, 42, 44, 45, 53, 61, 73, 75, 77, 78, 79, 80, 82, 83, 90], "760": [31, 61, 90], "760000": 52, "760262": [19, 40, 78], "760678": [30, 89], "760966": 63, "76161": [19, 40, 78], "761945e": [21, 42, 80], "762": [31, 61, 73, 90], "7620": [12, 32, 63, 71], "762093e": [21, 42, 80], "76270194": [23, 44, 82], "763": [16, 36, 75], "763480": 63, "7639": [13, 63, 72], "764052": [24, 45, 83], "76470588": [14, 34, 73], "764706": [14, 15, 19, 34, 35, 40, 73, 74, 78], "765": [20, 79], "765591": [20, 41, 79], "765601": [21, 42, 80], "766317e": [21, 42, 80], "766318": 63, "766423": [21, 42, 80], "766430": [15, 35, 74], "767": [21, 23, 42, 44, 53, 80, 82, 91], "767704": 31, "767742": [18, 39, 77], "767802": [19, 40, 78], "767819": [30, 89], "767852": [15, 35, 74], "768": [16, 21, 23, 36, 42, 44, 53, 75, 76, 80, 82, 91, 98], "76817313": 52, "768176": 90, "768184": 63, "768279": 91, "768512": [20, 41, 79], "76862746": 29, "768830": 54, "769030": 63, "76908228": 81, "76912071": [22, 43], "769231": [16, 36, 75], "7699221015680298": [22, 43], "77": [13, 14, 17, 18, 20, 21, 26, 30, 31, 33, 34, 37, 39, 41, 42, 47, 51, 56, 60, 61, 72, 73, 76, 77, 79, 80, 85, 89, 90, 95, 101], "770": [13, 63, 72], "770163": 63, "7706532429048965": 81, "770833": [27, 48, 57, 86], "770898": [19, 40, 78], "771": [16, 36, 52, 75], "771969": [15, 35, 74], "772185": 63, "772532": [20, 41, 79], "77254903": 29, "7728396574320712": 63, "773017": [21, 23, 42, 44, 80, 82, 91], "773125": 35, "7736": [19, 40, 78], "773851": [30, 51, 60, 89], "774261": [30, 89], "774789": [31, 61], "774844": [17, 37, 76], "77484447": [17, 37, 76], "775000": 19, "7750553478074826": [30, 89], "775270": [21, 42, 80], "7752884548630529": 77, "7752884548630534": [18, 39], "775311": [23, 53, 82], "77536150e": [23, 44, 53, 82], "7758": [19, 40, 78], "776": [19, 40, 78], "7763": [16, 24, 36, 45, 75, 83], "776427": [31, 61, 90], "77694295": 81, "77709": [19, 40, 78], "77716165": [22, 43], "777600": 63, "777934": [15, 35, 74], "778": 93, "77812055": 52, "7781845435415525": [30, 89], "779": [16, 24, 36, 45, 75, 83], "779271": [24, 45, 83], "78": [12, 13, 14, 16, 17, 20, 21, 24, 25, 30, 31, 32, 33, 34, 36, 37, 41, 42, 45, 46, 51, 54, 60, 61, 71, 72, 73, 75, 76, 79, 80, 83, 84, 89, 90, 95], "7800": [19, 40, 78], "780000": [22, 43, 81], "780296": [21, 42, 80], "780298": [21, 42, 80], "780316": [21, 42, 80], "780497": [21, 42, 80], "78058051e": [23, 44, 53, 82], "780745e": 40, "780864": [20, 41, 79], "781": [16, 19, 36, 75], "781004": [15, 35, 74], "781531": [20, 41, 79], "7816": [21, 42, 80], "781975": 64, "782183": [21, 42, 80], "782219": [15, 35, 74], "78260383": 52, "7827": [20, 41, 79], "782850": 31, "783282": [19, 40, 78], "783582": [15, 35, 74], "783784": [27, 48, 57, 86], "783789": [15, 35, 74], "784424": [18, 39, 77], "784573": [24, 45, 83], "785": 76, "785105": [21, 42, 80], "785108": [21, 42, 80], "785134": [21, 42, 80], "78521263": [28, 49, 58, 87], "785399": [21, 42, 80], "785483": [30, 89, 102], "785714": [16, 36, 75], "78586472": [22, 43], "786115": [24, 45, 83], "78617028": 81, "7862": 67, "786555": [21, 42, 80], "787": [16, 36, 75], "787574": [21, 42, 80], "787879": [15, 18, 35, 39, 74, 77], "787933": [21, 42, 80], "788": [31, 70, 73], "788374": 88, "788647472858429": [28, 58, 87], "7886475920677185": 49, "7887": [23, 44, 53, 82], "789": 61, "7891381897690047": 77, "7891381897690053": [18, 39], "789436": [16, 36, 75], "789657": [30, 89, 102], "79": [13, 14, 16, 17, 18, 20, 21, 30, 31, 34, 36, 37, 39, 42, 51, 54, 60, 61, 72, 73, 75, 76, 77, 79, 80, 89, 90, 96], "790": [20, 41, 79], "790000": [16, 36, 75], "79041": [21, 42, 80], "790481e": 65, "790521": 63, "790721": 91, "790731": [18, 39, 77], "791017": [61, 90], "791467": [16, 36, 75], "792": 94, "792023": [23, 44, 53, 82, 91], "79250": [16, 36, 75], "792500": 15, "792577": [21, 42, 80], "792603": [15, 35, 74], "792828": [21, 42, 80], "793": [24, 45, 83], "793243": [16, 36, 75], "79378": [20, 41, 79], "7938": 76, "794": 90, "794118": [15, 35, 74], "794190": 67, "794236": [16, 36, 75], "794820": [16, 36, 75], "795": [14, 15, 19, 40, 74, 78], "79500e": [15, 74], "7951": [19, 40, 78], "795155989041776": 21, "7951559890417761": [42, 80], "795902": [30, 89, 102], "796": [16, 36, 75], "7964215270662811": 77, "7964215270662817": [18, 39], "796982": 50, "797": [16, 36, 75], "797355": [16, 36, 75, 76], "7978563117812038": [16, 36, 75], "798": [16, 36, 75], "7982": [15, 35, 74], "7986546": [21, 42, 80], "799291": 54, "799845": 31, "799983": [15, 35, 74], "79998417": 94, "7f688092391a": [29, 50, 59, 88], "7l": 36, "7m": 29, "7pm": [24, 45, 54, 83], "7th": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "8": [1, 9, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 68, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 97, 102], "80": [12, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 26, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 44, 45, 47, 51, 53, 54, 56, 60, 61, 64, 65, 67, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 89, 90, 91, 95, 102], "800": [12, 19, 28, 32, 34, 40, 49, 58, 65, 71, 73, 78, 87, 99], "800000": [19, 30, 40, 78, 89, 102], "8001": [18, 39, 77], "800190": [15, 35, 74], "80062924": [15, 35, 74], "800k": 91, "801219e": [21, 42, 80], "801666": [20, 41, 79], "801863": [15, 35, 74], "802502": [24, 45, 83], "802902": [21, 42, 80], "802987": [15, 35, 74], "803": [15, 16, 35, 36, 74, 75, 93], "803551": 59, "803617": [20, 41, 79], "804": [15, 31, 35, 61, 74, 90, 93], "804818": [16, 36, 75, 76], "80482065": [17, 37, 76], "804821": [17, 37, 76], "805050": 50, "805198": [21, 42, 80], "805342": [30, 89], "805414": 64, "805970": [15, 18, 35, 39, 74, 77], "806": 76, "8062": [13, 63, 72], "806899": 88, "8076": [21, 42, 80], "807684": [15, 35, 74], "807735": [20, 41, 79], "8078": [12, 32, 71], "808": [31, 61, 90], "8080": [13, 63, 72], "808208": [20, 41, 79], "808958": [15, 35, 74], "809": [16, 36, 75], "809450": [31, 61], "8098": [31, 61, 90], "81": [13, 14, 15, 17, 18, 19, 20, 21, 23, 25, 30, 31, 34, 35, 37, 39, 40, 41, 42, 44, 46, 51, 53, 55, 60, 61, 63, 72, 73, 74, 76, 77, 78, 79, 80, 82, 84, 89, 90, 91, 102], "810073": [21, 23, 42, 44, 53, 80, 82], "810098": [24, 45, 54, 83], "810368": [15, 35, 74], "81071706": [19, 40, 78], "810811": [27, 48, 57, 86], "8112": [12, 32, 71], "812272": [21, 42, 80], "812363": [21, 42, 80], "812500": [14, 73], "812593": 88, "812875": [31, 61, 90], "813": [16, 36, 75], "813586": [20, 41, 79], "814218": 31, "815669": [20, 41, 79], "816": 52, "816200": 64, "8162831858407079": 92, "816717791411044": [31, 61, 90], "817": [22, 43, 52, 81], "817034": 93, "817558": [16, 36, 75, 76], "8180": [16, 36, 75], "818041": [31, 61, 90], "818868": [16, 36, 75], "819152": [15, 35, 74], "819213": [61, 90], "8195": [18, 39, 77], "819549": [15, 35, 74], "819584": [15, 35, 74], "81970188": [17, 37, 76], "819702": [17, 37, 76], "82": [13, 17, 19, 20, 26, 30, 31, 33, 37, 38, 40, 47, 56, 61, 72, 76, 78, 79, 85, 89, 90, 102], "820": [15, 35, 74], "820033": [21, 42, 80], "820143": [18, 39, 77], "82025568e": [23, 44, 53, 82], "820564": [21, 42, 80], "821040": [23, 44, 53, 82], "821208": 54, "821327": [28, 49, 87], "821807": [21, 42, 80], "8219": [16, 36, 75], "822": 67, "8221": 76, "8225": 93, "82273995": [17, 37, 76], "822740": [17, 37, 76], "823": 19, "823364": 65, "82336432": 65, "823511": [20, 41, 79], "823529": [14, 15, 18, 34, 35, 39, 73, 74, 77], "82352941": [14, 34, 73], "823543": [24, 45, 83], "823610e": 61, "8244": 67, "824849": [20, 41, 79], "824884": [21, 42, 80], "824899": 59, "825": [16, 36, 75], "825123": [24, 45, 83], "8253": [15, 35, 74], "825306": [19, 40, 78], "825470": [31, 61, 90], "825697": [21, 42, 80], "826142": [21, 42, 80], "826203": [18, 39, 77], "826216": [21, 42, 80], "82630": 67, "826513": [30, 89, 102], "82652929": 67, "826553": [21, 42, 80], "82670": [30, 89, 102], "826739": [21, 42, 80], "826758": [21, 42, 80], "826760": [21, 42, 80], "827039": [18, 39, 77], "827068": [18, 39, 77], "827130": [20, 41, 79], "827261": [21, 42, 80], "827842": [18, 39, 77], "827907": [19, 40, 78], "828": [61, 63, 65], "8280229354283182": [21, 42, 80], "82804": [19, 40, 78], "828332": [21, 23, 42, 44, 80, 82, 91], "828358": [15, 35, 74], "828405": [30, 51, 60, 89], "828682": [19, 40, 78], "82869879": [28, 49, 58, 87], "828891": [19, 40, 78], "828976": [19, 40, 78], "829": [61, 65], "829027": 61, "83": [13, 14, 17, 19, 20, 26, 27, 28, 30, 31, 33, 34, 37, 40, 41, 47, 48, 49, 51, 54, 56, 57, 58, 60, 61, 68, 72, 73, 76, 78, 79, 85, 86, 87, 89, 90, 95, 102], "830": [61, 65], "830382": [20, 41, 79], "8304": 67, "830712e": [21, 42, 80], "831": [61, 65], "831135": [15, 35, 74], "831329": 50, "831611": [21, 23, 42, 44, 53, 80, 82], "831989": [19, 40, 78], "832": [16, 36, 61, 65, 67, 75], "8320": 67, "832320": [18, 39, 77], "832370": [20, 41, 79], "832866": [21, 42, 80], "833": [15, 19, 40, 61, 65, 67, 74, 78], "83320": [30, 89], "8334": [23, 44, 67, 82], "833913": 63, "834": [61, 65], "8340": [15, 35, 74], "834109": [19, 40, 78], "834356e": [21, 42, 80], "83437": [21, 42, 80], "834455": [15, 35, 74], "835": [61, 65], "835563": 54, "8356": [23, 44, 53, 82], "835651": [19, 40, 78], "835749": [21, 23, 42, 44, 53, 80, 82], "835876": 63, "83603": [21, 23, 42, 53, 80, 82], "8361313": [21, 42, 80], "836189": [15, 35, 74], "836735": [20, 41, 79], "836878e": [21, 42, 80], "836880e": [21, 42, 80], "837": [52, 67], "837022e": [21, 42, 80], "837838": [15, 35, 74], "837848": [15, 35, 74], "838": [15, 19, 40, 74, 78], "83848729e": [29, 59, 88], "83848731e": 50, "83876": [19, 40, 78], "8388866943476283": 77, "8388866943476289": [18, 39], "838951": [21, 42, 80], "8389756947416362": 77, "8389756947416367": [18, 39], "839225": [21, 42, 80], "839920e": 19, "84": [13, 14, 17, 30, 31, 33, 34, 37, 51, 60, 61, 63, 72, 73, 76, 89, 90, 93, 94, 95], "840": [16, 36, 75], "84002795": [17, 37, 76], "840028": [17, 37, 76], "840074": [14, 34, 73], "840183": [21, 42, 80], "840492": [21, 23, 42, 44, 53, 80, 82, 91], "84062193": [23, 44, 82], "841": [21, 42, 80], "841208": [19, 40, 78], "8418": 67, "841886": [19, 40, 78], "841983": [19, 40, 78], "842": [16, 36, 67, 75], "842028": [20, 41, 79], "842064": [61, 90], "842105": [15, 35, 74], "843": [22, 43, 67, 81], "843281": [23, 44, 82], "843284": [15, 18, 35, 39, 74, 77], "843842": [16, 36, 75, 76], "843992": [21, 23, 42, 44, 53, 80, 82], "844": 52, "844409": [17, 37, 76], "84440919": [17, 37, 76], "844444": 16, "844921": [25, 46, 55, 84], "845": [19, 40, 78], "846154": [16, 36, 75, 93], "8462": [24, 45, 54, 83], "846260e": [21, 42, 80], "846650": [21, 42, 80], "84679073": [15, 35, 74], "84698489": [29, 50, 59, 88], "847": [52, 53], "847178": [20, 41, 79], "847287": [19, 40, 78], "8475": [30, 51, 60, 89], "8475374359985492": 52, "84772": [20, 41, 79], "847799": [19, 40, 78], "847808": [20, 41, 79], "8478316682480326": [30, 89], "848": [22, 23, 43, 44, 81, 82], "8481": 93, "848214": 16, "84893192": [19, 40, 78], "849": [22, 23, 43, 44, 52, 53, 81, 82], "849102e": [42, 80], "849438e": [21, 42, 80], "849612": [19, 40, 78], "85": [13, 14, 17, 20, 21, 22, 23, 24, 30, 31, 33, 34, 37, 41, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 69, 72, 73, 76, 79, 80, 81, 82, 83, 89, 90, 95, 102], "850": [12, 22, 23, 32, 43, 44, 52, 53, 71, 81, 82], "8502": [19, 40, 78], "850283": [30, 89, 102], "850503": [19, 40, 78], "850746": [15, 35, 74], "851291": 31, "851460": [21, 42, 80], "851493": 54, "851852": [18, 39, 77], "852": [31, 90, 93], "852053": [19, 40, 78], "852104": [21, 42, 80], "852941": [18, 39, 77], "853125": 74, "853399": [20, 41, 79], "854129": [21, 42, 80], "854167": [27, 48, 57, 86], "854500": [31, 61, 90], "8546143543902771": [31, 61, 90], "854744525547446": [31, 61, 90], "854749": [30, 89], "85545875": [15, 35, 74], "85597188": [17, 37, 76], "855972": [17, 37, 76], "856": [40, 78], "856175": [16, 36, 75], "856589": [19, 40, 78], "856722": 64, "857": [21, 42, 80], "857457": 64, "857874": [19, 40, 78], "858": [18, 39, 77], "8580": [16, 36, 75, 76, 98], "858209": [15, 18, 35, 39, 74, 77], "858240": 54, "858915": [19, 40, 78], "859": [22, 43, 81], "859318": [21, 42, 80], "859439": [25, 46, 84], "85943906": [25, 46, 84], "859455": [31, 61, 90], "85969": [19, 40, 78], "859704": 29, "859799": [19, 40, 78], "859864": 59, "86": [13, 15, 17, 18, 19, 20, 24, 30, 31, 33, 37, 39, 40, 41, 45, 51, 54, 60, 61, 72, 74, 76, 77, 78, 79, 83, 89, 90], "860": [20, 23, 41, 44, 52, 79, 82], "86000e": [15, 74], "8601643854446082": [21, 42, 80], "860677": [20, 41, 79], "861": [16, 36, 75], "86102": [30, 89, 102], "861157": 91, "861348": [19, 40, 78], "861559": 59, "862432": [21, 42, 80], "862450e": 19, "862552": [16, 36, 75], "8625888648969532": [31, 61, 90], "86267067": [17, 37, 76], "862671": [17, 37, 76], "862740": 59, "862855": 54, "862997": [24, 45, 83], "863014": [18, 39, 77], "863889": [30, 51, 60, 89], "863941": [21, 42, 80], "864": [22, 43, 52, 81], "86400": [30, 89, 102], "8641864337292489": [31, 61, 90], "864205": [23, 53, 82], "864292": 64, "864756": 59, "865562": [31, 61, 90], "8661": 93, "866110": [18, 39, 77], "866667": [14, 20, 41, 73, 79], "866980": [21, 42, 80], "867434": 88, "867558": [24, 45, 83], "868003": [21, 42, 80], "86820176": 67, "868281": [21, 42, 80], "868305": [21, 42, 80], "868308": [21, 42, 80], "869": 19, "869077": [17, 37, 76], "86907725": [17, 37, 76], "869094": [19, 40, 78], "8691": 76, "869531": [15, 35, 74], "869964": [19, 40, 78], "87": [13, 16, 17, 20, 30, 31, 36, 37, 51, 60, 61, 72, 75, 76, 79, 89, 90], "870": [22, 23, 43, 44, 52, 53, 81, 82], "870503": 88, "871": [22, 40, 43, 52, 78, 81], "871094": [30, 89], "8711": [20, 41, 79], "871200": 63, "872": [22, 23, 43, 44, 52, 53, 81, 82], "872093": [19, 40, 78], "872603": 88, "872722908439952": [23, 44, 53, 82], "8727229084399575": [23, 44, 53, 82], "872961060": [21, 42, 80], "8729610607986": [21, 42, 80], "873": [43, 52, 81], "8731": [21, 23, 42, 44, 80, 82, 91], "873103": [15, 35, 74], "873182": [30, 51, 60, 89], "8733333333333333": 50, "873356": [15, 35, 74], "873643": [19, 40, 78], "873704": [21, 42, 80], "874062": [17, 37, 76], "87406235": [17, 37, 76], "874305": [30, 51, 60, 89], "874516": [19, 40, 78], "874532": [21, 42, 80], "874767e": [21, 42, 80], "874962": 64, "875": [20, 79], "8750": [16, 24, 36, 45, 75, 83], "875000": [14, 16, 73], "876065": [19, 40, 78], "876540": [31, 61, 90], "876566e": 63, "876574": [16, 36, 75, 76], "876668": 54, "87681182": [28, 49, 58, 87], "877": 19, "877046": [24, 45, 54, 83], "877390": [23, 53, 82], "877519": [19, 40, 78], "877551": [20, 41, 79], "877887": 67, "878183": [15, 35, 74], "87844893": [21, 42, 80], "87849316": [18, 39, 77], "879": [16, 36, 75], "87907": [19, 40, 78], "879938": [19, 40, 78], "88": [13, 14, 16, 17, 18, 20, 24, 31, 34, 36, 37, 39, 41, 45, 54, 61, 72, 73, 75, 76, 77, 79, 83, 90, 93, 98], "880": [24, 45, 54, 83], "8801": 87, "880348": [19, 40, 78], "880831": [30, 89, 102], "881395": [19, 40, 78], "881720": [20, 41, 79], "883138": [19, 40, 78], "883362e": 19, "884586": [19, 40, 78], "885": [12, 32, 71, 76], "885044": [21, 23, 42, 44, 80, 82, 91], "8859": [38, 66, 67], "885968": [31, 61, 90], "886047": [19, 40, 78], "886759": [18, 39, 77], "887": [22, 43, 52, 81], "887017": [20, 41, 79], "887159": [30, 89, 102], "8873": [20, 41, 79], "887324": [20, 41, 79], "887343": [15, 35, 74], "887597": [19, 40, 78], "887701": [20, 41, 79], "8878117": [17, 37, 76], "887812": [17, 37, 76], "888": [22, 23, 40, 43, 44, 52, 53, 78, 81, 82], "888066": [23, 44, 82], "888372": [19, 40, 78], "888513": [20, 41, 79], "888811": [19, 40, 78], "888889": [16, 18, 36, 39, 75, 77], "888961": [23, 44, 82], "889086": [21, 42, 80], "889147": [19, 40, 78], "889429": [30, 51, 60, 89], "889921": [30, 89], "89": [13, 14, 17, 20, 26, 30, 31, 33, 34, 37, 41, 47, 51, 54, 56, 60, 61, 72, 73, 76, 79, 85, 89, 90, 95, 102], "890": [22, 43, 52, 61, 65, 81], "890456": 63, "890457": [21, 42, 80], "890933": [31, 61, 90], "891": 61, "891001": [20, 41, 79], "891557": [19, 40, 78], "892": 61, "892476": [20, 41, 79], "892477": [15, 35, 74], "892491": [16, 36, 75], "89270": [24, 45, 83], "892733": [30, 51, 60, 89], "892961": [24, 45, 83], "893": 61, "893000": [16, 36, 75], "893260": [17, 37, 76], "893580": 31, "8937442459553657": [23, 44, 53, 82], "894": [16, 36, 61, 75], "894587": 91, "894960": 63, "895": [43, 52, 81], "89515383": 65, "895154": 65, "895349": [19, 40, 78], "895541": [21, 42, 80], "89572": [30, 89, 102], "895833": [20, 41, 79], "895963": [18, 39, 77], "897010": [16, 36, 75, 76], "89706451e": [23, 44, 53, 82], "897674": [19, 40, 78], "898": [23, 44, 53, 82], "898016": [19, 40, 78], "898243": 64, "898703e": [21, 42, 80], "899": [16, 22, 36, 40, 43, 52, 75, 76, 78, 81, 98], "8994": [23, 44, 53, 82], "8997": [21, 42, 80], "899736": 63, "899969": [30, 89, 102], "8m": [59, 88], "8mb": 29, "8th": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "9": [1, 4, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 102, 103], "90": [8, 12, 13, 14, 15, 17, 20, 21, 26, 27, 30, 31, 32, 33, 34, 35, 37, 41, 42, 47, 48, 51, 54, 56, 57, 60, 61, 68, 69, 71, 72, 73, 74, 76, 79, 80, 85, 86, 89, 90, 95], "900": [17, 19, 20, 37, 40, 76, 78, 79], "90000": [30, 89, 102], "900000": [14, 30, 34, 73, 89, 102], "900000e": 63, "900662": [14, 34, 73], "901": 43, "901026": 50, "901085": [18, 39, 77], "9010852321946792": 77, "9010852321946795": [18, 39], "901262": [30, 51, 60, 89], "90159483": [25, 46, 84], "901595": [25, 46, 84], "901975": 54, "902343": 64, "902401": [19, 40, 78], "903101": [19, 40, 78], "903422": 64, "904": [15, 19, 35, 40, 74, 78], "90403853": [17, 37, 76], "904039": [17, 37, 76], "904226": [15, 35, 74], "904462e": 61, "904565": 64, "9047619047619048": [13, 33, 72], "904902": 88, "904930e": 63, "905": [15, 16, 35, 36, 74, 75], "905000": 35, "905327": [30, 89], "9066666666666666": 29, "906667": [14, 34, 64, 73], "90669": [24, 45, 83], "906865": [14, 34, 73], "907": [31, 61, 90], "907143": 93, "907595": [30, 51, 60, 89], "908": [16, 36, 75], "908140": [16, 36, 75, 76], "908215": [21, 42, 80], "909091": [16, 36, 75], "90982": [24, 45, 83], "91": [13, 14, 16, 17, 19, 20, 24, 25, 30, 33, 34, 36, 37, 40, 41, 45, 46, 51, 55, 60, 63, 72, 73, 75, 76, 78, 79, 83, 84, 89, 95, 102], "910": [13, 17, 37, 63, 72], "9100": [30, 51, 60, 89], "910018": [21, 42, 80], "910174": [21, 42, 80], "9103": [30, 51, 60, 89], "910456e": [21, 42, 80], "91063776": [23, 44, 82], "910714": 93, "9108334653214172": 63, "910843": [21, 42, 80], "911": [22, 61, 65], "911272": 56, "911615": [21, 42, 80], "911846": [21, 42, 80], "912": [16, 36, 61, 75], "912395": [23, 44, 53, 82], "913": 61, "913333": [14, 34, 64, 73], "913767": [21, 42, 80], "913849": [21, 42, 80], "914": 61, "914003": [23, 44, 53, 82], "914451894267": [21, 42, 80], "914585": [23, 44, 53, 82], "915": 61, "91515735": [21, 42, 80], "915714e": [21, 42, 80], "915952": [21, 42, 80], "916": 61, "916254": [15, 35, 74], "916347": 64, "916722": [23, 44, 53, 82], "917": 61, "917526": [20, 41, 79], "917837": [20, 41, 79], "918": [22, 43, 52, 61, 63, 81], "918124": [20, 41, 79], "918191": 88, "9182": [30, 51, 60, 89], "918224": 65, "91835": 67, "919": 61, "919198": [23, 44, 53, 82], "9193001": [28, 49, 58], "9196": [12, 32, 71], "92": [13, 14, 17, 20, 26, 30, 31, 33, 34, 37, 41, 47, 51, 56, 60, 61, 72, 73, 76, 79, 85, 88, 89, 90, 95], "920": 61, "920000": [14, 34, 64, 73], "9203": [19, 40, 78], "920305": [24, 45, 54, 83], "920462": [23, 44, 53, 82], "921": 61, "9212": 16, "92120500e": 94, "921422": [31, 61, 90], "921435": 64, "921438": [21, 42, 80], "921850": [21, 42, 80], "92195464": [23, 44, 53, 82], "921955": [23, 44, 53, 82], "922": 76, "923077": [20, 41, 79], "923283": [16, 36, 75, 76], "923432": [23, 44, 53, 82], "924485": [24, 45, 54, 83], "9245": [14, 18, 34, 39, 73, 77], "925272e": [21, 42, 80], "925288e": [21, 42, 80], "925593": [15, 35, 74], "925768": [20, 41, 79], "925956": 59, "926": 61, "926657": [21, 42, 80], "926667": 64, "926733e": [21, 42, 80], "926829": [20, 41, 79], "927": 61, "928": [19, 40, 61, 78], "92809": [24, 45, 83], "92852376": [15, 35, 74], "929": [22, 40, 61, 78], "9295": [19, 40, 78], "93": [13, 14, 17, 18, 25, 30, 31, 33, 34, 37, 39, 40, 46, 51, 54, 55, 60, 61, 72, 73, 76, 77, 78, 84, 89, 90, 95], "930": 61, "930000": [16, 36, 75], "930040e": 21, "930062": 63, "930123": [15, 35, 74], "930561": [15, 35, 74], "9308647034083802": 63, "931": 61, "931439e": [21, 42, 80], "931556": 31, "931786": [18, 39, 77], "931896": 63, "932": [16, 36, 61, 75], "932070": [31, 61, 90], "932124": [15, 35, 74], "932143": 93, "93232161": 67, "93279": [30, 89], "933": 61, "933020": 54, "933333": 64, "9336": [16, 36, 75], "934": 65, "934205": [15, 35, 74], "934269": [16, 36, 75, 76], "934783": [20, 41, 79], "9351": [24, 45, 54, 83], "935512": [61, 90], "935802": [15, 35, 74], "93665": [30, 89, 102], "936733": 31, "937429": 91, "9375": [14, 34, 73], "937500": [14, 17, 34, 37, 73, 76], "93788": [28, 49, 58], "938": [20, 41, 79], "938201": 63, "9383": [15, 18, 35, 39, 74, 77], "93869659": [17, 37, 76], "938697": [17, 37, 76], "939006": [20, 41, 79], "9391": [21, 42, 80], "939394": [15, 18, 35, 39, 74, 77], "939805": 63, "94": [13, 14, 16, 17, 18, 19, 20, 21, 30, 33, 34, 36, 37, 39, 40, 41, 42, 51, 60, 72, 73, 75, 76, 77, 78, 79, 80, 89, 95, 98], "940000": 64, "9401": [30, 51, 60, 89], "9406": [13, 14, 34, 72, 73, 96], "941": [31, 61, 90], "9410": 63, "941176": [14, 17, 34, 37, 73, 76], "94117647": [14, 34, 73], "942": [61, 65], "943": 61, "943609": [24, 45, 54, 83], "944": [12, 32, 61, 71], "944092": [20, 41, 79], "944342": [31, 61], "944354": 76, "945": 61, "945000": 64, "945549": 59, "945968": 64, "946": 61, "946667": 64, "946783": [15, 35, 74], "947": [16, 19, 36, 40, 61, 75, 78, 93], "9471": [19, 40, 78], "948482": 90, "94888": [20, 41, 79], "948901": 61, "949": [16, 17, 36, 37, 75], "9490": [16, 36, 75], "9492": [21, 42, 80], "94933723": [21, 42, 80], "94959681": [17, 37, 76], "949597": [17, 37, 76], "95": [13, 14, 17, 20, 26, 30, 31, 33, 34, 37, 41, 47, 51, 56, 60, 61, 72, 73, 76, 79, 85, 89, 90, 91], "950000": [16, 36, 75], "950088": [24, 45, 83], "9505": [23, 44, 82], "950564": [24, 45, 54, 83], "9506": [23, 44, 82], "950627": 54, "950696": [31, 61, 90], "950733": [15, 35, 74], "951": 19, "951294": [21, 42, 80], "951574": [24, 45, 83], "951644": [24, 45, 54, 83], "951667": 64, "951669": [24, 45, 83], "951696": [15, 35, 74], "951852": 50, "953": [22, 43, 81], "9530973451327434": 92, "953333": 64, "954": 52, "95511263": [15, 35, 74], "955113": [15, 35, 74], "9558": [30, 51, 60, 89], "956": [16, 36, 75], "956966": [24, 45, 83], "957075": [24, 45, 83], "9573": [30, 51, 60, 89], "9576": [12, 32, 71], "957886": 88, "957919": [15, 35, 74], "957987": [15, 35, 74], "9583333333333334": [29, 50, 59, 88], "958393": [16, 24, 36, 45, 75, 83], "95886206e": [29, 50, 59, 88], "959": [16, 36, 65, 75], "959139": [23, 44, 53, 82], "959402e": [21, 42, 80], "959870": [20, 41, 79], "959873": [61, 90], "96": [13, 17, 18, 19, 20, 24, 30, 37, 39, 40, 41, 45, 51, 54, 60, 72, 76, 77, 78, 79, 83, 89], "960": [17, 18, 37, 39, 65, 77], "960000e": 65, "960176": 59, "961": 65, "961106": 79, "961109802000133": [47, 56, 85], "961109802000134": 26, "961404": [16, 36, 75, 76], "961498": [21, 23, 42, 44, 53, 80, 82, 91], "961576": 20, "961771": [18, 39, 77], "961898": [18, 39, 77], "962": 65, "962660": 20, "962776": 79, "963": 65, "963024": 63, "96319": [30, 89], "96320": [30, 89], "96321": [30, 89], "96322": [30, 89], "96323": [30, 89], "96325": [30, 89], "963333": 64, "963689": [24, 45, 54, 83], "964": 65, "96554": [24, 45, 83], "9661": [21, 42, 80], "966131": [16, 36, 75, 76], "9664": [13, 14, 34, 72, 73, 96], "966491": 79, "966667": 64, "966812": 63, "967102": 79, "967907": [20, 41, 79], "968": [16, 36, 75], "968233": [24, 45, 54, 83], "96833": 87, "968333": 64, "96834506": [15, 35, 74], "968493": 90, "968514e": [21, 42, 80], "968620": 20, "96875": [29, 50, 59, 88], "969048e": [42, 80], "9691": [21, 42, 80], "9692602666681306": [18, 39, 77], "96965253": [23, 44, 53, 82], "969653": [23, 44, 53, 82], "97": [13, 14, 16, 17, 18, 19, 23, 26, 30, 31, 34, 37, 39, 40, 44, 47, 51, 53, 56, 60, 61, 72, 73, 76, 77, 78, 82, 85, 89, 90], "970204": 50, "970518": [20, 41, 79], "970683": [24, 45, 54, 83], "971": 76, "971805": 54, "97203586": [17, 37, 76], "972036": [17, 37, 76], "97217": [30, 89], "972198": [19, 40, 78], "97223953": [17, 37, 76], "972240": [17, 37, 76], "972379": 65, "97237936": 65, "972440": [20, 41, 79], "97253": [30, 89], "9730": 76, "973225": [20, 41, 79], "973280": [17, 37, 76], "97328024": [17, 37, 76], "973294": 65, "973333": 64, "973482e": 78, "973750": [15, 74], "974": [16, 36, 75], "974183": 64, "974480": [24, 45, 54, 83], "974531": 64, "9748": [18, 39, 77], "974801e": [21, 42, 80], "975104": 65, "975313": 54, "975895": [30, 89], "976": [16, 20, 22, 36, 41, 43, 52, 75, 79, 81], "97601304": 67, "976667": 64, "977": [16, 30, 36, 75, 89, 102], "977278": [24, 45, 83], "9773": [13, 14, 15, 34, 35, 72, 73, 74, 96], "977873": 31, "978": [18, 39, 77], "9781449369880": [30, 51, 60, 89], "9781789957211": [29, 50, 59, 88], "97823755": [18, 39, 77], "9785299": 87, "978738": [24, 45, 83], "979": [22, 23, 43, 44, 52, 53, 81, 82], "979562": [31, 61, 90], "98": [13, 16, 17, 18, 21, 23, 25, 28, 30, 31, 36, 37, 39, 42, 44, 46, 49, 51, 53, 55, 58, 60, 61, 72, 75, 76, 77, 80, 82, 84, 87, 89, 90, 91], "980": [30, 89, 102], "980000": 64, "98001": 63, "98007": [12, 32, 71], "98010": 63, "98024": 63, "98027": 63, "98028": [13, 63, 72], "98033": 63, "98038": 63, "98039": 63, "98045": [12, 32, 71], "98052": [12, 32, 63, 71], "98055": [12, 32, 71], "980634": [31, 61, 90], "98065": 63, "98072": [12, 32, 71], "98074": [13, 63, 72], "98075": [12, 32, 71], "98077": 63, "9808": [18, 39, 77], "980862": 31, "980962": 64, "98102": 63, "98103": 63, "98107": [12, 32, 71], "98112": [12, 32, 71], "98115": 63, "98116": [12, 32, 71], "98117": 63, "98118": 63, "981195": [30, 89], "98125": [13, 63, 72], "98136": [13, 63, 72], "98144": 63, "98146": 63, "98148": 63, "981643": 63, "981735": [18, 39, 77], "98178": [13, 63, 72], "98199": 63, "982": 76, "982184": [19, 40, 78], "982570": [31, 61, 90], "983": [29, 50, 59, 88], "983333": 64, "983340": 63, "9837": [14, 18, 34, 39, 73, 77], "984": [19, 40, 78], "984653": [18, 39, 77], "984664": [21, 42, 80], "985000": 64, "985283": [19, 40, 78], "9854": [13, 14, 18, 34, 39, 72, 73, 77, 96], "985457": 90, "98565": 67, "985816": [14, 73], "986047": [19, 40, 78], "9862": 93, "986207": [19, 40, 78], "986803": 54, "987": [19, 29, 40, 50, 59, 78, 88], "987062": [21, 42, 80], "987597": [19, 40, 78], "9876": [22, 23, 43, 44, 52, 53, 81, 82], "987677": 54, "987681": [24, 45, 54, 83], "988": [24, 45, 54, 83], "9881": [13, 14, 34, 72, 73, 96], "988333": 64, "988381": [19, 40, 78], "988841": [19, 40, 78], "988901": [21, 42, 80], "989": [13, 33, 72], "989059": 56, "989147": [19, 40, 78], "989156": [19, 40, 78], "989443": [31, 61, 90], "989922": [19, 40, 78], "989973": [18, 39, 77], "99": [13, 14, 16, 17, 19, 20, 30, 34, 36, 37, 40, 41, 51, 60, 65, 68, 72, 73, 75, 76, 78, 79, 89, 100, 102], "990631": [30, 89, 102], "990754": [30, 89], "991": 67, "9912": [15, 18, 35, 39, 74, 77], "9915": [30, 89, 102], "991667": 64, "991810": 63, "991966": [31, 61, 90], "992": [40, 73, 78], "992220": 63, "992254": [19, 40, 78], "99240562": [23, 44, 53, 82], "992406": [19, 40, 78], "992569": 65, "9926": 76, "992857": [14, 73], "992908": 73, "993023": [19, 40, 78], "993029": [19, 40, 78], "993065": [31, 61, 90], "9931": [13, 14, 34, 72, 73, 96], "993333": 64, "9934531067299874": [18, 39, 77], "99355746": 67, "993666": [23, 44, 82], "993969": [21, 23, 42, 44, 53, 80, 82, 91], "994": [12, 32, 71], "994266": [19, 40, 78], "994574": [19, 40, 78], "994764": [30, 89], "995": [24, 29, 45, 50, 54, 59, 83, 88], "9950": [24, 45, 54, 83], "9951": [13, 14, 34, 72, 73, 96], "99515": [30, 89], "995434": [21, 42, 80], "995511": 50, "996": 61, "996293": 50, "996424": 63, "996487": 63, "996588e": [42, 80], "996765": [23, 53, 82], "996788": [31, 61, 90], "996820": [31, 61, 90], "996899": [19, 40, 78], "997": 61, "99744241e": [23, 44, 53, 82], "9977957422135844": [23, 44, 82], "9977957422135846": 53, "998": [20, 31, 41, 61, 68, 79, 90, 93], "9983": [20, 41, 79], "998302": [20, 41, 79], "998370": 63, "998440": 63, "99845": [19, 40, 78], "998451": [19, 40, 78], "998562": 52, "999": [18, 39, 61, 77, 93], "99907": [19, 40, 78], "999122": [20, 41, 79], "9991338290544213": 63, "999147": [20, 41, 79], "999172": [20, 41, 79], "999178": 63, "999183": [20, 41, 79], "999185": [20, 41, 79], "999192": [20, 41, 79], "999210": [20, 41, 79], "999213": 63, "999214": [20, 41, 79], "999221": [20, 41, 79], "999223": [20, 41, 79], "999225": [19, 40, 78], "999254": [20, 41, 79], "999298": [20, 41, 79], "999317": [20, 41, 79], "99931882": [42, 80], "99931883": 21, "999335": [20, 41, 79], "999438": 63, "9994394006711425": 63, "999480": 63, "999518": 63, "999535": [19, 40, 78], "999539": 63, "999544": 63, "999545": 63, "999546": 63, "999558": 63, "999562": 63, "999567": 63, "999577": [30, 89], "999622": [16, 36, 75], "99975": 67, "99980": 67, "9999": [12, 32], "9999999999999998": 53, "9am": [24, 45, 54, 83], "9m": 50, "9th": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "A": [0, 1, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 59, 60, 61, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 86, 87, 88, 90, 91, 92, 94, 95, 102, 103], "AND": [0, 21, 42, 69, 80], "AS": 0, "And": [12, 13, 19, 21, 28, 30, 31, 32, 40, 42, 49, 51, 58, 60, 61, 69, 71, 72, 78, 80, 87, 89, 90, 91, 96, 97], "As": [4, 14, 17, 19, 21, 22, 23, 27, 30, 31, 34, 35, 37, 40, 42, 43, 44, 48, 52, 61, 69, 73, 76, 78, 80, 81, 82, 86, 89, 90, 91, 92, 94, 97, 99, 101, 103], "At": [4, 12, 14, 18, 20, 22, 24, 25, 29, 30, 32, 39, 41, 43, 45, 46, 51, 52, 54, 55, 59, 60, 61, 63, 65, 68, 71, 73, 77, 79, 81, 83, 84, 88, 89], "BE": [0, 28, 49, 58, 87], "BUT": [0, 8], "BY": [0, 1], "Be": [7, 12, 15, 23, 32, 35, 44, 53, 74, 82, 91, 92, 95, 97], "Being": [29, 50, 59, 88], "But": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 97, 99, 101, 102, 103], "By": [11, 12, 14, 15, 17, 20, 22, 25, 28, 29, 31, 32, 34, 35, 37, 41, 43, 46, 49, 50, 52, 54, 55, 58, 59, 61, 64, 71, 73, 74, 76, 79, 81, 84, 87, 88, 90, 91, 97, 99], "FOR": 0, "For": [0, 1, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 97, 99, 100, 101, 102, 103], "IN": [0, 14, 18, 34, 39, 73, 77], "IT": [18, 39, 77], "If": [4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103], "In": [1, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103], "Ines": 93, "It": [2, 4, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 97, 99, 101, 103], "Its": [31, 61, 90], "NEAR": [16, 24, 36, 45, 54, 75, 76, 83, 98], "NO": 0, "NOT": [0, 8, 17, 18, 37, 39, 76, 77], "No": [0, 12, 13, 21, 22, 23, 24, 26, 30, 31, 32, 33, 42, 43, 44, 45, 47, 52, 53, 54, 56, 61, 65, 69, 71, 72, 80, 81, 82, 83, 85, 89, 90, 91, 95, 102], "Not": [20, 21, 22, 23, 24, 25, 27, 30, 31, 41, 42, 43, 44, 45, 46, 48, 52, 53, 54, 55, 57, 61, 79, 80, 81, 82, 83, 84, 86, 89, 90, 100], "OF": 0, "OR": [0, 8, 21, 42, 69, 80], "Of": [9, 17, 19, 37, 40, 76, 78], "On": [4, 7, 12, 16, 17, 19, 20, 21, 22, 23, 24, 26, 29, 31, 32, 36, 37, 40, 41, 42, 43, 44, 45, 47, 50, 52, 53, 55, 56, 59, 61, 63, 64, 65, 67, 69, 71, 75, 76, 78, 79, 80, 81, 82, 83, 85, 88, 90, 91, 93], "One": [5, 8, 13, 14, 17, 18, 19, 20, 23, 25, 26, 31, 33, 34, 37, 38, 39, 40, 41, 44, 46, 47, 53, 55, 59, 61, 65, 66, 67, 68, 72, 73, 76, 77, 78, 79, 82, 84, 85, 90, 95, 100, 102], "Or": [15, 17, 19, 35, 40, 64, 74, 76, 78, 91, 97], "Such": [6, 27, 30, 48, 51, 57, 60, 86, 89], "THE": [0, 14, 34, 73], "TO": [0, 28, 49, 58, 87], "That": [13, 14, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 30, 31, 33, 34, 36, 39, 40, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 60, 61, 69, 72, 73, 75, 77, 78, 80, 81, 82, 84, 85, 86, 87, 89, 90, 91, 92, 100], "The": [0, 2, 5, 7, 8, 11, 12, 13, 15, 16, 17, 20, 21, 23, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 41, 42, 44, 45, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 76, 79, 80, 82, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 102, 103], "Their": 5, "Then": [13, 18, 22, 25, 30, 33, 39, 43, 46, 51, 52, 53, 55, 60, 67, 72, 77, 81, 84, 89, 92, 100], "There": [1, 2, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 67, 68, 69, 70, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 103], "These": [4, 10, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 27, 30, 33, 34, 35, 39, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54, 55, 57, 59, 60, 69, 72, 73, 74, 77, 79, 80, 81, 82, 83, 84, 86, 89, 91, 101], "To": [8, 10, 12, 13, 14, 15, 16, 17, 18, 21, 22, 24, 26, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 42, 43, 45, 49, 50, 51, 52, 54, 56, 58, 59, 60, 64, 65, 67, 70, 71, 72, 73, 74, 75, 76, 77, 80, 81, 83, 85, 87, 88, 89, 91, 92, 93, 97, 99, 101, 102, 103], "WITH": 0, "Will": [20, 31, 41, 61, 79, 90, 93, 95, 100], "With": [0, 12, 13, 15, 16, 17, 18, 19, 21, 23, 24, 25, 26, 27, 29, 31, 32, 33, 35, 36, 37, 39, 40, 42, 44, 45, 46, 47, 48, 50, 53, 54, 55, 56, 57, 59, 61, 64, 71, 72, 74, 75, 76, 77, 78, 80, 82, 83, 84, 85, 86, 88, 90, 94, 97], "_": [22, 28, 29, 31, 49, 50, 52, 58, 59, 61, 81, 87, 88, 90, 93], "__array__": [61, 65], "__call__": [17, 37, 61, 76], "__class__": [18, 30, 39, 51, 60, 77, 89], "__finalize__": [31, 61, 90], "__getitem__": [36, 73, 75], "__init__": [61, 93], "__name__": [18, 30, 39, 51, 60, 70, 77, 89], "__sklearn_tags__": 65, "__testing_word2vec": [28, 49, 87], "_arg": 93, "_array_api": [61, 65, 93], "_asarray_with_ord": [61, 65], "_assert_all_finit": 65, "_assert_all_finite_element_wis": 65, "_astype_nansaf": [31, 61, 90], "_base": 65, "_basic": 61, "_c": 93, "_california_housing_dataset": [18, 39, 77], "_call_func_on_transform": [17, 37, 61, 76], "_callback": 93, "_check_i": [61, 65], "_classif": 65, "_column_transform": [17, 37, 61, 76], "_constructor_from_mgr": [31, 61, 90], "_context": 93, "_data": [61, 78], "_deprecate_force_all_finit": 65, "_distn_infrastructur": [19, 40, 78], "_encod": [17, 37, 76], "_err_msg_1dcolumn": 61, "_estim": [61, 65], "_fit": 65, "_fit_context": 65, "_fit_model": 61, "_fit_model_breslow": 61, "_fit_model_splin": 61, "_fit_transform_on": 61, "_get_default_devic": 93, "_get_empty_rout": 61, "_get_sequential_output": [17, 37, 61, 76], "_i": [29, 42, 50, 59, 88], "_is_numpy_namespac": 65, "_iter": 61, "_join": 61, "_label": 61, "_logist": 94, "_mgr": [31, 61, 90], "_model": 61, "_newton_raphson_for_efron_model": 61, "_norm_mean": 61, "_norm_std": 61, "_original_iter": 61, "_print_elapsed_tim": 61, "_proba": [43, 81], "_pseudo_sync_runn": 93, "_raise_for_param": 61, "_reset": 61, "_run": [61, 93], "_run_cel": 93, "_run_cod": 93, "_run_module_as_main": 93, "_run_onc": 93, "_score": [17, 37, 76], "_scorer": [17, 37, 76], "_search": 19, "_set_output": [17, 37, 61, 76], "_solve_check": 61, "_temp": [29, 93], "_time_fit_was_cal": [61, 90], "_to_list_or_singleton": 61, "_transform": [17, 37, 76], "_transform_on": [17, 37, 76], "_valid": [17, 37, 76], "_validate_param": 65, "_valu": [61, 65], "_with_config": 61, "_x_subset": 14, "a1": 61, "ab": [18, 20, 21, 23, 39, 41, 42, 44, 53, 54, 68, 69, 77, 79, 80, 82], "abbrevi": [28, 49, 58, 87], "abdelrahman": [1, 103], "abil": [12, 17, 19, 23, 28, 30, 32, 37, 38, 40, 44, 49, 51, 53, 58, 60, 66, 67, 71, 76, 78, 82, 87, 89, 97], "abl": [8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 60, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 89, 91, 92, 97, 99], "about": [1, 2, 4, 7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 56, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 103], "abov": [0, 5, 8, 10, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 68, 69, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 91, 94, 97, 99, 102, 103], "absenc": [17, 23, 27, 37, 44, 48, 53, 57, 76, 82, 86], "absolut": [11, 18, 20, 21, 23, 25, 39, 42, 44, 46, 53, 54, 55, 65, 67, 68, 69, 77, 79, 80, 82, 84, 93], "abspath": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 99, 100, 101, 102], "absurd": 67, "academ": [1, 7, 24, 45, 54, 83, 92], "accent": 67, "accept": [5, 8, 20, 21, 28, 41, 42, 49, 58, 65, 68, 69, 79, 80, 87, 92], "accept_large_spars": [61, 65], "accept_spars": [17, 37, 61, 65, 76], "access": [1, 10, 12, 14, 19, 22, 25, 27, 28, 30, 32, 34, 36, 40, 43, 46, 48, 49, 51, 52, 55, 57, 58, 60, 73, 75, 78, 81, 84, 86, 87, 89, 91, 92, 99], "accessori": [30, 51, 60, 89], "accident": [15, 16, 35, 36, 74, 75, 92], "accomod": 7, "accompani": [7, 12, 13, 32, 71, 72], "accomplish": [64, 92], "accord": [18, 20, 21, 24, 27, 31, 39, 41, 42, 45, 48, 54, 57, 61, 68, 77, 79, 80, 83, 86, 90, 99, 100, 101, 103], "account": [1, 7, 12, 14, 20, 24, 27, 31, 32, 41, 48, 54, 57, 61, 73, 79, 83, 86, 90, 92, 95, 100], "accur": [12, 14, 22, 23, 24, 27, 31, 32, 34, 43, 44, 45, 48, 52, 53, 54, 57, 61, 71, 73, 81, 82, 83, 86, 90, 91, 95, 96], "accuraci": [11, 13, 14, 15, 16, 19, 20, 22, 23, 24, 26, 29, 31, 33, 34, 35, 36, 40, 41, 43, 44, 45, 47, 50, 52, 53, 54, 56, 59, 61, 63, 64, 68, 72, 73, 74, 75, 78, 79, 81, 82, 83, 85, 88, 90, 91, 93, 95, 96, 100, 101, 103], "accuracy_scor": [20, 41, 68, 79], "acdm": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "acf": [30, 51, 60, 89], "achiev": [8, 15, 20, 35, 41, 68, 74, 79, 92, 99, 101, 102], "acinonyx": [12, 29, 32, 50, 59, 71, 88], "ackland": 67, "acoust": [15, 16, 19, 36, 40, 74, 75, 78, 99], "acquir": 11, "acquisit": [27, 48, 57, 86], "across": [12, 13, 14, 16, 20, 23, 29, 32, 33, 34, 36, 41, 44, 50, 53, 59, 67, 68, 71, 72, 73, 75, 79, 82, 88, 103], "act": [18, 38, 39, 66, 67, 77, 103], "action": [0, 12, 22, 23, 25, 27, 28, 31, 32, 43, 44, 46, 48, 49, 52, 53, 55, 57, 58, 61, 67, 69, 71, 81, 82, 84, 86, 87, 90, 103], "activ": [4, 10, 19, 40, 71, 78, 93, 95, 103], "actor": [27, 28, 48, 49, 57, 58, 86, 87], "actual": [7, 12, 18, 20, 22, 23, 25, 27, 28, 30, 31, 32, 37, 38, 39, 41, 43, 44, 46, 48, 49, 52, 53, 55, 57, 58, 61, 66, 67, 68, 69, 71, 77, 79, 81, 82, 84, 86, 87, 89, 90, 91, 99, 101], "ad": [17, 18, 19, 20, 22, 23, 24, 26, 28, 29, 31, 37, 39, 40, 41, 43, 44, 45, 47, 49, 50, 52, 53, 54, 56, 58, 59, 61, 67, 76, 77, 78, 79, 81, 82, 83, 85, 87, 88, 90, 93, 99, 102], "adam": 67, "adapt": [0, 16, 17, 20, 28, 30, 36, 37, 41, 49, 51, 52, 58, 60, 75, 76, 79, 81, 87, 89, 91, 93], "add": [7, 8, 10, 14, 16, 20, 21, 22, 23, 24, 26, 28, 30, 31, 36, 42, 43, 44, 45, 47, 49, 51, 52, 53, 54, 56, 58, 60, 61, 67, 75, 76, 79, 80, 81, 82, 83, 85, 87, 89, 90, 92, 93, 98, 100, 101, 102], "add_pip": 93, "add_subplot": 55, "addit": [0, 4, 12, 21, 27, 32, 42, 48, 57, 80, 86, 91, 100, 103], "addition": [96, 97, 103], "address": [26, 38, 47, 56, 85, 92, 100], "adelaid": [30, 89, 102], "adio": 91, "adj": [28, 49, 58, 87, 93], "adject": [28, 49, 58, 87], "adjust": [15, 19, 26, 30, 35, 40, 47, 51, 56, 64, 74, 78, 85, 89, 97], "adm": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82], "admin": [1, 103], "administr": 1, "admit": [14, 73], "adopt": [6, 27, 48, 57, 86], "ador": 67, "adp": [28, 49, 58, 87, 93], "adult": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "adult_df_larg": [22, 23, 43, 44, 52, 53, 81, 82], "adv": [28, 49, 58, 87], "advanc": [11, 17, 19, 25, 26, 27, 28, 29, 37, 40, 46, 47, 48, 49, 50, 55, 56, 57, 58, 59, 76, 78, 84, 85, 86, 87, 88, 96], "advantag": [11, 16, 17, 18, 22, 26, 27, 28, 36, 37, 38, 39, 43, 47, 48, 49, 52, 56, 66, 67, 75, 76, 77, 81, 85, 86, 87, 95], "advic": [31, 61, 90], "advis": [12, 32, 71], "advisor": 103, "af": [23, 44, 53, 82], "affect": [10, 15, 16, 18, 19, 20, 25, 30, 31, 35, 36, 39, 40, 41, 46, 51, 55, 61, 74, 75, 77, 78, 79, 84, 89, 90, 92, 93, 97], "affix": [28, 49, 58, 87], "aft": 92, "after": [4, 6, 10, 14, 16, 17, 20, 21, 23, 25, 26, 28, 29, 30, 31, 34, 36, 37, 41, 42, 44, 46, 47, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 65, 67, 68, 69, 73, 75, 76, 79, 80, 82, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 101, 102, 103], "ag": [12, 18, 20, 21, 22, 23, 24, 27, 32, 39, 41, 42, 43, 44, 45, 48, 52, 53, 57, 65, 69, 71, 77, 79, 80, 81, 82, 83, 86, 100, 101], "again": [10, 14, 16, 26, 27, 28, 29, 31, 33, 34, 36, 47, 48, 49, 50, 56, 57, 58, 59, 61, 63, 64, 65, 72, 73, 75, 85, 86, 87, 88, 90, 92, 97, 100, 101, 102], "against": [27, 28, 30, 48, 49, 51, 57, 58, 60, 86, 87, 89, 99], "agenc": [28, 49, 58, 87, 93], "agent": 1, "agglomerativeclust": [26, 47, 56, 85], "aggress": [28, 49, 58, 87], "agnost": [23, 44, 53, 82], "ago": [29, 30, 50, 51, 59, 60, 88, 89], "agre": [56, 97], "agreement": [31, 61, 90, 103], "ahead": 100, "ahm": [1, 103], "ai": [7, 9, 20, 24, 28, 29, 41, 45, 49, 50, 54, 58, 59, 79, 83, 87, 88, 100], "aight": [12, 32, 71], "aim": [65, 95], "ain": [28, 49, 58, 87], "air": 67, "airplan": 91, "airport": [20, 79, 92], "aka": [18, 31, 39, 61, 77, 90], "al": [22, 28, 43, 49, 52, 55, 58, 81, 87], "alain": [1, 103], "alamine_aminotransferas": [12, 32, 71], "alan": 1, "alaska": [18, 39, 77], "alberta": [28, 49, 87], "album": [40, 78], "albumin": [12, 32, 71], "albumin_and_globulin_ratio": [12, 32, 71], "alburi": [30, 89, 102], "alexand": 91, "alexnet": [29, 50, 59, 88], "algebra": [27, 28, 48, 49, 58, 86, 87], "algorithm": [2, 11, 12, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 32, 36, 37, 41, 42, 43, 44, 47, 49, 50, 52, 53, 58, 59, 64, 69, 71, 73, 75, 76, 79, 80, 81, 82, 85, 87, 88, 91, 92, 96, 97, 98, 100], "alia": 61, "align": [8, 12, 13, 14, 32, 33, 34, 71, 72, 73], "align_kei": [31, 61, 90], "alison": [1, 103], "aliv": 92, "alkaline_phosphotas": [12, 32, 71], "all": [0, 1, 4, 5, 6, 7, 8, 10, 14, 15, 17, 19, 21, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 36, 37, 40, 42, 43, 44, 45, 49, 50, 51, 52, 53, 54, 58, 59, 60, 61, 63, 64, 65, 67, 69, 70, 73, 74, 76, 78, 80, 81, 82, 83, 87, 88, 89, 90, 92, 93, 94, 97, 98, 99, 100, 101, 102, 103], "all_cap": 93, "all_featur": [30, 89, 102], "allei": [21, 23, 42, 44, 53, 80, 82, 91], "allen": 93, "alley_grvl": [21, 42, 44, 80], "alley_miss": [21, 42, 44, 80], "alley_pav": [21, 42, 44, 80], "alloc": [8, 28, 29, 49, 50, 58, 59, 87, 88], "allow": [5, 7, 10, 14, 16, 19, 20, 24, 28, 30, 31, 36, 40, 41, 45, 49, 51, 54, 58, 60, 61, 65, 73, 75, 78, 79, 83, 87, 89, 90, 92, 96, 97, 99, 102, 103], "allow_nan": 65, "allow_nd": [61, 65], "allpub": [21, 23, 42, 44, 53, 80, 82, 91], "allya": [1, 103], "almost": [18, 19, 21, 24, 26, 27, 28, 39, 40, 42, 45, 47, 48, 49, 54, 56, 57, 58, 77, 78, 80, 83, 85, 86, 87, 100], "alon": 67, "along": [7, 13, 17, 20, 29, 30, 37, 41, 50, 51, 59, 60, 67, 68, 72, 76, 79, 88, 89, 91, 96], "alpha": [15, 16, 30, 35, 36, 54, 61, 64, 74, 75, 89, 97, 102], "alpha_": [21, 42, 69, 80], "alphabet": [18, 39, 77], "alphago": [12, 25, 32, 46, 55, 71, 84], "alq": [21, 23, 42, 44, 53, 69, 80, 82, 91], "alreadi": [4, 8, 10, 11, 12, 20, 21, 23, 25, 28, 30, 31, 32, 42, 44, 46, 49, 53, 55, 58, 61, 69, 79, 80, 82, 84, 87, 89, 90, 91, 93, 96, 99, 102], "also": [1, 2, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "altar": [29, 50, 59, 88], "altern": [8, 19, 25, 40, 46, 64, 69, 78, 84, 91, 99, 103], "although": [14, 22, 25, 27, 31, 34, 43, 46, 48, 49, 55, 57, 61, 73, 81, 84, 86, 90], "alwai": [12, 13, 15, 17, 18, 20, 21, 22, 23, 25, 26, 27, 32, 33, 35, 36, 37, 39, 41, 42, 43, 44, 46, 47, 48, 52, 53, 55, 56, 57, 63, 65, 67, 68, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86, 93, 95, 96, 97, 99, 103], "am": [16, 28, 32, 36, 38, 49, 58, 66, 67, 69, 75, 84, 87, 91, 93, 103], "amateurish": 67, "amatriain": [27, 48, 57, 86], "amaz": [65, 67], "amazon": [12, 25, 27, 32, 46, 48, 55, 57, 71, 84, 86, 93], "ambienc": 65, "ambigu": [28, 49, 87], "amer": [20, 41, 79], "america": [17, 28, 49, 58, 76, 87], "american": [25, 46, 65, 84], "amicu": 67, "amirali": [1, 103], "aml": [16, 36, 75], "among": [12, 13, 19, 20, 22, 23, 27, 32, 33, 40, 41, 43, 44, 48, 53, 57, 68, 71, 72, 78, 79, 81, 82, 86, 101], "amongst": 93, "amount": [4, 12, 14, 18, 19, 20, 21, 23, 25, 29, 30, 31, 32, 34, 39, 40, 41, 42, 44, 46, 50, 51, 53, 55, 59, 60, 61, 68, 69, 71, 73, 77, 78, 79, 80, 82, 84, 88, 89, 90, 92, 99, 102], "amp": [22, 23, 43, 44, 52, 53, 67, 81, 82], "amplifi": [20, 28, 41, 49, 58, 79, 87, 100], "amuel": [16, 36, 75], "an": [0, 1, 2, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 94, 95, 98, 99, 101, 102, 103], "anaconda": [10, 23, 29, 44, 53, 82, 93], "anaconda3": [33, 37, 50], "analogi": [26, 28, 35, 47, 49, 58, 85, 87, 91], "analysi": [1, 2, 9, 11, 13, 20, 21, 25, 26, 28, 41, 42, 46, 47, 49, 51, 55, 58, 60, 72, 79, 80, 84, 85, 87, 91, 100], "analyt": [30, 51, 60, 89], "analyz": [11, 20, 24, 30, 31, 38, 41, 45, 52, 54, 61, 68, 79, 83, 89, 90, 91, 102], "anatinu": [29, 50, 59, 88], "anca": [1, 103], "ancestor": [24, 45, 54, 83], "ancestr": 103, "ancuta": [1, 103], "andrea": [1, 9], "andrew": [1, 9, 19, 24, 40, 45, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 78, 83, 103], "anemon": [29, 50, 59, 88], "angel": [31, 61, 90, 93], "angl": 67, "ani": [0, 10, 13, 14, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 68, 72, 73, 75, 76, 77, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 103], "anim": [20, 29, 41, 50, 59, 64, 79, 88], "animal_fac": [29, 50, 59, 64, 88], "anita": 67, "anneal": [24, 45, 54, 83], "annoi": 67, "annot": [23, 25, 44, 46, 53, 55, 82, 84], "announc": 7, "annoyingli": [21, 42, 69, 80], "annual": 93, "anomali": [20, 21, 25, 42, 46, 55, 69, 79, 80, 84], "anonym": [30, 51, 60, 89], "anorm": 61, "anoth": [8, 10, 13, 15, 18, 19, 20, 22, 23, 25, 26, 27, 29, 30, 31, 33, 35, 39, 40, 41, 43, 44, 46, 47, 48, 50, 51, 52, 53, 55, 57, 59, 60, 61, 68, 72, 74, 77, 78, 79, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92, 95, 96, 98, 101, 102], "answer": [4, 6, 7, 12, 13, 14, 19, 22, 25, 27, 28, 30, 32, 34, 40, 43, 46, 48, 49, 51, 52, 55, 57, 58, 60, 66, 67, 71, 72, 73, 78, 81, 84, 86, 87, 89, 91, 94, 96, 97, 100, 101, 102, 103], "anteat": [29, 50, 59, 88], "anthologi": 67, "anti": [31, 61, 90], "anymor": [21, 25, 27, 42, 46, 48, 55, 57, 69, 80, 84, 86, 97], "anyon": [12, 67, 69, 91, 92], "anyth": [0, 12, 14, 17, 20, 27, 28, 31, 32, 34, 37, 41, 48, 49, 57, 58, 59, 61, 65, 68, 69, 73, 76, 79, 86, 87, 90, 92, 99], "anytim": 103, "anywher": [17, 37, 76], "ap": [11, 95], "ap_lr": [20, 41, 68, 79], "ap_svc": [20, 41, 68, 79], "apart": [15, 26, 35, 47, 56, 67, 74, 85], "apeendixa": 83, "api": [20, 28, 30, 49, 51, 58, 61, 65, 79, 87, 89, 95], "app": [12, 13, 32, 33, 72, 93, 95], "appar": 67, "appeal": [49, 58, 87], "appear": [2, 7, 17, 22, 37, 43, 52, 76, 81, 92, 97, 101, 103], "append": [4, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 96, 97, 98, 99, 100, 101], "appendix": [24, 54], "appendix_b": [28, 49, 58, 87], "appendixa": 45, "appendixb": [29, 50, 59, 88], "appl": [28, 49, 58, 87], "appli": [0, 2, 6, 9, 11, 12, 13, 14, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 66, 67, 71, 72, 73, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 98], "applic": [0, 5, 12, 17, 19, 20, 21, 23, 24, 28, 29, 31, 32, 37, 40, 41, 42, 44, 45, 49, 53, 54, 61, 69, 71, 76, 78, 79, 80, 82, 83, 87, 90, 92, 93, 95, 100, 103], "appreci": [11, 84, 103], "approach": [1, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 35, 36, 37, 40, 41, 42, 43, 44, 46, 49, 50, 52, 53, 54, 55, 58, 64, 65, 69, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 87, 88, 95, 97, 102], "appropri": [0, 4, 10, 11, 13, 14, 17, 20, 21, 25, 26, 30, 31, 33, 34, 37, 41, 42, 46, 47, 51, 54, 55, 56, 60, 61, 63, 69, 72, 73, 76, 79, 80, 84, 85, 89, 90, 92, 95, 103], "approv": [20, 41, 79, 100, 103], "approx": [15, 23, 35, 44, 53, 74, 82], "approxim": [13, 19, 24, 33, 40, 45, 54, 72, 78, 83, 92], "apr": 1, "april": [30, 89], "apt": 5, "ar": [0, 1, 2, 4, 6, 7, 8, 9, 10, 14, 15, 17, 19, 21, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 37, 38, 40, 42, 43, 44, 45, 49, 50, 51, 52, 53, 54, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 73, 74, 76, 78, 80, 81, 82, 83, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "arang": [8, 14, 15, 18, 19, 20, 21, 34, 35, 38, 39, 40, 41, 42, 63, 64, 66, 67, 68, 69, 73, 74, 77, 78, 79, 80, 97, 99], "arbitrari": [23, 25, 26, 30, 44, 46, 47, 51, 53, 55, 56, 60, 82, 84, 85, 89], "architectur": [29, 50, 59, 88], "area": [19, 21, 22, 24, 25, 40, 42, 43, 45, 46, 52, 54, 55, 67, 69, 78, 80, 81, 83, 84, 91, 99], "aren": [7, 21, 24, 25, 28, 29, 30, 42, 45, 46, 49, 50, 51, 54, 55, 58, 59, 60, 67, 69, 80, 83, 84, 87, 88, 89, 93, 102], "arena": [24, 45, 54, 83], "arg": [14, 17, 34, 37, 61, 64, 65, 73, 76, 93], "argh": [31, 90], "argmax": [38, 64, 67], "argmin": [14, 15, 20, 25, 34, 35, 41, 46, 68, 70, 73, 74, 79, 84], "argsort": [23, 28, 44, 49, 53, 58, 70, 82, 87], "argu": [25, 28, 32, 46, 49, 55, 58, 84, 87, 99], "argument": [8, 13, 17, 19, 20, 21, 23, 33, 37, 40, 41, 42, 44, 53, 54, 68, 69, 72, 76, 78, 79, 80, 82, 91, 93, 95, 98], "arima": [30, 51, 60, 89], "arima_model": [30, 51, 60, 89], "aris": [0, 12, 28, 49, 58, 71, 87], "aristotl": [15, 35, 74], "arithmet": 8, "ariti": 61, "arm": 67, "armi": 67, "aroth85": 62, "around": [7, 15, 17, 20, 21, 30, 31, 35, 37, 38, 40, 41, 42, 51, 60, 61, 67, 68, 69, 74, 76, 79, 80, 89, 90, 96], "aroundn": [12, 71], "arr": [31, 61, 65, 90], "arr1": 8, "arr2": 8, "arrai": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 66, 67, 68, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 99], "array_equ": 8, "array_orig": 65, "arriv": [24, 45, 54, 83], "art": 91, "arthur": [12, 32, 71], "articl": [1, 13, 14, 16, 20, 25, 27, 28, 29, 33, 36, 41, 46, 48, 49, 50, 55, 57, 59, 72, 73, 75, 79, 84, 86, 87, 88, 91], "articul": [91, 95], "artifici": [1, 28, 49, 58, 87], "artist": [15, 16, 19, 36, 40, 74, 75, 78, 99], "as_fram": [15, 35, 54, 64, 74, 97], "asarrai": [61, 65], "ascend": [8, 17, 18, 19, 21, 22, 23, 24, 30, 31, 37, 38, 39, 40, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 63, 66, 67, 69, 76, 77, 78, 80, 81, 82, 83, 89, 90, 95, 101], "ased": [26, 47, 56, 85], "asi": 93, "asia": [17, 76], "asid": [4, 14, 22, 34, 43, 52, 73, 81, 97], "ask": [3, 7, 10, 12, 13, 14, 15, 17, 20, 24, 25, 27, 28, 31, 32, 33, 34, 37, 41, 45, 46, 48, 49, 54, 57, 58, 61, 67, 71, 72, 73, 74, 76, 79, 83, 84, 86, 87, 90, 91, 93, 96, 103], "asleep": [18, 39, 77], "aspartate_aminotransferas": [12, 32, 71], "aspect": [18, 23, 24, 26, 27, 31, 39, 44, 45, 47, 48, 53, 54, 56, 57, 61, 77, 82, 83, 85, 86, 90, 91, 95], "assault": 103, "assert": [7, 17, 20, 22, 23, 37, 41, 43, 44, 52, 53, 76, 79, 81, 82, 100], "assess": [1, 6, 11, 12, 13, 14, 16, 20, 23, 32, 33, 34, 36, 41, 44, 53, 65, 68, 71, 72, 73, 75, 79, 82, 84, 91, 103], "asset": 29, "assign": [1, 4, 6, 8, 10, 12, 13, 15, 16, 18, 19, 23, 24, 25, 26, 28, 30, 31, 32, 33, 35, 36, 39, 40, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 60, 61, 64, 72, 74, 75, 76, 77, 78, 81, 82, 83, 84, 85, 87, 89, 90, 91, 92, 93, 95, 96, 98, 100, 102], "assist": [12, 32, 71], "assoc": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "associ": [0, 12, 14, 15, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 38, 41, 42, 44, 45, 46, 49, 50, 51, 53, 54, 55, 58, 59, 60, 61, 66, 67, 69, 71, 73, 74, 79, 80, 82, 83, 84, 87, 88, 89, 90, 91, 92, 95, 101, 103], "assum": [12, 13, 17, 18, 20, 21, 26, 27, 28, 30, 32, 37, 39, 41, 47, 48, 49, 51, 56, 57, 58, 60, 71, 72, 76, 77, 79, 80, 85, 86, 87, 89, 91, 95, 100], "assume_a": 61, "assumpt": [31, 61, 90], "asterisk": [19, 40, 78], "astyp": [8, 30, 31, 38, 51, 60, 61, 64, 65, 66, 67, 89, 90, 102], "astype_arrai": [31, 61, 90], "astype_array_saf": [31, 61, 90], "astype_is_view": [61, 65], "async_": 93, "async_help": 93, "asyncio": 93, "asyncio_loop": 93, "aten": [29, 50], "atmospher": 67, "atratu": [29, 50, 59, 88], "attack": [13, 28, 33, 49, 58, 67, 72], "attempt": [14, 34, 40, 64, 73, 99, 100], "attend": 103, "attent": [6, 28, 49, 58, 87, 92], "attic": [21, 42, 69, 80], "attract": [49, 58, 87], "attribut": [0, 1, 12, 13, 15, 16, 18, 19, 24, 25, 28, 29, 32, 33, 35, 36, 38, 39, 40, 45, 46, 49, 50, 54, 58, 59, 66, 67, 71, 72, 74, 75, 77, 78, 83, 84, 87, 88, 99, 101], "attrit": [31, 61, 90], "auc": [11, 31, 61, 90, 92, 95, 100], "audienc": [11, 91, 92, 100], "audio": [29, 50, 59, 88, 103], "audit": [92, 103], "auditor": 103, "augment": [20, 79], "august": [30, 51, 60, 89], "austin": [28, 49, 87], "australia": [30, 89, 102], "auteur": 67, "authent": [25, 46, 84], "author": [0, 28, 49, 58, 87, 103], "auto": [12, 19, 20, 24, 25, 30, 32, 40, 41, 45, 46, 54, 55, 70, 71, 78, 79, 83, 84, 91], "autocorrel": [30, 51, 60, 89], "autodiff": 59, "autom": [13, 21, 28, 33, 42, 49, 58, 72, 80, 87, 91], "automat": [16, 17, 21, 24, 28, 30, 31, 36, 37, 42, 45, 49, 54, 58, 59, 61, 67, 69, 75, 76, 80, 83, 87, 89, 90, 91, 102], "autoregress": [18, 39, 77], "autos": 58, "autumn": [30, 89], "autumn_month": [30, 89], "aux": [28, 49, 58, 87, 93], "av": [21, 23, 28, 42, 44, 49, 53, 69, 80, 82, 87, 91], "avail": [0, 1, 7, 9, 10, 12, 14, 17, 19, 20, 21, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 40, 41, 42, 47, 48, 49, 50, 51, 54, 56, 57, 58, 59, 60, 61, 70, 73, 76, 78, 79, 80, 85, 86, 87, 88, 89, 90, 95, 100, 101, 102, 103], "avebedrm": [18, 39, 77], "aveoccup": [18, 39, 77], "averag": [11, 14, 15, 17, 18, 19, 21, 23, 25, 26, 28, 31, 34, 35, 37, 39, 40, 42, 44, 46, 47, 49, 53, 55, 61, 68, 69, 73, 74, 76, 77, 78, 80, 82, 84, 85, 87, 90, 92, 93, 95, 97], "average_precis": [20, 41, 68, 79], "average_precision_scor": [20, 41, 68, 79], "average_word_length": 93, "averaging_model": [22, 43, 52, 81, 101], "averaging_model_ndt": [22, 43, 52, 81], "averoom": [18, 39, 77], "avg": [20, 27, 30, 41, 48, 51, 57, 60, 79, 86, 89], "avg_sent_emb": [28, 49, 58, 87], "avocado": 91, "avoid": [7, 8, 13, 16, 20, 21, 26, 30, 31, 36, 41, 42, 47, 51, 54, 56, 60, 61, 66, 67, 69, 72, 75, 79, 80, 85, 89, 90, 91, 92, 94, 95, 97, 100, 103], "aw": [65, 67, 92], "awai": [4, 6, 13, 18, 25, 27, 29, 31, 33, 39, 46, 48, 50, 55, 57, 59, 61, 72, 77, 84, 86, 88, 90, 91, 92, 95], "await": 93, "awar": [17, 37, 61, 76, 90, 91, 103], "awesom": [9, 67], "ax": [14, 15, 18, 20, 25, 26, 29, 31, 34, 35, 39, 41, 46, 47, 50, 54, 55, 58, 59, 61, 64, 70, 73, 74, 77, 79, 84, 85, 88, 90, 91, 97, 100], "axi": [7, 8, 12, 13, 14, 16, 17, 18, 23, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 44, 46, 47, 49, 50, 51, 53, 56, 58, 59, 64, 70, 71, 72, 73, 75, 76, 77, 82, 84, 85, 87, 88, 89, 91, 102], "axvlin": [25, 46, 55, 84], "az": 93, "b": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 90, 91], "b1": 61, "b3": [75, 82], "babe": [12, 32, 71], "babi": [24, 28, 45, 49, 54, 58, 83, 87], "babysitt": 67, "bachelor": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "back": [8, 16, 19, 28, 36, 40, 49, 58, 63, 64, 75, 78, 87, 95], "backdrop": [30, 51, 60, 89], "backend": [29, 50], "background": [11, 72, 91, 92], "bad": [8, 13, 14, 15, 20, 21, 22, 23, 24, 25, 29, 30, 33, 34, 35, 41, 42, 43, 44, 45, 46, 50, 51, 52, 54, 56, 59, 60, 65, 67, 69, 72, 73, 74, 76, 79, 80, 81, 82, 83, 84, 88, 89], "badgeryscreek": [30, 89], "bag": [24, 28, 29, 38, 45, 49, 50, 54, 58, 59, 65, 66, 67, 83, 87, 88, 95, 99], "bai": [16, 24, 36, 45, 54, 75, 76, 83], "baidu": [14, 73], "bal_scor": [20, 41, 79], "balanc": [6, 15, 22, 27, 35, 38, 43, 48, 52, 57, 65, 66, 67, 74, 81, 84, 86, 94, 100, 101], "ballarat": [30, 89, 102], "balltre": 65, "balust": [29, 50, 59, 88], "balustrad": [29, 50, 59, 88], "bambi": [19, 27, 48, 57, 86], "banist": [29, 50, 59, 88], "bank": [20, 23, 30, 31, 41, 44, 51, 53, 60, 61, 79, 82, 89, 90, 100], "bannist": [29, 50, 59, 88], "bar": [20, 21, 23, 29, 30, 31, 41, 42, 44, 50, 53, 59, 61, 68, 69, 79, 80, 82, 88, 89, 90, 91, 92, 102], "baranski": 93, "barbu": [1, 103], "bare": 67, "barrel": 67, "barri": [18, 39, 77], "base": [5, 8, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 23, 25, 26, 28, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 46, 47, 49, 53, 55, 56, 58, 61, 64, 65, 68, 69, 72, 73, 75, 76, 77, 78, 79, 80, 82, 84, 85, 87, 90, 91, 92, 93, 95, 96, 99, 100, 101, 103], "base_ev": 93, "base_scor": [22, 43, 52, 81], "base_valu": [23, 44, 53, 82], "baseblockmanag": [31, 61, 90], "baselin": [31, 61, 64, 90, 92, 95, 96, 98, 99, 102], "baseline_cumulative_hazard_": 61, "baseline_estimation_method": 61, "baseline_hazard_": [31, 61, 90], "bash": 5, "basi": [13, 15, 33, 35, 72, 74], "basic": [2, 8, 12, 13, 19, 24, 27, 29, 31, 32, 33, 40, 45, 48, 50, 54, 57, 59, 61, 67, 72, 78, 83, 86, 88, 90, 93, 101, 102], "batch": [28, 29, 49, 50, 58, 59, 64, 87, 88], "batch_mod": 61, "batch_siz": [29, 50, 59, 64, 70, 88], "batch_t": [29, 50, 59, 88], "bath": [12, 32, 67, 71], "bathroom": [12, 13, 18, 32, 39, 63, 71, 72, 77], "bayesian": [19, 40, 59, 78], "bayesopt": [19, 40, 78], "bazazeh": [1, 103], "bbc": 67, "beagl": [12, 29, 32, 50, 59, 71, 88], "bear": [29, 50, 59, 88], "beat": [22, 31, 43, 52, 61, 81, 90], "beatric": 67, "beauti": [27, 28, 48, 49, 57, 58, 67, 86, 87, 91], "becam": [29, 50, 59, 88], "becaus": [1, 7, 8, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 67, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 97, 100, 102, 103], "becom": [4, 14, 15, 18, 19, 20, 23, 24, 25, 28, 34, 35, 39, 40, 44, 45, 46, 49, 53, 54, 55, 58, 68, 69, 73, 74, 77, 78, 79, 82, 83, 84, 87], "bed": [20, 79, 92], "bedroom": [12, 13, 18, 32, 33, 39, 63, 71, 72, 77], "bedroomabvgr": [21, 23, 42, 44, 53, 69, 80, 82, 91], "bedrooms_per_household": [16, 36, 75, 76, 98], "beef": [28, 49, 58, 65, 87], "been": [1, 4, 6, 12, 13, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 67, 68, 69, 71, 72, 75, 76, 77, 78, 79, 80, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 97, 103], "befor": [1, 4, 10, 13, 14, 15, 17, 18, 21, 22, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 39, 42, 43, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 61, 65, 67, 69, 70, 71, 72, 73, 74, 76, 77, 80, 81, 84, 85, 86, 87, 88, 89, 90, 92, 96, 97, 99, 100, 101, 102], "begin": [18, 24, 27, 30, 31, 39, 45, 48, 51, 54, 57, 60, 61, 65, 72, 77, 83, 86, 89, 90, 95], "beginn": [29, 50, 59, 88], "behav": [19, 23, 40, 44, 53, 78, 82], "behavior": [20, 27, 36, 41, 48, 57, 68, 73, 75, 79, 86, 92], "behaviour": [17, 37, 76, 100, 101], "behind": [11, 12, 18, 32, 39, 40, 71, 77, 103], "being": [4, 12, 14, 16, 20, 21, 22, 23, 26, 28, 31, 32, 34, 36, 41, 42, 43, 47, 49, 53, 56, 58, 61, 68, 71, 73, 75, 79, 80, 81, 82, 85, 87, 90, 91, 97, 103], "belief": 91, "believ": [19, 23, 30, 40, 51, 53, 60, 63, 67, 78, 82, 89], "bell": [29, 50, 59, 88], "belong": [13, 18, 26, 39, 47, 56, 72, 77, 85, 96], "below": [1, 5, 8, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 99, 100, 101, 102, 103], "bench": [29, 50, 59, 88], "benchmark": [29, 50, 59, 63, 88], "bendigo": [30, 89, 102], "benefici": [17, 37, 76, 91], "benefit": [4, 15, 22, 26, 28, 43, 47, 49, 56, 58, 74, 81, 85, 87, 91, 95], "bengio": [19, 40, 78], "bennett": 67, "bento": 58, "ber": [28, 49, 87], "bergammi": 67, "bergstra": [19, 40, 78], "berri": [28, 49, 87], "bertop": [28, 49, 58, 87], "best": [2, 13, 14, 15, 19, 20, 21, 22, 23, 25, 26, 27, 31, 33, 34, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 55, 56, 57, 61, 63, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 84, 85, 86, 90, 91, 92, 96, 97, 99, 101], "best_alpha": [21, 42, 69, 80], "best_c": 64, "best_depth": [14, 34, 63, 73], "best_estimator_": [19, 21, 40, 42, 69, 78, 80], "best_k": 64, "best_n_neighbour": [15, 35, 74], "best_param": [19, 40, 78, 91], "best_paramet": [19, 40, 78], "best_params_": [19, 21, 40, 42, 69, 78, 80, 91, 99], "best_scor": [19, 40, 78], "best_score_": [19, 21, 40, 42, 69, 78, 80, 99], "best_svr": 91, "bestalpha_coeff": [21, 42, 69, 80], "beta_": 61, "better": [6, 12, 13, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 64, 65, 69, 70, 71, 72, 74, 75, 76, 77, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 92, 95, 96, 97, 98, 99, 100, 101, 103], "between": [2, 8, 10, 11, 12, 14, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 68, 69, 70, 71, 73, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 97], "bewar": [28, 49, 58, 87], "beyond": [14, 19, 24, 34, 40, 45, 54, 73, 78, 83, 91], "bhatt": [1, 103], "bia": [18, 20, 23, 31, 39, 41, 44, 49, 53, 61, 77, 79, 82, 90, 92, 95, 100], "bias": [11, 20, 23, 28, 31, 41, 44, 49, 53, 61, 79, 82, 87, 90, 100], "bicycl": [13, 30, 33, 51, 60, 72, 89], "big": [7, 15, 17, 19, 20, 22, 24, 25, 26, 27, 28, 29, 31, 35, 37, 38, 40, 41, 43, 45, 46, 47, 48, 49, 50, 54, 55, 56, 57, 58, 59, 61, 65, 66, 67, 69, 74, 76, 78, 79, 81, 83, 84, 85, 86, 87, 88, 90, 91, 97], "bigalpha_coeff": [21, 42, 69, 80], "bigger": [15, 17, 18, 21, 23, 26, 28, 29, 30, 35, 39, 42, 44, 47, 49, 50, 51, 53, 56, 58, 59, 69, 70, 74, 76, 77, 80, 82, 85, 87, 88, 89], "biggest": [21, 24, 42, 45, 54, 80, 83, 102], "bigotri": 67, "bike": [30, 51, 60, 89], "bill": [29, 50, 59, 88], "billboard": [30, 51, 60, 89], "billie_holidai": [28, 49, 87], "billion": [21, 42, 69, 80], "billionth": [30, 51, 89], "bin": [16, 19, 21, 24, 30, 31, 36, 40, 42, 45, 51, 54, 60, 61, 65, 69, 75, 78, 80, 83, 89, 90, 91, 93, 96], "binar": [13, 17, 33, 37, 72, 76], "binari": [13, 16, 17, 18, 29, 31, 33, 36, 37, 39, 50, 59, 61, 65, 72, 75, 76, 77, 88, 90, 91, 94, 95, 100], "binary_feat": [17, 37, 65, 76], "binary_featur": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100, 101], "binary_transform": [20, 22, 23, 41, 43, 44, 52, 53, 65, 79, 81, 82, 100, 101], "bincount": [20, 22, 41, 43, 52, 79, 81, 100], "bind": [15, 35, 64, 74, 97], "binomi": [19, 40, 78], "biolog": [24, 45, 54, 83], "biologi": [17, 37, 76], "bird": [67, 70], "birds_class": 70, "birds_input": 70, "bit": [10, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 29, 30, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 50, 51, 52, 53, 59, 60, 61, 64, 66, 67, 68, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 84, 88, 89, 90, 91, 99, 100, 102], "bite": 67, "black": [15, 23, 25, 29, 30, 35, 44, 46, 50, 53, 55, 59, 74, 82, 84, 88, 89, 102], "blackhawk": [28, 49, 87], "bland": 67, "bld": [29, 50, 93], "bldgtype": [21, 23, 42, 44, 53, 80, 82, 91], "bldgtype_1fam": [21, 42, 80], "bldgtype_2fmcon": [21, 42, 80], "bldgtype_duplex": [21, 42, 80], "bldgtype_twnh": [21, 42, 80], "bldgtype_twnhs": [21, 42, 80], "blei": [28, 49, 58, 87], "blend": [28, 49, 58, 87], "blindli": [20, 21, 41, 42, 79, 80], "blob": [12, 94], "block": [18, 31, 39, 61, 77, 90], "blog": [28, 30, 49, 51, 58, 60, 87, 89], "blood": 67, "bloomberg": [1, 9], "blq": [21, 23, 42, 44, 53, 69, 80, 82, 91], "blue": [13, 15, 19, 20, 23, 24, 25, 30, 33, 35, 40, 41, 44, 45, 46, 51, 53, 54, 55, 72, 74, 78, 79, 82, 83, 84, 89], "bluesman": [28, 49, 87], "bmatrix": [24, 27, 45, 48, 54, 57, 83, 86], "board": 4, "boathous": [29, 50, 59, 88], "bob_dylan": [28, 49, 87], "bodi": 93, "boggl": [22, 52, 81], "boi": 67, "bold": 91, "bond": [20, 79, 92], "bonu": [22, 43, 52, 81], "book": [9, 20, 21, 27, 28, 30, 42, 48, 49, 51, 54, 57, 58, 60, 69, 79, 80, 86, 87, 89, 91, 103], "bool": [21, 30, 38, 42, 51, 61, 66, 67, 69, 80, 89], "bool_t": [61, 65], "boom": 93, "boost": [28, 49, 58, 87, 92, 95], "booster": [22, 43, 52, 81], "bootstrap": [10, 91], "border": [13, 18, 26, 28, 39, 47, 49, 56, 58, 72, 77, 85, 87, 94, 96], "bore": [18, 38, 39, 66, 67, 77], "boston": [18, 39, 77], "both": [2, 6, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 65, 66, 67, 69, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 95, 98, 99, 100, 103], "bother": [23, 44, 53, 82], "bottom": [26, 47, 56, 67, 85], "bought": [27, 48, 57, 86], "bound": [24, 31, 45, 61, 83, 90], "boundari": [14, 26, 28, 34, 47, 49, 56, 58, 73, 85, 87, 91, 92, 97], "bow": [38, 66, 67], "bow_df": [17, 37, 76], "box": [9, 23, 44, 53, 82, 95], "boxplot": [23, 44, 53, 82], "boyc": [33, 72], "br": [28, 38, 49, 58, 66, 67, 87], "bracket": 8, "brain": [24, 29, 45, 50, 54, 59, 83, 88], "branch": [13, 26, 28, 31, 33, 47, 49, 56, 61, 72, 85, 87, 90], "brand": 91, "breach": 67, "break": [1, 20, 36, 38, 41, 66, 67, 68, 79, 95, 97], "breakdown": 32, "breakwat": [29, 50, 59, 88], "breath": 95, "breathtak": [28, 49, 58, 87], "breed": 95, "breiman": [22, 43, 52, 81], "breslow": 61, "bridg": 67, "brief": [4, 18, 22, 39, 43, 52, 77, 81], "briefli": [12, 20, 22, 24, 32, 41, 43, 45, 52, 54, 68, 71, 79, 81, 83], "bring": [6, 23, 26, 44, 47, 53, 56, 63, 82, 85, 92, 93, 95], "british": [1, 28, 49, 58, 87], "british_columbia": [28, 49, 87], "broad": [15, 35, 64, 74, 87, 97], "broadcast": [28, 49, 58, 87], "broader": [2, 22, 28, 43, 49, 52, 58, 81, 87], "broadest": 87, "broadli": [13, 15, 18, 20, 22, 25, 26, 28, 33, 35, 39, 41, 43, 46, 47, 49, 52, 55, 56, 58, 72, 74, 77, 79, 81, 84, 85, 87], "broken": 67, "broth": 65, "brownle": [24, 45, 54, 83], "browser": 10, "bruno": 67, "brush": [29, 50, 59, 88], "bryan": 67, "bsmtcond": [21, 23, 42, 44, 53, 69, 80, 82, 91], "bsmtexposur": [21, 23, 42, 44, 53, 69, 80, 82, 91], "bsmtfinsf1": [21, 23, 42, 44, 53, 69, 80, 82, 91], "bsmtfinsf2": [21, 23, 42, 44, 53, 69, 80, 82, 91], "bsmtfintype1": [21, 23, 42, 44, 53, 69, 80, 82, 91], "bsmtfintype2": [21, 23, 42, 44, 53, 69, 80, 82, 91], "bsmtfullbath": [21, 23, 42, 44, 53, 69, 80, 82, 91], "bsmthalfbath": [21, 23, 42, 44, 53, 69, 80, 82, 91], "bsmtqual": [21, 23, 42, 44, 53, 69, 80, 82, 91], "bsmtunfsf": [21, 23, 42, 44, 53, 69, 80, 82, 91], "btw": [23, 44, 61, 82], "bubbl": [27, 29, 48, 50, 57, 59, 86, 88], "bucket": [24, 45, 54, 83, 93], "buddi": 67, "budget": [19, 27, 40, 48, 57, 78, 86], "bug": [4, 8, 56], "bui": [27, 48, 57, 86, 92], "build": [0, 2, 10, 11, 14, 16, 17, 22, 24, 25, 28, 30, 34, 36, 37, 43, 45, 46, 49, 51, 52, 54, 55, 58, 59, 60, 65, 69, 73, 75, 76, 81, 83, 84, 87, 89, 91, 94, 97, 102], "built": [8, 12, 13, 14, 18, 19, 23, 30, 32, 33, 39, 40, 44, 53, 71, 72, 73, 77, 78, 82, 89, 91, 92, 102], "bullshit": [1, 31, 61, 90], "bulwark": [29, 50, 59, 88], "bunch": [8, 10, 13, 21, 22, 29, 31, 33, 42, 43, 50, 52, 59, 61, 63, 69, 72, 80, 81, 88, 90, 91, 92, 97], "bundl": [7, 10], "bureau": [18, 39, 77], "burger": 58, "busi": [20, 25, 31, 41, 46, 55, 61, 68, 79, 84, 90, 93], "businesswoman": [28, 49, 58, 87], "bustl": [30, 51, 60, 89], "butterfli": [26, 47, 85], "buzz": [12, 32, 71], "bypass": 103, "c": [0, 1, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 97, 99, 103], "c1": [26, 47, 56, 85], "c2": [26, 47, 56, 85], "c_1": [25, 46, 55, 84], "c_2": [25, 46, 55, 84], "c_3": [25, 46, 55, 84], "c_log": [15, 35, 64, 74, 97], "c_val": 64, "c_valu": 64, "c_widget": [15, 35, 64, 74, 97], "ca": [1, 5, 9, 12, 32, 92, 93, 103], "ca_transform": [17, 37, 76], "cache_s": 91, "cal_hous": [18, 39, 77], "calcul": [7, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 30, 34, 35, 36, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 63, 68, 70, 73, 74, 75, 79, 80, 81, 82, 83, 84, 85, 86, 89, 92, 93, 94, 95, 97, 100, 102], "calgary_flam": [28, 49, 87], "calibr": 92, "california": [16, 24, 36, 45, 54, 75, 83], "california_h": [24, 45, 54, 83], "californian": [16, 36, 75], "call": [1, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 99, 101, 102], "callback": [22, 43, 52, 81], "caller": 92, "calll": 54, "calm": 95, "came": [30, 51, 60, 89], "camera": [17, 37, 67, 76], "campu": [24, 45, 54, 83, 103], "can": [1, 4, 6, 7, 10, 12, 13, 15, 17, 18, 19, 20, 21, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 45, 47, 48, 49, 50, 51, 54, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "canada": [5, 14, 15, 17, 18, 28, 34, 35, 37, 39, 49, 58, 73, 74, 76, 77, 87, 91, 93, 95], "canada_usa_c": [13, 14, 15, 18, 34, 35, 39, 72, 73, 74, 77, 96], "canadian": [28, 49, 58, 65, 87], "canadien": [28, 49, 87], "canberra": [30, 89, 102], "cancel": 103, "cancer": [12, 24, 32, 45, 58, 60, 71, 83], "candid": [19, 22, 28, 40, 49, 58, 63, 78, 81, 87, 97], "cannibalist": 67, "cannonbal": 19, "cannot": [0, 8, 12, 14, 15, 19, 20, 22, 23, 24, 26, 29, 30, 31, 32, 34, 35, 40, 41, 43, 44, 45, 47, 50, 51, 52, 53, 54, 56, 60, 61, 68, 73, 74, 78, 79, 81, 82, 83, 85, 89, 90, 91, 93, 103], "canuck": [28, 49, 87], "canva": [1, 7, 12, 13, 32, 92], "cap": [28, 49, 58], "capabl": [9, 28, 49, 58], "capit": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "caption": [7, 29, 50, 59, 88], "captiv": [28, 49, 58, 87], "captur": [11, 14, 16, 18, 22, 24, 26, 27, 28, 30, 31, 34, 36, 39, 43, 45, 47, 48, 49, 51, 52, 54, 56, 57, 58, 60, 61, 73, 75, 77, 81, 83, 85, 86, 87, 89, 90, 95], "car": [12, 28, 29, 32, 49, 50, 58, 59, 71, 87, 88, 92], "card": [12, 13, 20, 31, 32, 33, 41, 61, 68, 71, 72, 79, 90, 91, 100], "care": [5, 7, 14, 16, 19, 20, 21, 23, 24, 25, 30, 31, 34, 36, 40, 41, 42, 44, 45, 46, 51, 53, 54, 55, 60, 61, 68, 73, 75, 78, 79, 80, 82, 83, 84, 89, 90, 95, 99, 101, 102], "carefulli": [1, 12, 20, 21, 32, 41, 42, 79, 80, 100, 103], "carpentri": 5, "carri": [13, 14, 15, 17, 19, 20, 21, 22, 25, 27, 28, 30, 33, 34, 35, 37, 40, 41, 42, 43, 46, 48, 49, 51, 52, 55, 57, 58, 60, 63, 65, 69, 72, 73, 74, 76, 78, 79, 80, 81, 84, 86, 87, 89, 92, 93, 97, 99, 102], "caruana": [23, 44, 53, 82], "case": [6, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 57, 58, 60, 61, 65, 66, 67, 68, 69, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91, 92, 94, 95, 102, 103], "cash": [12, 32, 67, 71], "cast": [27, 48, 57, 67, 78, 86, 93], "castl": [29, 50, 59, 88], "cat": [12, 20, 22, 28, 29, 32, 41, 43, 49, 50, 52, 58, 59, 64, 70, 71, 79, 81, 87, 88, 93, 95], "catamount": [12, 29, 32, 50, 59, 71, 88], "catboost": [11, 23, 44, 53, 82, 91, 95], "catboostclassifi": [22, 43, 52, 81], "catboostregressor": [22, 43, 52, 81], "catch": [20, 41, 79, 103], "categor": [13, 19, 20, 21, 22, 24, 25, 27, 28, 31, 33, 40, 41, 42, 43, 45, 46, 48, 49, 52, 54, 55, 57, 58, 61, 63, 68, 69, 70, 72, 78, 79, 80, 81, 83, 84, 86, 87, 90, 91, 95, 97, 98, 100, 102], "categori": [15, 16, 20, 21, 22, 23, 24, 25, 29, 35, 36, 41, 42, 43, 44, 45, 46, 50, 52, 53, 54, 55, 59, 64, 65, 69, 74, 75, 79, 80, 81, 82, 83, 84, 88, 91, 95, 100], "categorical_feat": [17, 19, 37, 40, 65, 76, 78, 95, 99], "categorical_featur": [20, 21, 22, 23, 30, 31, 41, 42, 43, 44, 52, 53, 61, 69, 76, 79, 80, 81, 82, 89, 90, 91, 100, 101, 102], "categorical_transform": [20, 21, 22, 23, 30, 41, 42, 43, 44, 52, 53, 65, 69, 76, 79, 80, 81, 82, 89, 91, 100, 101, 102], "categories_": [16, 17, 36, 37, 75, 76], "cater": [25, 46, 84], "caus": [20, 23, 24, 27, 31, 44, 45, 48, 53, 54, 57, 79, 82, 83, 86, 90, 99, 103], "causal": [23, 24, 44, 45, 53, 54, 82, 83], "caution": [30, 51, 60, 89], "cbar": [18, 39, 58, 77], "cbtf": [1, 54, 103], "cc": [0, 1], "cc_df": [20, 41, 68, 79, 100], "cconj": [28, 49, 58, 87], "ccp_alpha": 91, "cdot": 58, "ceil": 67, "cell": [7, 8, 12, 16, 17, 19, 20, 21, 22, 23, 24, 27, 29, 31, 32, 36, 37, 40, 41, 42, 43, 44, 45, 48, 50, 52, 53, 57, 59, 60, 61, 63, 64, 65, 67, 71, 75, 76, 78, 79, 80, 81, 82, 83, 86, 88, 90, 91, 93, 96, 97, 99, 101], "cell_nam": 93, "censor": [1, 11, 91, 92, 95], "censoringtyp": 61, "censu": [18, 20, 22, 23, 39, 41, 43, 44, 52, 53, 77, 79, 81, 82, 100], "census_df": [20, 41, 79, 100], "cent": [21, 42, 69, 80], "center": [15, 25, 26, 29, 35, 46, 47, 50, 56, 59, 70, 74, 84, 85, 88, 94], "centercrop": [29, 50, 59, 88], "centers_idx": [25, 46, 55, 84], "central": [5, 12], "centralair": [21, 23, 42, 44, 53, 80, 82, 91], "centralair_i": [21, 42, 80], "centralair_n": [21, 42, 80], "centric": [11, 91], "centroid": [25, 26, 46, 47, 55, 56, 84, 85], "centroids_idx": [25, 46, 55, 84], "centroids_idx_init": [25, 46, 55, 84], "centuri": [28, 49, 58, 87], "certain": [10, 15, 18, 19, 20, 23, 24, 25, 28, 31, 35, 39, 40, 41, 44, 45, 46, 49, 53, 54, 55, 58, 61, 66, 67, 74, 77, 78, 79, 82, 83, 84, 87, 90, 91, 100], "certainli": 96, "certainti": [20, 41, 68, 79], "cezannec": [29, 50, 59, 70, 88], "chaat": [28, 87], "chage": 99, "chain": [17, 37, 76], "challeng": [6, 11, 14, 24, 27, 29, 30, 32, 45, 48, 50, 51, 54, 57, 59, 60, 73, 83, 84, 86, 88, 89, 92, 95, 101], "chambar": 65, "chanc": [14, 19, 20, 21, 24, 25, 31, 40, 41, 42, 45, 46, 54, 55, 61, 68, 72, 73, 78, 79, 80, 83, 84, 90, 91, 92, 100], "chang": [0, 5, 7, 8, 10, 12, 13, 14, 15, 16, 19, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 40, 42, 43, 44, 45, 46, 47, 48, 50, 53, 54, 55, 56, 57, 59, 61, 64, 68, 69, 72, 73, 74, 75, 78, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 96, 97, 99, 100, 101, 102, 103], "channel": [1, 10, 29, 50, 59, 70, 88], "chapter": 1, "charact": [17, 20, 28, 37, 49, 58, 67, 76, 79, 87], "character": 48, "characterist": [13, 14, 18, 33, 34, 39, 72, 73, 77, 99], "charg": [0, 12, 31, 32, 61, 67, 71, 90], "charl": [18, 39, 67, 77], "charm": [28, 49, 58, 67, 87], "chart": [23, 30, 31, 44, 53, 61, 82, 89, 90, 91, 102], "chat": 103, "chatgpt": [12, 28, 49, 58, 87], "che210d": 9, "cheap": 67, "cheaper": [24, 45, 54, 83], "cheat": 9, "check": [1, 4, 7, 10, 12, 13, 14, 16, 18, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 36, 39, 42, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 68, 69, 71, 72, 73, 75, 77, 79, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 97, 100, 101, 102], "check_arrai": [61, 65], "check_assumpt": [31, 61, 90], "check_consistent_length": 65, "check_finit": 61, "check_invers": [17, 37, 76], "check_param": [61, 65], "check_x_i": 65, "check_y_param": 65, "checklist": 95, "checkmark": [27, 48, 57, 86], "checkout": [19, 40, 78], "cheetah": [12, 29, 32, 50, 59, 71, 88], "chegini": [1, 103], "chemic": 67, "chemistri": 67, "cherri": 91, "chest": [14, 34, 73], "chestpaintyp": 101, "chetah": [12, 29, 32, 50, 59, 71, 88], "chi": [31, 61, 90], "chicago": 93, "chicken": [25, 46, 55, 84], "child": [20, 23, 41, 44, 53, 67, 79, 82], "children": [27, 48, 57, 86], "chill": 67, "chines": [28, 49, 58, 65, 87], "chloe": 67, "chn": 8, "choic": [2, 19, 21, 22, 23, 25, 26, 27, 30, 34, 40, 42, 43, 44, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 60, 78, 80, 81, 82, 84, 85, 86, 89, 93, 97, 98, 99], "cholesterol": 101, "choos": [12, 19, 20, 22, 26, 40, 41, 43, 47, 52, 56, 71, 78, 79, 81, 85, 91, 92, 95, 97], "chop": [28, 40, 49, 58, 78, 87, 91], "choreograph": 93, "chose": [63, 91], "chosen": [14, 19, 20, 31, 34, 40, 61, 68, 73, 78, 79, 90, 91, 95, 101], "chrbv": [31, 61, 90], "christin": 93, "christma": 93, "christoph": 67, "chrome": [12, 32], "chunki": [25, 46, 84], "churn": [91, 95], "ciml": 1, "cinematographi": [28, 49, 58, 67, 87], "cinereu": [29, 50, 59, 88], "circl": [15, 20, 35, 41, 68, 74, 79], "circumst": 7, "citat": 7, "cite": [31, 61, 90], "citi": [13, 14, 15, 28, 30, 34, 35, 49, 51, 58, 60, 72, 73, 74, 87, 89, 91, 95, 96], "citibik": [30, 51, 60, 89], "cities_df": [15, 18, 35, 39, 74, 77], "citizen": [31, 61, 90], "cityscap": [30, 51, 60, 89], "civ": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82], "cl": 61, "clai": [23, 53, 82], "claim": [0, 19, 20, 40, 41, 78, 79], "clarif": 84, "clarifi": 95, "clariti": 11, "class": [1, 4, 5, 10, 13, 14, 15, 16, 17, 18, 24, 25, 28, 30, 31, 33, 34, 35, 36, 37, 39, 45, 46, 49, 54, 55, 58, 61, 71, 72, 73, 74, 75, 76, 77, 83, 84, 87, 89, 90, 91, 92, 96, 97, 100, 101, 102], "class_attend": [13, 14, 33, 34, 72, 73, 95], "class_attendance_enc": [17, 37, 76], "class_attendance_level": [17, 37, 76], "class_label": [20, 41, 79], "class_labels_fil": [12, 32, 71], "class_nam": [13, 15, 22, 29, 33, 35, 43, 50, 52, 59, 64, 70, 72, 74, 81, 88], "class_sep": [20, 79], "class_weight": [22, 43, 52, 81, 91, 100], "classes_": [18, 20, 22, 23, 29, 38, 39, 41, 43, 44, 50, 52, 59, 66, 67, 68, 77, 79, 81, 82, 88, 94], "classic": [15, 29, 35, 50, 59, 67, 74, 88, 94], "classif": [1, 2, 11, 14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 28, 30, 31, 34, 35, 36, 37, 39, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 58, 60, 61, 63, 65, 69, 70, 73, 74, 75, 76, 77, 80, 81, 82, 83, 86, 87, 89, 90, 91, 94, 96, 97, 99, 100, 101], "classifi": [14, 15, 16, 17, 19, 20, 23, 29, 34, 35, 36, 37, 40, 41, 44, 50, 53, 64, 68, 70, 73, 74, 75, 76, 78, 79, 82, 88, 91, 94, 96, 98, 100, 101], "classification_df": [13, 14, 33, 34, 72, 73], "classification_report": [20, 29, 41, 50, 59, 68, 79, 88, 100], "classifiers_ndt": [22, 43, 52, 81], "classify_imag": [12, 29, 32, 50, 59, 71, 88], "classmat": [6, 97, 98, 99, 100, 101, 102, 103], "classroom": [1, 92], "claudio": 67, "clean": [2, 12, 26, 32, 38, 47, 56, 63, 65, 66, 67, 71, 85, 91, 102, 103], "clean_text": [28, 49, 58, 87], "cleaned_hm": [20, 79, 92], "cleaned_restaurant_data": 65, "cleaner": [20, 23, 41, 44, 79, 82], "clear": [7, 11, 20, 25, 41, 46, 55, 68, 79, 84, 92, 97], "clearli": [4, 6, 7, 19, 22, 23, 30, 40, 43, 44, 51, 53, 67, 78, 81, 82, 89], "cleric": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82], "clever": 91, "clf": [12, 13, 15, 18, 29, 32, 33, 35, 39, 50, 59, 71, 72, 74, 77, 88], "click": [1, 5, 7, 20, 27, 41, 48, 57, 79, 86, 91, 92], "client": [27, 48, 57, 86, 92], "clinic": [13, 33, 72], "clip": [12, 32, 64, 71], "cloak": 67, "clonal": 60, "clone": [5, 7, 10], "close": [2, 12, 14, 15, 18, 19, 20, 25, 26, 28, 30, 34, 35, 39, 40, 41, 46, 47, 49, 51, 56, 58, 60, 64, 68, 73, 74, 77, 78, 79, 84, 85, 87, 89, 93, 94, 97, 103], "close_default_lr": [20, 41, 68, 79], "close_zero_svm": [20, 41, 68, 79], "closer": [15, 16, 18, 27, 35, 36, 39, 48, 57, 74, 75, 77, 86, 96, 99, 103], "closest": [15, 16, 20, 25, 26, 28, 30, 34, 35, 36, 41, 46, 47, 49, 51, 56, 58, 60, 68, 70, 74, 75, 79, 84, 85, 87, 89], "closest_index": 70, "closet": 67, "cloth": [30, 51, 60, 89], "cloud": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 52, 53, 54, 55, 56, 61, 71, 72, 76, 77, 78, 80, 81, 93, 103], "cloud3pm": [30, 89, 102], "cloud9am": [30, 89, 102], "clust_label": [25, 46, 55, 84], "cluster": [1, 2, 11, 27, 28, 30, 48, 49, 51, 58, 60, 86, 87, 89, 92], "cluster_cent": [25, 46, 55, 84], "cluster_centers_": [25, 46, 55, 70, 84], "cluster_col": 61, "cluster_prob": 70, "cluster_std": [26, 29, 47, 50, 56, 59, 85, 88], "clutter": [13, 72], "cm": [15, 18, 20, 23, 27, 35, 39, 41, 44, 48, 53, 57, 64, 68, 74, 77, 79, 82, 86, 97, 100], "cmap": [16, 19, 20, 23, 29, 36, 40, 41, 44, 50, 53, 59, 75, 78, 79, 82, 88, 99], "cmn": [21, 42, 80], "cmp": [31, 61, 90], "cnn": [29, 30, 50, 51, 59, 60, 88, 89], "co": [17, 28, 37, 49, 58, 76, 87], "coalesc": 61, "coast": [29, 50, 59, 88], "cockpit": 91, "code": [4, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102], "code_ast": 93, "code_obj": 93, "codecademi": 9, "coef": [30, 31, 61, 89, 90, 93, 102], "coef0": 91, "coef_": [18, 21, 22, 23, 24, 27, 29, 30, 31, 38, 39, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 57, 59, 60, 61, 66, 67, 69, 77, 80, 81, 82, 83, 86, 88, 89, 90, 93, 94, 101], "coef_df": [18, 23, 39, 44, 53, 77, 82], "coef_nonzero": [30, 51, 60, 89], "coeff": [18, 38, 39, 66, 67, 77], "coeff_df": [30, 89], "coeffici": [21, 22, 24, 27, 29, 30, 31, 42, 43, 45, 48, 50, 51, 52, 54, 57, 59, 60, 61, 69, 80, 81, 83, 86, 88, 89, 90, 91, 93, 94, 95, 101, 102], "coefs_df": [24, 45, 54, 83], "coher": [25, 46, 55, 84], "col": [13, 17, 18, 27, 30, 33, 37, 39, 48, 51, 57, 60, 72, 76, 77, 86, 89, 95], "col1": 8, "col2": 8, "col3": 8, "col4": 8, "col5": 8, "col6": 8, "cold": [16, 36, 75], "colinear": [23, 44, 53, 82], "collabor": [5, 11, 27, 48, 57, 86, 103], "collaps": [23, 44, 53, 82], "colleagu": [8, 9], "collect": [11, 12, 13, 16, 17, 20, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 36, 37, 41, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 65, 71, 72, 75, 76, 79, 81, 82, 83, 86, 87, 88, 89, 90, 92, 95, 101], "colleg": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "collinear": [24, 45, 54, 61, 83], "color": [18, 23, 24, 25, 26, 30, 39, 44, 45, 46, 47, 53, 54, 55, 56, 70, 77, 82, 83, 84, 85, 89, 91], "color_continuous_scal": [24, 45, 54, 58, 83], "color_threshold": [26, 47, 56, 85], "colorbar": [16, 18, 36, 39, 75, 77], "colour": [17, 18, 19, 23, 25, 26, 29, 37, 39, 40, 44, 46, 47, 50, 53, 56, 59, 76, 77, 78, 82, 84, 85, 88], "colsample_bylevel": [22, 43, 52, 81], "colsample_bynod": [22, 43, 52, 81], "colsample_bytre": [22, 43, 52, 81], "columbia": [1, 9, 28, 49, 58, 87], "column": [7, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102], "column_as_label": 61, "column_nam": [17, 37, 76], "column_stack": [24, 45, 54, 83], "columntranform": 98, "columntransform": [1, 16, 19, 20, 21, 22, 23, 24, 30, 31, 36, 40, 41, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 65, 69, 75, 78, 79, 80, 81, 82, 83, 89, 90, 91, 93, 99, 100, 101, 102], "columntransformer__countvectorizer__max_featur": [19, 40, 78, 99], "columntransformer__pipeline__polynomialfeatures__degre": 19, "columntransformercolumntransform": [17, 19, 21, 22, 24, 37, 40, 42, 43, 45, 52, 76, 78, 80, 81, 83, 93], "columntransformerifittedcolumntransform": [17, 21, 37, 42, 65, 76, 80, 91], "columntransformerinot": [17, 22, 37, 43, 76, 81], "com": [0, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 68, 71, 72, 76, 77, 79, 80, 81, 88, 89, 90, 92, 93, 100, 103], "comat": [28, 49, 58, 87], "combin": [13, 16, 19, 20, 24, 27, 29, 30, 31, 33, 36, 40, 41, 45, 48, 50, 51, 54, 57, 59, 61, 65, 68, 72, 75, 76, 78, 79, 83, 86, 88, 89, 90, 91, 96, 97, 99, 101], "come": [10, 12, 13, 16, 17, 20, 24, 27, 28, 29, 30, 31, 32, 33, 36, 37, 41, 45, 48, 49, 50, 51, 54, 57, 58, 59, 60, 61, 63, 65, 67, 71, 72, 75, 76, 79, 83, 86, 87, 88, 89, 90, 91, 96], "comedi": [27, 48, 57, 67, 86], "comfi": 65, "comfort": [5, 67], "command": [4, 10, 20, 28, 79, 87, 92], "comment": [8, 9, 65, 102], "commerci": 0, "commit": [7, 20, 41, 68, 79, 103], "common": [1, 8, 11, 13, 14, 15, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 40, 41, 42, 45, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 64, 69, 72, 73, 74, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 90, 92, 94, 97, 103], "commonli": [13, 16, 19, 20, 25, 31, 33, 36, 40, 41, 46, 55, 61, 68, 72, 75, 78, 79, 84, 90], "commonwealth": [28, 49, 58, 87], "commun": [1, 2, 10, 11, 17, 19, 21, 37, 40, 42, 54, 69, 76, 78, 80, 92, 103], "commut": [8, 21], "comp_dict": [20, 41, 79], "compact": [19, 24, 40, 45, 54, 78, 83], "compani": [20, 25, 27, 28, 31, 41, 46, 48, 49, 57, 58, 61, 79, 84, 86, 87, 90, 93, 100], "compar": [8, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59, 63, 68, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 91, 94, 95, 99, 100, 101, 102], "comparison": [26, 29, 31, 47, 50, 59, 61, 65, 85, 88, 90, 95], "compassion": 103, "compat": [8, 23, 53, 82, 93], "compatibitl": 8, "compel": [30, 51, 60, 89], "compet": 93, "competit": [22, 29, 43, 50, 52, 59, 81, 88, 94], "compil": 93, "complain": [6, 93], "complaint": [6, 103], "complement": [28, 49, 58, 87], "complet": [1, 6, 7, 12, 16, 19, 22, 23, 24, 26, 28, 31, 32, 34, 36, 40, 43, 44, 45, 47, 49, 52, 53, 54, 58, 61, 65, 67, 71, 75, 78, 81, 82, 83, 85, 87, 90, 91, 96, 97, 100, 101, 103], "complex": [11, 13, 15, 18, 19, 21, 22, 23, 24, 26, 28, 29, 30, 33, 35, 39, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 56, 58, 59, 61, 64, 65, 72, 74, 77, 78, 80, 81, 82, 83, 85, 87, 88, 89, 92, 97], "complex_warn": [61, 65], "complexwarn": [61, 65], "compli": 0, "complic": [4, 13, 14, 19, 21, 24, 33, 40, 42, 45, 54, 64, 65, 69, 70, 72, 73, 78, 80, 83], "compon": [17, 20, 27, 30, 37, 41, 48, 51, 57, 60, 76, 79, 86, 89, 91, 92, 103], "component_label": 58, "components_": [28, 49, 58, 87], "compos": [15, 17, 19, 20, 21, 22, 23, 24, 29, 30, 31, 37, 40, 41, 42, 43, 44, 45, 50, 51, 52, 53, 54, 59, 60, 61, 64, 65, 69, 70, 74, 76, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 93, 98, 99, 100, 101, 102], "composit": [17, 37, 76], "compound": [28, 29, 31, 49, 50, 58, 59, 61, 87, 88, 90, 93], "comprehend": [28, 49, 58, 64, 87], "comprehens": [25, 46, 84, 95, 103], "compress": [17, 25, 28, 37, 46, 49, 55, 58, 67, 76, 84, 87], "compris": [12, 13, 25, 32, 33, 46, 55, 71, 72, 84], "compu": [28, 49, 58], "comput": [1, 7, 9, 10, 11, 17, 19, 20, 22, 23, 24, 25, 26, 28, 30, 37, 40, 41, 44, 45, 46, 47, 49, 51, 53, 54, 55, 56, 58, 60, 61, 64, 68, 70, 71, 76, 78, 79, 81, 82, 83, 84, 85, 87, 89, 91, 92, 94, 100, 101, 103], "computation": [24, 45, 54, 83], "compute_class_weight": [20, 41, 79], "computer_programm": [28, 49, 58, 87], "coms4995": [16, 36, 75], "con": [25, 28, 29, 46, 49, 50, 55, 58, 59, 84, 87, 88, 91], "concat": [12, 15, 16, 17, 18, 23, 32, 35, 36, 37, 39, 44, 53, 71, 74, 75, 76, 77, 82], "concaten": [17, 28, 37, 49, 58, 76, 87], "concav": [24, 45, 54, 83], "concensu": [14, 73], "concentr": [19, 78, 95], "concept": [1, 11, 13, 14, 23, 24, 25, 30, 33, 34, 44, 45, 46, 51, 53, 54, 60, 65, 72, 73, 82, 83, 84, 89, 95, 97, 103], "conceptnet": [28, 49, 87], "conceptu": [22, 43, 52, 81, 91], "concern": [4, 11, 17, 22, 32, 37, 43, 52, 63, 76, 81, 103], "concess": [1, 7], "concis": [13, 33, 72, 92], "conclus": 91, "concord": [31, 61, 90], "concordance_index": [31, 61, 90], "concordance_index_": [31, 61, 90], "concret": [12, 32, 71, 91], "conda": [12, 20, 21, 22, 23, 25, 28, 29, 31, 32, 41, 42, 43, 44, 46, 49, 52, 53, 55, 58, 64, 68, 70, 71, 79, 80, 81, 82, 84, 87, 90, 93], "condens": 33, "condit": [0, 12, 13, 17, 24, 28, 31, 32, 33, 37, 45, 49, 54, 58, 61, 63, 67, 71, 72, 76, 83, 87, 90], "condition1": [21, 23, 42, 44, 53, 80, 82, 91], "condition1_arteri": [21, 42, 80], "condition1_feedr": [21, 42, 80], "condition1_norm": [21, 42, 80], "condition1_posa": [21, 42, 80], "condition1_posn": [21, 42, 80], "condition1_rra": [21, 42, 80], "condition1_rran": [21, 42, 80], "condition1_rrn": [21, 42, 80], "condition1_rrnn": [21, 42, 80], "condition2": [21, 23, 42, 44, 53, 80, 82, 91], "condition2_arteri": [21, 42, 80], "condition2_feedr": [21, 42, 80], "condition2_norm": [21, 42, 80], "condition2_posa": [21, 42, 80], "condition2_posn": [21, 23, 42, 53, 80, 82], "condition2_rra": [21, 42, 80], "condition2_rran": [21, 23, 42, 80], "condition2_rrnn": [21, 23, 42, 80], "conditional_aft": [31, 61, 90], "conduct": [11, 32], "confer": [28, 49, 58, 87], "confid": [12, 14, 23, 31, 32, 34, 38, 44, 53, 61, 66, 67, 71, 73, 82, 90, 92, 95, 97, 100, 101], "confidenti": [20, 41, 68, 79], "config": [10, 61, 93], "config_context": [61, 65], "configur": [19, 21, 22, 40, 43, 52, 78, 80, 81], "confirm": 10, "conflict": [10, 26, 47, 56, 85, 103], "confound": [24, 45, 54, 83], "confus": [8, 15, 17, 21, 35, 37, 42, 69, 74, 76, 80, 84, 92, 97, 100], "confusingli": [12, 32], "confusion_matrix": [20, 29, 31, 41, 50, 59, 61, 68, 79, 88, 90], "confusionmatrixdisplai": [20, 41, 68, 79, 100], "congrat": [17, 37, 76], "conjunct": [24, 45, 54, 83], "connect": [0, 13, 26, 27, 33, 47, 48, 56, 57, 72, 85, 86, 92], "connot": [28, 49, 58, 87], "conort": [24, 45, 54, 83], "consciou": 103, "consecut": [30, 51, 60, 89], "consequ": [7, 12, 17, 20, 27, 32, 41, 48, 57, 71, 76, 79, 86, 91, 100], "consid": [4, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 64, 65, 67, 68, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 89, 91, 92, 95, 97, 103], "consider": [2, 11, 20, 22, 25, 27, 31, 43, 46, 48, 52, 55, 57, 61, 67, 79, 81, 84, 86, 90, 91, 92], "consist": [6, 7, 13, 14, 16, 25, 33, 34, 36, 46, 55, 61, 65, 67, 72, 73, 75, 84, 92], "const": [28, 49, 58, 87], "constant": [13, 20, 21, 22, 23, 30, 31, 33, 41, 42, 43, 44, 51, 52, 53, 60, 61, 65, 69, 72, 79, 80, 81, 82, 89, 90, 91, 100, 102], "constitu": [22, 43, 52, 81], "constitut": [28, 49, 58, 87, 103], "construct": [27, 48, 57, 86], "constructor": [13, 16, 36, 72, 75], "consult": [15, 35, 64, 74, 97, 103], "consum": [12, 24, 25, 27, 32, 45, 46, 48, 54, 55, 57, 71, 83, 84, 86, 92, 95], "consumpt": [30, 51, 60, 89], "contact": [12, 32, 71, 103], "contain": [8, 10, 12, 13, 16, 17, 18, 21, 27, 28, 29, 32, 33, 36, 37, 39, 42, 48, 49, 50, 57, 58, 59, 61, 65, 67, 71, 72, 75, 76, 77, 80, 86, 87, 88, 92, 93, 94], "container": 92, "contamin": 67, "content": [1, 4, 10, 11, 28, 29, 32, 49, 50, 58, 59, 84, 87, 88, 92, 95, 103], "contest": 6, "context": [11, 13, 16, 18, 19, 20, 22, 23, 24, 26, 27, 29, 30, 33, 36, 39, 40, 41, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 56, 57, 59, 60, 68, 72, 75, 77, 78, 79, 81, 82, 83, 85, 86, 88, 89, 91, 95, 97], "contextu": 11, "contin": [17, 76], "conting": [26, 47, 56, 85], "continu": [17, 19, 21, 22, 24, 28, 30, 37, 40, 42, 45, 49, 51, 52, 58, 60, 65, 69, 76, 78, 80, 81, 83, 87, 89, 91, 102], "contract": [0, 31, 61, 90], "contract_month": [31, 61, 90], "contract_on": [31, 61, 90], "contract_two": [31, 61, 90], "contrast": [11, 95], "contribut": [15, 18, 23, 29, 35, 39, 44, 50, 53, 59, 74, 77, 82, 88, 101, 103], "control": [5, 8, 13, 14, 15, 17, 18, 21, 22, 25, 29, 33, 34, 35, 37, 39, 42, 43, 50, 52, 54, 59, 69, 72, 73, 74, 76, 77, 80, 81, 88, 103], "convei": 11, "conveni": [8, 12, 19, 20, 25, 28, 30, 31, 32, 40, 41, 46, 49, 51, 55, 58, 60, 61, 68, 78, 79, 84, 87, 89, 90, 91, 92], "converg": [25, 46, 55, 61, 84], "convergence_doc": 61, "convergenceerror": 61, "convers": [20, 21, 23, 28, 42, 44, 49, 53, 58, 69, 79, 80, 82, 87, 92, 99], "convert": [12, 16, 17, 18, 22, 23, 24, 28, 30, 31, 32, 36, 37, 39, 43, 44, 45, 49, 51, 52, 53, 58, 60, 61, 65, 69, 71, 75, 76, 77, 81, 82, 83, 87, 89, 90, 102, 103], "convinc": [17, 37, 76, 91], "convolut": [24, 29, 45, 50, 54, 59, 83, 88], "convolutional_neural_network": [29, 50, 59, 70, 88], "cooccurrencematrix": [28, 49, 58, 87], "cook": [25, 84], "cool": [29, 50, 67, 88], "coolwarm": [18, 39, 77], "coordin": [32, 103], "copi": [0, 7, 8, 10, 13, 22, 23, 25, 27, 29, 30, 31, 33, 43, 44, 46, 48, 50, 52, 53, 57, 59, 61, 65, 72, 78, 81, 82, 84, 86, 88, 89, 90, 91, 101, 102, 103], "copy_arrai": 93, "copyright": 0, "cor": [23, 44, 53, 82], "coral": [29, 50, 59, 88], "core": [9, 11, 16, 17, 19, 20, 21, 24, 26, 27, 30, 31, 36, 37, 40, 41, 42, 45, 47, 48, 54, 56, 57, 61, 65, 73, 75, 76, 78, 79, 80, 83, 85, 86, 89, 90, 92, 93, 95, 102], "corefer": [28, 49, 58, 87], "corei": 92, "corgi": [12, 29, 32, 50, 59, 71, 88], "corner": 67, "coro": 93, "corona_nlp_test": 93, "coronapocalyps": 93, "coronaviru": 93, "corpor": [5, 93], "corpora": [17, 28, 37, 49, 58, 76, 87], "corpu": [17, 20, 28, 37, 49, 76, 79, 87], "corr": [23, 44, 53, 82], "corr_df": [23, 44, 53, 82], "correct": [7, 12, 13, 14, 15, 20, 22, 23, 31, 32, 33, 34, 35, 41, 43, 44, 52, 53, 61, 68, 71, 72, 73, 74, 79, 81, 82, 90, 91, 96, 97, 101], "correctli": [1, 10, 13, 14, 20, 33, 34, 41, 68, 72, 73, 79], "correl": [30, 51, 54, 60, 89, 95], "correspond": [1, 12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 25, 27, 30, 32, 33, 34, 37, 39, 40, 41, 42, 44, 46, 48, 51, 53, 55, 57, 60, 64, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 80, 82, 84, 86, 89, 97, 99, 103], "cosin": [28, 49, 87], "cosine_similar": [28, 49, 58, 87], "cosmic": 58, "cost": [8, 12, 29, 32, 50, 59, 67, 71, 88, 91, 103], "cost_rep": 8, "costco": [28, 49, 87], "costli": [20, 41, 68, 79], "cot": [29, 50, 59, 88], "cote": [29, 50, 59, 88], "could": [6, 8, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 27, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 46, 48, 49, 51, 52, 54, 55, 57, 58, 60, 61, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 78, 79, 80, 81, 83, 84, 86, 87, 89, 90, 91, 92, 97, 99, 100, 102, 103], "couldn": [28, 49, 58, 67, 87], "count": [8, 13, 16, 17, 20, 21, 24, 26, 28, 29, 30, 31, 33, 36, 37, 41, 42, 45, 49, 50, 54, 59, 61, 63, 65, 67, 69, 72, 75, 76, 79, 80, 83, 87, 88, 89, 90, 92, 93, 94, 97, 99, 100, 102, 103], "counter": [20, 79], "counti": [63, 97], "countri": [14, 15, 17, 18, 20, 22, 23, 28, 34, 35, 39, 41, 43, 44, 49, 52, 53, 58, 73, 74, 76, 77, 79, 81, 82, 87, 100, 103], "country_columbia": [23, 44, 53, 82], "country_dominican": [23, 44, 53, 82], "country_guatemala": [23, 44, 82], "country_holand": 53, "country_hondura": [23, 44, 53, 82], "country_hong": [23, 44, 53, 82], "country_hungari": [23, 44, 53, 82], "country_india": [23, 44, 53, 82], "country_iran": [23, 44, 82], "country_ireland": 53, "country_miss": [22, 23, 43, 44, 52, 53, 81, 82], "country_outli": 53, "country_puerto": [22, 23, 44, 53, 82], "country_scotland": [22, 23, 44, 53, 82], "country_south": [22, 23, 44, 53, 82], "country_taiwan": [22, 23, 44, 53, 82], "country_thailand": [22, 23, 44, 53, 82], "country_trinadad": [22, 23, 43, 44, 52, 53, 81, 82], "country_unit": [22, 23, 43, 44, 52, 53, 81, 82], "country_vietnam": [22, 23, 43, 44, 52, 53, 81, 82], "country_yugoslavia": [22, 23, 43, 44, 52, 53, 81, 82], "countvector": [12, 18, 19, 20, 28, 32, 38, 39, 40, 49, 58, 65, 66, 67, 71, 77, 78, 79, 87, 92, 93, 95, 99], "countvectorizercountvector": [17, 19, 37, 40, 67, 76, 78, 93], "countvectorizeroriginaltweet": 93, "countvectorizersong_titl": [19, 40, 78], "coupl": [4, 13, 19, 26, 40, 47, 56, 72, 78, 85, 93, 102], "cour": [28, 49, 58, 87], "cours": [2, 4, 5, 6, 7, 10, 13, 14, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 37, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 63, 64, 65, 68, 69, 70, 72, 73, 76, 77, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 93, 95, 96, 97, 99], "coursera": [1, 9], "coursework": 103, "court": [28, 49, 58, 87], "covari": [13, 31, 33, 61, 72, 90], "cover": [8, 11, 20, 22, 25, 29, 30, 32, 41, 46, 49, 50, 51, 52, 54, 55, 59, 60, 79, 81, 84, 88, 89, 103], "coverag": [20, 41, 68, 79], "covid": 93, "covid2019": 93, "cow": 91, "cox": 11, "coxph_fitt": [61, 90], "coxphfitt": [31, 61, 90], "cph": [31, 61, 90, 91, 95], "cph_param": [31, 61, 90], "cpp": [29, 50, 93], "cpsc": [9, 10, 13, 22, 24, 28, 29, 30, 33, 43, 45, 49, 50, 51, 52, 54, 58, 59, 60, 71, 72, 81, 83, 87, 88, 89, 91, 92, 93, 103], "cpsc330": [0, 1, 10, 12, 17, 19, 23, 28, 29, 31, 32, 33, 37, 44, 50, 53, 59, 61, 62, 64, 65, 71, 72, 73, 76, 78, 82, 87, 88, 90, 92, 93, 103], "cpsc330env": 10, "cpu": [19, 29, 40, 50, 59, 64, 70, 78, 88, 93], "craft": [15, 20, 22, 23, 25, 35, 41, 43, 44, 46, 52, 53, 55, 74, 79, 81, 82, 84, 97], "crash": [1, 68, 93], "crate": [29, 50, 59, 88], "crawl": 67, "crazi": [65, 92], "creat": [8, 9, 10, 12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102], "create_lag_df": [30, 51, 60, 89], "create_lag_featur": [30, 89, 102], "create_y_from_r": [27, 48, 57, 86], "creativ": [1, 28, 49, 58, 67, 87], "credenc": 91, "credit": [0, 13, 20, 28, 30, 31, 33, 41, 49, 51, 52, 58, 60, 61, 68, 72, 79, 81, 87, 89, 90, 91, 100], "creditcard": [20, 41, 68, 79, 100], "creepi": 67, "crime": [18, 39, 77], "crimin": [23, 44, 53, 82], "criteria": [13, 26, 33, 47, 56, 72, 85], "criterion": [26, 47, 56, 85, 91], "critic": [11, 91], "cross": [13, 15, 17, 19, 21, 22, 23, 25, 27, 31, 33, 37, 40, 42, 43, 44, 46, 48, 52, 53, 55, 57, 61, 65, 69, 72, 74, 76, 78, 80, 81, 82, 84, 86, 90, 91, 92, 93, 95, 98, 99, 100, 101, 102], "cross_val": [22, 43, 52, 81], "cross_val_predict": [20, 22, 31, 41, 43, 52, 61, 68, 79, 81, 90], "cross_val_scor": [16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 65, 66, 67, 68, 69, 75, 76, 77, 78, 79, 80, 81, 82, 83, 89, 90, 91, 93, 95, 98, 99, 100, 101, 102], "cross_valid": [15, 16, 17, 18, 19, 20, 22, 23, 24, 27, 30, 31, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 48, 51, 52, 53, 54, 57, 60, 61, 63, 64, 65, 66, 67, 68, 74, 75, 76, 77, 78, 79, 81, 82, 83, 86, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 101, 102], "cross_validate_std": [14, 34, 73], "crowd": [22, 26, 43, 47, 52, 56, 81, 85], "crown": 103, "crown_princ": [28, 49, 58, 87], "crucial": [12, 14, 18, 23, 25, 26, 27, 28, 32, 34, 39, 44, 46, 47, 48, 49, 53, 55, 56, 57, 58, 71, 73, 77, 82, 84, 85, 86, 87], "crude": [28, 49, 58, 87], "cs189": 9, "cs189_ch7": 9, "csc": 61, "csr": [61, 65], "csrc": 93, "css": 92, "csv": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102], "ct": [17, 37, 76], "cuda": [29, 50, 59, 64, 70, 88], "cui": [1, 103], "cuisin": 92, "cultiv": 11, "cultur": [29, 50, 59, 88, 103], "cupi": 93, "curios": [12, 32, 71], "curiou": [12, 32, 71, 97], "curl": 92, "current": [1, 22, 28, 29, 30, 31, 43, 49, 50, 51, 52, 58, 59, 60, 61, 81, 87, 88, 89, 90, 91, 92, 93], "curriculum": 11, "curs": 91, "curv": [7, 8, 11, 25, 39, 46, 55, 84, 91, 95, 97], "cush": 67, "custom": [5, 8, 12, 13, 17, 20, 21, 27, 32, 33, 37, 41, 42, 48, 57, 65, 68, 69, 71, 72, 76, 79, 80, 86, 92, 93, 95], "custom_plot_tre": [13, 14, 22, 23, 33, 34, 43, 44, 52, 53, 72, 73, 81, 82], "customerid": [31, 61, 90], "customiz": 93, "cut": [26, 47, 85], "cv": [14, 17, 20, 21, 22, 23, 24, 30, 31, 34, 37, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 63, 64, 69, 73, 76, 79, 80, 81, 82, 83, 89, 90, 91, 92, 95, 97, 99], "cv_feat": 93, "cv_results_": [19, 21, 40, 42, 69, 78, 80, 99], "cv_score": [14, 21, 34, 42, 64, 69, 73, 80], "cv_train_scor": [63, 97], "cv_valid_scor": [63, 97], "cycl": 8, "cyclic": [30, 51, 60, 89], "cycling_data": 8, "cygnu": [29, 50, 59, 88], "d": [4, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 65, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 84, 85, 86, 87, 88, 89, 90, 92, 100, 101, 102], "d3": [25, 46, 84], "da": [12, 32, 71], "dabeaz": 9, "dad": [24, 45, 54, 83], "daft": 67, "dai": [4, 8, 14, 24, 29, 31, 45, 50, 54, 59, 61, 65, 67, 83, 88, 90, 91, 95, 102, 103], "daili": [31, 61, 90, 95], "dall": [30, 51, 60, 89], "damag": [0, 20, 41, 79], "dan": [28, 49, 58, 87], "danceabl": [15, 16, 19, 36, 40, 74, 75, 78, 99], "danger": [28, 49, 58], "dark": 93, "darker": [19, 40, 78], "dashboard": [15, 35, 64, 74, 97], "data": [1, 2, 5, 7, 8, 9, 10, 11, 24, 26, 28, 31, 38, 41, 45, 47, 49, 54, 61, 64, 66, 67, 68, 70, 85, 87, 90, 94, 95, 96, 98, 99, 100, 101, 103], "data_dict": [18, 39, 77], "data_dir": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 59, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 99, 100, 101, 102], "data_to_wrap": [17, 37, 61, 76], "data_transform": [29, 50, 59, 64, 70, 88], "data_transforms_bw": [29, 50, 59, 88], "data_url": [20, 41, 68, 79, 100], "datacamp": 9, "datafram": [12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 97, 98, 99, 101, 102], "dataload": [29, 50, 59, 64, 70, 88], "dataloaders_bw": [29, 50, 59, 88], "datapoint": [18, 39, 77], "dataquest": 9, "datas": 61, "dataset": [8, 11, 12, 14, 15, 17, 22, 23, 24, 25, 26, 31, 32, 34, 35, 37, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 61, 63, 64, 65, 70, 71, 73, 74, 81, 82, 83, 84, 85, 90, 92, 93, 94, 95, 97, 99, 100], "dataset2": [25, 46, 55, 84], "dataset_s": [29, 50, 59, 64, 70, 88], "dataviz": 91, "date": [7, 10, 12, 13, 27, 28, 31, 32, 48, 49, 54, 57, 58, 61, 63, 71, 72, 86, 87, 90, 92, 93, 95, 97, 102, 103], "date_rang": [30, 51, 60, 89], "dates_rain": [30, 89, 102], "datetim": [51, 60, 61, 90], "datetime64": [30, 51, 60, 89, 102], "datetimeindex": [30, 51, 60, 89], "datum": [28, 49, 58, 87], "daughter": [20, 67, 79, 92], "daum\u00e9": 1, "daunt": [27, 48, 57, 86], "dave": [28, 49, 58, 87], "david": [1, 28, 49, 58, 87, 91], "dawn": 67, "day_nam": [30, 51, 60, 89, 102], "daylight": [30, 89, 102], "dayofweek": [30, 51, 60, 89], "days_sinc": [30, 51, 60, 89], "dbscan": [11, 92], "dc": [30, 31, 61, 89, 90, 93], "dcc": [18, 39, 77], "dd": [30, 89, 102], "de": [28, 30, 49, 51, 58, 60, 87, 89], "deactiv": 10, "dead": 67, "deadlin": [14, 32, 103], "deal": [0, 14, 15, 16, 21, 28, 31, 34, 35, 36, 42, 49, 61, 65, 69, 73, 74, 75, 80, 87, 90, 91, 92, 95, 98], "death": 103, "debat": [8, 23, 32, 44, 53, 82], "debbi": 93, "debias": 49, "deborah": 67, "debug": [4, 23, 44, 53, 82], "decad": [29, 50, 59, 88], "decemb": [30, 51, 60, 63, 89, 102], "decent": 67, "decid": [8, 13, 15, 18, 22, 23, 24, 25, 26, 28, 30, 31, 33, 35, 39, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 60, 61, 67, 72, 74, 77, 81, 82, 83, 84, 85, 87, 89, 90, 95], "decis": [1, 2, 6, 14, 16, 19, 20, 22, 24, 29, 34, 36, 38, 40, 41, 43, 45, 50, 52, 54, 59, 66, 67, 68, 73, 75, 78, 79, 81, 83, 88, 94, 95, 96, 98, 101, 103], "decision_boundari": 94, "decision_funct": [20, 41, 68, 79], "decisiontreeclassifi": [14, 15, 16, 17, 18, 19, 23, 34, 35, 36, 37, 39, 40, 44, 53, 64, 73, 74, 75, 76, 77, 78, 82, 96, 97, 98, 99, 101], "decisiontreeclassifierdecisiontreeclassifi": [22, 43, 52, 81], "decisiontreeregressor": [13, 21, 33, 42, 63, 69, 72, 80, 96, 97], "decisiontreeregressorifitteddecisiontreeregressor": 63, "deck": 9, "declar": 103, "decomposit": [26, 27, 28, 47, 48, 49, 56, 57, 58, 61, 85, 86, 87], "decor": [65, 93], "decreas": [14, 18, 19, 22, 23, 25, 34, 39, 40, 43, 44, 46, 52, 53, 55, 63, 73, 77, 78, 81, 82, 84, 97], "deduct": 7, "deem": 6, "deep": [2, 9, 19, 23, 24, 28, 31, 40, 44, 45, 49, 53, 54, 58, 61, 78, 82, 83, 87, 90, 92], "deepen": [95, 103], "deeper": [2, 12, 19, 20, 21, 23, 32, 40, 41, 42, 44, 53, 68, 78, 79, 80, 82], "deepexplain": [23, 44, 53, 82], "def": [14, 15, 16, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 34, 35, 36, 38, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75, 78, 79, 80, 82, 84, 85, 86, 87, 88, 89, 92, 93, 97, 99, 102], "defalut": 99, "default": [5, 10, 12, 13, 14, 17, 18, 19, 20, 21, 22, 25, 26, 29, 30, 31, 32, 33, 34, 37, 39, 40, 41, 42, 43, 46, 47, 50, 51, 52, 54, 55, 59, 60, 61, 64, 68, 69, 72, 73, 76, 77, 78, 79, 80, 81, 84, 85, 88, 89, 90, 91, 94, 99, 100, 103], "default_check_param": 65, "default_threshold": [20, 41, 68, 79], "defaultdict": [27, 48, 57, 86], "defin": [13, 15, 16, 17, 20, 22, 23, 25, 26, 27, 30, 35, 36, 37, 41, 43, 44, 46, 47, 48, 52, 53, 55, 57, 65, 72, 74, 75, 76, 79, 81, 82, 84, 85, 86, 89, 92, 102], "definit": [8, 15, 23, 25, 28, 30, 35, 44, 46, 49, 53, 55, 58, 74, 82, 84, 87, 89, 94, 95, 96], "degre": [19, 20, 41, 68, 79], "degrees_freedom": [31, 61, 90], "degrees_of_freedom": [31, 61, 90], "del": [22, 43, 52, 81], "delai": [1, 10, 24, 45, 54, 83], "delayed_func": 61, "deleg": [28, 49, 58, 87], "delet": [4, 7, 16, 36, 75, 91], "delgado": [22, 43, 52, 81], "delight": [28, 49, 58, 87], "deliver": 7, "delv": [11, 28, 49, 58, 87], "demo": [1, 22, 32, 43, 52, 81, 91, 103], "demograph": [13, 27, 33, 48, 57, 72, 86], "demonstr": [13, 14, 16, 18, 19, 21, 22, 25, 27, 28, 29, 33, 34, 36, 38, 39, 40, 42, 43, 46, 48, 49, 50, 52, 55, 57, 58, 59, 64, 65, 66, 67, 69, 72, 73, 75, 77, 78, 80, 81, 84, 86, 87, 88], "denholm": 67, "denois": 12, "denomin": [21, 42, 69, 80, 93], "denot": [13, 27, 33, 48, 54, 57, 72, 86], "dens": [26, 28, 47, 49, 56, 58, 85, 87], "densenet": [29, 50, 59, 64, 70, 88], "densenet121": [29, 50, 59, 64, 70, 88], "densenet121_weight": [29, 50, 59, 64, 70, 88], "densiti": [23, 26, 44, 47, 53, 56, 82, 85, 95], "dep": [28, 49, 58, 87], "department": 103, "departur": [24, 45, 54, 83], "depend": [2, 8, 10, 13, 14, 15, 17, 19, 20, 21, 22, 23, 25, 26, 28, 30, 31, 33, 34, 35, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 55, 56, 60, 61, 69, 72, 73, 74, 76, 78, 79, 80, 81, 82, 84, 85, 87, 89, 90, 91, 101], "dependence_plot": [23, 44, 53, 82], "dependents_no": [31, 61, 90], "dependents_y": [31, 61, 90], "deploi": [14, 20, 27, 34, 41, 48, 57, 63, 68, 73, 79, 86, 91, 95], "deploy": [11, 23, 30, 44, 51, 53, 60, 82, 89], "deprec": [20, 21, 36, 42, 61, 68, 73, 75, 79, 80, 90, 94], "deprecationwarn": [22, 43, 52, 61, 81, 90], "depth": [1, 13, 14, 19, 22, 26, 33, 34, 40, 43, 47, 52, 56, 63, 72, 73, 78, 81, 85, 96, 97], "dequ": [22, 23, 43, 44, 52, 53, 81, 82, 101], "deran": 67, "deriv": [0, 13, 18, 20, 27, 31, 33, 39, 41, 48, 57, 61, 72, 77, 79, 86, 90, 95, 100], "descend": [8, 26, 29, 38, 47, 50, 59, 66, 67, 85, 88, 95], "descent": [30, 51, 60, 67, 89], "descr": [18, 39, 77], "describ": [8, 11, 12, 13, 14, 15, 16, 18, 20, 21, 27, 28, 30, 32, 33, 34, 35, 36, 39, 41, 42, 48, 49, 57, 58, 63, 65, 68, 69, 71, 72, 73, 74, 75, 77, 79, 80, 86, 87, 89, 92, 97, 100, 102], "descript": [1, 21, 31, 42, 61, 80, 90, 93], "desenet": 64, "deserv": 6, "design": [11, 23, 26, 29, 33, 44, 47, 50, 53, 56, 59, 72, 82, 85, 88, 91, 99, 103], "desir": [20, 28, 31, 41, 49, 58, 61, 65, 68, 79, 87, 90, 98], "desk": 103, "despit": [24, 28, 45, 49, 58, 83, 87], "det": [28, 49, 58, 67, 87, 93], "detach": [29, 50, 59, 64, 70, 88], "detail": [15, 17, 22, 28, 29, 35, 37, 41, 43, 49, 50, 54, 58, 59, 74, 76, 81, 87, 88, 92, 103], "detect": [12, 13, 20, 21, 25, 26, 30, 32, 33, 41, 42, 46, 47, 51, 55, 56, 60, 63, 68, 69, 71, 72, 79, 80, 84, 85, 89, 92, 100], "determin": [15, 25, 26, 28, 31, 33, 35, 46, 47, 49, 55, 56, 58, 61, 64, 74, 84, 85, 87, 90, 91, 97, 101, 103], "detriment": [20, 27, 41, 48, 57, 79, 86, 100], "dev": [14, 73, 94], "develop": [1, 9, 11, 12, 14, 16, 17, 19, 20, 21, 22, 28, 29, 32, 34, 36, 37, 40, 41, 42, 43, 44, 49, 50, 58, 59, 67, 68, 69, 71, 73, 75, 76, 78, 79, 80, 81, 87, 88, 91, 92, 93, 95], "devianc": [31, 61, 90], "deviat": [6, 14, 16, 22, 23, 34, 36, 43, 44, 52, 53, 73, 75, 81, 82], "devic": [22, 29, 43, 50, 52, 59, 61, 64, 65, 70, 81, 88, 93], "deviceprotect": [31, 61, 90], "deviceprotection_no": [31, 61, 90], "deviceprotection_y": [31, 61, 90], "df": [12, 13, 14, 16, 17, 19, 20, 21, 23, 24, 29, 30, 31, 32, 34, 36, 37, 40, 41, 42, 44, 45, 50, 51, 53, 54, 59, 60, 61, 63, 65, 68, 69, 71, 72, 73, 75, 76, 78, 79, 80, 82, 83, 88, 89, 90, 91, 92, 93, 96, 102], "df_concat": [12, 32, 71], "df_float_1": 8, "df_float_2": 8, "df_hour_week_ohe_poli": [30, 51, 89], "df_locat": [30, 89, 102], "di": [31, 61, 90], "diagnos": [14, 23, 44, 53, 73, 82, 95], "diagnosi": [20, 41, 79], "diagnost": [31, 61, 90, 92], "diagon": [15, 20, 23, 35, 41, 44, 53, 68, 74, 79, 82], "diagram": [17, 19, 22, 23, 37, 40, 43, 44, 52, 53, 76, 78, 81, 82], "dialogu": [28, 49, 58, 67, 87], "dict": [20, 27, 41, 48, 57, 61, 79, 86], "dict_kei": [19, 22, 43, 52, 81], "dictionari": [8, 16, 19, 20, 22, 23, 36, 40, 41, 43, 44, 68, 75, 78, 79, 81, 82, 92], "did": [6, 12, 13, 15, 23, 25, 28, 30, 32, 33, 35, 44, 46, 49, 51, 53, 55, 58, 60, 67, 68, 72, 74, 82, 84, 87, 89, 93, 97, 99, 100, 101, 103], "didn": [19, 22, 23, 26, 28, 30, 31, 40, 43, 44, 47, 49, 52, 53, 56, 58, 61, 65, 67, 78, 81, 82, 85, 87, 89, 90, 92], "die": 93, "diet": [13, 28, 33, 49, 58, 72, 87], "diff": [30, 89, 102], "differ": [1, 2, 5, 7, 8, 10, 11, 12, 13, 14, 15, 17, 18, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 70, 71, 72, 73, 74, 76, 77, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 96, 97, 99, 100, 101, 102], "differenti": [11, 12, 13, 32, 33, 59, 71, 72], "difficult": [4, 6, 7, 20, 24, 25, 41, 45, 46, 49, 54, 55, 79, 83, 84, 91], "difficulti": [25, 46, 55, 84, 95], "dig": [20, 21, 41, 42, 68, 79, 80], "digit": [30, 51, 60, 89, 91], "dilemma": [27, 48, 57, 86], "dim": [29, 50, 59, 64, 65, 70, 88], "dimens": [8, 18, 24, 39, 45, 54, 77, 83], "dimension": [2, 8, 18, 19, 20, 22, 24, 25, 28, 33, 39, 40, 41, 43, 45, 46, 49, 52, 54, 55, 58, 64, 68, 77, 78, 79, 81, 83, 84, 87], "dine": 92, "dir": 29, "direct": [18, 23, 24, 26, 28, 36, 38, 39, 44, 45, 47, 49, 53, 54, 56, 58, 66, 67, 77, 82, 83, 85, 87, 93], "direct_bilirubin": [12, 32, 71], "directli": [1, 8, 17, 21, 29, 31, 37, 42, 50, 61, 65, 76, 80, 88, 90, 92, 103], "director": [27, 48, 57, 67, 86], "directori": [10, 13, 14, 16, 34, 36, 64, 72, 73, 75], "dirichlet": [28, 29, 49, 50, 58, 59, 87, 88], "disabl": [28, 49, 58, 87], "disadvantag": [19, 22, 26, 27, 40, 43, 47, 48, 52, 56, 78, 81, 85, 86, 98], "disagre": 48, "disappoint": 67, "disast": [12, 71], "discard": [24, 28, 45, 49, 54, 58, 83, 87], "disciplin": [20, 24, 41, 45, 54, 79, 83], "disclos": [93, 103], "discomfort": 67, "discourag": [8, 54], "discours": [27, 48, 57, 86], "discov": [24, 25, 45, 46, 54, 55, 83, 84], "discoveri": [12, 32, 71], "discret": [13, 24, 28, 33, 45, 49, 54, 58, 65, 72, 83], "discrete_scatt": [13, 14, 15, 18, 25, 26, 29, 33, 34, 35, 39, 46, 47, 50, 55, 56, 59, 64, 72, 73, 74, 77, 84, 85, 88, 94, 96, 97], "discretization_feat": [24, 45, 54, 83], "discrimin": [22, 81], "discuss": [4, 14, 15, 16, 18, 23, 24, 25, 26, 30, 34, 35, 36, 39, 44, 45, 46, 47, 51, 53, 54, 55, 56, 57, 60, 68, 73, 74, 75, 77, 82, 83, 84, 85, 89, 95, 97, 98, 99, 101, 102, 103], "diseas": [13, 20, 31, 33, 41, 61, 68, 72, 79, 90], "dislik": [65, 91], "dispatch": 93, "dispatch_queu": 93, "dispatch_shel": 93, "dispers": 67, "displaci": [28, 49, 58, 87, 93], "displai": [7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 47, 48, 50, 51, 52, 53, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 85, 86, 88, 89, 90, 96, 97, 98, 99, 100, 102], "display_heatmap": [19, 40, 78, 99], "display_label": [20, 41, 68, 79, 100], "displaystyl": 87, "disput": [28, 49, 58, 87], "disregard": 67, "disrespect": 4, "dissemin": 92, "dist": [15, 25, 26, 35, 46, 47, 55, 56, 64, 70, 74, 84, 85], "distanc": [8, 16, 24, 26, 27, 28, 36, 47, 48, 49, 54, 57, 64, 70, 75, 83, 85, 86, 87], "distinct": [20, 24, 30, 41, 45, 51, 54, 60, 68, 70, 79, 83, 89, 91], "distinguish": [13, 15, 17, 20, 33, 35, 37, 41, 64, 68, 72, 74, 76, 79, 97], "distract": 103, "distribut": [0, 10, 12, 14, 20, 23, 24, 26, 28, 29, 30, 34, 41, 44, 45, 47, 49, 50, 53, 54, 58, 59, 63, 65, 68, 73, 79, 82, 83, 85, 87, 88, 89, 99, 102, 103], "district": [16, 18, 36, 39, 75, 77], "districtdatalab": [25, 46, 55, 84], "disturb": [12, 32, 71], "dive": [23, 44, 53, 82], "divers": [11, 22, 25, 27, 30, 43, 46, 48, 51, 52, 60, 81, 84, 86, 89], "divid": [18, 20, 22, 23, 30, 39, 41, 43, 44, 51, 52, 53, 60, 77, 79, 81, 82, 89, 97], "divis": [23, 33, 44, 53, 82], "divorc": [22, 23, 43, 44, 52, 53, 81, 82], "dktal": [31, 61, 90], "dlwqn": [31, 61, 90], "dmp": 103, "do": [0, 1, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 18, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 42, 46, 47, 48, 49, 50, 51, 56, 59, 60, 61, 63, 64, 67, 69, 70, 71, 72, 73, 74, 77, 80, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "do_execut": 93, "dobj": [28, 49, 58, 87], "doc": [8, 9, 12, 28, 29, 38, 49, 50, 58, 59, 66, 67, 82, 87, 88, 92, 93, 103], "doc_id": [28, 49, 58, 87], "docker": 92, "doctor": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "document": [0, 1, 7, 12, 13, 14, 16, 17, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 34, 36, 37, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 53, 59, 60, 61, 63, 64, 65, 67, 68, 69, 72, 73, 75, 76, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 91, 93, 95, 99, 100, 101, 103], "document_top": [28, 49, 58, 87], "documentari": [27, 48, 57, 86], "doe": [5, 8, 10, 12, 14, 15, 16, 19, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 35, 36, 40, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 57, 58, 61, 64, 65, 67, 69, 71, 73, 74, 75, 78, 80, 81, 82, 83, 84, 86, 87, 89, 90, 92, 93, 95, 97, 99, 101, 102, 103], "doesn": [7, 8, 12, 14, 16, 17, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 34, 36, 37, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 67, 68, 73, 75, 76, 79, 80, 81, 82, 84, 85, 86, 87, 88, 90, 91, 95], "dog": [20, 29, 41, 50, 59, 64, 79, 88], "dolist": 92, "dollar": [4, 18, 21, 39, 42, 69, 77, 80, 91], "dolli": 93, "domain": [0, 12, 23, 25, 28, 32, 44, 46, 49, 53, 55, 58, 71, 82, 84, 87], "domin": [16, 21, 29, 36, 42, 50, 59, 67, 75, 80, 88], "domingo": [1, 14, 24, 45, 54, 73, 83], "dominican_republ": [28, 49, 87], "domino_pizza": 49, "don": [4, 12, 13, 14, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 37, 38, 40, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 67, 71, 73, 76, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94], "done": [5, 10, 12, 14, 17, 19, 20, 29, 30, 32, 34, 37, 40, 41, 50, 59, 67, 73, 76, 78, 79, 88, 89, 91, 95, 98, 100], "dont": 93, "door": [29, 50, 59, 88], "dosa": [28, 49, 87], "dot": [15, 18, 20, 22, 23, 24, 26, 28, 35, 39, 41, 44, 45, 47, 49, 52, 53, 54, 56, 61, 68, 74, 77, 79, 81, 82, 83, 85, 87], "dot_product": [28, 49, 58, 87], "doubl": [19, 40, 67, 78], "down": [14, 20, 23, 28, 31, 34, 41, 44, 49, 53, 58, 61, 65, 67, 68, 73, 79, 82, 87, 90, 91, 97, 101, 103], "downarrow": 61, "downfal": [27, 48, 57, 86], "downgrad": 93, "download": [5, 7, 10, 12, 13, 16, 18, 20, 21, 23, 28, 29, 32, 36, 39, 41, 42, 44, 49, 50, 58, 59, 63, 68, 69, 71, 72, 75, 77, 79, 80, 82, 87, 88, 91, 93, 97, 101], "downright": 91, "dpi": [24, 45, 54, 64, 83], "dr": [28, 49, 58, 87], "draft": 1, "drag": 7, "drama": [27, 48, 57, 86], "drastic": [20, 41, 79], "draw": [18, 19, 28, 39, 40, 49, 58, 77, 78, 87, 91], "drawback": [11, 23, 27, 44, 48, 53, 57, 82, 86], "drawn": [22, 43, 52, 81], "dream": [29, 50, 59, 88], "dreampharmaceut": [28, 49, 87], "drink": 91, "drinker": [28, 49, 58, 87], "drive": [12, 23, 32, 38, 44, 53, 66, 67, 71, 82], "driven": [10, 19, 20, 40, 41, 68, 78, 79], "droit": [28, 49, 58, 87], "drop": [7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 51, 52, 53, 54, 60, 61, 63, 65, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 101, 102, 103], "drop_dupl": [15, 19, 35, 40, 74, 78], "drop_feat": [17, 37, 65, 76, 95], "drop_feats_new": 65, "drop_featur": [20, 21, 22, 23, 30, 31, 41, 42, 43, 44, 52, 53, 61, 69, 79, 80, 81, 82, 89, 90, 91, 93, 100, 102], "dropdrop": [17, 21, 22, 37, 42, 43, 52, 65, 76, 80, 81, 91, 93], "drope": [16, 36, 75], "dropna": [20, 30, 79, 89, 92, 102], "dropoff": [25, 46, 55, 84], "drought": [66, 67], "drug": [12, 32, 71, 92], "dsci": [1, 9, 23, 44, 82, 91, 94], "dsl": [31, 61, 90], "dt": [63, 97], "dt88trtd17lf726d55bq16c40000gr": 93, "dt_best": 97, "dt_final": 63, "dt_pipe": [19, 40, 78], "dt_regr": 63, "dtype": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 100, 101, 102], "dtypelik": [61, 65], "dual": [20, 41, 79], "duan": [1, 103], "dub": 67, "duck": [29, 50, 59, 88, 91], "duckbil": [29, 50, 59, 88], "due": [7, 12, 13, 14, 16, 17, 18, 22, 24, 27, 32, 43, 45, 48, 52, 53, 54, 57, 61, 77, 81, 83, 86, 103], "duffel": 67, "dull": 67, "dummi": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 29, 30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 50, 51, 52, 53, 54, 59, 60, 61, 63, 66, 67, 68, 69, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 96, 98, 99, 100, 101, 102], "dummy_clf": [13, 33, 72, 96], "dummy_regr": 63, "dummy_scor": [15, 35, 74], "dummy_valid_accuraci": [15, 35, 74], "dummyclassifi": [14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 29, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 50, 51, 53, 54, 59, 60, 64, 65, 66, 67, 68, 69, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 88, 91, 92, 93, 96, 97, 98, 99, 100, 101, 102], "dummyregressor": [17, 22, 23, 24, 37, 43, 44, 45, 52, 53, 54, 63, 69, 76, 81, 82, 83, 91, 92, 93, 98, 101], "dump": 92, "dun": [12, 32, 71], "dunham": 67, "dunno": [12, 32, 71], "duplex": [21, 42, 69, 80], "duplic": 8, "durat": [7, 24, 30, 31, 45, 51, 54, 60, 61, 83, 89, 90], "duration_col": [31, 61, 90], "duration_m": [15, 16, 19, 36, 40, 74, 75, 78], "dure": [1, 4, 8, 12, 13, 15, 17, 18, 19, 22, 23, 24, 27, 28, 32, 33, 35, 37, 39, 40, 43, 44, 45, 48, 49, 52, 53, 54, 57, 58, 61, 63, 67, 71, 72, 74, 76, 77, 78, 81, 82, 83, 86, 87, 92, 95, 96, 97, 98, 99, 100, 101, 102, 103], "dwell": [21, 42, 69, 80], "e": [6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 102], "e737c5242822": [31, 61, 90], "e_": [14, 34, 73], "each": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103], "eager": 92, "earli": [23, 31, 44, 53, 61, 67, 82, 90, 91, 103], "earlier": [16, 22, 24, 30, 31, 36, 43, 45, 51, 52, 54, 60, 61, 67, 75, 81, 83, 89, 90], "early_stopping_round": [22, 43, 52, 81], "earnest": 103, "easi": [7, 15, 16, 18, 22, 23, 24, 25, 26, 28, 35, 36, 39, 43, 44, 46, 47, 49, 52, 53, 54, 55, 56, 58, 74, 75, 77, 81, 82, 83, 84, 85, 87, 91, 93], "easier": [5, 7, 20, 23, 24, 27, 41, 44, 45, 48, 53, 54, 57, 68, 70, 79, 82, 83, 86, 91], "easiest": [23, 31, 44, 53, 61, 82, 90, 93], "easili": [22, 24, 30, 43, 45, 52, 54, 81, 83, 89, 91, 92, 96, 102], "east": [65, 67], "eat": 67, "eat_out_freq": 65, "echidna": [29, 50, 59, 88], "econom": [17, 30, 37, 51, 60, 76, 89], "ecosystem": [29, 50, 59, 88], "eda": [14, 28, 31, 34, 49, 58, 61, 63, 65, 73, 87, 90, 95, 102], "edg": [13, 19, 33, 40, 72, 78], "edgecolor": [19, 30, 40, 78, 89, 102], "edit": [28, 40, 49, 58, 78, 87], "edu": 9, "educ": [20, 22, 23, 27, 41, 43, 44, 48, 52, 53, 57, 79, 81, 82, 86, 100], "education_level": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "effect": [15, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 35, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60, 63, 64, 67, 69, 74, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 92, 95, 97, 100, 103], "effici": [19, 40, 78], "effort": [4, 10, 19, 24, 25, 27, 29, 40, 45, 46, 48, 50, 54, 55, 57, 59, 78, 83, 84, 86, 88, 103], "egg": [25, 46, 55, 84], "either": [4, 13, 14, 15, 17, 20, 23, 25, 26, 28, 29, 30, 33, 34, 35, 37, 41, 44, 46, 47, 49, 50, 51, 53, 55, 56, 58, 59, 60, 64, 68, 72, 73, 74, 76, 79, 82, 84, 85, 87, 88, 89, 97, 99], "elast": [31, 54, 61, 90], "elbow": [26, 47, 56, 85], "elect": [28, 49, 58, 87], "electr": [21, 23, 42, 44, 53, 80, 82, 91], "electrical_engin": [28, 49, 58, 87], "electrical_fusea": [21, 42, 80], "electrical_fusef": [21, 42, 80], "electrical_fusep": [21, 42, 80], "electrical_miss": [21, 42, 80], "electrical_mix": [21, 42, 80], "electrical_sbrkr": [21, 42, 80], "electron": [31, 61, 90, 103], "eleg": [16, 28, 36, 49, 58, 75, 87, 91], "elegantli": [28, 49, 87], "element": [0, 1, 9, 14, 17, 28, 37, 49, 58, 67, 73, 76, 87, 96], "eli5": [23, 53, 82], "elif": [13, 30, 31, 33, 61, 72, 89, 90], "elimin": 11, "elliott": 67, "els": [13, 17, 20, 29, 30, 31, 33, 37, 41, 50, 59, 61, 64, 65, 70, 72, 76, 79, 88, 89, 90, 93, 100], "email": [1, 12, 13, 14, 20, 32, 34, 41, 71, 73, 79, 92, 103], "emb": [7, 15, 20, 25, 35, 41, 46, 47, 56, 68, 74, 79, 84, 85], "embarrass": 67, "embed": [1, 11, 17, 29, 37, 50, 59, 76, 88, 92, 95], "emili": 67, "emoji": [66, 67, 93], "emoticon": [24, 25, 45, 46, 54, 55, 83, 84], "emp": [23, 44, 53, 82], "empathi": [28, 49, 58, 87], "emphas": 11, "emphasi": [92, 103], "emploi": [30, 31, 51, 60, 61, 64, 89, 90, 92, 95], "employ": [27, 48, 57, 86], "employe": [13, 33, 72], "empti": [18, 28, 29, 30, 39, 49, 50, 58, 59, 64, 70, 77, 87, 88, 89, 102], "en": [30, 31, 61, 89, 90, 91, 93, 102], "en_core_web_lr": [28, 49, 58, 87], "en_core_web_md": [28, 49, 58, 87, 93], "enabl": [10, 27, 28, 30, 48, 49, 51, 57, 60, 86, 87, 89], "enable_categor": [22, 43, 52, 81], "enable_halving_search_cv": [19, 40, 78], "enc": [16, 17, 30, 36, 37, 51, 60, 75, 76, 89], "enclosedporch": [21, 23, 42, 44, 53, 69, 80, 82, 91], "encod": [12, 14, 19, 20, 21, 23, 27, 31, 32, 34, 38, 40, 41, 42, 44, 48, 53, 57, 61, 63, 65, 66, 67, 68, 71, 73, 78, 79, 80, 82, 86, 90, 95, 98, 100, 102], "encompass": [31, 61, 90, 91, 95], "encount": [17, 37, 76, 78], "encourag": 10, "end": [4, 8, 11, 12, 14, 15, 18, 19, 20, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 39, 40, 41, 45, 46, 47, 48, 49, 51, 52, 54, 56, 57, 58, 60, 61, 64, 67, 68, 71, 73, 74, 77, 78, 79, 83, 84, 85, 86, 87, 89, 90, 91, 92, 97, 103], "endors": 0, "endpoint": [31, 61, 90], "energi": [15, 16, 19, 30, 36, 40, 51, 60, 74, 75, 78, 89, 99], "engag": 103, "engin": [1, 9, 11, 17, 20, 21, 25, 27, 28, 31, 37, 41, 42, 46, 48, 49, 55, 57, 58, 61, 68, 76, 79, 80, 84, 86, 87, 90, 92, 102], "england": 93, "english": [12, 16, 19, 20, 28, 29, 32, 36, 38, 40, 49, 50, 58, 59, 65, 66, 67, 71, 75, 78, 79, 87, 88, 92, 93, 99], "enhanc": 103, "enjoi": [1, 18, 38, 39, 66, 67, 77], "enjoy_class": [17, 37, 76], "enjoy_cours": [17, 37, 76, 95], "enjoy_course_enc": [17, 37, 76], "enjoy_the_mo": [20, 79, 92], "enough": [7, 15, 17, 20, 21, 22, 25, 27, 35, 41, 42, 43, 46, 48, 52, 55, 57, 67, 68, 74, 76, 79, 80, 81, 84, 86, 95, 99, 100, 102], "enrol": 103, "ensembl": [1, 11, 21, 23, 24, 26, 27, 30, 31, 42, 44, 45, 48, 51, 53, 54, 56, 57, 60, 61, 65, 69, 80, 82, 83, 85, 86, 89, 90, 91, 92, 93, 101, 102], "ensiti": [26, 47, 56, 85], "ensur": [7, 11, 16, 22, 30, 36, 43, 52, 63, 75, 81, 89, 102], "ensure_2d": [61, 65], "ensure_all_finit": [61, 65], "ensure_min_featur": [61, 65], "ensure_min_sampl": [61, 65], "ensure_non_neg": [61, 65], "ent": [28, 49, 58, 87, 93], "enter": [17, 31, 37, 61, 76, 90, 91, 99], "enterpris": 5, "entertain": [28, 49, 58, 67, 87], "enthusiast": [12, 32, 71, 91], "entir": [4, 8, 12, 14, 21, 29, 30, 32, 34, 42, 50, 51, 59, 60, 67, 73, 80, 88, 89, 91, 92, 93, 101, 103], "entiti": [24, 27, 28, 45, 48, 49, 54, 57, 83, 86, 87, 93], "entitl": [17, 37, 76], "entlebuch": [12, 29, 32, 50, 59, 71, 88], "entri": [15, 16, 17, 18, 20, 21, 24, 27, 30, 31, 35, 36, 37, 39, 41, 42, 45, 48, 54, 57, 61, 68, 74, 75, 76, 77, 79, 80, 83, 86, 89, 90, 102], "entropi": [13, 33, 72, 91], "entry_col": 61, "enumer": [22, 43, 81], "env": [10, 17, 19, 29, 31, 33, 37, 50, 61, 64, 65, 72, 73, 76, 78, 82, 90, 93, 94], "environ": [3, 5, 8, 12, 16, 17, 19, 20, 21, 22, 23, 24, 28, 29, 31, 32, 36, 37, 40, 41, 42, 43, 44, 45, 49, 50, 52, 53, 55, 58, 59, 63, 64, 65, 67, 68, 70, 71, 75, 76, 78, 79, 80, 81, 82, 83, 87, 88, 90, 91, 93, 103], "environemnt": 10, "environment": 95, "ep": [13, 14, 15, 18, 26, 34, 35, 39, 47, 72, 73, 74, 77, 85, 96], "episod": 67, "epoch": [30, 51, 89], "epsilon": [26, 47, 56, 85, 91], "equal": [8, 15, 17, 20, 21, 22, 23, 26, 27, 30, 35, 41, 42, 43, 44, 47, 48, 51, 52, 53, 56, 57, 60, 68, 69, 74, 76, 79, 80, 81, 82, 85, 86, 89, 95, 102, 103], "equat": [4, 12, 18, 32, 39, 54, 77], "equip": [15, 31, 35, 61, 74, 90, 103], "equival": [8, 20, 22, 41, 43, 52, 79, 81, 100], "erik": [28, 49, 87], "err": [28, 49, 87], "error": [4, 6, 7, 8, 10, 11, 13, 15, 17, 18, 22, 23, 24, 28, 31, 33, 35, 37, 39, 43, 44, 45, 49, 52, 53, 54, 58, 61, 65, 72, 74, 76, 77, 81, 82, 83, 87, 90, 91, 92, 93, 95, 97, 101], "error_": [14, 34, 73], "error_scor": 19, "erupt": [12, 71], "erythrocebu": [12, 29, 32, 50, 59, 71, 88], "es": [30, 89, 102], "escap": [50, 67], "eskimo": [20, 41, 79], "esl": 1, "especi": [2, 15, 19, 20, 22, 24, 27, 30, 33, 35, 40, 41, 43, 44, 45, 48, 51, 52, 57, 60, 67, 72, 74, 78, 79, 81, 83, 86, 89], "essenti": [31, 61, 90, 95], "establish": 63, "estat": [13, 33, 72], "estim": [14, 15, 17, 18, 19, 24, 25, 31, 35, 37, 39, 40, 45, 46, 54, 55, 61, 65, 73, 74, 76, 77, 78, 83, 84, 90, 91, 92, 95, 101], "estimator_nam": 65, "estimators_": [22, 43, 52, 81], "et": [22, 28, 43, 49, 52, 55, 58, 81, 87], "etc": [1, 2, 7, 8, 13, 24, 28, 29, 30, 31, 33, 45, 49, 50, 51, 53, 58, 59, 60, 61, 72, 83, 87, 88, 89, 90, 91, 92, 93, 103], "ethic": [1, 11, 92], "euclidean": [25, 26, 28, 46, 47, 49, 55, 56, 84, 85, 87], "euclidean_dist": [15, 16, 25, 26, 28, 35, 36, 46, 47, 49, 56, 58, 74, 75, 84, 85, 87], "ev": 93, "eva": [27, 48, 86], "eva_model": [27, 48, 57, 86], "eval": [29, 50, 59, 88], "eval_metr": [22, 23, 43, 44, 52, 53, 81, 82], "eval_on_featur": [30, 51, 60, 89], "evalu": [1, 8, 11, 13, 14, 19, 21, 23, 25, 30, 33, 34, 40, 44, 46, 51, 53, 55, 60, 63, 72, 73, 78, 80, 82, 84, 89, 91, 92, 97, 101], "evapor": [30, 89, 102], "even": [0, 7, 11, 12, 13, 14, 18, 19, 20, 24, 25, 26, 27, 30, 31, 32, 33, 34, 39, 41, 45, 46, 47, 48, 51, 54, 55, 56, 57, 60, 61, 65, 67, 72, 73, 77, 78, 79, 83, 84, 85, 86, 89, 90, 91, 93, 95, 97, 98, 100, 103], "evenli": 67, "event": [0, 20, 21, 42, 69, 79, 80, 93, 103], "event_col": [31, 61, 90], "event_observ": [31, 61, 90], "ever": [13, 33, 67, 72, 94], "everi": [8, 12, 13, 14, 22, 26, 30, 32, 33, 34, 43, 47, 51, 52, 56, 67, 72, 73, 81, 85, 89, 97], "everydai": [8, 28, 49, 87], "everyon": [6, 23, 44, 53, 82, 91, 95], "everyth": [12, 17, 20, 27, 30, 32, 37, 41, 48, 51, 57, 60, 68, 76, 79, 86, 89, 92, 101], "everywher": [30, 51, 60, 89], "evict": 93, "evo": 92, "evocarshar": 92, "evok": [28, 49, 58, 87], "ex": [21, 23, 42, 44, 53, 69, 80, 82, 91], "ex1_idx": [23, 44, 53, 82], "ex2_idx": [23, 44, 53, 82], "ex_df": [38, 66, 67], "exact": [4, 31, 61, 90], "exactli": [7, 12, 14, 23, 32, 33, 34, 44, 53, 67, 71, 73, 82, 97, 99], "exagger": 91, "exam": [1, 6, 12, 20, 32, 40, 54, 91, 92], "examin": [14, 15, 16, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 34, 35, 36, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 73, 74, 75, 77, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 94, 100, 102], "exampl": [0, 4, 5, 6, 7, 8, 10, 21, 26, 27, 29, 30, 34, 38, 42, 47, 48, 50, 51, 56, 59, 60, 64, 65, 66, 67, 69, 80, 85, 86, 88, 89, 92, 94, 95, 96, 97, 99, 100, 102, 103], "example1": [13, 33, 72], "example2": [13, 33, 72], "exceedingli": 97, "excel": [17, 18, 21, 23, 31, 37, 38, 39, 42, 44, 53, 61, 66, 67, 69, 76, 77, 80, 82, 90, 95, 98], "except": [0, 1, 7, 8, 14, 30, 31, 34, 61, 65, 67, 73, 89, 90, 102, 103], "exception": 4, "exchang": [20, 41, 60, 68, 79, 95], "excit": [27, 48, 57, 86], "exec": 93, "execut": [4, 7, 25, 46, 84, 92], "execute_request": 93, "exercis": [1, 7, 9, 12, 28, 32, 49, 87, 92, 93, 97, 98, 99, 100, 101, 102, 103], "exerciseangina": 101, "exhaust": 99, "exist": [8, 19, 20, 24, 31, 41, 45, 61, 79, 83, 90, 92, 100], "exp": [18, 31, 39, 61, 77, 90, 91], "expand": [1, 13, 33, 72, 103], "expect": [1, 4, 7, 8, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 69, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 97, 100, 102, 103], "expected_valu": [23, 44, 53, 82], "expenditur": [30, 51, 60, 89], "expens": [12, 20, 21, 24, 25, 27, 32, 41, 42, 45, 46, 48, 54, 55, 57, 68, 71, 79, 80, 83, 84, 86], "experi": [12, 19, 27, 28, 32, 40, 48, 49, 57, 58, 70, 71, 78, 86, 87, 103], "experienc": 103, "experiment": [19, 40, 67, 78, 92], "expert": [12, 13, 14, 19, 23, 24, 32, 33, 34, 40, 44, 45, 53, 54, 71, 72, 73, 78, 82, 83, 100], "expertis": 54, "explain": [4, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 95, 100, 101], "explan": [4, 14, 15, 35, 67, 73, 74, 95, 100], "explanatori": [13, 33, 72], "explicit": [20, 31, 41, 61, 68, 79, 90], "explicitli": [8, 12, 32, 71, 92], "exploit": 6, "explor": [13, 14, 17, 19, 20, 23, 24, 27, 28, 29, 34, 37, 38, 40, 41, 44, 45, 48, 49, 50, 53, 54, 58, 59, 63, 64, 66, 67, 68, 72, 73, 76, 78, 79, 82, 83, 86, 87, 88, 92, 97, 99], "exploratori": [21, 31, 42, 61, 80, 90, 92, 95], "explos": 93, "expm1": [21, 42, 69, 80, 91], "expon": [19, 40, 78], "exponenti": [19, 40, 78], "export_graphviz": [13, 33, 72, 96], "expos": [38, 66, 67], "exposur": [27, 48, 57, 86], "express": [0, 8, 17, 18, 24, 28, 37, 39, 45, 49, 54, 58, 67, 76, 77, 83, 87, 91], "extend": [28, 29, 49, 50, 58, 59, 87, 88, 94, 103], "extend_block": [31, 61, 90], "extens": [1, 12, 15, 20, 23, 25, 26, 28, 30, 32, 35, 41, 44, 46, 47, 49, 51, 53, 56, 58, 60, 64, 68, 74, 79, 82, 84, 85, 87, 89, 97, 103], "extent": [25, 28, 46, 49, 55, 58, 84, 87], "extercond": [21, 23, 42, 44, 53, 69, 80, 82, 91], "exterior": [23, 44, 53, 82], "exterior1st": [21, 23, 42, 44, 53, 80, 82, 91], "exterior1st_asbshng": [21, 42, 80], "exterior1st_asphshn": [21, 42, 80], "exterior1st_brkcomm": [21, 42, 80], "exterior1st_brkfac": [21, 42, 80], "exterior1st_cblock": [21, 42, 80], "exterior1st_cemntbd": [21, 42, 80], "exterior1st_hdboard": [21, 42, 80], "exterior1st_imstucc": [21, 23, 42, 53, 80, 82], "exterior1st_metalsd": [21, 42, 80], "exterior1st_plywood": [21, 42, 80], "exterior1st_ston": [21, 42, 80], "exterior1st_stucco": [21, 42, 80], "exterior1st_vinylsd": [21, 42, 80], "exterior1st_wd": [21, 42, 80], "exterior1st_wdsh": [21, 42, 80], "exterior2nd": [21, 23, 42, 44, 53, 80, 82, 91], "exterior2nd_asbshng": [21, 42, 80], "exterior2nd_asphshn": [21, 42, 80], "exterior2nd_brk": [21, 42, 80], "exterior2nd_brkfac": [21, 42, 80], "exterior2nd_cblock": [21, 42, 80], "exterior2nd_cmentbd": [21, 42, 80], "exterior2nd_hdboard": [21, 42, 80], "exterior2nd_imstucc": [21, 42, 80], "exterior2nd_metalsd": [21, 42, 80], "exterior2nd_oth": [21, 42, 80], "exterior2nd_plywood": [21, 42, 80, 91], "exterior2nd_ston": [21, 42, 80, 91], "exterior2nd_stucco": [21, 42, 80, 91], "exterior2nd_vinylsd": [21, 42, 80, 91], "exterior2nd_wd": [21, 42, 80, 91], "external_tool": 92, "exterqu": [21, 23, 42, 44, 53, 69, 80, 82, 91], "extra": [4, 25, 30, 46, 84, 89, 92, 102, 103], "extract": [24, 25, 27, 28, 29, 45, 46, 48, 49, 50, 54, 55, 57, 64, 70, 83, 84, 86, 87, 88, 93, 102, 103], "extractor": [70, 95], "extrapol": [30, 31, 51, 60, 61, 89, 90], "extratreesclassifi": [22, 81], "extrem": [6, 17, 20, 22, 23, 27, 31, 41, 43, 44, 48, 52, 53, 57, 61, 67, 68, 76, 79, 81, 82, 86, 90, 93], "ey": [69, 93], "f": [8, 10, 12, 13, 14, 15, 16, 17, 20, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 64, 65, 68, 71, 72, 73, 74, 75, 76, 79, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 97, 101, 102], "f1": [11, 21, 80, 95], "f1_score": [20, 41, 68, 79], "f2": 56, "f403": 93, "fa": [21, 23, 42, 44, 53, 69, 80, 82, 91], "face": [12, 13, 15, 27, 29, 32, 48, 50, 57, 59, 64, 67, 71, 72, 74, 86, 88], "facebook": [27, 28, 48, 49, 57, 58, 86, 87, 103], "facial": [15, 67, 74], "facil": 103, "facilit": [8, 103], "fact": [12, 19, 20, 22, 29, 30, 31, 40, 41, 43, 50, 51, 59, 60, 61, 68, 71, 78, 79, 81, 88, 89, 90, 91, 102], "factor": [13, 19, 23, 24, 26, 27, 31, 33, 40, 44, 45, 47, 48, 53, 54, 56, 61, 72, 78, 82, 83, 85, 86, 90], "fail": [1, 7, 8, 10, 14, 16, 17, 24, 26, 28, 31, 34, 36, 37, 45, 47, 49, 54, 56, 58, 61, 73, 75, 76, 83, 85, 87, 90, 91, 93], "failur": [7, 12, 31, 32, 61, 71, 90, 101, 103], "fair": [6, 14, 16, 21, 23, 25, 34, 36, 42, 44, 46, 53, 55, 69, 73, 75, 80, 82, 84, 92, 95, 103], "fairli": [14, 19, 20, 23, 34, 40, 41, 44, 48, 53, 73, 78, 79, 82, 92, 100], "fake": [15, 35, 38, 66, 67, 74], "fake_review": [38, 66, 67], "fall": [15, 25, 28, 30, 35, 46, 49, 58, 74, 84, 87, 89], "fals": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 53, 54, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 91, 95, 100, 101, 102], "famili": [12, 19, 20, 21, 22, 23, 25, 32, 40, 41, 42, 43, 44, 46, 52, 53, 55, 67, 69, 71, 78, 79, 80, 81, 82, 84, 92, 103], "familiar": [8, 10, 11, 13, 16, 33, 36, 72, 75, 91, 97, 102, 103], "famou": [1, 9, 28, 29, 38, 49, 50, 58, 59, 66, 67, 87, 88], "fanci": [4, 12, 19, 32, 71, 78], "fancier": [24, 45, 54, 83], "fantast": 67, "far": [13, 15, 16, 17, 18, 20, 23, 24, 25, 26, 28, 29, 30, 31, 35, 36, 37, 39, 41, 44, 46, 47, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 68, 72, 74, 75, 76, 77, 79, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 97, 99, 101], "farm": [20, 41, 79], "farthest": [13, 33, 72], "fashion": [22, 28, 33, 43, 49, 52, 58, 67, 81, 87], "fast": [14, 15, 18, 22, 23, 28, 31, 34, 39, 43, 44, 49, 53, 58, 61, 67, 73, 74, 77, 81, 82, 87, 90, 92, 103], "faster": [12, 19, 22, 24, 29, 32, 40, 43, 45, 50, 52, 54, 59, 61, 71, 78, 81, 83, 88], "fastest": [22, 43, 81], "fastingb": 101, "fasttext": [28, 49, 58, 87], "favorit": 67, "favour": 92, "favourit": [28, 49, 58, 87], "fc": [18, 39, 77], "fcluster": [26, 47, 56, 85], "fear": 67, "feat": [30, 40, 51, 60, 65, 78, 89, 93], "feat1": [25, 46, 84], "feat2": [25, 46, 84], "feat_nam": [30, 51, 60, 65, 89, 93], "feat_vec": [27, 38, 48, 57, 66, 67, 86], "feat_vect": 38, "featur": [1, 11, 14, 20, 22, 25, 26, 28, 31, 34, 38, 41, 43, 46, 47, 49, 52, 55, 56, 58, 61, 63, 64, 66, 67, 68, 70, 73, 79, 81, 84, 85, 87, 90, 92, 94, 97, 98, 99, 100, 101, 103], "feature_extract": [12, 17, 18, 19, 20, 28, 32, 37, 38, 39, 40, 49, 58, 65, 66, 67, 71, 76, 77, 78, 79, 87, 92, 93, 99], "feature_import": 63, "feature_importances_": [24, 45, 54, 63, 83], "feature_nam": [13, 14, 18, 22, 23, 24, 28, 33, 34, 38, 39, 43, 44, 45, 49, 52, 53, 54, 58, 63, 66, 67, 72, 73, 77, 81, 82, 83, 87], "feature_names_in_": 63, "feature_names_out": [17, 37, 76], "feature_select": [24, 45, 54, 83], "feature_typ": [22, 43, 52, 81], "features_lag": [30, 51, 60, 89], "features_nonzero": [30, 51, 60, 89], "features_poli": [30, 51, 60, 89], "feb": [1, 16, 18], "februari": [30, 51, 60, 63, 89], "feder": [20, 23, 30, 41, 44, 51, 60, 79, 82, 87, 89], "feed": [64, 65, 67], "feedback": [33, 72, 95], "feel": [5, 6, 14, 34, 65, 67, 73, 84, 92, 95], "feli": [12, 29, 32, 50, 59, 71, 88], "felix": 1, "fell": [18, 39, 77], "felt": 65, "femal": [20, 22, 23, 31, 41, 43, 44, 52, 53, 61, 79, 81, 82, 90, 100], "female_cm": [20, 41, 79, 100], "female_pr": [20, 41, 79, 100], "fenc": [21, 23, 29, 42, 44, 50, 53, 59, 69, 80, 82, 88, 91], "fernandez": [22, 43, 52, 81], "fest": 67, "fetch_california_h": [18, 39, 77], "few": [1, 8, 12, 18, 21, 22, 24, 27, 28, 29, 30, 31, 32, 38, 39, 42, 45, 48, 49, 50, 51, 52, 54, 57, 58, 59, 60, 61, 65, 66, 67, 69, 71, 77, 80, 81, 83, 86, 87, 88, 89, 90, 92, 96, 101], "fewer": [10, 22, 24, 26, 43, 45, 47, 54, 56, 81, 83, 85], "fewest": 101, "feynman": 91, "fiber": [31, 61, 90], "fiction": 93, "field": [2, 4, 11, 12, 17, 28, 29, 30, 32, 37, 49, 50, 51, 58, 59, 60, 71, 76, 87, 88, 89, 92], "fig": [14, 15, 18, 20, 24, 25, 26, 29, 34, 35, 39, 41, 45, 46, 47, 50, 54, 55, 56, 58, 59, 64, 70, 73, 74, 77, 79, 83, 84, 85, 88, 97, 100], "fight": 67, "figsiz": [13, 14, 15, 16, 18, 20, 23, 24, 25, 26, 29, 30, 31, 33, 34, 35, 36, 39, 41, 44, 45, 46, 47, 50, 51, 53, 54, 55, 56, 59, 60, 61, 64, 65, 70, 72, 73, 74, 75, 77, 79, 82, 83, 84, 85, 88, 89, 90, 91, 97, 100], "figur": [4, 8, 10, 12, 13, 15, 19, 21, 23, 24, 25, 26, 29, 30, 31, 32, 33, 35, 40, 42, 44, 45, 46, 47, 50, 51, 53, 54, 55, 56, 59, 60, 61, 64, 70, 71, 72, 74, 78, 80, 82, 83, 84, 85, 88, 89, 90, 91, 97], "file": [0, 1, 4, 5, 7, 8, 10, 12, 13, 17, 20, 23, 29, 31, 32, 37, 38, 41, 44, 50, 53, 59, 61, 65, 68, 72, 76, 79, 82, 88, 90, 92, 93, 100, 102], "file_nam": [64, 70], "filenam": [29, 50, 59, 88], "fill": [15, 18, 19, 27, 35, 39, 40, 48, 63, 64, 65, 74, 77, 78, 86, 92, 97, 101, 103], "fill_diagon": [15, 35, 74], "fill_valu": [20, 21, 22, 23, 30, 41, 42, 43, 44, 52, 53, 65, 69, 79, 80, 81, 82, 89, 91, 100, 102], "film": [28, 49, 58, 67, 87, 93], "filter": [4, 11, 12, 14, 25, 30, 32, 34, 46, 55, 71, 73, 84, 89, 95, 102], "filterwarn": [15, 23, 32, 34, 35, 43, 44, 45, 46, 47, 61, 74, 90, 101], "final": [1, 6, 7, 12, 14, 16, 22, 24, 32, 34, 36, 43, 44, 45, 52, 54, 61, 63, 67, 73, 75, 81, 83, 91, 92, 96, 98, 101], "final_estim": [22, 43, 52, 81], "final_estimator_": [22, 43, 52, 81, 101], "finalis": [66, 67], "financ": [29, 30, 50, 51, 59, 60, 88, 89], "find": [1, 7, 8, 12, 13, 16, 19, 21, 22, 23, 25, 26, 27, 28, 32, 33, 36, 38, 40, 42, 43, 44, 46, 47, 48, 49, 52, 53, 56, 57, 64, 65, 66, 67, 69, 70, 71, 72, 75, 78, 80, 81, 82, 84, 85, 86, 87, 91, 93, 94, 99, 100, 103], "fine": [7, 16, 17, 20, 27, 29, 30, 36, 37, 41, 48, 50, 51, 59, 60, 67, 75, 76, 79, 86, 88, 89, 92, 101], "finish": [12, 21, 32, 42, 67, 69, 71, 80], "fira": [0, 1], "firasm": [20, 41, 68, 79, 100], "firefox": [12, 32], "fireplac": [21, 23, 42, 44, 53, 69, 80, 82, 91], "fireplacequ": [21, 23, 42, 44, 53, 69, 80, 82, 91], "first": [1, 4, 8, 13, 15, 17, 18, 19, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 35, 37, 38, 39, 40, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 65, 66, 67, 72, 74, 76, 77, 78, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 96, 97, 99, 100, 101, 103], "first_cal": 61, "first_dai": [30, 89], "first_day_retail": [30, 51, 60, 89], "first_pass_isfinit": 65, "firth": [28, 49, 58, 87], "fish": [20, 23, 41, 44, 53, 79, 82], "fist": [30, 51, 60, 89], "fit": [0, 12, 14, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 102, 103], "fit_intercept": [20, 41, 79], "fit_method": [61, 65], "fit_opt": 61, "fit_param": 61, "fit_predict": [26, 47, 56, 85], "fit_resampl": [20, 79], "fit_right_censor": 61, "fit_tim": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 64, 65, 67, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 89, 90, 93], "fit_transform": [16, 17, 20, 22, 23, 24, 26, 27, 28, 30, 36, 37, 38, 41, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 57, 58, 60, 61, 65, 66, 67, 75, 76, 79, 81, 82, 83, 85, 86, 87, 89, 95, 100], "fittedcolumntransform": [17, 22, 37, 43, 76, 81], "fittedpipelin": [19, 21, 40, 42, 76, 78, 80], "fittedvotingclassifi": [22, 43, 52, 81], "fitter": [61, 90], "five": [19, 40, 78], "fix": [16, 17, 22, 31, 36, 37, 52, 56, 61, 65, 75, 76, 81, 90, 92, 94, 97, 103], "flag": [31, 61, 90], "flagstaff": 93, "flaki": [20, 79], "flashcard": 95, "flask": 92, "flat": [26, 47, 85], "flatten": [22, 23, 26, 30, 38, 43, 44, 47, 52, 53, 56, 64, 66, 67, 70, 81, 82, 85, 89, 101], "flatten_dataload": 70, "flatten_imag": 70, "flatten_train": [29, 50, 59, 70, 88], "flatten_transform": [29, 50, 59, 70, 88], "flatten_valid": [29, 50, 59, 88], "flatter": 39, "flaw": [14, 16, 34, 36, 73, 75], "flawless": [18, 38, 39, 66, 67, 77], "flesh": 67, "flexibl": [7, 12, 24, 29, 45, 50, 54, 59, 71, 83, 88, 95, 103], "flibbertigibbet": [28, 49, 58, 87], "flickr_cat_000002": [29, 50, 59, 88], "flight": [24, 45, 54, 83], "flip": [1, 14, 20, 21, 41, 42, 68, 69, 73, 79, 80, 92], "flip_i": [20, 79], "float": [8, 21, 24, 31, 42, 54, 61, 65, 80, 83, 90, 93], "float32": [28, 29, 49, 50, 58, 59, 87, 88], "float64": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 30, 31, 35, 36, 37, 40, 41, 42, 43, 44, 45, 48, 52, 53, 54, 57, 61, 64, 65, 67, 72, 74, 75, 76, 78, 79, 80, 81, 82, 83, 86, 89, 90, 102], "floatlogslid": [15, 35, 74, 97], "floatslid": [15, 20, 25, 35, 41, 46, 47, 56, 64, 68, 74, 79, 84, 85, 97], "floor": [12, 13, 32, 63, 71, 72, 103], "flower": [15, 20, 35, 64, 74, 79, 92, 97], "fly": 67, "fmt": [19, 40, 78], "fn": [20, 41, 68, 79], "fnlwgt": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "focu": [1, 11, 12, 16, 17, 18, 23, 26, 27, 28, 30, 32, 36, 37, 39, 44, 47, 48, 49, 51, 53, 54, 56, 57, 60, 65, 71, 75, 76, 77, 82, 85, 86, 87, 89, 95, 97, 98, 99, 100, 101, 103], "focus": [12, 18, 25, 28, 39, 46, 49, 54, 55, 67, 71, 77, 84, 87, 95, 102], "fog": 67, "foggi": 67, "fold": [14, 16, 17, 19, 20, 21, 22, 34, 36, 37, 40, 41, 42, 52, 69, 73, 75, 76, 78, 79, 80, 81, 92, 97], "folder": [5, 6, 36, 73, 75, 82, 92, 93], "folk": [31, 61, 90, 92, 103], "follow": [0, 5, 6, 7, 8, 10, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 53, 54, 58, 59, 60, 61, 65, 66, 67, 68, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 103], "font": [12, 13, 14, 25, 26, 27, 30, 31, 32, 33, 34, 46, 47, 48, 51, 55, 56, 57, 60, 61, 71, 72, 73, 84, 85, 86, 89, 90, 91], "font_scal": [23, 44, 53, 82], "fontsiz": [13, 14, 15, 20, 22, 23, 25, 29, 33, 34, 35, 41, 43, 44, 46, 50, 52, 53, 55, 59, 63, 64, 68, 72, 73, 74, 79, 81, 82, 84, 88, 91, 96, 97], "food": [25, 28, 29, 46, 49, 50, 55, 59, 65, 70, 84, 87, 88, 103], "food_class": 70, "food_input": 70, "food_typ": 65, "food_type_canadian": 65, "food_type_chines": 65, "food_type_fus": 65, "food_type_indian": 65, "food_type_italian": 65, "food_type_mexican": 65, "food_type_nan": 65, "food_type_oth": 65, "food_type_quebecoi": 65, "food_type_thai": 65, "foot": [21, 23, 42, 44, 53, 80, 82], "footag": [18, 39, 67, 77], "footstal": [29, 50, 59, 88], "forc": [20, 23, 44, 79, 82, 97], "force_all_finit": [61, 65], "force_plot": [23, 44, 53, 82], "force_writ": [61, 65], "forecast": [11, 13, 31, 33, 61, 72, 90, 91, 95, 102], "forest": [11, 20, 21, 29, 30, 31, 42, 50, 51, 59, 60, 61, 69, 79, 80, 88, 89, 90, 92, 95, 101], "forestcolumntransform": [22, 43, 52], "forev": [30, 51, 60, 89], "forg": [10, 20, 21, 22, 23, 28, 31, 42, 43, 44, 49, 52, 53, 58, 79, 80, 81, 82, 87, 90, 93], "forget": [13, 15, 16, 17, 22, 33, 37, 43, 52, 72, 76, 81, 101], "form": [1, 12, 17, 20, 24, 26, 27, 28, 31, 32, 35, 37, 41, 45, 47, 48, 49, 54, 56, 57, 58, 61, 76, 79, 83, 85, 86, 87, 90, 91, 92, 95], "formal": 103, "format": [0, 1, 13, 20, 26, 28, 30, 31, 33, 41, 47, 49, 51, 54, 56, 58, 60, 61, 63, 65, 68, 72, 79, 85, 87, 89, 90, 102], "former": [31, 61, 90], "formul": [4, 19, 40, 78], "formula": [18, 21, 29, 39, 42, 50, 59, 61, 77, 80, 88, 94], "forum": [12, 32], "forward": [31, 61, 90, 92], "found": [1, 7, 14, 17, 19, 21, 25, 27, 28, 34, 37, 40, 42, 46, 48, 49, 57, 58, 62, 63, 65, 69, 73, 76, 78, 80, 84, 86, 87, 93, 95, 99, 101, 103], "foundat": [1, 9, 11, 20, 21, 23, 42, 44, 53, 69, 79, 80, 82, 91], "foundation_brktil": [21, 42, 80], "foundation_cblock": [21, 42, 80], "foundation_pconc": [21, 42, 80], "foundation_slab": [21, 42, 80], "foundation_ston": [21, 42, 80], "foundation_wood": [21, 42, 80], "fountain": [29, 50, 59, 88], "four": [13, 14, 24, 26, 33, 45, 47, 54, 72, 73, 83, 85, 92, 95], "fourth": [26, 47, 56, 85], "foxhound": [12, 29, 32, 50, 59, 71, 88], "foyer": [21, 42, 69, 80], "fp": [20, 41, 68, 79], "fpr": [20, 41, 68, 79], "fpr_lr": [20, 41, 68, 79], "fpr_svc": [20, 41, 68, 79], "frac": [13, 18, 20, 21, 25, 28, 29, 33, 39, 41, 42, 46, 49, 50, 55, 58, 59, 68, 69, 72, 77, 79, 80, 84, 87, 88], "fractal": [24, 45, 54, 83], "fraction": [17, 20, 27, 37, 41, 48, 57, 68, 76, 79, 86], "fragasso": 67, "fragment": 97, "frame": [16, 17, 20, 21, 24, 30, 31, 36, 37, 41, 42, 45, 54, 61, 75, 76, 79, 80, 83, 89, 90, 91, 92, 102], "framework": [19, 40, 72, 78], "franco": 67, "frank": 67, "fraud": [13, 20, 21, 25, 30, 33, 41, 42, 46, 51, 55, 60, 68, 69, 72, 79, 80, 84, 89, 100], "fraudul": [13, 20, 33, 41, 68, 72, 79, 91, 100], "frederick": [1, 103], "free": [0, 5, 17, 21, 28, 31, 37, 42, 49, 58, 61, 76, 80, 87, 90, 92], "freedom": [0, 93], "french": [16, 28, 36, 49, 58, 75, 87], "freq": [30, 51, 60, 89, 102], "frequenc": [17, 28, 30, 31, 37, 49, 58, 61, 76, 87, 89, 90, 95, 102], "frequent": [13, 16, 27, 28, 31, 33, 36, 48, 49, 57, 58, 61, 72, 75, 86, 87, 90], "fresh": [27, 28, 48, 49, 58, 67, 86, 87], "fri": [12, 30, 51, 60, 89], "fridai": [14, 32, 103], "fridg": 67, "friend": [13, 14, 20, 23, 26, 27, 33, 44, 47, 48, 53, 57, 67, 72, 73, 79, 82, 85, 86, 92, 95, 103], "from": [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "from_block": [31, 61, 90], "from_estim": [20, 41, 68, 79, 100], "front": 103, "frozen": 93, "fruit": [28, 49, 58, 87], "frustrat": [4, 6, 19, 40, 78], "fu": 1, "fulci": 67, "full": [19, 22, 29, 30, 31, 38, 40, 43, 50, 51, 52, 59, 61, 63, 78, 81, 88, 89, 90, 103], "full_pip": 65, "fullbath": [21, 23, 42, 44, 53, 69, 80, 82, 91], "fulli": [26, 47, 56, 69, 85], "fun": [20, 28, 29, 49, 50, 58, 59, 67, 79, 87, 88], "func": [8, 17, 18, 21, 37, 39, 42, 61, 69, 76, 77, 80, 91], "function": [2, 12, 13, 14, 15, 17, 19, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 64, 68, 71, 72, 73, 74, 76, 78, 79, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 97, 99, 100, 102], "functiontransform": [17, 31, 37, 61, 65, 76, 90], "fund": 93, "fundament": [1, 2, 9, 11, 16, 18, 19, 21, 24, 29, 31, 36, 39, 40, 42, 45, 50, 54, 59, 61, 69, 75, 77, 78, 80, 83, 88, 90, 103], "funni": [12, 22, 43, 67, 71, 81, 93], "furnish": 0, "furnitur": 95, "further": [20, 22, 24, 25, 28, 31, 41, 45, 46, 49, 50, 54, 55, 58, 59, 61, 63, 79, 81, 83, 84, 87, 88, 90, 92, 97, 99, 100, 103], "furthermor": 91, "fusion": 65, "futur": [11, 14, 19, 21, 31, 32, 34, 36, 40, 42, 61, 68, 73, 75, 78, 80, 90, 95, 99, 102], "futurewarn": [21, 23, 36, 42, 44, 52, 53, 68, 69, 73, 75, 80, 82, 94], "fuyi": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 103], "fyi": [31, 61, 90], "g": [6, 7, 8, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 68, 69, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 99, 102], "g26r0dcx4b35vf3nk31216hc0000gr": [75, 82], "gain": [6, 11, 13, 20, 22, 23, 33, 41, 43, 44, 52, 53, 72, 79, 81, 82, 100], "game": [13, 23, 28, 33, 44, 49, 53, 58, 72, 82, 87], "gamma": [18, 19, 22, 39, 40, 43, 52, 64, 77, 78, 81, 91, 97, 99], "gamma_log": [15, 35, 64, 74, 97], "gamma_widget": [15, 35, 64, 74, 97], "gap": [14, 30, 31, 34, 51, 60, 61, 63, 73, 89, 90, 91, 95, 97], "garagearea": [21, 23, 42, 44, 53, 69, 80, 82, 91], "garagecar": [21, 23, 42, 44, 53, 69, 80, 82, 91], "garagecond": [21, 23, 42, 44, 53, 69, 80, 82, 91], "garagefinish": [21, 23, 42, 44, 53, 80, 82, 91], "garagefinish_fin": [21, 42, 80], "garagefinish_miss": [21, 42, 80], "garagefinish_rfn": [21, 42, 80], "garagefinish_unf": [21, 42, 80], "garagequ": [21, 23, 42, 44, 53, 69, 80, 82, 91], "garagetyp": [21, 23, 42, 44, 53, 80, 82, 91], "garagetype_2typ": [21, 42, 80], "garagetype_attchd": [21, 42, 80], "garagetype_bas": [21, 42, 80], "garagetype_builtin": [21, 42, 80], "garagetype_carport": [21, 42, 80], "garagetype_detchd": [21, 42, 80], "garagetype_miss": [21, 42, 80], "garageyrblt": [21, 23, 42, 44, 53, 69, 80, 82, 91], "garlic": [25, 84], "gaudenzi": 67, "gaurav": [1, 103], "gauss": [28, 49, 87], "gaussian": [26, 47, 85], "gaussianmixtur": [26, 47, 56, 70, 85], "gave": [27, 30, 48, 57, 65, 67, 86, 89], "gbr": 8, "gca": [25, 26, 31, 46, 47, 55, 61, 84, 85, 90], "gd": [12, 21, 23, 32, 42, 44, 53, 69, 71, 80, 82, 91], "gdprv": [21, 23, 42, 44, 53, 69, 80, 82, 91], "gdwo": [21, 23, 42, 44, 53, 69, 80, 82, 91], "gelbart": [0, 1, 28, 33, 49, 58, 72, 87, 99], "gender": [12, 17, 20, 28, 30, 31, 32, 41, 49, 51, 58, 60, 61, 71, 76, 79, 87, 89, 90, 100], "gender_femal": [31, 61, 90], "gender_mal": [31, 61, 90], "gener": [7, 9, 12, 13, 16, 17, 19, 20, 21, 23, 26, 28, 29, 30, 31, 33, 36, 37, 40, 41, 42, 44, 47, 49, 50, 51, 53, 56, 58, 60, 61, 63, 65, 67, 72, 75, 76, 78, 79, 80, 82, 85, 87, 88, 89, 90, 91, 92, 94, 95, 97, 99, 100, 102, 103], "genet": [24, 45, 54, 83], "genom": [24, 45, 52, 60, 83], "genr": [27, 48, 57, 86], "gensim": [28, 49, 58, 87], "gentl": 11, "geog": [1, 103], "geograph": [18, 39, 77, 92], "geometr": [13, 72], "georg": [28, 49, 58, 87], "geq": [18, 39, 77], "ger": 8, "german": [28, 49, 58, 87], "get": [1, 4, 5, 6, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 99, 100, 101, 102, 103], "get_avg_word_length": 93, "get_cluster_imag": 70, "get_cmap": [16, 36, 75], "get_depth": [63, 97], "get_dummi": [16, 36, 75], "get_featur": [29, 50, 59, 64, 70, 88], "get_feature_nam": 38, "get_feature_names_out": [16, 17, 20, 21, 22, 23, 24, 28, 30, 31, 36, 37, 38, 41, 42, 43, 44, 45, 49, 51, 52, 53, 54, 58, 60, 61, 65, 66, 67, 69, 75, 76, 79, 80, 81, 82, 83, 87, 89, 90, 91, 93, 100, 102], "get_length_in_word": 93, "get_lr_data_per_us": [27, 48, 57, 86], "get_param": [19, 64], "get_permutation_import": [23, 44, 53, 82], "get_relative_length": 93, "get_season": [30, 89], "get_senti": 93, "get_stat": [27, 48, 57, 86], "get_tag": 65, "get_text": 50, "get_user_profil": [27, 48, 57, 86], "getattr": [31, 61, 90], "ghassemi": [1, 103], "gif": [25, 26, 46, 47, 84, 85], "gift": 93, "gigaword": [28, 49, 87], "gini": [13, 23, 33, 44, 53, 72, 82, 91], "git": [3, 8, 12, 32], "github": [0, 1, 7, 9, 10, 12, 16, 17, 19, 20, 21, 22, 23, 24, 29, 32, 36, 37, 40, 41, 42, 43, 44, 45, 50, 52, 53, 55, 59, 62, 63, 64, 65, 67, 68, 70, 71, 75, 76, 78, 79, 80, 81, 82, 83, 88, 91, 92, 93, 99, 100], "githubusercont": 8, "gitlf": [20, 41, 68, 79], "giulia": [0, 1, 50, 103], "give": [0, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 67, 68, 69, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 96, 97, 100], "given": [0, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 100, 102], "gladwel": [25, 46, 84], "glass": 91, "glob": [12, 29, 32, 50, 59, 64, 70, 71, 88], "global": [16, 20, 22, 28, 36, 41, 43, 46, 49, 52, 58, 68, 75, 79, 81, 84, 87, 95], "global_skip_valid": [61, 65], "glove": [11, 28, 49, 58, 87], "glq": [21, 23, 42, 44, 53, 69, 80, 82, 91], "gmail": [12, 25, 32, 46, 55, 71, 84], "go": [1, 5, 7, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 60, 61, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 102], "goal": [2, 11, 15, 16, 19, 20, 25, 26, 27, 28, 35, 36, 40, 41, 46, 47, 48, 49, 55, 57, 68, 74, 75, 78, 79, 84, 85, 86, 87, 92, 93, 99, 101, 102], "goe": [2, 12, 14, 15, 17, 20, 22, 23, 26, 27, 29, 32, 34, 35, 37, 41, 44, 47, 48, 50, 53, 56, 57, 59, 67, 68, 73, 74, 76, 79, 81, 82, 85, 86, 88, 91, 92], "gold": 8, "goldcoast": [30, 89], "golden": [15, 38, 63, 66, 67, 74, 92, 95, 97], "good": [9, 10, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102], "good_serv": 65, "goodarzvand": [1, 103], "googl": [1, 4, 12, 13, 22, 25, 28, 32, 33, 43, 46, 49, 55, 58, 68, 71, 72, 81, 82, 83, 84, 87, 91, 93], "google_news_vector": [28, 49, 58, 87], "gore": 67, "gorgeou": 67, "gori": 67, "got": [15, 18, 19, 20, 21, 29, 35, 38, 39, 40, 42, 50, 59, 61, 66, 67, 69, 74, 77, 78, 79, 80, 88], "gotten": [31, 61, 90, 101], "gov": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82], "govern": [28, 49, 58, 87, 103], "gpe": [28, 49, 58, 87], "gpt": [27, 28, 48, 49, 57, 58, 86, 87], "gpu": [22, 28, 29, 43, 49, 50, 52, 58, 59, 81, 87, 88], "grad": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "grade": [1, 3, 7, 12, 14, 16, 17, 19, 34, 37, 40, 52, 63, 67, 71, 73, 76, 78, 91, 95, 97, 98, 99, 100, 101, 102], "grader": 6, "grades_df": 95, "gradescop": [1, 6, 12, 13, 32, 103], "gradient": [61, 92, 95], "gradientboostingclassifi": [22, 43, 52, 81], "gradientboostingregressor": [22, 43, 52, 81, 91], "gradientexplain": [23, 44, 53, 82], "grading_concern": 6, "graduat": [29, 50, 59, 88], "grai": [29, 50, 59, 88], "grain": [18, 23, 39, 44, 53, 77, 82], "gram": [28, 49, 87], "grammat": [28, 49, 58, 87], "grandma": [24, 45, 54, 83], "grandmoth": [20, 79, 92], "grant": 0, "grant_macewan": [28, 49, 87], "granular": [26, 47, 56, 85], "graph": [1, 29, 30, 50, 51, 59, 60, 64, 70, 88, 89], "graphic": [29, 50, 59, 88], "graphic_design": [28, 49, 58, 87], "graphviz": [13, 33, 72, 96], "grasp": [11, 95], "grass": 67, "grave": 67, "grayscal": [29, 50, 59, 88], "great": [12, 15, 17, 18, 23, 24, 28, 29, 30, 32, 34, 35, 37, 39, 44, 45, 49, 50, 51, 53, 54, 58, 59, 65, 67, 71, 72, 74, 76, 77, 82, 83, 87, 88, 89, 91, 93], "greater": [10, 24, 25, 45, 46, 54, 55, 83, 84], "greater_is_bett": [21, 42, 69, 80], "greedili": [26, 47, 56, 85], "green": [15, 19, 25, 35, 40, 46, 55, 67, 74, 78, 84, 91, 94], "grei": 103, "grid": [18, 21, 30, 31, 39, 42, 61, 69, 77, 80, 89, 90, 95, 99, 102], "grid_result": 91, "grid_search": [19, 40, 78, 91, 99], "gridsearchcv": [15, 22, 23, 35, 43, 44, 52, 53, 74, 81, 82, 99, 101], "gridsearchcvifittedgridsearchcv": [19, 40, 78], "gridspec_kw": 70, "grinberg": 92, "grip": [28, 49, 58, 87], "grlivarea": [21, 23, 42, 44, 53, 69, 80, 82, 91], "groak": [28, 49, 58, 87], "groceri": [29, 50, 59, 88, 93], "groin": [29, 50, 59, 88], "ground": [14, 24, 26, 27, 34, 39, 45, 47, 48, 54, 56, 57, 67, 73, 83, 85, 86, 103], "ground_truth_categori": [20, 79, 92], "group": [7, 11, 13, 15, 16, 17, 18, 22, 24, 33, 35, 39, 43, 52, 54, 64, 67, 72, 74, 76, 77, 81, 83, 95, 97, 98, 101], "groupbi": [30, 89, 102], "grow": [19, 22, 24, 40, 43, 45, 52, 54, 78, 81, 83], "grow_polici": [22, 43, 52, 81], "growth": [30, 31, 51, 60, 61, 89, 90], "groyn": [29, 50, 59, 88], "grv": [21, 23, 42, 80], "gsc": 91, "gt": [17, 18, 19, 20, 21, 22, 37, 39, 40, 41, 42, 43, 52, 67, 76, 77, 78, 79, 80, 81], "gtl": [23, 44, 53, 82], "gtoti": [33, 37, 49], "guam": 53, "guarante": [19, 20, 22, 25, 29, 40, 41, 43, 46, 50, 52, 54, 55, 57, 59, 68, 78, 79, 81, 84, 88], "guenon": [29, 50, 59, 88], "guess": [15, 16, 28, 35, 36, 49, 58, 74, 75, 87, 93], "gui": 67, "guid": [1, 7, 9, 12, 24, 29, 32, 45, 50, 54, 59, 83, 88, 92, 103], "guidanc": [23, 44, 53, 82], "guidelin": [16, 23, 24, 44, 45, 53, 54, 82, 83, 92], "guido": 1, "gun": 67, "h": [20, 22, 23, 25, 28, 29, 41, 43, 44, 46, 49, 50, 52, 53, 55, 58, 59, 61, 63, 79, 81, 82, 84, 87, 88, 90, 92, 93, 100], "h1": 59, "h2": 59, "ha": [1, 2, 5, 6, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 68, 69, 72, 73, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 97, 100, 101, 102, 103], "hab": [28, 49, 87], "habit": [17, 37, 76, 91, 92], "hacki": [29, 50, 59, 88, 94], "had": [12, 16, 17, 18, 20, 24, 28, 29, 30, 31, 32, 36, 37, 39, 49, 50, 51, 58, 59, 60, 61, 67, 71, 75, 76, 77, 79, 86, 87, 88, 89, 90, 92], "hadn": [28, 31, 49, 58, 61, 87, 90], "haidilao": 65, "hal": 1, "half": [1, 6, 12, 13, 18, 24, 26, 32, 33, 39, 45, 47, 54, 56, 67, 72, 77, 83, 85], "halfbath": [21, 23, 42, 44, 53, 69, 80, 82, 91], "halt": 61, "halvingrandomsearchcv": [19, 40, 78], "halvingrandomsearchcvifittedhalvingrandomsearchcv": [19, 40, 78], "ham": [12, 32, 71], "hand": [4, 9, 11, 20, 27, 41, 48, 65, 67, 68, 79, 86, 100, 103], "handi": [20, 41, 68, 79], "handl": [11, 22, 23, 26, 31, 43, 44, 47, 52, 53, 56, 61, 63, 65, 67, 81, 82, 85, 90, 92, 93, 94, 95, 97], "handle_unknow": [17, 37, 76], "handle_unknown": [16, 17, 19, 20, 21, 22, 23, 30, 31, 36, 37, 40, 41, 42, 43, 44, 52, 53, 61, 65, 69, 75, 76, 78, 79, 80, 81, 82, 89, 90, 91, 95, 99, 100, 101, 102], "handler": [20, 23, 41, 44, 79, 82], "handrail": [29, 50, 59, 88], "handwritten": [20, 79, 91], "hang": [20, 79], "happen": [4, 6, 12, 15, 17, 19, 22, 23, 24, 27, 30, 31, 35, 37, 40, 43, 44, 45, 48, 51, 52, 53, 54, 57, 60, 61, 65, 67, 68, 69, 71, 74, 76, 78, 81, 82, 83, 86, 89, 90, 91, 95, 102, 103], "happi": [20, 25, 31, 41, 46, 55, 61, 63, 65, 68, 79, 84, 90], "happier": [92, 103], "happydb": [20, 79, 92], "hard": [8, 12, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 32, 34, 35, 36, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 54, 55, 56, 57, 59, 67, 68, 69, 71, 73, 74, 75, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 91, 92, 93, 95, 101], "hardi": [1, 103], "hardli": [27, 48, 57, 86], "hardwar": [29, 50, 59, 88], "harmon": [20, 41, 68, 79], "harri": [1, 28, 49, 58, 87, 103], "has_cupi": 93, "has_emoji": 93, "has_nan_error": 65, "has_rais": 93, "hasattr": 61, "hasn": [4, 27, 28, 31, 48, 49, 57, 58, 86, 87, 90], "hassl": [8, 23, 30, 44, 51, 53, 60, 82, 89], "hat": [18, 21, 22, 39, 42, 52, 54, 69, 77, 80, 81], "have": [0, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103], "haven": [14, 28, 31, 34, 49, 58, 61, 65, 73, 87, 90, 91, 92, 95], "haylei": [33, 72], "hazard": 11, "hc_truncation_toy_demo": [26, 47, 56, 85], "hdbscan": [26, 47, 85], "he": [14, 17, 28, 34, 37, 49, 58, 67, 73, 76, 87], "head": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 95, 98, 99, 100, 101, 102], "header": 92, "headlin": [28, 49, 87, 91], "health": [28, 49, 58, 87], "healthcar": [23, 44, 53, 82], "healthi": [28, 49, 58, 87, 91], "heard": [14, 34, 73], "heart": [13, 33, 67, 72, 93, 101], "heart_df": 101, "heartdiseas": 101, "hearti": 65, "heat": [19, 21, 23, 40, 42, 44, 53, 78, 80, 82, 91, 99], "heating_floor": [21, 42, 80], "heating_gasa": [21, 42, 80], "heating_gasw": [21, 42, 80], "heating_grav": [21, 42, 80], "heating_othw": [21, 23, 42, 53, 80, 82], "heating_wal": [21, 42, 80], "heatingqc": [21, 23, 42, 44, 53, 69, 80, 82, 91], "heatmap": [23, 44, 53, 58, 82], "heavi": [22, 43, 52, 81, 93], "heavili": [27, 29, 30, 48, 50, 51, 57, 59, 60, 67, 86, 88, 89, 100], "heeren": [28, 49, 58, 87], "hei": [66, 67], "height": [13, 14, 20, 28, 33, 34, 41, 49, 58, 64, 72, 73, 79, 87, 93, 96], "helicopt": 67, "hell": 93, "help": [3, 7, 10, 12, 14, 16, 19, 20, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 40, 41, 44, 46, 47, 48, 49, 51, 53, 55, 56, 57, 58, 61, 65, 67, 68, 71, 73, 75, 76, 78, 79, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 96, 97, 98, 102, 103], "henc": [5, 20, 21, 23, 25, 41, 42, 44, 46, 53, 55, 68, 79, 80, 82, 84], "her": [12, 27, 28, 32, 48, 49, 57, 58, 67, 71, 86, 87], "here": [1, 4, 5, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 102, 103], "herebi": 0, "herself": [28, 49, 58, 87, 93], "herta": [15, 74], "hesist": 91, "hesit": 91, "hessian": 61, "hessian_": 61, "heurist": [13, 19, 33, 40, 72, 78], "hi": [28, 49, 58, 67, 87, 97], "hidden": [24, 28, 29, 45, 49, 50, 54, 58, 83, 87, 88, 91], "hide": [8, 29, 50, 59, 67, 88], "hier_label": [26, 47, 56, 85], "hier_labels1": [26, 47, 56, 85], "hier_labels2": [26, 47, 56, 85], "hierarch": [11, 95], "hierarchi": [13, 26, 33, 47, 56, 72, 85], "high": [6, 11, 14, 15, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 65, 68, 69, 73, 74, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92], "high_corr": [23, 44, 53, 82], "higher": [13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 27, 31, 33, 34, 35, 39, 41, 42, 43, 44, 45, 46, 48, 52, 53, 54, 55, 57, 61, 68, 69, 72, 73, 74, 77, 79, 80, 81, 82, 83, 84, 86, 90, 91, 92, 97, 99, 100], "highest": [22, 23, 27, 28, 29, 38, 43, 44, 48, 49, 50, 52, 53, 57, 58, 59, 66, 67, 81, 82, 86, 87, 88, 91, 94, 97, 100], "highland": 93, "highli": [1, 10, 16, 23, 27, 36, 38, 44, 48, 53, 57, 66, 67, 75, 82, 86], "highlight": [4, 29, 50, 59, 88, 91, 95], "highwai": [18, 39, 77], "him": [28, 49, 58, 67, 87], "himself": [28, 49, 58, 67, 87], "hinder": 103, "hindi": [16, 36, 75], "hint": [23, 44, 53, 82, 97], "hist": [16, 19, 21, 24, 31, 36, 40, 42, 45, 54, 61, 65, 69, 75, 78, 80, 83, 90], "histgradientboostingclassifi": [22, 43, 52, 65, 81], "histgradientboostingregressor": [22, 43, 52, 81], "histogram": [31, 61, 90], "histor": 95, "histori": [18, 27, 30, 39, 48, 51, 57, 60, 77, 86, 89, 103], "hit": [12, 19, 32, 40, 71, 78], "hitter": 93, "hl": [21, 23, 42, 44, 80, 82, 91], "hmid": [20, 79, 92], "hmmm": [31, 90], "hockei": [28, 49, 58, 87], "hold": [65, 67, 91, 92, 99], "holder": 0, "holdout": [20, 41, 79], "holi": 91, "holidai": [27, 48, 57, 86, 103], "home": [13, 18, 20, 29, 33, 39, 50, 58, 59, 61, 64, 65, 72, 77, 79, 88, 92], "homemak": [28, 49, 58, 87], "homepag": 1, "homework": [1, 3, 4, 6, 8, 10, 15, 19, 28, 40, 49, 55, 74, 77, 78, 87, 92, 95, 103], "honest": 91, "honour": 103, "hood": [14, 34, 65, 73, 92], "hook": 67, "hope": [14, 34, 67, 73, 91, 92], "hopefulli": [92, 99], "hopeless": [24, 45, 54, 83], "hopelessli": [15, 35, 74], "horizont": [13, 17, 33, 37, 65, 72, 76], "horror": 67, "host": [5, 31, 61, 90, 92], "hot": [14, 17, 23, 34, 37, 44, 51, 53, 60, 65, 67, 73, 76, 82, 95, 102], "hound": [12, 29, 32, 50, 59, 71, 88], "hour": [1, 4, 10, 12, 20, 22, 23, 24, 27, 30, 41, 43, 44, 45, 48, 51, 52, 53, 54, 57, 60, 67, 79, 81, 82, 83, 86, 89, 92, 95, 100, 103], "hourli": [31, 61, 90, 95], "hous": [21, 23, 24, 31, 33, 42, 44, 45, 53, 54, 61, 63, 69, 80, 82, 83, 90, 91, 97], "houseag": [18, 39, 77], "household": [16, 18, 24, 36, 39, 45, 54, 75, 76, 77, 83, 98], "housestyl": [21, 23, 42, 44, 53, 69, 80, 82, 91], "housestyle_1": [21, 42, 80], "housestyle_1stori": [21, 42, 80], "housestyle_2": [21, 42, 80], "housestyle_2stori": [21, 42, 80], "housestyle_sfoy": [21, 42, 80], "housestyle_slvl": [21, 42, 80], "housewif": [28, 49, 58, 87], "housing_df": [13, 16, 24, 36, 45, 54, 63, 72, 75, 76, 83, 97, 98], "housing_median_ag": [16, 24, 36, 45, 54, 75, 76, 83, 98], "houston": 93, "how": [0, 3, 8, 10, 11, 12, 17, 19, 20, 21, 25, 27, 28, 29, 30, 31, 32, 37, 38, 40, 41, 42, 46, 48, 49, 50, 51, 57, 59, 60, 61, 63, 64, 67, 68, 69, 70, 71, 76, 78, 79, 80, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103], "howard": [25, 46, 84], "howev": [2, 8, 16, 17, 20, 21, 23, 25, 27, 30, 31, 36, 37, 41, 42, 44, 46, 48, 51, 53, 55, 60, 61, 64, 67, 75, 76, 79, 80, 82, 84, 86, 89, 90, 92, 94, 97, 100], "hsjcy": [31, 90], "hspace": 70, "hstack": [30, 51, 60, 89], "html": [7, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 50, 52, 53, 55, 59, 61, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 88, 90, 91, 92, 93, 96, 98, 100], "htrz": [52, 53, 54, 55, 56, 61, 103], "http": [0, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 79, 80, 81, 88, 89, 90, 91, 92, 93, 100, 103], "hue": 54, "hug": [27, 48, 86], "huge": [17, 21, 28, 29, 30, 31, 37, 42, 49, 50, 51, 59, 60, 61, 69, 76, 80, 87, 88, 89, 90, 102], "human": [0, 12, 15, 16, 17, 18, 19, 20, 23, 24, 25, 28, 29, 32, 36, 37, 39, 40, 41, 44, 45, 46, 49, 50, 53, 54, 58, 59, 67, 71, 74, 75, 76, 77, 78, 79, 82, 83, 84, 87, 88, 100], "humidity3pm": [30, 89, 102], "humidity3pm_lag1": [30, 89, 102], "humidity9am": [30, 89, 102], "hummu": [25, 28, 49, 58, 84, 87], "humour": [1, 28, 49, 58, 87], "hundr": [18, 39, 77], "hungri": 65, "hurrai": 101, "hurrican": [12, 71], "husband": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82], "hussar": [12, 29, 32, 50, 59, 71, 88], "hw": [12, 16, 20, 25, 71], "hw1": [1, 4, 13, 14, 16, 17, 96], "hw2": [1, 14, 15, 16, 36, 74, 75, 99], "hw3": [1, 16, 17, 18], "hw4": 1, "hw5": [1, 52, 53, 54], "hw6": 1, "hw6a": 7, "hw6b": 7, "hw7": 1, "hw8": 1, "hybrid": [27, 48, 57, 86], "hyper": 91, "hyperband": [19, 40, 78], "hyperopt": [19, 40, 78], "hyperparamet": [1, 14, 20, 26, 27, 28, 29, 34, 38, 41, 47, 48, 49, 50, 57, 58, 59, 64, 66, 67, 68, 73, 79, 85, 86, 87, 88, 91, 92, 99], "hyperparameter_": 91, "hyperparamt": [14, 19, 31, 34, 40, 61, 73, 78, 90], "hyperparlan": [18, 39, 77], "hyperplan": [18, 39, 77], "hypothesi": [28, 31, 49, 58, 61, 87, 90, 92], "hypothet": [18, 25, 39, 46, 77, 84], "i": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 18, 21, 26, 29, 30, 31, 33, 35, 38, 39, 42, 47, 50, 51, 56, 59, 60, 61, 63, 64, 65, 66, 67, 69, 70, 72, 74, 77, 80, 85, 88, 89, 90, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "i1": [22, 52, 81], "i2": [22, 52, 81], "ia": 93, "ibm": 93, "ic": [28, 49, 58, 87], "icc": [1, 103], "iclick": 1, "id": [12, 13, 21, 23, 27, 32, 42, 44, 48, 53, 57, 61, 63, 69, 71, 72, 80, 82, 86, 91, 97], "idea": [8, 13, 14, 16, 19, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 40, 44, 46, 47, 48, 49, 50, 51, 53, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 72, 73, 75, 78, 82, 84, 85, 86, 87, 88, 89, 90, 92, 95, 97, 102], "ideal": [4, 16, 20, 22, 24, 27, 31, 41, 43, 45, 48, 52, 54, 57, 61, 65, 68, 79, 81, 83, 86, 90, 92], "ident": [28, 29, 49, 50, 58, 59, 64, 70, 87, 88, 93], "identif": [12, 32, 71, 93], "identifi": [11, 13, 14, 15, 16, 19, 20, 21, 25, 26, 28, 29, 30, 33, 34, 36, 38, 40, 41, 42, 46, 47, 49, 50, 53, 55, 56, 58, 59, 61, 63, 66, 67, 68, 69, 72, 73, 74, 75, 78, 79, 80, 84, 85, 87, 88, 89, 91, 92, 95, 100, 102], "idf": [17, 37, 76], "idli": [28, 49, 87], "idx": [29, 50, 55, 59, 64, 88], "idxmax": [15, 35, 63, 66, 67, 74], "if_binari": [17, 20, 22, 23, 37, 41, 43, 44, 52, 53, 65, 76, 79, 81, 82, 95, 98, 100, 101], "ifram": [14, 20, 34, 41, 73, 79], "igloo": [28, 49, 58, 87], "ignor": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 52, 53, 58, 61, 65, 68, 69, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 87, 89, 90, 91, 95, 99, 100, 101, 102], "ignore_index": 8, "ii": [20, 41, 68, 79], "iii": 1, "ij": [18, 27, 38, 39, 48, 57, 66, 67, 77, 86], "ik": [22, 52, 81], "ill": 103, "illus": [20, 41, 79, 100], "illustr": [26, 30, 47, 51, 54, 60, 85, 89], "iloc": [8, 13, 14, 15, 16, 17, 22, 23, 28, 30, 33, 34, 35, 36, 37, 38, 43, 44, 49, 52, 53, 54, 58, 61, 66, 67, 72, 73, 74, 75, 76, 81, 82, 87, 89, 93, 96, 101, 102], "im": 93, "imag": [7, 11, 14, 20, 23, 24, 25, 26, 30, 34, 36, 41, 44, 45, 46, 47, 51, 53, 54, 55, 56, 60, 67, 68, 73, 79, 82, 83, 84, 85, 89, 91, 95, 100], "image_dataset": [29, 50, 59, 64, 70, 88], "image_datasets_bw": [29, 50, 59, 88], "image_fil": 64, "image_s": [29, 50, 59, 64, 70, 88], "image_shap": 70, "imagefold": [29, 50, 59, 64, 70, 88], "imagenet": [50, 94], "imagenet1k_v1": [29, 50, 59, 64, 70, 88], "imagenet_class": [12, 29, 32, 50, 59, 71, 88], "imagin": [12, 13, 14, 16, 18, 20, 23, 24, 25, 28, 31, 32, 33, 34, 36, 39, 41, 44, 45, 49, 53, 54, 58, 61, 68, 71, 72, 73, 75, 77, 79, 82, 83, 84, 87, 90, 91, 92, 95, 96, 100], "imaginari": [14, 28, 34, 49, 58, 73, 87], "imbal": [25, 31, 46, 55, 68, 84, 90, 100], "imbalanc": [20, 21, 41, 42, 68, 69, 79, 80, 94], "imblearn": [20, 79], "imdb": [38, 66, 67], "imdb_df": [38, 66, 67], "imdb_mast": [38, 66, 67], "img": [12, 29, 32, 50, 59, 64, 70, 71, 88], "img_classifi": [12, 32, 71], "img_ind": 64, "img_path": [12, 32, 71], "img_shap": 70, "img_t": [29, 50, 59, 88], "immedi": [23, 27, 44, 48, 53, 57, 61, 65, 82, 86, 103], "imp": [16, 30, 36, 51, 60, 75, 76, 89], "impact": [7, 11, 17, 18, 22, 23, 26, 30, 37, 39, 43, 44, 47, 51, 53, 56, 60, 76, 77, 81, 82, 85, 89, 91, 97, 102, 103], "implement": [2, 4, 12, 16, 20, 21, 22, 24, 26, 27, 28, 31, 32, 36, 42, 43, 45, 47, 48, 49, 52, 54, 56, 57, 58, 59, 61, 71, 75, 79, 80, 81, 83, 85, 86, 87, 90, 91, 92, 94], "impli": [0, 31, 61, 90], "implic": [11, 16, 36, 75, 92, 95], "implicit": [28, 49, 87], "import": [8, 11, 38, 54, 56, 57, 58, 59, 60, 61, 69, 70, 94, 98, 99, 100, 101, 103], "importance_typ": [22, 43, 52, 81], "importances_mean": [23, 44, 53, 82], "impos": [16, 36, 75], "imposs": [25, 46, 55, 84], "impress": [23, 44, 53, 82], "improv": [11, 19, 20, 21, 22, 24, 25, 26, 27, 30, 31, 40, 41, 42, 43, 45, 46, 47, 48, 51, 52, 54, 55, 56, 57, 60, 61, 63, 65, 68, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 95, 99, 103], "impur": [13, 22, 33, 43, 52, 63, 72, 81], "imput": [14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 31, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 51, 52, 53, 54, 55, 60, 61, 65, 69, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 89, 90, 91, 92, 93, 95, 98, 99, 100, 101, 102], "imread": [29, 50, 59, 88], "imshow": [12, 29, 32, 50, 58, 59, 64, 70, 71, 88], "inabl": 32, "inbox": [14, 34, 73], "inc": [23, 28, 44, 49, 53, 58, 82, 87], "incept": [27, 29, 48, 50, 57, 59, 86, 88], "inception": [29, 50, 59, 88], "incl": [21, 42, 69, 80], "includ": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 61, 64, 68, 69, 72, 75, 76, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 97, 98, 99, 100, 101, 102, 103], "include_bia": [24, 30, 45, 51, 54, 60, 83, 89], "incom": [14, 18, 20, 22, 23, 34, 39, 41, 43, 44, 52, 53, 73, 77, 79, 81, 82, 100], "incomplet": [31, 90], "inconsist": [17, 37, 76], "incorpor": [19, 21, 24, 31, 40, 42, 45, 54, 61, 69, 78, 80, 83, 90, 92, 95], "incorrect": [31, 61, 90, 91], "incorrectli": [12, 20, 32, 41, 68, 71, 79], "increament": 92, "increas": [8, 14, 15, 17, 18, 22, 23, 24, 25, 26, 29, 34, 35, 37, 38, 39, 43, 44, 45, 46, 47, 50, 52, 53, 54, 55, 56, 59, 63, 66, 67, 73, 74, 76, 77, 81, 82, 83, 84, 85, 88, 97, 99], "increasingli": [12, 32, 71], "incred": [29, 50, 59, 88], "incredibli": 67, "increment": 92, "ind": 70, "inde": [23, 44, 53, 82], "independ": [8, 9, 13, 19, 21, 22, 24, 30, 32, 33, 40, 42, 43, 45, 51, 52, 54, 60, 69, 72, 78, 80, 81, 83, 89, 103], "index": [12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 93, 97, 100, 101, 102], "index_col": [8, 15, 16, 19, 20, 27, 36, 40, 48, 57, 74, 75, 78, 79, 86, 92, 99], "india": [28, 49, 87], "indian": [20, 41, 65, 79], "indian_liver_pati": [12, 32, 71], "indic": [0, 17, 25, 27, 28, 29, 30, 31, 37, 38, 46, 48, 49, 50, 51, 55, 57, 58, 59, 61, 65, 66, 67, 70, 76, 84, 86, 87, 88, 89, 90], "indirectli": 91, "individu": [22, 23, 25, 27, 28, 31, 43, 44, 46, 48, 52, 53, 55, 57, 61, 65, 81, 82, 84, 86, 87, 90, 92, 101, 103], "industri": [22, 24, 28, 29, 43, 45, 49, 50, 52, 54, 58, 59, 81, 83, 87, 88], "inept": 67, "ineptli": 67, "inequ": [20, 41, 79, 100], "inertia": 55, "inertia_": [25, 46, 55, 84], "inertia_valu": [25, 46, 55, 84], "inf": [15, 31, 35, 61, 70, 74, 90], "infeas": [19, 40, 78], "infer": [13, 28, 29, 30, 49, 50, 51, 58, 59, 60, 72, 87, 88, 89, 92, 96], "infin": [15, 35, 74, 91], "infinit": [19, 40, 78], "inflamm": 9, "inflat": [23, 44, 53, 82], "inflect": [25, 28, 46, 49, 55, 58, 84, 87], "influenc": [13, 14, 19, 23, 25, 27, 31, 33, 34, 38, 40, 44, 46, 48, 53, 55, 57, 61, 72, 73, 78, 82, 84, 86, 90, 97], "info": [1, 3, 8, 16, 17, 20, 21, 24, 28, 30, 31, 36, 37, 41, 42, 45, 49, 54, 58, 61, 68, 69, 75, 76, 79, 80, 83, 87, 89, 90, 97, 101, 102], "infom": [28, 49, 58, 87], "infor_m": [28, 49, 58, 87], "inform": [1, 4, 7, 10, 12, 13, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 33, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 54, 55, 56, 57, 58, 59, 61, 64, 68, 72, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 97, 100, 101, 102, 103], "informa_t": [28, 49, 58, 87], "informaion": [28, 49, 58, 87], "informaiton": [28, 49, 58, 87], "informationabout": [28, 49, 58, 87], "informationon": [28, 49, 58, 87], "ingrid": 67, "inhabit": 103, "inher": [20, 30, 31, 33, 41, 51, 60, 61, 79, 89, 90, 100], "initi": [26, 29, 47, 50, 56, 59, 64, 70, 85, 88, 93], "initial_point": 61, "initj": [23, 44, 53, 82], "inject": [24, 27, 45, 48, 54, 57, 83, 86, 95], "ink": 91, "inland": [16, 24, 36, 45, 54, 75, 76, 83, 98], "inlin": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 56, 57, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 86, 96, 97, 99, 100, 101], "inner": [17, 19, 28, 37, 40, 49, 58, 76, 78, 87], "inplac": [8, 12, 13, 19, 32, 38, 40, 71, 72, 78], "input": [8, 13, 16, 18, 22, 23, 26, 28, 29, 30, 33, 36, 39, 43, 44, 47, 49, 50, 51, 52, 53, 59, 61, 64, 65, 70, 72, 75, 77, 81, 82, 85, 87, 88, 89, 92, 93, 95, 102], "input_img": [29, 50, 59, 88], "input_nam": [61, 65], "input_tag": 65, "inputs_bw": [29, 50, 59, 88], "insid": [9, 17, 20, 37, 41, 67, 68, 76, 79], "insight": [2, 11, 15, 20, 23, 25, 35, 41, 44, 46, 53, 55, 68, 74, 79, 82, 84], "inspct": [20, 41, 79], "inspect": [23, 26, 44, 47, 53, 56, 69, 82, 85], "inspir": [13, 20, 22, 43, 52, 72, 79, 81], "inst": 69, "instal": [12, 15, 20, 21, 22, 23, 25, 28, 29, 31, 32, 41, 42, 43, 44, 46, 49, 50, 52, 53, 55, 58, 59, 61, 64, 65, 68, 70, 71, 74, 79, 80, 81, 82, 84, 87, 88, 90, 92, 93], "instanc": [12, 13, 14, 17, 18, 20, 25, 26, 27, 28, 29, 30, 32, 33, 34, 37, 38, 39, 41, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 61, 64, 65, 68, 71, 72, 73, 76, 77, 79, 84, 85, 86, 87, 88, 89, 94], "instanti": [19, 40, 63, 78, 97], "instead": [5, 8, 10, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 33, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 54, 55, 56, 57, 58, 59, 61, 67, 68, 69, 72, 73, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 90, 91, 93, 94, 97, 99, 100, 101], "institut": [28, 49, 58, 87, 93], "instruct": [3, 4, 5, 10, 12, 15, 16, 32, 74, 91, 92, 103], "instructor": [4, 6, 12, 32, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 71, 91, 92, 103], "instrument": [15, 16, 19, 36, 40, 74, 75, 78, 99], "int": [16, 17, 20, 22, 23, 28, 30, 36, 37, 41, 43, 44, 49, 51, 52, 53, 58, 75, 76, 79, 81, 82, 87, 89, 93, 100, 101, 102], "int32": [15, 25, 26, 30, 35, 46, 47, 51, 55, 56, 60, 74, 84, 85, 89], "int64": [13, 15, 16, 17, 19, 20, 21, 27, 28, 30, 31, 33, 37, 41, 42, 48, 49, 51, 57, 58, 60, 61, 63, 65, 67, 72, 74, 76, 79, 80, 86, 87, 89, 90, 92, 93], "integ": [8, 16, 19, 22, 23, 30, 36, 40, 43, 44, 51, 52, 53, 60, 73, 75, 78, 81, 82, 89], "integr": [11, 92], "intellig": [1, 28, 49, 58, 87], "intelligen": 87, "intend": [0, 91, 103], "intens": [28, 49, 58, 67, 87], "intent": [28, 49, 58], "inter": 93, "interact": [9, 12, 15, 19, 20, 23, 25, 26, 27, 30, 32, 35, 40, 41, 44, 46, 47, 48, 51, 53, 56, 57, 60, 64, 68, 74, 78, 79, 82, 84, 85, 86, 89, 92, 93, 97], "interaction_constraint": [22, 43, 52, 81], "interaction_onli": [24, 30, 45, 51, 54, 60, 83, 89], "interactive_plot": [15, 35, 64, 74, 97], "interactiveshel": 93, "intercept": [23, 29, 44, 50, 53, 59, 82, 88, 94], "intercept_": [18, 22, 29, 39, 43, 50, 52, 59, 77, 81, 88, 94], "intercept_sc": [20, 41, 79], "interest": [2, 12, 14, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 65, 68, 69, 71, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 97, 99, 101, 102], "interestingli": 54, "interfac": [22, 43, 52, 81, 92], "intermedi": [26, 29, 47, 50, 56, 59, 85, 88], "intern": [0, 1, 13, 29, 30, 31, 33, 50, 51, 59, 61, 72, 88, 89, 90, 93], "internet": [31, 61, 90, 91, 92], "internetservic": [31, 61, 90], "internetservice_dsl": [31, 61, 90], "internetservice_fib": [31, 61, 90], "internetservice_no": [31, 61, 90], "internship": [12, 32, 71], "interpret": [1, 10, 11, 15, 16, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 35, 36, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 54, 55, 56, 57, 59, 61, 63, 68, 69, 70, 74, 75, 79, 80, 81, 83, 84, 85, 86, 87, 88, 90, 91, 100], "interrupt": 61, "interv": [11, 30, 31, 51, 61, 89, 90, 95, 99], "interweb": 92, "intestin": 67, "intraop": [29, 50], "intrins": [30, 51, 60, 89], "intro": [1, 28, 29, 49, 50, 59, 87, 88], "introduc": [17, 20, 31, 37, 61, 76, 79, 90], "introduct": [1, 9, 10, 11, 30, 31, 51, 60, 61, 63, 89, 90, 97], "intslid": [15, 25, 35, 64, 74, 97], "intuit": [11, 15, 16, 17, 19, 21, 23, 25, 26, 31, 35, 36, 37, 40, 42, 44, 46, 47, 53, 55, 56, 61, 69, 74, 75, 76, 78, 80, 82, 84, 85, 90, 93], "inv_h_dot_g_t": 61, "invalid": [50, 78], "inventori": 95, "invers": [18, 21, 39, 42, 61, 69, 77, 80], "inverse_func": [21, 42, 69, 80, 91], "investig": [15, 23, 35, 44, 53, 64, 74, 82, 97], "involv": [2, 4, 19, 21, 22, 26, 28, 29, 40, 42, 43, 47, 49, 52, 56, 58, 59, 69, 78, 80, 81, 85, 87, 88], "io": [9, 16, 29, 31, 36, 50, 59, 61, 62, 70, 75, 88, 90, 93], "io_loop": 93, "ipkernel": 93, "ipykernel": 93, "ipykernel_19402": 82, "ipykernel_22611": 65, "ipykernel_32469": 75, "ipykernel_4311": 53, "ipykernel_4777": 61, "ipykernel_70329": 36, "ipykernel_79734": 73, "ipykernel_86208": 93, "ipykernel_launch": 93, "ipynb": [7, 8, 12, 32], "ipython": [12, 13, 14, 15, 16, 17, 18, 20, 28, 32, 33, 34, 35, 36, 37, 38, 39, 41, 49, 58, 68, 71, 72, 73, 74, 75, 76, 77, 79, 87, 93, 96, 98, 100], "ipywidget": [15, 35, 74, 97], "ir1": [21, 23, 42, 44, 53, 80, 82, 91], "ir2": [21, 23, 42, 44, 80, 82, 91], "iri": [15, 35, 64, 74, 97], "iris_df": [15, 35, 64, 74, 97], "irregular": 11, "irregularli": 95, "irrelev": [15, 24, 28, 35, 45, 49, 54, 58, 74, 83, 87], "irrelevant_po": [28, 49, 58, 87], "irrespect": [14, 18, 34, 39, 73, 77, 103], "is_avail": [29, 50, 59, 64, 70, 88], "is_classifi": 65, "is_leap_year": [30, 89, 102], "is_right_censor": 61, "is_stop": [28, 49, 58, 87], "is_year_end": [30, 89, 102], "isinst": [31, 61, 65, 90], "island": [16, 36, 75, 76], "isn": [14, 15, 20, 21, 22, 28, 35, 41, 42, 43, 49, 58, 67, 73, 74, 79, 80, 81, 87, 91], "isna": 38, "isnul": [16, 36, 65, 75], "iso": [38, 66, 67], "isol": [10, 20, 21, 23, 42, 44, 53, 69, 79, 80, 82, 91], "issu": [4, 6, 7, 12, 22, 27, 31, 32, 43, 48, 52, 57, 63, 81, 86, 90, 95, 99, 103], "issubclass": [31, 61, 90], "isupp": 93, "itali": [28, 49, 58, 87], "italian": [65, 67], "item": [12, 22, 23, 25, 27, 28, 29, 31, 32, 43, 44, 46, 48, 49, 50, 52, 53, 55, 57, 58, 59, 61, 64, 71, 81, 82, 84, 86, 87, 88, 90, 95, 101], "item_inverse_mapp": [27, 48, 57, 86], "item_kei": [27, 48, 57, 86], "item_mapp": [27, 48, 57, 86], "iter": [19, 24, 25, 26, 29, 40, 45, 46, 47, 50, 54, 56, 59, 61, 64, 70, 78, 83, 84, 85, 88, 92], "iterable_with_config": [17, 37, 61, 76], "iterrow": [27, 48, 57, 86], "its": [8, 11, 12, 14, 15, 17, 18, 20, 23, 25, 26, 28, 29, 30, 31, 32, 35, 36, 37, 39, 41, 44, 46, 47, 49, 51, 53, 55, 56, 58, 59, 60, 61, 64, 65, 71, 73, 74, 76, 77, 79, 82, 84, 85, 87, 88, 89, 90, 93, 94, 97, 99, 102, 103], "itself": [7, 20, 22, 26, 28, 41, 43, 47, 49, 52, 56, 58, 79, 81, 85, 87], "j": [8, 18, 23, 24, 25, 27, 29, 39, 44, 45, 46, 48, 50, 53, 54, 57, 59, 77, 82, 83, 84, 86, 88], "j6": 93, "jackin": [40, 78], "jackpot": [17, 37, 76], "jaguar": [12, 29, 32, 50, 59, 71, 88], "jake": 67, "jalebi": [28, 49, 87], "jam": [40, 78], "jame": [28, 31, 49, 58, 61, 87, 90, 93], "jan": [1, 12, 13, 16], "januari": [12, 30, 32, 51, 60, 89], "japan": [28, 49, 58, 87], "jargon": [13, 33, 72], "jason": [1, 24, 45, 54, 83], "javascript": [23, 44, 53, 82], "jazz_musician": [28, 49, 87], "jellyfish": [29, 50, 59, 88], "jennif": 93, "jerri": [27, 48, 57, 86], "jet": [16, 36, 75], "jetti": [29, 50, 59, 88], "jieba": [28, 49, 58, 87], "jim": [27, 48, 57, 86], "jmlr": [19, 40, 78], "joan_baez": [28, 49, 87], "joanna": 67, "job": [17, 30, 31, 37, 61, 67, 70, 76, 89, 90, 102], "joblib": [17, 37, 61, 76, 92], "joei": 65, "john": [22, 43, 52, 67, 81], "johnny_cash": [28, 49, 87], "join": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 28, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 99, 100, 101, 102, 103], "joinpath": 70, "jointli": [30, 51, 60, 89], "joke": [12, 27, 32, 48, 57, 71, 86], "jolen": 93, "jon": 67, "joni_mitchel": [28, 49, 87], "joss": 67, "journal": [28, 49, 87], "journei": [1, 26, 47, 56, 85, 103], "jpg": [29, 50, 59, 64, 70, 88], "json": [29, 92], "ju": [12, 32, 71], "jubatu": [12, 29, 32, 50, 59, 71, 88], "judg": [24, 45, 54, 83], "judgment": 91, "juic": [28, 49, 58, 87], "juli": [30, 89], "jump": 67, "june": [30, 89], "jupyt": [1, 7, 8, 9, 10, 16, 17, 19, 20, 21, 22, 23, 24, 29, 36, 37, 40, 41, 42, 43, 44, 45, 50, 52, 53, 55, 59, 63, 64, 65, 67, 71, 75, 76, 78, 79, 80, 81, 82, 83, 88, 91, 92, 93], "jupyter_notebook": [31, 61, 90], "jupyterlab": [23, 44, 53, 82], "jurafski": [28, 49, 58, 87], "jurisdict": [28, 49, 58, 87], "just": [4, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 93, 95, 97, 101, 102, 103], "justic": [23, 44, 53, 82, 87], "justif": 101, "k": [1, 7, 11, 14, 18, 19, 20, 21, 22, 24, 28, 29, 31, 34, 38, 39, 42, 45, 49, 50, 52, 54, 58, 59, 61, 64, 65, 66, 67, 69, 70, 73, 77, 79, 80, 81, 83, 87, 88, 90, 92, 93, 94, 97], "k_neighbor": [20, 79], "k_valu": [15, 35, 74], "kaggl": [13, 16, 20, 21, 22, 23, 24, 29, 36, 41, 42, 43, 44, 45, 50, 53, 54, 59, 64, 68, 69, 72, 75, 79, 80, 81, 82, 83, 88, 91, 100, 101], "kaggler": [24, 45, 54, 83], "kangaroo": [29, 50, 59, 88], "kaplan": 11, "kaplanmeierfitt": [31, 61, 90], "kazmi": [1, 103], "kb": [17, 21, 31, 37, 42, 61, 76, 80, 90], "kbinsdiscret": [24, 45, 54, 83], "kbinsdiscretizer__latitude_0": [24, 45, 54, 83], "kbinsdiscretizer__latitude_1": [24, 45, 54, 83], "kbinsdiscretizer__latitude_2": [24, 45, 54, 83], "kbinsdiscretizer__latitude_3": [24, 45, 54, 83], "kbinsdiscretizer__latitude_4": [24, 45, 54, 83], "kbinsdiscretizer__latitude_5": [24, 45, 54, 83], "kbinsdiscretizer__latitude_6": [24, 45, 54, 83], "kbinsdiscretizer__latitude_7": [24, 45, 54, 83], "kbinsdiscretizer__latitude_8": [24, 45, 54, 83], "kbinsdiscretizer__latitude_9": [24, 45, 54, 83], "kbinsdiscretizer__longitude_11": [24, 45, 54, 83], "kbinsdiscretizer__longitude_12": [24, 45, 54, 83], "kbinsdiscretizer__longitude_13": [24, 45, 54, 83], "kbinsdiscretizer__longitude_14": [24, 45, 54, 83], "kbinsdiscretizer__longitude_15": [24, 45, 54, 83], "kbinsdiscretizer__longitude_16": [24, 45, 54, 83], "kbinsdiscretizer__longitude_17": [24, 45, 54, 83], "kbinsdiscretizer__longitude_18": [24, 45, 54, 83], "kbinsdiscretizer__longitude_19": [24, 45, 54, 83], "kbinsdiscretizerkbinsdiscret": [24, 45, 83], "kc_house_data": [12, 13, 32, 63, 71, 72, 97], "kdtree": 65, "keep": [1, 14, 15, 16, 17, 20, 22, 23, 24, 27, 28, 31, 34, 35, 36, 37, 41, 43, 44, 45, 48, 49, 52, 53, 54, 57, 58, 61, 63, 67, 68, 73, 74, 75, 76, 79, 81, 82, 83, 84, 86, 87, 90, 92, 97, 98, 103], "keep_empty_featur": [27, 48, 57, 86], "kei": [9, 11, 13, 15, 16, 19, 20, 21, 22, 27, 28, 29, 31, 33, 35, 36, 40, 41, 42, 43, 48, 49, 52, 57, 61, 68, 69, 72, 73, 74, 75, 78, 79, 80, 81, 86, 87, 90, 99, 101], "kelbowvisu": [25, 46, 55, 84], "kellei": [18, 39, 77], "ken": 67, "kenni": 67, "kept": [14, 34, 73], "kera": [23, 44, 53, 82], "kernel": [1, 7, 16, 18, 19, 23, 24, 36, 39, 40, 44, 45, 53, 54, 64, 75, 77, 78, 82, 83, 91, 97], "kernelapp": 93, "kernelbas": 93, "kernelexplain": [23, 44, 53, 82], "keyword": [4, 19, 40, 78, 93], "kfold": [20, 41, 79], "kick": [28, 49, 58, 87], "kiddi": [66, 67], "kilian": [23, 44, 53, 82], "kill": [31, 61, 67, 90], "killer": 67, "kimia": [1, 103], "kind": [0, 12, 13, 14, 16, 17, 18, 20, 21, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 39, 41, 42, 44, 46, 47, 48, 50, 51, 53, 55, 56, 59, 60, 61, 68, 69, 71, 72, 73, 75, 76, 77, 79, 80, 82, 84, 85, 86, 88, 89, 90, 92, 94, 102], "king": [27, 28, 48, 49, 57, 58, 63, 86, 87, 97], "kitchenabvgr": [21, 23, 42, 44, 53, 69, 80, 82, 91], "kitchenqu": [21, 23, 42, 44, 53, 69, 80, 82, 91], "kiwi": [28, 49, 58, 87], "kk": [25, 46, 84], "km": [31, 61, 70, 90, 91, 95], "km_flatten": 70, "km_label": [25, 46, 55, 84], "kmean": [25, 26, 46, 47, 55, 56, 70, 84, 85, 95], "kmeansifittedkmean": 55, "kmf": [31, 61, 90], "kmqfw": [31, 61, 90], "kneighbor": 64, "kneighborregressor": [16, 36, 75], "kneighborsclassifi": [16, 17, 18, 24, 36, 37, 39, 45, 54, 65, 75, 76, 77, 83, 97, 98], "kneighborsclassifierifittedkneighborsclassifi": 65, "kneighborsregressor": [16, 17, 18, 36, 37, 39, 75, 76, 77, 98], "kneighborsregressorkneighborsregressor": [16, 36, 75, 76], "knew": [25, 46, 55, 84], "knn": [2, 14, 15, 16, 18, 23, 24, 27, 29, 34, 35, 36, 39, 44, 45, 48, 50, 53, 54, 57, 59, 73, 74, 75, 76, 77, 82, 83, 86, 88, 92, 94, 95, 101], "knn1": [15, 35, 74], "knn100": [15, 35, 74], "knn_pipe": 76, "knn_scale": [16, 36, 75], "knn_unscal": [16, 36, 75], "knn_valid_accuraci": [15, 35, 74], "knnimput": [27, 48, 57, 86], "knob": [13, 33, 72, 91], "know": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 102, 103], "knowledg": [8, 12, 13, 17, 19, 24, 25, 28, 32, 33, 37, 40, 45, 46, 49, 54, 55, 58, 72, 76, 78, 83, 84, 87, 91, 95], "knowleg": 95, "known": [27, 28, 31, 48, 49, 57, 58, 61, 64, 86, 87, 90], "koala": [29, 50, 59, 88], "kolhatkar": [0, 1, 28, 33, 49, 58, 87], "kr9rkqfj4w78h49djkz8yy9r0000gp": 73, "ksatr": [31, 61, 90], "kvarada": [10, 72, 73, 76, 78, 82, 87, 88, 90, 94], "kvarada01": 10, "kwantlen": [28, 49, 58, 87], "kwarg": [14, 16, 17, 31, 34, 36, 37, 54, 61, 65, 73, 75, 76, 90, 93], "l": [10, 55], "l1": [31, 61, 90], "l123": 4, "l17": 4, "l1_ratio": [20, 41, 61, 79], "l2": [20, 28, 31, 41, 49, 58, 61, 79, 87, 90], "l9": 4, "la": 91, "lab": [10, 12, 13, 14, 27, 32, 34, 46, 72, 73, 84, 86], "lab1": [13, 14, 17, 33, 34, 37, 72, 73, 76, 95], "lab2": [13, 14, 17, 33, 34, 37, 72, 73, 76, 95], "lab3": [13, 14, 17, 33, 34, 37, 72, 73, 76, 95], "lab4": [13, 14, 17, 33, 34, 37, 72, 73, 76, 95], "label": [7, 8, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 68, 69, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 98], "label_": [28, 49, 58, 87, 93], "label_encod": [22, 23, 43, 44, 52, 53, 81, 82], "label_n_clust": [26, 47, 56, 85], "labelencod": [22, 23, 43, 44, 52, 53, 81, 82], "labels": [20, 25, 41, 46, 55, 68, 79, 84], "labels_": [25, 26, 46, 47, 55, 56, 70, 84, 85], "lack": [14, 27, 34, 48, 57, 67, 73, 86, 91], "lag": [31, 61, 90, 95], "lag_df": [30, 51, 60, 89], "lakehead_univers": [28, 49, 58, 87], "lakeshor": [29, 50, 59, 88], "lakesid": [29, 50, 59, 88], "lamb": 65, "lambda": [8, 13, 18, 26, 29, 30, 31, 33, 39, 47, 50, 51, 56, 59, 60, 61, 65, 70, 72, 77, 85, 88, 89, 90, 93], "lamch": 61, "land": [31, 61, 90], "landcontour": [21, 23, 42, 44, 53, 80, 82, 91], "landcontour_bnk": [21, 42, 53, 80], "landcontour_hl": [21, 42, 53, 80], "landcontour_low": [21, 42, 53, 80], "landcontour_lvl": [21, 42, 53, 80], "landmark": 95, "landown": 93, "landscap": [25, 28, 46, 49, 55, 58, 84, 87], "landslop": [21, 23, 42, 44, 53, 80, 82, 91], "landslope_gtl": [21, 23, 42, 44, 53, 80, 82], "landslope_mod": [21, 23, 42, 44, 53, 80, 82], "landslope_sev": [21, 23, 42, 44, 53, 80, 82], "langara_colleg": [28, 49, 87], "languag": [2, 9, 16, 17, 27, 29, 36, 37, 48, 50, 57, 67, 75, 76, 86, 88, 92, 93], "language_enc": [16, 36, 75], "language_english": [16, 36, 75], "language_french": [16, 36, 75], "language_hindi": [16, 36, 75], "language_mandarin": [16, 36, 75], "language_spanish": [16, 36, 75], "language_vietnames": [16, 36, 75], "laptop": [12, 32, 71, 92], "lar": [12, 32, 71], "larg": [12, 14, 15, 16, 18, 20, 21, 25, 26, 28, 29, 32, 34, 35, 36, 38, 39, 41, 42, 46, 47, 49, 50, 54, 55, 56, 58, 59, 63, 66, 67, 68, 69, 71, 73, 74, 75, 77, 79, 80, 84, 85, 87, 88, 92, 95, 97, 100], "larger": [13, 14, 15, 16, 18, 19, 21, 22, 23, 25, 26, 31, 34, 35, 36, 39, 40, 42, 43, 44, 46, 47, 52, 53, 55, 56, 61, 72, 73, 74, 75, 77, 78, 80, 81, 82, 84, 85, 90], "largest": [21, 42, 69, 80], "larvatu": [12, 29, 32, 50, 59, 71, 88], "last": [8, 12, 13, 14, 15, 16, 17, 20, 23, 27, 29, 30, 31, 32, 33, 34, 36, 37, 44, 48, 50, 53, 56, 57, 59, 61, 64, 65, 67, 68, 70, 72, 73, 74, 75, 76, 79, 82, 86, 88, 89, 90, 91, 92, 93, 97, 99, 101, 102, 103], "last_row": 8, "lastp": [26, 47, 56, 85], "lat": [12, 13, 32, 63, 71, 72], "late": [19, 20, 32, 67, 79, 103], "latent": [27, 28, 29, 48, 49, 50, 58, 59, 86, 87, 88], "latentdirichletalloc": [28, 49, 58, 87], "later": [10, 13, 17, 20, 29, 30, 33, 37, 41, 50, 51, 59, 60, 68, 72, 76, 79, 88, 89, 92, 97], "latest": [17, 23, 31, 37, 53, 61, 76, 82, 90], "latex": [4, 7, 12, 32], "latin": [12, 20, 32, 41, 68, 71, 79, 100], "latitud": [14, 15, 16, 18, 24, 34, 35, 36, 39, 45, 54, 73, 74, 75, 76, 77, 83, 98], "latitude_0": [24, 45, 54, 83], "latitude_1": [24, 45, 54, 83], "latitude_10": [24, 45, 83], "latitude_11": [24, 45, 83], "latitude_12": [24, 45, 83], "latitude_13": [24, 45, 83], "latitude_14": [24, 45, 83], "latitude_15": [24, 45, 83], "latitude_16": [24, 45, 83], "latitude_17": [24, 45, 83], "latitude_18": [24, 45, 83], "latitude_19": [24, 45, 83], "latitude_2": [24, 45, 54, 83], "latitude_3": [24, 45, 83], "latitude_4": [24, 45, 83], "latitude_5": [24, 45, 83], "latitude_6": [24, 45, 83], "latitude_7": [24, 45, 83], "latitude_8": [24, 45, 54, 83], "latitude_9": [24, 45, 83], "latter": [21, 42, 69, 80], "laugh": 67, "launch": [12, 32], "launch_inst": 93, "launch_new_inst": 93, "lauvagrand": 93, "law": [28, 49, 65, 87], "lawsuit": [28, 49, 58, 87], "layer": [29, 50, 64, 70, 88], "layout": [15, 35, 64, 74, 97], "lazi": [15, 35, 74], "lbfg": [20, 41, 79], "lda": [29, 50, 59, 88], "ldot": [19, 40, 78], "lead": [1, 8, 14, 18, 21, 26, 27, 28, 31, 34, 39, 42, 47, 48, 49, 56, 57, 58, 61, 73, 77, 80, 85, 86, 87, 90, 91], "leaf": [13, 26, 28, 33, 47, 49, 72, 85, 87], "leagu": [28, 49, 58, 87], "leak": [16, 31, 36, 61, 75, 90, 95], "leakag": 95, "leaner": [14, 34, 73], "learn": [2, 9, 10, 65, 70, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "learner": [14, 15, 22, 34, 35, 43, 52, 73, 74, 81], "learning_method": [28, 49, 58, 87], "learning_r": [22, 43, 52, 81], "learnxinyminut": 9, "least": [1, 4, 14, 15, 20, 21, 23, 24, 25, 26, 34, 35, 38, 41, 42, 44, 45, 46, 47, 53, 54, 55, 56, 66, 67, 68, 69, 73, 74, 79, 80, 82, 83, 84, 85, 91, 101, 102], "least_confident_i": [18, 39, 77], "least_confident_x": [18, 39, 77], "leav": [7, 13, 26, 29, 31, 33, 47, 50, 56, 59, 61, 72, 85, 88, 90, 91, 94], "lectur": [5, 7, 8, 10, 62, 95, 100], "lecun": [23, 44, 53, 82], "lecuy": 1, "lee": [23, 44, 53, 67, 82], "left": [7, 12, 19, 20, 21, 25, 26, 28, 30, 31, 32, 40, 41, 42, 46, 47, 49, 51, 55, 56, 58, 60, 61, 68, 69, 71, 78, 79, 80, 84, 85, 87, 89, 90, 91, 103], "leg": 67, "legal": [0, 28, 49, 58, 87], "legend": [7, 8, 15, 18, 20, 21, 24, 25, 29, 30, 31, 35, 39, 41, 42, 45, 46, 50, 51, 54, 55, 59, 60, 61, 68, 69, 74, 77, 79, 80, 83, 84, 88, 89, 90, 91, 94], "legendari": 93, "legless": 67, "leisur": [20, 79, 92], "lemma": [28, 49, 58, 87], "lemma_": [28, 49, 58, 87], "lemmat": [28, 49, 87], "lemon": [25, 84], "len": [12, 14, 16, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 34, 36, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 64, 68, 69, 70, 73, 75, 78, 79, 80, 81, 82, 85, 86, 87, 88, 89, 91, 93], "length": [13, 14, 15, 18, 21, 23, 25, 26, 28, 30, 31, 33, 34, 35, 39, 42, 44, 46, 47, 49, 51, 53, 55, 56, 58, 60, 61, 63, 64, 72, 73, 74, 77, 80, 82, 84, 85, 87, 89, 90, 93, 97, 102], "leo": [22, 43, 52, 81], "leopard": [12, 29, 32, 50, 59, 71, 88], "leq": [24, 25, 45, 46, 54, 55, 83, 84], "less": [1, 5, 6, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 31, 32, 35, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 52, 53, 54, 56, 57, 61, 69, 71, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 90, 91, 95, 97, 100], "lesson": [9, 16, 36, 75, 93], "lesssim": [14, 34, 73], "let": [12, 13, 14, 18, 19, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 66, 67, 69, 71, 72, 73, 77, 78, 81, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "letter": [18, 39, 77, 93], "lev": [21, 42, 69, 80], "level": [11, 15, 18, 20, 21, 22, 23, 24, 26, 28, 29, 30, 35, 39, 41, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 56, 58, 59, 60, 67, 69, 74, 77, 79, 80, 81, 82, 83, 85, 87, 88, 89, 91, 92, 100], "leverag": [23, 27, 44, 48, 53, 57, 82, 86], "lewi": 93, "lexic": [28, 49, 87], "lexicon": 93, "lgbm": [11, 22, 23, 43, 44, 52, 81, 82, 95], "lgbmclassifi": [12, 22, 23, 32, 43, 44, 52, 53, 71, 81, 82, 101], "lgbmclassifierifittedlgbmclassifi": [12, 23, 32, 44, 53, 71, 82], "lgbmclassifierlgbmclassifi": [22, 43, 52, 81], "lgbmregressor": [12, 22, 32, 43, 52, 71, 81], "li": [1, 18, 39, 77, 103], "lia": 67, "liabil": 0, "liabl": 0, "liao": [12, 32, 71], "lib": [17, 19, 29, 31, 33, 37, 50, 61, 64, 65, 72, 73, 76, 78, 82, 90, 93, 94], "liblinear": 54, "librari": [4, 8, 10, 14, 20, 23, 24, 28, 29, 30, 34, 44, 45, 49, 50, 51, 53, 54, 58, 59, 60, 63, 65, 73, 79, 82, 83, 87, 88, 89, 91, 93, 97], "libtorch_1741738354177": 50, "licensor": 0, "life": [13, 18, 25, 27, 39, 46, 48, 54, 55, 57, 65, 72, 77, 84, 86, 91, 92, 96, 103], "lifeless": 67, "lifelin": [11, 31, 61, 90], "lifetim": [31, 61, 90], "light": 67, "lighter": [19, 40, 78], "lightgbm": [12, 23, 32, 44, 53, 71, 82, 92, 101], "lightgbmcolumntransform": [22, 43, 52], "lightweight": [28, 49, 58, 87], "likabl": 67, "like": [1, 2, 4, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 99, 100, 101, 103], "likelihood": [31, 61, 68, 90], "likewis": 7, "lime": [23, 44, 82], "limit": [0, 12, 13, 14, 17, 22, 23, 32, 34, 37, 43, 44, 52, 53, 71, 72, 73, 76, 81, 82, 91, 92, 93, 95, 96, 99, 103], "linalg": [28, 49, 58, 61, 70, 87], "linalgerror": 61, "line": [4, 8, 10, 12, 13, 17, 18, 19, 20, 21, 25, 28, 29, 30, 31, 32, 33, 37, 39, 40, 42, 46, 49, 50, 51, 55, 58, 59, 60, 61, 65, 67, 69, 72, 76, 77, 78, 79, 80, 84, 87, 88, 89, 90, 91, 93, 97, 99], "line2d": 8, "linear": [1, 19, 20, 22, 24, 26, 27, 29, 30, 31, 40, 41, 43, 45, 47, 48, 50, 51, 52, 56, 57, 60, 61, 68, 69, 78, 79, 81, 83, 85, 86, 88, 89, 90, 91, 92, 94, 95], "linear_model": [12, 18, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 38, 39, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 66, 67, 68, 69, 71, 77, 79, 80, 81, 82, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 100, 101, 102], "linear_svc": [18, 39, 77], "linearli": [18, 24, 30, 39, 45, 51, 54, 60, 77, 83, 89], "linearregress": [18, 21, 24, 31, 39, 42, 45, 54, 61, 69, 77, 80, 83, 90, 93], "linestyl": [25, 30, 46, 55, 84, 89, 102], "linewidth": [30, 51, 60, 89, 91], "linger": [15, 74], "lingual": [28, 49, 58, 87], "linguist": [17, 37, 76], "link": [0, 4, 5, 7, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 26, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 52, 53, 54, 55, 56, 61, 71, 72, 76, 77, 80, 81, 85, 90, 91, 92, 103], "linkag": [26, 47, 85], "linkage_arrai": [26, 47, 56, 85], "linkage_typ": [26, 47, 56, 85], "linkedin": [27, 48, 57, 86], "linspac": [18, 19, 21, 24, 39, 40, 42, 45, 69, 77, 78, 80, 83, 91, 99], "lion": [27, 48, 57, 86], "lipstick": 49, "list": [4, 7, 8, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 31, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 52, 53, 55, 57, 58, 59, 61, 65, 66, 67, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 86, 87, 88, 90, 91, 101, 103], "listedcolormap": [18, 39, 77], "liter": [67, 93], "literatur": [22, 43, 52, 81], "littl": [8, 19, 20, 29, 41, 50, 59, 67, 68, 79, 88, 91, 92], "live": [1, 10, 12, 15, 16, 17, 19, 25, 31, 32, 36, 37, 40, 46, 55, 61, 74, 75, 76, 78, 84, 90, 91, 92, 99], "liver": [13, 33, 72], "livestream": 103, "ll": [1, 6, 7, 10, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 94, 95, 97, 102, 103], "ll_": 61, "llazx": [31, 61, 90], "llm": 30, "lo": 93, "load": [8, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 32, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 49, 50, 52, 53, 55, 58, 59, 63, 64, 65, 67, 68, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 87, 88, 91, 93, 97, 98, 100], "load_breast_canc": [24, 45, 54, 83], "load_citibik": [30, 51, 60, 89], "load_digit": 91, "load_iri": [15, 35, 64, 74, 97], "loan": [20, 41, 79, 100], "loc": [8, 15, 18, 20, 23, 27, 30, 31, 35, 39, 41, 44, 48, 51, 53, 54, 57, 60, 61, 68, 74, 77, 79, 82, 86, 89, 90, 91, 102], "local": [5, 7, 10, 20, 22, 23, 24, 29, 41, 43, 44, 45, 50, 52, 53, 54, 59, 61, 64, 65, 68, 79, 81, 82, 83, 88, 93], "locat": [8, 17, 25, 27, 28, 30, 37, 46, 48, 49, 55, 57, 58, 64, 67, 76, 84, 86, 87, 89, 93, 101, 102, 103], "location_katherin": [30, 89], "location_mountginini": [30, 89], "location_townsvil": [30, 89], "location_witchcliff": [30, 89], "location_wollongong": [30, 89], "lock": [14, 34, 73], "log": [12, 13, 15, 21, 22, 31, 35, 42, 43, 52, 61, 64, 65, 74, 80, 81, 90, 91, 92, 97, 101], "log10": [21, 42, 69, 80], "log1p": [21, 42, 69, 80, 91], "log2": [31, 61, 90], "log_likelihood_": 61, "log_likelihood_ratio_test": [31, 61, 90], "log_loss": 91, "logarithm": [15, 35, 64, 74, 97], "logic": [24, 45, 54, 83], "logical_xor": [24, 45, 54, 83], "login": [27, 48, 57, 86], "logisit": [29, 50, 88], "logist": [22, 23, 30, 31, 38, 43, 44, 52, 53, 61, 66, 67, 81, 82, 89, 90, 91, 92, 93, 94, 95, 100, 101, 102], "logisticregress": [12, 18, 21, 22, 23, 24, 28, 29, 32, 38, 39, 42, 43, 44, 45, 49, 50, 51, 52, 53, 54, 58, 59, 60, 66, 67, 68, 69, 71, 77, 80, 81, 82, 83, 87, 88, 92, 93, 94, 100, 101, 102], "logisticregressionifittedlogisticregress": [29, 50, 88], "logisticregressionlogisticregress": [20, 22, 29, 41, 43, 50, 52, 59, 67, 79, 81, 88, 93], "logloss": [23, 44, 53, 82], "lognorm": [19, 40, 78], "logspac": [19, 40, 64, 78, 99], "loguniform": [19, 40, 78, 99], "lol": [17, 37, 76], "london": 93, "lone": [26, 47, 85], "long": [0, 12, 13, 18, 20, 22, 26, 27, 31, 32, 33, 39, 43, 47, 48, 56, 57, 61, 63, 71, 72, 77, 79, 81, 85, 86, 90, 92, 95, 103], "longer": [7, 19, 20, 29, 31, 40, 41, 50, 59, 61, 78, 79, 88, 90, 91, 92], "longest": [13, 33, 72], "longitud": [14, 15, 16, 18, 24, 34, 35, 36, 39, 45, 54, 73, 74, 75, 76, 77, 83, 98], "longitude_0": [24, 45, 54, 83], "longitude_1": [24, 45, 54, 83], "longitude_10": [24, 45, 83], "longitude_11": [24, 45, 83], "longitude_12": [24, 45, 83], "longitude_13": [24, 45, 83], "longitude_14": [24, 45, 83], "longitude_15": [24, 45, 83], "longitude_16": [24, 45, 83], "longitude_17": [24, 45, 83], "longitude_18": [24, 45, 83], "longitude_19": [24, 45, 83], "longitude_2": [24, 45, 54, 83], "longitude_3": [24, 45, 54, 83], "longitude_4": [24, 45, 54, 83], "longitude_5": [24, 45, 83], "longitude_6": [24, 45, 83], "longitude_7": [24, 45, 83], "longitude_8": [24, 45, 83], "longitude_9": [24, 45, 83], "look": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 99, 100, 101], "lookatm": [12, 32, 71], "loop": [19, 22, 30, 40, 51, 52, 60, 78, 81, 89, 94, 95], "loos": [26, 47, 56, 85, 92], "lose": [6, 17, 37, 76], "loss": [2, 20, 21, 22, 23, 28, 31, 41, 42, 43, 44, 49, 52, 53, 61, 69, 79, 80, 81, 82, 87, 90, 100], "lot": [5, 9, 12, 13, 15, 17, 18, 19, 20, 21, 23, 24, 26, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 44, 45, 47, 50, 51, 53, 54, 56, 59, 60, 61, 65, 67, 68, 71, 72, 74, 76, 77, 78, 79, 80, 82, 83, 85, 88, 89, 90, 91, 92, 99, 103], "lotarea": [21, 23, 42, 44, 53, 69, 80, 82, 91], "lotconfig": [21, 23, 42, 44, 53, 80, 82, 91], "lotconfig_corn": [21, 42, 80], "lotconfig_culdsac": [21, 42, 80], "lotconfig_fr2": [21, 42, 80], "lotconfig_fr3": [21, 42, 80], "lotconfig_insid": [21, 42, 80], "lotfrontag": [21, 23, 42, 44, 53, 69, 80, 82, 91], "lotshap": [21, 23, 42, 44, 53, 80, 82, 91], "lotshape_ir1": [21, 42, 80, 91], "lotshape_ir2": [21, 42, 80, 91], "lotshape_ir3": [21, 42, 44, 80, 91], "lotshape_reg": [21, 42, 44, 80, 91], "loud": [15, 16, 19, 36, 40, 65, 74, 75, 78, 95, 99], "loui": [30, 51, 60, 89], "lourenzutti": [19, 40, 78], "love": [67, 92, 93], "low": [6, 14, 15, 19, 20, 21, 23, 24, 26, 31, 34, 35, 40, 41, 42, 44, 45, 47, 53, 54, 56, 61, 65, 68, 69, 73, 74, 78, 79, 80, 82, 83, 84, 85, 90, 91, 92], "lower": [14, 15, 20, 21, 23, 25, 27, 28, 31, 34, 35, 41, 42, 44, 46, 48, 49, 53, 55, 57, 58, 61, 68, 69, 73, 74, 79, 80, 82, 84, 86, 87, 90, 91, 99], "lowerbound_peopl": 65, "lowercas": [16, 17, 36, 37, 75, 76], "lowest": [97, 103], "lowqualfinsf": [21, 23, 42, 44, 53, 69, 80, 82, 91], "lr": [18, 20, 21, 23, 29, 30, 31, 39, 41, 42, 44, 50, 51, 53, 59, 60, 61, 66, 67, 68, 69, 77, 79, 80, 82, 88, 89, 90, 93, 94], "lr_1": [24, 45, 54, 83], "lr_2": [24, 45, 54, 83], "lr_3": [24, 45, 54, 83], "lr_coef": [23, 30, 31, 44, 53, 61, 82, 89, 90, 102], "lr_coefs_landslop": [23, 44, 53, 82], "lr_flatten_pip": [29, 50, 59, 88], "lr_item": [27, 48, 57, 86], "lr_l1_pipe": 54, "lr_l2_pipe": 54, "lr_pipe": [21, 23, 30, 42, 44, 53, 69, 80, 82, 89], "lr_pred": [20, 21, 41, 42, 68, 69, 79, 80], "lr_scale": [23, 44, 53, 82], "lr_schedul": [29, 50, 59, 88], "lr_x": [27, 48, 57, 86], "lr_y": [27, 48, 57, 86], "ls15hb": [12, 32, 71], "lstm": [30, 51, 60, 89], "lt": [14, 16, 17, 19, 20, 21, 22, 23, 24, 31, 34, 36, 37, 40, 41, 42, 43, 44, 45, 52, 53, 54, 61, 67, 73, 75, 76, 78, 79, 80, 81, 82, 83, 90], "ltorgo": [18, 39, 77], "lu": 61, "lucio": 67, "luck": 92, "lucki": [15, 19, 35, 40, 74, 78], "luckili": [99, 101], "lundberg": [23, 44, 53, 82], "luster": [26, 47, 56, 85], "lvert": [28, 49, 58, 87], "lvl": [21, 23, 42, 44, 53, 80, 82, 91], "lwq": [21, 23, 42, 44, 53, 69, 80, 82, 91], "lynx": [12, 29, 32, 50, 59, 71, 88], "l\u00e9cuyer": [28, 49, 58, 87, 103], "m": [10, 12, 14, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 67, 69, 70, 71, 73, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94], "m_neighbor": [20, 79], "ma": [28, 49, 58, 78, 87], "macaqu": [12, 29, 32, 50, 59, 71, 88], "macbook": 10, "mach": 87, "machet": 67, "machin": [2, 9, 10, 11, 16, 17, 19, 21, 22, 23, 24, 27, 28, 29, 30, 31, 36, 37, 40, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 64, 65, 67, 69, 75, 76, 78, 80, 81, 82, 83, 86, 87, 88, 89, 90, 91, 93, 95, 97, 102, 103], "machine_learn": 91, "mackworth": 1, "made": [0, 6, 7, 8, 12, 13, 20, 22, 23, 27, 28, 29, 30, 32, 33, 41, 44, 48, 49, 50, 51, 52, 53, 57, 58, 59, 60, 68, 71, 72, 79, 81, 82, 86, 87, 88, 89, 91, 92, 99], "magazin": [28, 49, 87], "magnitud": [19, 21, 23, 28, 30, 36, 38, 40, 42, 44, 49, 53, 58, 66, 67, 69, 78, 80, 82, 87, 89, 102], "maguir": [27, 48, 57, 86], "mahsa": [1, 103], "mai": [0, 1, 7, 8, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 60, 61, 65, 67, 68, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 89, 90, 92, 93, 96, 97, 98, 99, 100, 101, 102, 103], "mail": [31, 61, 90], "main": [8, 10, 12, 13, 15, 17, 22, 25, 26, 32, 33, 35, 37, 43, 46, 47, 52, 54, 63, 72, 74, 76, 81, 84, 85, 95, 103], "mainland": [18, 39, 77], "mainli": 103, "maintain": [22, 27, 43, 48, 52, 57, 81, 86, 91, 95], "mainten": [22, 43, 52, 81], "maissan": [1, 103], "maj1": [21, 23, 42, 44, 53, 69, 80, 82, 91], "maj2": [21, 23, 42, 44, 53, 69, 80, 82, 91], "major": [2, 14, 15, 16, 17, 28, 34, 35, 36, 37, 49, 58, 73, 74, 75, 76, 87, 95, 96, 101], "major_biologi": [17, 37, 76], "major_comput": [17, 37, 76], "major_econom": [17, 37, 76], "major_linguist": [17, 37, 76], "major_mathemat": [17, 37, 76], "major_mechan": [17, 37, 76], "major_phys": [17, 37, 76], "major_psychologi": [17, 37, 76], "make": [2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 98, 100, 101, 102, 103], "make_blob": [15, 25, 26, 29, 35, 46, 47, 50, 55, 56, 59, 74, 84, 85, 88, 94], "make_circl": [26, 47, 56, 85], "make_classif": [15, 20, 35, 74, 79], "make_column_transform": [19, 20, 21, 22, 23, 24, 30, 31, 40, 41, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 65, 69, 78, 79, 80, 81, 82, 83, 89, 90, 91, 93, 98, 99, 100, 101, 102], "make_forg": [15, 35, 74], "make_grid": [29, 50, 59, 64, 70, 88], "make_imb_pipelin": [20, 79], "make_moon": [26, 47, 56, 85], "make_num_tree_plot": [22, 43, 52, 81], "make_pipelin": [12, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 37, 38, 39, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 53, 54, 58, 59, 60, 61, 65, 66, 67, 68, 69, 71, 76, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 91, 92, 93, 98, 99, 100, 101, 102], "make_scor": [21, 24, 42, 45, 54, 69, 80, 83, 93], "maker": [67, 91], "malcolm": [25, 27, 46, 48, 57, 84, 86], "malcom": [25, 46, 84], "male": [20, 22, 23, 31, 41, 43, 44, 52, 53, 61, 79, 81, 82, 90, 100], "male_cm": [20, 41, 79, 100], "male_pr": [20, 41, 79, 100], "malkovich": 67, "mall": 93, "mamba": [61, 64, 65], "man": [27, 28, 48, 49, 57, 58, 67, 86, 87], "manag": [5, 11, 30, 31, 51, 60, 61, 89, 90, 91, 95], "mandarin": [16, 36, 75], "mango": [28, 49, 58, 87], "mani": [1, 2, 5, 8, 12, 13, 14, 15, 16, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 77, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 97, 99, 101, 102, 103], "manipul": 91, "manner": [0, 22, 43, 52, 81], "manual": [10, 12, 17, 20, 24, 25, 26, 28, 32, 33, 37, 41, 45, 46, 47, 49, 54, 55, 56, 58, 64, 68, 69, 71, 76, 79, 83, 84, 85, 87, 99], "manual_se": [64, 70], "manufactur": [19, 29, 50, 59, 88], "map": [1, 13, 14, 17, 19, 27, 33, 34, 37, 38, 40, 48, 57, 66, 67, 72, 73, 76, 78, 86, 99], "mape": [92, 95], "mape_scor": [21, 42, 69, 80], "maple_leaf": [28, 49, 87], "mapper": [27, 48, 57, 86], "mar": 1, "march": [30, 52, 53, 54, 89], "marit": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "mark": [6, 7, 19, 20, 26, 32, 40, 41, 47, 54, 68, 78, 79, 85, 103], "markdown": [12, 32], "marker": [15, 18, 25, 35, 39, 46, 55, 74, 77, 84], "markers": [18, 20, 39, 41, 68, 77, 79], "market": [12, 25, 29, 30, 32, 46, 50, 51, 55, 59, 60, 71, 84, 88, 89, 91, 92], "markov": [28, 49, 58, 87], "marri": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82], "martin": [28, 49, 58, 87], "mask": [19, 40, 70, 78], "massiv": [17, 19, 37, 40, 76, 78], "master": [8, 19, 20, 22, 23, 28, 40, 41, 43, 44, 49, 52, 53, 58, 68, 78, 79, 81, 82, 87, 100], "masvnrarea": [21, 23, 42, 44, 53, 69, 80, 82, 91], "masvnrtyp": [21, 23, 42, 44, 53, 80, 82, 91], "masvnrtype_brkcmn": [21, 42, 80], "masvnrtype_brkfac": [21, 42, 80], "masvnrtype_miss": [21, 42, 80], "masvnrtype_ston": [21, 42, 80], "match": [17, 18, 20, 22, 23, 30, 37, 39, 41, 43, 44, 53, 68, 76, 77, 79, 81, 82, 89, 101, 102], "materi": [8, 10, 12, 13, 14, 15, 20, 28, 32, 35, 49, 58, 61, 71, 72, 73, 74, 84, 87, 90, 92, 95, 103], "matern": [24, 45, 54, 83], "math": [2, 25, 27, 31, 46, 48, 54, 55, 57, 61, 84, 86, 90], "mathcal": [15, 74], "mathemat": [2, 17, 22, 37, 43, 52, 76, 81, 92, 95], "mathematician": [28, 49, 87], "mathia": [1, 17, 19, 28, 29, 93, 103], "matlab": 8, "matplotlib": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 99, 100, 101, 102], "matplotlibdeprecationwarn": [53, 82], "matric": [12, 15, 20, 27, 32, 35, 41, 48, 57, 74, 79, 86, 100], "matrix": [17, 26, 28, 37, 47, 49, 56, 58, 61, 65, 67, 76, 85, 87, 92, 95, 100], "mattei": 67, "matter": [16, 17, 20, 22, 26, 36, 37, 41, 43, 47, 52, 56, 60, 75, 76, 79, 81, 85, 91, 95, 103], "max": [8, 14, 16, 18, 19, 20, 21, 22, 25, 26, 30, 34, 36, 38, 39, 40, 41, 42, 43, 46, 47, 51, 52, 55, 56, 60, 63, 65, 66, 67, 69, 73, 75, 77, 78, 79, 80, 81, 84, 85, 89, 102], "max_bin": [22, 43, 52, 81], "max_cat_threshold": [22, 43, 52, 81], "max_cat_to_onehot": [22, 43, 52, 81], "max_clust": [26, 47, 56, 85], "max_colwidth": [12, 13, 14, 15, 16, 17, 18, 19, 20, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 47, 48, 56, 57, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 85, 86, 96, 97, 98, 99, 100], "max_delta_step": [22, 43, 52, 81], "max_depth": [14, 15, 19, 22, 23, 34, 35, 40, 43, 44, 52, 53, 63, 64, 73, 74, 78, 81, 82, 91, 96, 97], "max_depth_widget": [15, 35, 64, 74, 97], "max_df": [17, 37, 76], "max_displai": [23, 44, 53, 82], "max_featur": [12, 17, 19, 22, 32, 37, 38, 40, 43, 52, 65, 66, 67, 71, 76, 78, 81, 91, 99], "max_it": [12, 20, 22, 23, 24, 28, 29, 30, 31, 32, 38, 41, 43, 44, 45, 49, 50, 52, 53, 54, 58, 59, 61, 67, 68, 71, 79, 81, 82, 83, 87, 88, 89, 90, 91, 92, 93, 94, 100], "max_leaf_nod": [13, 33, 72, 91], "max_leav": [22, 43, 52, 81], "max_opt": [15, 20, 25, 35, 41, 46, 47, 56, 68, 74, 79, 84, 85], "max_row": [31, 61, 90], "max_sampl": 91, "max_step": 61, "maxabsscal": 65, "maxclust": [26, 47, 56, 85], "maxent": 94, "maxhr": 101, "maxim": [12, 20, 21, 25, 32, 41, 42, 46, 55, 69, 71, 79, 80, 84], "maximum": [13, 16, 21, 22, 25, 26, 33, 36, 38, 42, 43, 46, 47, 52, 55, 56, 65, 66, 67, 69, 72, 75, 80, 81, 84, 85, 97], "maxosx": 10, "maxtemp": [30, 89, 102], "may": 1, "mayb": [20, 23, 30, 41, 44, 51, 53, 60, 79, 82, 89, 91, 103], "maybe_coerce_valu": [31, 61, 90], "mb": [16, 20, 24, 30, 31, 36, 41, 45, 54, 75, 76, 79, 83, 89, 90, 102], "mcld": 103, "mcml": [1, 103], "md": [10, 12, 13, 28, 49, 58, 72, 87], "me": [8, 12, 19, 28, 32, 40, 49, 58, 67, 71, 78, 87, 91, 92, 93], "mean": [5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 48, 50, 52, 53, 54, 57, 59, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 86, 88, 89, 90, 92, 93, 94, 95, 97, 99, 100, 101, 102, 103], "mean_absolute_error": 92, "mean_absolute_percentage_error": [21, 42, 69, 80], "mean_cv_error": [14, 34, 73], "mean_cv_scor": [15, 18, 19, 35, 38, 39, 40, 64, 66, 67, 74, 77, 78], "mean_fit_tim": [19, 21, 40, 42, 69, 78, 80], "mean_scor": [14, 16, 19, 34, 36, 40, 54, 61, 73, 75, 78, 93], "mean_score_tim": [19, 21, 40, 42, 78, 80], "mean_squared_error": [21, 24, 42, 45, 54, 69, 80, 83, 93], "mean_std_cross_val_scor": [14, 16, 22, 23, 31, 34, 36, 43, 44, 52, 53, 54, 61, 73, 75, 76, 81, 82, 90, 93], "mean_test_neg_mean_squared_error": [21, 42, 80], "mean_test_scor": [19, 21, 40, 42, 69, 78, 80, 99], "mean_train_error": [14, 34, 73], "mean_train_neg_mean_squared_error": [21, 42, 80], "mean_train_scor": [15, 18, 19, 21, 35, 38, 39, 40, 42, 64, 66, 67, 69, 74, 77, 78, 80], "meaning": [11, 15, 17, 20, 23, 25, 28, 35, 37, 41, 44, 46, 49, 53, 55, 58, 64, 68, 74, 76, 79, 82, 84, 87, 98], "meaningless": [26, 47, 56, 85], "means_": 70, "measur": [0, 12, 13, 14, 15, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 41, 42, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 60, 61, 68, 69, 71, 72, 73, 74, 79, 80, 82, 84, 85, 86, 87, 89, 90, 91, 92, 95, 97, 101, 102], "meat": 65, "mechan": [17, 37, 76, 95], "mechanical_engin": [28, 49, 58, 87], "medal": 8, "media": 91, "median": [13, 16, 18, 21, 23, 24, 30, 31, 33, 36, 39, 42, 44, 45, 53, 54, 61, 65, 69, 72, 75, 76, 77, 80, 82, 83, 89, 90, 91, 102], "median_house_valu": [16, 24, 36, 45, 54, 75, 76, 83, 98], "median_incom": [16, 24, 36, 45, 54, 75, 76, 83, 98], "mediat": 91, "medic": [20, 25, 41, 46, 55, 79, 84, 103], "medinc": [18, 39, 77], "medit": [20, 79, 92], "medium": [0, 15, 31, 35, 61, 65, 74, 90, 95], "meet": [28, 49, 58, 87], "meier": 11, "melbourneairport": [30, 89, 102], "member": [18, 22, 39, 43, 52, 77, 81, 103], "membership": [17, 25, 26, 37, 46, 47, 55, 56, 76, 84, 85], "memori": [8, 16, 17, 20, 21, 22, 24, 29, 30, 31, 36, 37, 41, 42, 43, 45, 50, 52, 54, 59, 61, 65, 75, 76, 79, 80, 81, 83, 88, 89, 90, 95, 102], "men": 67, "mental": 91, "mention": [0, 4, 18, 31, 39, 61, 67, 77, 90, 91], "menu": [10, 92], "merchant": 0, "merg": [0, 5, 10, 26, 47, 56, 85], "meshgrid": [24, 45, 83], "mess": [27, 31, 48, 57, 61, 67, 86, 90], "messag": [4, 6, 10, 14, 17, 34, 37, 61, 65, 73, 76], "message_clsnam": 61, "messi": [24, 28, 45, 49, 54, 58, 83, 87], "met": 103, "meta": [22, 43, 52, 81], "metacademi": 1, "metal": 67, "method": [2, 11, 13, 15, 16, 18, 20, 22, 23, 26, 27, 28, 29, 30, 31, 33, 35, 36, 38, 39, 41, 43, 44, 47, 48, 49, 50, 51, 52, 53, 56, 57, 59, 60, 61, 63, 64, 66, 67, 68, 72, 74, 75, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 101, 102], "methodologi": [16, 30, 36, 51, 60, 75, 89], "metric": [1, 11, 15, 17, 22, 23, 24, 25, 26, 27, 28, 29, 31, 35, 37, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 61, 65, 74, 76, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 100, 101], "mexican": 65, "mexico": [20, 41, 79], "mglearn": [13, 14, 15, 16, 17, 18, 19, 20, 25, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 46, 49, 50, 51, 55, 58, 59, 60, 64, 66, 67, 68, 72, 73, 74, 75, 76, 77, 78, 79, 84, 87, 88, 89, 94, 96, 97, 99, 100], "mi": [12, 20, 32, 40, 41, 68, 70, 71, 78, 79, 91], "microsoft": 93, "middl": [38, 66, 67], "midnight": [30, 51, 89], "midterm": [1, 6, 12, 18, 32], "might": [1, 6, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 64, 65, 68, 69, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 91, 92, 93, 95, 97, 103], "mightn": [28, 49, 58, 87], "miguel": 92, "mike": [0, 1, 9, 33, 72, 92, 99], "mikolov": [28, 49, 58, 87], "milk": [28, 49, 58, 87], "mill": [22, 43, 52, 81], "millennia": 103, "million": [29, 50, 59, 88], "min": [1, 18, 21, 26, 30, 36, 39, 41, 42, 47, 51, 56, 60, 63, 65, 69, 77, 80, 85, 89, 102], "min1": [21, 23, 42, 44, 53, 69, 80, 82, 91], "min2": [21, 23, 42, 44, 53, 69, 80, 82, 91], "min_child_weight": [22, 43, 52, 81], "min_df": [17, 37, 76], "min_impurity_decreas": 91, "min_impurity_split": 91, "min_sampl": [26, 47, 85], "min_samples_leaf": [13, 33, 72, 91], "min_samples_split": [13, 33, 72, 91], "min_token_len": [28, 49, 58, 87], "min_token_length": [28, 49, 58, 87], "min_weight_fraction_leaf": 91, "mind": [14, 16, 17, 22, 23, 27, 31, 34, 36, 43, 44, 48, 52, 53, 57, 61, 73, 75, 76, 81, 82, 86, 90, 91, 92, 95, 103], "mine": 1, "minibatchkmean": [26, 47, 56, 85], "miniconda": 10, "miniconda3": [10, 17, 19, 29, 31, 93], "miniforge3": [72, 73, 76, 78, 82, 90, 94], "minim": [5, 13, 21, 25, 26, 33, 42, 46, 47, 54, 55, 56, 72, 80, 84, 85, 91], "minimum": [8, 14, 16, 26, 28, 34, 36, 47, 49, 56, 58, 67, 73, 75, 85, 87], "minmaxscal": [16, 17, 36, 37, 65, 75, 76, 91], "minor": [6, 31, 61, 90], "mintemp": [30, 89, 102], "minut": [4, 12, 13, 24, 31, 32, 33, 45, 54, 61, 67, 72, 83, 90, 95], "miracl": 93, "miscalcul": 1, "miscfeatur": [21, 23, 42, 44, 53, 80, 82, 91], "miscfeature_gar2": [21, 42, 80], "miscfeature_miss": [21, 42, 80], "miscfeature_othr": [21, 42, 80], "miscfeature_sh": [21, 42, 80], "miscfeature_tenc": [21, 42, 80], "misclassifi": 100, "misconduct": 103, "miscval": [21, 23, 42, 44, 53, 69, 80, 82, 91], "mishaal": [1, 103], "mislead": [14, 20, 34, 41, 68, 73, 79], "miss": [10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 30, 31, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54, 55, 57, 60, 61, 63, 65, 68, 69, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 86, 89, 90, 91, 95, 97, 99, 100, 102, 103], "mist": 67, "mistak": [16, 22, 31, 36, 43, 52, 61, 75, 81, 90, 91, 97], "mit": [0, 1], "mithai": 49, "mitig": [11, 27, 48, 57, 86], "mitlp": [31, 90], "mitt": [28, 49, 58, 87], "mitten": [28, 49, 58, 87], "mix": [12, 21, 32, 42, 69, 80, 91, 92], "mixtur": [26, 28, 29, 47, 49, 50, 56, 58, 59, 85, 87, 88], "ml": [1, 2, 9, 11, 13, 16, 22, 26, 28, 29, 33, 36, 40, 43, 47, 49, 50, 52, 54, 56, 72, 75, 81, 85, 87, 88, 92], "ml_experi": [13, 14, 17, 33, 34, 37, 72, 73, 76, 95], "mlpclassifi": [29, 50, 59, 88], "mlpregressor": [29, 50, 59, 88], "mm": [30, 89, 102], "mmsto": [12, 32, 71], "mn": [21, 23, 42, 44, 53, 69, 80, 82, 91], "mnprv": [21, 23, 42, 44, 53, 69, 80, 82, 91], "mnww": [21, 23, 42, 44, 53, 69, 80, 82, 91], "mo": [28, 49, 58, 87], "mobil": [17, 28, 29, 37, 49, 50, 58, 59, 76, 88], "mobilenet": [29, 50, 59, 88], "mod": [21, 23, 42, 44, 53, 69, 80, 82, 91], "mode": [15, 16, 19, 36, 40, 53, 74, 75, 78, 99], "model": [1, 2, 11, 19, 20, 25, 26, 27, 30, 35, 40, 41, 46, 47, 48, 51, 55, 56, 60, 70, 78, 79, 84, 85, 86, 89, 91, 94, 96, 99, 102], "model_nam": [27, 48, 57, 86], "model_select": [12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 97, 98, 99, 100, 101, 102], "modelmatrix": 61, "modern": [1, 15, 28, 35, 49, 58, 74, 87, 91], "modif": [31, 61, 90], "modifi": [0, 10, 20, 31, 61, 79, 90, 92, 103], "modul": [9, 14, 20, 33, 34, 41, 64, 65, 72, 73, 79, 93], "moe": [19, 40, 78], "mole": [29, 50, 59, 88], "mom": [24, 45, 54, 83], "moment": [20, 79, 99, 101, 103], "moment_predictor": 92, "mon": [30, 51, 60, 89], "monarch": [28, 49, 58, 87], "monarchi": [28, 49, 58, 87], "mondai": [1, 18, 30, 51, 60, 89, 103], "mone": 67, "monei": [8, 31, 61, 67, 90], "monitor": [28, 49, 58, 87], "monkei": [12, 29, 32, 50, 59, 71, 88], "monotone_constraint": [22, 43, 52, 81], "montani": 93, "month": [14, 17, 21, 31, 37, 42, 51, 60, 61, 69, 73, 76, 80, 90, 102], "month_nam": [30, 51, 60, 63, 89, 102], "monthli": [31, 61, 90], "monthlycharg": [31, 61, 90], "montreal": [28, 49, 87, 93], "moon": [26, 47, 56, 85], "moosvi": [0, 1, 28, 49, 58, 87], "moral": [0, 84], "more": [1, 2, 5, 6, 7, 8, 10, 12, 14, 19, 22, 23, 25, 27, 28, 29, 31, 32, 40, 43, 44, 46, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 64, 65, 67, 70, 73, 78, 81, 82, 84, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 103], "morn": [12, 32, 71], "morpholog": [28, 49, 58, 87], "morri": 67, "morton": 67, "moskowitz": [25, 46, 84], "mosold": [21, 23, 42, 44, 53, 69, 80, 82, 91], "mosold_1": [21, 42, 80], "mosold_10": [21, 42, 80], "mosold_11": [21, 42, 80], "mosold_12": [21, 42, 80], "mosold_2": [21, 42, 80], "mosold_3": [21, 42, 80], "mosold_4": [21, 42, 80], "mosold_5": [21, 42, 80], "mosold_6": [21, 42, 80], "mosold_7": [21, 42, 80], "mosold_8": [21, 42, 80], "mosold_9": [21, 42, 80], "most": [7, 8, 10, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 69, 72, 73, 74, 75, 76, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 101, 103], "most_confident_i": [18, 39, 77], "most_confident_x": [18, 39, 77], "most_frequ": [13, 15, 16, 20, 21, 23, 33, 35, 36, 41, 42, 44, 53, 65, 68, 69, 72, 74, 75, 79, 80, 82, 91, 96], "most_neg": 38, "most_negative_id": [66, 67], "most_posit": 38, "most_positive_id": [66, 67], "most_similar": [28, 49, 58, 87], "mostli": [8, 17, 30, 37, 51, 60, 76, 89], "motiv": [12, 17, 32, 37, 55, 71, 76], "mountginini": [30, 89], "move": [7, 18, 23, 24, 38, 39, 44, 45, 53, 54, 66, 67, 77, 82, 83, 96, 101, 103], "movi": [18, 28, 38, 39, 49, 58, 66, 67, 77, 87, 93], "movie_feats_df": [27, 48, 57, 86], "movie_id": [27, 48, 57, 86], "movie_nam": [27, 48, 57, 86], "movies_rated_by_pat": [27, 48, 57, 86], "movies_to_pr": [27, 48, 57, 86], "movieto": 93, "mpimg": [29, 50, 59, 88], "mr": 67, "mri": 95, "mrtssm448usn": [30, 51, 60, 89], "mse": [13, 27, 33, 48, 57, 72, 86, 92, 95], "msg": [17, 31, 37, 61, 76, 90], "msg_dtype": 65, "msg_err": 65, "mssubclass": [21, 23, 42, 44, 53, 69, 80, 82, 91], "mssubclass_120": [21, 42, 53, 80], "mssubclass_160": [21, 42, 53, 80], "mssubclass_180": [21, 42, 53, 80], "mssubclass_190": [21, 42, 53, 80], "mssubclass_20": [21, 42, 80], "mssubclass_30": [21, 42, 80], "mssubclass_40": [21, 42, 80], "mssubclass_45": [21, 42, 80], "mssubclass_50": [21, 42, 80], "mssubclass_60": [21, 42, 80], "mssubclass_70": [21, 42, 80], "mssubclass_75": [21, 42, 80], "mssubclass_80": [21, 42, 80], "mssubclass_85": [21, 42, 53, 80], "mssubclass_90": [21, 42, 53, 80], "mszone": [21, 23, 42, 44, 53, 80, 82, 91], "mszoning_c": [21, 23, 42, 53, 80, 82], "mszoning_fv": [21, 42, 80], "mszoning_rh": [21, 42, 80], "mszoning_rl": [21, 42, 80], "mszoning_rm": [21, 42, 80], "mt1": [52, 54], "much": [4, 5, 8, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 41, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 67, 68, 72, 73, 74, 75, 76, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 97, 99, 103], "mueller": 1, "multi": [21, 23, 25, 28, 30, 41, 42, 44, 46, 49, 51, 53, 55, 58, 60, 69, 80, 82, 84, 87, 89, 92], "multi_class": [20, 41, 79, 94], "multi_output": 65, "multi_strategi": [22, 43, 52, 81], "multiclass": [29, 50, 59, 88, 92, 94], "multicoliniar": [23, 44, 53, 82], "multicultur": [28, 49, 58, 87], "multilevel": [21, 42, 69, 80], "multimod": [25, 46, 84], "multinomi": 94, "multipl": [7, 8, 14, 18, 19, 22, 23, 28, 29, 30, 31, 34, 39, 40, 43, 49, 50, 51, 52, 58, 59, 60, 61, 63, 73, 77, 78, 81, 82, 87, 88, 89, 90, 102], "multiplelin": [31, 61, 90], "multiplelines_no": [31, 61, 90], "multiplelines_y": [31, 61, 90], "multipli": [18, 19, 20, 22, 24, 31, 39, 40, 43, 45, 52, 54, 61, 69, 77, 78, 79, 81, 83, 90], "murder": 67, "music": [27, 48, 57, 65, 67, 86, 93], "musqueam": 103, "must": [0, 6, 7, 8, 12, 13, 14, 16, 23, 26, 28, 31, 32, 33, 36, 43, 44, 47, 49, 53, 56, 58, 61, 67, 72, 73, 75, 82, 85, 87, 90, 93], "mustn": [28, 49, 58, 87], "mutat": 58, "mutual": [26, 47, 56, 85], "my": [6, 10, 12, 20, 28, 32, 40, 41, 49, 56, 58, 67, 71, 78, 79, 84, 87, 91, 92, 93, 103], "my_heatmap": [19, 40, 78, 99], "my_map": [21, 42, 69, 80], "mypreprocessor": [28, 49, 58, 87], "myself": [28, 49, 58, 72, 87, 91], "m\u00fcller": 9, "n": [1, 13, 15, 18, 19, 21, 22, 23, 24, 26, 27, 28, 30, 33, 35, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54, 56, 57, 58, 60, 61, 64, 65, 66, 67, 69, 72, 74, 77, 78, 80, 81, 82, 83, 85, 86, 87, 89, 91, 93, 94, 97, 102], "n_bin": [24, 45, 54, 83], "n_class": [15, 20, 35, 41, 74, 79, 100], "n_cluster": [25, 26, 46, 47, 55, 56, 70, 84, 85], "n_clusters_per_class": [20, 79], "n_compon": [28, 49, 58, 87], "n_constitu": [22, 43, 52, 81], "n_estim": [24, 30, 31, 45, 51, 54, 60, 61, 83, 89, 90, 91], "n_estimators_valu": 91, "n_exampl": [25, 46, 55, 84], "n_feat": [15, 35, 74], "n_featur": [15, 20, 25, 35, 46, 55, 74, 79, 84, 99], "n_features_to_select": [24, 45, 54, 83], "n_imag": [64, 70], "n_img": 70, "n_inform": [20, 79], "n_init": [25, 46, 55, 70, 84], "n_iter": 99, "n_job": [17, 20, 21, 22, 37, 41, 42, 43, 52, 61, 69, 76, 79, 80, 81, 91, 99], "n_neighbor": [27, 48, 57, 64, 86, 97], "n_neighbors_selector": [15, 35, 74], "n_neighbors_widget": [15, 35, 64, 74, 97], "n_peopl": 65, "n_redund": [20, 79], "n_rental": [30, 51, 60, 89], "n_rentalsin3hour": [30, 51, 60, 89], "n_rentalsin6hour": [30, 51, 60, 89], "n_repeat": [23, 44, 53, 82], "n_resourc": [19, 40, 78], "n_sampl": [15, 20, 25, 26, 29, 35, 41, 46, 47, 50, 55, 56, 59, 74, 79, 84, 85, 88, 94, 100], "n_samples_seen_": 61, "n_split": [30, 51, 60, 89], "n_threshold": [20, 68, 79], "n_top_feat": [66, 67], "n_top_featur": [38, 66, 67], "n_topic": [28, 49, 58, 87], "n_train": [30, 51, 60, 89], "n_word": [28, 49, 58, 87, 93], "na": [21, 23, 42, 44, 53, 69, 80, 82, 91], "nafter": [28, 49, 58, 87], "nah": [17, 37, 76], "naiv": [26, 56, 85], "name": [1, 4, 5, 6, 7, 8, 10, 13, 15, 16, 17, 19, 20, 22, 23, 24, 25, 28, 29, 30, 31, 33, 35, 36, 37, 40, 41, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 59, 60, 61, 63, 64, 65, 66, 67, 72, 74, 75, 76, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 93, 97, 101, 102, 103], "named_estimators_": [22, 43, 52, 81], "named_step": [18, 20, 21, 22, 23, 24, 30, 38, 39, 41, 42, 43, 44, 45, 52, 53, 54, 66, 67, 69, 77, 79, 80, 81, 82, 83, 89, 91, 93, 102], "named_transformers_": [17, 20, 21, 22, 23, 24, 30, 31, 37, 41, 42, 43, 44, 45, 52, 53, 54, 61, 65, 69, 76, 79, 80, 81, 82, 83, 89, 90, 91, 93, 100, 102], "namespac": [61, 65], "nan": [16, 17, 20, 21, 22, 23, 24, 27, 30, 31, 36, 37, 41, 42, 43, 44, 45, 48, 51, 52, 53, 57, 60, 61, 65, 75, 76, 79, 80, 81, 82, 83, 86, 89, 90, 91, 93, 95, 100, 102], "nanmean": [27, 48, 57, 86], "nanosecond": [30, 51, 89], "narr": [28, 49, 58, 87], "narrat": 67, "narrow": [12, 27, 32, 48, 57, 86, 91], "nasali": [12, 29, 32, 50, 59, 71, 88], "nation": 103, "nativ": [20, 22, 23, 29, 41, 43, 44, 50, 52, 53, 59, 65, 79, 81, 82, 88, 94, 100], "natur": [2, 11, 12, 17, 20, 22, 24, 29, 37, 43, 45, 50, 54, 59, 65, 71, 76, 79, 81, 83, 88, 92, 94], "navig": [7, 10, 92], "nbsp": [12, 32, 71, 75, 76, 78, 80, 81, 82, 83, 88, 91], "nbviewer": [12, 16, 17, 19, 20, 21, 22, 23, 24, 29, 32, 36, 37, 40, 41, 42, 43, 44, 45, 50, 52, 53, 55, 59, 63, 64, 65, 67, 71, 75, 76, 78, 79, 80, 81, 82, 83, 88, 91, 93], "nc": 1, "ncol": [18, 39, 77], "ndarrai": [8, 17, 37, 61, 65, 76], "ndate": 93, "ndframe": [24, 31, 45, 61, 83, 90], "ndim": [8, 65], "ne": [30, 89, 102], "nearbi": [15, 25, 35, 46, 55, 74, 84], "nearest": [20, 26, 47, 56, 64, 65, 79, 85, 97], "nearestneighbor": 64, "nearestneighborsifittednearestneighbor": 64, "nearli": [63, 67], "necessari": [0, 7, 13, 19, 39, 40, 65, 72, 78, 95, 98], "necessarili": [14, 21, 22, 27, 34, 42, 43, 48, 52, 57, 73, 80, 81, 86, 92], "neck": 67, "necvq": [31, 61, 90], "need": [5, 7, 8, 10, 12, 13, 15, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 35, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 60, 61, 63, 64, 65, 68, 69, 70, 71, 72, 74, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 98, 99, 101, 102, 103], "needn": [28, 49, 58, 87], "neg": [13, 14, 15, 18, 21, 22, 23, 28, 30, 31, 33, 34, 35, 39, 42, 43, 44, 49, 52, 53, 58, 61, 69, 72, 73, 74, 77, 80, 81, 82, 87, 89, 90, 93, 97, 100], "neg_mean_absolute_percentage_error": [21, 42, 69, 80], "neg_mean_squared_error": [21, 42, 69, 80, 91], "neg_prob": [38, 66, 67], "neg_root_mean_square_error": [21, 42, 69, 80], "neg_root_mean_squared_error": [21, 42, 69, 80], "neigh": [15, 35, 64, 74], "neighbor": [15, 16, 17, 18, 20, 24, 26, 35, 36, 37, 39, 45, 47, 54, 56, 64, 65, 74, 75, 76, 77, 79, 83, 85, 97, 98], "neighborhood": [18, 21, 23, 39, 42, 44, 53, 77, 80, 82, 91], "neighborhood_blmngtn": [21, 42, 80], "neighborhood_bluest": [21, 42, 80], "neighborhood_brdal": [21, 42, 80], "neighborhood_brksid": [21, 42, 80], "neighborhood_clearcr": [21, 42, 80], "neighborhood_collgcr": [21, 42, 80], "neighborhood_crawfor": [21, 42, 80], "neighborhood_edward": [21, 42, 80], "neighborhood_gilbert": [21, 42, 80], "neighborhood_idotrr": [21, 42, 80], "neighborhood_meadowv": [21, 42, 80], "neighborhood_mitchel": [21, 42, 80], "neighborhood_nam": [21, 42, 80], "neighborhood_noridg": [21, 42, 80, 82], "neighborhood_npkvil": [21, 42, 80], "neighborhood_nridght": [21, 23, 42, 53, 80, 82], "neighborhood_nwam": [21, 42, 80], "neighborhood_oldtown": [21, 42, 80, 82], "neighborhood_sawy": [21, 42, 80, 82], "neighborhood_sawyerw": [21, 42, 80, 82], "neighborhood_somerst": [21, 42, 80, 82], "neighborhood_stonebr": [21, 23, 42, 53, 80, 82], "neighborhood_swisu": [21, 42, 80, 82], "neighborhood_timb": [21, 42, 80, 82], "neighborhood_veenk": [21, 42, 80, 82], "neighborsbas": 65, "neighbour": [14, 25, 26, 28, 46, 47, 49, 53, 55, 56, 64, 73, 82, 84, 85, 87, 97], "neighbourhood": [18, 24, 26, 39, 45, 47, 54, 56, 77, 83, 85, 98], "neither": [14, 17, 27, 34, 37, 48, 57, 73, 76, 86], "neo": [1, 103], "neq": [23, 27, 44, 48, 53, 57, 82, 86], "ner": [28, 49, 58, 87], "nervou": [13, 33, 72], "nest": [19, 40, 78, 95], "net": [29, 31, 50, 54, 59, 61, 88, 90], "netflix": [27, 48, 52, 57, 86, 93], "netherland": 53, "network": [1, 11, 12, 17, 22, 24, 25, 27, 30, 32, 37, 43, 45, 46, 48, 51, 52, 54, 55, 57, 60, 70, 71, 76, 81, 83, 84, 86, 87, 89, 92], "neu": 93, "neural": [1, 11, 24, 30, 45, 51, 54, 60, 83, 89], "neutral": 93, "never": [20, 22, 23, 27, 29, 31, 41, 43, 44, 48, 50, 52, 53, 57, 59, 61, 79, 81, 82, 86, 88, 90], "nevertheless": 103, "new": [1, 10, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 95, 98, 99, 101, 102], "new_cent": [25, 46, 55, 84], "new_column": [21, 23, 30, 31, 42, 44, 53, 61, 69, 80, 82, 89, 90, 91, 102], "new_data": [31, 61, 90], "new_df": [30, 89, 102], "new_exampl": [13, 25, 33, 46, 55, 72, 84], "new_feature_nam": [30, 89, 102], "new_text": 50, "new_valu": [31, 61, 90], "newaxi": 8, "newcastl": 93, "newer": [21, 42, 69, 80], "newli": [16, 21, 24, 26, 36, 42, 45, 47, 54, 56, 75, 80, 83, 85], "newsgroup": [28, 49, 58, 87], "newswir": [28, 49, 58, 87], "next": [1, 10, 13, 14, 15, 16, 18, 20, 21, 22, 28, 29, 30, 33, 35, 36, 40, 41, 42, 43, 49, 50, 51, 52, 58, 59, 60, 61, 64, 65, 68, 70, 72, 73, 74, 75, 76, 79, 80, 81, 87, 88, 89, 91, 98, 99, 100, 101, 103], "nfeat": [15, 35, 74], "nfeats_accuraci": [15, 35, 74], "ng": [1, 9, 19, 24, 40, 45, 54, 78, 83], "ngram": [24, 45, 54, 83], "ngram_rang": [17, 37, 76], "nhl": [28, 49, 58, 87], "nhqxu": [31, 90], "nice": [4, 12, 19, 20, 22, 23, 26, 29, 31, 32, 41, 43, 44, 47, 50, 52, 53, 59, 61, 67, 68, 69, 78, 79, 81, 82, 85, 88, 90, 91, 92], "nicki": [40, 78], "night": [20, 30, 51, 79, 89, 92], "nightmar": 91, "niki": [1, 103], "nlemma": [28, 49, 58, 87], "nlp": [17, 29, 37, 50, 59, 76, 88, 93], "nltk": [28, 49, 58, 87, 93], "nltk_data": [28, 49, 58, 87, 93], "nmax": 91, "nn": [1, 16, 29, 36, 38, 50, 59, 64, 66, 67, 70, 75, 88, 93, 97], "nne": [30, 89, 102], "nnw": [30, 89, 102], "nnz": [17, 37, 76], "no_grad": [29, 50, 59, 64, 70, 88], "no_val_i": 61, "no_val_x": [61, 65], "nobodi": [12, 71], "node": [13, 22, 26, 29, 33, 43, 47, 50, 52, 56, 59, 72, 81, 85, 88, 96], "nois": [26, 47, 56, 85, 95, 97], "noise_cat": 65, "noise_level": 65, "non": [1, 8, 12, 13, 14, 16, 18, 19, 20, 21, 22, 24, 26, 27, 29, 30, 31, 32, 33, 34, 36, 39, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 54, 56, 57, 60, 61, 68, 71, 72, 73, 75, 77, 78, 79, 80, 81, 83, 85, 86, 88, 89, 90, 92, 95, 100, 102, 103], "noncommerci": 1, "none": [1, 14, 16, 17, 18, 19, 20, 22, 24, 26, 30, 31, 34, 36, 37, 39, 40, 41, 43, 45, 47, 51, 52, 54, 56, 61, 65, 67, 73, 75, 76, 77, 78, 79, 81, 83, 85, 89, 90, 91, 93, 101], "noninfring": 0, "nonzero": [17, 37, 76], "noodl": [58, 65], "noqa": [19, 40, 78, 93], "nor": [7, 14, 17, 28, 34, 37, 49, 58, 73, 76, 87], "norg": [28, 49, 58, 87, 93], "norm": [19, 28, 40, 49, 54, 58, 65, 70, 78, 87], "normal": [6, 20, 21, 22, 23, 25, 26, 28, 29, 30, 36, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 64, 65, 68, 69, 70, 79, 80, 81, 82, 84, 85, 87, 88, 89, 91, 93, 100, 101], "north": [28, 49, 58, 87], "north_america": 65, "norvig": 1, "notat": [15, 74], "note": [0, 1, 3, 7, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 27, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 48, 52, 53, 54, 56, 57, 58, 60, 68, 69, 72, 74, 75, 76, 77, 78, 79, 81, 82, 83, 86, 92, 94, 95, 99, 100, 102, 103], "notebook": [5, 7, 9, 10, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 29, 34, 36, 37, 40, 41, 42, 43, 44, 45, 50, 52, 53, 55, 59, 63, 64, 65, 67, 69, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 88, 91, 93, 98, 102], "noth": 67, "notic": [0, 17, 18, 20, 21, 24, 37, 39, 41, 42, 45, 54, 60, 65, 67, 69, 76, 77, 79, 80, 83], "notion": [15, 19, 25, 27, 35, 40, 46, 48, 55, 57, 74, 78, 84, 86], "notna": [30, 89, 102], "noun": [28, 49, 58, 87, 93], "nov": [30, 89], "novel": 95, "novemb": [30, 51, 60, 89], "novic": 9, "now": [8, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 91, 92, 93, 96, 97, 98, 99, 100, 101], "np": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 99, 100, 101, 102], "nperson": 93, "npie": 8, "npo": [28, 49, 58, 87], "npr": [24, 28, 45, 49, 54, 58, 83, 87, 93, 95], "npt": [61, 65], "nsubj": [28, 49, 58, 87], "ntest": [15, 19, 35, 40, 64, 74, 78, 97], "ntoken": [28, 49, 58, 87], "ntree": [22, 43, 81], "null": [16, 17, 20, 21, 24, 30, 31, 36, 37, 41, 42, 45, 54, 61, 75, 76, 79, 80, 83, 89, 90, 102], "null_distribut": [31, 61, 90], "num": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "num_output_channel": [29, 50, 59, 88], "num_parallel_tre": [22, 43, 52, 81], "num_sent": [20, 79, 92], "num_thread": [29, 50], "num_work": [29, 50, 59, 64, 70, 88], "number": [1, 4, 6, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 87, 88, 90, 92, 95, 97, 99, 102, 103], "number_test": [19, 40, 78], "numberbatch": [28, 49, 87], "numer": [2, 13, 16, 17, 18, 20, 21, 22, 27, 28, 30, 31, 33, 36, 37, 39, 41, 42, 43, 48, 49, 51, 52, 57, 58, 60, 64, 65, 68, 69, 72, 75, 76, 77, 79, 80, 81, 86, 87, 89, 90, 91, 97, 98, 100, 102], "numeric_feat": [17, 19, 24, 37, 40, 45, 54, 65, 76, 78, 83, 95, 99], "numeric_featur": [20, 21, 22, 23, 30, 31, 41, 42, 43, 44, 52, 53, 61, 69, 76, 79, 80, 81, 82, 89, 90, 91, 93, 100, 101, 102], "numeric_looking_column": [21, 42, 69, 80], "numeric_transform": [20, 21, 22, 23, 30, 41, 42, 43, 44, 52, 53, 65, 69, 76, 79, 80, 81, 82, 89, 91, 100, 101, 102], "numpi": [9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 99, 100, 101, 102], "numpy_dtyp": [31, 61, 90], "numpyro": 59, "nuniqu": 63, "nutrit": [28, 49, 58, 87], "nw": [30, 89, 102], "nwith": [15, 35, 74], "ny": 93, "nyre": 67, "nyt": 91, "o": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102], "obelisk": [29, 50, 59, 88], "object": [14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 54, 55, 63, 65, 66, 67, 69, 73, 75, 76, 77, 78, 79, 80, 82, 83, 84, 93, 95, 96, 97, 99, 100, 102], "observ": [12, 13, 14, 15, 22, 23, 25, 26, 30, 31, 32, 33, 34, 35, 43, 44, 46, 47, 51, 52, 53, 54, 55, 60, 61, 64, 71, 72, 73, 74, 81, 82, 84, 85, 89, 90, 97, 100, 101, 102], "obtain": [0, 18, 25, 26, 27, 31, 38, 39, 46, 47, 48, 55, 56, 57, 61, 64, 66, 67, 77, 84, 85, 86, 90, 97, 99], "obviou": [26, 28, 47, 49, 56, 58, 85, 87], "obvious": 67, "occasion": [20, 41, 68, 79], "occup": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "occupation_arm": 53, "occupation_farm": [23, 44, 53, 82], "occupation_miss": [23, 44, 53, 82], "occupation_priv": [23, 44, 53, 82], "occupi": 103, "occur": [8, 13, 14, 17, 28, 31, 33, 34, 37, 49, 58, 61, 72, 73, 76, 87, 90], "occurr": [28, 31, 49, 58, 61, 87, 90], "ocean": [16, 24, 36, 45, 54, 75, 76, 83, 98], "ocean_proxim": [16, 24, 36, 45, 54, 75, 76, 83, 98], "ocean_proximity_": [16, 36, 75, 76], "ocean_proximity_inland": [16, 36, 75, 76], "ocean_proximity_island": [16, 36, 75, 76], "ocean_proximity_near": [16, 36, 75, 76], "oct": 77, "octob": [30, 63, 89], "oe": [17, 37, 76, 95], "oe_encod": 95, "off": [11, 18, 19, 20, 21, 24, 25, 28, 29, 31, 39, 40, 41, 42, 45, 46, 49, 50, 54, 55, 58, 59, 61, 64, 67, 68, 69, 70, 77, 78, 79, 80, 83, 84, 87, 88, 90, 91, 95, 99], "off_shelf": 101, "offens": 4, "offer": [8, 22, 27, 28, 31, 43, 48, 49, 52, 57, 58, 61, 67, 81, 86, 87, 90, 103], "offic": [1, 4, 10, 12, 95, 103], "offici": [28, 49, 58, 87, 103], "offlin": [27, 48, 57, 86], "offset": [18, 39, 77], "often": [8, 12, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 68, 71, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97], "ogunrind": [12, 32, 71], "oh": [23, 24, 29, 30, 31, 44, 45, 50, 51, 53, 54, 59, 60, 61, 65, 82, 83, 88, 89, 90, 92, 95, 99, 102, 103], "ohe_column": [21, 23, 42, 44, 53, 69, 80, 82, 91], "ohe_enc": [17, 37, 76], "ohe_encod": 95, "ohe_feat": 65, "ohe_feat_nam": 65, "ohe_feature_nam": [23, 30, 44, 53, 82, 89, 102], "ohehotencod": [17, 37, 76], "ois": [26, 47, 56, 85], "ok": [12, 15, 21, 30, 31, 32, 35, 42, 51, 60, 61, 67, 69, 71, 74, 80, 89, 90, 92, 95, 102], "okai": [84, 92], "ola": [28, 49, 58, 87], "old": [9, 22, 52, 53, 67, 81, 82], "old_cent": [25, 46, 84], "older": [21, 42, 69, 80], "oldpeak": 101, "olymp": 8, "omit": [23, 44, 53, 82], "omp_num_thread": [29, 50], "omw": [28, 49, 58, 87], "onc": [6, 7, 8, 10, 13, 14, 16, 17, 19, 24, 26, 27, 28, 29, 33, 34, 36, 37, 40, 45, 47, 48, 49, 50, 54, 56, 57, 58, 59, 64, 72, 73, 75, 76, 78, 83, 85, 86, 87, 88, 92, 99, 100, 101, 103], "onca": [12, 29, 32, 50, 59, 71, 88], "one": [6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 97, 99, 100, 101, 102, 103], "one_c": [15, 35, 74], "one_ex_preprocess": [23, 44, 53, 82], "one_ex_preprocessed_perturb": [23, 44, 53, 82], "one_exampl": [23, 44, 53, 82], "one_example_perturb": [23, 44, 53, 82], "onedr": 50, "onehot": [17, 24, 37, 45, 54, 76, 83], "onehotencod": [16, 18, 19, 20, 21, 22, 23, 24, 30, 31, 36, 39, 40, 41, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 65, 69, 75, 77, 78, 79, 80, 81, 82, 83, 89, 90, 91, 93, 95, 98, 99, 100, 101, 102], "onehotencoder__major_biologi": [17, 37, 76], "onehotencoder__major_comput": [17, 37, 76], "onehotencoder__major_econom": [17, 37, 76], "onehotencoder__major_linguist": [17, 37, 76], "onehotencoder__major_mathemat": [17, 37, 76], "onehotencoder__major_mechan": [17, 37, 76], "onehotencoder__major_phys": [17, 37, 76], "onehotencoder__major_psychologi": [17, 37, 76], "onehotencoderonehotencod": [17, 19, 21, 22, 37, 40, 42, 43, 52, 65, 76, 78, 80, 81, 91], "ones": [8, 12, 15, 16, 22, 23, 25, 27, 28, 32, 35, 36, 43, 44, 46, 48, 49, 52, 53, 55, 57, 58, 63, 64, 71, 74, 75, 81, 82, 84, 86, 87, 97, 101], "onevsoneclassifi": 94, "onevsrestclassifi": 94, "onigiri": 58, "onli": [2, 4, 8, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 65, 66, 67, 68, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 95, 97, 98, 100, 103], "onlin": [3, 5, 7, 10, 28, 33, 49, 58, 72, 87, 103], "onlinebackup": [31, 61, 90], "onlinebackup_no": [31, 61, 90], "onlinebackup_y": [31, 61, 90], "onlinesecur": [31, 61, 90], "onlinesecurity_no": [31, 61, 90], "onlinesecurity_y": [31, 61, 90], "onrend": 92, "ontario": [28, 49, 87], "ontonot": [28, 49, 58, 87], "oob_scor": 91, "op": [20, 41, 79], "open": [5, 6, 10, 12, 29, 32, 50, 54, 59, 71, 88, 92, 103], "openporchsf": [21, 23, 42, 44, 53, 69, 80, 82, 91], "oper": [4, 8, 10, 17, 24, 28, 37, 45, 49, 58, 76, 83, 87, 92], "opera": 67, "operand": 8, "opinion": [22, 43, 52, 81], "opportun": [27, 48, 57, 63, 86], "oppos": [21, 22, 42, 43, 52, 69, 80, 81], "opposit": [8, 21, 22, 23, 42, 43, 44, 53, 69, 80, 81, 82, 102], "opt": [10, 22, 43, 61, 64, 65, 81], "optic": [31, 61, 90], "optim": [1, 2, 13, 14, 15, 20, 22, 23, 24, 25, 26, 29, 31, 33, 34, 35, 38, 41, 43, 44, 45, 46, 47, 50, 52, 53, 54, 55, 56, 59, 61, 64, 66, 67, 68, 72, 73, 74, 76, 79, 81, 82, 83, 84, 85, 88, 90, 91, 92, 99], "optimist": [19, 40, 78], "optimized_c": [38, 66, 67], "option": [1, 7, 8, 13, 21, 25, 28, 32, 33, 42, 43, 49, 58, 72, 80, 84, 87, 91, 99, 101, 102], "orang": [18, 39, 55, 77], "orch": 103, "order": [5, 7, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 60, 61, 65, 66, 67, 68, 69, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 89, 91, 92, 95], "ordering_ordinal_oth": [21, 23, 42, 44, 53, 69, 80, 82, 91], "ordering_ordinal_reg": [21, 23, 42, 44, 53, 69, 80, 82, 91], "ordin": [21, 42, 69, 80, 95, 98], "ordinal_feat": [17, 37, 65, 76], "ordinal_featur": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "ordinal_features_oth": [21, 23, 42, 44, 53, 69, 80, 82, 91], "ordinal_features_reg": [21, 23, 42, 44, 53, 69, 80, 82, 91], "ordinal_transform": [20, 22, 23, 41, 43, 44, 52, 53, 65, 79, 81, 82, 100], "ordinal_transformer_oth": [21, 23, 42, 44, 53, 69, 80, 82, 91], "ordinal_transformer_reg": [21, 23, 42, 44, 53, 69, 80, 82, 91], "ordinalencod": [16, 17, 20, 21, 22, 23, 24, 30, 31, 36, 37, 41, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 65, 69, 75, 76, 79, 80, 81, 82, 83, 89, 90, 91, 93, 95, 98, 100, 101, 102], "ordinalencoderordinalencod": [17, 21, 22, 37, 42, 43, 52, 65, 76, 80, 81, 91], "ordinari": [21, 42, 80], "oreilli": [29, 30, 50, 51, 59, 60, 88, 89], "org": [9, 12, 14, 16, 17, 19, 20, 21, 22, 23, 24, 28, 29, 32, 34, 36, 37, 40, 41, 42, 43, 44, 45, 49, 50, 52, 53, 55, 58, 59, 63, 64, 65, 67, 71, 73, 75, 76, 78, 79, 80, 81, 82, 83, 87, 88, 91, 93], "organ": [12, 13, 16, 28, 32, 33, 36, 49, 58, 71, 72, 75, 87, 91, 92], "orgin": 8, "orig_featur": [30, 89, 102], "orig_pr": [23, 44, 53, 82], "orig_scor": [20, 41, 79], "origin": [12, 16, 17, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 36, 37, 41, 43, 44, 48, 49, 50, 52, 53, 54, 57, 58, 59, 61, 75, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 90, 93, 97, 99, 102, 103], "original_hm": [20, 79, 92], "originaltweet": 93, "ornithorhynchu": [29, 50, 59, 88], "oscar": [18, 39, 77], "ostblom": [28, 49, 58, 87], "other": [0, 1, 4, 5, 6, 7, 10, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 26, 27, 29, 32, 33, 34, 36, 37, 39, 40, 41, 43, 44, 47, 48, 50, 52, 53, 56, 57, 59, 63, 64, 65, 67, 68, 69, 70, 72, 73, 75, 76, 77, 78, 79, 81, 82, 85, 86, 88, 92, 93, 94, 95, 97, 99, 100, 101, 102, 103], "otherwis": [0, 7, 17, 37, 76], "ounc": [12, 29, 32, 50, 59, 71, 88], "our": [5, 6, 8, 10, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 99, 100, 101, 102, 103], "ourselv": [13, 20, 28, 29, 30, 33, 41, 49, 50, 58, 59, 68, 72, 79, 87, 88, 89], "out": [0, 1, 4, 7, 8, 10, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 60, 61, 63, 65, 67, 68, 69, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 84, 85, 86, 87, 89, 90, 93, 95, 97, 99, 101, 102, 103], "out_col": [14, 16, 34, 36, 54, 61, 73, 75, 93], "out_step": [20, 79], "outer": 93, "outlier": [21, 26, 42, 47, 56, 65, 69, 80, 85, 92, 95], "outlook": [31, 61, 90], "output": [7, 8, 10, 12, 13, 14, 17, 18, 20, 22, 23, 28, 29, 30, 32, 33, 34, 37, 39, 41, 43, 44, 49, 50, 51, 52, 53, 59, 60, 61, 65, 68, 70, 71, 72, 73, 76, 77, 79, 81, 82, 87, 88, 89, 91, 92, 95, 101, 102, 103], "outsid": [7, 20, 22, 23, 27, 28, 30, 31, 41, 43, 44, 48, 49, 51, 52, 53, 57, 60, 61, 68, 79, 81, 82, 86, 87, 89, 90], "over": [14, 19, 21, 28, 29, 30, 31, 40, 41, 42, 49, 50, 51, 58, 59, 60, 61, 69, 73, 78, 80, 87, 88, 89, 90, 91, 92, 95, 103], "over_confident_i": [18, 39, 77], "over_confident_x": [18, 39, 77], "over_sampl": [20, 79], "overal": [10, 20, 23, 25, 28, 29, 38, 41, 44, 46, 49, 50, 53, 55, 59, 65, 66, 67, 70, 79, 82, 84, 87, 88, 91, 95, 100, 101, 103], "overallcond": [21, 23, 42, 44, 53, 69, 80, 82, 91], "overallqu": [21, 23, 42, 44, 53, 69, 80, 82, 91], "overconfid": [23, 24, 44, 45, 53, 54, 82, 83, 92], "overcrowd": 103, "overfit": [1, 11, 15, 18, 21, 22, 24, 29, 35, 38, 39, 42, 43, 45, 50, 52, 54, 59, 63, 64, 66, 67, 69, 74, 77, 80, 81, 83, 88, 92, 97, 99, 101], "overflow": 7, "overhead": [17, 37, 61, 76], "overlap": [2, 14, 25, 34, 39, 46, 55, 73, 84, 92], "overli": [15, 19, 35, 40, 64, 74, 78, 97], "overload": [27, 31, 48, 57, 61, 86, 90], "overpredict": [21, 42, 80], "oversampl": 41, "oversample_pip": [20, 79], "overshadow": [28, 49, 58, 87], "overst": 91, "overus": [22, 43, 52, 81], "overview": [25, 26, 27, 28, 46, 47, 48, 49, 56, 84, 85, 86, 87], "overwhelm": 84, "overwrite_a": 61, "overwrite_b": 61, "overzeal": 6, "own": [4, 5, 8, 12, 14, 16, 20, 21, 23, 24, 25, 26, 28, 29, 30, 32, 36, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 58, 60, 67, 68, 73, 75, 79, 80, 82, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 102], "oz": 67, "p": [18, 19, 26, 28, 31, 39, 40, 47, 49, 56, 58, 61, 67, 77, 78, 85, 87, 90, 92], "p_i": [25, 46, 55, 84], "p_value_threshold": [31, 61, 90], "pace": [18, 28, 39, 49, 58, 67, 77, 84, 87, 103], "packag": [5, 8, 11, 17, 19, 20, 23, 25, 26, 27, 28, 29, 31, 33, 37, 40, 41, 44, 46, 47, 48, 49, 50, 53, 55, 56, 58, 59, 61, 64, 65, 68, 72, 73, 76, 78, 79, 82, 84, 85, 86, 87, 88, 90, 92, 93, 94], "pad": [29, 50, 59, 64, 70, 88], "page": [1, 4, 7, 12, 16, 17, 19, 20, 21, 22, 23, 24, 28, 29, 32, 36, 37, 40, 41, 42, 43, 44, 45, 49, 50, 52, 53, 55, 58, 59, 63, 64, 65, 67, 71, 75, 76, 78, 79, 80, 81, 82, 83, 87, 88, 91, 93, 101, 103], "pai": [23, 44, 53, 82, 92], "pain": [4, 29, 30, 50, 59, 88, 89, 91, 102], "pair": [26, 28, 47, 49, 56, 58, 85, 87, 94], "pairwis": [15, 26, 35, 47, 56, 74, 85], "panda": [9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102], "pandas_profil": 69, "pane": [15, 35, 64, 74, 97], "panel": [15, 20, 23, 25, 26, 35, 41, 44, 46, 47, 53, 56, 64, 68, 74, 79, 82, 84, 85, 97], "panic": 93, "panther": [12, 29, 32, 50, 59, 71, 88], "panthera": [12, 29, 32, 50, 59, 71, 88], "paper": [7, 23, 24, 28, 29, 31, 44, 45, 49, 50, 53, 54, 58, 59, 61, 82, 83, 87, 88, 90, 92, 93], "paperlessbil": [31, 61, 90], "paperlessbilling_no": [31, 61, 90], "paperlessbilling_y": [31, 61, 90], "paradigm": [12, 13, 25, 28, 32, 33, 46, 49, 55, 58, 71, 72, 84, 87], "paradox": [27, 48, 86], "paragraph": [28, 49, 58, 87], "paraleg": [28, 49, 58, 87], "parallel": [17, 19, 22, 29, 37, 40, 43, 50, 52, 61, 76, 78, 81], "paralleln": [29, 50], "param": [15, 17, 19, 21, 35, 37, 40, 42, 61, 64, 74, 76, 78, 80, 97], "param_columntransformer__countvectorizer__max_featur": [19, 40, 78], "param_columntransformer__pipeline__polynomialfeatures__degre": 19, "param_dist": [19, 40, 78, 99], "param_distribut": [19, 40, 78, 99], "param_grid": [14, 15, 19, 21, 34, 35, 40, 42, 69, 73, 74, 78, 80, 91, 99], "param_grid1": [19, 40, 78, 99], "param_grid2": [19, 40, 78, 99], "param_grid3": [19, 40, 78], "param_grid4": [19, 40, 78], "param_ridge__alpha": [21, 42, 69, 80], "param_svc__c": [19, 40, 78], "param_svc__gamma": [19, 40, 78], "param_svc__kernel": 19, "paramet": [15, 16, 17, 21, 22, 25, 26, 28, 30, 31, 35, 36, 37, 43, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 61, 64, 65, 74, 75, 76, 80, 81, 82, 84, 85, 87, 89, 90, 91, 93, 96, 97, 99, 100, 101, 102], "parametr": [26, 47, 56, 85], "params_": [31, 61, 90], "params_str": [19, 40, 78], "paramter": [15, 35, 74], "pardu": [12, 29, 32, 50, 59, 71, 88], "parent": [26, 47, 56, 67, 85, 93], "park": [24, 29, 45, 50, 54, 59, 83, 88, 92, 93], "pars": [28, 49, 87], "parse_d": [8, 30, 51, 60, 89, 102], "parser": [28, 49, 58, 87], "part": [1, 4, 9, 10, 16, 17, 18, 19, 20, 22, 23, 24, 26, 28, 30, 36, 39, 40, 41, 43, 44, 45, 47, 49, 51, 52, 53, 54, 56, 58, 60, 67, 68, 75, 76, 77, 78, 79, 81, 82, 83, 85, 87, 89, 91, 92, 93, 101, 103], "part1": [27, 48, 57, 86], "part2": [27, 48, 57, 86], "parti": [28, 49, 58, 87], "partial": [4, 31, 61, 90, 91], "partial_fit": 61, "particip": 103, "particular": [0, 9, 10, 16, 17, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 36, 37, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 75, 76, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 97, 100], "particularli": [22, 27, 43, 48, 52, 57, 67, 81, 86, 103], "partit": [17, 25, 26, 37, 46, 47, 55, 56, 76, 84, 85], "partner": [31, 61, 90, 103], "partner_no": [31, 61, 90], "partner_y": [31, 61, 90], "parton": 93, "pass": [8, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 28, 29, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 49, 50, 52, 54, 55, 58, 59, 64, 65, 68, 69, 70, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 87, 88, 97, 103], "passthrough": [17, 19, 31, 37, 40, 61, 76, 78, 90, 93, 99, 101], "passthrough__ml_experi": [17, 37, 76], "passthrough_feat": [17, 19, 37, 40, 76, 78, 95, 99], "passthrough_featur": [31, 61, 90, 93, 101], "passthroughpassthrough": [17, 19, 37, 40, 76, 78, 93], "past": [13, 14, 30, 31, 33, 34, 43, 51, 52, 60, 61, 72, 73, 81, 89, 90, 91, 95], "pat": [27, 48, 86], "pat_i": [27, 48, 57, 86], "pat_model": [27, 48, 57, 86], "pat_x": [27, 48, 57, 86], "pata": [12, 29, 32, 50, 59, 71, 88], "path": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102], "pathlib": 70, "patial": [26, 47, 56, 85], "patient": [13, 33, 72, 92, 101], "patio": [29, 50, 59, 88], "patric": [23, 44, 53, 82], "patricia": 67, "patrick": [1, 103], "pattern": [12, 13, 14, 17, 19, 24, 25, 28, 30, 32, 33, 34, 37, 40, 45, 46, 49, 51, 54, 55, 58, 60, 63, 71, 72, 73, 76, 78, 83, 84, 87, 89, 91, 97, 102], "paus": 67, "pav_bhaji": [28, 49, 87], "pave": [21, 23, 42, 44, 53, 80, 82, 91], "paveddr": [21, 23, 42, 44, 53, 80, 82, 91], "paveddrive_i": [21, 42, 80], "paveddrive_n": [21, 42, 80], "paveddrive_p": [21, 42, 80], "paymentmethod": [31, 61, 90], "paymentmethod_bank": [31, 61, 90], "paymentmethod_credit": [31, 61, 90], "paymentmethod_electron": [31, 61, 90], "paymentmethod_mail": [31, 61, 90], "pca": [20, 26, 27, 41, 47, 48, 56, 57, 68, 79, 85, 86], "pcarter": 9, "pd": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102], "pdf": [7, 9], "peac": [28, 49, 58, 87], "peck": 67, "pedest": [29, 50, 59, 88], "pedro": [1, 14, 24, 45, 54, 73, 83], "peek": 102, "peer": [92, 95, 103], "pembrok": [12, 29, 32, 50, 59, 71, 88], "penal": [6, 31, 61, 90], "penalti": [20, 28, 41, 49, 58, 61, 79, 87, 103], "peopl": [4, 13, 14, 16, 18, 20, 25, 27, 28, 29, 30, 31, 33, 34, 36, 39, 41, 43, 46, 48, 49, 50, 51, 52, 57, 58, 59, 60, 61, 67, 72, 73, 75, 77, 79, 81, 84, 86, 87, 88, 89, 90, 91, 92, 93, 95, 97, 100, 103], "per": [8, 18, 20, 21, 22, 23, 27, 29, 30, 39, 41, 42, 43, 44, 48, 50, 52, 53, 57, 59, 69, 77, 79, 80, 81, 82, 86, 88, 89, 91, 94, 95, 99, 100, 102], "perceiv": 6, "percent": [21, 42, 69, 80], "percent_error": [21, 42, 69, 80], "percentag": [13, 20, 27, 33, 41, 48, 57, 72, 79, 86, 91], "perfect": [6, 13, 14, 20, 21, 23, 27, 31, 33, 34, 41, 42, 44, 48, 53, 57, 61, 63, 67, 68, 69, 72, 73, 79, 80, 82, 86, 90, 93], "perfectli": [2, 27, 28, 49, 57, 58, 86, 87], "perform": [11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 60, 63, 64, 67, 68, 69, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 91, 92, 93, 95, 96, 98, 99, 100, 101, 102], "performac": [14, 34, 73], "perhap": [21, 30, 42, 51, 60, 69, 80, 89, 94], "perimet": [24, 45, 54, 83], "period": [28, 30, 31, 49, 51, 58, 60, 61, 87, 89, 90, 93, 103], "perm_sorted_idx": [23, 44, 53, 82], "perman": 8, "permiss": [0, 103], "permit": [0, 16, 20, 36, 41, 75, 79, 103], "permut": [23, 25, 44, 53, 82], "persist": [27, 48, 86], "person": [0, 1, 4, 6, 12, 20, 25, 28, 29, 30, 31, 32, 41, 48, 49, 50, 51, 58, 59, 60, 61, 68, 71, 79, 84, 87, 88, 89, 90, 92, 93, 103], "perspect": [22, 27, 43, 48, 52, 57, 81, 86], "pertain": 5, "perthairport": [30, 89, 102], "perturb": [23, 26, 44, 47, 53, 56, 65, 82, 85], "perturbed_pr": [23, 44, 53, 82], "pertwe": 67, "pete_seeg": [28, 49, 87], "peter": [1, 67], "petter": 67, "ph": [28, 49, 58, 87], "pharma": 92, "phascolarcto": [29, 50, 59, 88], "phase": [14, 34, 73], "phd": [28, 49, 58, 87], "phdei": [31, 61, 90], "phenomenon": [27, 31, 48, 57, 61, 86, 90, 97], "philippin": [67, 93], "philosoph": [28, 49, 58, 87], "phone": [12, 31, 32, 61, 71, 90, 103], "phoneservic": [31, 61, 90], "phoneservice_no": [31, 61, 90], "phoneservice_y": [31, 61, 90], "photo": [93, 95], "photograph": 103, "phrase": [28, 49, 58, 87], "physic": [17, 30, 37, 51, 60, 76, 89], "pi": 8, "piazza": [1, 6, 7, 12, 13, 32, 54], "pick": [13, 18, 20, 22, 23, 24, 25, 26, 29, 33, 39, 41, 44, 45, 46, 47, 50, 52, 53, 54, 55, 56, 59, 63, 67, 68, 72, 77, 79, 81, 82, 83, 84, 85, 88, 91, 92, 94, 96, 97, 99, 100, 101], "pictur": [22, 23, 26, 28, 30, 43, 44, 47, 49, 51, 52, 53, 56, 58, 60, 81, 82, 85, 87, 89, 91], "pie": 8, "piec": [18, 31, 39, 61, 67, 77, 90], "pig": 49, "pil": [12, 29, 32, 50, 59, 64, 70, 71, 88], "pile": 67, "pin": [7, 29, 50, 59, 88], "pineappl": [28, 49, 58, 87], "pip": [10, 23, 28, 29, 44, 49, 50, 59, 82, 87, 88, 92, 93], "pipe": [16, 17, 18, 19, 20, 28, 29, 36, 37, 39, 40, 41, 43, 49, 50, 58, 59, 68, 75, 76, 77, 78, 79, 81, 87, 88, 93, 99, 100], "pipe_bestalpha": [21, 42, 69, 80], "pipe_bigalpha": [21, 42, 69, 80], "pipe_catboost": [43, 52, 81], "pipe_dt": [22, 23, 43, 44, 52, 53, 81, 82, 101], "pipe_forward": [24, 45, 54, 83], "pipe_knn": [65, 101], "pipe_lgbm": [22, 23, 43, 44, 52, 53, 81, 82, 101], "pipe_lr": [20, 22, 23, 38, 41, 43, 44, 52, 53, 66, 67, 68, 79, 81, 82, 92, 100, 101], "pipe_lr_all_feat": [24, 45, 83], "pipe_lr_balanc": [20, 41, 79, 100], "pipe_lr_model_bas": [24, 45, 54, 83], "pipe_lr_weight": [20, 41, 79, 100], "pipe_ohe_knn": 65, "pipe_ordinal_knn": 65, "pipe_rf": [22, 23, 43, 44, 52, 53, 81, 82, 101], "pipe_rf_demo": [22, 43, 52, 81], "pipe_ridg": [18, 21, 39, 42, 69, 77, 80], "pipe_sklearn_gb": [22, 43, 52, 81], "pipe_sklearn_histgb": [22, 43, 52, 81], "pipe_smallalpha": [21, 42, 69, 80], "pipe_svc": [20, 41, 65, 68, 79], "pipe_svm": [19, 40, 78, 99], "pipe_xgb": [22, 23, 43, 44, 52, 53, 81, 82], "pipe_xor": [24, 45, 54, 83], "pipelin": [1, 2, 11, 12, 14, 17, 18, 19, 20, 21, 22, 23, 24, 29, 30, 31, 32, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 50, 51, 52, 53, 54, 60, 61, 66, 67, 68, 69, 71, 73, 76, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 98, 99, 100, 101, 102], "pipeline__lab1": [17, 37, 76], "pipeline__lab2": [17, 37, 76], "pipeline__lab3": [17, 37, 76], "pipeline__lab4": [17, 37, 76], "pipeline__quiz1": [17, 37, 76], "pipeline__rooms_per_household": [24, 45, 54, 83], "pipeline__university_year": [17, 37, 76], "pipelineifittedpipelin": [16, 17, 19, 20, 24, 29, 36, 37, 40, 41, 45, 50, 59, 67, 75, 76, 78, 79, 83, 88, 93], "pipelineinot": [19, 21, 40, 42, 76, 78, 80], "pipelinepipelin": [19, 40, 78], "pitch": 91, "pitfal": [30, 51, 60, 89, 91], "pitt": 67, "pivot": 57, "pixel": [23, 44, 53, 82], "pizza": [28, 49, 58, 87], "pkg": 10, "pla": [28, 49, 58, 87], "place": [5, 28, 30, 49, 51, 58, 60, 87, 89, 103], "plagiar": 103, "plagu": 67, "plai": [13, 15, 19, 23, 26, 28, 33, 35, 40, 44, 47, 49, 53, 56, 58, 67, 72, 74, 78, 82, 85, 87, 96, 97], "plain": [25, 46, 84], "plan": [10, 12, 21, 24, 31, 32, 42, 54, 61, 69, 71, 80, 83, 90, 92, 93, 98, 101, 103], "plane": [18, 33, 39, 77], "plant": 95, "plastic": [28, 49, 58, 87], "platform": [4, 93], "platypu": [29, 50, 59, 88], "player": [23, 28, 29, 44, 49, 50, 53, 58, 59, 82, 87, 88], "pleas": [1, 4, 7, 10, 12, 16, 17, 19, 20, 21, 22, 23, 24, 29, 32, 36, 37, 40, 41, 42, 43, 44, 45, 50, 52, 53, 55, 59, 61, 63, 64, 65, 67, 71, 75, 76, 78, 79, 80, 81, 82, 83, 88, 91, 92, 93, 99, 103], "plenti": 67, "plinth": [29, 50, 59, 88], "plot": [7, 13, 14, 15, 16, 18, 19, 20, 21, 24, 26, 27, 28, 29, 30, 33, 34, 35, 36, 39, 40, 41, 42, 45, 47, 48, 49, 50, 51, 54, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 77, 78, 79, 80, 83, 85, 86, 87, 88, 89, 91, 92, 97, 99, 100, 102], "plot_2d_scor": [18, 39, 77], "plot_2d_separ": [15, 18, 35, 39, 64, 74, 77, 97], "plot_coeff_exampl": [38, 66, 67], "plot_confusion_matrix": [20, 41, 79], "plot_confusion_matrix_exampl": [20, 41, 68, 79], "plot_cross_valid": [14, 30, 34, 51, 60, 73, 89], "plot_dbscan": [26, 47, 56, 85], "plot_dbscan_with_label": [26, 47, 56, 85], "plot_dendrogram_clust": [26, 47, 56, 85], "plot_df": 58, "plot_elbow": [25, 46, 55, 84], "plot_example_dist": [25, 46, 55, 84], "plot_fruit_tre": [13, 72], "plot_grid_search_overview": [19, 40, 78], "plot_improper_process": 65, "plot_k_means_dbscan_comparison": [26, 47, 56, 85], "plot_km_initi": [25, 46, 55, 84], "plot_km_it": [25, 46, 55, 84], "plot_km_iter": [25, 46, 55, 84], "plot_kmean": [26, 47, 56, 85], "plot_knn_clf": [15, 35, 74], "plot_knn_decision_boundari": [15, 35, 74], "plot_knn_regress": [15, 35, 74], "plot_lda_w_vector": [28, 49, 58, 87], "plot_linkage_criteria": [26, 47, 56, 85], "plot_logistic_regress": [18, 39, 77], "plot_logistic_regression_graph": [29, 50, 59, 88], "plot_loss_diagram": 91, "plot_multiclass_lr_ovr": 94, "plot_original_clust": [26, 47, 56, 85], "plot_partial_effects_on_outcom": [31, 61, 90], "plot_proper_process": 65, "plot_result": [15, 35, 64, 74, 97], "plot_sample_img": [64, 70], "plot_scal": [16, 36, 75], "plot_silhouette_dist": [25, 46, 55, 84], "plot_single_hidden_layer_graph": [29, 50, 59, 88], "plot_support_vector": [15, 35, 74], "plot_survival_funct": [31, 61, 90], "plot_svc_c": [15, 35, 74], "plot_svc_gamma": [15, 35, 74], "plot_time_spacing_distribut": [30, 89, 102], "plot_train_test_point": [15, 35, 74], "plot_tre": 63, "plot_tree_decision_boundari": [14, 34, 73], "plot_tree_decision_boundary_and_tre": [13, 14, 33, 34, 72, 73, 96], "plot_two_hidden_layer_graph": [29, 50, 59, 88], "plot_typ": [23, 44, 53, 82], "plot_x_dendrogram": [26, 47, 56, 85], "plotli": [24, 28, 45, 49, 54, 83, 87], "plotting_funct": [13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 29, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 50, 52, 53, 55, 56, 57, 59, 63, 64, 65, 66, 67, 68, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 88, 91, 94, 96, 97, 98, 99, 100, 101], "plotting_functions_unsup": [25, 26, 27, 28, 46, 47, 48, 49, 55, 56, 57, 84, 85, 86, 87], "plt": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102], "plu": [18, 29, 39, 50, 59, 67, 77, 88], "plural": [17, 37, 76], "pm": [1, 12, 16, 18, 30, 32, 89, 102, 103], "pmltt": 1, "pn": [15, 20, 25, 26, 35, 41, 46, 47, 56, 64, 68, 74, 79, 84, 85, 97], "po": [18, 21, 23, 28, 36, 38, 39, 42, 44, 49, 53, 58, 61, 66, 67, 69, 73, 75, 77, 80, 82, 87, 91, 93], "pobox": [12, 32, 71], "pocon": 61, "poet": [28, 49, 87], "point": [1, 4, 11, 12, 13, 14, 16, 17, 18, 19, 21, 24, 26, 31, 32, 33, 36, 37, 39, 40, 42, 45, 47, 54, 56, 61, 63, 65, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 83, 85, 90, 91, 92, 94, 95, 97, 100, 103], "point_ind": [25, 46, 55, 84], "point_index": [25, 46, 84], "pointless": 99, "polarity_scor": 93, "pole": [29, 50, 59, 88], "poli": 19, "polici": [3, 4, 7, 32, 103], "polit": [27, 28, 29, 48, 49, 50, 57, 58, 59, 86, 87, 88], "poly_transform": [30, 51, 60, 89], "polynomialfeatur": [19, 24, 30, 45, 51, 54, 60, 83, 89], "pomegran": [29, 50, 59, 88], "pool": [1, 66, 67], "poolarea": [21, 23, 42, 44, 53, 69, 80, 82, 91], "poolqc": [21, 23, 42, 44, 53, 69, 80, 82, 91], "poor": [17, 21, 24, 37, 42, 45, 53, 54, 67, 69, 76, 80, 83, 95, 98], "poorli": [15, 21, 26, 30, 35, 42, 47, 51, 56, 60, 74, 80, 85, 89], "pope": [49, 58, 87], "popul": [16, 18, 24, 30, 36, 39, 45, 51, 54, 60, 75, 76, 77, 83, 89, 98], "popular": [8, 11, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 35, 36, 37, 39, 41, 42, 43, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 59, 68, 69, 73, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 91, 93], "population_per_household": [16, 36, 75, 76, 98], "port": 92, "porter": [28, 49, 58, 67, 87], "porterstemm": [28, 49, 58, 87], "portion": [0, 14, 16, 19, 21, 23, 34, 36, 38, 40, 42, 44, 66, 67, 69, 73, 75, 78, 80, 82, 91, 101, 102, 103], "portrait": 67, "portug": [20, 23, 41, 44, 79, 82], "pos_": [28, 49, 58, 87, 93], "pos_label": [21, 80], "pos_prob": [38, 66, 67], "posit": [13, 14, 15, 18, 21, 22, 23, 28, 30, 31, 34, 35, 36, 39, 42, 43, 44, 49, 51, 52, 53, 58, 60, 61, 69, 72, 73, 74, 75, 77, 80, 81, 82, 87, 89, 90, 93, 100], "posix": [31, 61, 90], "possess": 91, "possibl": [4, 5, 6, 8, 12, 13, 14, 16, 19, 20, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 36, 38, 40, 41, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 56, 57, 59, 61, 63, 65, 66, 67, 68, 70, 71, 72, 73, 75, 78, 79, 81, 82, 83, 85, 86, 87, 88, 90, 91, 95, 97, 98, 99, 100, 103], "possibli": [7, 28, 49, 58, 87], "post": [1, 4, 6, 7, 8, 12, 17, 28, 30, 32, 44, 49, 51, 54, 58, 60, 87, 89, 92, 103], "postprocess": [29, 50, 59, 88], "posv": 61, "potenti": [11, 15, 16, 25, 28, 35, 36, 46, 49, 55, 58, 63, 74, 75, 84, 87, 91, 92], "powder": [28, 49, 58, 87], "power": [8, 14, 22, 27, 28, 29, 34, 43, 48, 49, 50, 52, 54, 57, 58, 59, 65, 73, 81, 86, 87, 88, 91], "pp": 58, "pplicat": [26, 47, 56, 85], "pr": 95, "practic": [0, 1, 6, 9, 12, 14, 16, 20, 24, 29, 34, 36, 45, 50, 54, 59, 73, 75, 83, 88, 91, 92, 95, 98, 99, 103], "practition": 91, "prairielearn": [1, 12, 17, 32, 103], "pre": [1, 10, 12, 22, 24, 28, 32, 43, 45, 49, 52, 54, 64, 70, 71, 81, 83, 87, 91, 92, 93, 95], "precipit": 92, "precis": [11, 21, 42, 61, 80, 91, 92, 95, 100], "precision_lr": [20, 41, 68, 79], "precision_recall_curv": [20, 41, 68, 79], "precision_scor": [20, 41, 68, 79], "precision_svc": [20, 41, 68, 79], "precisionrecallcurvedisplai": [20, 41, 68, 79], "precisionrecalldisplai": [20, 41, 68, 79], "pred": [20, 21, 27, 30, 31, 41, 42, 48, 51, 57, 60, 61, 68, 69, 79, 80, 86, 89, 90], "pred_df": [12, 27, 32, 48, 57, 71, 86], "pred_dict": [12, 32, 71], "pred_g": [27, 48, 57, 86], "pred_lin_reg": [27, 48, 57, 86], "pred_train": [21, 42, 69, 80], "pred_x": [27, 48, 57, 86], "prediciton": [31, 61, 90], "predict": [2, 11, 14, 15, 16, 19, 20, 21, 24, 25, 26, 28, 30, 34, 35, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 49, 51, 54, 55, 56, 60, 63, 65, 66, 67, 68, 69, 73, 74, 75, 78, 79, 80, 83, 84, 85, 87, 89, 91, 92, 93, 95, 97, 98, 99, 100, 101, 102], "predict_expect": [31, 61, 90], "predict_for_usr": [27, 48, 57, 86], "predict_proba": [20, 22, 23, 29, 38, 41, 43, 44, 50, 52, 53, 59, 66, 67, 68, 70, 79, 81, 82, 88, 94, 101], "predict_survival_funct": [31, 61, 90], "predicted_categori": [20, 79, 92], "predicted_n_rent": [30, 51, 60, 89], "predicted_partial_hazards_": 61, "predicted_quiz2": [13, 33, 72], "predicted_sal": [30, 51, 60, 89], "predicted_target": [12, 32, 71], "predictor": [13, 33, 72, 95], "prefer": [12, 22, 25, 27, 32, 43, 46, 48, 55, 57, 71, 81, 84, 86, 99], "prefer_skip_nested_valid": [61, 65], "prefix": 8, "pregnant": 67, "preliminari": [16, 24, 36, 45, 54, 75, 83], "prepar": [16, 24, 29, 36, 45, 50, 54, 59, 75, 83, 88], "prepend": 10, "preprocess": [1, 11, 14, 15, 18, 19, 20, 22, 23, 24, 26, 27, 29, 31, 34, 35, 39, 40, 41, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 63, 64, 65, 68, 73, 74, 77, 78, 79, 81, 82, 83, 85, 86, 88, 90, 93, 97, 98, 99, 101], "preprocess_featur": [30, 89, 102], "preprocessing_fin": [31, 61, 90], "preprocessing_notenur": [31, 61, 90], "preprocessor": [19, 20, 21, 22, 23, 30, 31, 40, 41, 42, 43, 44, 52, 53, 61, 65, 69, 76, 78, 79, 80, 81, 82, 89, 90, 91, 93, 98, 99, 100, 101, 102], "preprocessor1": [24, 45, 54, 83], "preprocessor2": [24, 45, 54, 83], "preprocessor3": [24, 45, 54, 83], "prereq": 92, "prerequisit": [2, 61, 90, 103], "preschool": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "presenc": [17, 23, 31, 37, 41, 44, 53, 61, 76, 82, 90], "present": [7, 14, 20, 27, 28, 29, 30, 31, 34, 38, 48, 49, 50, 54, 57, 58, 59, 61, 64, 66, 67, 73, 79, 86, 87, 88, 89, 90, 91, 92, 95, 97, 102], "preserv": [20, 25, 41, 46, 55, 79, 84], "pressure3pm": [30, 89, 102], "pressure9am": [30, 89, 102], "pretend": [13, 14, 30, 34, 51, 60, 72, 73, 89], "pretrain": [28, 29, 49, 50, 70, 87, 88, 93], "pretti": [13, 18, 20, 22, 25, 28, 30, 31, 33, 39, 41, 43, 46, 49, 51, 52, 58, 60, 65, 68, 70, 72, 76, 77, 79, 81, 84, 87, 89, 90, 102], "prevent": [19, 28, 31, 40, 49, 58, 61, 78, 87, 90, 103], "previou": [12, 13, 21, 22, 25, 26, 30, 31, 32, 33, 42, 43, 46, 47, 51, 52, 55, 56, 60, 61, 63, 72, 80, 81, 84, 85, 89, 90, 91, 95, 99, 100, 102], "previous": [27, 29, 30, 48, 50, 51, 57, 59, 60, 86, 88, 89], "price": [8, 16, 18, 21, 23, 24, 31, 33, 36, 39, 42, 44, 53, 54, 61, 63, 65, 69, 75, 77, 80, 82, 83, 90, 91, 97], "primari": [8, 15, 35, 38, 66, 67, 74], "primarili": [12, 13, 23, 29, 32, 33, 44, 50, 53, 59, 72, 82, 88, 92], "prime": [12, 32, 71], "princ": [28, 49, 58, 87], "princess": [28, 49, 58, 87], "principl": [9, 11, 13, 72, 95], "print": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 97, 100, 102], "print_progress": 61, "print_top": [28, 49, 58, 87], "prior": [25, 30, 46, 51, 55, 60, 84, 89, 95], "priorit": [24, 45, 54, 83, 95], "privaci": [0, 11, 25, 46, 55, 84, 92], "privat": [7, 20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82], "privileg": 6, "prize": [17, 37, 52, 76], "pro": [25, 29, 46, 50, 55, 59, 84, 88, 91], "prob": [18, 22, 39, 43, 52, 77, 81], "proba": [29, 50, 59, 88], "probabilist": [2, 28, 49, 58, 87], "probabl": [12, 15, 16, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 35, 36, 38, 41, 42, 43, 44, 45, 47, 49, 50, 52, 53, 54, 56, 58, 59, 61, 65, 66, 67, 68, 71, 74, 75, 79, 80, 81, 82, 83, 85, 87, 88, 89, 90, 91, 92, 95, 100, 101, 102], "problem": [1, 4, 6, 11, 12, 17, 18, 20, 21, 22, 23, 25, 26, 28, 29, 31, 32, 37, 39, 41, 42, 43, 44, 46, 47, 49, 50, 52, 53, 55, 56, 58, 61, 63, 65, 67, 68, 69, 71, 76, 77, 79, 80, 81, 82, 84, 85, 87, 88, 90, 91, 94, 95, 97, 99, 100, 101, 102, 103], "problemat": [20, 23, 31, 41, 44, 53, 79, 82, 90], "probosci": [12, 29, 32, 50, 59, 71, 88], "proce": [64, 103], "procedur": [22, 52, 81], "proceed": [14, 73, 102], "process": [2, 5, 7, 11, 13, 15, 16, 17, 19, 24, 25, 26, 29, 33, 35, 36, 37, 40, 45, 46, 47, 50, 54, 56, 59, 63, 64, 72, 74, 75, 76, 78, 83, 84, 85, 88, 91, 92, 93, 97, 99], "process_on": 93, "process_rout": 61, "procfil": 92, "prod": [17, 19, 37, 40, 76, 78], "produc": [2, 7, 21, 23, 26, 31, 33, 42, 44, 53, 56, 61, 65, 67, 80, 82, 85, 90, 91, 95, 97], "product": [5, 19, 27, 28, 40, 48, 49, 57, 67, 78, 86, 87, 91], "prof": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "profession": [27, 48, 57, 86, 92], "profil": [21, 42, 80], "profile_df": [27, 48, 57, 86], "profilereport": [21, 42, 80], "profit": 91, "program": [0, 4, 9, 10, 12, 28, 32, 49, 58, 71, 87, 103], "programm": [28, 49, 58, 87], "progress": 84, "project": [10, 16, 24, 29, 36, 43, 45, 50, 52, 54, 59, 75, 81, 83, 88, 91, 92, 95, 103], "promin": [28, 49, 58, 87], "promis": [12, 28, 30, 32, 49, 51, 52, 58, 60, 63, 71, 87, 89, 92], "promot": [31, 61, 90], "prompt": [10, 12, 103], "pron": [28, 49, 58, 87, 93], "prone": [19, 40, 78], "proper": [29, 50, 59, 88, 96], "properli": [7, 12, 31, 32, 61, 90, 91], "properti": [13, 21, 23, 24, 33, 42, 44, 53, 69, 72, 80, 82, 83], "prophet": [30, 51, 60, 89], "propn": [28, 49, 58, 87, 93], "proport": [11, 13, 14, 17, 18, 20, 21, 22, 23, 33, 34, 37, 39, 41, 42, 43, 44, 52, 53, 69, 72, 73, 76, 77, 79, 80, 81, 82, 91, 100], "proportional_hazard_test": [31, 61, 90], "prostitut": [49, 58, 87], "protocol": 92, "prototyp": [92, 95], "prove": [20, 79], "proven": 49, "provid": [0, 5, 7, 10, 11, 13, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 33, 34, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 60, 64, 68, 69, 72, 73, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 89, 91, 95, 99, 100, 101, 102, 103], "provinc": [17, 28, 37, 49, 58, 76, 87], "provinci": 87, "proxi": [14, 34, 73], "proxim": [18, 28, 39, 49, 77, 87, 103], "prune": [24, 54, 83], "psychiatr": 67, "psychologi": [17, 37, 76, 95], "pt": [18, 29, 39, 40, 50, 59, 77, 78, 88], "public": [0, 4, 7, 28, 49, 58, 87, 93], "publish": [0, 1, 18, 28, 39, 49, 58, 77, 87], "puck": [28, 49, 58, 87], "pud": [21, 42, 69, 80], "pull": [10, 18, 28, 39, 49, 58, 77, 87], "punct": [28, 49, 58, 87, 93], "punctuat": [17, 28, 37, 49, 76, 87], "punish": 91, "punkt": 93, "punkt_tab": [58, 93], "purchas": [12, 27, 32, 48, 57, 64, 71, 86, 92], "pure": [13, 30, 33, 51, 60, 72, 89], "purpos": [0, 13, 14, 16, 27, 28, 30, 33, 34, 36, 38, 48, 49, 51, 54, 57, 58, 60, 66, 67, 72, 73, 75, 86, 87, 89, 92, 95, 96, 97, 101, 103], "pursuit": 91, "push": [7, 23, 44, 53, 82], "put": [7, 8, 10, 13, 14, 16, 17, 24, 25, 26, 27, 34, 36, 37, 38, 45, 46, 47, 48, 54, 56, 57, 64, 65, 66, 67, 72, 73, 75, 76, 83, 84, 85, 86, 92, 99], "px": [24, 28, 45, 49, 54, 83, 87], "py": [13, 17, 19, 22, 25, 26, 29, 31, 33, 36, 37, 43, 46, 47, 50, 52, 53, 61, 64, 65, 72, 73, 75, 76, 78, 81, 82, 84, 85, 90, 92, 93, 94], "pybind11": 93, "pybo": [19, 40, 78], "pydata": [24, 45, 54, 83], "pyplot": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 99, 100, 101, 102], "pysurviv": [31, 61, 90], "python": [1, 3, 4, 11, 19, 21, 27, 28, 29, 30, 31, 40, 42, 48, 49, 50, 51, 59, 60, 61, 71, 78, 80, 86, 87, 88, 89, 90, 91, 92, 93, 103], "python3": [9, 17, 19, 29, 31, 33, 37, 61, 64, 65, 72, 73, 76, 78, 82, 90, 93, 94], "pythonwarn": [21, 42, 68, 80], "pytorch": [12, 29, 32, 50, 59, 70, 71, 88], "pytorch_1711403226120": [29, 93], "pyviz": [20, 41, 68, 79], "q": 1, "qualit": 65, "qualiti": [20, 23, 24, 25, 26, 41, 44, 45, 46, 47, 53, 54, 55, 56, 68, 79, 82, 84, 85, 91], "quantifi": [20, 41, 79, 100], "quantil": 65, "quantit": 65, "quebecoi": 65, "queen": [28, 49, 58, 87], "queen_consort": [28, 49, 58, 87], "queri": [16, 20, 22, 25, 27, 28, 30, 31, 36, 41, 43, 46, 49, 51, 52, 58, 60, 61, 64, 75, 79, 81, 84, 86, 87, 89, 90, 100, 102, 103], "query_img": 64, "query_point": [15, 35, 74], "quest": [24, 45, 54, 83], "question": [1, 6, 7, 54, 55, 59, 69, 103], "queuepredictor": 92, "quick": [4, 12, 28, 32, 49, 58, 87, 92, 103], "quickli": [13, 15, 16, 19, 26, 31, 33, 35, 36, 40, 47, 56, 72, 74, 75, 78, 85, 90, 95, 103], "quickstart": [9, 29], "quirk": [14, 34, 73], "quit": [6, 12, 13, 16, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 33, 36, 40, 41, 42, 44, 45, 47, 49, 50, 51, 53, 54, 56, 58, 59, 64, 67, 69, 70, 71, 72, 75, 78, 79, 80, 82, 83, 85, 87, 88, 89, 90, 91, 93], "quiz": [1, 12, 16, 28, 32, 49, 58, 87, 103], "quiz1": [13, 14, 17, 33, 34, 37, 72, 73, 76, 95], "quiz2": [14, 17, 34, 37, 73, 76, 95], "quizz": [13, 15, 17, 33, 72], "r": [11, 13, 17, 18, 20, 30, 33, 37, 39, 41, 51, 60, 66, 67, 68, 72, 76, 77, 79, 89, 91, 101], "r1": [22, 43, 52, 81], "r2": [21, 22, 42, 43, 52, 63, 69, 80, 81, 95, 97], "r2_score": [21, 24, 42, 45, 54, 69, 80, 83, 93], "r4": [43, 81], "r_precis": 61, "race": [17, 20, 22, 23, 41, 43, 44, 52, 53, 76, 79, 81, 82, 100, 103], "radial": [15, 35, 74], "radiu": [24, 26, 45, 47, 54, 56, 83, 85], "rail": [29, 50, 59, 88], "rain": [30, 89, 102], "rain_df": [30, 89, 102], "rain_df_modifi": [30, 89, 102], "rainfal": [30, 89, 102], "rainfall_lag1": [30, 89, 102], "rainfall_lag2": [30, 89, 102], "rainfall_lag3": [30, 89, 102], "raintodai": [30, 89, 102], "raintoday_miss": [30, 89, 102], "raintoday_no": [30, 89, 102], "raintoday_y": [30, 89, 102], "raintomorrow": [30, 89, 102], "rais": [6, 17, 19, 20, 30, 31, 32, 37, 41, 54, 61, 65, 68, 76, 79, 89, 90, 102], "ramen": 58, "ramen_noodl": 58, "rand": [8, 22, 43, 52, 81], "randint": [19, 40, 78, 99], "randn": [18, 24, 39, 45, 54, 77, 83], "random": [6, 8, 11, 14, 15, 18, 20, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 39, 41, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 60, 61, 64, 68, 70, 73, 74, 77, 79, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 99, 101], "random_forest_data": [22, 43, 81], "random_search": [19, 40, 78, 99], "random_st": [12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 97, 98, 99, 100, 101], "randomforest": 54, "randomforestclassifi": [23, 24, 30, 44, 45, 51, 53, 54, 60, 82, 83, 89, 91, 101, 102], "randomforestclassifierrandomforestclassifi": [22, 43, 52, 81], "randomforestregressor": [21, 22, 23, 24, 30, 31, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 69, 80, 81, 82, 83, 89, 90, 91, 92, 93, 101], "randomhorizontalflip": [29, 50, 59, 88], "randomizedsearchcv": [15, 22, 23, 35, 43, 44, 52, 53, 74, 81, 82, 91, 99, 101], "randomizedsearchcvifittedrandomizedsearchcv": [19, 40, 78], "randomli": [14, 18, 19, 20, 22, 34, 39, 40, 41, 43, 52, 61, 68, 73, 77, 78, 79, 81, 90, 100], "randomoversampl": [20, 79], "randomresizedcrop": [29, 50, 59, 88], "randomst": [24, 26, 45, 47, 54, 56, 83, 85], "randomundersampl": [20, 79], "rang": [4, 8, 11, 14, 15, 16, 17, 18, 22, 25, 27, 28, 29, 30, 31, 34, 35, 36, 37, 39, 43, 46, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 65, 70, 73, 74, 75, 76, 77, 81, 84, 86, 87, 88, 89, 90, 91, 93, 99], "rangeindex": [17, 24, 30, 31, 37, 45, 54, 76, 83, 89, 90, 102], "rank": [20, 24, 27, 28, 31, 41, 45, 48, 49, 54, 57, 58, 61, 68, 79, 83, 86, 87, 90, 100], "rank_test_mape_scor": [21, 42, 69, 80], "rank_test_neg_mean_squared_error": [21, 42, 80], "rank_test_scor": [19, 21, 40, 42, 69, 78, 80], "ranking_": [24, 45, 54, 83], "rare": [17, 20, 21, 25, 28, 41, 42, 46, 49, 54, 55, 58, 69, 76, 79, 80, 84, 87, 95], "rate": [12, 18, 20, 22, 25, 31, 32, 39, 41, 43, 46, 52, 55, 61, 68, 71, 77, 79, 81, 84, 90, 91, 95, 100], "rated_item": [27, 48, 57, 86], "rather": [12, 17, 19, 20, 21, 22, 23, 25, 28, 29, 32, 37, 40, 41, 42, 43, 44, 46, 49, 50, 52, 53, 55, 58, 59, 65, 67, 69, 71, 76, 78, 79, 80, 81, 82, 84, 87, 88, 103], "ratings_df": [27, 48, 57, 86], "ratio": [20, 22, 28, 31, 43, 49, 52, 61, 79, 81, 87, 90], "ravel": [20, 38, 41, 64, 66, 67, 68, 79, 95], "raw": [8, 17, 20, 23, 24, 28, 29, 37, 41, 44, 45, 49, 50, 53, 54, 58, 59, 68, 76, 79, 82, 83, 87, 88, 91, 94, 100], "raw_model_output": [18, 39, 77], "raw_scor": [23, 44, 53, 82], "rbf": [1, 14, 16, 18, 19, 22, 23, 24, 34, 36, 39, 40, 43, 44, 45, 52, 53, 54, 73, 75, 77, 78, 81, 82, 83, 91, 92, 95, 97, 99], "rcond": 61, "rcparam": [12, 13, 14, 20, 25, 26, 27, 29, 30, 31, 32, 33, 34, 41, 46, 47, 48, 50, 51, 55, 56, 57, 59, 60, 61, 68, 71, 72, 73, 79, 84, 85, 86, 88, 89, 90, 91, 96, 102], "re": [4, 7, 8, 10, 12, 13, 14, 17, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 66, 67, 69, 71, 72, 73, 76, 78, 79, 80, 81, 82, 84, 86, 87, 88, 89, 90, 92, 93, 95, 96, 102], "reach": [1, 6, 25, 46, 55, 84, 103], "read": [1, 4, 7, 12, 15, 16, 17, 20, 21, 22, 23, 28, 30, 32, 35, 36, 37, 42, 43, 44, 49, 52, 54, 58, 64, 68, 69, 74, 75, 76, 79, 80, 81, 82, 87, 89, 91, 92, 101, 102], "read_csv": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102], "read_excel": 8, "read_html": 8, "read_img_dataset": [64, 70], "read_json": 8, "readabl": [0, 8], "reader": 11, "readi": [7, 12, 14, 15, 16, 18, 34, 35, 36, 39, 73, 74, 75, 77], "readlin": [29, 50, 59, 88], "readm": [31, 61, 90], "readthedoc": [31, 61, 90], "real": [14, 15, 16, 17, 18, 20, 23, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 39, 41, 44, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 65, 73, 74, 75, 76, 77, 79, 82, 84, 85, 86, 87, 88, 91, 93, 95], "realdonaldtrump": 93, "realism": 67, "realist": [16, 30, 36, 51, 60, 75, 89, 92, 102], "realiti": [14, 21, 31, 34, 42, 61, 73, 80, 90], "realiz": 91, "realli": [8, 14, 18, 19, 22, 24, 26, 27, 29, 30, 31, 34, 39, 40, 45, 47, 48, 50, 51, 52, 54, 56, 57, 59, 60, 61, 67, 73, 77, 78, 81, 83, 85, 86, 88, 89, 90, 92], "reanim": 67, "reason": [0, 2, 4, 8, 11, 14, 16, 19, 20, 21, 23, 25, 27, 28, 30, 31, 34, 36, 40, 41, 42, 44, 46, 48, 49, 51, 53, 55, 57, 58, 60, 61, 67, 68, 69, 73, 75, 78, 79, 80, 82, 84, 86, 87, 89, 90, 91, 92, 95, 103], "rebuild": 93, "rec": [21, 23, 42, 44, 53, 69, 80, 82, 91], "recal": [11, 13, 14, 15, 16, 17, 18, 21, 25, 30, 34, 36, 37, 39, 42, 46, 51, 54, 55, 57, 60, 65, 69, 72, 73, 74, 75, 76, 77, 80, 84, 89, 92, 95, 100], "recall_lr": [20, 41, 68, 79], "recall_scor": [20, 41, 68, 79], "recall_svc": [20, 41, 68, 79], "receiv": [6, 7, 17, 26, 29, 30, 32, 37, 47, 50, 56, 59, 76, 85, 88, 89, 92], "recent": [8, 10, 12, 17, 24, 27, 28, 30, 31, 32, 37, 45, 48, 49, 51, 54, 57, 58, 60, 61, 65, 71, 76, 83, 86, 87, 89, 90, 93], "recip": [14, 34, 73], "recogn": [11, 14, 26, 30, 34, 47, 51, 56, 60, 67, 73, 85, 89, 91, 103], "recognit": [12, 13, 15, 20, 28, 32, 49, 58, 71, 72, 74, 79, 87, 103], "recommend": [1, 2, 4, 8, 10, 11, 14, 15, 19, 20, 25, 28, 34, 38, 40, 41, 44, 46, 49, 50, 55, 58, 59, 64, 66, 67, 71, 73, 74, 78, 79, 84, 87, 88, 91, 92, 101], "record": [13, 31, 33, 61, 72, 90], "recreat": 102, "rectangular": [25, 46, 55, 84], "recurr": [30, 51, 60, 89], "recurs": 11, "red": [13, 15, 20, 23, 24, 25, 30, 33, 35, 41, 44, 45, 46, 51, 53, 54, 55, 68, 72, 74, 79, 82, 83, 84, 89], "redbon": [19, 40, 78], "redefin": [31, 61, 90], "redistribut": 0, "reduc": [7, 8, 12, 15, 19, 20, 21, 22, 23, 24, 27, 28, 29, 32, 35, 40, 41, 42, 43, 44, 45, 48, 49, 50, 52, 53, 54, 57, 58, 59, 71, 74, 78, 79, 80, 81, 82, 83, 86, 87, 88, 94, 97, 100, 103], "reduct": [2, 20, 22, 24, 25, 41, 43, 45, 46, 52, 54, 55, 68, 79, 81, 83, 84], "redund": [18, 23, 39, 44, 53, 77, 82], "ref": [20, 31, 41, 61, 68, 79, 90, 100], "refer": [8, 12, 13, 14, 15, 16, 17, 18, 20, 23, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 39, 41, 44, 46, 48, 49, 50, 53, 55, 57, 58, 59, 60, 72, 73, 74, 75, 76, 77, 79, 82, 84, 86, 87, 88, 97, 103], "referenc": 103, "referenti": [28, 49, 87], "refin": [15, 35, 64, 74, 97], "refit": [21, 42, 69, 80], "reflect": [15, 21, 23, 28, 35, 42, 44, 49, 53, 58, 69, 74, 80, 82, 87, 97, 99, 103], "reflection_period": [20, 79, 92], "refus": 67, "reg": [13, 22, 33, 43, 52, 72, 81, 101], "reg_model": [13, 33, 72], "regard": [38, 103], "regardless": 7, "regex": [28, 49, 58, 87], "regim": 92, "region": [13, 20, 26, 30, 33, 47, 56, 72, 79, 85, 89, 92, 94, 99, 102], "region_data": [30, 89, 102], "regist": [12, 32, 92, 103], "registered_nurs": [28, 49, 58, 87], "registr": 54, "registri": 93, "regrad": [6, 32], "regress": [1, 2, 11, 12, 16, 17, 23, 24, 27, 30, 31, 32, 36, 37, 38, 43, 44, 48, 51, 53, 60, 61, 63, 66, 67, 71, 75, 76, 82, 83, 86, 89, 90, 91, 92, 93, 94, 95, 97, 100, 101, 102], "regression_df": [13, 33, 72], "regressioncolumntransform": [22, 43, 52], "regressor": [13, 16, 17, 21, 30, 33, 36, 37, 42, 51, 60, 63, 65, 72, 75, 76, 80, 89, 101], "regular": [15, 17, 18, 22, 28, 30, 31, 35, 37, 39, 49, 51, 52, 54, 58, 60, 61, 74, 76, 77, 81, 87, 89, 90, 91, 95], "regularli": 67, "regulatori": [23, 44, 53, 82], "reinforc": [12, 25, 32, 46, 55, 71, 84], "reject": [20, 41, 79, 100], "rel": [18, 23, 26, 28, 34, 39, 44, 47, 49, 53, 56, 58, 65, 77, 82, 85, 87, 93, 94, 100], "rel_char_len": 93, "relabel": [25, 46, 55, 84], "relat": [2, 6, 10, 12, 18, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 39, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 57, 60, 61, 67, 69, 71, 77, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 93, 101, 103], "relationship": [11, 20, 22, 23, 24, 28, 30, 41, 43, 44, 45, 49, 51, 52, 53, 54, 60, 79, 81, 82, 83, 87, 89, 91, 93, 95, 96, 97, 100, 102, 103], "relationship_husband": [23, 44, 53, 82], "relationship_own": [23, 44, 53, 82], "releas": [1, 7, 14, 15, 16, 17, 29], "relev": [1, 4, 8, 11, 13, 15, 16, 19, 23, 30, 33, 35, 36, 40, 44, 53, 72, 74, 75, 78, 82, 89, 103], "reli": [14, 15, 24, 26, 27, 30, 34, 35, 45, 47, 48, 51, 54, 56, 57, 60, 64, 73, 74, 83, 85, 86, 89, 97], "reliabl": [12, 25, 32, 34, 46, 55, 71, 84], "religi": [28, 49, 58, 87], "remain": [5, 21, 24, 27, 30, 42, 45, 48, 51, 54, 57, 60, 80, 83, 86, 89, 91], "remaind": 6, "rememb": [7, 15, 17, 19, 20, 23, 24, 26, 29, 30, 31, 32, 35, 37, 38, 40, 41, 44, 45, 47, 50, 53, 54, 56, 59, 61, 66, 67, 68, 69, 74, 76, 78, 79, 82, 83, 85, 88, 89, 90, 96, 97, 99, 102], "remind": 96, "remix": 0, "remov": [7, 16, 20, 22, 23, 24, 28, 29, 31, 36, 41, 43, 44, 45, 49, 50, 52, 53, 54, 59, 61, 64, 70, 75, 79, 81, 82, 83, 87, 88, 90, 94, 99, 100, 102], "renam": [12, 20, 30, 32, 51, 53, 60, 71, 79, 82, 89, 92], "render": [4, 7, 12, 16, 17, 19, 20, 21, 22, 23, 24, 25, 28, 29, 32, 36, 37, 40, 41, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 58, 59, 63, 64, 65, 67, 71, 75, 76, 78, 79, 80, 81, 82, 83, 84, 87, 88, 91, 93], "rent": [30, 51, 60, 89], "rental": [30, 51, 60, 89, 92], "rentals_df": [30, 51, 60, 89], "rentals_lag5": [30, 51, 60, 89], "rentals_lag5_i": [30, 51, 60, 89], "rentals_lag5_x": [30, 51, 60, 89], "rentals_model": [30, 51, 60, 89], "repair": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82], "repeat": [8, 24, 25, 26, 29, 45, 46, 47, 50, 54, 55, 56, 59, 83, 84, 85, 88, 92, 99, 100, 101], "repeatedli": 6, "repetit": 67, "rephras": 91, "replac": [12, 16, 20, 22, 23, 27, 31, 32, 36, 38, 41, 43, 44, 52, 53, 54, 57, 61, 65, 66, 67, 71, 75, 79, 81, 82, 86, 90, 100], "replace_tag": [38, 66, 67], "replic": 92, "reply_cont": 93, "repo": [1, 20, 41, 68, 79, 92], "report": [6, 13, 19, 21, 24, 30, 33, 40, 42, 45, 54, 72, 78, 80, 83, 89, 93, 100], "repositori": [0, 1, 5, 10, 12, 18, 20, 32, 39, 41, 64, 65, 68, 77, 79, 92, 103], "repres": [13, 14, 15, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 60, 61, 68, 72, 73, 74, 75, 76, 77, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 101], "represent": [12, 13, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 32, 33, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 52, 53, 54, 55, 56, 63, 64, 65, 66, 67, 70, 71, 72, 75, 78, 79, 80, 81, 82, 83, 84, 85, 87, 91, 92, 93, 95], "reproduc": [4, 14, 19, 22, 34, 40, 43, 73, 78, 81, 92, 103], "republ": [23, 44, 53, 82], "request": [6, 32, 49, 58, 87, 103], "requir": [5, 7, 15, 16, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 35, 36, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 61, 64, 65, 68, 74, 75, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 95, 97, 102, 103], "rerun": [12, 16, 17, 19, 20, 21, 22, 23, 24, 29, 32, 36, 37, 40, 41, 42, 43, 44, 45, 50, 52, 53, 55, 59, 63, 64, 65, 67, 71, 75, 76, 78, 79, 80, 81, 82, 83, 88, 91, 93], "res_mean": [14, 34, 73], "resampl": [20, 79], "research": [12, 14, 19, 27, 28, 32, 34, 40, 48, 49, 57, 58, 71, 73, 78, 86, 87, 92], "reserv": [30, 51, 60, 89, 103], "reset": [29, 50, 61, 65], "reset_index": [12, 32, 71], "reshap": [8, 18, 19, 29, 30, 39, 40, 50, 51, 59, 60, 65, 70, 77, 78, 88, 89, 99], "reshape_transform": 65, "resid": [18, 39, 77], "residu": [22, 52, 81], "resiz": [29, 50, 59, 64, 70, 88], "resnet": [29, 50, 59, 88], "resolut": [28, 49, 58, 87], "resolv": 103, "resort": [18, 39, 77], "resourc": [1, 3, 5, 22, 23, 28, 29, 43, 44, 49, 50, 53, 58, 59, 72, 81, 82, 87, 88, 92, 95], "respect": [18, 19, 20, 22, 23, 39, 40, 43, 44, 52, 53, 68, 77, 78, 79, 81, 82, 99], "respons": [4, 7, 13, 28, 33, 49, 58, 67, 72, 84, 87, 91, 103], "rest": [18, 19, 29, 31, 39, 40, 50, 59, 61, 67, 77, 78, 88, 90, 92, 95, 102], "restart": [7, 10], "restaur": [27, 48, 57, 65, 86, 92], "restaurant_df": 65, "restaurant_nam": 65, "restingbp": 101, "restingecg": 101, "restrict": [0, 21, 22, 28, 42, 43, 49, 52, 58, 80, 81, 87], "resubmit": 32, "result": [1, 2, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 63, 64, 65, 68, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 92, 93, 97, 99, 100, 101, 102, 103], "result_block": [31, 61, 90], "result_img": [29, 50, 59, 88], "results_df": [14, 15, 18, 34, 35, 38, 39, 63, 64, 66, 67, 73, 74, 77, 97], "results_dict": [14, 15, 16, 19, 34, 35, 36, 40, 64, 73, 74, 75, 76, 78], "results_single_valid_df": [63, 97], "retail": [93, 95], "retail_df": [30, 51, 60, 89], "retail_df_test": [30, 51, 60, 89], "retail_df_train": [30, 51, 60, 89], "retail_lag_5": [30, 51, 60, 89], "retail_model": [30, 51, 60, 89], "retail_test_5": [30, 51, 60, 89], "retail_test_5_pr": [30, 51, 60, 89], "retail_train_5": [30, 51, 60, 89], "retail_train_5_d": [30, 51, 60, 89], "retail_train_5_i": [30, 51, 60, 89], "retail_train_5_x": [30, 51, 60, 89], "retain": [28, 49, 58], "retent": [31, 61, 90], "retrain": [19, 40, 78, 92, 99], "return": [5, 8, 10, 13, 14, 15, 16, 17, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 41, 42, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 79, 80, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 97, 99, 102], "return_gener": [17, 37, 61, 76], "return_predict": 92, "return_train_scor": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 63, 64, 65, 66, 67, 68, 69, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 89, 90, 93, 97, 99, 101], "return_tupl": 61, "reus": [20, 41, 79, 103], "revenu": [27, 48, 57, 86], "revers": [17, 21, 37, 42, 76, 80], "review": [1, 4, 18, 39, 77, 84, 91, 93, 95, 99, 100, 101, 103], "review_pp": [38, 66, 67], "revisit": [20, 41, 79, 95], "revok": 0, "reward": [12, 17, 25, 32, 37, 46, 55, 71, 76, 84], "rf": [30, 31, 51, 60, 61, 89, 90], "rf_imp_df": [23, 44, 82], "rfe_cv": [24, 45, 54, 83], "rfe_pip": [24, 45, 54, 83], "rfecv": [24, 45, 54, 83], "rgb": [12, 32, 71], "rhode_island": [28, 49, 87], "rich": [23, 28, 31, 44, 49, 53, 58, 61, 82, 87, 90, 91, 95], "richard": [67, 91], "rico": [22, 23, 44, 53, 82], "rid": [10, 17, 22, 23, 28, 31, 37, 43, 44, 49, 52, 53, 58, 61, 65, 76, 81, 82, 87, 90], "ridg": [23, 24, 27, 30, 31, 44, 45, 48, 51, 53, 57, 60, 61, 82, 83, 86, 89, 90, 91, 92, 93], "ridge__alpha": [21, 42, 69, 80], "ridge_pr": [21, 42, 69, 80], "ridge_tun": [21, 42, 69, 80], "ridgecv": [24, 45, 54, 83, 93], "ridgecv_pip": [21, 42, 69, 80], "ridgeridg": [21, 24, 42, 45, 80, 83], "rifl": 67, "right": [0, 1, 11, 12, 18, 19, 20, 21, 24, 25, 26, 27, 28, 32, 39, 40, 41, 42, 45, 46, 47, 48, 49, 54, 55, 56, 57, 58, 63, 65, 67, 68, 69, 71, 77, 78, 79, 80, 83, 84, 85, 86, 87, 91, 92, 95, 99, 100], "right_censor": 61, "rightarrow": [13, 15, 18, 20, 21, 22, 25, 26, 27, 28, 35, 39, 41, 42, 43, 46, 47, 48, 49, 52, 55, 56, 57, 58, 68, 69, 72, 74, 77, 79, 80, 81, 84, 85, 86, 87, 91, 92, 95], "rindfleischetikettierungs\u00fcberwachungsaufgaben\u00fcbertragungsgesetz": [28, 49, 58, 87], "ring": 67, "rip": 67, "rise": [24, 28, 45, 49, 58, 83, 87], "risk": [1, 20, 24, 41, 45, 54, 68, 79, 83, 91, 97, 101], "riti": [32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 103], "river": [18, 39, 77], "rl": [21, 23, 42, 44, 53, 80, 82, 91], "rmse": [27, 48, 57, 86, 95], "rng": [24, 26, 45, 47, 54, 56, 83, 85], "rnn": [30, 51, 60, 89], "ro": [20, 79], "roast": [25, 84], "robot": [27, 28, 48, 49, 57, 58, 86, 87], "robust": [12, 14, 15, 16, 19, 22, 26, 32, 34, 35, 36, 40, 43, 47, 56, 61, 65, 71, 73, 74, 75, 78, 81, 85, 97, 99], "robustscal": 65, "roc": [11, 92, 95], "roc_auc": [20, 41, 68, 79], "roc_auc_scor": [20, 41, 68, 79], "roc_curv": [20, 41, 68, 79], "roc_lr": [20, 41, 68, 79], "roc_svc": [20, 41, 68, 79], "roccurvedisplai": [20, 41, 68, 79], "rock": 67, "rodolfo": [19, 40, 78], "rodr\u00edguez": [28, 49, 58, 87], "roger": [24, 45, 54, 67, 83], "role": [18, 19, 23, 29, 39, 40, 44, 50, 53, 59, 67, 77, 78, 82, 88], "roman": [27, 48, 57, 86], "romanc": [27, 48, 57, 86], "romant": [27, 48, 57, 86], "ronald": [18, 39, 77], "roof": [23, 53, 82], "roofmatl": [21, 23, 42, 44, 53, 80, 82, 91], "roofmatl_clytil": [21, 23, 42, 53, 80, 82], "roofmatl_compshg": [21, 23, 42, 53, 80, 82], "roofmatl_membran": [21, 23, 42, 80], "roofmatl_met": [21, 23, 42, 80], "roofmatl_rol": [21, 23, 42, 80], "roofmatl_tar": [21, 23, 42, 80], "roofmatl_wdshak": [21, 23, 42, 80], "roofmatl_wdshngl": [21, 23, 42, 53, 80, 82], "roofstyl": [21, 23, 42, 44, 53, 80, 82, 91], "roofstyle_flat": [21, 42, 80], "roofstyle_g": [21, 42, 80], "roofstyle_gambrel": [21, 42, 80], "roofstyle_hip": [21, 42, 80], "roofstyle_mansard": [21, 42, 80], "roofstyle_sh": [21, 42, 80], "room": [12, 13, 18, 21, 24, 32, 33, 39, 42, 45, 54, 65, 71, 72, 77, 80, 83, 92, 93, 103], "room_row": 54, "rooms_per_household": [16, 24, 36, 45, 54, 75, 76, 83, 98], "rooms_per_household_0": [24, 45, 54, 83], "rooms_per_household_1": [24, 45, 54, 83], "rooms_per_household_10": [24, 45, 54, 83], "rooms_per_household_11": [24, 45, 54, 83], "rooms_per_household_12": [24, 45, 54, 83], "rooms_per_household_13": [24, 45, 54, 83], "rooms_per_household_14": [24, 45, 54, 83], "rooms_per_household_15": [24, 45, 54, 83], "rooms_per_household_16": [24, 45, 54, 83], "rooms_per_household_17": [24, 45, 54, 83], "rooms_per_household_18": [24, 45, 54, 83], "rooms_per_household_19": [24, 45, 54, 83], "rooms_per_household_2": [24, 45, 54, 83], "rooms_per_household_3": [24, 45, 54, 83], "rooms_per_household_4": [24, 45, 54, 83], "rooms_per_household_5": [24, 45, 54, 83], "rooms_per_household_6": [24, 45, 54, 83], "rooms_per_household_7": [24, 45, 54, 83], "rooms_per_household_8": [24, 45, 54, 83], "rooms_per_household_9": [24, 45, 54, 83], "root": [10, 13, 15, 27, 29, 33, 35, 48, 50, 57, 59, 64, 70, 72, 74, 86, 88, 95], "rose": [28, 49, 58, 87], "rostin": [1, 103], "rotat": [30, 51, 60, 89, 102], "roth": [1, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 103], "rough": [4, 69], "roughli": [5, 14, 28, 49, 58, 73, 87, 92, 95], "round": [8, 15, 16, 19, 20, 22, 26, 29, 35, 36, 40, 41, 43, 47, 50, 52, 56, 59, 64, 68, 74, 75, 78, 79, 81, 85, 88, 97], "rout": [5, 13, 30, 33, 51, 60, 72, 89], "routed_param": 61, "row": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 67, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 96, 97, 101, 102, 103], "rry": [28, 49, 87], "rsh": [19, 40, 78], "ru": [8, 20, 79], "rubric": [18, 32, 39, 77], "rule": [1, 8, 12, 13, 15, 18, 20, 22, 28, 32, 33, 38, 39, 41, 49, 58, 63, 66, 67, 71, 72, 74, 77, 79, 81, 87, 92, 95, 97, 100], "run": [1, 4, 5, 7, 10, 12, 14, 15, 17, 19, 20, 21, 23, 25, 26, 28, 29, 32, 34, 37, 40, 41, 42, 44, 46, 47, 49, 50, 53, 55, 56, 58, 59, 61, 64, 67, 68, 69, 70, 71, 73, 74, 76, 78, 79, 80, 82, 84, 85, 87, 88, 92, 93, 94, 96, 97, 99, 101], "run_ast_nod": 93, "run_cel": 93, "run_cell_async": 93, "run_cod": 93, "run_forev": 93, "runner": [29, 93], "runpi": 93, "runs_dir": 29, "runtimewarn": 78, "ruscorpora": [28, 49, 87], "rush": [24, 45, 54, 83], "russel": 1, "rv": [19, 40, 78], "rv_continuous_frozen": [19, 40, 78], "rv_discrete_frozen": [19, 40, 78], "rvert_2": [28, 49, 58, 87], "s1": [8, 28, 49, 58, 87], "s19": [16, 36, 75], "s2": [8, 28, 49, 58, 87], "s_lag": [30, 89, 102], "sa": 1, "sabr": [28, 49, 87], "sabrina": 1, "sadli": [28, 49, 58, 87], "safe": [16, 36, 75], "safeti": [29, 50, 59, 88], "sai": [8, 13, 15, 16, 17, 20, 21, 22, 23, 28, 30, 33, 35, 36, 37, 41, 42, 43, 44, 49, 51, 53, 57, 58, 60, 67, 72, 74, 75, 76, 79, 80, 81, 82, 87, 89, 91, 95, 100], "said": [14, 16, 18, 23, 26, 27, 28, 34, 36, 39, 44, 47, 48, 49, 54, 56, 57, 58, 73, 75, 77, 82, 85, 86, 87, 91], "sal": [21, 23, 42, 44, 53, 69, 80, 82, 91], "sale": [8, 20, 21, 30, 41, 42, 51, 60, 63, 69, 79, 80, 89, 91, 97], "salecondit": [21, 23, 42, 44, 53, 80, 82, 91], "salecondition_abnorml": [21, 42, 80], "salecondition_adjland": [21, 42, 80], "salecondition_alloca": [21, 42, 80], "salecondition_famili": [21, 42, 80], "salecondition_norm": [21, 42, 80], "salecondition_parti": [21, 42, 80], "salepric": [21, 23, 42, 44, 53, 69, 80, 82, 91], "sales_data": [30, 51, 60, 89], "salesforc": 93, "saleswoman": [28, 49, 58, 87], "saletyp": [21, 23, 42, 44, 53, 80, 82, 91], "saletype_cod": [21, 42, 80], "saletype_con": [21, 42, 80], "saletype_conld": [21, 42, 80], "saletype_conli": [21, 42, 80], "saletype_conlw": [21, 42, 80], "saletype_cwd": [21, 42, 80], "saletype_new": [21, 42, 80], "saletype_oth": [21, 42, 80], "saletype_wd": [21, 42, 80], "salt": [18, 23, 39, 44, 53, 77, 82], "sam": [27, 48, 57, 86], "same": [6, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 61, 63, 68, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 96, 97, 100, 102], "samosa": [28, 49, 87], "sampl": [12, 13, 15, 16, 18, 19, 23, 26, 29, 30, 31, 33, 34, 35, 36, 39, 40, 41, 44, 47, 50, 51, 53, 56, 59, 61, 64, 65, 70, 72, 74, 75, 77, 78, 82, 85, 88, 89, 90, 91, 92, 96, 97, 100, 101, 102], "sample_df": [20, 79, 92], "sample_text": 93, "sample_weight": 61, "sampling_strategi": [20, 79], "samuel": [12, 32, 71], "sand": [29, 50, 59, 88], "sandbar": [29, 50, 59, 88], "saniti": [13, 31, 33, 61, 72, 90], "sarafian": 67, "sarah": 1, "sarkozi": 55, "sat": [30, 51, 60, 89], "satisfactori": [25, 46, 55, 84], "satisfi": [25, 46, 84], "satur": 91, "saturdai": [30, 51, 60, 89], "sauc": 65, "save": [7, 8, 17, 19, 23, 28, 29, 30, 37, 40, 44, 49, 50, 53, 58, 59, 67, 76, 78, 82, 87, 88, 89, 91, 93, 98, 99, 102], "saw": [16, 18, 19, 20, 26, 36, 39, 40, 41, 47, 54, 56, 75, 77, 78, 79, 85, 95], "sb": [24, 45, 54, 58, 83], "scalabl": [12, 26, 32, 47, 56, 71, 85], "scalar": 8, "scale": [14, 15, 17, 19, 20, 21, 22, 24, 26, 29, 31, 34, 35, 37, 40, 41, 42, 43, 45, 47, 50, 52, 54, 56, 59, 61, 63, 64, 68, 69, 73, 74, 76, 78, 79, 80, 81, 83, 85, 88, 90, 91, 92, 95, 97, 98, 99], "scale_pos_weight": [22, 43, 52, 81], "scaler": [16, 23, 24, 36, 44, 45, 53, 54, 61, 65, 75, 82, 83], "scan": 95, "scari": 92, "scatter": [16, 21, 23, 24, 36, 42, 44, 45, 53, 54, 55, 69, 75, 80, 82, 83], "scatter_3d": [24, 45, 54, 83], "scatterplot": [24, 45, 54, 83, 92], "scc": [28, 49, 58, 87], "scenario": [11, 14, 17, 23, 24, 26, 30, 31, 34, 37, 43, 44, 45, 47, 51, 52, 53, 54, 56, 60, 61, 73, 76, 81, 82, 83, 85, 89, 90, 92, 95], "scene": 67, "schafer": 92, "schedul": [61, 90, 95, 103], "schmidt": [19, 40, 78], "school": [12, 20, 22, 23, 27, 32, 41, 43, 44, 48, 52, 53, 57, 71, 79, 81, 82, 86, 100], "schoolteach": [28, 49, 58, 87], "scienc": [1, 2, 9, 10, 11, 17, 25, 30, 37, 46, 51, 55, 60, 76, 84, 89, 91, 95, 97], "scientif": [27, 28, 48, 49, 57, 86, 87], "scientist": [1, 9, 26, 47, 56, 85], "scikit": [9, 10, 11, 13, 15, 18, 19, 20, 22, 25, 26, 29, 30, 33, 35, 39, 40, 41, 43, 46, 47, 50, 51, 52, 54, 59, 61, 65, 68, 72, 74, 77, 78, 79, 81, 84, 85, 88, 89, 91, 93, 94, 99, 100], "scipi": [10, 19, 26, 28, 40, 47, 49, 56, 61, 78, 85, 87, 99], "scm": 5, "scope": [12, 28, 30, 32, 49, 51, 58, 60, 87, 89], "score": [11, 12, 15, 16, 17, 22, 23, 26, 28, 29, 30, 31, 32, 35, 36, 37, 38, 43, 44, 47, 48, 49, 50, 51, 52, 53, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 71, 74, 75, 76, 81, 82, 85, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 99, 100, 101, 102, 103], "score_func": [21, 42, 69, 80], "score_gb_test": 91, "score_gb_train": 91, "score_lr_print_coeff": [30, 89, 102], "score_param": [17, 37, 76], "score_rf_test": 91, "score_rf_train": 91, "score_tim": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 64, 65, 67, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 89, 90, 93], "scorer": [17, 21, 37, 42, 69, 76, 80], "scores_averag": 101, "scores_dict": [18, 38, 39, 66, 67, 77], "scores_imag": [18, 39, 77], "scores_stack": 101, "scoring_method": [31, 61, 90], "scoring_metr": [22, 23, 43, 44, 52, 53, 81, 82, 93], "scotland": [28, 49, 58, 87], "scott": 91, "scratch": [2, 29, 50, 59, 88, 92], "screen": [7, 66, 67], "screennam": 93, "screenplai": [28, 49, 58, 87], "screenporch": [21, 23, 42, 44, 53, 69, 80, 82, 91], "screenshot": 91, "script": [10, 67], "scroog": 93, "sdng": [21, 42, 80, 91], "se": [30, 31, 61, 89, 90, 102], "sea": [29, 50, 59, 88], "seaborn": [23, 24, 25, 26, 27, 44, 45, 46, 47, 48, 53, 54, 55, 56, 57, 58, 82, 83, 84, 85, 86], "seacoast": [29, 50, 59, 88], "search": [4, 5, 10, 21, 28, 42, 49, 69, 80, 87, 95, 99], "search_multi": [21, 42, 69, 80], "seashor": [29, 50, 59, 88], "season": 102, "season_autumn": [30, 89], "season_fal": [30, 89], "season_summ": [30, 89], "season_wint": [30, 89], "seat": [29, 50, 59, 88, 103], "seattl": 93, "seawal": [29, 50, 59, 88], "second": [4, 6, 13, 18, 22, 23, 26, 29, 30, 32, 33, 39, 43, 44, 47, 50, 51, 52, 53, 56, 59, 60, 67, 72, 77, 81, 82, 85, 88, 89, 91], "secondari": [12, 32, 71], "secpompeo": 93, "section": [1, 7, 10, 14, 24, 33, 45, 54, 72, 73, 83, 101, 103], "secur": [23, 44, 53, 82, 92, 103], "see": [1, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 61, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 87, 88, 89, 90, 91, 92, 95, 96, 97, 99, 100, 101, 102, 103], "seed": [18, 19, 25, 26, 39, 40, 46, 47, 55, 56, 64, 70, 77, 78, 84, 85, 92], "seem": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 51, 52, 53, 55, 56, 57, 61, 66, 67, 69, 70, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 86, 89, 90, 93, 94, 97, 99, 100], "seemingli": [20, 41, 79, 100], "seen": [8, 12, 14, 15, 16, 17, 18, 24, 26, 27, 31, 32, 34, 35, 36, 37, 39, 45, 47, 48, 54, 56, 61, 67, 69, 71, 73, 74, 75, 76, 77, 83, 85, 86, 90, 95, 97, 99, 101], "segment": [11, 20, 28, 29, 31, 49, 50, 59, 61, 79, 87, 88, 90, 92, 95], "segmentspher": 92, "selction": 54, "select": [1, 5, 6, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 50, 51, 52, 53, 59, 60, 61, 63, 68, 69, 73, 74, 75, 76, 77, 78, 79, 80, 81, 88, 89, 90, 91, 92], "select_dtyp": [21, 42, 69, 80], "select_knn": [24, 45, 54, 83], "select_rf": [24, 45, 54, 83], "select_svc": [24, 45, 54, 83], "selectfrommodel": [24, 45, 54, 83], "self": [12, 17, 31, 32, 37, 61, 65, 71, 76, 90, 93, 103], "sell": [0, 8, 13, 33, 69, 72, 91], "semant": [11, 25, 26, 28, 46, 47, 49, 55, 56, 84, 85, 87], "semest": [12, 32, 103], "semi": [1, 12, 28, 49, 58, 87], "semicolon": 8, "semilogx": [21, 42, 69, 80], "semiparametricphfitt": 61, "send": [4, 12, 32, 71, 93], "senior": [31, 61, 90], "seniorcitizen": [31, 61, 90], "sens": [6, 14, 17, 18, 20, 21, 23, 24, 25, 27, 28, 30, 31, 34, 37, 38, 39, 41, 42, 44, 45, 46, 48, 49, 51, 53, 54, 55, 57, 58, 60, 66, 67, 73, 76, 77, 79, 80, 82, 83, 84, 86, 87, 89, 90, 92, 94], "sensibl": [7, 92], "sensit": [14, 16, 19, 20, 21, 25, 31, 34, 36, 40, 41, 42, 46, 55, 61, 68, 73, 75, 78, 79, 80, 84, 90], "sent": [12, 28, 32, 49, 58, 71, 87], "sent_token": [28, 49, 58, 87], "sentenc": [28, 49, 87, 91], "sentiment": [13, 18, 28, 38, 39, 49, 58, 66, 67, 72, 77, 87, 93], "sentimentintensityanalyz": 93, "sepal": [15, 35, 64, 74, 97], "separ": [13, 14, 16, 17, 18, 20, 24, 25, 27, 28, 30, 33, 34, 36, 37, 39, 41, 45, 46, 48, 49, 51, 54, 55, 57, 58, 60, 65, 68, 72, 73, 75, 76, 77, 79, 83, 84, 86, 87, 89, 94, 95, 96, 97, 98, 99, 100], "septemb": [30, 51, 60, 89], "sequel": 67, "sequenc": [14, 17, 29, 30, 34, 37, 50, 51, 59, 60, 73, 76, 88, 89], "sequenti": [13, 22, 30, 31, 33, 43, 51, 52, 54, 60, 61, 72, 81, 89, 90, 95], "sequentialfeatureselector": [24, 45, 54, 83], "ser": [31, 36, 61, 73, 75, 90], "seri": [1, 2, 11, 14, 16, 17, 20, 24, 29, 31, 34, 36, 37, 41, 45, 50, 54, 59, 61, 68, 73, 75, 76, 79, 83, 88, 90, 92, 93], "serial": [22, 43, 52, 81], "seriou": [6, 20, 27, 31, 48, 49, 57, 58, 61, 79, 86, 87, 90, 92, 103], "serv": [5, 11, 13, 23, 33, 44, 53, 67, 72, 82, 103], "server": 5, "servic": [22, 23, 27, 31, 43, 44, 48, 52, 53, 57, 61, 65, 81, 82, 86, 90, 93], "session": [12, 13, 84, 95, 103], "set": [1, 7, 8, 9, 13, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 67, 68, 69, 71, 72, 74, 75, 76, 77, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 97, 98, 99, 100, 101, 102], "set_censoring_typ": 61, "set_config": [19, 22, 40, 43, 52, 78, 81], "set_index": [14, 15, 19, 20, 21, 34, 35, 40, 41, 42, 61, 64, 68, 69, 73, 74, 78, 79, 80], "set_num_thread": [29, 50], "set_opt": [12, 13, 14, 15, 16, 17, 18, 19, 20, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 47, 48, 56, 57, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 85, 86, 96, 97, 98, 99, 100], "set_properti": [12, 32, 71], "set_se": [64, 70], "set_titl": [15, 18, 20, 29, 35, 39, 41, 50, 59, 64, 70, 74, 77, 79, 88, 97, 100], "set_xlabel": [15, 18, 25, 35, 39, 46, 55, 58, 64, 74, 77, 84, 97], "set_ylabel": [15, 18, 25, 35, 39, 46, 55, 58, 64, 74, 77, 84, 97], "settl": [99, 100], "setup": [3, 7, 10, 12, 32, 96], "setup_default_warn": 93, "sev": [21, 23, 42, 44, 53, 69, 80, 82, 91], "sever": [10, 16, 18, 25, 26, 28, 29, 30, 36, 39, 46, 47, 49, 50, 55, 56, 58, 59, 67, 75, 77, 84, 85, 87, 88, 89, 94, 102, 103], "sex": [20, 22, 23, 24, 41, 43, 44, 45, 52, 53, 54, 79, 81, 82, 83, 100, 101], "sexual": 103, "sfu": [28, 49, 58, 87], "shall": [0, 28, 49, 58, 87], "shallow": [22, 43, 52, 66, 67, 81], "shan": [28, 49, 58, 87], "shap": 92, "shape": [13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 78, 79, 80, 82, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 95, 97, 100, 102], "shape_df": [14, 34, 73], "shape_dict": [14, 34, 73], "share": [0, 24, 45, 54, 65, 83, 92, 103], "sharealik": 1, "sharex": [16, 36, 75], "she": [12, 27, 28, 32, 48, 49, 57, 58, 67, 71, 86, 87, 93], "shed": [21, 23, 42, 44, 53, 80, 82, 91], "sheet": [9, 92, 95], "shelf": [22, 28, 43, 49, 52, 58, 81, 87, 99], "shell": [5, 9, 12, 32, 93], "shelv": 93, "shift": [30, 51, 60, 89, 102], "shipyard": 65, "shit": 93, "shng": [21, 42, 80, 91], "shock": 67, "shoot": 67, "shop": [27, 48, 57, 86], "short": [1, 10, 14, 19, 22, 28, 40, 43, 49, 58, 73, 78, 81, 87, 103], "shorter": [31, 61, 90], "shorthand": [16, 36, 75], "shortli": 92, "shot": [24, 45, 54, 67, 83], "should": [5, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 20, 23, 24, 25, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 41, 44, 45, 46, 49, 50, 51, 53, 54, 55, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 72, 73, 74, 75, 76, 77, 79, 82, 83, 84, 87, 88, 89, 90, 92, 93, 95, 96, 97, 98, 99, 101, 102, 103], "shouldn": [20, 22, 28, 41, 43, 49, 52, 58, 68, 79, 81, 87, 97], "show": [4, 7, 10, 12, 14, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 34, 36, 37, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 67, 70, 71, 73, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 92, 93, 95, 97, 99, 101, 102], "show_nearest_neighbor": 64, "show_plot": [31, 61, 90], "show_progress": 61, "showcas": [28, 49, 58, 87], "shown": [7, 10, 12, 13, 15, 20, 22, 25, 26, 30, 32, 33, 35, 41, 43, 46, 47, 51, 52, 56, 60, 68, 71, 72, 74, 79, 81, 84, 85, 89, 91], "shrink": [19, 24, 40, 45, 54, 78, 83, 91], "shuffl": [14, 29, 30, 34, 50, 59, 64, 67, 70, 73, 88, 89, 102], "si": [12, 32, 71], "sibl": [24, 45, 54, 83], "sick": [25, 46, 55, 84, 93], "sid": 93, "side": [6, 29, 30, 50, 58, 59, 88, 91], "sift": [27, 48, 57, 86], "sigma": [29, 50, 54, 59, 88], "sigmoid": 54, "sign": [4, 21, 23, 29, 38, 42, 44, 50, 53, 59, 66, 67, 69, 80, 82, 88, 97, 99, 101, 103], "signal": [14, 28, 34, 49, 58, 73, 87], "signatur": 58, "signific": [11, 16, 29, 36, 50, 59, 65, 75, 88, 91], "significantli": [17, 20, 27, 37, 41, 48, 57, 76, 79, 86], "sigoptsearchcv": [19, 40, 78], "silhouett": [26, 47, 56, 85], "silhouettevisu": [25, 26, 46, 47, 55, 56, 84, 85], "sim": [23, 44, 53, 82], "sim_word": [28, 49, 58, 87], "simard": [23, 44, 53, 82], "similar": [1, 10, 13, 14, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 31, 32, 33, 34, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 52, 54, 55, 56, 57, 64, 68, 72, 73, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 90, 91, 94], "similarity_": [28, 49, 58, 87], "similarli": [23, 25, 31, 42, 44, 46, 53, 55, 61, 82, 84, 90], "simon_fras": [28, 49, 58, 87], "simp": [30, 51, 89], "simpl": [1, 13, 15, 16, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 33, 35, 36, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 60, 61, 69, 72, 74, 75, 79, 80, 81, 82, 83, 85, 86, 87, 89, 90, 91, 92, 95, 96, 100], "simplefilt": [22, 23, 43, 44, 52, 53, 69, 81, 82], "simpleimput": [16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 36, 37, 39, 40, 41, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 69, 75, 76, 77, 78, 79, 80, 81, 82, 83, 89, 90, 91, 93, 95, 98, 99, 100, 101, 102], "simpleimputersimpleimput": [16, 17, 21, 22, 24, 36, 37, 42, 43, 45, 52, 65, 75, 76, 80, 81, 83, 91], "simpler": [18, 19, 39, 40, 63, 77, 78, 92, 97], "simplest": [17, 37, 70, 76], "simpli": [16, 24, 25, 28, 36, 45, 46, 49, 54, 55, 58, 59, 67, 75, 83, 84, 87], "simplic": [13, 17, 27, 33, 37, 48, 57, 72, 76, 86], "simplist": [15, 23, 35, 44, 53, 64, 67, 74, 82, 97], "simul": [24, 45, 54, 83], "sin": 8, "sinc": [5, 12, 18, 21, 23, 24, 25, 27, 29, 30, 31, 32, 39, 42, 44, 45, 46, 48, 50, 51, 53, 54, 55, 57, 59, 60, 61, 64, 67, 69, 77, 80, 82, 83, 84, 86, 88, 89, 90, 91, 94, 95, 96, 102], "singer_songwriter_bob_dylan": [28, 49, 87], "singl": [8, 15, 16, 18, 19, 20, 22, 23, 26, 30, 31, 35, 36, 39, 40, 41, 43, 44, 47, 51, 52, 53, 54, 60, 61, 64, 68, 74, 75, 77, 78, 79, 81, 82, 85, 89, 90, 95, 96, 97, 99, 100], "singular": 61, "sit": [65, 67, 103], "sitarist_ravi_shankar": [28, 49, 87], "site": [5, 12, 17, 19, 29, 31, 33, 37, 50, 61, 64, 65, 72, 73, 76, 78, 82, 90, 93, 94, 103], "situat": [6, 12, 20, 22, 25, 29, 31, 32, 41, 46, 50, 52, 55, 59, 61, 67, 68, 71, 79, 81, 84, 88, 90, 103], "six": [14, 22, 30, 43, 51, 52, 60, 73, 81, 89, 92], "size": [12, 13, 14, 15, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 68, 71, 72, 73, 74, 76, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 96, 97, 101, 102, 103], "skeleton": 91, "skeptic": 91, "skew": [21, 42, 69, 80], "skill": [11, 43, 52, 81, 92], "skin": 93, "skip": [69, 100], "skip_check_arrai": [61, 65], "skip_parameter_valid": [61, 65], "skipna": [31, 61, 90], "sklearn": [1, 12, 14, 15, 18, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 38, 39, 42, 45, 46, 47, 48, 49, 50, 51, 54, 56, 57, 59, 60, 61, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 77, 80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102], "sklearn_gb": [22, 43, 52, 81], "sklearn_histgb": [22, 43, 52, 81], "sktime": [30, 51, 60, 89], "skyblu": [30, 89, 102], "skyscrap": [30, 51, 60, 89], "sl": [28, 49, 58, 87], "slate": 102, "slice": 8, "slide": [1, 9, 16, 29, 36, 50, 59, 62, 75, 88, 103], "slider": 25, "slightli": [17, 18, 20, 22, 31, 37, 39, 41, 43, 52, 61, 64, 65, 68, 76, 77, 79, 81, 90], "slipper": 91, "slope": [18, 39, 77], "sloppi": [16, 36, 75], "slot": 103, "slow": [15, 22, 24, 29, 35, 43, 45, 50, 52, 54, 59, 67, 74, 81, 83, 88], "slower": [22, 25, 43, 46, 52, 55, 67, 81, 84], "slowest": 101, "sm": [12, 17, 32, 37, 71, 76], "smac": [19, 40, 78], "small": [10, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 27, 29, 31, 34, 35, 37, 40, 42, 43, 44, 46, 48, 50, 52, 53, 54, 55, 57, 59, 61, 64, 65, 69, 70, 73, 74, 76, 78, 80, 81, 82, 83, 84, 86, 88, 90, 95, 97, 99, 101], "small_citi": [15, 35, 74], "small_train_df": [15, 35, 74], "smallalpha_coeff": [21, 42, 69, 80], "smaller": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 31, 35, 36, 37, 39, 42, 43, 44, 45, 46, 47, 51, 53, 54, 55, 56, 61, 63, 68, 69, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 89, 90, 91, 97, 99], "smallest": [18, 21, 25, 26, 39, 42, 46, 47, 56, 69, 77, 80, 84, 85], "smart": [25, 46, 55, 84, 91, 93], "smile": 93, "smooth": [15, 35, 54, 74, 97], "smoothli": 10, "smote": 41, "smote_pip": [20, 79], "sms_df": [12, 32, 71], "sn": [23, 25, 26, 44, 46, 47, 53, 55, 56, 82, 84, 85], "snake": [18, 29, 39, 50, 59, 77, 88], "snake_length": [18, 39, 77], "snakes_df": [18, 39, 77], "snbf": 81, "snippet": [7, 12, 32], "snow": [12, 29, 32, 50, 59, 71, 88], "snp": [24, 45, 54, 83], "so": [0, 1, 4, 5, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103], "soap": 67, "social": [25, 26, 27, 30, 46, 47, 48, 51, 55, 60, 84, 85, 86, 89], "societ": 11, "societi": [20, 28, 41, 49, 58, 79, 87, 100], "sofist": 97, "soft": [18, 22, 39, 43, 52, 65, 77, 81, 101], "softmax": 95, "softwar": [1, 5, 10, 31, 61, 90], "solar": [27, 48, 57, 86], "sold": [8, 21, 42, 69, 80], "sole": [20, 26, 41, 47, 56, 79, 85], "solid": 67, "solidifi": 95, "solut": [12, 14, 22, 25, 31, 32, 33, 34, 46, 55, 61, 71, 72, 73, 81, 84, 90, 91, 92, 93, 95, 103], "solv": [4, 12, 13, 15, 24, 28, 32, 33, 34, 35, 45, 49, 54, 58, 61, 71, 72, 74, 83, 87, 91, 92, 97, 103], "solver": [20, 41, 54, 79], "some": [4, 6, 7, 8, 10, 12, 14, 15, 16, 17, 18, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 80, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99, 100, 102, 103], "someon": [12, 13, 14, 24, 31, 32, 33, 34, 45, 54, 61, 67, 71, 72, 73, 83, 90, 91], "someth": [4, 7, 10, 13, 17, 20, 21, 22, 23, 25, 30, 31, 33, 37, 41, 42, 44, 46, 51, 53, 55, 59, 60, 61, 67, 68, 69, 72, 76, 79, 80, 81, 82, 84, 89, 90, 91, 92, 95, 103], "sometim": [6, 13, 14, 17, 18, 19, 22, 23, 28, 33, 34, 37, 39, 40, 43, 44, 49, 53, 58, 60, 67, 72, 73, 76, 77, 78, 81, 82, 87, 91, 92], "somewhat": [21, 42, 67, 69, 80], "somewher": [12, 21, 32, 42, 71, 80], "song": [15, 16, 27, 36, 48, 57, 74, 75, 86, 93, 99], "song_titl": [15, 16, 19, 36, 40, 74, 75, 78, 99], "soon": [12, 15, 16, 30, 32, 35, 36, 51, 67, 71, 74, 75, 89, 92], "sopha": [12, 32, 71], "sophist": [19, 23, 28, 40, 44, 49, 53, 58, 78, 82, 87], "sorri": 67, "sort": [1, 5, 13, 14, 16, 23, 27, 28, 29, 30, 34, 36, 38, 40, 44, 48, 49, 50, 51, 53, 57, 58, 59, 60, 66, 67, 68, 72, 73, 75, 82, 86, 87, 88, 89, 92, 102], "sort_index": [8, 19, 21, 30, 40, 42, 51, 60, 69, 78, 80, 89, 102], "sort_valu": [16, 17, 18, 19, 21, 22, 23, 24, 30, 31, 36, 37, 38, 39, 40, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 63, 66, 67, 69, 75, 76, 77, 78, 80, 81, 82, 83, 89, 90, 93, 101, 102], "sound": [23, 24, 44, 45, 53, 54, 67, 82, 83], "soundtrack": [28, 49, 58, 87], "sourc": [10, 12, 13, 14, 15, 16, 17, 19, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 36, 37, 40, 43, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 61, 65, 70, 71, 72, 73, 74, 75, 76, 78, 81, 82, 83, 84, 85, 86, 87, 88, 93, 96, 99, 103], "south": [17, 76], "space": [15, 18, 19, 24, 25, 26, 28, 33, 35, 39, 40, 45, 46, 47, 49, 54, 55, 56, 58, 74, 77, 78, 83, 84, 85, 87, 93, 102, 103], "spaci": [24, 45, 54, 83], "spacymoji": 93, "spam": [14, 20, 25, 34, 41, 46, 55, 68, 73, 79, 84], "spam_predict": [12, 32, 71], "span": [28, 30, 49, 51, 58, 60, 87, 89], "spanish": [16, 36, 75], "spars": [12, 15, 18, 22, 27, 28, 32, 35, 39, 43, 48, 49, 52, 57, 58, 65, 67, 74, 77, 81, 86, 87, 95], "sparse_output": [16, 17, 20, 21, 22, 23, 30, 31, 36, 37, 41, 42, 43, 44, 52, 53, 61, 65, 69, 75, 76, 79, 80, 81, 82, 89, 90, 91, 95, 100, 101, 102], "sparse_output_": 61, "spatial": [18, 39, 77], "speak": [5, 67, 92], "spearmint": [19, 40, 78], "speci": [15, 35, 64, 70, 74, 95, 97], "special": [11, 12, 17, 27, 28, 29, 30, 31, 32, 37, 48, 49, 50, 51, 57, 58, 59, 60, 61, 67, 71, 76, 86, 87, 88, 89, 90, 97], "specialti": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82], "specif": [8, 11, 13, 14, 19, 20, 23, 25, 27, 28, 29, 30, 31, 33, 34, 40, 41, 44, 46, 48, 49, 50, 51, 53, 57, 58, 59, 60, 65, 72, 73, 78, 79, 82, 84, 86, 87, 88, 89, 90, 91, 92, 95, 97, 99, 101], "specifi": [8, 13, 14, 17, 19, 20, 25, 26, 29, 33, 34, 37, 40, 41, 46, 47, 50, 55, 56, 59, 64, 72, 73, 76, 78, 79, 84, 85, 88, 91, 92, 99, 101], "spectrogram": [24, 45, 54, 83], "speech": [24, 28, 45, 49, 54, 58, 83, 87, 93], "speechi": [15, 16, 19, 36, 40, 74, 75, 78, 99], "speed": [8, 13, 22, 29, 33, 38, 43, 50, 52, 59, 66, 67, 72, 81, 88, 92], "spell": [12, 32, 71], "spend": [12, 16, 24, 32, 36, 45, 54, 65, 67, 71, 75, 83, 91, 93, 103], "spent": [6, 16, 24, 36, 45, 54, 75, 83], "spheric": [26, 47, 56, 85, 95], "spici": [25, 46, 84], "spini": [29, 50, 59, 88], "spit": [29, 50, 59, 88], "spline": 61, "split": [11, 13, 15, 17, 18, 19, 21, 22, 24, 27, 28, 31, 33, 35, 37, 38, 39, 40, 42, 43, 45, 48, 49, 52, 58, 61, 66, 67, 68, 69, 72, 74, 76, 77, 78, 80, 81, 83, 86, 87, 90, 92, 93, 95, 100, 101, 102], "split0_test_r2": [21, 42, 80], "split0_test_scor": [19, 40, 78], "split0_train_neg_mean_squared_error": [21, 42, 80], "split0_train_scor": [19, 40, 78], "split1_test_r2": [21, 42, 80], "split1_test_scor": [19, 40, 78], "split1_train_neg_mean_squared_error": [21, 42, 80], "split1_train_scor": [19, 40, 78], "split2_test_r2": [21, 42, 80], "split2_test_scor": [19, 40, 78], "split2_train_neg_mean_squared_error": [21, 42, 80], "split2_train_scor": [19, 40, 78], "split3_test_r2": [21, 42, 80], "split3_test_scor": [19, 40, 78], "split3_train_neg_mean_squared_error": [21, 42, 80], "split3_train_scor": [19, 40, 78], "split4_test_scor": [19, 40, 78], "split4_train_neg_mean_squared_error": [21, 42, 80], "split4_train_scor": [19, 40, 78], "spoil": 67, "spoken": [17, 37, 76], "sport": [28, 29, 30, 49, 50, 51, 58, 59, 60, 87, 88, 89], "spot": [20, 21, 41, 42, 68, 69, 79, 80, 92, 97], "spotifi": [15, 27, 48, 57, 74, 86, 99], "spotify_df": [15, 16, 19, 36, 40, 74, 75, 78, 99], "spotlight": [5, 10], "spous": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82], "spread": [26, 47, 56, 67, 85], "spring": 67, "spring_month": [30, 89], "spsolv": 61, "sqft": [23, 44, 53, 82], "sqft_abov": [12, 13, 32, 63, 71, 72], "sqft_basement": [12, 13, 32, 63, 71, 72], "sqft_live": [12, 13, 32, 63, 71, 72], "sqft_living15": [12, 13, 32, 63, 71, 72], "sqft_lot": [12, 13, 32, 63, 71, 72], "sqft_lot15": [12, 13, 32, 63, 71, 72], "sqrt": [15, 21, 23, 27, 28, 35, 42, 44, 48, 49, 53, 57, 58, 69, 74, 80, 82, 86, 87], "squar": [8, 11, 13, 15, 18, 23, 27, 31, 33, 35, 39, 44, 48, 53, 54, 57, 61, 72, 74, 77, 82, 86, 90, 91, 93, 95], "squash": [18, 29, 39, 50, 59, 77, 88], "squeez": [8, 31, 61, 65, 90], "src": [20, 29, 34, 41, 50, 73, 79], "sse": [30, 89, 102], "ssw": [30, 89], "st": [30, 51, 60, 89, 93], "st_slope": 101, "stabil": 10, "stabl": [14, 20, 22, 34, 41, 43, 52, 65, 73, 79, 81, 97], "stack": [7, 11, 53, 65, 92, 95], "stack_method": 101, "stacking_model": [22, 43, 52, 81, 101], "stacking_model_tre": [22, 43, 52, 81], "stackingclassifi": [22, 43, 52, 81, 101], "stackingregressor": [22, 43, 52, 81], "staff": 6, "stai": [12, 20, 31, 32, 41, 61, 68, 79, 90], "stakehold": [11, 91, 92], "stale": [25, 46, 55, 84], "stand": [15, 19, 28, 35, 40, 49, 58, 67, 74, 78, 87, 92], "standard": [4, 6, 14, 16, 19, 22, 23, 24, 28, 34, 36, 40, 43, 44, 45, 49, 52, 53, 54, 58, 73, 75, 78, 81, 82, 83, 87, 92], "standardscal": [17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 65, 68, 69, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 93, 95, 98, 99, 100, 101, 102], "standardscalerstandardscal": [16, 17, 19, 20, 21, 22, 24, 29, 36, 37, 40, 41, 42, 43, 45, 50, 52, 59, 65, 75, 76, 78, 79, 80, 81, 83, 88, 91, 93], "stanford": [28, 49, 58, 87], "star": [15, 25, 27, 35, 46, 48, 57, 74, 84, 86, 93], "start": [7, 8, 10, 13, 14, 15, 20, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33, 34, 35, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 64, 65, 67, 68, 70, 72, 73, 74, 79, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102], "startswith": [23, 38, 44, 53, 54, 68, 82], "starttim": [30, 51, 60, 89], "stat": [19, 31, 40, 61, 78, 90, 99], "state": [6, 8, 14, 20, 22, 23, 27, 28, 34, 41, 43, 44, 48, 49, 52, 53, 57, 58, 61, 73, 79, 81, 82, 86, 87, 92, 93, 100], "statement": [7, 14, 15, 16, 17, 18, 19, 20, 21, 24, 29, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 50, 54, 59, 61, 73, 74, 75, 76, 77, 78, 79, 80, 83, 88, 90, 91], "static": [12, 32, 92], "station": [30, 51, 60, 67, 89], "statist": [1, 9, 11, 13, 18, 23, 27, 28, 31, 33, 39, 44, 48, 49, 57, 59, 61, 72, 77, 82, 86, 87, 90], "statistician": [15, 35, 74], "statlib": [18, 39, 77], "statsmodel": [30, 31, 51, 60, 61, 89, 90], "statu": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "status_marri": [23, 44, 53, 82], "status_nev": [23, 44, 53, 82], "status_separ": [23, 44], "std": [14, 15, 16, 20, 21, 29, 30, 34, 35, 36, 41, 42, 50, 54, 59, 61, 63, 64, 65, 73, 74, 75, 79, 80, 88, 89, 93, 94, 102], "std_cv_error": [14, 34, 73], "std_cv_score": [15, 35, 64, 74], "std_fit_tim": [19, 21, 40, 42, 78, 80], "std_score": [14, 16, 34, 36, 54, 61, 73, 75, 93], "std_score_tim": [19, 21, 40, 42, 78, 80], "std_test_neg_mean_squared_error": [21, 42, 80], "std_test_scor": [14, 19, 34, 40, 73, 78], "std_train_error": [14, 34, 73], "std_train_neg_mean_squared_error": [21, 42, 80], "std_train_scor": [14, 15, 19, 34, 35, 40, 64, 73, 74, 78], "stdki": [31, 90], "steal": 67, "stem": [28, 49, 87], "step": [7, 12, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 64, 65, 66, 67, 68, 71, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 95, 96, 97, 99, 101, 103], "step_siz": 61, "stereotyp": [28, 49, 87], "steroid": 67, "stick": [13, 30, 51, 60, 66, 67, 89], "still": [4, 10, 19, 20, 21, 22, 24, 25, 30, 31, 33, 40, 41, 42, 43, 45, 46, 51, 52, 54, 55, 60, 61, 67, 78, 79, 80, 81, 83, 84, 89, 90, 93, 97, 98, 99, 100], "stipul": 91, "stochast": [24, 25, 45, 46, 54, 55, 83, 84], "stock": [12, 30, 32, 51, 60, 71, 89], "stomach": 67, "stop": [8, 25, 28, 29, 31, 46, 49, 50, 58, 59, 61, 63, 65, 67, 84, 87, 88, 90, 97], "stop_word": [19, 20, 28, 38, 40, 49, 58, 65, 66, 67, 78, 79, 87, 92, 93, 99], "stopword": [28, 49, 87], "storag": [15, 74], "store": [7, 8, 15, 16, 17, 19, 20, 22, 23, 26, 27, 28, 29, 30, 31, 35, 36, 37, 40, 41, 43, 44, 47, 48, 49, 50, 51, 56, 57, 58, 59, 60, 61, 67, 68, 74, 75, 76, 78, 79, 81, 82, 85, 86, 87, 88, 89, 90, 92, 93], "stori": [21, 22, 42, 43, 67, 69, 80, 81, 93], "storylin": [28, 49, 58, 87], "str": [19, 23, 28, 30, 31, 38, 40, 44, 49, 51, 53, 58, 61, 64, 68, 78, 82, 87, 89, 90, 93, 102], "straight": [31, 61, 67, 90, 92], "straightforward": [23, 44, 48, 53, 82], "strain": 7, "strang": [23, 31, 44, 53, 61, 69, 82, 90], "strata": [31, 61, 90], "strategi": [13, 15, 16, 17, 20, 21, 23, 25, 27, 30, 31, 33, 35, 36, 37, 41, 42, 44, 46, 48, 53, 55, 57, 61, 65, 68, 69, 72, 74, 75, 76, 79, 80, 82, 84, 86, 89, 90, 91, 92, 95, 96, 100, 102], "stratif": [31, 61, 90], "stratifi": [31, 61, 90], "stratifiedkfold": [14, 20, 34, 41, 73, 79], "stream": [31, 61, 90, 93], "streamingmovi": [31, 61, 90], "streamingmovies_no": [31, 61, 90], "streamingmovies_y": [31, 61, 90], "streamingtv": [31, 61, 90], "streamingtv_no": [31, 61, 90], "streamingtv_y": [31, 61, 90], "street": [21, 23, 42, 44, 53, 80, 82, 91], "street_grvl": [21, 42, 44, 80], "street_pav": [21, 42, 44, 80], "strength": [28, 49, 54, 58, 87, 95], "stress": 84, "strftime": [30, 51, 60, 61, 89, 90], "string": [8, 10, 15, 20, 21, 22, 23, 28, 30, 31, 35, 41, 42, 43, 44, 49, 52, 53, 58, 61, 65, 68, 69, 74, 79, 80, 81, 82, 87, 89, 90, 97, 101], "strip": [23, 29, 44, 50, 53, 59, 82, 88], "stroke": 67, "strong": [22, 31, 43, 52, 61, 81, 90, 95], "stronger": [22, 43, 52, 81], "strongli": [22, 43, 52, 81], "struck": 67, "structur": [8, 25, 28, 29, 46, 49, 50, 55, 58, 59, 84, 87, 88], "struggl": [30, 51, 60, 84, 89], "stuart": [1, 22, 43, 52, 81], "stuck": [4, 8], "student": [1, 4, 5, 6, 7, 11, 12, 13, 18, 20, 21, 23, 24, 25, 26, 27, 29, 32, 33, 39, 41, 42, 44, 45, 46, 47, 48, 50, 53, 54, 55, 56, 57, 59, 69, 71, 72, 77, 79, 80, 82, 83, 84, 85, 86, 88, 92, 93, 103], "studi": [12, 17, 24, 28, 31, 32, 37, 45, 49, 54, 58, 61, 71, 76, 83, 87, 90], "stuff": [15, 29, 31, 35, 50, 61, 64, 67, 70, 74, 88, 90], "stump": [13, 14, 15, 22, 33, 34, 35, 52, 63, 72, 73, 74, 81, 96], "stun": 67, "stunningli": 67, "stupid": [67, 93], "style": [21, 24, 25, 27, 28, 29, 42, 45, 46, 48, 49, 50, 54, 55, 57, 58, 59, 69, 71, 80, 83, 84, 86, 87, 88, 92, 93], "sub": [25, 28, 31, 38, 40, 46, 49, 50, 55, 61, 66, 67, 78, 84, 87, 90, 92, 95], "subdirectori": [23, 44, 82, 92], "subgroup": [31, 61, 90], "subject": [0, 1, 31, 61, 90, 103], "sublicens": 0, "submiss": [3, 103], "submit": [1, 8, 16, 32, 92, 103], "subplot": [14, 15, 18, 20, 25, 29, 31, 34, 35, 39, 41, 46, 50, 55, 59, 61, 64, 70, 73, 74, 77, 79, 84, 88, 90, 91, 97, 100], "subplot_kw": [14, 34, 64, 70, 73], "subprocess": [21, 42, 68, 80], "subscrib": [31, 61, 90], "subscript": [30, 31, 51, 60, 61, 89, 90], "subset": [13, 14, 19, 22, 29, 30, 33, 34, 40, 43, 50, 51, 52, 59, 60, 64, 70, 72, 73, 78, 81, 88, 89, 94, 97], "substanti": 0, "substitut": 0, "subtl": [28, 49, 58, 87], "subtleti": [14, 21, 34, 42, 73, 80], "subtract": [15, 20, 23, 32, 35, 44, 53, 68, 74, 79, 82], "suburb": 93, "subword": [28, 49, 87], "succe": [24, 45, 54, 67, 83, 103], "success": [5, 8, 10, 12, 20, 22, 27, 28, 29, 30, 32, 43, 48, 49, 50, 51, 52, 57, 59, 60, 71, 79, 81, 86, 87, 88, 89, 92], "successfulli": [10, 12, 32, 71, 93], "suddenl": 67, "suddenli": 67, "sudo": 5, "suei": [40, 78], "suffer": [19, 40, 67, 78], "suffici": [7, 28, 49, 58, 87], "suggest": [0, 1, 13, 27, 31, 33, 48, 57, 61, 66, 67, 69, 72, 86, 90, 92], "suicid": [28, 49, 58, 87], "suit": [27, 36, 48, 57, 67, 86], "suitabl": [10, 11, 12, 25, 27, 32, 46, 48, 55, 57, 63, 71, 84, 86, 92, 95, 101], "sultan": [28, 49, 58, 87], "sum": [8, 15, 16, 17, 18, 22, 23, 25, 29, 35, 36, 37, 38, 39, 43, 44, 46, 50, 52, 53, 54, 55, 59, 65, 70, 74, 75, 76, 77, 81, 82, 84, 88, 93], "sum_": [15, 21, 25, 28, 29, 35, 42, 46, 49, 50, 55, 58, 59, 69, 74, 80, 84, 87, 88], "sum_i": [23, 28, 44, 49, 53, 54, 58, 82, 87], "sum_j": 54, "sum_prob_ex1_class_0": [22, 43, 52, 81], "sum_prob_ex1_class_1": [22, 43, 52, 81], "summar": [1, 12, 18, 20, 21, 25, 28, 32, 39, 41, 42, 46, 49, 55, 58, 68, 71, 77, 79, 80, 84, 87, 92], "summari": [0, 94, 95, 97], "summary_plot": [23, 44, 53, 82], "summat": [43, 52, 81, 91], "summer": [27, 30, 48, 57, 67, 86, 89], "summer_month": [30, 89], "sun": [28, 30, 49, 51, 58, 60, 87, 89], "sundai": [30, 51, 60, 89], "sundial": [29, 50, 59, 88], "sunshin": [19, 30, 89, 102], "sunstrum": [1, 103], "super": [17, 37, 61, 76, 93, 95], "superfici": [15, 35, 74], "superior": 11, "supermarket": 93, "supervis": [11, 16, 17, 19, 20, 21, 24, 26, 28, 30, 31, 36, 37, 40, 41, 42, 45, 47, 49, 51, 54, 56, 58, 60, 61, 65, 68, 69, 75, 76, 78, 79, 80, 83, 85, 87, 89, 90, 95, 102, 103], "suppli": 103, "support": [10, 13, 16, 20, 22, 23, 24, 26, 28, 29, 33, 36, 41, 43, 44, 47, 49, 52, 53, 54, 56, 58, 61, 64, 65, 72, 75, 79, 81, 82, 83, 85, 87, 91, 93, 94, 97, 103], "support_": [15, 24, 35, 45, 54, 74, 83], "suppos": [12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 32, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 57, 58, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 91, 95, 96], "suppress": 8, "suprem": [28, 49, 58, 87], "supr\u00eam": [28, 49, 58, 87], "sure": [4, 7, 8, 10, 13, 14, 15, 16, 17, 20, 21, 22, 23, 26, 29, 30, 35, 37, 41, 42, 43, 44, 47, 50, 52, 59, 61, 68, 73, 74, 76, 79, 80, 81, 82, 85, 88, 89, 91, 92, 97, 100, 101, 102, 103], "surfac": 33, "surgeri": [31, 61, 90], "surpris": [23, 27, 44, 48, 53, 57, 67, 82, 86], "surprisingli": [17, 18, 37, 39, 61, 76, 77], "surround": [4, 11, 67, 91], "survei": [25, 46, 65, 84], "surviv": [1, 2, 11, 91, 92], "survival_function_": [31, 61, 90], "suscept": [26, 47, 56, 85, 92], "sushi": 58, "suspect": [19, 40, 78], "suspens": 67, "suspicion": 61, "svc": [15, 16, 17, 18, 19, 22, 23, 24, 29, 35, 36, 37, 39, 40, 43, 44, 45, 50, 52, 53, 54, 59, 64, 65, 74, 75, 76, 77, 78, 81, 82, 83, 88, 93, 97, 98, 99, 101], "svc__c": [19, 40, 78, 99], "svc__degre": 19, "svc__gamma": [19, 40, 78, 99], "svc__kernel": 19, "svc_pipe": [19, 40, 78], "svc_pred": [20, 41, 68, 79], "svcsvc": [17, 19, 20, 37, 40, 41, 76, 78, 79], "svm": [1, 14, 16, 17, 19, 22, 23, 24, 29, 30, 34, 36, 37, 40, 43, 44, 45, 50, 51, 52, 53, 54, 59, 60, 65, 73, 75, 76, 78, 81, 82, 83, 88, 89, 91, 92, 93, 94, 95, 97, 98, 99, 101], "svm_estim": [20, 79], "svr": [15, 23, 35, 44, 53, 74, 76, 82, 91], "svr_c_pipe": 76, "svr_pipe": 76, "sw": [30, 89, 102], "swai": [12, 71], "swamp": [15, 35, 74], "swan": [29, 50, 59, 88], "swcarpentri": 9, "sweep": [20, 41, 68, 79], "sweet": [67, 93], "switch": [13, 23, 25, 30, 31, 44, 46, 53, 55, 61, 82, 84, 89, 90, 91, 102], "swng": [1, 103], "sy": [12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101], "sydnei": [30, 89], "syllabu": [3, 7, 12, 13, 15, 16, 17, 32], "symbol": [33, 72], "symmetri": [24, 45, 54, 83], "sync": 5, "synonym": [28, 49, 58, 87], "synopsi": [28, 49, 87], "syntact": [28, 49, 87], "syntax": [4, 8, 12, 24, 31, 32, 45, 54, 71, 83, 90], "syntaxwarn": 50, "synthet": [24, 45, 54, 83, 94], "system": [1, 2, 4, 5, 6, 10, 11, 12, 14, 15, 17, 20, 23, 25, 30, 32, 34, 41, 44, 46, 51, 53, 55, 60, 64, 68, 71, 73, 74, 76, 79, 82, 84, 89, 91, 92, 100], "systemat": [13, 19, 23, 28, 33, 40, 44, 49, 53, 58, 72, 76, 78, 82, 87], "t": [1, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 101, 102], "t2a": 103, "t2b": 103, "t2c": 103, "t2d": 103, "t2e": 103, "t2f": 103, "t2g": 103, "t2h": 103, "t2i": 103, "t2j": 103, "t2k": 103, "ta": [7, 12, 21, 23, 32, 42, 44, 53, 69, 71, 80, 82, 91, 92, 96, 97, 98, 99, 100, 101, 102], "tab": [12, 32], "tabbi": [12, 29, 32, 50, 59, 71, 88], "tabl": [7, 43, 65, 101], "tabular": [8, 12, 29, 30, 32, 50, 51, 59, 60, 64, 71, 88, 89], "tackl": [14, 16, 20, 26, 34, 36, 47, 73, 75, 79, 85, 97], "taco": [24, 45, 54, 83], "tag": [4, 28, 49, 58, 87, 93], "tail": [8, 30, 51, 60, 89], "tailor": [11, 25, 46, 55, 84, 91, 92], "take": [2, 4, 5, 6, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 61, 65, 67, 68, 69, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103], "taken": [30, 51, 60, 89, 94, 99, 103], "takoyaki": 58, "talk": [13, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 68, 69, 72, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 92, 93, 94, 95, 103], "tall": [28, 49, 58, 87], "target": [14, 15, 16, 18, 19, 20, 22, 23, 24, 27, 29, 30, 31, 34, 35, 36, 38, 39, 40, 41, 43, 44, 45, 48, 50, 51, 52, 53, 54, 57, 59, 60, 61, 64, 65, 66, 67, 73, 74, 75, 77, 78, 79, 81, 82, 83, 86, 88, 89, 90, 91, 92, 95, 97, 98, 99, 100, 101, 102], "target_column": [22, 23, 31, 43, 44, 52, 53, 61, 81, 82, 90, 101], "target_nam": [20, 41, 68, 79], "target_names_toi": [20, 79], "target_tag": 65, "tariff": [28, 49, 58, 87], "task": [11, 16, 17, 18, 19, 23, 24, 25, 27, 29, 30, 31, 36, 37, 39, 40, 44, 45, 46, 48, 50, 51, 53, 54, 55, 57, 59, 60, 61, 63, 64, 75, 76, 77, 78, 82, 83, 84, 86, 88, 89, 90, 91, 92, 93, 95, 99, 102], "tast": [25, 27, 46, 48, 57, 65, 84, 86], "tasti": 65, "taught": [17, 28, 37, 49, 58, 76, 87, 103], "tax": 91, "tba": 1, "teach": [4, 12, 16, 28, 29, 32, 36, 49, 58, 59, 71, 75, 87, 95], "team": [4, 8, 12, 23, 28, 32, 43, 44, 49, 52, 53, 58, 71, 81, 82, 87, 101], "tech": [15, 20, 23, 41, 44, 74, 79, 82], "technic": [67, 91, 92, 103], "techniqu": [1, 11, 12, 15, 19, 24, 27, 29, 31, 35, 40, 41, 45, 48, 50, 54, 57, 59, 61, 67, 68, 74, 78, 83, 86, 88, 90, 92, 94, 95], "technolog": 0, "technologi": [28, 49, 58, 87], "techsupport": [31, 61, 90], "techsupport_no": [31, 61, 90], "techsupport_y": [31, 61, 90], "ted": [25, 46, 84], "tediou": [26, 47, 56, 85], "telco": [31, 61, 90], "telecom": [31, 61, 90], "telephon": [28, 49, 58, 87], "tell": [14, 15, 16, 18, 20, 23, 24, 27, 28, 30, 31, 34, 36, 39, 41, 44, 45, 48, 49, 53, 54, 57, 58, 61, 67, 68, 73, 74, 75, 77, 79, 82, 83, 86, 87, 89, 90, 91, 92, 97, 99, 102], "temp3pm": [30, 89, 102], "temp9am": [30, 89, 102], "temperatur": [13, 33, 72], "templat": 92, "tempo": [15, 16, 19, 36, 40, 74, 75, 78, 99], "tempor": [31, 61, 90, 95, 102], "tend": [14, 15, 18, 22, 24, 27, 30, 31, 34, 35, 39, 43, 45, 48, 51, 52, 54, 57, 60, 61, 73, 74, 77, 81, 83, 86, 89, 90, 103], "tendenc": [14, 34, 73], "tensor": [29, 50, 59, 64, 70, 88], "tensor_numpi": 93, "tensorflow": [10, 23, 29, 44, 50, 53, 59, 82, 88], "tent": 12, "tenur": [31, 61, 90, 91, 95], "tenure_lm": [31, 61, 90], "tenure_predict": [31, 61, 90], "teriyaki": 58, "term": [0, 2, 13, 15, 17, 18, 20, 23, 24, 27, 28, 31, 33, 35, 37, 39, 41, 44, 45, 48, 49, 53, 54, 57, 58, 61, 68, 72, 74, 76, 77, 79, 82, 83, 86, 87, 90, 91, 92, 95], "termin": [5, 10, 13, 25, 46, 55, 72, 84, 92], "terminologi": [14, 20, 68, 73, 79, 95, 96], "terrac": [29, 50, 59, 88], "terribl": [21, 27, 42, 48, 57, 67, 69, 80, 86], "terribli": 67, "territori": 103, "tesoro": [40, 78], "test": [1, 7, 8, 10, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 26, 31, 32, 33, 35, 36, 37, 38, 39, 41, 42, 43, 44, 47, 52, 53, 56, 65, 66, 67, 68, 69, 71, 72, 74, 75, 76, 77, 79, 80, 81, 82, 85, 90, 91, 92, 94, 95, 97, 99, 100, 101, 102, 103], "test_accuraci": [20, 41, 79], "test_average_precis": [20, 41, 79], "test_df": [12, 16, 18, 20, 21, 22, 23, 24, 30, 31, 32, 36, 38, 39, 41, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 66, 67, 68, 69, 71, 75, 76, 77, 79, 80, 81, 82, 83, 89, 90, 91, 92, 93, 98, 100, 101, 102], "test_df_churn": [31, 61, 90], "test_df_nan": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "test_df_sort": [30, 51, 60, 89], "test_df_surv": [31, 61, 90], "test_exampl": [22, 43, 52, 81], "test_f1": [20, 41, 79], "test_format": [15, 35, 74], "test_g50k": [22, 43, 52, 81], "test_idx": 64, "test_imag": [12, 29, 32, 50, 59, 71, 88], "test_l50k": [22, 43, 52, 81], "test_mape_scor": [21, 42, 80], "test_nam": [31, 61, 90], "test_neg_mean_squared_error": [21, 42, 80], "test_neg_root_mean_square_error": [21, 42, 80], "test_point": [15, 35, 74, 94], "test_precis": [20, 41, 79], "test_r2": [21, 42, 80], "test_recal": [20, 41, 79], "test_roc_auc": [20, 41, 79], "test_sampl": 101, "test_scor": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 63, 64, 65, 66, 67, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 89, 90, 93, 97], "test_shap_valu": [23, 44, 53, 82], "test_siz": [12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 32, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 57, 59, 60, 63, 64, 65, 66, 67, 68, 69, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101], "test_sklearn": [21, 42, 80], "test_statist": [31, 61, 90], "test_x": [31, 61, 90], "testabl": 32, "text": [1, 7, 11, 12, 13, 18, 19, 20, 21, 22, 23, 24, 27, 29, 32, 33, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 50, 52, 53, 54, 57, 59, 66, 67, 68, 71, 72, 77, 78, 79, 80, 81, 82, 83, 86, 88, 91, 92, 95, 99], "text_feat": [19, 40, 78, 99], "text_featur": 93, "text_pip": 65, "text_pp": [28, 49, 58, 87], "text_transform": 65, "textbook": [3, 9, 91], "textrm": [14, 34, 73], "textual": 11, "textur": [24, 45, 54, 83], "tf": [17, 37, 76], "tfidfvector": [18, 39, 66, 67, 77], "th": [12, 18, 27, 32, 39, 48, 57, 77, 86], "thai": 65, "than": [6, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 61, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 94, 96, 97, 100, 101, 103], "thank": [12, 28, 32, 49, 58, 67, 71, 87, 97], "thankfulli": [30, 89, 102], "theater": 67, "thei": [1, 7, 8, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 67, 68, 69, 72, 73, 74, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 96, 97, 99, 100, 101, 102, 103], "theirs": [28, 49, 58, 87], "them": [1, 2, 4, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 64, 67, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 95, 96, 97, 99, 100, 101, 103], "theme": [28, 49, 58, 87], "themselv": [25, 26, 28, 46, 47, 49, 55, 56, 58, 67, 84, 85, 87], "theoret": [16, 20, 22, 36, 41, 43, 52, 75, 79, 81, 95], "theori": [23, 44, 53, 82], "thepopbreak": 93, "therefor": [32, 67, 97], "thermostat": [13, 33, 72], "thi": [0, 1, 2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 64, 66, 67, 69, 70, 72, 73, 74, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "thick": [25, 46, 55, 65, 67, 84], "thicker": 67, "thin": 67, "thinc": 93, "thing": [1, 5, 7, 8, 12, 13, 14, 15, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59, 60, 61, 66, 67, 68, 69, 72, 73, 74, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 97, 101, 102], "think": [4, 12, 13, 14, 15, 17, 18, 20, 21, 23, 24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 37, 39, 41, 42, 44, 45, 46, 48, 50, 53, 54, 55, 57, 59, 61, 65, 67, 69, 71, 72, 73, 74, 76, 77, 79, 80, 82, 83, 84, 86, 88, 89, 90, 91, 92, 95, 96, 97, 99, 100, 102], "third": [26, 47, 56, 85], "thk": [12, 32, 71], "thorough": [10, 101], "thoroughli": 95, "those": [5, 8, 10, 11, 12, 16, 21, 22, 23, 27, 28, 31, 32, 36, 42, 43, 44, 48, 49, 52, 53, 57, 58, 61, 69, 75, 80, 81, 82, 86, 87, 90, 91, 92, 103], "though": [14, 17, 18, 25, 26, 27, 33, 34, 37, 39, 46, 47, 48, 52, 55, 56, 57, 65, 67, 73, 76, 77, 84, 85, 86, 92, 93], "thought": [4, 15, 31, 35, 61, 67, 74, 82, 90, 95], "thousand": [18, 26, 27, 39, 47, 48, 56, 57, 77, 85, 86], "thrasher": [28, 49, 87], "thread": [29, 50], "threahold": [24, 45, 83], "threaten": 93, "three": [8, 13, 16, 18, 20, 22, 23, 24, 25, 26, 28, 29, 30, 36, 39, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 64, 68, 72, 75, 77, 79, 81, 82, 83, 84, 85, 87, 88, 89, 94, 95, 100, 103], "thresh": 8, "threshold": [13, 18, 22, 24, 26, 28, 31, 33, 39, 43, 45, 47, 49, 52, 54, 58, 61, 72, 77, 81, 83, 85, 87, 90], "thresholds_lr": [20, 41, 68, 79], "thresholds_svc": [20, 41, 68, 79], "through": [1, 7, 10, 12, 13, 20, 21, 24, 26, 27, 28, 29, 32, 33, 41, 42, 45, 47, 48, 49, 50, 54, 56, 57, 58, 59, 67, 68, 69, 70, 72, 79, 80, 83, 85, 86, 87, 88, 91, 103], "throughout": [14, 34, 67, 73, 91], "throught": [32, 103], "throw": [17, 29, 31, 37, 50, 59, 61, 76, 88, 90, 91, 95], "thu": [1, 6, 12, 19, 30, 31, 40, 51, 60, 61, 78, 89, 90, 103], "thumb": [13, 33, 72, 93], "thursdai": [12, 103], "ti": [17, 37, 76], "tianyu": [1, 103], "tick": [30, 51, 89], "tick_label": [53, 82], "tick_param": [25, 46, 55, 84], "tickangl": 58, "tiffin": [28, 49, 87], "tiger": [12, 29, 32, 50, 59, 71, 88], "tight": [15, 26, 35, 47, 56, 64, 74, 85, 97], "tight_layout": [29, 50, 59, 88, 91], "tightrop": [15, 35, 64, 74, 97], "tile": [23, 53, 82], "till": [15, 28, 31, 35, 49, 58, 61, 74, 87, 90], "timber": [28, 49, 58, 87], "time": [1, 2, 4, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 96, 97, 99, 100, 101, 103], "time_diff": [30, 89, 102], "time_signatur": [15, 16, 19, 36, 40, 74, 75, 78, 99], "timedelta": [30, 89, 102], "timeit": [8, 94], "timelin": [61, 91], "timeseri": [29, 30, 50, 59, 88, 89], "timeseriessplit": [30, 31, 51, 60, 61, 89, 90, 95, 102], "timestamp": [30, 51, 60, 89, 102], "timezon": [1, 61, 90], "tinder": [27, 48, 57, 86], "tini": [7, 14, 20, 26, 34, 41, 47, 56, 68, 70, 73, 79, 85], "tip": [28, 49, 58, 61, 87], "tire": 93, "titan": [27, 48, 57, 86], "titi": [12, 32, 71], "titl": [7, 14, 15, 18, 21, 24, 26, 29, 30, 31, 34, 35, 39, 42, 45, 47, 48, 50, 51, 54, 56, 59, 60, 61, 63, 64, 67, 70, 73, 74, 77, 80, 83, 85, 88, 89, 90, 91, 97, 102], "tldr": [12, 32], "tmp": [53, 61, 65], "tn": [20, 41, 68, 79], "to_datetim": [30, 63, 89, 102], "to_html": [12, 13, 14, 32, 34, 71, 72, 73], "to_list": 68, "to_notebook_ifram": [21, 42, 80], "to_numpi": [15, 23, 27, 30, 35, 48, 51, 57, 60, 74, 86, 89], "to_str": [12, 29, 32, 50, 59, 71, 88], "toarrai": [17, 23, 30, 37, 38, 44, 51, 53, 60, 66, 67, 76, 82, 89], "tobago": [22, 23, 43, 44, 52, 53, 81, 82], "todai": [13, 27, 29, 30, 31, 33, 48, 50, 54, 57, 59, 61, 72, 86, 88, 89, 90, 92, 95, 101, 102], "todens": [23, 24, 44, 45, 53, 54, 82, 83], "togeth": [5, 8, 12, 13, 15, 16, 17, 25, 28, 32, 33, 35, 36, 37, 46, 49, 55, 58, 65, 72, 74, 75, 76, 84, 87, 97], "toi": [8, 14, 15, 24, 25, 26, 27, 30, 34, 35, 45, 46, 47, 48, 51, 54, 55, 56, 60, 73, 74, 83, 84, 85, 86, 89, 95], "toilet": [29, 50, 59, 88, 93], "token": [7, 32, 93, 103], "token_pattern": [17, 37, 76], "tol": [20, 24, 41, 45, 54, 79, 83, 91], "told": [5, 103], "tolist": [12, 13, 14, 17, 18, 20, 21, 22, 23, 24, 25, 27, 30, 31, 32, 33, 34, 37, 39, 41, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54, 55, 57, 60, 61, 63, 64, 65, 66, 67, 69, 71, 72, 73, 76, 77, 79, 80, 81, 82, 83, 84, 86, 89, 90, 93, 102], "tom": 67, "tomasbeuzen": 8, "tomorrow": [13, 16, 17, 30, 31, 33, 61, 72, 89, 90, 95, 102], "ton": [19, 40, 67, 78], "tone": 93, "too": [6, 7, 14, 15, 17, 19, 21, 22, 23, 28, 30, 31, 34, 35, 36, 37, 40, 42, 43, 44, 49, 51, 52, 53, 58, 59, 60, 61, 64, 67, 69, 73, 74, 76, 78, 80, 81, 82, 87, 89, 90, 91, 92, 97, 99, 102, 103], "took": [30, 51, 60, 67, 89], "tool": [1, 7, 8, 10, 11, 17, 18, 20, 21, 23, 26, 27, 29, 30, 31, 37, 38, 39, 41, 42, 44, 47, 48, 50, 51, 53, 56, 57, 59, 60, 61, 66, 67, 68, 69, 76, 77, 79, 80, 82, 85, 86, 88, 89, 90, 92, 95, 103], "toolbox": [15, 22, 28, 35, 43, 52, 74, 81, 87], "toolkit": [28, 49, 58, 87], "top": [13, 17, 19, 20, 26, 30, 33, 37, 38, 40, 41, 47, 56, 58, 66, 67, 68, 72, 76, 78, 79, 85, 89, 91, 92, 102], "topi": [28, 49, 58, 87], "topic": [1, 2, 8, 11, 13, 20, 21, 25, 27, 29, 33, 42, 46, 48, 50, 55, 57, 59, 69, 72, 79, 80, 84, 86, 88, 92, 95, 103], "topic2vec": [28, 49, 58, 87], "topic_": 58, "topics_per_chunk": [28, 49, 58, 87], "topn": [12, 29, 32, 50, 59, 71, 88], "torch": [29, 50, 59, 64, 70, 88, 93], "torch_util": [29, 50], "torchvis": [12, 29, 32, 50, 59, 64, 70, 71, 88], "tornado": 93, "toronto": [28, 49, 87, 91, 93], "tort": 0, "total": [1, 8, 13, 16, 17, 19, 20, 21, 22, 23, 24, 28, 30, 31, 33, 36, 37, 41, 42, 43, 44, 45, 49, 51, 52, 53, 54, 58, 60, 61, 68, 69, 72, 75, 76, 79, 80, 81, 82, 83, 87, 89, 90, 91, 102], "total_bedroom": [16, 24, 36, 45, 54, 75, 76, 83, 98], "total_bilirubin": [12, 32, 71], "total_protien": [12, 32, 71], "total_room": [16, 24, 36, 45, 54, 75, 76, 83, 98], "total_second": [30, 89, 102], "totalbsmtsf": [21, 23, 42, 44, 53, 69, 80, 82, 91], "totalcharg": [31, 61, 90], "totem": [29, 50, 59, 88], "totensor": [29, 50, 59, 64, 70, 88], "toti": [0, 1, 28, 49, 58, 87, 103], "totrmsabvgrd": [21, 23, 42, 44, 53, 69, 80, 82, 91], "touch": 92, "toward": [18, 23, 28, 38, 39, 44, 49, 53, 58, 66, 67, 77, 82, 87, 100, 103], "towardsdatasci": [29, 31, 50, 59, 61, 88, 90], "town": 93, "townsvil": [30, 89], "toy_clust": [28, 49, 58, 87], "toy_clust_df": [25, 46, 84], "toy_df": [17, 28, 37, 49, 58, 76, 87], "toy_lda_data": [28, 49, 58, 87], "toy_movie_feat": [27, 48, 57, 86], "toy_rat": [27, 48, 57, 86], "toy_spam": [17, 37, 76], "toy_x": [28, 49, 58, 87], "tp": [20, 41, 68, 79], "tpot": [19, 40, 78], "tpr": [20, 41, 68, 79], "tpr_lr": [20, 41, 68, 79], "tpr_svc": [20, 41, 68, 79], "tr_score": [63, 97], "traceback": [4, 8, 17, 31, 37, 61, 65, 76, 90, 93], "track": [1, 17, 37, 76, 92, 103], "trade": [11, 18, 20, 24, 25, 39, 41, 45, 46, 54, 55, 68, 77, 79, 83, 84, 95], "tradeoff": [15, 16, 18, 21, 24, 25, 29, 35, 36, 39, 42, 45, 46, 50, 54, 55, 59, 63, 69, 74, 75, 77, 80, 83, 84, 88], "tradit": [12, 27, 29, 31, 32, 48, 50, 57, 59, 61, 71, 86, 88, 90, 103], "tradition": 103, "trail": 8, "train": [7, 15, 16, 19, 21, 22, 23, 24, 25, 27, 28, 31, 35, 36, 38, 40, 42, 43, 44, 45, 46, 48, 49, 52, 53, 54, 55, 57, 61, 63, 64, 65, 66, 67, 68, 69, 70, 74, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90, 93, 94, 95, 96, 97, 98, 99, 101, 102], "train_accuraci": [20, 41, 79], "train_dataload": [29, 50, 59, 88], "train_df": [12, 16, 18, 20, 21, 22, 23, 24, 30, 31, 32, 36, 38, 39, 41, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 66, 67, 68, 69, 71, 75, 76, 77, 79, 80, 81, 82, 83, 89, 90, 91, 92, 93, 98, 100, 101, 102], "train_df_churn": [31, 61, 90], "train_df_nan": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "train_df_ord": [30, 89, 102], "train_df_sort": [30, 51, 60, 89], "train_df_surv": [31, 61, 90], "train_df_surv_not_churn": [31, 61, 90], "train_dir": 64, "train_f1": [20, 41, 79], "train_flatten": [29, 50, 59, 88], "train_for_usr": [27, 48, 57, 86], "train_load": [29, 50, 59, 88], "train_mape_scor": [21, 42, 80], "train_mat": [27, 48, 57, 86], "train_mat_imp": [27, 48, 57, 86], "train_neg_mean_squared_error": [21, 42, 80], "train_neg_root_mean_square_error": [21, 42, 80], "train_precis": [20, 41, 79], "train_r2": [21, 42, 80], "train_recal": [20, 41, 79], "train_scor": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 51, 52, 53, 54, 60, 61, 63, 64, 65, 66, 67, 69, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 89, 90, 93, 97], "train_shap_valu": [23, 44, 53, 82], "train_sklearn": [21, 42, 80], "train_test_split": [12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 97, 98, 99, 100, 101, 102], "train_x": [27, 48, 57, 86], "traitlet": 93, "transact": [13, 20, 30, 33, 41, 51, 60, 68, 72, 79, 89, 91, 100], "transfer": [31, 61, 70, 90, 92], "transfer_learning_tutori": [29, 50, 59, 88], "transform": [0, 15, 19, 20, 22, 23, 26, 28, 29, 30, 31, 35, 38, 40, 41, 43, 44, 47, 49, 50, 51, 52, 53, 56, 58, 59, 60, 61, 64, 65, 66, 67, 68, 70, 74, 78, 79, 81, 82, 85, 87, 88, 89, 90, 92, 93, 95, 97, 98, 102], "transformed_exampl": [22, 43, 52, 81], "transformed_oh": [16, 36, 75], "transformedtargetregressor": [21, 24, 42, 45, 54, 69, 80, 83, 91, 93, 95], "transformedtargetregressortransformedtargetregressor": [21, 42, 80], "transformerdecod": 93, "transformerencod": 93, "translat": [1, 9, 12, 32, 71], "transpar": [20, 41, 68, 79, 95], "transpos": [24, 29, 45, 50, 54, 59, 61, 64, 70, 83, 88], "transpose_ax": 70, "trasform": [16, 36, 75], "trash": 96, "traumat": 103, "treat": [8, 16, 17, 20, 21, 27, 30, 31, 36, 37, 41, 42, 48, 57, 61, 69, 73, 75, 76, 79, 80, 86, 89, 90, 91, 95, 100, 102], "treati": 103, "treatment": [17, 37, 76], "tree": [1, 2, 14, 15, 16, 17, 18, 19, 21, 24, 26, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 42, 47, 50, 51, 54, 56, 59, 60, 61, 64, 66, 67, 69, 73, 74, 75, 76, 77, 78, 80, 83, 85, 88, 89, 90, 92, 94, 95, 96, 98, 99, 101], "tree1": [22, 43, 81], "tree2": [22, 43, 81], "tree3": [22, 43, 81], "tree_numeric_transform": [23, 44, 53, 82], "treecolumntransform": [22, 43, 52], "treeexplain": [23, 44, 53, 82], "trend": [11, 31, 61, 90, 95], "tri": [22, 23, 33, 43, 44, 52, 53, 54, 67, 81, 82, 91, 94, 99, 100, 101], "trial": [19, 31, 40, 61, 78, 90], "triangl": [15, 25, 35, 46, 74, 84], "trick": [5, 21, 42, 69, 80], "tricki": [17, 19, 23, 27, 37, 40, 44, 48, 53, 57, 76, 78, 82, 86], "trigger": [15, 29, 35, 50, 74, 93], "trigram": [28, 49, 87], "trivial": [26, 47, 56, 85], "troubl": [10, 67], "true": [8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 53, 54, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 91, 92, 93, 94, 97, 99, 100, 101, 102], "truli": [21, 28, 42, 49, 58, 80, 87], "truncat": [26, 47, 85], "truncate_mod": [26, 47, 56, 85], "truncation_mod": [26, 47, 85], "trust": [12, 16, 17, 19, 20, 21, 22, 23, 24, 27, 29, 32, 36, 37, 40, 41, 42, 43, 44, 45, 48, 50, 52, 53, 55, 59, 63, 64, 65, 67, 71, 75, 76, 78, 79, 80, 81, 82, 83, 86, 88, 91, 93], "trustworthi": [26, 47, 56, 85, 101], "truth": [22, 24, 25, 26, 27, 30, 39, 43, 45, 46, 47, 48, 51, 52, 54, 55, 56, 57, 60, 81, 83, 84, 85, 86, 89], "try": [1, 4, 5, 8, 10, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 95, 96, 97, 99, 100, 101, 102, 103], "tsa": [30, 51, 60, 89], "tscv": [30, 51, 60, 89], "tslearn": [30, 51, 60, 89], "tsunami": [12, 71], "ttr": [21, 42, 69, 80], "ttr_pipe": [21, 42, 69, 80], "tue": [1, 12, 13, 30, 51, 60, 89, 103], "tuesdai": [1, 12, 24, 30, 32, 45, 54, 83, 89, 102, 103], "tuggeranong": [30, 89], "tumor": 95, "tune": [14, 19, 22, 26, 27, 29, 34, 40, 43, 47, 48, 50, 52, 54, 56, 59, 63, 73, 78, 81, 85, 86, 88, 91, 92, 99, 101], "tupl": 61, "turn": [4, 14, 28, 29, 31, 34, 49, 50, 58, 59, 61, 64, 67, 70, 73, 87, 88, 90, 98, 99, 103], "tusker": [29, 50, 59, 88], "tutori": [1, 4, 5, 9, 10, 12, 27, 29, 32, 48, 50, 57, 59, 86, 88, 92, 95, 103], "tweak": [15, 35, 64, 74, 97], "tweet": [28, 49, 58, 87, 93], "tweetat": 93, "twice": [8, 14, 17, 18, 37, 39, 73, 76, 77], "twinx": 91, "twist": [28, 49, 58, 67, 87], "twitter": [28, 49, 87], "twitter_allowed_char": 93, "two": [4, 6, 7, 8, 9, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 65, 68, 70, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 98, 100, 103], "two_citi": [15, 35, 74], "two_song": [16, 36, 75], "two_songs_subset": [16, 36, 75], "tx": [18, 39, 77, 93], "tx_i": 91, "txt": [12, 29, 32, 50, 59, 71, 88, 92], "typ": [21, 23, 42, 44, 53, 69, 80, 82, 91], "type": [4, 8, 10, 11, 13, 15, 16, 17, 19, 22, 24, 26, 27, 28, 29, 33, 36, 37, 38, 40, 43, 45, 47, 48, 49, 50, 52, 54, 57, 59, 65, 70, 72, 74, 75, 76, 78, 81, 83, 85, 86, 87, 88, 92, 93, 95, 97, 98, 99, 102], "typeerror": [31, 61, 90], "typic": [2, 7, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 25, 27, 30, 32, 33, 35, 36, 39, 40, 41, 42, 43, 44, 46, 48, 51, 52, 53, 55, 57, 68, 69, 71, 72, 74, 75, 77, 78, 79, 80, 81, 82, 84, 86, 89, 91, 92, 99], "u": [4, 10, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 96, 97, 98, 99, 101, 102], "u6": [13, 33, 72], "u_1": [15, 35, 74], "u_2": [15, 35, 74], "u_i": [15, 35, 74], "u_n": [15, 35, 74], "ubc": [0, 4, 5, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 100, 101, 102, 103], "ubc_img": [29, 50, 59, 88], "ubc_okanagan": [28, 49, 58, 87], "ubco": [28, 49, 58, 87], "ubyssei": [28, 49, 87], "ucsb": 9, "ud036": 9, "udac": 9, "ufunc": [21, 42, 80], "ufv": [28, 49, 58, 87], "uint8": 64, "ultim": [4, 14, 34, 73, 91], "ultralyt": [29, 50, 59, 88], "uluru": [30, 89, 102], "umbrella": [27, 48, 57, 86], "un": [21, 31, 42, 61, 69, 80, 90], "unabl": [12, 16, 17, 19, 20, 21, 22, 23, 24, 26, 29, 31, 32, 36, 37, 40, 41, 42, 43, 44, 45, 47, 50, 52, 53, 55, 56, 59, 61, 63, 64, 65, 67, 71, 75, 76, 78, 79, 80, 81, 82, 83, 85, 88, 90, 91, 93, 103], "unambigu": [28, 49, 58, 87], "unassign": [25, 26, 46, 47, 55, 56, 84, 85], "unassum": 67, "unbalanc": 100, "unbias": [20, 41, 79, 100], "unced": 103, "uncertain": [18, 39, 77, 101], "uncertain_indic": 101, "uncertainti": [18, 20, 39, 41, 68, 77, 79, 91, 92], "unchang": [23, 44, 53, 82], "uncia": [12, 29, 32, 50, 59, 71, 88], "uncomfort": [27, 48, 57, 86], "uncorrel": [23, 44, 53, 82], "undead": 67, "under": [0, 1, 7, 13, 14, 21, 28, 29, 31, 34, 42, 49, 50, 58, 59, 61, 65, 67, 69, 72, 73, 80, 87, 88, 90, 92], "under_sampl": [20, 79], "underestim": [31, 61, 90], "underfit": [15, 18, 19, 29, 35, 39, 40, 50, 59, 63, 64, 74, 77, 78, 88, 97, 99], "underli": [2, 23, 24, 25, 44, 45, 46, 53, 54, 55, 82, 83, 84], "underneath": 7, "underpredict": [21, 42, 80], "underr": 67, "undersampl": 41, "undersample_pip": [20, 79], "understand": [0, 1, 4, 7, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 67, 68, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 96, 100, 103], "understood": [20, 79], "unemploi": [31, 61, 90], "unexpect": [17, 18, 19, 28, 37, 39, 40, 49, 58, 76, 77, 78, 87], "unexplain": [21, 42, 69, 80], "unf": [21, 23, 42, 44, 53, 69, 80, 82, 91], "unfinish": [21, 42, 69, 80], "unflatten_input": 70, "unfortun": [6, 19, 23, 25, 26, 40, 46, 47, 53, 55, 56, 78, 82, 84, 85, 99], "unfunni": 67, "uniform": [19, 20, 26, 40, 41, 47, 56, 78, 79, 85, 99], "unimport": [19, 23, 40, 44, 53, 78, 82], "uninstal": 10, "unintent": 67, "uninterpret": [23, 44, 53, 82], "unintuit": 8, "union": 8, "uniqu": [16, 17, 20, 21, 22, 23, 27, 28, 30, 31, 36, 37, 41, 42, 43, 44, 48, 49, 52, 53, 55, 57, 58, 61, 68, 69, 75, 76, 79, 80, 81, 82, 86, 87, 89, 90, 100, 102], "unit": [18, 20, 21, 22, 23, 28, 29, 31, 39, 41, 42, 43, 44, 49, 50, 52, 53, 58, 61, 65, 67, 69, 77, 79, 80, 81, 82, 87, 88, 90, 93], "unitless": [21, 42, 69, 80], "univers": [1, 9, 28, 49, 58, 87], "university_year": [17, 37, 76, 95], "unix": [5, 30, 51, 60, 89], "unknown": [6, 28, 49, 87, 95], "unlabel": [12, 14, 26, 32, 34, 47, 56, 71, 73, 85], "unless": [7, 32, 103], "unlik": [8, 12, 14, 15, 17, 21, 23, 25, 26, 32, 34, 35, 37, 42, 44, 46, 47, 53, 55, 56, 69, 73, 74, 76, 80, 82, 84, 85], "unlimit": [30, 51, 60, 89], "unlucki": [14, 34, 73], "unmarri": [22, 23, 43, 44, 52, 53, 81, 82], "unnam": [12, 32, 38, 71], "uno": 65, "unoffici": 103, "unpredict": 67, "unqualifi": [20, 41, 79, 100], "unreason": [6, 21, 32, 42, 69, 80], "unrecogniz": [12, 32], "unreli": [14, 34, 73], "unrespond": [12, 32], "unscal": [16, 36, 75], "unseen": [13, 24, 25, 29, 45, 46, 50, 54, 59, 72, 83, 84, 88, 92, 97], "unsqueez": [29, 50, 59, 88], "unstructur": [28, 49, 58, 87], "unsupervis": [12, 27, 28, 29, 32, 48, 49, 50, 54, 57, 59, 61, 71, 86, 87, 88, 92, 103], "unsur": [7, 91], "until": [4, 13, 14, 19, 24, 25, 26, 28, 31, 33, 34, 40, 45, 46, 47, 49, 54, 55, 56, 58, 61, 72, 73, 78, 83, 84, 85, 87, 90, 91, 92], "unus": 97, "unusu": 65, "unwieldi": [13, 16, 33, 36, 72, 75], "unzip": [23, 44, 82], "uoft": [28, 49, 87], "up": [7, 8, 13, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 71, 72, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 95, 96, 99, 103], "uparrow": [26, 47, 56, 61, 85], "upcom": 84, "updat": [10, 15, 16, 17, 22, 25, 29, 35, 36, 37, 43, 46, 52, 64, 74, 75, 76, 81, 84, 97], "update_cent": [25, 46, 55, 84], "update_layout": 58, "update_plot": [15, 35, 64, 74, 97], "update_z": [25, 46, 55, 84], "upei": [28, 49, 58, 87], "upgrad": [28, 49, 87, 93], "upload": 7, "upon": [0, 13, 14, 17, 20, 22, 23, 24, 25, 26, 28, 33, 34, 37, 41, 43, 44, 45, 46, 47, 49, 52, 53, 54, 55, 56, 58, 72, 73, 76, 79, 81, 82, 83, 84, 85, 87], "upper": [20, 31, 41, 61, 68, 79, 90], "upperbound_pric": 65, "uppercas": 93, "upto": [30, 51, 60, 89], "ur": [12, 32, 71], "urgent": [17, 37, 49, 58, 76, 87], "url": [4, 14, 20, 31, 34, 41, 61, 68, 73, 79, 90, 92, 100], "us": [0, 1, 2, 4, 5, 10, 11, 18, 19, 23, 26, 27, 30, 31, 38, 39, 40, 41, 44, 45, 47, 48, 51, 53, 56, 57, 60, 61, 63, 65, 66, 67, 68, 70, 77, 78, 82, 85, 86, 89, 90, 92, 93, 95, 97, 98, 99, 100, 101, 102], "usa": [8, 14, 15, 18, 28, 34, 35, 39, 49, 58, 73, 74, 77, 87], "usabl": 92, "usag": [16, 17, 20, 21, 24, 28, 30, 31, 36, 37, 41, 42, 45, 49, 54, 58, 61, 75, 76, 79, 80, 83, 87, 89, 90, 102], "usec_": [31, 61, 90], "useless": [19, 23, 24, 40, 44, 45, 53, 54, 78, 82, 83], "user": [10, 12, 16, 17, 19, 22, 23, 25, 26, 28, 29, 31, 32, 33, 36, 37, 40, 43, 44, 46, 47, 49, 50, 52, 53, 55, 56, 61, 64, 71, 72, 73, 75, 76, 78, 81, 82, 84, 85, 87, 88, 90, 91, 92, 93, 94, 95, 99], "user_global_n": 93, "user_id": [27, 48, 57, 86], "user_inverse_mapp": [27, 48, 57, 86], "user_kei": [27, 48, 57, 86], "user_mapp": [27, 48, 57, 86], "user_n": 93, "user_nam": [27, 48, 57, 86], "usernam": 93, "userwarn": [17, 19, 22, 29, 33, 37, 43, 50, 52, 61, 64, 72, 73, 76, 81, 82, 93], "usf": [17, 37, 76], "using_copy_on_writ": [31, 61, 65, 90], "using_cow": [31, 61, 90], "usual": [1, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 65, 67, 68, 69, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 102, 103], "usvi": 53, "utc": [30, 51, 61, 89, 90], "utcnow": [61, 90], "util": [5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 50, 52, 53, 59, 61, 63, 64, 65, 66, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 88, 90, 91, 93, 95, 96, 97, 98, 99, 101], "utilities_allpub": [21, 42, 80], "utilities_nosewa": [21, 42, 80], "utility_mat": [27, 48, 57, 86], "uvic": [28, 49, 58, 87], "v": [1, 3, 7, 17, 18, 26, 28, 30, 31, 37, 47, 49, 51, 58, 60, 61, 63, 64, 76, 77, 85, 87, 89, 90, 91, 95], "v0": 29, "v1": [12, 20, 32, 41, 71, 79], "v10": [20, 41, 79], "v11": [20, 41, 79], "v12": [20, 41, 79], "v13": [20, 41, 79], "v14": [20, 41, 79], "v15": [20, 41, 79], "v16": [20, 41, 79], "v17": [20, 41, 79], "v18": [20, 41, 79], "v19": [20, 41, 79], "v2": [12, 20, 32, 41, 71, 79], "v20": [20, 41, 79], "v21": [20, 41, 79], "v22": [20, 41, 79], "v23": [20, 41, 79], "v24": [20, 41, 79], "v25": [20, 41, 79], "v26": [20, 41, 79], "v27": [20, 41, 79], "v28": [20, 41, 79], "v3": [20, 41, 79], "v4": [20, 41, 79], "v5": [20, 41, 79], "v6": [20, 41, 79], "v7": [20, 41, 79], "v8": [20, 29, 41, 79], "v9": [20, 41, 79], "v_1": [15, 35, 74], "v_2": [15, 35, 74], "v_i": [15, 35, 74], "v_n": [15, 35, 74], "vacat": [18, 39, 77], "vaccin": [91, 93], "vada_pav": [28, 49, 87], "vader": 93, "vader_lexicon": 93, "vader_senti": 93, "vain": [40, 78], "val": [27, 31, 48, 57, 61, 86, 90], "valenc": [15, 16, 19, 36, 40, 74, 75, 78, 93, 99], "valid": [1, 15, 17, 21, 22, 23, 24, 25, 27, 29, 31, 33, 35, 37, 38, 42, 43, 44, 45, 46, 48, 50, 52, 53, 54, 55, 57, 59, 61, 64, 65, 66, 67, 69, 72, 74, 76, 80, 81, 82, 83, 84, 86, 88, 90, 91, 92, 93, 95, 98, 99, 100, 101, 102], "valid_dataload": [29, 50, 59, 88], "valid_dir": 64, "valid_flatten": [29, 50, 59, 88], "valid_load": [29, 50, 59, 88], "valid_mat": [27, 48, 57, 86], "valid_sample_df": [22, 43, 52, 81], "valid_sample_i": [22, 43, 52, 81], "valid_sample_x": [22, 43, 52, 81], "valid_scor": [63, 97], "valid_x": [27, 48, 57, 86], "validate_data": [61, 65], "validate_separ": [61, 65], "valu": [7, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 102], "valuabl": [11, 24, 26, 45, 47, 54, 56, 83, 85, 103], "value_count": [13, 17, 20, 22, 23, 30, 31, 33, 37, 41, 43, 44, 52, 53, 61, 63, 65, 67, 68, 69, 72, 76, 79, 81, 82, 89, 90, 92, 93, 100, 101, 102], "value_throttl": [15, 35, 64, 74, 97], "valueerror": [8, 16, 17, 31, 36, 37, 61, 65, 75, 76, 90], "values_format": [20, 41, 68, 79, 100], "vampir": 67, "vancouv": [28, 49, 58, 87, 91], "vancouver_canuck": [28, 49, 87], "vanilla": [18, 39, 77], "var": [36, 73, 75, 82, 93, 99], "var_": [23, 44, 53, 82], "varada": [0, 1, 33], "vari": [11, 13, 19, 26, 31, 33, 40, 43, 47, 52, 54, 56, 61, 72, 78, 81, 85, 90, 97], "variabl": [7, 8, 13, 16, 17, 18, 19, 21, 23, 24, 30, 31, 33, 36, 37, 39, 40, 42, 44, 51, 53, 54, 60, 61, 63, 69, 72, 75, 76, 77, 78, 80, 82, 83, 89, 90, 91, 97, 102], "varianc": [21, 23, 26, 30, 42, 44, 47, 51, 53, 56, 60, 69, 80, 82, 85, 89, 97], "variance_matrix_": 61, "variant": [23, 26, 44, 47, 53, 56, 82, 85], "variat": [14, 18, 20, 21, 24, 34, 39, 41, 42, 45, 54, 73, 77, 79, 80, 83], "varieti": [12, 22, 28, 32, 43, 49, 52, 58, 71, 81, 87], "variou": [11, 12, 15, 21, 23, 29, 30, 31, 32, 35, 42, 44, 50, 51, 53, 59, 60, 61, 64, 71, 74, 80, 82, 88, 89, 90, 91, 92, 95, 97, 99], "vault": [14, 34, 73], "ve": [7, 8, 12, 14, 15, 20, 21, 23, 27, 28, 29, 30, 32, 34, 35, 41, 42, 44, 48, 49, 50, 53, 57, 58, 59, 63, 64, 68, 71, 73, 74, 79, 80, 82, 86, 87, 88, 89, 91, 92, 94, 102], "vec": [17, 28, 29, 37, 38, 49, 50, 58, 59, 66, 67, 76, 87, 88], "vec1": [28, 49, 58, 87], "vec1_i": [28, 49, 58, 87], "vec2": [28, 49, 58, 87], "vec2_i": [28, 49, 58, 87], "vec8": [17, 37, 76], "vec8_binari": [17, 37, 76], "vec_binari": [17, 37, 76], "vecom": [19, 40, 78], "vector": [13, 18, 20, 27, 29, 33, 36, 39, 48, 50, 57, 59, 64, 70, 72, 77, 79, 86, 88, 91, 97, 101], "verb": [28, 49, 58, 87, 93], "verbos": [12, 20, 22, 23, 32, 41, 43, 44, 52, 53, 71, 79, 81, 82, 91], "veri": [2, 4, 5, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 97, 102, 103], "verifi": 100, "versa": [21, 42, 69, 80, 97, 100], "version": [1, 4, 5, 7, 8, 10, 12, 18, 21, 23, 26, 28, 30, 33, 36, 39, 40, 42, 44, 47, 49, 51, 53, 56, 57, 58, 60, 61, 65, 67, 69, 73, 75, 77, 78, 80, 82, 85, 87, 89, 90, 93, 94, 100, 102], "versu": 9, "vert": [23, 44, 53, 82], "vertic": [13, 20, 30, 33, 51, 60, 72, 79, 89], "vgg": [29, 50, 59, 88], "vgg16": [29, 50, 59, 64, 70, 88], "vgg16_weight": [29, 50, 59, 88], "via": [4, 7, 10, 12, 20, 24, 32, 45, 54, 79, 83, 103], "vibe": 65, "vice": [21, 42, 69, 80, 97, 100], "victim": 67, "video": [1, 7, 8, 9, 10, 27, 29, 31, 48, 50, 57, 59, 61, 63, 86, 88, 90, 91, 92, 97, 100, 103], "vietnames": [16, 36, 75], "view": [6, 7, 10, 12, 13, 23, 26, 29, 30, 31, 32, 44, 47, 50, 51, 53, 54, 56, 59, 60, 61, 63, 71, 72, 82, 85, 88, 89, 90, 91], "viewpoint": [27, 48, 57, 86], "vif": [23, 44, 53, 82], "vikski": [28, 49, 58, 87], "violat": [16, 17, 31, 36, 37, 61, 75, 76, 90, 92, 103], "virginia": [29, 50, 59, 88], "viridi": [19, 40, 58, 78, 99], "visibl": 99, "vision": [1, 70, 92, 94], "visit": [8, 103], "visual": [1, 11, 13, 14, 15, 17, 18, 20, 21, 22, 23, 25, 26, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 46, 47, 50, 51, 52, 55, 59, 61, 63, 66, 67, 68, 69, 72, 73, 74, 76, 77, 79, 80, 81, 82, 84, 85, 88, 89, 90, 93, 95, 98, 99], "visualize_coeffici": [38, 66, 67], "viu": [28, 49, 58, 87], "vivid": 67, "viz": 91, "voc": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "vocab": [28, 38, 49, 58, 66, 67, 87], "vocabulari": [17, 18, 28, 37, 39, 49, 58, 76, 77, 87], "vocabulary_": [17, 37, 76], "voic": [12, 32, 71], "volcano": [12, 71], "volum": 92, "vote": [15, 16, 22, 35, 36, 43, 52, 74, 75, 81, 94, 101], "voting_ndt": [22, 43, 52, 81], "votingclassifi": [22, 43, 52, 81, 101], "votingclassifierinot": [22, 43, 52, 81], "votingregressor": [22, 43, 52, 81], "vulner": 67, "vyfj": [71, 72, 76, 77, 80, 81], "w": [10, 17, 18, 21, 25, 28, 30, 37, 39, 42, 46, 49, 55, 58, 61, 69, 76, 77, 80, 84, 87, 89, 91, 92, 102], "w_0": [18, 39, 77], "w_1": [18, 39, 77], "w_1x_1": [18, 39, 77], "w_2x_2": [18, 39, 77], "w_3x_3": [18, 39, 77], "w_4x_4": [18, 39, 77], "w_d": [18, 39, 77], "w_dx_d": [18, 39, 77], "w_j": [18, 38, 39, 54, 66, 67, 77], "wa": [4, 5, 10, 14, 16, 17, 18, 20, 22, 23, 27, 28, 29, 31, 32, 33, 34, 36, 38, 39, 41, 43, 44, 48, 49, 50, 52, 53, 57, 58, 59, 61, 64, 65, 66, 67, 72, 73, 75, 77, 79, 81, 82, 86, 87, 88, 90, 91, 93, 94, 96, 97, 99, 102, 103], "wa_fn": [31, 61, 90], "wai": [0, 2, 6, 8, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 92, 94, 95, 97, 99, 100, 102, 103], "wait": [4, 12, 15, 17, 31, 32, 33, 35, 37, 61, 71, 72, 74, 76, 90, 92, 103], "waitlist": [13, 103], "walk": [15, 20, 35, 64, 74, 79, 92, 97], "walker": [12, 29, 32, 50, 59, 71, 88], "wallabi": [29, 50, 59, 88], "wang": [1, 103], "want": [4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 95, 98, 99, 100, 102, 103], "war": [27, 48, 57, 86], "ward": [26, 47, 85], "warm": [16, 36, 75], "warm_start": [20, 41, 79, 91], "warn": [6, 12, 15, 17, 19, 21, 22, 23, 32, 34, 35, 37, 42, 43, 44, 46, 47, 52, 53, 59, 61, 64, 68, 69, 73, 74, 76, 80, 81, 82, 90, 94, 101], "warranti": 0, "washington": 93, "washroom": 103, "wasn": [28, 49, 58, 65, 67, 87], "wast": [4, 17, 37, 67, 76, 91], "watch": [1, 10, 12, 15, 18, 27, 28, 32, 39, 48, 49, 57, 58, 67, 74, 77, 86, 87, 95], "watchfil": 64, "water": 91, "waterfal": [23, 44, 82], "waterfront": [12, 13, 32, 63, 71, 72], "wavelet": [24, 45, 54, 83], "waxwork": 67, "wb": 92, "wd": [21, 23, 42, 44, 53, 80, 82, 91], "we": [1, 4, 5, 6, 7, 10, 12, 13, 15, 26, 28, 29, 30, 32, 33, 35, 38, 47, 49, 50, 51, 56, 59, 60, 64, 65, 66, 67, 68, 70, 71, 72, 74, 85, 87, 88, 89, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "weak": [67, 95], "weather": [13, 30, 33, 51, 60, 72, 89, 92], "weatherau": [30, 89, 102], "web": [5, 12, 28, 32, 49, 58, 87, 95], "web_api": 92, "web_appl": 92, "weblog": [28, 49, 58, 87], "websit": [4, 10], "wed": [30, 51, 60, 89], "wednesdai": [30, 51, 89, 103], "week": [1, 6, 14, 15, 16, 17, 20, 21, 22, 23, 28, 32, 35, 36, 37, 41, 42, 43, 44, 49, 51, 52, 53, 58, 60, 73, 74, 75, 76, 79, 80, 81, 82, 86, 87, 89, 91, 100, 103], "weekdai": [30, 51, 89], "weekend": [8, 30, 51, 67, 89, 91], "weekli": [12, 93], "weight": [15, 22, 24, 27, 28, 29, 32, 35, 43, 48, 49, 50, 52, 54, 57, 58, 59, 61, 64, 70, 74, 81, 83, 86, 87, 88, 100, 103], "weighted_averag": [20, 79], "weights_col": 61, "weinberg": [23, 44, 53, 82], "weird": [21, 42, 69, 80], "welcom": [96, 103], "well": [4, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 67, 68, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 87, 88, 89, 90, 91, 92, 95, 99, 102, 103], "wellyanto": [1, 103], "welsh": [12, 29, 32, 50, 59, 71, 88], "went": [21, 42, 80, 93, 99, 101], "were": [0, 6, 12, 18, 20, 21, 28, 29, 30, 31, 32, 39, 41, 42, 49, 50, 51, 58, 59, 60, 61, 65, 68, 69, 76, 77, 79, 80, 87, 88, 89, 90, 91, 99, 101, 103], "weren": [28, 49, 58, 87], "what": [7, 8, 9, 13, 15, 19, 26, 29, 30, 33, 35, 38, 40, 47, 50, 51, 56, 59, 60, 63, 64, 65, 66, 67, 72, 74, 78, 85, 88, 89, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "whatev": [24, 45, 54, 83], "whatsoev": 67, "when": [4, 6, 7, 10, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 94, 95, 96, 98, 100, 101, 102, 103], "wher": 93, "where": [0, 1, 7, 10, 13, 14, 15, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 64, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 86, 87, 88, 89, 91, 92, 95, 97, 100, 102], "wherea": [2, 13, 18, 19, 21, 23, 26, 33, 39, 40, 42, 44, 47, 53, 56, 65, 72, 77, 78, 80, 82, 85, 91], "whether": [0, 4, 7, 8, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 26, 28, 30, 31, 33, 34, 36, 37, 39, 41, 42, 43, 44, 45, 47, 49, 51, 52, 53, 54, 56, 58, 60, 61, 65, 69, 72, 73, 75, 76, 77, 79, 80, 81, 82, 83, 85, 87, 89, 90, 92, 93, 96, 101, 102, 103], "which": [4, 6, 8, 10, 14, 15, 16, 17, 18, 19, 21, 23, 24, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 49, 50, 51, 53, 54, 58, 59, 60, 61, 63, 64, 65, 66, 67, 69, 73, 74, 75, 76, 77, 78, 80, 82, 83, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103], "whichev": [22, 43, 52, 81], "while": [14, 18, 19, 20, 22, 23, 25, 27, 28, 31, 33, 34, 36, 39, 40, 41, 43, 44, 46, 48, 49, 52, 53, 55, 57, 58, 61, 67, 68, 72, 73, 77, 78, 79, 81, 82, 84, 86, 87, 90, 93, 99], "white": [20, 22, 23, 26, 28, 41, 43, 44, 47, 49, 52, 53, 58, 67, 79, 81, 82, 85, 87], "whitespac": [28, 31, 49, 58, 87, 90], "who": [4, 5, 6, 12, 20, 23, 25, 26, 28, 30, 31, 32, 44, 46, 47, 49, 51, 53, 58, 60, 61, 67, 71, 79, 82, 84, 85, 87, 89, 90, 91, 92, 93, 95, 103], "whole": [14, 19, 21, 23, 27, 34, 40, 42, 44, 48, 53, 57, 67, 69, 73, 78, 80, 82, 86, 92, 99], "whom": [0, 28, 49, 58, 87, 93], "whose": 4, "why": [8, 14, 15, 20, 21, 22, 25, 26, 28, 30, 31, 33, 35, 41, 42, 43, 46, 47, 49, 51, 52, 55, 56, 60, 61, 63, 65, 67, 73, 74, 79, 80, 81, 84, 85, 87, 89, 90, 95, 96, 97, 98, 99], "wid": [20, 79, 92], "wide": [10, 18, 19, 22, 24, 27, 29, 39, 40, 43, 45, 48, 50, 52, 54, 57, 59, 77, 78, 81, 83, 86, 88, 91], "wider": [15, 35, 64, 74, 97], "widespread": [28, 49, 58, 87], "widget": [15, 20, 25, 26, 35, 41, 46, 47, 56, 64, 68, 74, 79, 84, 85, 97], "width": [13, 14, 15, 20, 28, 33, 34, 35, 41, 49, 58, 64, 72, 73, 74, 79, 87, 96, 97], "wife": [12, 20, 22, 23, 41, 43, 44, 52, 53, 67, 71, 79, 81, 82], "wiki": [28, 49, 58, 87, 91], "wiki_df": [28, 49, 58, 87], "wiki_dict": [28, 49, 58, 87], "wikipedia": [28, 29, 49, 50, 58, 59, 87, 88, 91], "wikipedia2vec": [28, 49, 58, 87], "wild": [12, 14, 29, 32, 34, 50, 59, 64, 71, 73, 88], "willing": [20, 41, 68, 79], "win": [15, 17, 22, 23, 24, 27, 35, 37, 38, 43, 44, 45, 48, 53, 54, 57, 66, 67, 74, 76, 81, 82, 83, 86, 94], "wind": [13, 33, 72], "winddir3pm": [30, 89, 102], "winddir3pm_miss": [30, 89, 102], "winddir3pm_ss": [30, 89, 102], "winddir3pm_ssw": [30, 89, 102], "winddir3pm_sw": [30, 89, 102], "winddir3pm_w": [30, 89, 102], "winddir3pm_wnw": [30, 89, 102], "winddir3pm_wsw": [30, 89, 102], "winddir9am": [30, 89, 102], "windgustdir": [30, 89, 102], "windgustspe": [30, 89, 102], "window": [31, 61, 90], "windsor": 93, "windspeed3pm": [30, 89, 102], "windspeed9am": [30, 89, 102], "wine_1": 8, "winter": [30, 89], "winter_month": [30, 89], "wire": [27, 48, 57, 86], "wisdom": [22, 43, 52, 81], "wish": [12, 13, 25, 32, 33, 46, 55, 67, 71, 72, 84, 91, 103], "within": [13, 16, 18, 22, 24, 25, 26, 31, 33, 36, 39, 45, 46, 47, 52, 54, 55, 56, 61, 64, 67, 72, 75, 77, 81, 83, 84, 85, 90, 92, 95, 99], "without": [0, 7, 12, 13, 20, 22, 23, 24, 27, 29, 30, 31, 32, 33, 41, 43, 44, 45, 48, 50, 51, 52, 53, 54, 57, 59, 60, 61, 68, 71, 72, 79, 81, 82, 83, 86, 88, 89, 90, 91, 92, 99, 103], "wnw": [30, 89, 102], "wolf": 67, "wolv": [26, 47, 85], "woman": [28, 49, 58, 67, 87], "wombat": [29, 50, 59, 88], "won": [5, 10, 12, 13, 14, 15, 17, 18, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 45, 48, 49, 50, 51, 54, 57, 58, 59, 60, 61, 72, 73, 74, 76, 77, 83, 86, 87, 88, 89, 90, 92, 93], "wonder": [12, 14, 32, 67, 71, 73], "wooddecksf": [21, 23, 42, 44, 53, 69, 80, 82, 91], "word": [11, 12, 18, 19, 20, 24, 25, 26, 27, 29, 30, 31, 32, 38, 39, 40, 41, 45, 46, 47, 48, 50, 51, 54, 55, 56, 57, 59, 60, 61, 63, 65, 66, 67, 68, 71, 77, 78, 79, 83, 84, 85, 86, 88, 89, 90, 91, 95, 99, 103], "word1": [28, 49, 58, 87], "word2": [28, 49, 58, 87], "word2vec": [11, 28, 29, 49, 50, 59, 87, 88], "word3": [28, 49, 58, 87], "word_coeff_df": [38, 66, 67], "word_pair": [28, 49, 58, 87], "word_token": [28, 49, 58, 87, 93], "wordnet": [28, 49, 58, 87], "wordnetlemmat": [28, 49, 58, 87], "words_in_ex": [38, 66, 67], "work": [0, 4, 5, 7, 8, 10, 12, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 32, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60, 61, 65, 67, 68, 69, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 86, 87, 88, 89, 90, 92, 93, 95, 99, 101, 102, 103], "work_of_art": 93, "workclass": [20, 22, 23, 41, 43, 44, 52, 53, 79, 81, 82, 100], "workclass_feder": [22, 23, 43, 44, 53, 81, 82], "workclass_loc": [22, 23, 43, 44, 53, 81, 82], "workclass_miss": [23, 44, 53, 82], "workclass_nev": [22, 23, 43, 44, 53, 81, 82], "workclass_priv": [22, 23, 43, 44, 53, 81, 82], "workclass_self": [23, 44, 53, 82], "workclass_st": [23, 44, 53, 82], "workclass_without": [23, 44, 53, 82], "workflow": [13, 33, 72, 92, 103], "worksheet": 92, "world": [15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 34, 35, 36, 37, 39, 40, 41, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 67, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 95], "worm": [29, 50, 59, 88], "worri": [12, 26, 27, 32, 47, 48, 56, 57, 71, 84, 85, 86, 101], "wors": [13, 19, 21, 22, 31, 33, 40, 42, 43, 52, 61, 69, 72, 78, 80, 81, 90, 96, 99, 100], "worst": [20, 24, 25, 41, 45, 46, 54, 55, 67, 68, 79, 83, 84], "worth": [13, 15, 20, 21, 33, 35, 41, 42, 69, 72, 74, 79, 80, 100], "worthi": [18, 39, 77], "would": [4, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 69, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 97, 98, 99, 100, 101, 102, 103], "wouldn": [17, 19, 28, 31, 37, 40, 49, 58, 61, 76, 78, 87, 90], "wound": 67, "wow": [23, 44, 53, 82], "wrangl": 65, "wrap": [17, 37, 61, 76], "wrapper": [24, 45, 54, 65, 83], "write": [4, 7, 11, 12, 19, 25, 28, 32, 40, 43, 46, 49, 53, 55, 58, 71, 78, 82, 83, 84, 87, 91, 92, 93, 97, 101, 103], "writer": 67, "written": [7, 17, 23, 30, 37, 44, 53, 67, 76, 82, 89, 91, 102], "wrong": [10, 14, 18, 21, 24, 25, 31, 34, 39, 42, 45, 46, 54, 55, 61, 65, 67, 69, 73, 77, 80, 83, 84, 90, 91, 99], "wrote": [28, 30, 49, 58, 87, 89, 102], "wsw": [30, 89, 102], "wtf": 92, "www": [9, 18, 39, 77], "x": [4, 8, 10, 14, 15, 16, 17, 18, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 39, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 68, 73, 74, 75, 76, 77, 79, 81, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100], "x0": [24, 45, 54, 83], "x0_male": [20, 41, 79], "x1": [24, 27, 45, 48, 54, 57, 83, 86], "x1_x2": 54, "x1x2": [24, 45, 54, 83], "x2": [24, 26, 27, 45, 47, 48, 54, 56, 57, 83, 85, 86], "x27": [16, 17, 19, 20, 21, 22, 24, 29, 36, 37, 40, 41, 42, 43, 45, 50, 52, 59, 65, 67, 75, 76, 78, 79, 80, 81, 83, 88, 91, 93], "x_": [18, 38, 39, 54, 66, 67, 77], "x_1": [18, 24, 25, 39, 45, 46, 54, 55, 77, 83, 84], "x_1x_2": [24, 45, 83], "x_2": [18, 24, 25, 39, 45, 46, 54, 55, 77, 83, 84], "x_anim_train": 64, "x_anim_valid": 64, "x_binari": [13, 33, 72], "x_bird": 70, "x_citi": [15, 35, 74], "x_count": [17, 37, 76], "x_d": [18, 39, 77], "x_femal": [20, 41, 79, 100], "x_food": 70, "x_hour": [30, 51, 60, 89], "x_hour_week": [30, 51, 60, 89], "x_hour_week_onehot": [30, 51, 60, 89], "x_hour_week_onehot_poli": [30, 51, 60, 89], "x_hour_week_onehot_poly_lag": [30, 51, 60, 89], "x_i": [18, 27, 39, 48, 57, 77, 86], "x_imp_ohe_train": [16, 36, 75], "x_init": [25, 46, 55, 84], "x_int": [17, 37, 76], "x_label": [13, 14, 15, 33, 34, 35, 72, 73, 74, 96], "x_lag_featur": [30, 51, 60, 89], "x_lag_features_imp": [30, 51, 60, 89], "x_male": [20, 41, 79, 100], "x_mask": [17, 37, 76], "x_multi": 94, "x_n": [24, 45, 54, 83], "x_norm": 61, "x_orig": [26, 47, 85], "x_re": [20, 79], "x_small_citi": [15, 35, 74], "x_spotifi": [15, 19, 40, 74, 78, 99], "x_subset": [13, 14, 33, 34, 72, 73], "x_test": [12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 50, 51, 52, 53, 54, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 93, 94, 97, 98, 99, 100, 101], "x_test_big": [19, 40, 78], "x_test_cat": 65, "x_test_cat_oh": 65, "x_test_enc": [23, 30, 31, 44, 53, 61, 82, 89, 90, 91, 102], "x_test_happi": [20, 79, 92], "x_test_imp": [16, 36, 75], "x_test_multi": 94, "x_test_num": 65, "x_test_num_imp": 65, "x_test_num_imp_sc": 65, "x_test_pr": [30, 51, 60, 89], "x_test_predict": [16, 36, 75], "x_test_scal": [16, 36, 75], "x_test_transform": [16, 36, 75], "x_toi": [15, 16, 17, 30, 35, 36, 37, 51, 60, 74, 75, 76, 89], "x_toy_oh": [16, 36, 75], "x_toy_ord": [16, 17, 36, 37, 75, 76], "x_tr": [63, 97], "x_train": [12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 93, 94, 97, 98, 99, 100, 101], "x_train_big": [20, 41, 68, 79, 100], "x_train_cat": 65, "x_train_cat_oh": 65, "x_train_enc": [20, 21, 23, 30, 31, 41, 42, 44, 53, 61, 69, 79, 80, 82, 89, 90, 91, 100, 102], "x_train_happi": [20, 79, 92], "x_train_hous": [24, 45, 54, 83], "x_train_imp": [16, 36, 75], "x_train_imp_sc": [16, 36, 75], "x_train_multi": 94, "x_train_num": 65, "x_train_num_imp": 65, "x_train_num_imp_sc": 65, "x_train_oversampl": [20, 79], "x_train_perm": [23, 44, 53, 82], "x_train_pp": 76, "x_train_predict": [16, 36, 75], "x_train_scal": [16, 24, 36, 45, 54, 75, 83], "x_train_subsampl": [20, 79], "x_train_tini": [19, 40, 78], "x_train_transform": [16, 36, 75], "x_train_usr": [27, 48, 57, 86], "x_transform": [17, 37, 76], "x_valid": [20, 27, 41, 48, 57, 63, 64, 68, 79, 86, 97, 100], "x_vari": [26, 47, 56, 85], "x_xor": [24, 45, 83], "xanni": [19, 40, 78], "xavier": [24, 27, 45, 48, 54, 57, 83, 86], "xaxi": 58, "xaxis_titl": 58, "xcode": 5, "xgbclassifi": [22, 23, 43, 44, 52, 53, 81, 82], "xgbclassifierxgbclassifi": [22, 43, 52, 81], "xgboost": [23, 44, 53, 82], "xgboostcolumntransform": [22, 43, 52], "xgbregressor": [12, 22, 32, 43, 52, 71, 81], "xlabel": [8, 13, 14, 15, 18, 19, 20, 21, 23, 26, 29, 30, 31, 33, 34, 35, 39, 40, 41, 42, 44, 47, 50, 51, 53, 54, 59, 60, 61, 64, 68, 69, 72, 73, 74, 77, 78, 79, 80, 82, 85, 88, 89, 90, 91, 94, 96, 99, 102], "xlim": [31, 61, 90], "xor": [18, 24, 39, 45, 54, 77, 83], "xp": [61, 65], "xt": [17, 37, 76], "xtick": [14, 20, 30, 34, 41, 51, 60, 64, 68, 70, 73, 79, 89, 102], "xticklabel": [19, 40, 78, 99], "xticks_rot": [20, 79], "xwm\u0259\u03b8kw\u0259y": 103, "xx": [24, 25, 45, 46, 55, 83, 84], "y": [8, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 34, 35, 36, 37, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 68, 73, 74, 75, 76, 77, 78, 79, 81, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 100, 102], "y_": [27, 48, 57, 86], "y_citi": [15, 35, 74], "y_femal": [20, 41, 79, 100], "y_hat": [18, 22, 39, 52, 77, 81], "y_i": [21, 22, 24, 27, 42, 45, 48, 52, 54, 57, 69, 80, 81, 83, 86], "y_init": [25, 46, 55, 84], "y_label": [13, 14, 15, 33, 34, 35, 72, 73, 74, 96], "y_male": [20, 41, 79, 100], "y_mat": [27, 48, 86], "y_multi": 94, "y_numer": 65, "y_pred": [20, 30, 41, 51, 60, 68, 79, 89], "y_pred_lower_threshold": [20, 41, 79], "y_pred_toi": [20, 79], "y_pred_train": [30, 51, 60, 89], "y_re": [20, 79], "y_small_citi": [15, 35, 74], "y_spotifi": [19, 40, 78, 99], "y_test": [12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 50, 51, 52, 53, 54, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 93, 94, 97, 98, 99, 100, 101, 102], "y_test_big": [19, 40, 78], "y_test_happi": [20, 79, 92], "y_test_multi": 94, "y_test_num": [22, 23, 43, 44, 52, 53, 81, 82], "y_toi": [15, 30, 35, 51, 60, 74, 89], "y_tr": [63, 97], "y_train": [12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 93, 94, 97, 98, 99, 100, 101, 102], "y_train_big": [20, 41, 68, 79, 100], "y_train_happi": [20, 79, 92], "y_train_hous": [24, 45, 54, 83], "y_train_multi": 94, "y_train_num": [22, 23, 43, 44, 52, 53, 81, 82], "y_train_ord": [30, 89, 102], "y_train_oversampl": [20, 79], "y_train_subsampl": [20, 79], "y_train_tini": [19, 40, 78], "y_train_usr": [27, 48, 57, 86], "y_true": 91, "y_true_toi": [20, 79], "y_valid": [20, 27, 29, 41, 48, 50, 57, 59, 63, 64, 68, 79, 86, 88, 97, 100], "y_vari": [26, 47, 56, 85], "y_xor": [24, 45, 83], "yakisoba": 58, "yale": [28, 49, 87], "yan": [1, 103], "yann": [23, 44, 53, 82], "yaxis_titl": 58, "ycxmx": [31, 90], "ye": [4, 12, 13, 16, 17, 23, 25, 26, 27, 29, 30, 32, 33, 36, 37, 44, 46, 47, 48, 50, 51, 53, 55, 56, 57, 59, 65, 71, 72, 75, 76, 82, 84, 85, 86, 88, 89, 91, 92, 93, 95, 102], "year": [12, 13, 27, 28, 29, 30, 31, 32, 33, 48, 49, 50, 57, 58, 59, 61, 72, 86, 87, 88, 89, 90], "yearbuilt": [21, 23, 42, 44, 53, 69, 80, 82, 91], "yearremodadd": [21, 23, 42, 44, 53, 69, 80, 82, 91], "yellow": [19, 40, 78], "yellowbrick": [25, 26, 46, 47, 55, 56, 84, 85], "yesterdai": [30, 89, 102], "yet": [1, 10, 11, 18, 23, 27, 30, 31, 39, 44, 48, 51, 53, 57, 60, 61, 65, 67, 77, 82, 86, 89, 90, 97], "yield": 99, "yifei": [1, 103], "ylabel": [8, 13, 14, 15, 18, 19, 20, 21, 26, 29, 30, 31, 33, 34, 35, 39, 40, 41, 42, 47, 50, 51, 54, 59, 60, 61, 63, 64, 68, 69, 72, 73, 74, 77, 78, 79, 80, 85, 88, 89, 90, 91, 94, 96, 97, 99, 102], "ylim": [31, 61, 90, 91], "yml": 10, "yolo": [29, 50, 59, 88], "yolo8": [29, 50, 59, 88], "yolo_input": [29, 50, 59, 88], "yolo_result": [29, 50, 59, 88], "yolo_test": [29, 50, 59, 88], "yolov8n": [29, 50, 59, 88], "york": [30, 51, 60, 89, 93], "you": [0, 1, 4, 5, 6, 7, 8, 10, 23, 28, 44, 49, 53, 55, 59, 63, 64, 68, 69, 70, 82, 87, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "young": 67, "your": [0, 1, 2, 4, 6, 7, 8, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 65, 68, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "your_miniconda_path": 93, "your_nam": 10, "yourself": [4, 11, 17, 20, 27, 28, 37, 41, 48, 49, 57, 58, 76, 79, 86, 87, 91, 103], "yourselv": [28, 49, 58, 87], "youtub": [1, 12, 27, 28, 32, 48, 49, 57, 58, 86, 87, 91, 103], "yr_built": [12, 13, 32, 63, 71, 72], "yr_renov": [12, 13, 32, 63, 71, 72], "yrpxn": [31, 61, 90], "yrsold": [21, 23, 42, 44, 53, 69, 80, 82, 91], "ytick": [14, 20, 34, 41, 64, 68, 70, 73, 79], "yticklabel": [19, 40, 78, 99], "yy": [24, 30, 45, 83, 89, 102], "yyyi": [30, 89, 102], "z": [8, 18, 24, 25, 26, 27, 29, 31, 39, 45, 46, 47, 48, 50, 54, 55, 56, 57, 59, 61, 64, 70, 77, 83, 84, 85, 86, 88, 90], "z_bird": 70, "z_food": 70, "z_i": [29, 50, 59, 88], "z_j": [29, 50, 59, 88], "z_km": [25, 46, 84], "z_train": [29, 50, 59, 64, 70, 88], "z_valid": [29, 50, 59, 64, 88], "zachari": [31, 61, 90], "zarei": [1, 103], "zefeng": [1, 103], "zeng": [1, 103], "zero": [8, 14, 17, 19, 27, 28, 34, 37, 40, 48, 49, 53, 54, 57, 58, 73, 76, 78, 86, 87, 91], "zero_divis": [20, 41, 68, 79], "zhiyanov": [1, 103], "zip": [15, 18, 27, 35, 39, 48, 57, 64, 74, 77, 86, 97], "zipcod": [12, 13, 32, 63, 71, 72, 97], "zmqshell": 93, "zombi": 67, "zone": [30, 67, 89, 102], "zoo": 67, "zoom": [7, 99], "zorro": 67, "zu": 67, "zucco": 67, "\u0259m": 103, "\u03bc": 94}, "titles": ["LICENSE", "UBC CPSC 330: Applied Machine Learning (2024W2)", "CPSC 330 vs. CPSC 340", "CPSC 330 Documents", "How to ask for help", "What are git and GitHub?", "CPSC 330 grading policies", "Homework info &amp; submission guidelines", "CPSC 330 Python notes", "Reference material", "Setting up coding environment", "Course Learning Objectives", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 12: Ensembles", "Lecture 13: Feature importances and model transparency", "Lecture 14: Feature engineering and feature selection", "Lecture 15: K-Means Clustering", "Lecture 16: More Clustering", "Lecture 17: Recommender Systems", "Lecture 18: Introduction to natural language processing", "Lecture 19: Multi-class classification and introduction to computer vision", "Lecture 20: Time series", "Lecture 21: Survival analysis", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Class demo", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 12: Ensembles", "Lecture 13: Feature importances and model transparency", "Lecture 14: Feature engineering and feature selection", "Lecture 15: K-Means Clustering", "Lecture 16: More Clustering", "Lecture 17: Recommender Systems", "Lecture 18: Introduction to natural language processing", "Lecture 19: Multi-class classification and introduction to computer vision", "Lecture 20: Time series", "Lecture 12: Ensembles", "Lecture 13: Feature importances and model transparency", "Lecture 14: Feature engineering and feature selection", "Lecture 15: K-Means Clustering", "Lecture 16: More Clustering", "Lecture 17: Recommender Systems", "Lecture 18: Introduction to natural language processing", "Lecture 19: Multi-class classification and introduction to computer vision", "Lecture 20: Time series", "Lecture 21: Survival analysis", "&lt;no title&gt;", "Lecture 3: ML Fundamentals Class Demo", "Lecture 4: Class demo", "Lecture 5 and 6: Class demo", "Lectures 7: Class demo", "Lectures 7: Class demo", "Lecture 9: Class demo", "Lecture 10: Regression metrics", "Lecture 15: Class demo", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 12: Ensembles", "Lecture 13: Feature importances and model transparency", "Lecture 14: Feature engineering and feature selection", "Lecture 15: K-Means Clustering", "Lecture 16: More Clustering", "Lecture 17: Recommender Systems", "Lecture 18: Introduction to natural language processing", "Lecture 19: Multi-class classification and introduction to computer vision", "Lecture 20: Time series", "Lecture 21: Survival analysis", "Lecture 22: Communication", "Lecture 24: Deployment and conclusion", "Appendix A: Demo of feature engineering for text data", "Appendix B: Multi-class, meta-strategies", "Final exam preparation: guiding questions", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Tutorial 4", "Tutorial 5", "Tutorial 6", "Tutorial 7", "Syllabus"], "titleterms": {"": [12, 14, 15, 16, 17, 20, 21, 23, 30, 32, 35, 36, 37, 41, 42, 44, 53, 57, 58, 65, 68, 70, 71, 73, 74, 75, 76, 79, 80, 82, 89, 91], "0": [43, 52, 81], "1": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 59, 61, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 90, 91, 95, 96, 97, 98, 99, 100, 101, 102], "10": [21, 42, 69, 80, 101], "12": [22, 43, 52, 81], "13": [23, 44, 53, 82], "14": [24, 45, 54, 83], "15": [25, 46, 55, 70, 84, 91, 92], "16": [26, 47, 56, 85], "17": [27, 48, 57, 86], "18": [28, 49, 58, 87], "19": [29, 50, 59, 88], "2": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 46, 47, 48, 53, 54, 55, 56, 57, 61, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 84, 85, 86, 90, 91, 95, 96, 97, 98, 99, 100, 101, 102], "20": [30, 51, 60, 89, 91, 92], "2024w2": 1, "21": [31, 61, 90], "22": 91, "24": 92, "3": [12, 13, 14, 16, 25, 26, 31, 32, 33, 34, 36, 39, 46, 47, 54, 55, 56, 61, 63, 71, 72, 73, 75, 83, 84, 85, 90, 96, 97, 98, 99, 100, 101, 102], "330": [1, 2, 3, 6, 8, 12, 32, 92], "340": [2, 12, 32, 92], "4": [13, 14, 15, 33, 34, 35, 64, 72, 73, 74, 91, 96, 97, 98, 99, 100, 101, 102], "5": [8, 12, 13, 14, 15, 16, 17, 20, 23, 24, 25, 28, 29, 31, 32, 33, 34, 35, 36, 37, 44, 46, 49, 50, 53, 55, 58, 59, 61, 65, 72, 73, 74, 75, 76, 79, 82, 83, 84, 87, 88, 90, 91, 97, 98, 99, 100, 101, 102], "6": [17, 37, 65, 76, 97, 99, 100, 101, 102], "7": [18, 38, 39, 66, 67, 77, 99, 101, 102], "8": [19, 40, 78, 99, 101], "9": [20, 41, 68, 79, 101], "A": [4, 20, 26, 30, 41, 47, 55, 56, 57, 58, 68, 79, 85, 89, 93], "In": 57, "No": 8, "Not": 95, "One": [16, 30, 36, 75, 89, 94], "The": [1, 14, 18, 19, 22, 24, 25, 34, 39, 40, 43, 46, 52, 54, 55, 73, 77, 78, 81, 83, 84, 101], "__": [19, 40, 78], "about": [8, 12, 24, 27, 32, 45, 48, 54, 55, 57, 58, 83, 86, 91], "academ": 103, "access": [7, 18, 39, 77, 103], "accommod": 103, "acknowledg": 103, "activ": [12, 20, 23, 25, 28, 32, 41, 44, 46, 49, 53, 55, 58, 63, 79, 82, 83, 84, 87, 91, 100], "actual": [17, 76], "ad": 8, "addit": [7, 23, 44, 53, 82], "address": [20, 41, 68, 79], "advantag": [19, 40, 57, 78], "advic": [24, 45, 54, 83], "ai": 103, "aka": 91, "algorithm": [13, 15, 24, 25, 33, 35, 45, 46, 54, 55, 56, 72, 74, 83, 84], "all": [12, 13, 16, 18, 20, 25, 26, 27, 32, 39, 41, 46, 47, 48, 55, 56, 57, 68, 71, 72, 75, 77, 79, 84, 85, 86, 91], "alpha": [18, 21, 39, 42, 69, 77, 80], "alreadi": 92, "altern": [13, 16, 33, 36, 65, 72, 75], "ambigu": 58, "an": [22, 43, 52, 81, 91, 93], "analogi": [15, 59, 74], "analysi": [30, 31, 56, 61, 63, 65, 89, 90, 92, 95, 97, 102], "angl": 91, "announc": [12, 13, 14, 15, 16, 17, 18, 20, 22, 35, 37, 39, 43, 52, 53, 54, 72, 74, 76, 77, 81], "answer": [31, 61, 90], "ap": [20, 41, 68, 79], "api": [16, 36, 75, 92], "app": 92, "appendix": [93, 94], "appli": [1, 8, 16, 17, 21, 36, 37, 42, 69, 75, 76, 80, 91], "applic": [25, 46, 55, 58, 84], "applicatiion": 61, "applymap": 8, "approach": [27, 30, 31, 48, 51, 57, 59, 60, 61, 86, 89, 90, 91, 92, 94], "approxim": [14, 34, 73], "ar": [5, 12, 13, 16, 18, 20, 25, 26, 27, 32, 36, 39, 41, 46, 47, 48, 55, 56, 57, 58, 69, 71, 72, 75, 77, 79, 84, 85, 86], "area": [20, 41, 68, 79], "argument": [14, 15, 34, 35, 73, 74], "around": 91, "arrai": 8, "articl": [9, 58], "asap": 91, "ask": 4, "assess": 63, "assign": [7, 103], "associ": [18, 39, 77], "assum": [31, 61, 90], "attent": [13, 15, 33, 35, 72, 74], "attribut": [23, 44, 53, 82, 91], "auc": [20, 41, 68, 79], "autom": [19, 40, 78], "averag": [20, 22, 27, 41, 43, 48, 52, 56, 57, 58, 79, 81, 86, 101], "avoid": [14, 34, 73], "b": [25, 46, 55, 84, 94], "backward": [24, 45, 54, 83], "bad": [19, 40, 55, 78], "bag": [17, 37, 76, 93], "balanc": [20, 41, 79], "bank": 68, "base": [15, 22, 24, 27, 30, 43, 45, 48, 51, 52, 54, 57, 60, 74, 81, 83, 86, 89, 102], "baselin": [13, 16, 20, 22, 23, 27, 33, 36, 41, 43, 44, 48, 52, 53, 57, 59, 63, 68, 69, 72, 75, 79, 81, 82, 86, 97], "basic": [28, 49, 58, 87], "befor": [12, 16, 32, 36, 75], "best": [24, 54, 83], "better": [14, 19, 20, 24, 34, 40, 41, 45, 54, 55, 68, 73, 78, 79, 83, 91], "between": [13, 15, 35, 58, 72, 74, 92, 96], "beyond": [23, 27, 44, 48, 53, 57, 82, 86], "bia": [14, 19, 34, 40, 73, 78], "bias": 58, "big": [13, 14, 16, 33, 34, 36, 72, 73, 75], "binari": [20, 41, 68, 79], "biomark": 61, "book": 1, "boost": [22, 43, 52, 81, 91], "bootstrap": [22, 43, 52, 81], "bottom": 91, "boundari": [13, 15, 18, 33, 35, 39, 64, 72, 74, 77, 96], "bow": [17, 37, 76], "box": [29, 50, 59, 88], "break": [8, 12, 13, 14, 15, 16, 17, 24, 28, 29, 31, 32, 33, 34, 35, 37, 49, 50, 58, 59, 61, 72, 73, 74, 75, 76, 83, 87, 88, 90, 91, 92], "broadcast": 8, "browser": [12, 32], "build": [12, 13, 21, 27, 32, 33, 38, 42, 48, 57, 63, 66, 67, 71, 72, 80, 86, 92], "c": [15, 19, 35, 40, 74, 78], "calcul": [18, 39, 77], "california": [18, 39, 76, 77, 98], "can": [8, 14, 16, 22, 23, 25, 34, 36, 43, 44, 46, 52, 53, 55, 58, 73, 75, 81, 82, 83, 84], "canada": [13, 72, 96], "cancer": [55, 56], "care": [27, 48, 57, 86, 91], "carri": [16, 24, 36, 45, 54, 75, 83], "case": [17, 18, 26, 37, 39, 47, 56, 76, 77, 85], "catboost": [22, 43, 52, 81], "categor": [16, 17, 23, 30, 36, 37, 44, 51, 53, 60, 65, 75, 76, 82, 89], "categori": [17, 37, 76], "caution": 58, "cell": [55, 56], "censor": [31, 61, 90], "center": 55, "centr": 103, "certain": [17, 76], "cfa": 103, "chang": [20, 41, 79], "charact": [12, 32, 71], "characterist": [20, 41, 68, 79], "cheatsheet": 8, "checklist": [12, 32], "choos": [15, 25, 35, 46, 55, 74, 84], "chunk": 91, "churn": [31, 61, 90], "cite": 7, "citi": [18, 39, 77], "claim": 91, "class": [12, 19, 20, 21, 22, 23, 27, 29, 32, 38, 40, 41, 42, 43, 44, 48, 50, 52, 53, 59, 63, 64, 65, 66, 67, 68, 69, 70, 78, 79, 80, 81, 82, 86, 88, 94, 103], "class_attend": [17, 37, 76], "class_weight": [20, 41, 79], "classif": [13, 20, 29, 33, 41, 50, 57, 59, 64, 68, 72, 79, 88, 92, 95], "classifi": [13, 18, 22, 33, 38, 39, 43, 52, 59, 65, 66, 67, 72, 77, 81, 93], "clearli": [24, 45, 54, 83], "closest": 55, "cluster": [25, 26, 46, 47, 55, 56, 70, 84, 85, 95], "co": [1, 103], "code": [10, 103], "coeffici": [18, 23, 38, 39, 44, 53, 66, 67, 77, 82], "color": [96, 97, 98, 99, 100, 101, 102], "column": [8, 16, 17, 30, 36, 37, 51, 60, 75, 76, 89], "columntransform": [17, 37, 76, 98], "com": [15, 24, 25, 26, 27, 29, 31], "combin": [22, 43, 52, 81], "come": [14, 15, 34, 35, 73, 74], "command": 5, "comment": [13, 19, 20, 21, 25, 26, 27, 33, 40, 41, 42, 46, 47, 48, 55, 56, 57, 68, 69, 72, 78, 79, 80, 84, 85, 86], "common": [16, 25, 36, 46, 55, 75, 84], "commonli": [28, 49, 58, 87], "commun": [12, 32, 91, 95], "compact": [16, 36, 75], "companion": 9, "complet": [27, 48, 56, 57, 86], "complex": [14, 34, 73], "complic": [30, 89, 102], "compon": [18, 39, 77], "comprehens": 98, "comput": [12, 29, 32, 50, 59, 88, 95], "con": [15, 26, 35, 47, 56, 74, 85, 95], "concept": [63, 91], "concern": 6, "concess": 103, "conclus": 92, "conda": 10, "conduct": 103, "confid": [18, 39, 77, 91], "confus": [20, 41, 68, 79, 91], "consid": [31, 61, 90], "construct": [22, 43, 52, 81], "content": [27, 48, 57, 86], "context": [28, 49, 58, 87], "continu": [13, 33, 72], "conveni": [17, 37, 76], "cool": 59, "corpu": [58, 92], "correct": [25, 46, 55, 84], "correl": [23, 44, 53, 82], "cosin": 58, "countri": [13, 72, 96], "countvector": [17, 37, 76], "cours": [1, 9, 11, 12, 32, 71, 92, 103], "cover": [27, 31, 48, 57, 61, 86, 90, 92], "cox": [31, 61, 90], "cpsc": [1, 2, 3, 6, 8, 12, 32], "creat": [7, 13, 14, 17, 27, 33, 34, 37, 48, 56, 57, 72, 73, 76, 86, 92], "credit": 10, "critic": 68, "cross": [14, 16, 20, 24, 30, 34, 36, 41, 45, 51, 54, 60, 63, 68, 73, 75, 79, 83, 89, 97], "cross_val_scor": [14, 34, 73], "cross_valid": [14, 21, 34, 42, 69, 73, 80], "csv": 8, "curs": [15, 35, 74], "curv": [20, 31, 41, 61, 68, 79, 90], "custom": [25, 31, 46, 55, 61, 84, 90], "cv": [19, 40, 78], "dai": [30, 51, 60, 89], "data": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 46, 48, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 63, 65, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 88, 89, 91, 92, 93, 97, 102], "datafram": [8, 17, 37, 76], "dataset": [7, 13, 16, 18, 19, 20, 21, 29, 30, 33, 36, 38, 39, 40, 41, 42, 50, 51, 59, 60, 66, 67, 68, 69, 72, 75, 76, 77, 78, 79, 80, 88, 89, 91, 98, 101, 102], "date": [1, 30, 51, 60, 89], "datetim": [30, 89, 102], "dbscan": [26, 47, 56, 85], "deal": [17, 20, 37, 41, 76, 79], "debug": 10, "decis": [13, 15, 18, 23, 33, 35, 39, 44, 53, 63, 64, 72, 74, 77, 82, 91, 97], "decisiontreeclassifi": [13, 22, 33, 43, 52, 72, 81], "decreas": [20, 41, 68, 79], "deep": [29, 30, 50, 51, 59, 60, 88, 89], "deeper": 59, "defin": [24, 45, 54, 56, 83], "definit": [12, 32, 71], "deliver": [1, 12, 32], "demo": [24, 38, 45, 54, 63, 64, 65, 66, 67, 68, 70, 83, 89, 92, 93], "demonstr": [20, 41, 68, 79], "dendrogram": [26, 47, 56, 85], "depend": [24, 53, 54, 58, 83], "deploi": 92, "deploy": [14, 34, 73, 92, 95], "descript": 103, "desktop": 5, "detail": [20, 21, 26, 34, 42, 47, 56, 68, 69, 79, 80, 85], "detect": [29, 50, 59, 88], "df": 8, "did": [14, 16, 17, 20, 21, 27, 31, 34, 36, 37, 41, 42, 48, 57, 61, 69, 73, 75, 76, 79, 80, 86, 90, 91, 92], "differ": [16, 19, 20, 21, 23, 36, 40, 41, 42, 44, 53, 68, 69, 75, 78, 79, 80, 82, 92, 95], "dimens": [15, 35, 74], "dimension": [15, 35, 74], "directli": 59, "directori": 92, "disadvantag": 57, "discuss": [19, 20, 27, 28, 40, 41, 48, 49, 58, 63, 65, 78, 79, 86, 87, 91, 92, 100], "diseas": [12, 32, 71], "distanc": [15, 25, 35, 46, 55, 56, 58, 74, 84], "distribut": [19, 40, 78], "divers": 57, "do": [16, 17, 19, 20, 22, 23, 24, 36, 40, 41, 43, 44, 45, 52, 53, 54, 55, 57, 58, 65, 68, 75, 76, 78, 79, 81, 82, 83, 91, 92], "document": [3, 8, 25, 46, 55, 58, 84], "doe": [13, 18, 26, 33, 34, 39, 47, 56, 72, 77, 85, 91], "domain": [24, 45, 54, 83], "dot": 58, "downsid": 59, "drop": 8, "due": 1, "dummi": [64, 65, 93], "dummyclassifi": [13, 22, 30, 31, 33, 43, 52, 61, 72, 81, 89, 90], "dummyregressor": [13, 16, 21, 33, 36, 42, 72, 75, 80], "eda": [16, 20, 21, 36, 41, 42, 60, 68, 69, 75, 79, 80, 92, 97], "effect": [22, 43, 52, 56, 81, 91], "elbow": [25, 46, 55, 84], "element": 8, "elimin": [24, 45, 54, 83], "embed": [28, 49, 58, 87], "encod": [16, 17, 24, 30, 36, 37, 45, 51, 54, 60, 75, 76, 83, 89], "engin": [24, 30, 45, 51, 54, 59, 60, 83, 89, 93, 95], "ensembl": [22, 43, 52, 81, 95], "enter": 65, "entiti": 58, "environ": [10, 92], "ep": 56, "equal": 91, "error": [14, 19, 20, 21, 27, 34, 40, 41, 42, 48, 57, 68, 69, 73, 78, 79, 80, 86], "estim": [16, 22, 36, 43, 52, 75, 81], "ethic": 95, "euclidean": [15, 35, 58, 74], "eva": [12, 14, 32, 57, 71, 73], "evalu": [20, 26, 27, 31, 41, 47, 48, 56, 57, 61, 68, 79, 85, 86, 90, 95, 100], "evalut": [20, 41, 68, 79], "event": [31, 61, 90], "everydai": 58, "everyon": [31, 61, 90], "exactli": [18, 39, 77], "exam": [95, 103], "examin": [17, 21, 37, 38, 42, 57, 66, 67, 69, 76, 80, 91, 95], "exampl": [12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 28, 31, 32, 33, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 49, 52, 53, 54, 55, 57, 58, 61, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 87, 90, 91, 93], "exercis": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 27, 29, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 48, 50, 52, 54, 57, 58, 59, 61, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 86, 88, 90, 96], "exhaust": [19, 40, 78], "experi": 91, "explain": [23, 44, 53, 82, 91], "explan": [23, 44, 53, 82, 91], "explor": [15, 25, 35, 46, 55, 56, 69, 74, 84], "exploratori": [30, 63, 65, 89, 97, 102], "extract": [17, 30, 37, 51, 58, 59, 60, 76, 89], "extractor": [29, 50, 59, 88], "f1": [20, 41, 68, 79], "failur": [26, 47, 56, 85], "fair": [20, 41, 79, 100], "fancier": [19, 40, 78], "farewel": 92, "faster": 8, "fastest": 8, "featur": [12, 13, 15, 16, 17, 18, 21, 23, 24, 27, 29, 30, 32, 33, 35, 36, 37, 39, 42, 44, 45, 48, 50, 51, 53, 54, 57, 59, 60, 65, 69, 71, 72, 74, 75, 76, 77, 80, 82, 83, 86, 88, 89, 91, 93, 95, 102], "feature_importances_": [23, 44, 53, 82], "few": [20, 26, 41, 47, 56, 68, 79, 85, 91], "fictiti": [12, 32, 71], "figur": 7, "fill": 57, "filter": [8, 27, 48, 57, 86], "final": [13, 19, 25, 26, 27, 30, 33, 40, 46, 47, 48, 51, 55, 56, 57, 60, 72, 78, 84, 85, 86, 89, 95, 97, 103], "find": [15, 24, 35, 45, 54, 55, 58, 74, 83], "fine": 57, "first": [12, 16, 32, 36, 75], "fit": [13, 16, 22, 33, 36, 52, 72, 75, 81], "flat": 56, "flatten": [29, 50, 59, 88], "follow": [12, 13, 14, 25, 26, 27, 32, 34, 46, 47, 48, 55, 56, 57, 63, 71, 72, 73, 84, 85, 86], "font": [96, 97, 98, 99, 100, 101, 102], "food": 58, "forc": 53, "forecast": [30, 51, 60, 89], "forest": [22, 23, 43, 44, 52, 53, 81, 82, 91], "format": [7, 8, 12, 32], "formul": [27, 48, 57, 86], "forward": [24, 45, 54, 83], "framework": 59, "fresh": 57, "from": [8, 91, 93], "full": 92, "function": [8, 18, 21, 39, 42, 69, 77, 80], "fundament": [14, 15, 22, 34, 35, 43, 52, 63, 73, 74, 81, 95], "further": [30, 51, 60, 89, 93], "futur": [30, 51, 60, 89], "fuyi": [15, 24, 25, 26, 27, 29, 31], "gamma": [15, 35, 74], "garbag": [24, 45, 54, 83], "gb": 91, "gener": [4, 6, 14, 15, 18, 22, 24, 34, 35, 39, 43, 45, 52, 54, 59, 73, 74, 77, 81, 83], "genom": [54, 55], "geometr": [15, 35, 74], "get": [23, 53, 58, 69, 82], "git": [5, 10], "github": 5, "given": [12, 13, 32, 33, 71, 72], "global": [27, 48, 57, 86], "go": 59, "goal": [14, 34, 58, 73], "golden": [14, 16, 17, 34, 36, 37, 73, 75, 76], "good": [20, 41, 79, 91], "grade": [4, 6, 13, 32, 33, 72, 103], "gradescop": 7, "gradient": [22, 43, 52, 81, 91], "grid": [19, 40, 78, 91], "gridsearchcv": [19, 21, 40, 42, 69, 78, 80, 91], "group": [20, 25, 41, 46, 55, 63, 79, 84, 100], "guid": 95, "guidelin": [4, 6, 7], "ha": [12, 32, 71], "halv": [19, 40, 78], "handl": [20, 41, 79], "hard": 58, "have": [22, 23, 43, 44, 52, 53, 81, 82, 91], "hazard": [31, 61, 90], "hdbscan": 56, "headlin": 58, "heatmap": [19, 40, 78], "help": [4, 24, 45, 54, 83], "here": [14, 34, 73], "hidden": 59, "hierarch": [26, 47, 56, 85], "home": [26, 47, 56, 85], "homework": [7, 12, 32], "hot": [16, 24, 30, 36, 45, 54, 75, 83, 89], "hous": [12, 13, 16, 18, 32, 36, 39, 71, 72, 75, 76, 77, 98], "how": [4, 7, 13, 14, 15, 16, 18, 22, 23, 24, 26, 33, 34, 35, 36, 39, 43, 44, 45, 47, 52, 53, 54, 55, 56, 58, 65, 72, 73, 74, 75, 77, 81, 82, 83, 85, 91], "http": [15, 24, 25, 26, 27, 29, 31], "hyper": [19, 40, 78], "hyperparamet": [13, 15, 17, 18, 19, 21, 22, 25, 33, 35, 37, 39, 40, 42, 43, 46, 52, 55, 56, 63, 69, 72, 74, 76, 77, 78, 80, 81, 84, 95, 97], "i": [12, 14, 16, 17, 19, 20, 22, 23, 24, 25, 27, 28, 32, 34, 36, 37, 40, 41, 43, 44, 45, 46, 48, 49, 52, 53, 54, 55, 57, 58, 68, 71, 73, 75, 76, 78, 79, 81, 82, 83, 84, 86, 87, 91, 92, 93], "iclick": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 59, 61, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 90, 103], "idea": [15, 20, 22, 24, 35, 41, 43, 45, 52, 54, 55, 56, 74, 79, 81, 83, 91], "identifi": [17, 23, 37, 44, 76, 82], "illustr": 56, "imag": [12, 29, 32, 50, 59, 64, 70, 71, 88], "imagenet": [29, 59, 88], "imbal": [20, 21, 22, 23, 41, 42, 43, 44, 52, 53, 69, 79, 80, 81, 82], "implicit": 58, "import": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 102], "improv": 93, "imput": [16, 27, 36, 48, 57, 75, 86], "incorpor": [17, 37, 65, 76], "increas": [20, 41, 68, 79], "index": 8, "inertia": [25, 46, 84], "info": 7, "inform": [23, 30, 44, 51, 53, 60, 82, 89], "initi": [25, 46, 55, 84, 92], "inject": [22, 43, 52, 81], "input": [12, 25, 32, 46, 55, 56, 58, 71, 84], "instal": [5, 10], "instruct": [0, 7], "instructor": 1, "int": 57, "interact": [24, 45, 54, 83], "intercept": [18, 39, 77], "interest": 91, "interim": [20, 23, 24, 30, 41, 44, 45, 51, 53, 54, 60, 68, 79, 82, 83, 89], "interpret": [18, 23, 38, 39, 44, 53, 58, 66, 67, 77, 82, 92], "intra": [25, 46, 55, 84], "intro": [27, 48, 58, 86], "introduct": [8, 12, 23, 24, 25, 26, 28, 29, 32, 44, 45, 46, 47, 49, 50, 53, 54, 55, 56, 58, 59, 71, 82, 83, 84, 85, 87, 88, 91, 95], "intuit": [18, 39, 59, 77], "involv": [30, 51, 60, 89, 91], "issu": 91, "iter": 55, "join": [15, 24, 25, 26, 27, 29, 31], "journal": 58, "jupyt": [12, 32], "jupyterlab": 10, "k": [15, 16, 25, 26, 27, 35, 36, 46, 47, 48, 55, 56, 57, 74, 75, 84, 85, 86], "kaplan": [31, 61, 90], "kei": [23, 44, 53, 82, 91, 92], "kernel": [15, 35, 74], "kind": [22, 43, 52, 57, 81], "kneighborsclassifi": [15, 35, 64, 74], "knn": [64, 65], "l1": 54, "l2": 54, "label": [12, 25, 32, 46, 55, 71, 84, 91], "lag": [30, 51, 60, 89, 102], "land": 103, "languag": [28, 49, 58, 59, 87], "larg": [19, 40, 78], "lasso": 54, "late": 7, "latitud": [13, 72, 96], "law": 58, "layer": 59, "lda": [28, 49, 58, 87], "learn": [1, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92], "least": [18, 39, 77], "lectur": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 103], "lemmat": 58, "let": [15, 16, 17, 20, 21, 23, 35, 36, 37, 41, 42, 44, 57, 65, 68, 70, 74, 75, 76, 79, 80, 82, 91], "lexic": 58, "lgbm": 53, "licens": [0, 1], "lightgbm": [22, 43, 52, 81], "limit": [6, 18, 26, 39, 47, 56, 77, 85], "line": 5, "linear": [18, 21, 23, 38, 39, 42, 44, 53, 54, 59, 66, 67, 77, 80, 82], "link": 1, "linkag": 56, "list": 9, "liver": [12, 32, 71], "ll": [14, 34, 73], "lo": [14, 16, 17, 18, 19, 20, 21, 22, 23, 27, 29, 30, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 48, 50, 51, 57, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 86, 88, 89, 92], "load": 92, "local": 92, "localhost": 92, "log": 69, "logisit": 59, "logist": [18, 20, 29, 39, 41, 50, 54, 59, 68, 77, 79, 88], "logisticregress": [20, 30, 31, 41, 61, 79, 89, 90, 91], "longitud": [13, 72, 96], "look": [20, 25, 41, 46, 55, 68, 79, 84], "loop": 8, "loss": 91, "lower": [19, 40, 78], "lymphoma": [56, 61], "mac": 5, "machin": [1, 12, 13, 14, 15, 20, 25, 32, 33, 34, 35, 41, 46, 55, 63, 68, 71, 72, 73, 74, 79, 84, 92], "maco": 10, "macro": [20, 41, 79], "magazin": 58, "magnitud": [18, 39, 77], "mai": [24, 54, 83], "main": [18, 27, 39, 48, 55, 56, 57, 77, 86, 91], "make": [8, 18, 39, 77, 91], "make_column_transform": [17, 37, 76], "make_pipelin": [16, 36, 75], "mani": [17, 19, 40, 58, 76, 78], "manual": [19, 40, 78], "mape": [21, 42, 69, 80], "materi": [0, 1, 9], "matplotlib": 8, "matric": [17, 37, 76], "matrix": [20, 27, 41, 48, 57, 68, 79, 86], "matter": 34, "max_depth": [13, 33, 72], "mean": [21, 25, 26, 28, 42, 46, 47, 49, 55, 56, 58, 69, 80, 84, 85, 87, 91], "measur": 83, "media": [28, 49, 58, 87], "meet": [12, 32, 71, 103], "meier": [31, 61, 90], "messag": [12, 26, 32, 47, 56, 71, 85], "meta": 94, "method": [8, 19, 24, 25, 40, 45, 46, 54, 55, 58, 65, 78, 83, 84], "metric": [20, 21, 41, 42, 68, 69, 79, 80, 95], "midterm": [84, 103], "might": [31, 61, 90], "min": [8, 12, 13, 14, 15, 16, 17, 20, 23, 24, 25, 28, 29, 31, 32, 33, 34, 35, 37, 44, 46, 49, 50, 53, 55, 58, 59, 61, 72, 73, 74, 75, 76, 79, 82, 83, 84, 87, 88, 90, 91, 92], "min_sampl": 56, "minor": [20, 79], "misc": [1, 9], "miscellan": [27, 48, 57, 86], "mislead": 91, "ml": [12, 14, 15, 20, 23, 32, 34, 35, 41, 44, 53, 58, 59, 63, 71, 73, 74, 79, 82, 91, 95, 100], "model": [12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 42, 43, 44, 45, 49, 50, 52, 53, 54, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 80, 81, 82, 83, 87, 88, 90, 92, 93, 95, 97, 100], "model_select": [19, 40, 78], "modellin": 58, "moment": 92, "month": [30, 89], "more": [13, 15, 16, 17, 18, 20, 21, 24, 26, 30, 33, 34, 35, 36, 37, 39, 41, 42, 45, 47, 54, 56, 68, 69, 72, 74, 75, 76, 77, 79, 80, 83, 85, 89, 102], "most": [18, 38, 39, 66, 67, 68, 77], "motiv": [14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 34, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 56, 57, 58, 60, 68, 73, 74, 75, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 89, 91], "movi": [27, 48, 57, 86], "mse": [21, 42, 69, 80], "much": [19, 40, 78], "multi": [20, 29, 50, 59, 79, 88, 94], "multiclass": 95, "multipl": [15, 17, 21, 35, 37, 42, 53, 69, 74, 76, 80], "multipli": 8, "mutat": 55, "n_estim": [22, 43, 52, 81], "n_iter": [19, 40, 78], "n_job": [19, 40, 78], "n_neighbor": [15, 35, 74], "name": [14, 21, 27, 34, 42, 48, 57, 58, 73, 80, 86], "natur": [28, 49, 58, 87], "nearest": [15, 16, 25, 27, 35, 36, 46, 48, 55, 57, 74, 75, 84, 86], "need": [16, 19, 36, 40, 57, 75, 78], "neg": [20, 38, 41, 66, 67, 68, 79], "neighbour": [15, 16, 27, 35, 36, 48, 57, 74, 75, 86], "nest": 8, "netflix": [22, 43, 81], "network": [29, 50, 59, 88], "neural": [29, 50, 59, 88], "new": [58, 91, 92], "next": [12, 32, 92], "nlp": [28, 49, 58, 87, 95], "nn": [15, 35, 74], "non": [15, 17, 23, 35, 37, 53, 59, 74, 76, 82], "notat": 8, "note": [8, 14, 30, 51, 73, 89, 97], "notebook": [12, 32], "now": [31, 61, 90], "number": [22, 25, 30, 43, 46, 52, 55, 81, 84, 89], "numer": [23, 24, 44, 45, 53, 54, 82, 83], "numpi": 8, "object": [11, 13, 22, 28, 29, 30, 31, 33, 43, 49, 50, 51, 52, 58, 59, 60, 61, 72, 81, 87, 88, 89, 90, 91, 92], "observ": [20, 41, 56, 68, 79], "occasion": [16, 36, 75], "off": [14, 15, 22, 34, 35, 43, 52, 73, 74, 81], "often": 58, "oh": [16, 17, 36, 37, 75, 76], "ok": [16, 17, 36, 37, 75, 76], "onc": [20, 41, 68, 79], "one": [17, 24, 37, 45, 54, 76, 83], "onehotencod": [17, 37, 76], "onli": [17, 31, 37, 61, 76, 90], "onlin": [1, 9], "oper": [20, 41, 68, 79], "optim": [19, 40, 63, 78, 95], "option": [10, 15, 16, 19, 20, 22, 24, 31, 35, 36, 40, 41, 45, 52, 54, 61, 68, 74, 75, 78, 79, 81, 83, 90, 92], "ordin": [1, 16, 17, 23, 36, 37, 44, 53, 65, 75, 76, 82, 103], "other": [8, 15, 21, 24, 25, 28, 30, 31, 35, 42, 45, 46, 49, 51, 54, 55, 58, 60, 61, 74, 80, 83, 84, 87, 89, 90, 91], "our": [7, 14, 16, 34, 36, 59, 73, 75, 91, 92, 93], "out": [16, 24, 29, 36, 45, 50, 54, 59, 75, 83, 88, 91, 92], "outcom": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 53, 54, 55, 56, 57, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86], "outlin": [96, 97, 98, 99, 100, 101, 102], "output": [25, 46, 55, 56, 58, 84], "outsid": 58, "over": [8, 15, 18, 20, 35, 39, 74, 77, 79], "overal": 58, "overfit": [14, 19, 34, 40, 73, 78], "oversampl": [20, 79], "overview": [15, 20, 35, 41, 57, 58, 68, 74, 79], "ovo": 94, "ovr": 94, "own": 59, "packag": [10, 30, 51, 60, 89], "panda": 8, "pandas_profil": [21, 42, 80], "paper": [20, 22, 41, 43, 52, 79, 81], "paradigm": [16, 36, 75], "paramet": [13, 18, 19, 20, 33, 39, 40, 41, 72, 77, 78, 79, 95], "parametr": [15, 35, 74], "pars": [30, 58, 89, 102], "part": 95, "pass": [19, 40, 78], "pat": 57, "patient": [12, 32, 71], "penalti": 54, "perfect": [25, 46, 84], "perhap": 91, "permutation_import": [23, 44, 53, 82], "persist": 57, "persona": [12, 32, 71], "piazza": 4, "pick": [14, 19, 34, 40, 73, 78], "pictur": [13, 14, 16, 33, 34, 36, 72, 73, 75], "piec": 91, "pipelin": [16, 28, 36, 49, 58, 59, 65, 75, 87], "plan": [26, 47, 58, 85], "playground": [15, 35, 64, 74, 97], "plot": [8, 23, 25, 31, 44, 46, 53, 55, 61, 82, 84, 90], "point": [15, 20, 23, 25, 30, 35, 41, 44, 46, 51, 53, 55, 60, 68, 74, 79, 82, 84, 89], "polici": 6, "poll": 84, "ponder": [38, 66, 67], "popular": [12, 32, 58, 71], "posit": [20, 38, 41, 66, 67, 68, 79], "posix": [30, 51, 60, 89], "possibl": [17, 21, 25, 37, 42, 46, 55, 58, 76, 80, 84, 93], "post": 9, "pr": [20, 41, 68, 79], "practic": [15, 33, 72, 74], "pre": [29, 50, 58, 59, 88], "precis": [20, 41, 68, 79], "predict": [12, 13, 17, 18, 22, 23, 27, 29, 31, 32, 33, 39, 44, 48, 50, 52, 53, 57, 59, 61, 71, 72, 76, 77, 81, 82, 86, 88, 90, 94, 96], "predict_proba": [18, 39, 77, 91], "predictor": 92, "prefer": 91, "prepar": [7, 95], "preprocess": [16, 17, 21, 28, 30, 36, 37, 42, 49, 58, 69, 75, 76, 80, 87, 89, 91, 92, 95, 100, 102], "prerequisit": [12, 32], "pretrain": [58, 59], "preval": [12, 32, 71], "price": [12, 13, 32, 71, 72], "principl": 91, "prize": [22, 43, 81], "pro": [15, 26, 35, 47, 56, 74, 85, 95], "probabilist": 59, "probabl": [18, 19, 39, 40, 77, 78], "problem": [13, 14, 15, 16, 19, 24, 27, 30, 33, 34, 35, 36, 40, 45, 48, 51, 54, 57, 59, 60, 72, 73, 74, 75, 78, 83, 86, 89, 92, 93], "procedur": [20, 41, 79], "process": [28, 49, 55, 58, 87], "product": [12, 32, 58, 71], "profil": [27, 48, 57, 86], "program": [13, 33, 59, 72], "project": 93, "properli": 65, "proport": [31, 61, 90], "punctuat": 58, "python": [8, 9, 10, 12, 32], "q": 4, "qualiti": 83, "queri": [8, 15, 35, 74], "question": [4, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 56, 57, 58, 60, 61, 63, 65, 66, 67, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99, 100, 101, 102], "quick": [15, 74], "quiz": [13, 33, 72], "quiz2": [13, 33, 72], "quot": [24, 45, 54, 83], "r": [21, 42, 69, 80], "random": [19, 22, 23, 40, 43, 44, 52, 53, 59, 78, 81, 82, 91], "random_st": [14, 34, 73], "randomforestclassifi": [22, 31, 43, 52, 61, 81, 90], "randomizedsearchcv": [19, 21, 40, 42, 69, 78, 80], "rang": [19, 40, 78], "rate": [27, 48, 57, 86], "raw": [18, 39, 77], "rbf": [15, 35, 64, 74], "re": 91, "read": [8, 13, 19, 29, 33, 40, 50, 59, 72, 78, 88], "reader": 91, "real": [13, 72, 92, 96], "realist": [17, 37, 76], "reason": 6, "recal": [20, 41, 68, 79], "recap": [13, 15, 26, 31, 33, 47, 54, 56, 57, 61, 72, 74, 85, 90, 91, 96, 98], "receiv": [20, 41, 68, 79], "recip": 92, "recommend": [12, 16, 27, 32, 36, 48, 57, 75, 86, 95], "record": 103, "recurs": [24, 45, 54, 83], "red": [96, 97, 98, 99, 100, 101, 102], "refer": [1, 9, 31, 61, 90], "referenti": 58, "reflect": [13, 14, 25, 26, 33, 34, 46, 47, 55, 56, 72, 73, 84, 85], "registr": [12, 32, 103], "regress": [13, 15, 18, 20, 21, 22, 29, 33, 35, 39, 41, 42, 50, 52, 54, 57, 59, 68, 69, 72, 74, 77, 79, 80, 81, 88], "regressor": [15, 35, 74], "relat": [4, 13, 15, 33, 35, 58, 72, 74, 91], "relationship": 58, "relev": [9, 20, 22, 24, 41, 43, 45, 52, 54, 79, 81, 83], "remark": [30, 51, 60, 89], "rememb": [25, 46, 55, 84], "remind": [13, 27, 48, 57, 72, 86], "remov": [8, 58], "renam": 8, "render": 92, "report": [7, 20, 41, 68, 79], "repositori": 7, "repres": [58, 59], "represent": [17, 29, 37, 50, 58, 59, 76, 88], "request": 92, "requir": [12, 32, 92], "rescu": [14, 34, 73], "resourc": [9, 12, 19, 20, 24, 25, 26, 27, 32, 40, 41, 45, 46, 47, 48, 54, 78, 79, 83, 84, 85, 86], "rest": 94, "result": [19, 40, 78, 91], "retail": [30, 51, 60, 89], "reus": 91, "review": [38, 66, 67, 92], "revis": 63, "rf": 91, "rfe": [24, 45, 54, 83], "ridg": [18, 21, 39, 42, 54, 69, 77, 80], "ridgecv": [21, 42, 69, 80], "right": [31, 61, 90], "rmse": [21, 42, 69, 80], "roc": [20, 41, 68, 79], "root": [21, 42, 69, 80], "row": 8, "rule": [14, 16, 17, 34, 36, 37, 73, 75, 76], "run": [16, 36, 75, 91], "same": [8, 69], "sampl": [20, 22, 25, 43, 46, 52, 55, 79, 81, 84], "sauc": [25, 46, 84], "save": [12, 32, 71, 92], "scale": [12, 16, 18, 23, 32, 36, 39, 44, 53, 65, 71, 75, 77, 82], "scenario": 68, "schedul": 1, "scheme": 103, "scientif": 58, "scikit": [14, 16, 17, 21, 34, 36, 37, 42, 69, 73, 75, 76, 80], "score": [13, 14, 18, 19, 20, 21, 24, 25, 33, 34, 39, 40, 41, 42, 45, 46, 54, 55, 58, 68, 69, 72, 73, 77, 78, 79, 80, 83, 84, 93], "search": [15, 19, 24, 35, 40, 45, 54, 58, 74, 78, 83, 91], "season": [30, 51, 60, 89], "segment": [25, 46, 55, 58, 84], "select": [12, 13, 24, 25, 26, 27, 32, 45, 46, 47, 48, 54, 55, 56, 57, 71, 72, 83, 84, 85, 86, 95], "semant": 58, "send": 92, "sentenc": 58, "separ": [21, 23, 42, 44, 69, 80, 82, 91], "seri": [8, 30, 51, 60, 89, 95, 102], "server": 92, "servic": 92, "set": [5, 10, 12, 14, 19, 20, 32, 34, 40, 41, 63, 73, 78, 79, 92], "set_config": [17, 37, 76], "shap": [23, 44, 53, 82], "shape": [8, 26, 47, 56, 85], "shaplei": [23, 44, 53, 82], "short": 9, "should": [22, 27, 43, 48, 52, 57, 81, 86, 91], "show": [23, 44, 53, 82, 91], "sigmoid": [18, 29, 39, 50, 59, 77, 88], "sign": [18, 39, 77], "silhouett": [25, 46, 55, 84], "similar": [15, 35, 58, 74], "simpl": [14, 34, 73, 93], "simplefeatur": [23, 44, 53, 82], "simpleimput": 65, "simpler": 57, "simul": 101, "singl": [14, 34, 56, 63, 73], "size": 8, "sklearn": [13, 16, 17, 19, 20, 22, 23, 33, 36, 37, 40, 41, 43, 44, 52, 53, 55, 58, 65, 72, 75, 76, 78, 79, 81, 82], "slightli": 57, "slowest": 8, "small": 91, "smote": [20, 79], "social": [28, 49, 57, 58, 87], "softmax": [29, 50, 59, 88], "softwar": [0, 29, 30, 50, 51, 59, 60, 88, 89], "solut": 43, "solv": [19, 40, 78], "some": [13, 19, 20, 22, 24, 33, 40, 43, 45, 52, 54, 58, 68, 72, 78, 79, 81, 83, 92], "sort": 8, "sort_valu": 8, "sourc": [7, 44], "space": [30, 51, 60, 89], "spaci": [28, 49, 58, 87, 93], "spaghetti": [25, 46, 84], "spam": [12, 17, 32, 37, 71, 76], "spars": [17, 37, 76], "sparsiti": 57, "specif": [4, 24, 45, 54, 83], "split": [14, 16, 20, 30, 34, 36, 41, 51, 57, 60, 63, 65, 73, 75, 79, 89, 97], "spotifi": [16, 19, 36, 40, 75, 78], "squar": [21, 42, 69, 80], "stack": [22, 43, 52, 81, 101], "standardscal": [16, 36, 75], "statement": [12, 13, 25, 26, 27, 32, 46, 47, 48, 55, 56, 57, 71, 72, 84, 85, 86], "statist": 92, "stem": 58, "step": [13, 28, 33, 49, 58, 63, 72, 87, 98], "stereotyp": 58, "stop": 55, "stopword": 58, "strategi": [22, 43, 52, 81, 94], "stratifi": [20, 41, 79], "strength": [18, 22, 39, 43, 52, 77, 81], "structur": 92, "studi": 95, "stuff": 59, "style": [12, 32], "submiss": 7, "submit": 7, "success": [19, 40, 58, 78], "summari": [8, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 68, 71, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90], "supervis": [12, 13, 14, 15, 25, 27, 32, 33, 34, 35, 46, 48, 55, 57, 63, 71, 72, 73, 74, 84, 86, 92], "support": [15, 35, 74], "surviv": [31, 61, 90, 95], "svc": [20, 41, 68, 79], "svm": [15, 18, 35, 39, 64, 74, 77], "syllabu": [1, 103], "syntact": 58, "syntax": [16, 17, 19, 36, 37, 40, 75, 76, 78], "synthet": [20, 79], "system": [27, 48, 57, 86, 95], "ta": [1, 103], "tabular": [13, 15, 33, 35, 72, 74, 92], "tackl": [21, 42, 69, 80], "take": [26, 47, 56, 85], "takeawai": 92, "target": [12, 13, 17, 21, 25, 32, 33, 37, 42, 46, 55, 69, 71, 72, 76, 80, 84], "task": [28, 49, 58, 87], "teach": [1, 103], "team": [1, 103], "techniqu": [16, 20, 36, 75, 79], "templat": 7, "tempor": [30, 51, 60, 89], "tent": 1, "terminologi": [13, 29, 33, 50, 59, 72, 88], "test": [5, 14, 19, 30, 34, 40, 51, 60, 61, 63, 73, 78, 89], "test_df": [14, 34, 73], "test_siz": [14, 34, 73], "text": [17, 28, 37, 49, 58, 65, 76, 87, 93], "than": [17, 19, 24, 37, 40, 45, 54, 76, 78, 83, 91], "thei": [22, 43, 52, 81], "them": 8, "thi": [8, 12, 16, 17, 23, 30, 32, 36, 37, 44, 53, 63, 65, 68, 71, 75, 76, 82, 91, 92], "thing": [16, 36, 58, 75, 91], "threshold": [20, 41, 68, 79], "time": [6, 12, 30, 31, 32, 51, 60, 61, 71, 89, 90, 95, 102], "tip": 95, "todai": [14, 16, 17, 20, 21, 34, 36, 37, 41, 42, 58, 69, 73, 75, 76, 79, 80, 91], "toi": [13, 17, 20, 28, 33, 37, 41, 49, 57, 58, 68, 72, 76, 79, 87], "token": [28, 49, 58, 87], "tool": [28, 49, 58, 87], "topic": [28, 49, 58, 87], "trade": [14, 15, 22, 34, 35, 43, 52, 73, 74, 81], "tradeoff": [14, 20, 22, 34, 41, 43, 52, 68, 73, 79, 81], "tradit": [13, 30, 33, 51, 60, 72, 89], "train": [12, 13, 14, 17, 18, 20, 29, 30, 32, 33, 34, 37, 39, 41, 50, 51, 58, 59, 60, 71, 72, 73, 76, 77, 79, 88, 89, 91, 92, 100], "train_df": [14, 34, 73], "train_siz": [14, 34, 73], "transfer": [29, 50, 59, 88], "transform": [16, 17, 21, 24, 36, 37, 42, 45, 54, 69, 75, 76, 80, 83, 91], "transpar": [23, 44, 53, 82, 92], "tree": [13, 22, 23, 33, 43, 44, 52, 53, 63, 72, 81, 82, 91, 97], "trend": [30, 51, 60, 89], "true": [12, 25, 26, 27, 32, 46, 47, 48, 55, 56, 57, 71, 84, 85, 86], "truncat": 56, "trust": 57, "try": [16, 21, 36, 42, 65, 75, 80, 91, 92], "tumour": 55, "tune": [21, 25, 42, 46, 55, 57, 69, 80, 84, 97], "tutori": [30, 35, 41, 96, 97, 98, 99, 100, 101, 102], "two": [17, 37, 56, 76], "type": [12, 14, 20, 21, 23, 25, 30, 31, 32, 34, 41, 42, 44, 46, 51, 55, 58, 60, 61, 68, 69, 71, 73, 79, 80, 82, 84, 89, 90, 91], "typic": [14, 28, 34, 49, 58, 63, 73, 87], "u": 91, "ubc": 1, "ubuntu": 5, "under": [20, 41, 68, 79], "underfit": [14, 34, 73], "undersampl": [20, 79], "understand": 92, "unequ": [30, 51, 60, 89], "unit": 59, "unknown": [17, 37, 76], "unlabel": [25, 46, 55, 84], "unseen": [12, 14, 32, 34, 71, 73], "unsupervis": [13, 25, 33, 46, 55, 58, 72, 84], "up": [5, 10, 12, 14, 15, 32, 34, 35, 73, 74, 91, 92], "updat": 7, "url": 8, "us": [7, 8, 12, 13, 14, 15, 16, 17, 20, 21, 22, 24, 25, 28, 29, 32, 33, 34, 35, 36, 37, 42, 43, 46, 49, 50, 52, 54, 55, 58, 59, 64, 69, 71, 72, 73, 74, 75, 76, 79, 80, 81, 83, 84, 87, 88, 91, 94, 96, 103], "usa": [13, 72, 96], "user": [5, 27, 48, 57, 86], "usual": [24, 45, 54, 83], "util": [27, 48, 57, 86], "v": [2, 12, 13, 14, 15, 20, 23, 25, 29, 32, 33, 34, 35, 41, 44, 46, 50, 53, 54, 55, 56, 59, 68, 72, 73, 74, 79, 82, 84, 88, 92, 94], "valid": [14, 16, 19, 20, 30, 34, 36, 40, 41, 51, 60, 63, 68, 73, 75, 78, 79, 89, 97], "varianc": [14, 34, 73], "vector": [8, 15, 28, 35, 49, 58, 74, 87], "video": [12, 13, 14, 15, 16, 18, 20, 21, 22, 25, 26, 28, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 46, 47, 49, 52, 55, 56, 58, 71, 72, 73, 74, 75, 77, 79, 80, 81, 84, 85, 87], "view": [15, 17, 35, 37, 58, 74, 76], "violat": [14, 34, 73], "virtual": 10, "vision": [29, 50, 59, 88, 95], "visual": [9, 19, 40, 53, 56, 78, 91], "vocabulari": [38, 66, 67], "wai": [19, 24, 40, 45, 54, 78, 83, 91], "waitlist": [12, 32], "want": [17, 23, 31, 37, 44, 53, 61, 76, 82, 90], "ward": 56, "warn": [13, 24, 33, 45, 54, 72, 83], "watch": 91, "waterfal": 53, "we": [8, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 31, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 52, 53, 54, 55, 57, 58, 61, 63, 69, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 90, 91, 92], "weak": [22, 43, 52, 81], "web": 92, "websit": [12, 32], "week": 30, "weight": [18, 20, 39, 41, 77, 79], "what": [5, 10, 12, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 34, 36, 37, 39, 41, 42, 43, 44, 45, 46, 48, 49, 52, 53, 54, 55, 57, 58, 61, 68, 69, 71, 73, 75, 76, 77, 79, 80, 81, 82, 83, 84, 86, 87, 90, 91, 92], "when": [8, 16, 19, 36, 40, 55, 75, 78, 91], "where": [17, 31, 37, 61, 76, 90], "whether": [12, 32, 71], "which": [12, 13, 20, 22, 25, 26, 27, 32, 41, 43, 46, 47, 48, 52, 55, 56, 57, 68, 71, 72, 79, 81, 84, 85, 86], "why": [10, 12, 17, 19, 23, 24, 27, 29, 32, 34, 37, 40, 44, 45, 48, 50, 53, 54, 57, 58, 59, 71, 76, 78, 82, 83, 86, 88, 91], "window": [5, 10], "wise": 8, "without": [25, 46, 55, 84], "word": [17, 28, 37, 49, 58, 76, 87, 93], "word2vec": 58, "work": [13, 22, 26, 33, 43, 47, 52, 56, 72, 81, 85, 91], "workflow": [12, 14, 20, 34, 41, 68, 71, 73, 79], "would": [14, 34, 65, 68, 73, 92], "wrapper": 94, "write": [13, 33, 72], "x": [12, 13, 21, 23, 32, 33, 42, 44, 69, 71, 72, 80, 82, 91], "xgboost": [22, 43, 52, 81], "y": [12, 13, 21, 23, 32, 33, 42, 44, 69, 71, 72, 80, 82, 91], "yale": 58, "ye": [31, 61, 90], "yield": [19, 40, 78], "you": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 54, 56, 57, 58, 60, 61, 65, 66, 67, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92], "your": [5, 12, 13, 32, 33, 57, 63, 72, 91]}})