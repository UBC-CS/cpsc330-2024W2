Search.setIndex({"alltitles": {"": [[23, "id1"]], "(Optional) Changing the data": [[34, "optional-changing-the-data"]], "(Optional) Evaluation": [[45, "optional-evaluation"]], "(Optional) Evaluation metrics for multi-class classification": [[34, "optional-evaluation-metrics-for-multi-class-classification"]], "(Optional) Example 1: Optimization bias": [[33, "optional-example-1-optimization-bias"]], "(Optional) Example 2: Optimization bias": [[33, "optional-example-2-optimization-bias"]], "(Optional) Fancier methods": [[33, "optional-fancier-methods"]], "(Optional) Fitting in boosted regression trees.": [[36, "optional-fitting-in-boosted-regression-trees"]], "(Optional) Forward or backward selection": [[38, "optional-forward-or-backward-selection"]], "(Optional) Macro average and weighted average": [[34, "optional-macro-average-and-weighted-average"]], "(Optional) Parametric vs non parametric": [[15, "optional-parametric-vs-non-parametric"], [20, "optional-parametric-vs-non-parametric"], [29, "optional-parametric-vs-non-parametric"]], "(Optional) Passing probability distributions to random search": [[33, "optional-passing-probability-distributions-to-random-search"]], "(Optional) Prediction in boosted regression trees": [[36, "optional-prediction-in-boosted-regression-trees"]], "(Optional) Problems with feature selection": [[38, "optional-problems-with-feature-selection"]], "(Optional) Search and score": [[38, "optional-search-and-score"]], "(Optional) Searching for optimal parameters with successive halving\u00b6": [[33, "optional-searching-for-optimal-parameters-with-successive-halving"]], "(Optional) Setting up a directory structure and environment": [[47, "optional-setting-up-a-directory-structure-and-environment"]], "(Optional) Some more details": [[34, "optional-some-more-details"]], "(Supervised) machine learning: popular definition": [[12, "supervised-machine-learning-popular-definition"], [17, "supervised-machine-learning-popular-definition"], [26, "supervised-machine-learning-popular-definition"]], "(iClicker) Exercise 14.1": [[38, "id1"]], "(iClicker) Exercise 21.1": [[45, "iclicker-exercise-21-1"]], "(iClicker) Exercise 21.2": [[45, "iclicker-exercise-21-2"]], "(iClicker) Exercise 4.1": [[20, "iclicker-exercise-4-1"], [29, "iclicker-exercise-4-1"]], "(iClicker) Exercise 4.1 https://join.iclicker.com/FUYI": [[15, "iclicker-exercise-4-1-https-join-iclicker-com-fuyi"]], "(iClicker) Exercise 4.2": [[20, "iclicker-exercise-4-2"], [29, "iclicker-exercise-4-2"]], "(iClicker) Exercise 4.2 https://join.iclicker.com/FUYI": [[15, "iclicker-exercise-4-2-https-join-iclicker-com-fuyi"]], "(iClicker) Exercise 5.1": [[16, "iclicker-exercise-5-1"], [21, "iclicker-exercise-5-1"], [30, "iclicker-exercise-5-1"]], "(iClicker) Exercise 5.2": [[16, "iclicker-exercise-5-2"], [21, "iclicker-exercise-5-2"], [30, "iclicker-exercise-5-2"]], "(iClicker) Exercise 5.3": [[16, "iclicker-exercise-5-3"], [21, "iclicker-exercise-5-3"], [30, "iclicker-exercise-5-3"]], "(iClicker) Exercise 6.1": [[31, "iclicker-exercise-6-1"]], "(iClicker) Exercise 6.2": [[31, "iclicker-exercise-6-2"]], "(iClicker) Exercise 7.1": [[32, "iclicker-exercise-7-1"]], "(iClicker) Exercise 7.2": [[32, "iclicker-exercise-7-2"]], "(iClicker) Exercise 8.1": [[33, "iclicker-exercise-8-1"]], "(iClicker) Midterm poll": [[39, "iclicker-midterm-poll"]], "15.1 Select all of the following statements which are True (iClicker)": [[39, "select-all-of-the-following-statements-which-are-true-iclicker"]], "15.2 Select all of the following statements which are True (iClicker)": [[39, "id1"]], "15.3 Select all of the following statements which are True (iClicker)": [[39, "id3"]], "16.1 Select all of the following statements which are True (iClicker)": [[40, "select-all-of-the-following-statements-which-are-true-iclicker"]], "16.2 Select all of the following statements which are True (iClicker)": [[40, "id2"]], "16.3 Select all of the following statements which are True": [[40, "select-all-of-the-following-statements-which-are-true"]], "330 vs. 340": [[47, "vs-340"]], "<font color='red'>Question 1</font>": [[51, "question-1"], [52, "question-1"]], "<font color='red'>Question 2: Baseline model</font>": [[52, "question-2-baseline-model"]], "<font color='red'>Question 2</font>": [[51, "question-2"]], "<font color='red'>Question 3: Decision tree</font>": [[52, "question-3-decision-tree"]], "<font color='red'>Question 3</font>": [[51, "question-3"]], "<font color='red'>Question 4: Hyperparameter tuning</font>": [[52, "question-4-hyperparameter-tuning"]], "<font color='red'>Question 4</font>": [[51, "question-4"]], "<font color='red'>Question 5: Cross-validation</font>": [[52, "question-5-cross-validation"]], "<font color='red'>Question 6: Hyperparameters playground</font>": [[52, "question-6-hyperparameters-playground"]], "<font color='red'>Recap Questions</font>": [[51, "recap-questions"]], "<font color='red'>Recap/comprehension questions</font>": [[53, "recap-comprehension-questions"]], "A few comments on PR curve": [[34, "a-few-comments-on-pr-curve"]], "A few comments on clustering evaluation": [[40, "a-few-comments-on-clustering-evaluation"]], "AP score": [[34, "ap-score"]], "AP vs. F1-score": [[34, "ap-vs-f1-score"]], "API on the localhost": [[47, "api-on-the-localhost"]], "About this course": [[12, "about-this-course"], [17, "about-this-course"]], "About this document": [[8, "about-this-document"]], "Academic concessions": [[54, "academic-concessions"]], "Accessing homework assignments": [[7, "accessing-homework-assignments"]], "Accessing learned parameters": [[32, "accessing-learned-parameters"]], "Activity": [[12, "activity"], [17, "activity"]], "Activity (~5 mins)": [[37, "activity-5-mins"], [37, "id3"]], "Activity: Context and word meaning": [[42, "activity-context-and-word-meaning"]], "Activity: Discuss the following questions in your group": [[23, "activity-discuss-the-following-questions-in-your-group"]], "Activity: How can you measure quality of the data? (~3 mins)": [[38, "activity-how-can-you-measure-quality-of-the-data-3-mins"]], "Activity: explaining GridSearchCV (15 min)": [[46, "activity-explaining-gridsearchcv-15-min"]], "Adding/removing columns with [] and drop()": [[8, "adding-removing-columns-with-and-drop"]], "Adding/removing rows with [] and drop()": [[8, "adding-removing-rows-with-and-drop"]], "Additional submission instructions": [[7, "additional-submission-instructions"]], "Addressing class imbalance": [[34, "addressing-class-imbalance"]], "Advantages of RandomizedSearchCV": [[33, "advantages-of-randomizedsearchcv"], [33, "id1"]], "Alternative and more compact syntax: make_pipeline": [[16, "alternative-and-more-compact-syntax-make-pipeline"], [21, "alternative-and-more-compact-syntax-make-pipeline"], [30, "alternative-and-more-compact-syntax-make-pipeline"]], "Alternative methods for scaling": [[25, "alternative-methods-for-scaling"]], "Alternative terminology for examples, features, targets, and training": [[13, "alternative-terminology-for-examples-features-targets-and-training"], [18, "alternative-terminology-for-examples-features-targets-and-training"], [27, "alternative-terminology-for-examples-features-targets-and-training"]], "An effective strategy": [[36, "an-effective-strategy"]], "An example from a project": [[48, "an-example-from-a-project"]], "An example of a bootstrap samples": [[36, "an-example-of-a-bootstrap-samples"]], "An introduction to Grid Search": [[46, "an-introduction-to-grid-search"]], "Analogy-based algorithms in practice": [[15, "analogy-based-algorithms-in-practice"], [29, "analogy-based-algorithms-in-practice"]], "Analogy-based models": [[15, "analogy-based-models"], [29, "analogy-based-models"]], "Announcements": [[12, "announcements"], [13, "announcements"], [14, "announcements"], [16, "announcements"], [32, "announcements"]], "Appendix A: Demo of feature engineering for text data": [[48, null]], "Appendix B: Multi-class, meta-strategies": [[49, null]], "Applying feature transformations": [[35, "applying-feature-transformations"], [46, "applying-feature-transformations"]], "Applying functions to a dataframe with df.apply() and df.applymap()": [[8, "applying-functions-to-a-dataframe-with-df-apply-and-df-applymap"]], "Approach 1: Only consider the examples where \u201cChurn\u201d=Yes": [[45, "approach-1-only-consider-the-examples-where-churn-yes"]], "Approach 2: Assume everyone churns right now": [[45, "approach-2-assume-everyone-churns-right-now"]], "Approach 3: Survival analysis": [[45, "approach-3-survival-analysis"]], "Approach from all angles": [[46, "approach-from-all-angles"]], "Are we doing better with class_weight=\"balanced\"?": [[34, "are-we-doing-better-with-class-weight-balanced"]], "Area under the curve (AUC)": [[34, "area-under-the-curve-auc"]], "Assessing on the test set": [[23, "assessing-on-the-test-set"]], "Assignments": [[54, "assignments"]], "Attention": [[13, null], [13, null], [15, null], [18, null], [18, null], [20, null], [27, null], [27, null], [27, null], [29, null]], "Attribution": [[46, "attribution"]], "Automated hyperparameter optimization": [[33, "automated-hyperparameter-optimization"], [33, "id3"]], "Averaging": [[36, "averaging"]], "Bad range for hyperparameters": [[33, "bad-range-for-hyperparameters"]], "Bag of words (BOW) representation": [[31, "bag-of-words-bow-representation"]], "Bag-of-words model": [[48, "bag-of-words-model"]], "Baseline": [[34, "baseline"], [37, "baseline"]], "Baseline Approaches": [[41, "baseline-approaches"]], "Baseline model": [[23, "baseline-model"]], "Baselines": [[13, "baselines"], [18, "baselines"], [27, "baselines"], [36, "baselines"]], "Baselines [video]": [[13, "baselines-video"], [18, "baselines-video"], [27, "baselines-video"]], "Basic text preprocessing [video]": [[42, "basic-text-preprocessing-video"]], "Better features usually help more than a better model.": [[38, "better-features-usually-help-more-than-a-better-model"]], "Beyond error rate in recommendation systems": [[41, "beyond-error-rate-in-recommendation-systems"]], "Bias vs variance tradeoff": [[14, "bias-vs-variance-tradeoff"], [19, "bias-vs-variance-tradeoff"], [28, "bias-vs-variance-tradeoff"]], "Big picture and datasets": [[13, "big-picture-and-datasets"], [18, "big-picture-and-datasets"], [27, "big-picture-and-datasets"]], "Big picture and motivation": [[14, "big-picture-and-motivation"], [19, "big-picture-and-motivation"], [28, "big-picture-and-motivation"]], "Books": [[1, "books"]], "Bottom-up explanations": [[46, "bottom-up-explanations"]], "Break (5 min)": [[8, "break-5-min"], [12, "break-5-min"], [13, "break-5-min"], [14, "break-5-min"], [15, "break-5-min"], [16, "break-5-min"], [17, "break-5-min"], [18, "break-5-min"], [19, "break-5-min"], [20, "break-5-min"], [27, "break-5-min"], [28, "break-5-min"], [29, "break-5-min"], [30, "break-5-min"], [31, "break-5-min"], [38, "break-5-min"], [42, "break-5-min"], [43, "break-5-min"], [45, "break-5-min"], [46, "break-5-min"]], "Break (~15 min)": [[47, "break-15-min"]], "Broadcasting in numpy": [[8, "broadcasting-in-numpy"]], "Building a model": [[47, "building-a-model"]], "Building a supervise machine learning model": [[12, "building-a-supervise-machine-learning-model"], [17, "building-a-supervise-machine-learning-model"], [26, "building-a-supervise-machine-learning-model"]], "Building and deploying a web app": [[47, "building-and-deploying-a-web-app"]], "Building decision trees with sklearn": [[13, "building-decision-trees-with-sklearn"], [18, "building-decision-trees-with-sklearn"], [27, "building-decision-trees-with-sklearn"]], "Building user profiles": [[41, "building-user-profiles"]], "CPSC 330 Documents": [[3, null]], "CPSC 330 Python notes": [[8, null]], "CPSC 330 grading policies": [[6, null]], "CPSC 330 vs. 340": [[12, "cpsc-330-vs-340"], [17, "cpsc-330-vs-340"]], "CPSC 330 vs. CPSC 340": [[2, null]], "Can we learn without targets?": [[39, "can-we-learn-without-targets"]], "Can we use this feature in the model?": [[16, "can-we-use-this-feature-in-the-model"], [21, "can-we-use-this-feature-in-the-model"], [30, "can-we-use-this-feature-in-the-model"]], "Cases where it\u2019s OK to break the golden rule": [[31, "cases-where-it-s-ok-to-break-the-golden-rule"]], "CatBoost": [[36, "catboost"]], "Categorical features": [[25, "categorical-features"], [37, "categorical-features"]], "Categorical features [video]": [[16, "categorical-features-video"], [21, "categorical-features-video"], [30, "categorical-features-video"]], "Categorical features with only two possible categories": [[31, "categorical-features-with-only-two-possible-categories"]], "Censoring and survival analysis": [[45, "censoring-and-survival-analysis"]], "Centre for Accessibility (CfA) Exam Accommodations": [[54, "centre-for-accessibility-cfa-exam-accommodations"]], "Changing the training procedure": [[34, "changing-the-training-procedure"]], "Characters in this course?": [[12, "characters-in-this-course"], [17, "characters-in-this-course"], [26, "characters-in-this-course"]], "Checklist for you before next class": [[12, "checklist-for-you-before-next-class"], [17, "checklist-for-you-before-next-class"]], "Choosing K [video]": [[39, "choosing-k-video"]], "Choosing n_neighbors": [[15, "choosing-n-neighbors"], [20, "choosing-n-neighbors"], [29, "choosing-n-neighbors"]], "Citing sources": [[7, "citing-sources"]], "Class imbalance in training sets": [[34, "class-imbalance-in-training-sets"]], "Class meetings": [[54, "class-meetings"]], "Classification report": [[34, "classification-report"]], "Classification vs. Regression": [[13, "classification-vs-regression"], [18, "classification-vs-regression"], [27, "classification-vs-regression"]], "Classification with KNeighborsClassifier": [[24, "classification-with-kneighborsclassifier"]], "Clustering": [[50, "clustering"]], "Clustering Activity (~5 mins)": [[39, "clustering-activity-5-mins"]], "Clustering motivation [video]": [[39, "clustering-motivation-video"]], "Clustering: Input and (possible) output": [[39, "clustering-input-and-possible-output"]], "Code of conduct": [[54, "code-of-conduct"]], "Coefficients and intercept": [[32, "coefficients-and-intercept"]], "ColumnTransformer example": [[31, "columntransformer-example"]], "ColumnTransformer on the California housing dataset": [[31, "columntransformer-on-the-california-housing-dataset"], [53, "columntransformer-on-the-california-housing-dataset"]], "ColumnTransformer: Transformed data": [[31, "columntransformer-transformed-data"]], "Coming up \u2026": [[14, "coming-up"], [19, "coming-up"], [28, "coming-up"]], "Coming up:": [[15, "coming-up"], [20, "coming-up"], [29, "coming-up"]], "Command-line git": [[5, "command-line-git"]], "Common applications": [[39, "common-applications"]], "Common preprocessing techniques": [[16, "common-preprocessing-techniques"], [21, "common-preprocessing-techniques"], [30, "common-preprocessing-techniques"]], "Communication": [[50, "communication"]], "Communications": [[12, "communications"], [17, "communications"]], "Completing the utility matrix with content-based filtering": [[41, "completing-the-utility-matrix-with-content-based-filtering"]], "Components of a linear classifier": [[32, "components-of-a-linear-classifier"]], "Concepts then labels, not the other way around": [[46, "concepts-then-labels-not-the-other-way-around"]], "Concepts we revised in this demo": [[23, "concepts-we-revised-in-this-demo"]], "Conclusion & farewell": [[47, "conclusion-farewell"]], "Confidence and predict_proba (20 min)": [[46, "confidence-and-predict-proba-20-min"]], "Confusing and perhaps misleading visualization of results": [[46, "confusing-and-perhaps-misleading-visualization-of-results"]], "Confusion matrix": [[34, "confusion-matrix"]], "Confusion matrix with cross-validation": [[34, "confusion-matrix-with-cross-validation"]], "Cons of k-NNs for supervised learning": [[15, "cons-of-k-nns-for-supervised-learning"], [20, "cons-of-k-nns-for-supervised-learning"], [29, "cons-of-k-nns-for-supervised-learning"]], "Content-based filtering": [[41, "content-based-filtering"]], "Convenient make_column_transformer syntax": [[31, "convenient-make-column-transformer-syntax"]], "Course Learning Objectives": [[11, null]], "Course co-ordinator": [[1, "course-co-ordinator"], [54, "course-co-ordinator"]], "Course description": [[54, "course-description"]], "Course format": [[12, "course-format"], [17, "course-format"]], "Course review / conclusion (~20 min)": [[47, "course-review-conclusion-20-min"]], "Course website": [[12, "course-website"], [17, "course-website"]], "Cox proportional hazards model": [[45, "cox-proportional-hazards-model"]], "Create X and y": [[13, "create-x-and-y"], [18, "create-x-and-y"], [27, "create-x-and-y"]], "Create a classifier object": [[13, "create-a-classifier-object"], [18, "create-a-classifier-object"], [27, "create-a-classifier-object"]], "Create a column transformer": [[31, "create-a-column-transformer"]], "Creating train_df and test_df": [[14, "creating-train-df-and-test-df"], [19, "creating-train-df-and-test-df"], [28, "creating-train-df-and-test-df"]], "Creating utility matrix": [[41, "creating-utility-matrix"]], "Credit": [[10, "credit"]], "Cross validation with different metrics": [[34, "cross-validation-with-different-metrics"]], "Cross-validation": [[23, "cross-validation"], [44, "cross-validation"], [44, "id4"]], "Cross-validation [video]": [[14, "cross-validation-video"], [19, "cross-validation-video"], [28, "cross-validation-video"]], "Cross-validation to the rescue!!": [[14, "cross-validation-to-the-rescue"], [19, "cross-validation-to-the-rescue"], [28, "cross-validation-to-the-rescue"]], "Cross-validation using scikit-learn": [[14, "cross-validation-using-scikit-learn"], [19, "cross-validation-using-scikit-learn"], [28, "cross-validation-using-scikit-learn"]], "Curse of dimensionality": [[15, "curse-of-dimensionality"], [20, "curse-of-dimensionality"], [29, "curse-of-dimensionality"]], "Customer churn": [[45, "customer-churn"]], "Customer segmentation": [[39, "customer-segmentation"]], "DBSCAN [video]": [[40, "dbscan-video"]], "DBSCAN introduction": [[40, "dbscan-introduction"]], "DBSCAN: failure cases": [[40, "dbscan-failure-cases"], [40, "id1"]], "Data": [[31, "data"], [32, "data"], [36, "data"], [37, "data"], [37, "id1"]], "Data Splitting [video]": [[14, "data-splitting-video"], [19, "data-splitting-video"], [28, "data-splitting-video"]], "Data and main approaches": [[41, "data-and-main-approaches"]], "Data and splitting": [[25, "data-and-splitting"]], "Data exploration": [[39, "data-exploration"]], "Data splitting": [[23, "data-splitting"], [52, "data-splitting"]], "Dataframe summaries": [[8, "dataframe-summaries"]], "Dataset": [[43, "dataset"], [46, "dataset"]], "Dataset [video]": [[35, "dataset-video"]], "Dataset for demonstration": [[34, "dataset-for-demonstration"]], "Dataset, splitting, and baseline": [[16, "dataset-splitting-and-baseline"], [21, "dataset-splitting-and-baseline"], [30, "dataset-splitting-and-baseline"]], "Datasets": [[7, "datasets"]], "Dealing with class imbalance [video]": [[34, "dealing-with-class-imbalance-video"]], "Dealing with unknown categories": [[31, "dealing-with-unknown-categories"]], "Debugging": [[10, "debugging"]], "Decision boundaries playground": [[24, "decision-boundaries-playground"]], "Decision boundary": [[13, "decision-boundary"], [18, "decision-boundary"], [27, "decision-boundary"]], "Decision boundary for max_depth=1": [[13, "decision-boundary-for-max-depth-1"], [18, "decision-boundary-for-max-depth-1"], [27, "decision-boundary-for-max-depth-1"]], "Decision boundary for max_depth=2": [[13, "decision-boundary-for-max-depth-2"], [18, "decision-boundary-for-max-depth-2"], [27, "decision-boundary-for-max-depth-2"]], "Decision boundary for max_depth=5": [[13, "decision-boundary-for-max-depth-5"], [18, "decision-boundary-for-max-depth-5"], [27, "decision-boundary-for-max-depth-5"]], "Decision boundary of SVMs": [[15, "decision-boundary-of-svms"], [20, "decision-boundary-of-svms"], [29, "decision-boundary-of-svms"]], "Decision boundary of logistic regression": [[32, "decision-boundary-of-logistic-regression"]], "Decision tree algorithm": [[13, "decision-tree-algorithm"], [18, "decision-tree-algorithm"], [27, "decision-tree-algorithm"]], "Decision tree feature importances": [[37, "decision-tree-feature-importances"]], "Decision tree for regression problems": [[13, "decision-tree-for-regression-problems"], [18, "decision-tree-for-regression-problems"], [27, "decision-tree-for-regression-problems"]], "Decision tree model": [[23, "decision-tree-model"]], "Decision tree with max_depth=1": [[13, "decision-tree-with-max-depth-1"], [18, "decision-tree-with-max-depth-1"], [27, "decision-tree-with-max-depth-1"]], "Decision tree with max_depth=3": [[13, "decision-tree-with-max-depth-3"], [18, "decision-tree-with-max-depth-3"], [27, "decision-tree-with-max-depth-3"]], "Decision trees [video]": [[13, "decision-trees-video"], [18, "decision-trees-video"], [27, "decision-trees-video"]], "Decision trees with continuous features": [[13, "decision-trees-with-continuous-features"], [18, "decision-trees-with-continuous-features"], [27, "decision-trees-with-continuous-features"]], "DecisionTreeClassifier baseline": [[36, "decisiontreeclassifier-baseline"]], "DecisionTreeClassifier on quiz2 grade prediction toy dataset": [[13, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"], [18, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"], [27, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"]], "Decisions involve a few key pieces": [[46, "decisions-involve-a-few-key-pieces"]], "Decreasing the threshold": [[34, "decreasing-the-threshold"]], "Deep learning": [[44, "deep-learning"]], "Deep learning software": [[43, "deep-learning-software"]], "Deliverable due dates (tentative)": [[1, "deliverable-due-dates-tentative"]], "Demo of creating a new web service": [[47, "demo-of-creating-a-new-web-service"]], "Demo of feature engineering with numeric features": [[38, "demo-of-feature-engineering-with-numeric-features"]], "Demo: A more complicated dataset": [[44, "demo-a-more-complicated-dataset"]], "Demo: Deploying moment classification model": [[47, "demo-deploying-moment-classification-model"]], "Dendrogram": [[40, "dendrogram"]], "Deploying the API on a server (not covered)": [[47, "deploying-the-api-on-a-server-not-covered"]], "Deployment (Not examinable)": [[50, "deployment-not-examinable"]], "Difference between Statistics and Machine Learning": [[47, "difference-between-statistics-and-machine-learning"]], "Different models": [[37, "different-models"]], "Different range for hyperparameters yields better results!": [[33, "different-range-for-hyperparameters-yields-better-results"]], "Different scoring functions with cross_validate": [[35, "different-scoring-functions-with-cross-validate"]], "Dimensions in ML problems": [[15, "dimensions-in-ml-problems"], [20, "dimensions-in-ml-problems"], [29, "dimensions-in-ml-problems"]], "Discuss the following questions in your group": [[23, "discuss-the-following-questions-in-your-group"]], "Discussion": [[47, "discussion"]], "Discussion question": [[42, "discussion-question"]], "Discussion questions": [[25, "discussion-questions"]], "Discussion questions:": [[46, "discussion-questions"]], "Distance between feature vectors": [[15, "distance-between-feature-vectors"], [20, "distance-between-feature-vectors"], [29, "distance-between-feature-vectors"]], "Do we actually want to use certain features for prediction?": [[31, "do-we-actually-want-to-use-certain-features-for-prediction"]], "Do we have class imbalance?": [[36, "do-we-have-class-imbalance"], [37, "do-we-have-class-imbalance"]], "Do we have correlated features?": [[37, "do-we-have-correlated-features"]], "Document clustering": [[39, "document-clustering"]], "Domain-specific transformations": [[38, "domain-specific-transformations"]], "Dummy Classifier": [[25, "dummy-classifier"]], "Dummy classifier": [[48, "dummy-classifier"]], "Dummy model": [[24, "dummy-model"]], "DummyClassifier": [[13, "dummyclassifier"], [18, "dummyclassifier"], [27, "dummyclassifier"], [44, "dummyclassifier"], [45, "dummyclassifier"]], "DummyClassifier baseline": [[36, "dummyclassifier-baseline"]], "DummyClassifier on quiz2 grade prediction toy dataset": [[13, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"], [18, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"], [27, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"]], "DummyRegressor": [[13, "dummyregressor"], [18, "dummyregressor"], [27, "dummyregressor"], [35, "dummyregressor"]], "EDA": [[16, "eda"], [21, "eda"], [30, "eda"], [34, "eda"], [35, "eda"]], "EDA: Exploratory Data Analysis": [[52, "eda-exploratory-data-analysis"]], "Encoding text data": [[31, "encoding-text-data"]], "Encoding time as a number": [[44, "encoding-time-as-a-number"]], "Encoding time of day as a categorical feature": [[44, "encoding-time-of-day-as-a-categorical-feature"]], "Ensembles": [[50, "ensembles"]], "Equally good": [[46, "equally-good"]], "Ethics": [[50, "ethics"]], "Euclidean distance": [[15, "euclidean-distance"], [20, "euclidean-distance"], [29, "euclidean-distance"]], "Evaluating DBSCAN clusters": [[40, "evaluating-dbscan-clusters"]], "Evaluation": [[41, "evaluation"], [41, "id3"]], "Evaluation metrics": [[50, "evaluation-metrics"]], "Evaluation metrics for binary classification: Motivation": [[34, "evaluation-metrics-for-binary-classification-motivation"]], "Evalution metrics overview": [[34, "evalution-metrics-overview"]], "Examining the preprocessed data": [[35, "examining-the-preprocessed-data"], [46, "examining-the-preprocessed-data"]], "Example": [[32, "example"], [36, "example"]], "Example 1: Predicting whether a patient has a liver disease or not": [[12, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"], [17, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"], [26, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"]], "Example 1: What is \u201ccorrect\u201d grouping?": [[39, "example-1-what-is-correct-grouping"]], "Example 1: quiz 2 grade prediction": [[13, "example-1-quiz-2-grade-prediction"], [18, "example-1-quiz-2-grade-prediction"], [27, "example-1-quiz-2-grade-prediction"]], "Example 2: Predicting country using the longitude and latitude": [[13, "example-2-predicting-country-using-the-longitude-and-latitude"], [27, "example-2-predicting-country-using-the-longitude-and-latitude"]], "Example 2: Predicting the label of a given image": [[12, "example-2-predicting-the-label-of-a-given-image"], [17, "example-2-predicting-the-label-of-a-given-image"], [26, "example-2-predicting-the-label-of-a-given-image"]], "Example 3: Predicting housing prices": [[12, "example-3-predicting-housing-prices"], [17, "example-3-predicting-housing-prices"], [26, "example-3-predicting-housing-prices"]], "Example showing how can we interpret coefficients of scaled features.": [[37, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"]], "Example: Is \u201cRelevance\u201d clearly defined?": [[38, "example-is-relevance-clearly-defined"]], "Example: Predict whether a message is spam or not": [[12, "example-predict-whether-a-message-is-spam-or-not"], [17, "example-predict-whether-a-message-is-spam-or-not"], [26, "example-predict-whether-a-message-is-spam-or-not"]], "Example: Supervised vs unsupervised learning": [[39, "example-supervised-vs-unsupervised-learning"]], "Example: Tabular data for grade prediction": [[13, "example-tabular-data-for-grade-prediction"], [18, "example-tabular-data-for-grade-prediction"], [27, "example-tabular-data-for-grade-prediction"]], "Example: Tabular data for the housing price prediction": [[13, "example-tabular-data-for-the-housing-price-prediction"], [27, "example-tabular-data-for-the-housing-price-prediction"]], "Example: class_weight parameter of sklearn LogisticRegression": [[34, "example-class-weight-parameter-of-sklearn-logisticregression"]], "Example: k-nearest neighbours on the Spotify dataset": [[16, "example-k-nearest-neighbours-on-the-spotify-dataset"], [21, "example-k-nearest-neighbours-on-the-spotify-dataset"], [30, "example-k-nearest-neighbours-on-the-spotify-dataset"]], "Examples": [[12, "examples"], [17, "examples"], [26, "examples"]], "Exercise 17.1 Select all of the following statements which are True (iClicker)": [[41, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 17.2 Select all of the following statements which are True (iClicker)": [[41, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 2.1 Select all of the following statements which are examples of supervised machine learning": [[13, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"], [27, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"]], "Exercise 2.3": [[18, "exercise-2-3"]], "Exercise 2.4": [[13, "exercise-2-4"], [27, "exercise-2-4"]], "Exercise 8.2": [[33, "exercise-8-2"]], "Exercise: Predicting country using the longitude and latitude": [[51, "exercise-predicting-country-using-the-longitude-and-latitude"]], "Exhaustive grid search: sklearn.model_selection.GridSearchCV": [[33, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"]], "Explaining a prediction": [[37, "explaining-a-prediction"]], "Explanation 1": [[46, "explanation-1"]], "Explanation 2": [[46, "explanation-2"]], "Exploratory Data Analysis": [[23, "exploratory-data-analysis"]], "Exploratory data analysis": [[25, "exploratory-data-analysis"], [44, "exploratory-data-analysis"]], "Extracting BOW features using scikit-learn": [[31, "extracting-bow-features-using-scikit-learn"]], "Extracting date and time information": [[44, "extracting-date-and-time-information"]], "F1-score": [[34, "f1-score"]], "Faster method: vectorize the loop over rows": [[8, "faster-method-vectorize-the-loop-over-rows"]], "Fastest method: broadcasting": [[8, "fastest-method-broadcasting"]], "Feature crosses for one-hot encoded features": [[38, "feature-crosses-for-one-hot-encoded-features"]], "Feature engineering": [[44, "feature-engineering"]], "Feature engineering and selection": [[50, "feature-engineering-and-selection"]], "Feature engineering for date/time columns": [[44, "feature-engineering-for-date-time-columns"]], "Feature engineering: Encoding date/time as feature(s)": [[44, "feature-engineering-encoding-date-time-as-feature-s"]], "Feature engineering: Motivation": [[38, "feature-engineering-motivation"]], "Feature importances": [[37, "feature-importances"], [50, "feature-importances"]], "Feature importances in linear models": [[37, "feature-importances-in-linear-models"], [37, "id2"]], "Feature interactions and feature crosses": [[38, "feature-interactions-and-feature-crosses"]], "Feature names of transformed data": [[35, "feature-names-of-transformed-data"]], "Feature selection: Introduction and motivation": [[38, "feature-selection-introduction-and-motivation"]], "Feature transformations and the golden rule": [[16, "feature-transformations-and-the-golden-rule"], [21, "feature-transformations-and-the-golden-rule"], [30, "feature-transformations-and-the-golden-rule"]], "Feature types": [[35, "feature-types"], [35, "id1"], [46, "feature-types"]], "Feature vectors": [[15, "feature-vectors"], [29, "feature-vectors"]], "Figures": [[7, "figures"]], "Filtering a dataframe with [] and df.query()": [[8, "filtering-a-dataframe-with-and-df-query"]], "Final comments and summary": [[33, "final-comments-and-summary"], [41, "final-comments-and-summary"]], "Final comments, summary, and reflection": [[13, "final-comments-summary-and-reflection"], [18, "final-comments-summary-and-reflection"], [27, "final-comments-summary-and-reflection"], [39, "final-comments-summary-and-reflection"], [40, "final-comments-summary-and-reflection"]], "Final exam": [[54, "final-exam"]], "Final exam preparation: guiding questions": [[50, null]], "Final note": [[52, "final-note"]], "Final remarks": [[44, "final-remarks"]], "Finding the distances to a query point": [[15, "finding-the-distances-to-a-query-point"], [20, "finding-the-distances-to-a-query-point"], [29, "finding-the-distances-to-a-query-point"]], "Finding the nearest neighbour": [[15, "finding-the-nearest-neighbour"], [20, "finding-the-nearest-neighbour"], [29, "finding-the-nearest-neighbour"]], "First deliverables": [[12, "first-deliverables"], [17, "first-deliverables"]], "Forecasting further into the future": [[44, "forecasting-further-into-the-future"]], "Forecasting further into the future on a retail dataset": [[44, "forecasting-further-into-the-future-on-a-retail-dataset"]], "Formulating the problem of recommender systems": [[41, "formulating-the-problem-of-recommender-systems"]], "GB better than RF": [[46, "gb-better-than-rf"]], "Garbage in, garbage out.": [[38, "garbage-in-garbage-out"]], "General advice on finding relevant features": [[38, "general-advice-on-finding-relevant-features"]], "General guidelines": [[6, "general-guidelines"]], "General idea": [[36, "general-idea"]], "General idea of k-nearest neighbours algorithm": [[15, "general-idea-of-k-nearest-neighbours-algorithm"], [20, "general-idea-of-k-nearest-neighbours-algorithm"], [29, "general-idea-of-k-nearest-neighbours-algorithm"]], "General idea of search and score methods": [[38, "general-idea-of-search-and-score-methods"]], "General questions": [[4, "general-questions"]], "Generalization [video]": [[14, "generalization-video"], [19, "generalization-video"], [28, "generalization-video"]], "Generalization: Fundamental goal of ML": [[14, "generalization-fundamental-goal-of-ml"], [19, "generalization-fundamental-goal-of-ml"], [28, "generalization-fundamental-goal-of-ml"]], "Generalizing to more features": [[32, "generalizing-to-more-features"]], "Generalizing to unseen data": [[14, "generalizing-to-unseen-data"], [19, "generalizing-to-unseen-data"], [28, "generalizing-to-unseen-data"]], "Geometric view of tabular data and dimensions": [[15, "geometric-view-of-tabular-data-and-dimensions"], [20, "geometric-view-of-tabular-data-and-dimensions"], [29, "geometric-view-of-tabular-data-and-dimensions"]], "Git": [[10, "git"]], "GitHub Desktop": [[5, "github-desktop"]], "Global average baseline": [[41, "global-average-baseline"]], "Golden rule violation: Example 1": [[14, "golden-rule-violation-example-1"], [28, "golden-rule-violation-example-1"]], "Golden rule violation: Example 2": [[14, "golden-rule-violation-example-2"], [28, "golden-rule-violation-example-2"]], "Grades": [[17, "grades"]], "Gradient boosted trees [video]": [[36, "gradient-boosted-trees-video"]], "Gradient boosting in sklearn": [[36, "gradient-boosting-in-sklearn"]], "Grading concerns: time limit": [[6, "grading-concerns-time-limit"]], "Grading scheme": [[54, "grading-scheme"]], "Grading-related questions": [[4, "grading-related-questions"]], "Handling imbalance": [[34, "handling-imbalance"]], "Here is the workflow we\u2019ll generally follow.": [[14, "here-is-the-workflow-we-ll-generally-follow"], [19, "here-is-the-workflow-we-ll-generally-follow"], [28, "here-is-the-workflow-we-ll-generally-follow"]], "Hierarchical clustering [video]": [[40, "hierarchical-clustering-video"]], "Homework info & submission guidelines": [[7, null]], "How are we making predictions?": [[32, "how-are-we-making-predictions"]], "How can we avoid violating golden rule?": [[14, "how-can-we-avoid-violating-golden-rule"], [19, "how-can-we-avoid-violating-golden-rule"], [28, "how-can-we-avoid-violating-golden-rule"]], "How can we get feature importances for non sklearn models?": [[37, "how-can-we-get-feature-importances-for-non-sklearn-models"]], "How do they work?": [[36, "how-do-they-work"]], "How do we carry out feature selection?": [[38, "how-do-we-carry-out-feature-selection"]], "How does fit work?": [[13, "how-does-fit-work"], [13, "id2"], [18, "how-does-fit-work"], [27, "how-does-fit-work"], [27, "id2"]], "How does it work?": [[40, "how-does-it-work"], [46, "how-does-it-work"]], "How does logistic regression calculate these probabilities?": [[32, "how-does-logistic-regression-calculate-these-probabilities"]], "How does predict work?": [[13, "how-does-predict-work"], [18, "how-does-predict-work"], [27, "how-does-predict-work"]], "How to approximate generalization error?": [[14, "how-to-approximate-generalization-error"], [19, "how-to-approximate-generalization-error"], [28, "how-to-approximate-generalization-error"]], "How to ask for help": [[4, null]], "How to carry out cross-validation?": [[16, "how-to-carry-out-cross-validation"], [21, "how-to-carry-out-cross-validation"], [30, "how-to-carry-out-cross-validation"]], "How to choose n_neighbors?": [[15, "how-to-choose-n-neighbors"], [20, "how-to-choose-n-neighbors"], [29, "how-to-choose-n-neighbors"]], "How to pick a model that would generalize better?": [[14, "how-to-pick-a-model-that-would-generalize-better"], [19, "how-to-pick-a-model-that-would-generalize-better"], [28, "how-to-pick-a-model-that-would-generalize-better"]], "How to submit": [[7, "how-to-submit"]], "How would you do it properly? Enter sklearn pipelines!!": [[25, "how-would-you-do-it-properly-enter-sklearn-pipelines"]], "Hyperparameter alpha of Ridge": [[32, "hyperparameter-alpha-of-ridge"]], "Hyperparameter optimization": [[23, "hyperparameter-optimization"], [50, "hyperparameter-optimization"]], "Hyperparameter optimization motivation": [[33, "hyperparameter-optimization-motivation"]], "Hyperparameter tuning for the number of clusters": [[39, "hyperparameter-tuning-for-the-number-of-clusters"]], "Hyperparameters of SVM": [[15, "hyperparameters-of-svm"], [20, "hyperparameters-of-svm"], [29, "hyperparameters-of-svm"]], "Hyperparameters: the problem": [[33, "hyperparameters-the-problem"]], "Identify the transformations we want to apply": [[31, "identify-the-transformations-we-want-to-apply"]], "Image classification using KNNs and SVM RBF": [[24, "image-classification-using-knns-and-svm-rbf"]], "ImageNet": [[43, "imagenet"]], "Import": [[48, "import"]], "Importance of scaling": [[32, "importance-of-scaling"]], "Important hyperparameters": [[36, "important-hyperparameters"]], "Important hyperparameters of CountVectorizer": [[31, "important-hyperparameters-of-countvectorizer"]], "Important links": [[1, "important-links"]], "Important points to remember": [[39, "important-points-to-remember"]], "Imports": [[12, "imports"], [13, "imports"], [14, "imports"], [15, "imports"], [15, "id1"], [16, "imports"], [17, "imports"], [18, "imports"], [19, "imports"], [20, "imports"], [21, "imports"], [23, "imports"], [24, "imports"], [25, "imports"], [26, "imports"], [27, "imports"], [28, "imports"], [29, "imports"], [30, "imports"], [31, "imports"], [32, "imports"], [33, "imports"], [34, "imports"], [35, "imports"], [36, "imports"], [37, "imports"], [38, "imports"], [39, "imports"], [40, "imports"], [41, "imports"], [42, "imports"], [43, "imports"], [44, "imports"], [45, "imports"], [46, "imports"], [47, "imports"], [50, "imports"], [51, "imports"], [52, "imports"]], "Imports and LO": [[33, "imports-and-lo"], [35, "imports-and-lo"], [43, "imports-and-lo"], [44, "imports-and-lo"]], "Imports and LOs": [[34, "imports-and-los"], [47, "imports-and-los"]], "Imports and learning outcomes": [[39, "imports-and-learning-outcomes"]], "Imports, Announcements, LOs": [[27, "imports-announcements-los"]], "Imports, Announcements, and LO": [[31, "imports-announcements-and-lo"], [32, "imports-announcements-and-lo"]], "Imports, LOs": [[14, "imports-los"], [16, "imports-los"], [19, "imports-los"], [21, "imports-los"], [28, "imports-los"], [30, "imports-los"], [37, "imports-los"]], "Imports, announcements, LOs": [[36, "imports-announcements-los"]], "Imports, announcements, and LOs": [[20, "imports-announcements-and-los"], [29, "imports-announcements-and-los"]], "Imputation": [[16, "imputation"], [21, "imputation"], [30, "imputation"]], "Imputation and scaling [video]": [[16, "imputation-and-scaling-video"], [21, "imputation-and-scaling-video"], [30, "imputation-and-scaling-video"]], "Incorporating ordinal feature class_attendance": [[31, "incorporating-ordinal-feature-class-attendance"]], "Incorporating text features": [[25, "incorporating-text-features"]], "Increasing the threshold": [[34, "increasing-the-threshold"]], "Indexing Dataframes": [[8, "indexing-dataframes"]], "Indexing cheatsheet": [[8, "indexing-cheatsheet"]], "Inertia": [[39, "inertia"]], "Initial analysis, EDA, preprocessing": [[47, "initial-analysis-eda-preprocessing"]], "Initialization of K-Means": [[39, "initialization-of-k-means"]], "Inject randomness in the classifier construction": [[36, "inject-randomness-in-the-classifier-construction"]], "Input data": [[12, "input-data"], [17, "input-data"], [26, "input-data"]], "Input features X and target y": [[12, "input-features-x-and-target-y"], [17, "input-features-x-and-target-y"], [26, "input-features-x-and-target-y"]], "Installing Python packages": [[10, "installing-python-packages"]], "Instructional Material": [[0, "instructional-material"]], "Instructors": [[1, "instructors"]], "Interesting to you != useful to the reader (aka it\u2019s not about you)": [[46, "interesting-to-you-useful-to-the-reader-aka-it-s-not-about-you"]], "Interim summary": [[34, "interim-summary"], [37, "interim-summary"], [38, "interim-summary"], [44, "interim-summary"]], "Interpretation of coefficients": [[32, "interpretation-of-coefficients"]], "Interpretation of coefficients in linear models": [[32, "interpretation-of-coefficients-in-linear-models"]], "Interpreting coefficients of numeric features": [[37, "interpreting-coefficients-of-numeric-features"]], "Introduction": [[40, "introduction"], [50, "introduction"]], "Introduction to NLP": [[50, "introduction-to-nlp"]], "Introduction to computer vision": [[43, "introduction-to-computer-vision"]], "Introduction to neural networks": [[43, "introduction-to-neural-networks"]], "Introduction to pandas": [[8, "introduction-to-pandas"]], "Introduction to unsupervised learning": [[39, "introduction-to-unsupervised-learning"]], "Is it possible to further improve the scores?": [[48, "is-it-possible-to-further-improve-the-scores"]], "Is stratifying a good idea?": [[34, "is-stratifying-a-good-idea"]], "Is this a realistic representation of text data?": [[31, "is-this-a-realistic-representation-of-text-data"]], "Is this misleading?": [[46, "is-this-misleading"]], "Is \u201cRelevance\u201d clearly defined?": [[38, "is-relevance-clearly-defined"], [38, "id2"], [38, "id3"], [38, "id4"], [38, "id5"], [38, "id6"], [38, "id7"]], "K-Means algorithm": [[39, "k-means-algorithm"]], "K-Means clustering [video]": [[39, "k-means-clustering-video"]], "K-Means example": [[39, "k-means-example"]], "K-Means limitations": [[40, "k-means-limitations"]], "K-Means limitations: Shape of K-Means clusters": [[40, "k-means-limitations-shape-of-k-means-clusters"]], "K-Means recap": [[40, "k-means-recap"]], "K-Means: failure case 1": [[40, "k-means-failure-case-1"]], "K-Means: failure case 2": [[40, "k-means-failure-case-2"]], "K-Means: failure case 3": [[40, "k-means-failure-case-3"]], "Kaplan-Meier survival curve": [[45, "kaplan-meier-survival-curve"]], "Key point": [[37, "key-point"]], "LDA topics in social media": [[42, "lda-topics-in-social-media"]], "LICENSE": [[0, null]], "Labeled vs. Unlabeled data": [[39, "labeled-vs-unlabeled-data"]], "Lag-based features": [[44, "lag-based-features"], [44, "id5"]], "Land acknowledgement": [[54, "land-acknowledgement"]], "Large datasets solve many of these problems": [[33, "large-datasets-solve-many-of-these-problems"]], "Late submissions": [[7, "late-submissions"]], "Learned coefficients associated with all features": [[32, "learned-coefficients-associated-with-all-features"]], "Learned model": [[23, "learned-model"]], "Learning git": [[5, "learning-git"]], "Learning objectives": [[42, "learning-objectives"], [43, "learning-objectives"], [44, "learning-objectives"], [45, "learning-objectives"], [46, "learning-objectives"], [47, "learning-objectives"]], "Learning outcomes": [[12, "learning-outcomes"], [13, "learning-outcomes"], [14, "learning-outcomes"], [15, "learning-outcomes"], [16, "learning-outcomes"], [17, "learning-outcomes"], [18, "learning-outcomes"], [19, "learning-outcomes"], [20, "learning-outcomes"], [21, "learning-outcomes"], [26, "learning-outcomes"], [27, "learning-outcomes"], [28, "learning-outcomes"], [29, "learning-outcomes"], [30, "learning-outcomes"], [31, "learning-outcomes"], [32, "learning-outcomes"], [33, "learning-outcomes"], [34, "learning-outcomes"], [35, "learning-outcomes"], [37, "learning-outcomes"], [38, "learning-outcomes"], [39, "learning-outcomes"], [40, "learning-outcomes"]], "Learning outcomes <a name=\"lo\"></a>": [[41, "learning-outcomes"]], "Least confident cases": [[32, "least-confident-cases"]], "Lecture 10: Regression metrics": [[35, null]], "Lecture 12: Ensembles": [[36, null]], "Lecture 13: Feature importances and model transparency": [[37, null]], "Lecture 14: Feature engineering and feature selection": [[38, null]], "Lecture 15: K-Means Clustering": [[39, null]], "Lecture 16: More Clustering": [[40, null]], "Lecture 17: Recommender Systems": [[41, null]], "Lecture 18: Introduction to natural language processing": [[42, null]], "Lecture 19: Multi-class classification and introduction to computer vision": [[43, null]], "Lecture 1: Course Introduction": [[12, null], [17, null], [26, null]], "Lecture 20: Time series": [[44, null]], "Lecture 21: Survival analysis": [[45, null]], "Lecture 22: Communication": [[46, null]], "Lecture 24: Deployment and conclusion": [[47, null]], "Lecture 2: Terminology, Baselines, Decision Trees": [[13, null], [18, null], [27, null]], "Lecture 3: ML Fundamentals Class Demo": [[23, null]], "Lecture 3: Machine Learning Fundamentals": [[14, null], [19, null], [28, null]], "Lecture 4: Class demo": [[24, null]], "Lecture 4: k-Nearest Neighbours and SVM RBFs": [[15, null], [20, null], [29, null]], "Lecture 5 and 6: Class demo": [[25, null]], "Lecture 5: Preprocessing and sklearn pipelines": [[16, null], [21, null], [30, null]], "Lecture 6: sklearn ColumnTransformer and Text Features": [[31, null]], "Lecture 7: Linear Models": [[32, null]], "Lecture 8: Hyperparameter Optimization and Optimization Bias": [[33, null]], "Lecture 9: Classification metrics": [[34, null]], "Lecture and homework format: Jupyter notebooks": [[12, "lecture-and-homework-format-jupyter-notebooks"], [17, "lecture-and-homework-format-jupyter-notebooks"]], "Lecture learning objectives": [[36, "lecture-learning-objectives"]], "Lecture plan and learning outcomes": [[40, "lecture-plan-and-learning-outcomes"]], "Lecture recordings": [[54, "lecture-recordings"]], "Lecture schedule (tentative)": [[1, "lecture-schedule-tentative"]], "Lecture style": [[12, "lecture-style"], [17, "lecture-style"]], "Let\u2019s do it on our housing data": [[16, "let-s-do-it-on-our-housing-data"], [21, "let-s-do-it-on-our-housing-data"], [30, "let-s-do-it-on-our-housing-data"]], "Let\u2019s examine the transformed data": [[31, "let-s-examine-the-transformed-data"]], "Let\u2019s explore SVM RBFs": [[15, "let-s-explore-svm-rbfs"], [20, "let-s-explore-svm-rbfs"], [29, "let-s-explore-svm-rbfs"]], "Let\u2019s first run our baseline model DummyRegressor": [[16, "let-s-first-run-our-baseline-model-dummyregressor"], [21, "let-s-first-run-our-baseline-model-dummyregressor"], [30, "let-s-first-run-our-baseline-model-dummyregressor"]], "Let\u2019s identify feature types": [[37, "let-s-identify-feature-types"]], "Let\u2019s look at all the scores at once": [[34, "let-s-look-at-all-the-scores-at-once"]], "Let\u2019s separate X and y": [[35, "let-s-separate-x-and-y"], [37, "let-s-separate-x-and-y"], [46, "let-s-separate-x-and-y"]], "Let\u2019s try KNN on this data": [[25, "let-s-try-knn-on-this-data"]], "Let\u2019s try a linear model: Ridge": [[35, "let-s-try-a-linear-model-ridge"]], "Let\u2019s try cross-validation with our pipeline": [[16, "let-s-try-cross-validation-with-our-pipeline"], [21, "let-s-try-cross-validation-with-our-pipeline"], [30, "let-s-try-cross-validation-with-our-pipeline"]], "License": [[1, "license"]], "LightGBM": [[36, "lightgbm"]], "Limitations of linear models": [[32, "limitations-of-linear-models"]], "Linear SVM": [[32, "linear-svm"]], "Linear models [video]": [[32, "linear-models-video"]], "Linear regression": [[32, "linear-regression"]], "Lists of resources": [[9, "lists-of-resources"]], "Loading our saved model": [[47, "loading-our-saved-model"]], "Logistic regression [video]": [[32, "logistic-regression-video"]], "Logistic regression intuition": [[32, "logistic-regression-intuition"]], "Logistic regression on the cities data": [[32, "logistic-regression-on-the-cities-data"]], "Logistic regression with flattened representation of images": [[43, "logistic-regression-with-flattened-representation-of-images"]], "LogisticRegression": [[44, "logisticregression"], [45, "logisticregression"]], "MAPE": [[35, "mape"]], "ML and decision-making (5 min)": [[46, "ml-and-decision-making-5-min"]], "ML fairness activity (~5 mins)": [[34, "ml-fairness-activity-5-mins"]], "ML fundamentals": [[50, "ml-fundamentals"]], "Mac Users": [[5, "mac-users"]], "Machine learning workflow": [[12, "machine-learning-workflow"], [26, "machine-learning-workflow"], [34, "machine-learning-workflow"]], "Magnitude of the coefficients": [[32, "magnitude-of-the-coefficients"]], "Main hyperparameter of logistic regression": [[32, "main-hyperparameter-of-logistic-regression"]], "Main hyperparameters": [[32, "main-hyperparameters"]], "Main issues in ML-related communication": [[46, "main-issues-in-ml-related-communication"]], "Manual hyperparameter optimization": [[33, "manual-hyperparameter-optimization"]], "Mean intra-cluster distance (a)": [[39, "mean-intra-cluster-distance-a"]], "Mean nearest-cluster distance (b)": [[39, "mean-nearest-cluster-distance-b"]], "Mean squared error (MSE)": [[35, "mean-squared-error-mse"]], "Meet Eva (a fictitious persona)!": [[12, "meet-eva-a-fictitious-persona"], [17, "meet-eva-a-fictitious-persona"], [26, "meet-eva-a-fictitious-persona"]], "Method 1: The Elbow method": [[39, "method-1-the-elbow-method"]], "Method 2: The Silhouette method": [[39, "method-2-the-silhouette-method"]], "Midterms": [[54, "midterms"]], "Misc": [[1, "misc"], [9, "misc"]], "Miscellaneous comments on content-based filtering": [[41, "miscellaneous-comments-on-content-based-filtering"]], "Model building": [[35, "model-building"], [47, "model-building"]], "Model complexity and training error": [[14, "model-complexity-and-training-error"], [19, "model-complexity-and-training-error"], [28, "model-complexity-and-training-error"]], "Model deployment": [[47, "model-deployment"], [47, "id1"]], "Model interpretability beyond linear models": [[37, "model-interpretability-beyond-linear-models"]], "Model predictions on unseen data": [[12, "model-predictions-on-unseen-data"], [17, "model-predictions-on-unseen-data"], [26, "model-predictions-on-unseen-data"]], "Model transparency and interpretation": [[47, "model-transparency-and-interpretation"]], "Model-based selection": [[38, "model-based-selection"]], "Modeling": [[25, "modeling"]], "More comments on tackling class imbalance": [[35, "more-comments-on-tackling-class-imbalance"]], "More details": [[19, "more-details"]], "More details on DBSCAN": [[40, "more-details-on-dbscan"]], "More on feature transformations": [[31, "more-on-feature-transformations"]], "More on k-NNs [video]": [[15, "more-on-k-nns-video"], [20, "more-on-k-nns-video"], [29, "more-on-k-nns-video"]], "More terminology [video]": [[13, "more-terminology-video"], [18, "more-terminology-video"], [27, "more-terminology-video"]], "More than one ordinal columns?": [[31, "more-than-one-ordinal-columns"]], "Most confident cases": [[32, "most-confident-cases"]], "Motivating example": [[32, "motivating-example"]], "Motivation": [[33, "motivation"], [44, "motivation"], [46, "motivation"]], "Motivation [video]": [[36, "motivation-video"]], "Motivation and big picture [video]": [[16, "motivation-and-big-picture-video"], [21, "motivation-and-big-picture-video"], [30, "motivation-and-big-picture-video"]], "Motivation and context": [[42, "motivation-and-context"]], "Motivation and distances [video]": [[15, "motivation-and-distances-video"], [20, "motivation-and-distances-video"], [29, "motivation-and-distances-video"]], "Movie features": [[41, "movie-features"]], "Multi-class classification": [[43, "multi-class-classification"]], "Multiclass classification and computer vision": [[50, "multiclass-classification-and-computer-vision"]], "Multiple transformations in a transformer": [[31, "multiple-transformations-in-a-transformer"]], "NOTE:": [[8, "note"]], "New ideas in small chunks": [[46, "new-ideas-in-small-chunks"]], "No-loop method: make them the same size, and multiply element-wise": [[8, "no-loop-method-make-them-the-same-size-and-multiply-element-wise"]], "Note": [[14, null], [14, null], [28, null], [28, null], [44, null]], "Number of trees and fundamental trade-off": [[36, "number-of-trees-and-fundamental-trade-off"]], "Numpy array shapes": [[8, "numpy-array-shapes"]], "Numpy arrays": [[8, "numpy-arrays"]], "OHE with many categories": [[31, "ohe-with-many-categories"]], "Object detection": [[43, "object-detection"]], "Observations": [[34, "observations"]], "One Vs. One approach": [[49, "one-vs-one-approach"]], "One Vs. One prediction": [[49, "one-vs-one-prediction"]], "One vs. Rest": [[49, "one-vs-rest"]], "One-hot encoding (OHE)": [[16, "one-hot-encoding-ohe"], [21, "one-hot-encoding-ohe"], [30, "one-hot-encoding-ohe"]], "One-hot encoding of the month": [[44, "one-hot-encoding-of-the-month"]], "One-hot encoding seasons": [[44, "one-hot-encoding-seasons"]], "OneHotEncoder and sparse features": [[31, "onehotencoder-and-sparse-features"]], "Online courses": [[1, "online-courses"], [9, "online-courses"]], "Operating point": [[34, "operating-point"]], "Optimization bias of hyper-parameter learning": [[33, "optimization-bias-of-hyper-parameter-learning"]], "Optimization bias of parameter learning": [[33, "optimization-bias-of-parameter-learning"]], "Optimization bias on the Spotify dataset": [[33, "optimization-bias-on-the-spotify-dataset"]], "Optimization bias/Overfitting of the validation set": [[33, "optimization-bias-overfitting-of-the-validation-set"]], "Optional readings and resources": [[33, "optional-readings-and-resources"]], "Ordinal encoding (occasionally recommended)": [[16, "ordinal-encoding-occasionally-recommended"], [21, "ordinal-encoding-occasionally-recommended"], [30, "ordinal-encoding-occasionally-recommended"]], "Ordinal features": [[25, "ordinal-features"], [37, "ordinal-features"]], "Other applications": [[39, "other-applications"]], "Other approaches / what did we not cover?": [[45, "other-approaches-what-did-we-not-cover"]], "Other commonly used preprocessing steps": [[42, "other-commonly-used-preprocessing-steps"]], "Other possible preprocessing?": [[35, "other-possible-preprocessing"]], "Other software package": [[44, "other-software-package"]], "Other tools for preprocessing": [[42, "other-tools-for-preprocessing"]], "Other typical NLP tasks": [[42, "other-typical-nlp-tasks"]], "Other useful arguments of KNeighborsClassifier": [[15, "other-useful-arguments-of-kneighborsclassifier"], [20, "other-useful-arguments-of-kneighborsclassifier"], [29, "other-useful-arguments-of-kneighborsclassifier"]], "Other ways to search": [[38, "other-ways-to-search"]], "Our typical supervised learning set up is as follows:": [[14, "our-typical-supervised-learning-set-up-is-as-follows"], [19, "our-typical-supervised-learning-set-up-is-as-follows"], [28, "our-typical-supervised-learning-set-up-is-as-follows"]], "Outline": [[51, "outline"], [52, "outline"], [53, "outline"]], "Over confident cases": [[32, "over-confident-cases"]], "Overfitting": [[14, "overfitting"], [19, "overfitting"], [28, "overfitting"]], "Overfitting of the validation data": [[33, "overfitting-of-the-validation-data"]], "Overfitting of the validation error": [[33, "overfitting-of-the-validation-error"]], "Oversampling": [[34, "oversampling"]], "Overview": [[15, "overview"], [20, "overview"], [29, "overview"]], "POSIX time feature": [[44, "posix-time-feature"]], "PR curves for logistic regression and SVC": [[34, "pr-curves-for-logistic-regression-and-svc"]], "Pandas DataFrames": [[8, "pandas-dataframes"]], "Pandas Series": [[8, "pandas-series"]], "Parameters": [[13, "parameters"], [18, "parameters"], [27, "parameters"]], "Parameters and hyperparameters: Summary": [[13, "parameters-and-hyperparameters-summary"], [18, "parameters-and-hyperparameters-summary"], [27, "parameters-and-hyperparameters-summary"]], "Parsing datetimes": [[44, "parsing-datetimes"]], "Part 1": [[50, "part-1"]], "Part 2": [[50, "part-2"]], "Piazza-specific Q&A guidelines": [[4, "piazza-specific-q-a-guidelines"]], "Pipelines": [[16, "pipelines"], [21, "pipelines"], [30, "pipelines"]], "Playground": [[15, "playground"], [29, "playground"]], "Playground (in tutorial)": [[20, "playground-in-tutorial"]], "Plotting with matplotlib": [[8, "plotting-with-matplotlib"]], "Practice exercises": [[18, "practice-exercises"], [27, "practice-exercises"]], "Precision": [[34, "precision"]], "Precision and recall: toy example": [[34, "precision-and-recall-toy-example"]], "Precision, recall, f1 score": [[34, "precision-recall-f1-score"]], "Precision-recall curve": [[34, "precision-recall-curve"], [34, "id1"]], "Precision/Recall tradeoff": [[34, "precision-recall-tradeoff"]], "Predicting on unseen data using the trained model": [[12, "predicting-on-unseen-data-using-the-trained-model"], [17, "predicting-on-unseen-data-using-the-trained-model"], [26, "predicting-on-unseen-data-using-the-trained-model"]], "Predicting probability scores [video]": [[32, "predicting-probability-scores-video"]], "Predicting with learned weights": [[32, "predicting-with-learned-weights"]], "Prediction": [[45, "prediction"]], "Prediction of linear regression": [[32, "prediction-of-linear-regression"]], "Prediction with learned parameters": [[32, "prediction-with-learned-parameters"]], "Predictions": [[43, "predictions"]], "Preferences in LogisticRegression": [[46, "preferences-in-logisticregression"]], "Preparation": [[7, "preparation"]], "Preprocessing": [[31, "preprocessing"], [44, "preprocessing"], [50, "preprocessing"]], "Preprocessing the targets?": [[31, "preprocessing-the-targets"]], "Prevalence of ML": [[12, "prevalence-of-ml"], [17, "prevalence-of-ml"], [26, "prevalence-of-ml"]], "Principles of effective communication": [[46, "principles-of-effective-communication"]], "Principles of good explanations (~15 min)": [[46, "principles-of-good-explanations-15-min"]], "Problem formulation": [[41, "problem-formulation"]], "Problem: Different transformations on different columns": [[16, "problem-different-transformations-on-different-columns"], [21, "problem-different-transformations-on-different-columns"], [30, "problem-different-transformations-on-different-columns"]], "Problems with exhaustive grid search": [[33, "problems-with-exhaustive-grid-search"]], "Problems with single train/validation split": [[14, "problems-with-single-train-validation-split"], [19, "problems-with-single-train-validation-split"], [28, "problems-with-single-train-validation-split"]], "Pros of k-NNs for supervised learning": [[15, "pros-of-k-nns-for-supervised-learning"], [20, "pros-of-k-nns-for-supervised-learning"], [29, "pros-of-k-nns-for-supervised-learning"]], "Pros, cons, parameters and hyperparameters of different ML models": [[50, "pros-cons-parameters-and-hyperparameters-of-different-ml-models"]], "Python and Conda": [[10, "python-and-conda"]], "Python requirements/resources": [[12, "python-requirements-resources"], [17, "python-requirements-resources"]], "Python resources": [[9, "python-resources"]], "Question": [[15, "question"], [20, "question"], [29, "question"]], "Question for you": [[40, "question-for-you"]], "Questions for class discussion": [[41, "questions-for-class-discussion"]], "Questions for class discussion (hyperparameter optimization)": [[33, "questions-for-class-discussion-hyperparameter-optimization"]], "Quick recap": [[15, "quick-recap"], [29, "quick-recap"]], "RF better than GB": [[46, "rf-better-than-gb"]], "RFE algorithm": [[38, "rfe-algorithm"]], "R^2 (not in detail)": [[35, "r-2-not-in-detail"]], "Random forest feature importances": [[37, "random-forest-feature-importances"]], "Random forests": [[36, "random-forests"]], "Random forests: number of trees (n_estimators) and the fundamental tradeoff": [[36, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"]], "RandomForestClassifier": [[36, "randomforestclassifier"], [45, "randomforestclassifier"]], "Randomized hyperparameter search": [[33, "randomized-hyperparameter-search"]], "Range of C": [[33, "range-of-c"]], "Raw scores": [[32, "raw-scores"]], "Reading from .csv": [[8, "reading-from-csv"]], "Reading from other formats": [[8, "reading-from-other-formats"]], "Reading from url": [[8, "reading-from-url"]], "Reading the data": [[13, "reading-the-data"], [18, "reading-the-data"], [27, "reading-the-data"], [43, "reading-the-data"]], "Real boundary between Canada and USA": [[13, "real-boundary-between-canada-and-usa"], [27, "real-boundary-between-canada-and-usa"], [51, "real-boundary-between-canada-and-usa"]], "Reasonable grading concerns": [[6, "reasonable-grading-concerns"]], "Recall": [[34, "recall"]], "Recap": [[45, "recap"], [46, "recap"]], "Recap and motivation [video]": [[40, "recap-and-motivation-video"]], "Recap: Supervised machine learning": [[13, "recap-supervised-machine-learning"], [18, "recap-supervised-machine-learning"], [27, "recap-supervised-machine-learning"]], "Receiver Operating Characteristic (ROC) curve": [[34, "receiver-operating-characteristic-roc-curve"]], "Recipe to approach a supervised learning problem with tabular data": [[47, "recipe-to-approach-a-supervised-learning-problem-with-tabular-data"]], "Recommended browser": [[12, "recommended-browser"], [17, "recommended-browser"]], "Recommender systems": [[50, "recommender-systems"]], "Recommender systems intro and motivation": [[41, "recommender-systems-intro-and-motivation"]], "Recommender systems problem": [[41, "recommender-systems-problem"]], "Recursive feature elimination (RFE)": [[38, "recursive-feature-elimination-rfe"]], "Reference Material": [[1, "reference-material"]], "Reference material": [[9, null]], "References": [[45, "references"]], "Registration": [[54, "registration"]], "Registration, waitlist and prerequisites": [[12, "registration-waitlist-and-prerequisites"], [17, "registration-waitlist-and-prerequisites"]], "Regression scoring functions": [[35, "regression-scoring-functions"]], "Regression with k-nearest neighbours (k-NNs)": [[15, "regression-with-k-nearest-neighbours-k-nns"], [20, "regression-with-k-nearest-neighbours-k-nns"], [29, "regression-with-k-nearest-neighbours-k-nns"]], "Relation of C and the fundamental trade-off": [[15, "relation-of-c-and-the-fundamental-trade-off"], [20, "relation-of-c-and-the-fundamental-trade-off"], [29, "relation-of-c-and-the-fundamental-trade-off"]], "Relation of gamma and the fundamental trade-off": [[15, "relation-of-gamma-and-the-fundamental-trade-off"], [20, "relation-of-gamma-and-the-fundamental-trade-off"], [29, "relation-of-gamma-and-the-fundamental-trade-off"]], "Relevant companion materials": [[9, "relevant-companion-materials"]], "Relevant papers": [[36, "relevant-papers"]], "Relevant papers and resources": [[34, "relevant-papers-and-resources"]], "Relevant resources": [[38, "relevant-resources"]], "Reminder": [[41, "reminder"]], "Renaming columns with df.rename()": [[8, "renaming-columns-with-df-rename"]], "Render set-up (I already did these):": [[47, "render-set-up-i-already-did-these"]], "Report format": [[7, "report-format"]], "Requirements (I already did these)": [[47, "requirements-i-already-did-these"]], "Resources": [[39, "resources"], [40, "resources"], [41, "resources"]], "Reuse your running examples": [[46, "reuse-your-running-examples"]], "Ridge": [[32, "ridge"]], "Ridge on the California housing dataset": [[32, "ridge-on-the-california-housing-dataset"]], "RidgeCV": [[35, "ridgecv"]], "Root mean squared error or RMSE": [[35, "root-mean-squared-error-or-rmse"]], "SHAP  (SHapley Additive exPlanations) introduction": [[37, "shap-shapley-additive-explanations-introduction"]], "SHAP plots": [[37, "shap-plots"]], "SMOTE idea": [[34, "smote-idea"]], "SMOTE: Synthetic Minority Over-sampling Technique": [[34, "smote-synthetic-minority-over-sampling-technique"]], "SVM Regressor": [[15, "svm-regressor"], [20, "svm-regressor"], [29, "svm-regressor"]], "Saving the model": [[47, "saving-the-model"]], "Saving time and scaling products": [[12, "saving-time-and-scaling-products"], [17, "saving-time-and-scaling-products"], [26, "saving-time-and-scaling-products"]], "Scaling": [[16, "scaling"], [21, "scaling"], [30, "scaling"]], "Scaling using scikit-learn\u2019s StandardScaler": [[16, "scaling-using-scikit-learn-s-standardscaler"], [21, "scaling-using-scikit-learn-s-standardscaler"], [30, "scaling-using-scikit-learn-s-standardscaler"]], "Search over multiple hyperparameters": [[15, "search-over-multiple-hyperparameters"], [20, "search-over-multiple-hyperparameters"], [29, "search-over-multiple-hyperparameters"]], "Seasonality and trends": [[44, "seasonality-and-trends"]], "Select all of the following statements which are True (iClicker)": [[12, "select-all-of-the-following-statements-which-are-true-iclicker"], [17, "select-all-of-the-following-statements-which-are-true-iclicker"], [26, "select-all-of-the-following-statements-which-are-true-iclicker"]], "Sending a request to the API": [[47, "sending-a-request-to-the-api"]], "Setting up": [[5, "setting-up"]], "Setting up a virtual environment: Conda environments": [[10, "setting-up-a-virtual-environment-conda-environments"]], "Setting up coding environment": [[10, null]], "Setting up your computer for the course": [[12, "setting-up-your-computer-for-the-course"], [17, "setting-up-your-computer-for-the-course"]], "Short posts/articles": [[9, "short-posts-articles"]], "Sigmoid vs. Softmax": [[43, "sigmoid-vs-softmax"]], "Sign of the coefficients": [[32, "sign-of-the-coefficients"]], "Silhouette distance for a sample": [[39, "silhouette-distance-for-a-sample"]], "Similarity between examples": [[15, "similarity-between-examples"], [20, "similarity-between-examples"], [29, "similarity-between-examples"]], "Simple feature engineering for our problem.": [[48, "simple-feature-engineering-for-our-problem"]], "Simple train/test split": [[14, "simple-train-test-split"], [19, "simple-train-test-split"], [28, "simple-train-test-split"]], "SimpleFeature correlations": [[37, "simplefeature-correlations"]], "Single validation set": [[23, "single-validation-set"]], "Slowest method: nested loop": [[8, "slowest-method-nested-loop"]], "Software": [[0, "software"]], "Some important hyperparameters:": [[36, "some-important-hyperparameters"]], "Some key takeaways": [[47, "some-key-takeaways"]], "Some quotes on feature engineering": [[38, "some-quotes-on-feature-engineering"]], "Some terminology related to trees": [[13, "some-terminology-related-to-trees"], [18, "some-terminology-related-to-trees"], [27, "some-terminology-related-to-trees"]], "Some ways to pick hyperparameters:": [[33, "some-ways-to-pick-hyperparameters"]], "Sorting a dataframe with df.sort_values()": [[8, "sorting-a-dataframe-with-df-sort-values"]], "Spam/non spam toy example": [[31, "spam-non-spam-toy-example"]], "Specific questions": [[4, "specific-questions"]], "Stacking": [[36, "stacking"]], "Step 1": [[53, "step-1"]], "Step 2": [[53, "step-2"]], "Step 3": [[53, "step-3"]], "Step 4": [[53, "step-4"]], "Step 5": [[53, "step-5"]], "Steps to train a classifier using sklearn": [[13, "steps-to-train-a-classifier-using-sklearn"], [18, "steps-to-train-a-classifier-using-sklearn"], [27, "steps-to-train-a-classifier-using-sklearn"]], "Stratified Splits": [[34, "stratified-splits"]], "Strengths and weaknesses": [[36, "strengths-and-weaknesses"]], "Strengths of linear models": [[32, "strengths-of-linear-models"]], "Study tips": [[50, "study-tips"]], "Submitting on Gradescope": [[7, "submitting-on-gradescope"]], "Summary": [[12, "summary"], [15, "summary"], [17, "summary"], [20, "summary"], [26, "summary"], [29, "summary"], [36, "summary"], [42, "summary"], [43, "summary"], [45, "summary"]], "Summary and reflection": [[14, "summary-and-reflection"], [19, "summary-and-reflection"], [28, "summary-and-reflection"]], "Summary of linear models": [[32, "summary-of-linear-models"]], "Summary of train, validation, test, and deployment data": [[14, "summary-of-train-validation-test-and-deployment-data"], [19, "summary-of-train-validation-test-and-deployment-data"], [28, "summary-of-train-validation-test-and-deployment-data"]], "Summary: Pros and cons": [[40, "summary-pros-and-cons"]], "Supervised approach to rating prediction": [[41, "supervised-approach-to-rating-prediction"]], "Supervised learning": [[39, "supervised-learning"]], "Supervised learning (Reminder)": [[13, "supervised-learning-reminder"], [27, "supervised-learning-reminder"]], "Supervised learning vs. Unsupervised learning": [[13, "supervised-learning-vs-unsupervised-learning"], [18, "supervised-learning-vs-unsupervised-learning"], [27, "supervised-learning-vs-unsupervised-learning"]], "Supervised machine learning": [[12, "supervised-machine-learning"], [17, "supervised-machine-learning"], [26, "supervised-machine-learning"]], "Support Vector Machines (SVMs) with RBF kernel [video]": [[15, "support-vector-machines-svms-with-rbf-kernel-video"], [20, "support-vector-machines-svms-with-rbf-kernel-video"], [29, "support-vector-machines-svms-with-rbf-kernel-video"]], "Support vectors": [[15, "support-vectors"], [20, "support-vectors"], [29, "support-vectors"]], "Survival analysis": [[50, "survival-analysis"]], "Survival plots": [[45, "survival-plots"]], "Syllabus": [[1, "syllabus"], [54, null]], "TAs": [[1, "tas"], [54, "tas"]], "Tabular data": [[13, "tabular-data"], [18, "tabular-data"], [27, "tabular-data"]], "Take-home message": [[40, "take-home-message"]], "Teaching Team": [[54, "teaching-team"]], "Terminology": [[43, "terminology"]], "Terminology [video]": [[13, "terminology-video"], [18, "terminology-video"], [27, "terminology-video"]], "Testing your git installation": [[5, "testing-your-git-installation"]], "The Netflix prize": [[36, "the-netflix-prize"]], "The __ syntax": [[33, "the-syntax"]], "The best features may be dependent on the model you use.": [[38, "the-best-features-may-be-dependent-on-the-model-you-use"]], "The golden rule <a name=\"4\"></a>": [[14, "the-golden-rule"], [19, "the-golden-rule"], [28, "the-golden-rule"]], "The random forests classifier": [[36, "the-random-forests-classifier"]], "The sigmoid function": [[32, "the-sigmoid-function"]], "The teaching team": [[1, "the-teaching-team"]], "The \u201cfundamental tradeoff\u201d of supervised learning:": [[14, "the-fundamental-tradeoff-of-supervised-learning"], [19, "the-fundamental-tradeoff-of-supervised-learning"], [28, "the-fundamental-tradeoff-of-supervised-learning"]], "The \u201cperfect\u201d spaghetti sauce": [[39, "the-perfect-spaghetti-sauce"]], "Things to watch out for": [[46, "things-to-watch-out-for"]], "Time series": [[50, "time-series"]], "Time to event and censoring": [[45, "time-to-event-and-censoring"]], "Tokenization": [[42, "tokenization"]], "Topic modeling": [[42, "topic-modeling"]], "Topic modeling motivation": [[42, "topic-modeling-motivation"]], "Topic modeling pipeline": [[42, "topic-modeling-pipeline"]], "Topic modeling toy example": [[42, "topic-modeling-toy-example"]], "Toy datasets": [[13, "toy-datasets"], [27, "toy-datasets"]], "Traditional time series approaches": [[44, "traditional-time-series-approaches"]], "Train/test split for temporal data": [[44, "train-test-split-for-temporal-data"]], "Train/test splits": [[44, "train-test-splits"]], "Train/validation/test split": [[14, "train-validation-test-split"], [19, "train-validation-test-split"], [28, "train-validation-test-split"]], "Training a supervised machine learning model with X and y": [[12, "training-a-supervised-machine-learning-model-with-x-and-y"], [17, "training-a-supervised-machine-learning-model-with-x-and-y"], [26, "training-a-supervised-machine-learning-model-with-x-and-y"]], "Training data for the motivating example": [[32, "training-data-for-the-motivating-example"]], "Training error vs. Generalization error": [[14, "training-error-vs-generalization-error"], [19, "training-error-vs-generalization-error"], [28, "training-error-vs-generalization-error"]], "Training models with transformed data": [[31, "training-models-with-transformed-data"]], "Training on the full corpus": [[47, "training-on-the-full-corpus"]], "Training random forests and gradient boosted trees": [[46, "training-random-forests-and-gradient-boosted-trees"]], "Transfer learning": [[43, "transfer-learning"]], "Transformations on the toy data": [[31, "transformations-on-the-toy-data"]], "Transforming the targets": [[35, "transforming-the-targets"]], "Transparency and explainability of ML models: Motivation": [[37, "transparency-and-explainability-of-ml-models-motivation"]], "Tree-based ensemble models": [[36, "tree-based-ensemble-models"]], "Tree-based models": [[36, "tree-based-models"]], "Try out this moment predictor": [[47, "try-out-this-moment-predictor"]], "Tuning alpha hyperparameter of Ridge": [[35, "tuning-alpha-hyperparameter-of-ridge"]], "Tutorial 1": [[51, null]], "Tutorial 2": [[52, null]], "Tutorial 3": [[53, null]], "Types of censoring": [[45, "types-of-censoring"]], "Types of errors": [[14, "types-of-errors"], [19, "types-of-errors"], [28, "types-of-errors"]], "Types of machine learning": [[12, "types-of-machine-learning"], [17, "types-of-machine-learning"], [26, "types-of-machine-learning"], [39, "types-of-machine-learning"]], "Types of problems involving time series": [[44, "types-of-problems-involving-time-series"]], "Types of questions we might want to answer:": [[45, "types-of-questions-we-might-want-to-answer"]], "Typical steps to build a supervised machine learning model": [[23, "typical-steps-to-build-a-supervised-machine-learning-model"]], "UBC CPSC 330: Applied Machine Learning (2024W2)": [[1, null]], "Ubuntu Users": [[5, "ubuntu-users"]], "Underfitting": [[14, "underfitting"], [19, "underfitting"], [28, "underfitting"]], "Underfitting, overfitting, the fundamental trade-off, the golden rule [video]": [[14, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"], [19, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"], [28, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"]], "Undersampling": [[34, "undersampling"]], "Understanding the problem": [[47, "understanding-the-problem"]], "Unequally spaced time points": [[44, "unequally-spaced-time-points"]], "Unsupervised learning": [[39, "unsupervised-learning"]], "Updates to assignments": [[7, "updates-to-assignments"]], "Use of AI in the course": [[54, "use-of-ai-in-the-course"]], "Use our template to create a repository": [[7, "use-our-template-to-create-a-repository"]], "Using OVR and OVO as wrappers": [[49, "using-ovr-and-ovo-as-wrappers"]], "Using SMOTE": [[34, "using-smote"]], "Using Silhouette scores to select the number of clusters": [[39, "using-silhouette-scores-to-select-the-number-of-clusters"]], "Using multiple metrics in GridSearchCV or RandomizedSearchCV": [[35, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"]], "Using pre-trained models as feature extractor": [[43, "using-pre-trained-models-as-feature-extractor"]], "Using pre-trained models out-of-the-box": [[43, "using-pre-trained-models-out-of-the-box"]], "Using regression metrics with scikit-learn": [[35, "using-regression-metrics-with-scikit-learn"]], "Viewing the transformed data as a dataframe": [[31, "viewing-the-transformed-data-as-a-dataframe"]], "Virtual environment": [[10, "virtual-environment"]], "Visualization": [[9, "visualization"]], "Visualizing the parameter grid as a heatmap": [[33, "visualizing-the-parameter-grid-as-a-heatmap"]], "Visualizing your results": [[46, "visualizing-your-results"]], "Warning": [[13, null], [18, null], [27, null]], "Warnings about feature selection": [[38, "warnings-about-feature-selection"], [38, "id8"]], "Weaknesses": [[36, "weaknesses"]], "Web app on a real server": [[47, "web-app-on-a-real-server"]], "Web app on local server": [[47, "web-app-on-local-server"]], "What all transformations we need to apply on the dataset?": [[16, "what-all-transformations-we-need-to-apply-on-the-dataset"], [30, "what-all-transformations-we-need-to-apply-on-the-dataset"]], "What and Why": [[10, "what-and-why"]], "What are git and GitHub?": [[5, null]], "What are the options?": [[16, "what-are-the-options"], [21, "what-are-the-options"], [30, "what-are-the-options"]], "What are we exactly learning?": [[32, "what-are-we-exactly-learning"]], "What did we cover?": [[41, "what-did-we-cover"], [47, "what-did-we-cover"]], "What did we learn today?": [[14, "what-did-we-learn-today"], [16, "what-did-we-learn-today"], [19, "what-did-we-learn-today"], [21, "what-did-we-learn-today"], [28, "what-did-we-learn-today"], [30, "what-did-we-learn-today"], [31, "what-did-we-learn-today"], [34, "what-did-we-learn-today"], [35, "what-did-we-learn-today"], [46, "what-did-we-learn-today"]], "What does this have to do with applied ML?": [[46, "what-does-this-have-to-do-with-applied-ml"]], "What does this mean for us, when we\u2019re trying to make claims about our data?": [[46, "what-does-this-mean-for-us-when-we-re-trying-to-make-claims-about-our-data"]], "What if we apply OHE?": [[31, "what-if-we-apply-ohe"]], "What is Natural Language Processing (NLP)?": [[42, "what-is-natural-language-processing-nlp"]], "What is a recommender system?": [[41, "what-is-a-recommender-system"]], "What is clustering?": [[39, "what-is-clustering"]], "What is deployment?": [[47, "what-is-deployment"]], "What is feature engineering?": [[38, "what-is-feature-engineering"]], "What is feature selection?": [[38, "what-is-feature-selection"]], "What is grid search?": [[46, "what-is-grid-search"]], "What is model interpretability?": [[37, "what-is-model-interpretability"]], "What is supervised machine learning (ML)?": [[12, "what-is-supervised-machine-learning-ml"], [17, "what-is-supervised-machine-learning-ml"], [26, "what-is-supervised-machine-learning-ml"]], "What is \u201cpositive\u201d and \u201cnegative\u201d?": [[34, "what-is-positive-and-negative"]], "What kind of estimators can we combine?": [[36, "what-kind-of-estimators-can-we-combine"]], "What next?": [[47, "what-next"]], "What should be the loss? (Activity: 4 mins)": [[46, "what-should-be-the-loss-activity-4-mins"]], "What to look for in these plots?": [[39, "what-to-look-for-in-these-plots"]], "What transformations do we need to apply on the dataset?": [[21, "what-transformations-do-we-need-to-apply-on-the-dataset"]], "What would I do differently?": [[47, "what-would-i-do-differently"]], "What\u2019s the problem?": [[16, "what-s-the-problem"], [21, "what-s-the-problem"], [30, "what-s-the-problem"]], "When can we use broadcasting?": [[8, "when-can-we-use-broadcasting"]], "When experimenting, show the results asap": [[46, "when-experimenting-show-the-results-asap"]], "When is it OK to do things before splitting?": [[16, "when-is-it-ok-to-do-things-before-splitting"], [21, "when-is-it-ok-to-do-things-before-splitting"], [30, "when-is-it-ok-to-do-things-before-splitting"]], "When test score is much lower than CV score": [[33, "when-test-score-is-much-lower-than-cv-score"]], "Which model should I use?": [[36, "which-model-should-i-use"]], "Which type of error is more important?": [[34, "which-type-of-error-is-more-important"]], "Why do we need a test set?": [[33, "why-do-we-need-a-test-set"]], "Why do we want this information?": [[37, "why-do-we-want-this-information"]], "Why does it matter": [[19, "why-does-it-matter"]], "Why feature selection?": [[38, "why-feature-selection"]], "Why machine learning (ML)? [video]": [[12, "why-machine-learning-ml-video"], [17, "why-machine-learning-ml-video"], [26, "why-machine-learning-ml-video"]], "Why model transparency/interpretability?": [[37, "why-model-transparency-interpretability"]], "Why neural networks?": [[43, "why-neural-networks"], [43, "id1"]], "Why not neural networks?": [[43, "why-not-neural-networks"], [43, "id2"]], "Why should I use it?": [[46, "why-should-i-use-it"]], "Why should we care about effective communication?": [[46, "why-should-we-care-about-effective-communication"]], "Why should we care about recommendation systems?": [[41, "why-should-we-care-about-recommendation-systems"]], "Why sparse matrices?": [[31, "why-sparse-matrices"]], "Windows": [[10, "windows"]], "Windows Users": [[5, "windows-users"]], "Word embeddings": [[42, "word-embeddings"]], "Word vectors with spaCy": [[42, "word-vectors-with-spacy"]], "Writing a traditional program to predict quiz2 grade": [[13, "writing-a-traditional-program-to-predict-quiz2-grade"], [18, "writing-a-traditional-program-to-predict-quiz2-grade"], [27, "writing-a-traditional-program-to-predict-quiz2-grade"]], "XGBoost": [[36, "xgboost"]], "[Optional] Jupyterlab and Python": [[10, "optional-jupyterlab-and-python"]], "[] notation": [[8, "notation"]], "announcements": [[15, "announcements"]], "class_weight=\"balanced\"": [[34, "class-weight-balanced"]], "cross_val_score": [[14, "cross-val-score"], [19, "cross-val-score"], [28, "cross-val-score"]], "cross_validate": [[14, "cross-validate"], [19, "cross-validate"], [28, "cross-validate"]], "fit and transform paradigm for transformers": [[16, "fit-and-transform-paradigm-for-transformers"], [21, "fit-and-transform-paradigm-for-transformers"], [30, "fit-and-transform-paradigm-for-transformers"]], "fit the classifier": [[13, "fit-the-classifier"], [18, "fit-the-classifier"], [27, "fit-the-classifier"]], "fit, predict , and score summary": [[13, "fit-predict-and-score-summary"], [18, "fit-predict-and-score-summary"], [27, "fit-predict-and-score-summary"]], "iClicker": [[54, "iclicker"]], "iClicker Exercise 10.1": [[35, "iclicker-exercise-10-1"]], "iClicker Exercise 10.2": [[35, "iclicker-exercise-10-2"]], "iClicker Exercise 12.0": [[36, "iclicker-exercise-12-0"]], "iClicker Exercise 12.1": [[36, "iclicker-exercise-12-1"]], "iClicker Exercise 14.1": [[38, "iclicker-exercise-14-1"]], "iClicker Exercise 19.1": [[43, "iclicker-exercise-19-1"]], "iClicker Exercise 2.1 Supervised vs unsupervised": [[18, "iclicker-exercise-2-1-supervised-vs-unsupervised"]], "iClicker Exercise 2.2 Classification vs regression": [[18, "iclicker-exercise-2-2-classification-vs-regression"]], "iClicker Exercise 2.2 Supervised vs unsupervised": [[13, "iclicker-exercise-2-2-supervised-vs-unsupervised"], [27, "iclicker-exercise-2-2-supervised-vs-unsupervised"]], "iClicker Exercise 2.3 Classification vs regression": [[13, "iclicker-exercise-2-3-classification-vs-regression"], [27, "iclicker-exercise-2-3-classification-vs-regression"]], "iClicker Exercise 2.4: Baselines and decision trees": [[18, "iclicker-exercise-2-4-baselines-and-decision-trees"]], "iClicker Exercise 2.5: Baselines and decision trees": [[13, "iclicker-exercise-2-5-baselines-and-decision-trees"], [27, "iclicker-exercise-2-5-baselines-and-decision-trees"]], "iClicker Exercise 3.1": [[14, "iclicker-exercise-3-1"], [19, "iclicker-exercise-3-1"], [28, "iclicker-exercise-3-1"]], "iClicker Exercise 3.2": [[14, "iclicker-exercise-3-2"], [19, "iclicker-exercise-3-2"], [28, "iclicker-exercise-3-2"]], "iClicker Exercise 9.1": [[34, "iclicker-exercise-9-1"]], "iClicker Exercise 9.2": [[34, "iclicker-exercise-9-2"]], "k-Nearest Neighbours (k-NNs) [video]": [[15, "k-nearest-neighbours-k-nns-video"], [20, "k-nearest-neighbours-k-nns-video"], [29, "k-nearest-neighbours-k-nns-video"]], "k-nearest neighbours imputation": [[41, "k-nearest-neighbours-imputation"]], "macOS": [[10, "macos"]], "n_iter": [[33, "n-iter"]], "n_jobs=-1": [[33, "n-jobs-1"]], "pandas_profiler": [[35, "pandas-profiler"]], "predict the target of given examples": [[13, "predict-the-target-of-given-examples"], [18, "predict-the-target-of-given-examples"], [27, "predict-the-target-of-given-examples"]], "predict_proba": [[32, "predict-proba"]], "random_state argument": [[14, "random-state-argument"], [19, "random-state-argument"], [28, "random-state-argument"]], "score your model": [[13, "score-your-model"], [18, "score-your-model"], [27, "score-your-model"]], "sklearn API summary: estimators": [[16, "sklearn-api-summary-estimators"], [21, "sklearn-api-summary-estimators"], [30, "sklearn-api-summary-estimators"]], "sklearn API summary: transformers": [[16, "sklearn-api-summary-transformers"], [21, "sklearn-api-summary-transformers"], [30, "sklearn-api-summary-transformers"]], "sklearn set_config": [[31, "sklearn-set-config"]], "sklearn\u2019s ColumnTransformer": [[31, "sklearn-s-columntransformer"]], "sklearn\u2019s SimpleImputer": [[25, "sklearn-s-simpleimputer"]], "sklearn\u2019s feature_importances_ and permutation_importance": [[37, "sklearn-s-feature-importances-and-permutation-importance"]], "sklearn\u2019s feature_importances_ attribute vs permutation_importance": [[37, "sklearn-s-feature-importances-attribute-vs-permutation-importance"]], "spaCy": [[48, "spacy"]], "test score vs. cross-validation score": [[14, "test-score-vs-cross-validation-score"], [19, "test-score-vs-cross-validation-score"], [28, "test-score-vs-cross-validation-score"]], "test_size, train_size arguments": [[14, "test-size-train-size-arguments"], [19, "test-size-train-size-arguments"], [28, "test-size-train-size-arguments"]], "\u201cDeployment\u201d data": [[14, "deployment-data"], [19, "deployment-data"], [28, "deployment-data"]], "\u2753\u2753 Questions for group discussion": [[34, "questions-for-group-discussion"]], "\u2753\u2753 Questions for you": [[12, "questions-for-you"], [13, "questions-for-you"], [13, "id1"], [13, "id3"], [14, "questions-for-you"], [14, "id1"], [15, "questions-for-you"], [15, "id2"], [16, "questions-for-you"], [16, "id1"], [16, "id2"], [17, "questions-for-you"], [18, "questions-for-you"], [18, "id1"], [19, "questions-for-you"], [19, "id1"], [20, "questions-for-you"], [20, "id1"], [21, "questions-for-you"], [21, "id1"], [21, "id2"], [26, "questions-for-you"], [27, "questions-for-you"], [27, "id1"], [27, "id3"], [28, "questions-for-you"], [28, "id1"], [29, "questions-for-you"], [29, "id1"], [30, "questions-for-you"], [30, "id1"], [30, "id2"], [31, "questions-for-you"], [31, "id1"], [32, "questions-for-you"], [32, "id1"], [32, "id2"], [33, "questions-for-you"], [33, "id2"], [34, "questions-for-you"], [34, "id2"], [35, "questions-for-you"], [35, "id2"], [36, "questions-for-you"], [36, "id1"], [36, "id2"], [38, "questions-for-you"], [39, "questions-for-you"], [39, "id2"], [40, "questions-for-you"], [40, "id3"], [41, "questions-for-you"], [41, "id1"], [41, "id2"], [43, "questions-for-you"], [44, "questions-for-you"], [44, "id1"], [44, "id2"], [44, "id3"], [45, "questions-for-you"], [45, "id1"], [45, "id2"], [45, "id3"], [45, "id4"], [46, "questions-for-you"], [46, "id1"], [47, "questions-for-you"], [47, "id2"]], "\ud83e\udd14 Eva\u2019s questions": [[12, "eva-s-questions"], [14, "eva-s-questions"], [17, "eva-s-questions"], [26, "eva-s-questions"], [28, "eva-s-questions"]]}, "docnames": ["LICENSE", "README", "docs/330_vs_340", "docs/README", "docs/asking_for_help", "docs/git_installation", "docs/grades", "docs/homework_instructions", "docs/python_notes", "docs/resources", "docs/setup", "learning-objectives", "lectures/201-Lecuyer-lectures/01_intro", "lectures/201-Lecuyer-lectures/02_terminology-decision-trees", "lectures/201-Lecuyer-lectures/03_ml-fundamentals", "lectures/201-Lecuyer-lectures/04_kNNs-SVM-RBF", "lectures/201-Lecuyer-lectures/05_preprocessing-pipelines", "lectures/202-203-Giulia-lectures/01_intro", "lectures/202-203-Giulia-lectures/02_terminology-decision-trees", "lectures/202-203-Giulia-lectures/03_ml-fundamentals", "lectures/202-203-Giulia-lectures/04_kNNs-SVM-RBF", "lectures/202-203-Giulia-lectures/05_preprocessing-pipelines", "lectures/204-Andy-lectures/README", "lectures/204-Andy-lectures/class_demos/demo_03-ml-fundamentals", "lectures/204-Andy-lectures/class_demos/demo_04-kNNs-SVMs", "lectures/204-Andy-lectures/class_demos/demo_05-06-preprocessing", "lectures/notes/01_intro", "lectures/notes/02_terminology-decision-trees", "lectures/notes/03_ml-fundamentals", "lectures/notes/04_kNNs-SVM-RBF", "lectures/notes/05_preprocessing-pipelines", "lectures/notes/06_column-transformer-text-feats", "lectures/notes/07_linear-models", "lectures/notes/08_hyperparameter-optimization", "lectures/notes/09_classification-metrics", "lectures/notes/10_regression-metrics", "lectures/notes/12_ensembles", "lectures/notes/13_feat-importances", "lectures/notes/14_feature-engineering-selection", "lectures/notes/15_K-Means", "lectures/notes/16_DBSCAN-hierarchical", "lectures/notes/17_recommender-systems", "lectures/notes/18_natural-language-processing", "lectures/notes/19_intro_to_computer-vision", "lectures/notes/20_time-series", "lectures/notes/21_survival-analysis", "lectures/notes/22_communication", "lectures/notes/24_deployment-conclusion", "lectures/notes/appendixA_feature-engineering-text-data", "lectures/notes/appendixB_multiclass-strategies", "lectures/notes/final-exam-review-guiding-question", "lectures/tutorials/01_decision_boundaries", "lectures/tutorials/02_ML_fundamentals", "lectures/tutorials/03_Preprocessing", "syllabus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["LICENSE.md", "README.md", "docs/330_vs_340.md", "docs/README.md", "docs/asking_for_help.md", "docs/git_installation.md", "docs/grades.md", "docs/homework_instructions.md", "docs/python_notes.ipynb", "docs/resources.md", "docs/setup.md", "learning-objectives.md", "lectures/201-Lecuyer-lectures/01_intro.ipynb", "lectures/201-Lecuyer-lectures/02_terminology-decision-trees.ipynb", "lectures/201-Lecuyer-lectures/03_ml-fundamentals.ipynb", "lectures/201-Lecuyer-lectures/04_kNNs-SVM-RBF.ipynb", "lectures/201-Lecuyer-lectures/05_preprocessing-pipelines.ipynb", "lectures/202-203-Giulia-lectures/01_intro.ipynb", "lectures/202-203-Giulia-lectures/02_terminology-decision-trees.ipynb", "lectures/202-203-Giulia-lectures/03_ml-fundamentals.ipynb", "lectures/202-203-Giulia-lectures/04_kNNs-SVM-RBF.ipynb", "lectures/202-203-Giulia-lectures/05_preprocessing-pipelines.ipynb", "lectures/204-Andy-lectures/README.md", "lectures/204-Andy-lectures/class_demos/demo_03-ml-fundamentals.ipynb", "lectures/204-Andy-lectures/class_demos/demo_04-kNNs-SVMs.ipynb", "lectures/204-Andy-lectures/class_demos/demo_05-06-preprocessing.ipynb", "lectures/notes/01_intro.ipynb", "lectures/notes/02_terminology-decision-trees.ipynb", "lectures/notes/03_ml-fundamentals.ipynb", "lectures/notes/04_kNNs-SVM-RBF.ipynb", "lectures/notes/05_preprocessing-pipelines.ipynb", "lectures/notes/06_column-transformer-text-feats.ipynb", "lectures/notes/07_linear-models.ipynb", "lectures/notes/08_hyperparameter-optimization.ipynb", "lectures/notes/09_classification-metrics.ipynb", "lectures/notes/10_regression-metrics.ipynb", "lectures/notes/12_ensembles.ipynb", "lectures/notes/13_feat-importances.ipynb", "lectures/notes/14_feature-engineering-selection.ipynb", "lectures/notes/15_K-Means.ipynb", "lectures/notes/16_DBSCAN-hierarchical.ipynb", "lectures/notes/17_recommender-systems.ipynb", "lectures/notes/18_natural-language-processing.ipynb", "lectures/notes/19_intro_to_computer-vision.ipynb", "lectures/notes/20_time-series.ipynb", "lectures/notes/21_survival-analysis.ipynb", "lectures/notes/22_communication.ipynb", "lectures/notes/24_deployment-conclusion.ipynb", "lectures/notes/appendixA_feature-engineering-text-data.ipynb", "lectures/notes/appendixB_multiclass-strategies.ipynb", "lectures/notes/final-exam-review-guiding-question.ipynb", "lectures/tutorials/01_decision_boundaries.ipynb", "lectures/tutorials/02_ML_fundamentals.ipynb", "lectures/tutorials/03_Preprocessing.ipynb", "syllabus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 4, 5, 7, 8, 9, 10, 13, 18, 19, 23, 24, 27, 32, 33, 36, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54], "0": [0, 1, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "00": [1, 12, 13, 15, 17, 23, 25, 26, 27, 29, 31, 32, 33, 34, 37, 40, 41, 44, 45, 46, 54], "000": [12, 14, 15, 16, 17, 19, 20, 21, 26, 28, 29, 30, 31, 32, 33, 35, 36, 37, 42, 43, 45, 48], "0000": [16, 21, 30, 32, 34, 42, 48], "00000": [33, 44], "000000": [13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 44, 45], "00000000e": 37, "000000e": [25, 33], "000001": 35, "00000e": [15, 29], "000010": 35, "000011": 34, "000021": [16, 21, 30], "000036": 34, "000057": [16, 21, 30], "000065": 33, "000067": 33, "000077": 33, "000087": 32, "000089": 32, "0001": [32, 34, 35, 45, 46], "000100": [16, 21, 30, 35], "000102e": 23, "000108": 32, "000113": 34, "000114": 33, "000117": 35, "000128": 24, "000130": 32, "000136": 43, "000137": 33, "000144": 24, "000145": 33, "000146": 32, "000147": 33, "000149": [16, 21, 24, 30], "000150": 32, "000151": 33, "000154": 24, "000155": [16, 21, 30, 34], "000156": 24, "000159": 33, "000162": 24, "000163": [24, 33], "000166": [32, 33], "000175": 24, "000177": [30, 44], "000179": 24, "000180": 30, "000181": 33, "000182": 32, "000183": 32, "000187": [24, 32], "000188": 30, "000190": 44, "000192": 44, "000194": 32, "000195": 30, "000197": 16, "000198": 34, "000200": 16, "000201": [16, 33], "000206": 33, "000208": [16, 21, 30], "000210": 33, "000212": 38, "000213": 32, "000214": 16, "000218": [21, 32], "000221": 35, "000222": 21, "000226": 35, "000227": 34, "000228": 21, "000231": 30, "000232": 43, "000234": [15, 29, 33], "000235": [24, 30, 34], "000236": 24, "000240": 30, "000241": [21, 24], "000245": 33, "000247": 43, "000248": 24, "000255": 32, "000256": 44, "000257": 16, "000259": 30, "000260": 30, "000264": 16, "000265": 24, "000270": 24, "000271": 44, "000273": 43, "000274": 43, "000278": 21, "000279": 21, "000281": [24, 32], "000283": 32, "000285": [21, 32], "000286": 33, "000287": 25, "000289": [16, 21, 30], "000291": 16, "000294": [25, 33], "000296": 24, "000303": 25, "000304": 25, "000306": 21, "000310": 24, "000312": 34, "000313": 24, "000316": 24, "000321": 24, "000323": 16, "000328": 24, "000329": 24, "000332": 35, "000336": 43, "000339": 33, "000342": 21, "000348": 33, "000353": 33, "000354": 33, "000363": 43, "000366": 34, "000370": 33, "000371": 32, "000373": 35, "000374": 24, "000378": 32, "00038": 33, "000387": 24, "000397": 35, "000399": 43, "000420": 24, "000423": 24, "000428": 24, "000432": 24, "000433": 35, "000434": 14, "000435": [14, 43], "000437": 43, "000438": 14, "000441": [14, 24], "000442": 25, "000444": 25, "000445": 14, "000448": 14, "000451": 14, "000452": 30, "000458": 25, "000459": [14, 32], "000460": 24, "000463": 14, "000468": 25, "000471": [14, 44], "000472": 43, "000475": 24, "000477": 19, "000480": [19, 24], "000485": 25, "000489": 33, "000492": 34, "000496": 19, "000498": 44, "0005": 46, "000500": 14, "000502": [19, 21], "000503": [15, 33], "000508": 33, "000511": 14, "000520": [24, 35], "000524": 14, "000528": 15, "000534": 19, "000536": 16, "000540": 24, "000542": 24, "000545": 15, "000548": 15, "000549": 15, "000551": 19, "000558": 19, "000561": [15, 24], "000575": 44, "00058": 33, "000580": 29, "000602": 15, "000607": 15, "000610": 19, "000612": 15, "000625": 15, "000626": 14, "000630": 34, "000633": 29, "000636": 14, "000637": [14, 43], "000639": 14, "000640": 15, "000642": 14, "000644": 14, "000645": 24, "000646": 14, "000647": 29, "000650": 29, "000651": 29, "000652": [14, 35], "000655": [14, 29], "000657": 14, "000661": 29, "000664": 14, "000666": 15, "000671": 29, "000675": [14, 20], "000678": 33, "000683": 15, "000685": 24, "000686": 14, "000691": 19, "000696": 19, "000697": 15, "000700": 20, "000701": [15, 19], "000707": 19, "000710": 20, "000711": 19, "000712": 19, "000713": [24, 35], "000714": 20, "000720": 19, "000722": 14, "000726": 34, "000728": 20, "000736": 20, "000737": 44, "000739": 20, "000740": 24, "000742": 15, "000746": 15, "000747": 33, "000748": 30, "000752": [15, 29], "000757": 14, "000758": 43, "000765": 30, "000774": 30, "000777": 25, "000786": 34, "000787": 29, "00079": 33, "000794": 29, "000795": 29, "000797": 29, "000800": 14, "000803": 35, "000805": 15, "000812": [14, 24], "000815": 15, "000816": 19, "000820": 15, "000823": 19, "000829": [24, 29], "000831": 29, "000832": 35, "000839": [19, 20, 24], "000842": 15, "000851": 20, "000867": 30, "000869": 44, "000870": 19, "000873": 29, "000881": 21, "000889": 29, "000890": 24, "000891": 34, "000894": 21, "000917": 33, "000927": 34, "000934": 24, "000935": 16, "000936": 29, "000944": 15, "000945": 38, "000947": 16, "000950": 20, "000952": 21, "000960": 43, "000964": 38, "000967": 20, "000969": 20, "000975": 14, "000976": 33, "000977": 29, "000982": 33, "000999": 16, "001": [12, 14, 15, 16, 17, 20, 21, 26, 28, 29, 30, 31, 32, 33, 35, 36, 37, 43, 45, 46, 48], "0010": 32, "00100": 33, "001000": [33, 35], "001002": 28, "001006": 28, "001010": 28, "001011": [14, 29, 35], "001014": 28, "001016": 28, "001017": 28, "001021": 14, "001026": 28, "001027": 28, "001029": 28, "001038": 28, "001043": 30, "001057": [28, 33], "001060": [16, 21, 30], "001063": 28, "001064": 43, "001068": 37, "001071": 28, "001073": 16, "001078": 28, "001079": 21, "001082": 19, "001086": 28, "001087": 38, "001103": 28, "001109": 24, "001111": 28, "001113": 19, "001116": 20, "001126": 20, "001139": 29, "001144": 14, "001145": 15, "001146": 20, "001149": 28, "001155": 38, "001162": [33, 38], "001174": 28, "001178": 24, "001179": 15, "001204": 15, "001205": 34, "001220": 32, "001224": 29, "001226": 43, "001230": 24, "001236": 33, "001239": 34, "001245": 16, "001260": 15, "001266": 35, "001271": 15, "001279": 38, "001282": 15, "001286": 34, "001294": 28, "001299": 28, "001302": 20, "001305": 28, "001307": 28, "001315": 28, "001317": 28, "001322": 28, "001323": 28, "001325": 29, "001329": 28, "001337": 28, "001338": [20, 32], "001344": 15, "001347": 33, "001352": 28, "001361": 32, "001362": 32, "001365": 29, "001371": 31, "001375": 24, "001390": 28, "001391": 28, "001392": 29, "001400": 31, "001406": 35, "001407": 28, "001412": 33, "001414": 29, "001416": 15, "001419": 24, "001421": 34, "001422": 35, "001423": 33, "001429": 28, "001433": 35, "001441": 28, "001448": 31, "001453": 28, "00146": 33, "001466": 31, "001467": 33, "001492": 33, "001495": 29, "001511": 24, "001519": 15, "001521": 20, "001541": 20, "001563": 31, "001566": [24, 35], "001580": 20, "001585": 33, "001586": 29, "001591": 31, "001594": 33, "001595": 29, "001600": 29, "001604": 31, "001606": 31, "001608": 33, "001616": 33, "001620": 33, "001629": 33, "001641": 43, "001645": 32, "001647": 31, "001679": 33, "001682": 33, "001687": 24, "001693": 38, "001699": 28, "0017": 34, "001700": 34, "001710": 32, "001715": 31, "001730": 15, "001740": 35, "001769": 33, "001773": 29, "001776": 28, "001790": 35, "001792": 33, "001805": 15, "001807": 15, "001836": 15, "001847": 38, "001850": 32, "001873": 15, "001877": 29, "001882": 24, "001888": 20, "001894": 35, "001900": 29, "001920": 31, "001922": 31, "001933": 35, "001949": 38, "001952": 29, "0019627889": 42, "001968": 28, "001994": 38, "002": [14, 28, 32, 36, 37, 42, 45], "002003": 33, "002022": 31, "002030": 29, "002045": 33, "002057": [16, 21, 30, 31], "002083": 29, "002096": 43, "002105": 33, "002116": 31, "002118": 29, "002123": 33, "002143": 28, "002146": 33, "002158": 38, "002159": 33, "002197": 33, "002221": 35, "002224": 20, "002225": 20, "002251": 15, "002321": [24, 32], "00234": 33, "002355": 38, "002385": 35, "002418": 24, "002441": 38, "002460": 43, "002477": 24, "002516": 20, "002525": 43, "002561": 33, "002643": 24, "002646": 38, "002664": 38, "002675": 33, "002682": 43, "002690": [16, 21, 30], "002692": 33, "002704": 33, "002711": 43, "002716": 20, "002720": 20, "002746": 35, "002783": 33, "002788": 31, "002789": 31, "002802": 24, "002807": 31, "002814": 21, "002823": 16, "002833": 16, "002835": 33, "002848": 24, "002852": 16, "002858": [16, 31], "002867": 38, "002889": 34, "0029": 45, "002910": 31, "002921": 24, "002934": 32, "002940": 43, "002948": 29, "002949": 20, "002962": 43, "002965": 24, "002986": 43, "002987": 24, "002999": 33, "003": [33, 36], "003013": 31, "003014": 33, "003015": 33, "003027": 33, "003038": [24, 33], "003044": 24, "003077": 16, "003083": 33, "003086": 31, "003088": 24, "003115": 31, "003124": [34, 35], "003133": 35, "003146": 31, "003148": 32, "003166": [30, 38], "003181": 30, "003183": 38, "003185": 45, "003186": 31, "003188": [30, 31], "003194": 32, "003210": 24, "003212": 30, "003218": 20, "003224": 20, "003242": 43, "003257": 43, "003272": 24, "003273": 28, "003283": 43, "003284": 20, "003288": 35, "003300": [16, 21, 30], "003316": 21, "00332": 33, "003324": 30, "003365": 31, "003388": 21, "003401": 38, "003421": 33, "003423": 38, "003427": 38, "003442": 21, "003463": 24, "003472": 33, "003477": 43, "003479": [21, 33], "003483": 33, "003493": 38, "003528": 33, "003529": 33, "003540": 24, "003547": 35, "003561": [14, 19], "003563": 33, "003593": 24, "003633": 33, "003647": 43, "003663": 24, "003666": 21, "00369": 33, "003748": 33, "003757": 33, "003785": [24, 35], "003877": 24, "003885": 33, "003898": 20, "003910": 24, "003919": [24, 33], "003919287722401839": 33, "00392157": 43, "003923": 31, "003924": 38, "003933": 33, "003998": 33, "004": [15, 29, 33, 36, 37, 43], "004057": 33, "004065": 44, "004082": 44, "004121": 35, "004143": 35, "004264": [14, 19, 28], "004293": 33, "004305": 33, "004337": 33, "00435173": 39, "004352": 39, "004398": 37, "004402": 33, "004461": 24, "004462": 20, "004466": 33, "004469": 24, "004496": 33, "004521": 35, "004529": 37, "004556": 33, "004574": 35, "004594": 24, "004602": 35, "00461": 33, "004714": 33, "004723": 37, "004761": 37, "004769": [14, 19], "004770": [16, 21, 30], "004801": [16, 21, 30, 31], "004807": 31, "004826": 35, "004829": 35, "004852": 24, "004854": 35, "004884": 43, "004885": 16, "004919": 33, "004952": 33, "004955": 16, "004959": 33, "00496": 33, "004977": 16, "004980": 16, "005": [12, 17, 26, 36, 37, 45, 46], "005067": 30, "005074": 43, "005093": 30, "005098": 35, "005114": 35, "005126": 33, "005136": 23, "005151": 33, "005157": 30, "005167": 35, "005196": 33, "005241": 35, "00525962": [16, 21, 30], "005269": 35, "005270": 24, "005288": 31, "005309": 20, "005313": 20, "005335": 33, "005336": 35, "005373": 21, "005377": 21, "005387": 34, "005398": 21, "005423": 33, "005426": 33, "005437": 16, "00543825": [16, 21, 30], "005440": 43, "005443": 20, "005478": 37, "00548": 33, "005538": 35, "005563": 19, "005579": 35, "005593": 20, "005622": 21, "005641": 35, "005674": 35, "005699": [14, 19, 28], "005708": 33, "00573": 33, "005734": 33, "005735": 33, "005767": 33, "005809": 44, "005834": 33, "005836": 30, "005888": [16, 21, 30], "005963": 34, "006": [16, 36, 37, 45], "006012": 33, "006046": 35, "006055": 33, "006067": 35, "006070": 24, "006106": 33, "006110": [15, 29, 33, 35], "006208": 24, "006236": [24, 35], "006244": 33, "006250": 24, "006435": 33, "006452": 32, "006465": 20, "006476": 35, "006505": 43, "006531": [14, 19, 28], "006545": 33, "006546893270012566": 32, "006557": 32, "006570": 21, "006578": [16, 21, 30, 31], "006649": 20, "006652": 33, "006667": [24, 33], "00667": 33, "006744": 35, "006770": 24, "006805": [14, 19, 28], "006861": 33, "006904": 33, "00691": 33, "006973": 30, "007": [21, 30, 36, 37, 45, 48], "007068": 38, "00715": 33, "00720988e": 37, "007228": 35, "007291": 31, "007316": [14, 19, 28], "007362": 33, "007434": 37, "007438": 34, "007458": [16, 21, 30, 31], "007517": 35, "007542": 23, "007544": 33, "007563": 33, "007588": 39, "00758803": 39, "00759438": 37, "007655": 33, "007666": 34, "00767": 33, "007737": 35, "007776": 35, "007818": 33, "007926": 20, "007938": [14, 28], "007986": 35, "008": [36, 37, 48], "008040": 44, "008120": 35, "008153": 33, "008167": [16, 21, 30, 31], "008286": 24, "00830586": 31, "008306": 31, "008322e": 45, "008333": 31, "008346": 35, "008377": 33, "008472": 35, "008498": 24, "008577": 43, "008581": 35, "008606": 35, "008617": 35, "008667": 33, "00871": 33, "008735": [15, 20, 29], "008785": 35, "008786": 34, "009": [31, 36, 45, 48], "009059": [14, 19, 28], "009063": 33, "009082": 33, "009090": 35, "009131": 24, "009132": 33, "009140": 35, "009260": 19, "009297": 33, "009305": 33, "009339": 35, "009422": [14, 28], "009512": 33, "009514e": 35, "009556": 34, "009664": 35, "009692": 43, "009703": 24, "009724": 38, "00pm": 1, "01": [15, 16, 20, 21, 25, 29, 30, 32, 33, 34, 35, 37, 43, 44, 45, 46, 49, 54], "010": [12, 17, 26, 32, 33, 45], "0100": 32, "01000": 33, "010000": [16, 21, 30, 33, 35], "010027": 32, "010183": [16, 21, 30, 31], "0102": [15, 29, 33], "010208": 38, "010294": [14, 19, 28], "010547": 19, "010650": [14, 19, 28], "010679": [14, 28], "010688": 38, "010715": 33, "010750": 38, "011": [12, 17, 26, 31, 43, 45], "011210": 38, "011234": 34, "011248": 35, "011252": 38, "011269e": 35, "011287": 38, "011332": 45, "011336": [15, 20, 29], "011415": 24, "011440": 35, "011617": 33, "011678": 34, "011767": 35, "011773": 36, "012": [16, 21, 30, 31, 36, 37, 43, 45, 48], "012019": [19, 28], "012030": 38, "012065": 14, "012232": 35, "012240": 38, "012247": 24, "012252": 33, "012616": 33, "012624": 35, "012758": 35, "013031": 35, "01311996071": 35, "013120": 37, "013157": 33, "013161": 33, "013433": [15, 20, 29], "013629": 33, "013706928443177698": 33, "013707": 33, "013863": 33, "013888": 33, "014": [16, 21, 28, 30, 36, 37, 45], "014030": 35, "014081e": 35, "01409912": 42, "014305": 35, "01432486e": 37, "014337": 24, "014481": 33, "014503": 33, "014650": 45, "014730": 31, "01473536": [15, 20, 29], "014758": 45, "014990": 24, "015": [12, 16, 17, 21, 26, 30, 31, 36, 45, 48], "015003": 33, "015039": 34, "015056": 33, "015165": 35, "015372": 33, "015639": 24, "015724": 38, "015755": 33, "015819": 33, "016263": 33, "016330": 24, "016372": 33, "01647": 33, "016525": [35, 37, 46], "016555": 32, "016587": 34, "016598": 33, "016602": 33, "016607": 33, "016660": 25, "016676": 39, "016688": [16, 21, 30, 38], "016693": 35, "016807": 32, "016815": 33, "016918": 34, "016944": [15, 20, 29], "017": [31, 43], "017185": 33, "017226": 35, "017308": 33, "017427": 33, "017561": 34, "017610": 37, "017696": 37, "017737": 37, "017741": 37, "017795": 24, "017829": 44, "017837": 33, "01784": 33, "017927": 33, "017951": 24, "017959e": 35, "017972": [16, 21, 30], "018": 36, "018014": 37, "018077": 33, "018178": [15, 20, 29], "018243": 33, "018310": [15, 20, 29], "018434": 44, "018459e": 35, "018487": 32, "0185": 32, "018505": 33, "018507e": 35, "018558": 33, "018581": 35, "018622": 25, "018653": 33, "018745": [12, 17, 26], "018789": 33, "018846": 33, "018854": 34, "019": [36, 48], "019012": 33, "019163": 33, "019293": 24, "019381838999846482": 33, "019382": 33, "019390": 34, "019396": 33, "019444": 31, "019446": 33, "019531": 34, "019556": 45, "0195598": 32, "019574": 33, "019603": 34, "019839": 33, "019963": 34, "02": [15, 16, 21, 23, 25, 29, 30, 31, 32, 33, 35, 37, 38, 44, 45, 53, 54], "020000": 24, "02000e": [15, 29], "020123": 35, "020273": 34, "020319": 34, "020403": 33, "020414": 33, "020641": 37, "020648": 35, "020653": [14, 19, 28], "020833": 41, "020862": 35, "020873": [16, 21, 30], "021": 36, "021082": 24, "021100": [16, 21, 30], "021281": 33, "021305": [15, 20, 29], "021345": 33, "021603": 43, "021721": 33, "021746": 33, "021862": 33, "021900": [15, 29, 33], "022039": 34, "022331": 37, "022433": 33, "022629": 33, "022686": 33, "022730": 24, "022848": [14, 19, 28], "022866": 34, "023": [36, 43], "023086": 45, "023105": 44, "023279": 25, "023305": 35, "023366": 38, "023511": 33, "023554": 35, "023636": 34, "023666": 33, "023810": 48, "024": 36, "024028": 33, "024122": 33, "024291": 44, "024351e": 35, "024390": 38, "02446630e": 37, "024540": [16, 21, 30], "024944": 24, "025": [30, 34], "025381": [37, 46], "025391": [16, 21, 30, 31], "025396": 33, "025460": 24, "025489": 37, "025689": 33, "025910": [15, 20, 29], "025998": [16, 21, 30, 31], "026": 45, "0261": [15, 29, 33], "026616": 24, "026620": 33, "026667": 24, "026777": 33, "02677733855112973": 33, "026793": [35, 37, 46], "026972": 35, "027070": 35, "027079": 24, "027112": 44, "027321": 38, "027484": 35, "027578": 35, "028023": 34, "02807617": 42, "028186": 24, "028337": 33, "028351": 33, "028420": 35, "028672": 38, "028772": 35, "029": 42, "029146": 34, "029164": 44, "029198": 33, "029264": 35, "029396": 24, "029409": 35, "029475": 35, "029909": [14, 28], "029950e": 35, "02d": 44, "03": [1, 16, 23, 32, 33, 35, 37, 43, 44, 45, 48, 54], "030": 37, "03017665e": 37, "030200": [16, 21, 30], "030343": 35, "030349": 35, "030408": [15, 20, 29], "03049217": [15, 20, 29], "0305": [15, 20, 29], "030618": 19, "030739733331869412": 32, "030786": 35, "030805": 35, "031": 31, "031070": 35, "031385": [15, 20, 29], "031483": 35, "031564": [16, 21, 30], "031794": 35, "031863": 35, "0319": 42, "031994": 35, "032000": 24, "032140": 35, "032324": 33, "032404": 33, "032508": 34, "032566": 31, "03256625": 31, "032656": [15, 20, 29], "032660": 24, "032836": 34, "032874": [15, 20, 29], "033165": 35, "033222": 45, "033267": 44, "033279": 37, "033305": 43, "033322": 35, "033459": [15, 20, 29], "0335": 33, "033723": 35, "033739": 35, "033780": 45, "033815": 34, "033833": 34, "0339": [16, 21, 30], "033993": 24, "034071": 34, "03411038e": 37, "034132": 35, "0344": [15, 29, 33], "034894": 37, "034977": 35, "034979e": 35, "035": 43, "0351": [16, 21, 30], "03516073": 37, "035161": 37, "035223": 35, "035230": 44, "035722": 35, "036": [14, 16, 21, 30, 36, 43], "036136": 38, "0362": [16, 21, 30], "036646": 35, "036764": 34, "036886": 36, "0370": [16, 21, 30], "0373": [16, 21, 30], "037414": 44, "037785": 34, "0378": [16, 21, 30, 45], "038102": 32, "038609": 35, "038707": 37, "038873": 24, "038948": 35, "039": 43, "039498": 32, "039739": 24, "039741": 29, "0399": [16, 21, 30], "04": [16, 21, 23, 25, 30, 31, 33, 35, 37, 44, 45, 53, 54], "040": 36, "040000": 24, "040000e": 23, "040129": 45, "040497": 34, "040563": 24, "040698e": 35, "040954": 45, "040984": 44, "041": [36, 43], "041031": 34, "04108378": 32, "041084": 32, "041129": [15, 20, 29], "041201": 34, "041488": 35, "041704": 37, "041769": 35, "042081": 37, "042382": 38, "042743": 35, "042957": [16, 21, 30, 31], "043": 33, "043257": 31, "043319": 37, "043509": 33, "043624": 16, "0437": [13, 14, 15, 19, 20, 27, 28, 29, 51], "043890": [15, 20, 29], "044": [15, 29, 33], "044029": [16, 21, 30, 31], "044166": 32, "044253": 37, "044313": [16, 21, 30], "044409": 35, "044614": 33, "044873": [14, 19, 28], "045": [13, 23, 27, 43], "045267": 44, "045304": [15, 20, 29], "045415": 30, "045481": 44, "046": 43, "04600e": [15, 29], "046020": [15, 20, 29], "046114": 24, "046116": 33, "046193e": 35, "046216": 33, "046638": 31, "0468": 45, "0469": [16, 21, 30], "046945": 33, "04709519e": 37, "0474": 32, "047567": 35, "04774884": 39, "047749": 39, "047851": 21, "048": [14, 19, 28, 31], "048378": [14, 19, 28], "04861878": 39, "048630": 44, "048860": [16, 21, 30], "048889": 35, "048940": 14, "049": [31, 43], "049097": 24, "05": [15, 16, 21, 23, 25, 29, 30, 33, 34, 35, 40, 44, 45, 46, 54], "050": [12, 17, 26, 43], "050110e": 35, "050132": [16, 21, 30, 31], "051": 43, "051269": [16, 21, 30, 31], "05137470e": 37, "051392": 43, "051472": [15, 20, 29], "051620": [16, 21, 30], "051824": 35, "051925": 33, "052": [16, 21, 30], "052349": [16, 21, 30], "052607": 34, "052790": 34, "052819": 34, "05290827e": 37, "053156": 39, "05350962": 49, "0537": 33, "053763": [14, 19, 28], "053918": 33, "054054": 34, "054461": 34, "054653": 31, "05465323": 31, "054669": [35, 37, 46], "054784": 31, "05478443": 31, "055": [16, 21, 28, 30, 31], "055100": 33, "055398": 15, "055915e": 35, "05598498": 31, "055985": 31, "056": 43, "056478": [16, 21, 30, 31], "05656664": 42, "056599": 24, "056703": 34, "057": [16, 21, 30, 43], "057003": [15, 20, 29], "057082": 35, "057254": 45, "057296": 34, "057331": 35, "057646": [15, 20, 29], "057729": 34, "057732e": 45, "057793": [16, 21, 30, 31], "057910": [16, 21, 30, 31], "058": 36, "0580": [14, 19, 28, 32], "058176": 46, "058298": 35, "059": [12, 16, 17, 21, 26, 30], "059077": 34, "0591": [16, 21, 30], "059242": [16, 21, 30, 31], "059360": 43, "059588": 33, "059863": [15, 20, 29], "06": [16, 21, 23, 30, 33, 35, 40, 42, 43, 44, 45, 49, 54], "060": 43, "060477": 35, "060543": 38, "061100": [16, 21, 30], "061206": 34, "061241": [15, 20, 29], "061312": 35, "061313": 43, "061937": [15, 20, 29], "062": [12, 15, 17, 26, 29, 33], "062043": 33, "062449": 45, "062658e": 35, "062723": [19, 28], "062792": [15, 20, 29], "062793": 42, "063004": 38, "063110": [16, 21, 30, 31], "063173": 37, "064": [33, 37], "06405": 33, "064050": 33, "064200": [15, 20, 29], "064205": 14, "064307": 38, "064452": [15, 20, 29], "064635": 16, "065": 43, "065169": 33, "065449": 35, "065463": 34, "066166": 45, "066251": [19, 28], "066512": 24, "066605": 33, "066667": [16, 21, 30], "0667579112160865": 32, "066810": 45, "066944": 33, "066960": 14, "067099": 24, "067119": 30, "067120": [19, 28], "06797961": 35, "067991": [16, 21, 30], "068": [12, 17, 26], "068214": [32, 33], "068291": 43, "068428": 24, "068498": 33, "068775": 33, "068800e": 23, "068891": 33, "069": [16, 23], "069150": 37, "06915047": 37, "069188": 45, "0694": [15, 29, 33], "069530": [15, 20, 29], "069828": 16, "07": [1, 25, 33, 35, 38, 44, 45], "070047": 21, "070081": 33, "070195": 33, "070771": 16, "070850": 34, "070898": 33, "070907": [14, 19, 28], "070929": 34, "071": 43, "071330": 44, "071541": [16, 21, 30, 31], "071654": 38, "07174469222": 35, "071745": 37, "071975": 38, "072": 36, "072043": 33, "072243": 37, "0723": [16, 21, 30], "072396": 33, "07245741": 35, "072595": 33, "072707": [14, 28], "073016": 46, "073058": 30, "073073": 16, "073233": 32, "073366": 30, "074": [16, 21, 30, 36], "0741": [15, 20, 29], "074141": [15, 20, 29], "07418": 33, "074327": 36, "074418": 43, "074475": 30, "074719": 31, "07471942": 31, "074773": 19, "074853": 46, "075000": 41, "075170": 44, "075453": 45, "075467": 45, "075668": 24, "075747": 33, "076018": 24, "076104": 35, "0762": [16, 21, 30], "076284": 39, "076358": 21, "07639": 33, "076533": 35, "076798": [15, 20, 29], "076938": 21, "077": [36, 43], "077204": 37, "077749": 42, "077761": 45, "077803": 33, "078": [32, 36], "0780": [13, 14, 19, 27, 28, 51], "078052": 34, "07808506982896266": 35, "078243": 33, "078387": 45, "078552": 33, "078740": 33, "07877994e": 49, "078880": 31, "079": 33, "079181": 21, "079282": 33, "079377": 45, "0794": [15, 29, 33], "079471e": 35, "079852e": 35, "08": [16, 21, 30, 33, 35, 38, 40, 43, 44, 45], "080": 43, "08002986030": 31, "080084": 33, "080165": 33, "080319": 31, "08031924": 31, "080694": 37, "080734": 28, "0808": 33, "080847": 14, "081": [12, 17, 26], "08116": 33, "081167": 45, "081292": 44, "08151507e": 37, "081837": 45, "082": 30, "082100": 33, "082251": 32, "082265e": 45, "082749": [15, 20, 29], "082835": 37, "082949": [15, 20, 29], "083": [15, 29, 33, 36], "083123": [16, 21, 30, 31], "083338": [14, 19, 28], "08338644": 42, "083545": 34, "083615": 33, "083813": [16, 21, 30, 31], "083836": 14, "084288": 33, "084490": 46, "084683": 24, "084746": [16, 21, 30, 31], "084870": 19, "085150": 44, "085415": [37, 46], "085477": 34, "085508": 35, "085546": 35, "085550": 35, "085551": 35, "085693": 33, "085698": 35, "086078": 24, "08613": 33, "08642578": 42, "086461": 38, "086517": 23, "086932": 28, "087": 31, "087128": 33, "08740234": 42, "087668": 33, "08791477": 42, "087996e": 33, "088": 43, "0880": [16, 21, 30], "088373": 14, "088543": 33, "088948": [15, 20, 29], "089136": 19, "089294": 33, "089313": 33, "089354": [14, 19], "089485": [19, 28], "089892": 19, "09": [14, 19, 23, 28, 31, 33, 35, 44, 45], "090000": 34, "09009799": 35, "090231": 37, "090376e": 35, "090453": 34, "090473": 33, "090579": 24, "09058097218": [12, 17, 26], "090785": 35, "090951": 20, "090978": 23, "091": 43, "091243": 33, "091625": 38, "091632": 24, "091819": 28, "092": 36, "092072": 33, "092123": 33, "0922": [15, 29, 33], "092204": [14, 28], "092331": 14, "09245358900622544": 33, "092454": 33, "092604": [14, 19, 28], "092660": 45, "092669": 19, "092670": 33, "092729": 33, "092930": 31, "093051": 33, "0931": 33, "093228": 38, "093350": 46, "093390": [15, 20, 29], "093407": 34, "09345386": 31, "093454": 31, "093624": 28, "093787": 33, "093893": 33, "094": [12, 17, 26, 42], "094290": 45, "09430199": 31, "094302": 31, "094581": 31, "094586": 34, "094725": 33, "094863": 33, "095018": 33, "09503409246217484": 35, "095177": 33, "095345": 33, "09573445": 33, "09619141": 42, "096426": 19, "096462": 35, "096692": [16, 21, 30], "096722": 33, "096858": 33, "096927": 34, "096960": 35, "096990": 28, "096997": 43, "097": 43, "09706504": 43, "097088": 45, "097184": 33, "097293": [16, 21, 30, 31], "097516": [16, 21, 30], "097707": 33, "097763": 33, "097938": 19, "098": [32, 43], "098019": 14, "098152": 33, "098307": 35, "098326": [15, 20, 29, 43], "098559": 33, "098629e": 33, "098663": 33, "098787": 24, "0989147678053208": 32, "098915": 32, "098950": 33, "098966": [16, 21, 30], "099": 36, "099230": 37, "099240": [16, 21, 30, 31], "099454": 33, "099558": [16, 21, 30, 31], "099685": 35, "099723": [16, 21, 30], "099729": 33, "099749": 44, "099802": 33, "099869": 33, "0x1227a36e0": 8, "0x1577111f0": 33, "0x16888d4c0": 33, "0x168921100": 33, "1": [1, 7, 8, 9, 10, 23, 24, 25, 37, 42, 44, 47, 48, 49, 54], "10": [1, 4, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54], "100": [12, 13, 15, 16, 20, 21, 23, 24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 46], "1000": [12, 14, 15, 19, 20, 28, 29, 31, 32, 33, 34, 35, 37, 38, 43, 44, 45, 46, 48, 49], "10000": [12, 13, 23, 27, 31, 32, 33, 35, 44], "100000": [12, 15, 20, 29, 31, 32, 33, 35, 44], "1000000": [25, 33], "100103": 44, "100105": 33, "100139": 31, "100146": 44, "100248": [15, 20, 29], "100275": 38, "1004": [15, 20, 29], "1005": 44, "1006": 44, "1007": 44, "1008": 44, "10083": 23, "100882": 34, "1009": 44, "10092665203438746": 35, "101": [1, 9, 39, 43, 45, 54], "1010": 44, "1012": 44, "101259": 35, "101387": 19, "1014": [24, 33, 43], "1015": [24, 43, 44], "1016": [24, 43, 44], "101688": 33, "1017": [24, 43, 44], "101772": 14, "101796": 35, "1018": [24, 43, 44], "101810": 28, "101832": 33, "101894": 34, "1019": [24, 43, 44], "102": [25, 34, 35], "1020": [23, 24, 33, 38, 43, 44], "102044": 38, "1021": [24, 43, 44], "102135": 34, "1022": [24, 43, 44], "1023": [24, 43, 44], "1024": [24, 31, 43, 44], "102435": [15, 20, 29, 35], "102474": 31, "10247431": 31, "1025": 44, "10254": 44, "1026": [32, 44], "1027": 44, "10273": 35, "10274": 34, "1028": 44, "1029": 44, "103": 45, "103023": 33, "1031": 44, "103219": 38, "103222": 43, "1034": 38, "103439": 31, "1039": 44, "104": [15, 16, 20, 21, 29, 30, 36, 39, 43], "1040": [16, 21, 30], "104070": 35, "1041": [35, 37, 44, 48], "10416666666666667": 41, "1042": 33, "1044": [12, 17, 26], "104596": 33, "104643": 35, "105": [23, 36], "1050": [13, 23, 27], "105080": 38, "105089": 31, "10513": 44, "1052": 25, "1053": [25, 48], "105314": 44, "1054": 25, "1055": 25, "10556679": 39, "1056": 25, "105656": 37, "1057": 25, "1058": 25, "10584063": 43, "1059": 25, "106": 25, "106000": [16, 21, 30], "106023": 35, "106112": 44, "106180": 44, "106319": 44, "106322": 44, "106424": 44, "10644531": 42, "106452": [15, 20, 29], "10645223": [15, 20, 29], "10653": 44, "106705": 44, "106764": 33, "1068": 48, "106816": 44, "1069": 48, "10693359": 42, "106996": 33, "107": 36, "1070": 38, "107050": 44, "107292": 44, "107502": 44, "1076": [23, 31], "107718": 33, "10781": [36, 37], "107917": 44, "10793260e": 43, "107947": 35, "107985": 35, "107991": 34, "108": [12, 17, 26], "1080": [12, 17, 26], "10800": [12, 17, 26], "1085": 32, "10868": 44, "108681": [15, 20, 29], "1089": 35, "10910": 44, "10931": 31, "109526": 34, "109580": 24, "1099": 35, "10_000": 45, "10th": [33, 34, 36, 37], "10x": 34, "11": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 48, 50, 52, 54], "110": [32, 43], "1101": 25, "1102": 25, "1103": 25, "110316": 44, "110319": 44, "1104": [15, 20, 25, 29], "11057": 44, "1106": [25, 38], "110645": 35, "1107": 25, "1108": 25, "1109": 25, "110915e": 35, "111": [16, 21, 30, 33, 34, 35, 45], "1110": 25, "1111": 25, "111111": 16, "1112": 25, "11121453": 39, "111215": 39, "111220": 44, "1114": 25, "111438": 38, "1115": 25, "111543": 35, "1116": 25, "112": [15, 16, 20, 29], "1122": [35, 37, 48], "1123": [33, 48], "112441": 33, "112490": 33, "112527": 37, "112848": 35, "1131": 23, "11331": 48, "11336331e": 37, "113600": [16, 21, 30, 31, 53], "1138": 38, "113837": 35, "1139": [35, 37, 46], "113949e": 45, "114": [16, 21, 30], "1140": [12, 17, 26, 35, 37, 46], "114000": [16, 21, 30, 38], "114079": 33, "114214": 33, "114507": 43, "11457": [35, 37, 46], "114757": 23, "114766": 37, "114836": 38, "114966": 37, "115": 31, "1150": [12, 17, 26], "115083": [16, 21, 30], "115089": 44, "11509": 35, "115090": 44, "115091": 44, "115092": 44, "115183": 33, "115276": 45, "115401": 35, "115406": [15, 20, 29], "115428": 44, "115956": 32, "116": [16, 21, 30], "116145": 38, "116167": 32, "116443": 38, "116497": 35, "11664": 48, "11693": 35, "117": [16, 21, 25, 30, 31, 32, 38, 53], "117058": 32, "117379": 33, "117380": [16, 21, 30], "117412": 35, "117528": 38, "11758": 44, "117612": 43, "117712": 44, "117816": [16, 21, 30], "117899e": 35, "1179": [16, 21, 30], "118": [16, 21, 25, 30, 31, 32, 35, 37, 38, 46], "1180": [13, 23, 27], "118182": [16, 21, 30, 31], "118347": 35, "118450": 34, "118563": 38, "11886432": 33, "118874": 35, "118934": 34, "11898": 34, "119": [16, 21, 30, 31, 32, 38, 44, 53], "1190": [16, 21, 23, 30], "119049": 44, "11909976": 39, "119100": 39, "119121": 24, "11914062": 42, "119189": 24, "119400": [16, 21, 30], "119570": 38, "119911": 44, "11th": [34, 36, 37], "12": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51, 52, 54], "120": [15, 16, 20, 21, 25, 29, 30, 32, 35, 36, 43, 44, 49], "1204": [15, 20, 29], "120769e": 35, "121": [12, 16, 17, 21, 23, 25, 26, 30, 31, 32, 33, 36, 38, 44], "1210": 33, "121056e": 35, "121084e": 35, "121351": 37, "12138": [16, 21, 30], "1214": 35, "121438": 45, "12150684": 32, "121531": 34, "121599": 37, "121628": [15, 20, 29], "1217": 45, "12178": 38, "121846": 37, "121985": 35, "122": [12, 13, 14, 16, 17, 19, 21, 23, 25, 26, 27, 28, 30, 31, 38, 43, 51], "1220": [12, 16, 17, 21, 26, 30, 33], "1222": 33, "122307": [16, 21, 30, 31], "122331": 35, "122668": 33, "123": [4, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53], "123049e": 23, "123367": 35, "1235387316046016": 33, "123539": 33, "124": [16, 21, 25, 30, 42], "1240": [12, 17, 26], "1241": [35, 38], "1243": [16, 21, 30], "12436984": 31, "124370": 31, "1247": 33, "12498": 37, "124982": 38, "125": [8, 25, 35], "1250": [16, 21, 30, 31, 53], "125000": 23, "12508": [35, 37, 46], "125440e": 35, "125476": [15, 20, 29], "125523": 44, "1256": 49, "125617": 44, "125644": 35, "1258": 45, "126": [25, 38], "126238": 38, "126398": [16, 21, 30, 31], "126488": 39, "12649": [16, 21, 30], "126500": [16, 21, 30], "126563": 33, "126808": [16, 21, 30, 31], "127": [14, 16, 19, 21, 25, 28, 30, 32, 33, 47], "127086": [16, 21, 30], "127087": 45, "1271": 36, "127107": 37, "127226": 31, "127242": 35, "1273": 37, "127326": 35, "1274": 38, "127418": 35, "127439": 35, "127441": 35, "127614": 35, "12761659": 35, "12768": 23, "127878": [15, 20, 29], "1279": 35, "1280": [16, 21, 30, 33, 35], "1281": 35, "128188": [16, 21, 30, 31], "128384": 35, "128528": 35, "1287": 23, "128820": 44, "128828": 44, "128829": 44, "128830": 44, "12890625": 42, "128984": 35, "129": [15, 20, 29, 32, 38, 45], "1290": [16, 21, 30, 31], "12906": [12, 17, 26], "129257": 35, "12927": [12, 17, 26], "129300": [16, 21, 30, 31, 53], "129459": 38, "129600": 35, "129900": 34, "129904": 35, "129985": [16, 21, 30], "12th": [34, 36, 37], "13": [1, 8, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 40, 41, 42, 44, 45, 48, 50, 53], "130": [12, 13, 14, 15, 16, 17, 19, 20, 21, 26, 27, 28, 29, 30, 31, 33, 35, 37, 38, 46, 51, 53], "1300": [35, 37, 46], "1302": 34, "130395": 44, "1304": [15, 20, 29, 45, 46], "130432": 44, "1306": 47, "130690e": 35, "1307": 35, "130991": 34, "131": [16, 21, 25, 30, 36, 44, 45], "131000": 35, "13107": 44, "131275": 34, "1313": 35, "1314": [35, 37, 46], "131607": [35, 37, 46], "131773": 45, "1319796954314723": 36, "132": [16, 45], "1320": 38, "1321": [12, 17, 26], "132158": 35, "132292": 38, "13229595e": 37, "13255": 44, "132875": [16, 21, 30, 31], "132886": 44, "133": [33, 45], "133000": 35, "133210": 33, "133270": 35, "133337": 35, "133562": 45, "13392236": 43, "134": [13, 14, 19, 27, 28, 31, 32, 51], "1340": [13, 23, 27], "134061": 38, "13407": 37, "13418": 16, "134287": 34, "1346": [16, 21, 30, 35, 37, 38, 45, 48], "134615": 32, "134658": [16, 21, 30], "1347": 48, "13476562": 42, "134798": 34, "134894": 44, "135": [44, 45], "1350": 23, "135134": 44, "135197": 44, "13521135": 37, "135299": 38, "135305": [16, 21, 30, 31], "135384": 35, "13540": 23, "135422": 35, "1357": [12, 17, 23, 26], "136": [16, 21, 30, 31], "1360": [13, 23, 27], "1364": 25, "1365": 25, "1366": 25, "13665": [16, 21, 30, 31, 53], "1367": 25, "136714": 34, "1368": 25, "1369": 25, "1370": [12, 15, 17, 25, 26, 29, 33, 45], "13704": [35, 37, 46], "1371": 25, "1372": [25, 46], "1373": 25, "137339": 34, "1374": 25, "137410": 39, "1375": 25, "137500": [16, 21, 30, 31, 53], "1376": 25, "1377": 25, "1378": [25, 35], "1379": 25, "138": 48, "1380": [12, 17, 25, 26], "1381": 25, "138103": 43, "1382": 25, "1383": [25, 33], "1384": 25, "1385": 25, "138503": 38, "138528": 32, "138564": 23, "1386": 25, "1387": 25, "1388": 25, "138876": 45, "1389": [16, 21, 25, 30, 35, 37], "139": [16, 21, 30, 48], "1390": [12, 17, 26], "139297": 34, "139317": 34, "139322": 34, "139349": 34, "13941": 34, "139554": 34, "1396": 33, "1397": 33, "14": [1, 12, 13, 14, 15, 16, 17, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 40, 41, 42, 43, 44, 45, 50], "140": [16, 21, 30], "140185": 38, "140371": 24, "1404": [15, 20, 29, 45], "1405": 38, "1406": [16, 21, 30, 35, 37], "140641": 44, "140828": 23, "140953": 44, "141": [16, 21, 30, 32], "1410": 23, "141232": 44, "14159265358979323": 8, "14160": 34, "141851": 44, "142": 36, "142051e": 23, "142193": 44, "142199": 44, "1423": 34, "142398": 44, "142467": [14, 19, 28], "1427": [23, 46], "142806": 44, "142857": 31, "14289": [16, 21, 30, 31, 53], "143": [33, 34], "143693": 44, "143803": 38, "1438387200": 44, "1438398000": 44, "1438408800": 44, "1438419600": 44, "1438430400": 44, "1438441200": 44, "1438452000": 44, "1438462800": 44, "1438473600": 44, "1438484400": 44, "143975": 44, "144": [12, 17, 26, 33], "144000": [35, 37, 46], "1441": 48, "144199": 44, "144686": 37, "14471": [16, 21, 30, 31, 53], "144729": 44, "144730": 44, "144731": 44, "144732": 44, "144733": 44, "144750": [15, 20, 29], "14485": 35, "145": [24, 44], "145186": 24, "1452": 38, "145425": 35, "145454": 44, "145455": 44, "145456": 44, "145457": 44, "145458": 44, "145459": 44, "145460": 44, "1457": [16, 21, 30, 31, 45, 53], "14579": 38, "1458": [16, 21, 30, 31, 53], "145833": 41, "146": [12, 17, 24, 26, 36, 46], "1460": [35, 45], "14648438": 42, "1465": [16, 21, 30, 31, 53], "146656": 44, "1467": 38, "146767": [34, 37], "146809": 34, "146830": 34, "14690": 31, "147": [24, 37, 46], "147166": [36, 37], "14716638": 37, "1472": 25, "147226": 24, "147616": 34, "147641": 35, "147737": 43, "147893": [16, 21, 30], "147898": 34, "147917": 34, "148": [15, 24, 25, 29, 33, 37, 49], "14813": 44, "148141": 36, "148343": 35, "148349": 45, "14841": 34, "149": [24, 45], "1490": 23, "149122": 47, "14970": [16, 21, 30], "149788": 37, "149822": [16, 21, 30, 31], "14999": [16, 21, 30], "14th": [12, 13, 17], "15": [1, 8, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 45, 48, 50, 51, 54], "150": [15, 24, 29, 33, 35, 43, 46], "1500": 25, "150000": [34, 41], "150115": 33, "15026771": 35, "150395": [15, 20, 29], "1504": [15, 20, 29], "1505": [16, 21, 30], "1509": 23, "150mb": 34, "150p": [12, 17, 26], "151357": 38, "1514": 47, "152": [25, 44], "1520": 33, "1523300141": 23, "1523300157": 23, "152401": 34, "152691": 24, "15278": 16, "152859": 34, "153": 25, "1530": [12, 17, 23, 26], "1534": [16, 21, 30], "15377": [16, 21, 30, 38], "154": 25, "1540": [12, 17, 26], "154076": [34, 37], "154105": 38, "15429": 44, "154386": [16, 21, 30, 31], "1545": 38, "154795": [35, 37, 46], "154842": 45, "154883": 24, "155": [12, 17, 25, 26, 33], "15500": 35, "155178e": 35, "15559528e": 37, "155624": 35, "155900": 23, "156": [16, 21, 25, 30, 33, 34], "1560": 23, "1562": 33, "156311e": 35, "1564": 33, "15661": 44, "157": [12, 17, 25, 26, 33, 43], "157008": 35, "157157": 48, "157234": 38, "15725": [16, 21, 30, 38], "157572": 24, "157712": 34, "15775": 44, "1578": 37, "15795": [34, 37], "158": 33, "1580": [12, 17, 26], "1582": 37, "158867": 44, "158982": 35, "159": 33, "1590": [15, 29, 33], "15915": 44, "159751": 24, "15992": 37, "15pm": 1, "16": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 41, 42, 44, 45, 47, 48, 50, 51], "160": [14, 15, 19, 28, 29, 32, 33, 35, 37], "1600": 23, "160000": [35, 37, 46], "160258": [14, 19, 28], "160282": 38, "1604": [15, 20, 29], "160506": 34, "160634": 43, "16063983": 31, "160640": 31, "160727": 37, "160729": 44, "161": [16, 21, 25, 30], "1610243052583638": 32, "16111330565237164": 32, "1613": [16, 21, 30], "161300e": 23, "161429": 24, "16153": 44, "16157": 44, "16160": 44, "161606": [16, 21, 30, 31], "161782": 34, "1619": 33, "161931": [35, 37, 46], "162": [12, 17, 26], "162000": 35, "162007": 48, "162214": 46, "162330": 34, "162363": 34, "162667": [34, 37], "16269": 16, "1627": 38, "162904": 45, "163": 23, "1631": 33, "163195": [16, 21, 30, 31], "163397": [16, 21, 30, 31], "1634": [16, 21, 30, 31, 33, 53], "16358": 44, "164": [38, 43], "1645": 32, "16460": 38, "164679": 34, "165": [32, 35], "1650": [15, 29, 33], "16507": [32, 38], "16508": [32, 38], "16509": [32, 38], "16510": [32, 38], "16511": [32, 38], "16512": [32, 38], "165198e": 35, "1652": [14, 19, 28, 32], "16533": 44, "165485": 37, "165617": 44, "165811": 33, "166": 19, "16630": 38, "166631": [16, 21, 30, 31], "16686": 16, "167": [14, 19, 25, 28], "167214": [15, 20, 29], "167241": 48, "167600": 38, "167620": 43, "168": [25, 35], "1680": [13, 23, 27], "168151": 43, "168196": [16, 21, 30, 31], "168244": 37, "1687": 33, "169": [14, 19, 25, 28, 32, 38], "1690": [12, 13, 17, 23, 26, 27], "169269e": 45, "169421": 33, "169693": [15, 20, 29], "169748": 32, "16991815": 8, "1699181533555938": 8, "17": [1, 4, 8, 13, 15, 16, 20, 21, 23, 25, 27, 29, 30, 31, 32, 33, 34, 35, 38, 42, 44, 45, 50, 53], "170": [16, 21, 30, 40], "170100": [16, 21, 30, 31, 53], "170277": [36, 37], "1704": [15, 20, 29], "17054987": 43, "170670": 35, "170931": 43, "171": [12, 17, 26, 43], "17144": 44, "171468": [35, 37, 46], "1715": 33, "171657": [14, 19, 28], "171899": 45, "1720": [16, 21, 30], "17205": 44, "1724668": 42, "172792": 34, "17290": 23, "173": [15, 29, 33], "173025": 33, "17393037": 8, "1739787032867638": 33, "173979": 33, "174": [12, 15, 17, 26, 29, 33], "174590": 34, "17476": 16, "174766": 38, "1750": [16, 21, 30, 47], "175000": [35, 37, 46], "17518": 44, "175459": 23, "176": [16, 21, 30], "176026": 24, "1766": 35, "176924": 45, "177": 38, "17730": [16, 21, 30, 38], "177709": 45, "178": [12, 17, 26, 35], "17847": 16, "178494": 35, "1788": 23, "17896": 44, "179": [36, 45], "179080": 34, "179123": [15, 20, 29], "179152": 25, "179300": [16, 21, 30], "179631": 23, "179730": 33, "17973005068132514": 33, "179802": 35, "18": [1, 12, 13, 14, 15, 16, 17, 19, 20, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 41, 44, 45, 46, 50, 53], "180": [33, 35, 43], "1800": [12, 13, 15, 17, 23, 26, 27, 29, 33], "18000": 44, "180000": [13, 23, 27], "180279e": 35, "180388": [15, 20, 29], "1804": [15, 20, 29], "18066406": 42, "180900": 38, "180926": 24, "18096": 44, "181": 45, "18113": 44, "18116": 44, "1813": 33, "182": [44, 45], "18201414": 37, "182382": 24, "18245": 44, "182639": 35, "182648": 35, "1830": 23, "18311": 44, "18313": 44, "18317085": 8, "183179": 45, "183423": [15, 20, 29], "183471e": 35, "18365": 31, "18391": [16, 21, 30, 31], "184": [44, 45], "1840": [12, 17, 23, 26], "184405": 37, "1847": 31, "185": [14, 19, 45], "185000": 14, "185155": 37, "185175": 45, "18533": 44, "1854": 33, "185707": [15, 29, 33], "18571": [16, 21, 30, 31], "18572": [16, 21, 30, 31], "18573": [16, 21, 30, 31], "18574": [16, 21, 30, 31], "18575": [16, 21, 30, 31], "18576": [16, 21, 30, 31], "1858": 38, "185868": 38, "185975": 37, "18597545": 37, "186": 25, "186024": [12, 17, 26], "186814": 34, "186899": 34, "187": [14, 19, 28, 32, 36], "1870": 33, "187000": [16, 21, 30], "1872": 35, "1875": [32, 42], "187503": 44, "187663": [15, 20, 29], "187700": [16, 21, 30], "188": [12, 14, 17, 19, 26, 28, 32], "1880": 33, "1886": 32, "1887": [34, 37], "189": 25, "18955": 44, "189981": 35, "19": [1, 8, 12, 13, 14, 15, 17, 20, 23, 26, 27, 28, 29, 31, 33, 34, 35, 38, 41, 42, 44, 45, 48, 50], "190": [14, 19, 28, 35, 38], "1900": 23, "19000e": [15, 29], "1901": [12, 17, 26], "190319": 38, "19032": 44, "1904": [15, 20, 29], "190617": [16, 21, 30, 31], "190833": 19, "191": [16, 19, 21, 28, 30], "1910": 23, "1911": 38, "191169": [35, 37], "191204": 38, "191250": [14, 19, 28], "191396": [15, 20, 29], "191700": 38, "1918": 31, "191k": 37, "1920": [12, 17, 26], "19213263": 31, "192133": 31, "19266": 44, "1927": 48, "1928": 48, "193": 43, "1930": [12, 17, 26], "193021": 34, "193122": 34, "193247": 38, "1933": [13, 23, 27], "193346": 37, "1934": 23, "193427": 33, "19365": 44, "193704": 44, "19380": 44, "1940": 31, "194002": [15, 20, 29], "194034": 44, "194040": [16, 21, 30], "19422": 37, "19433594": 42, "1944": 23, "1945": 35, "1946": [12, 17, 26, 35], "194710": 35, "1948": 23, "19485": [16, 21, 30], "194914": 24, "194985": 35, "195": [16, 21, 30], "1950": 35, "1951": [13, 23, 27], "195228": 31, "1953": [33, 35], "19536": 34, "1954": 42, "1954400510": 23, "1955": [13, 23, 27], "195564": 38, "1957": 42, "1959": [12, 17, 23, 26], "19591": 38, "1960": [13, 23, 27], "1962": 42, "1963": 33, "196385": 37, "1965": [13, 23, 27], "196599": 35, "1966": 35, "196717": 43, "196739": 44, "1968": [12, 17, 26], "196963": 24, "1970": [32, 35, 44], "197083": 14, "1971": 23, "1972": 35, "1975": 23, "197500": 19, "197649": 38, "1977": [12, 17, 26, 45], "19777": [36, 37], "19781": 44, "198": 43, "198127": 35, "1984": 35, "1985": 35, "1986": 23, "198629": 43, "198645": 45, "1987": [12, 13, 17, 23, 26, 27], "1989": [12, 17, 26], "198924": [16, 21, 30, 31], "199": [12, 15, 17, 20, 26, 29, 34], "1990": [15, 29, 32, 33], "1991": [13, 23, 27, 36], "1992": 44, "1993": 35, "199364": 34, "1994": [12, 17, 26], "199412": [24, 45], "199413": [15, 29, 33], "19966": [16, 21, 30, 31, 38], "1997": [23, 32, 33], "199771": 37, "1_000_000_000": 33, "1d": [25, 43], "1e": [33, 35], "1e3": 33, "1e4": 33, "1h": [16, 21, 30, 31, 38], "1st": [8, 34, 36, 37, 44], "1stflrsf": [35, 37, 46], "1v": 49, "1v2": 49, "1v3": 49, "2": [1, 4, 7, 8, 9, 10, 23, 24, 25, 36, 37, 38, 42, 43, 44, 47, 48, 49, 54], "20": [1, 4, 8, 13, 14, 15, 16, 18, 19, 20, 21, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 45, 48, 49, 50, 52, 53, 54], "200": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 42, 43, 46, 51, 52, 53], "2000": [15, 20, 25, 29, 33, 34, 35, 36, 37, 38, 43, 47, 49], "200000": [33, 44], "200000e": 23, "2003": 23, "200326e": 35, "2004": [23, 35], "200458": 24, "200475": 34, "2005": 23, "2006": [35, 37, 46], "2007": [23, 35, 37, 44, 46], "2008": [23, 35, 37, 44, 46], "200876": 31, "20087625": 31, "2009": [23, 35, 37, 44, 46], "200978": [15, 20, 29], "201": [1, 15, 20, 29, 54], "2010": [35, 37, 44], "20113": [16, 21, 30, 31, 53], "2012": [8, 16, 21, 30, 33, 54], "2013": [23, 42, 44], "201332": 40, "2014": [12, 17, 23, 26, 36, 44], "20140521t000000": 23, "20140623t000000": 23, "20141013t000000": 23, "20141015t000000": 23, "20141209t000000": 23, "2015": [23, 43, 44], "20150116t000000": 23, "20150218t000000": 23, "20150223t000000": 23, "20150225t000000": 23, "20150630": 44, "2016": [8, 43, 44], "20160101": 44, "2017": [37, 44], "201810": 34, "201862": 38, "202": [1, 15, 20, 29, 31, 54], "2020": 48, "2022": 44, "202247": 24, "2022w2": [12, 17], "2023": [1, 44], "2024": [0, 1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53], "20248": [16, 21, 30], "2024w1": [0, 10, 12, 43], "2024w2": [10, 12, 17], "2025": 1, "20274": 44, "202839": 34, "203": [1, 15, 20, 29, 54], "20310": 44, "20311": 38, "20319": 44, "203265": 37, "20334": 44, "203421": 35, "203500": [16, 21, 30], "20357847293371892": 32, "204": [1, 13, 14, 15, 19, 20, 27, 28, 29, 33, 42, 51, 54], "204167": [14, 19, 28], "2043": 45, "204302": 44, "20433": 38, "204583": [14, 19, 28], "2046": 31, "204600": [15, 29, 33], "204692": 35, "204734": 34, "20485": 44, "205": [13, 14, 15, 19, 20, 27, 28, 29, 51], "205000": [16, 21, 30, 31, 35, 37, 46, 53], "205059": 38, "20509": 44, "20514": 44, "205144": 38, "205323": 44, "205479": 32, "205597": 35, "20564": 44, "206": [13, 14, 15, 19, 20, 27, 28, 29, 33, 34, 47, 51], "206019": 24, "206041": 37, "206073": 34, "206099": 33, "20620": 44, "206292": [16, 21, 30], "20639": 38, "2064": [16, 21, 30], "20640": [32, 38], "206724": 45, "20683258": 32, "20694": 44, "20699": 23, "207": [13, 14, 15, 16, 19, 20, 21, 27, 28, 29, 30, 33, 42, 43, 51], "207039e": 35, "2071": 38, "207814e": 35, "2079": 23, "20794": 44, "208": [13, 14, 15, 19, 20, 27, 28, 29, 32, 33, 51], "209": [12, 13, 14, 15, 17, 19, 20, 26, 27, 28, 29, 33, 51], "209221": 46, "209583": 28, "209746": 34, "209903": 38, "20analysi": 45, "20assumpt": 45, "20hazard": 45, "20intro": 45, "20learn": 43, "20lifelin": 45, "20with": 45, "21": [1, 12, 13, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 29, 30, 31, 34, 35, 38, 39, 41, 42, 44, 48, 54], "210": 33, "210000": 14, "210001": 34, "210240": 33, "210272": 38, "210286": 24, "210417": 19, "210591": [16, 21, 30, 31], "210779": 44, "21086181023099526": 32, "211": 33, "2110": [16, 21, 30], "211250": [14, 19, 28], "211343": 38, "211544": 34, "211724": 24, "211892": [16, 21, 30, 31], "212": [1, 14, 28, 33, 54], "212385": 37, "212581": 38, "21274": 44, "212870": 35, "212975": 35, "213": [14, 33, 43, 44], "2130": [12, 17, 26], "21353": 44, "21382972": 36, "21389": 44, "213896": 23, "2139": [16, 21, 30, 31, 53], "214": [12, 17, 26, 31, 33], "21405": 44, "21436": 23, "2144": 33, "21450": 23, "214740": [16, 21, 30], "214769": 43, "214821": 44, "214852": 34, "2149": 25, "215": 33, "2150": 25, "2151": 25, "215167": 24, "2152": 25, "215245": 35, "2153": 25, "21530": 44, "2154": 25, "215412": 35, "21549": 44, "2155": 25, "2156": 25, "21571": 44, "21581": 44, "21582031": 42, "215865": 37, "21596": 44, "216": 33, "21603": 44, "21605": 44, "21608": 23, "21609": 23, "21610": 23, "21611": 23, "21612": 23, "216123": 45, "21613": [13, 23, 27], "21616484": 49, "21617": 44, "216250": 19, "216346": 37, "21634631": 37, "216585": [16, 21, 30], "216596": 44, "21668": 44, "21670": 44, "216718": 34, "216728": [16, 21, 30], "21694": 44, "21697": 44, "217": [25, 47], "2170": [13, 23, 27], "217083": 14, "217334": 31, "21733442": 31, "2173627": 42, "217500": 14, "21767954": 37, "21768": [37, 44], "217680": [36, 37], "21774": 44, "218": 25, "218207": [16, 21, 30, 31], "21847": 44, "21872": [35, 37, 46], "218760": 37, "218830": [16, 21, 30], "218867": 24, "219": [25, 38], "2190": [16, 21, 30], "2192": 33, "219500e": 23, "219512": 38, "219700": 38, "219714": 24, "21972656": 42, "219845e": 35, "22": [15, 16, 20, 21, 25, 29, 30, 31, 33, 34, 35, 36, 37, 38, 42, 44, 45, 48, 49, 53, 54], "220": [25, 28], "2200": 25, "22001": 37, "220392": 45, "22057": 44, "2206": 45, "22078": 44, "221": 25, "2210": [12, 17, 23, 26], "22114": 44, "221329": 35, "221348": 44, "2214": 48, "22154": 44, "221622": [16, 21, 30, 31], "22168237": 49, "221760": 24, "221900": [13, 23, 27], "222": [1, 25, 54], "22219": 44, "22221894": 35, "222222": [16, 21, 30], "22225": 44, "222307": [16, 21, 30], "222500": [19, 28], "22260": 44, "222647": [35, 37, 46], "2229": 32, "222963e": 35, "223": 25, "22305705": 36, "22320": 44, "223333": [19, 28], "223460": 45, "223750": [19, 28], "223804": 37, "224": [25, 33, 43], "22452": 44, "2246468746": 28, "224662": 35, "22471154513694713": 32, "224865": [35, 37], "225": 43, "225301e": 35, "2254": [16, 21, 30], "22550": 44, "226": 33, "226415": [16, 21, 30], "226789": 45, "2268": 36, "22697768": 31, "226978": 31, "2270": 33, "227143": [16, 21, 30], "2272": [34, 47], "227304": 44, "22741": 38, "227559": [35, 37, 46], "227836": 34, "22788": 44, "22811601": 32, "22826": 44, "228329": 34, "2285": 44, "22851562": 42, "228603": 35, "228750": [14, 19, 28], "229": 43, "229000": [16, 21, 30], "22910": 44, "229102": 37, "229167": 14, "2293467570951035": 36, "2295": 44, "229583": [14, 19, 28], "229718": 37, "23": [1, 15, 16, 20, 21, 23, 25, 29, 30, 31, 32, 33, 34, 35, 38, 42, 44, 45, 53], "230": [15, 29, 33], "2300": [12, 17, 26], "230000": 23, "23011": 37, "2305": 37, "2307": [14, 19, 28, 32], "2309": 44, "23091772": 36, "231": [1, 54], "2310": [23, 44], "2311": 44, "2312": 44, "2313": 44, "23175": 44, "231815": 37, "232": 25, "232075": 24, "232143": 31, "232751": 45, "23290": 44, "233": [13, 23, 27], "2334": 16, "234": 45, "234040": 34, "234303": 23, "234436": 45, "235": [25, 38], "235096": [16, 21, 30, 31], "235152": [15, 20, 29], "235417": 28, "235706": 38, "235833": 14, "236": [15, 25, 29, 33, 45], "2360": 23, "236096": 43, "236174": 38, "236210": 39, "23621041": 39, "23640124": 32, "236456": [16, 21, 30], "23654": [34, 37], "236960": 33, "237": [25, 34, 45], "237935": 37, "238": [25, 34, 45], "238192": [34, 37], "2388": 23, "2389": 31, "239": [25, 45], "23902": 44, "239082": 24, "23941": 44, "239944e": 35, "24": [1, 10, 12, 15, 16, 17, 20, 21, 24, 25, 26, 29, 30, 34, 35, 36, 37, 38, 42, 43, 44, 45], "240": 45, "2401": 38, "240893": 38, "241": 45, "241489": 45, "241620": 34, "24182": 44, "242015": [36, 37], "242083": 28, "242169": 34, "242381": 44, "242740": 24, "24295676": 31, "242957": 31, "242996": [16, 21, 30, 31], "243": 44, "2431": 16, "243243": 35, "2435": 38, "2436": 38, "24395": [36, 37], "24397122221206388": 44, "244": 44, "244592": [15, 20, 29], "2447": 36, "244814": 45, "245": 44, "2451": 33, "245329": 35, "245521": 34, "245635": 24, "245686": 34, "246": [44, 48], "246332": 35, "246486": 25, "246646": 33, "246646103936": 33, "246653": 33, "247": 44, "247119": 44, "247439": 39, "24743939": 39, "247690828913": 33, "247691": 33, "248": 44, "248328": 36, "248333": [19, 28], "2484": [12, 17, 26], "248457": [35, 37, 46], "248609": 35, "248664": 38, "2487200875": 23, "2488": [15, 20, 29], "248999": 45, "249": 48, "2496": [14, 19, 28, 32], "249601e": 35, "249618e": 35, "249720": [15, 20, 29], "24h": [34, 47], "24th": [12, 17], "25": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53], "2500": [8, 25, 48], "250000": [16, 21, 23, 30, 34, 35], "25031": 44, "25037": 44, "2506": [13, 14, 19, 27, 28, 51], "250900": 35, "251093": 33, "251158e": 35, "2516": 36, "25176": 44, "251769": 43, "252": 47, "252042": 38, "25214": 44, "252160": [15, 20, 29], "252859": 37, "2530": [12, 17, 26], "2533": [14, 19, 28, 32], "253312": [16, 21, 30, 31], "253432": 37, "253724": [15, 20, 29], "253914": 35, "254380": 45, "254443": 34, "255": [16, 21, 24, 30], "2550": 23, "2551": 48, "255134": 43, "2556": 36, "255751": 38, "255889": 44, "256": [12, 17, 26, 43], "25622": 44, "256263": [36, 37], "256333": [16, 21, 30], "256437": 38, "25658": 38, "256813": [15, 20, 29], "257": [13, 23, 27], "2570": [12, 13, 17, 23, 26, 27], "257024": 33, "257103": 34, "2574": 38, "257787": 25, "2580": [12, 17, 26], "258225": 44, "25823": 34, "258387": 37, "2584": 42, "258427": [15, 20, 29], "259": [35, 38], "259026": 24, "25904": 44, "2590575478171884": 32, "259085": 24, "259286": [15, 20, 29], "259500": [16, 21, 30], "259520": 24, "26": [8, 12, 15, 17, 20, 21, 25, 26, 29, 30, 33, 34, 35, 36, 37, 38, 39, 42, 44, 45, 48], "2600": [16, 21, 30, 31, 53], "260258": 38, "26048": 37, "260572": 35, "26063": 44, "260890": [35, 37, 46], "261035": 35, "261953": 44, "262": [35, 37, 45, 46], "262079e": 35, "262156e": 35, "262269e": 35, "2623": 35, "262361": 38, "262500": 35, "262990": 34, "263": 35, "2630": [16, 21, 30], "263000018": 23, "263541": 45, "263600": [16, 21, 30], "26370005": 32, "263736": 45, "263742e": 35, "26376": 44, "264195": 45, "264283e": 35, "26447953": 31, "264480": 31, "265": 36, "265273": 32, "265483": 24, "266120": 44, "266135": [16, 21, 30, 31], "2670": 33, "267612e": 35, "268": 33, "2683": 34, "26831": 44, "2691": [13, 14, 19, 27, 28, 51], "26919": 38, "269880": [15, 20, 29], "269972": [35, 37, 46], "27": [1, 8, 15, 16, 20, 23, 25, 29, 31, 33, 34, 35, 42, 44, 45], "270093": 33, "270093376167": 33, "27021": 44, "270270": 41, "27048": 34, "2705": 33, "271037": 38, "271287": 44, "271500": 38, "271738e": 35, "2720": [13, 23, 27], "27206": 44, "27263": 37, "272667": [16, 21, 30, 31], "2730": [16, 21, 30], "27304": 23, "273382": [16, 21, 30, 31], "273606": [16, 21, 30, 31], "273890": 43, "2739": [18, 24], "273962": 38, "274": [16, 21, 30, 31, 44, 53], "274404": [16, 21, 30], "275008": 44, "27502379069": 35, "275290": 34, "275352": [15, 20, 29], "275410": 32, "2759": 37, "276": [16, 21, 30], "27610135": 42, "27638": 44, "27652": 34, "276687": 35, "27676": [34, 47], "27678": [34, 47], "276943e": 35, "27697": [34, 47], "2770": 33, "27705": [34, 47], "27715": [34, 47], "277381": [15, 20, 29], "2777": 45, "278": 48, "278441": 44, "278634": 34, "27874871715903093": 32, "278755": 31, "27875502": 31, "2788": [14, 19, 28, 32], "2794": 32, "28": [1, 15, 16, 20, 21, 29, 30, 31, 32, 33, 34, 35, 38, 39, 42, 44, 45], "280": [16, 21, 30, 38, 48], "2800": 8, "280028": 38, "280310": [16, 21, 30, 31], "2806": 33, "280618": 34, "2807": 45, "280801": 45, "281": [16, 21, 30], "28122025543": 35, "281583": 35, "2817": 37, "2820": 33, "282021e": 35, "2822": 37, "282600": 45, "283119e": 35, "28327": 44, "283421": 35, "2836": 37, "28362": 44, "283857": [15, 20, 29], "283921": [16, 21, 30], "284": [38, 44], "2845": 45, "2846": 48, "2847": 48, "285": [16, 21, 30, 31, 44, 53], "285263": 37, "28526302": 37, "285467": [35, 37, 46], "28571429": [13, 18, 27], "286": [14, 15, 19, 28, 29, 33, 44], "286000": 33, "286200": 38, "286326": 24, "286416": 31, "2865025": 49, "286821": [15, 20, 29], "287": 44, "287031": 44, "287079e": 35, "287344": [16, 21, 30, 31], "287500": 38, "28753559": 42, "288": 44, "288002": 44, "288462": 32, "28854": 44, "28868": 34, "289": 44, "2890": [15, 29, 33], "28953": 44, "289541": [35, 37, 46], "289799": [15, 20, 29], "29": [8, 15, 16, 20, 21, 23, 25, 29, 30, 34, 35, 42, 44, 45, 48], "290": [23, 44], "290002": 34, "290424": 35, "29045704": 35, "290961e": 35, "291": [23, 32, 44], "291310100": 23, "291667": 41, "292": 44, "292587": 45, "293": 44, "29324459": 43, "293663": 34, "294": [16, 21, 30, 42], "294251": 31, "2948": [16, 21, 30, 31, 53], "294855": 37, "295193": 24, "2953863599856862": 32, "295397": 34, "29545": 35, "2957": 25, "29572402": 42, "2958": 25, "2959": 25, "296": [16, 21, 30], "2960": 25, "2961": 25, "2962": 25, "2963": 25, "2964": 25, "296601": 38, "29691": 44, "297": 32, "29802": [34, 37], "298043": 24, "298436": 24, "298561": 45, "298612": 44, "29881": 44, "299": [23, 43], "299164": 38, "2d": [18, 25, 43], "2d454e5fd9a5": 45, "2e": 1, "2f": [14, 19, 28, 33, 41, 44], "2m7m0lw97rvf654x1cwtdfmr0000gr": 21, "2nd": 32, "2ndflrsf": [35, 37, 46], "2v": 49, "2v3": 49, "3": [1, 7, 8, 10, 15, 20, 24, 25, 29, 31, 32, 33, 34, 35, 36, 37, 41, 42, 43, 44, 46, 47, 49, 50, 54], "30": [1, 4, 12, 14, 15, 17, 19, 20, 25, 26, 28, 29, 32, 34, 35, 36, 37, 38, 42, 44, 45, 46, 48, 54], "300": [15, 20, 29, 40, 42, 46, 49], "3000": [25, 43], "300000": [16, 21, 30, 31, 44], "3000000": 42, "300464": 38, "300837": 34, "301": 45, "3010": 38, "301200": 33, "3014": 38, "30146": 44, "301563": 35, "30167": 44, "301784": 45, "3018": 54, "301838": 46, "3019": [13, 14, 19, 27, 28, 32, 51], "301952": 38, "302": [35, 37, 46], "302043": 24, "302131": 35, "30279": 44, "302801": 45, "302844": 45, "303": [35, 37, 46], "303000": [16, 21, 30], "303004": 38, "303030": 32, "303109": 31, "303694": 24, "303790": 33, "3038": 48, "3038344082": 37, "303916": [15, 20, 29], "304": [15, 20, 29], "3040": 44, "3041": 44, "3042": 44, "3043": 44, "3044": 44, "304784": 35, "305": [12, 17, 26], "30504657": 39, "305047": 39, "30530902": [15, 20, 29], "305346": [15, 20, 29], "305674": 38, "3057": [14, 19, 28, 32], "30573": 38, "306500": [15, 20, 29], "306564": 43, "307": [16, 21, 30], "307516": 43, "307521": 32, "30792853": 42, "30798381": 42, "308120": [16, 21, 30], "30815": 35, "308216": 43, "308236": 24, "308448": [15, 20, 29], "3089": 33, "308900e": 23, "309": 38, "3092": [13, 14, 19, 27, 28, 51], "309249": 43, "309859": 32, "30am": 12, "30pm": 1, "31": [1, 12, 15, 16, 17, 20, 21, 23, 26, 29, 30, 31, 32, 34, 35, 36, 37, 39, 42, 44, 45, 48, 53], "310000": [16, 21, 30], "31000e": [15, 29], "310284": 37, "31038074": 42, "310405": 34, "311": [16, 21, 30], "3110": [16, 21, 30], "311151": 45, "31127015": 37, "311310": [12, 17, 26], "311769": 38, "31196406381465247": 32, "3120": [16, 21, 30], "3125": [16, 21, 30], "312500": [16, 41], "312501": [35, 37, 46], "312696": 48, "3129": 48, "31297381": 31, "312974": 31, "31298589e": 43, "313": [31, 35], "31384": 34, "314": [16, 21, 30], "3140": [16, 21, 30], "314000": 33, "31449687e": 37, "31454": 38, "314582": 37, "314840": 38, "314929": 44, "315000": 23, "315134": 44, "315630": 34, "316164": 38, "316230": 38, "31634363": 42, "316363": [15, 20, 29], "316395e": 35, "316426": 38, "316552": 31, "31655231": 31, "316798": 38, "317": [1, 16, 21, 30, 37, 54], "317277": 38, "31767136668453344": 23, "317761": 34, "318": [16, 21, 30], "3180": 33, "3180174485124284": [16, 21, 30], "318937": [16, 21, 30, 31], "319": [13, 16, 21, 23, 27, 30], "31908384": 43, "319481": 24, "319559": 23, "319630": 45, "31984311": 35, "31st": 44, "32": [8, 15, 16, 20, 21, 24, 25, 29, 30, 31, 32, 33, 35, 39, 42, 44, 45, 53], "320": [16, 21, 30], "320155": 34, "320430": 35, "32064171": 36, "3209427041566191": 23, "321": 37, "321050": 23, "32127053": 35, "322": 38, "32240": [36, 37], "322465": 23, "32247597e": 37, "322755": [15, 20, 29], "323045": [16, 21, 30, 31], "32323": [12, 17, 26], "32397724e": 37, "3245": [12, 26], "324762": 24, "325000": 23, "3252": 38, "325319": 38, "32561": 34, "326": [16, 21, 30, 38], "326616": 23, "326730": 34, "326741e": 45, "326933": [15, 29, 33], "327188": 34, "3272": 45, "327283": 35, "32734": 38, "3274": 45, "327408": 34, "32791718": 42, "328": 38, "328000": 23, "328077e": 35, "328953": [15, 20, 29], "3298721": 43, "3299": [42, 48], "33": [8, 12, 15, 16, 17, 20, 21, 23, 26, 29, 30, 31, 32, 33, 34, 35, 38, 42, 44, 45], "330": [9, 10, 13, 18, 25, 26, 27, 43, 44, 46, 48, 54], "33000e": [15, 29], "330346": 45, "330_vs_340": 12, "3310": [16, 21, 30], "331588": 24, "33191802": 42, "332130": 35, "33223002": 42, "3322447": 42, "33224516": 42, "33224759": 42, "332671": 37, "3327": 44, "332710": 35, "332746": 45, "332791": 45, "332824": 35, "333": 25, "3330": [16, 21, 30], "33308783": 31, "333088": 31, "333139": 34, "333333": [13, 16, 18, 21, 24, 27, 30, 33, 41], "3333333333333333": [41, 43], "333340": [15, 20, 29], "33380649": 42, "33380754": 42, "33380761": 42, "33381373": 42, "33394593": 42, "3339473": 42, "33394769": 42, "33395626": 42, "33397112": 42, "334": 38, "33400489": 42, "33411086": 42, "33425967": 42, "33435326": 42, "33439238": 42, "33440682": 42, "334411": [15, 20, 29], "334576": 35, "33462759": 42, "334764": 24, "33476534": 42, "335": 36, "335309": 35, "3355": [16, 21, 30, 31, 53], "3356700488_183566145b": 43, "33590": 44, "336389": 37, "33641142": 37, "3364114233677307": 37, "336411423367732": 37, "336735": 33, "336826": 31, "33682642": 31, "33683087": 32, "336831": 32, "337034": 38, "33726089": 35, "33732465": 42, "337625": 24, "33782315": 42, "33797555": 42, "338": [15, 29, 33], "33888659": 8, "339": 34, "339368": 45, "339889": 45, "34": [12, 15, 16, 17, 20, 21, 25, 26, 29, 30, 31, 32, 34, 35, 38, 42, 44, 45, 53], "340": [1, 3, 13, 18, 27, 36, 38, 43, 44, 45], "34000e": [15, 29], "340988": 34, "341109": 35, "341300": 38, "341571": 45, "34161762": [35, 37], "341712": 44, "34182": 37, "3420": [16, 21, 30], "342200": 38, "342605e": 35, "3436": 44, "3437": 48, "3438": 48, "344": [16, 21, 30], "3442": 45, "34426571": 35, "34441": 35, "345": 37, "345136": [15, 20, 29], "345386e": 35, "3454": [45, 48], "3455": 48, "345831": [12, 17, 26], "346": [16, 21, 23, 30, 31, 53], "346850": 34, "34691": 44, "347523": 33, "348": [16, 21, 30, 38], "34806": 35, "348569": 46, "34900": 35, "34924955": 42, "35": [15, 16, 20, 21, 23, 29, 30, 32, 34, 35, 36, 37, 42, 44, 45, 52], "350": [12, 17, 26], "3500": [25, 52], "350000": [16, 21, 30], "351351": 41, "351366": 34, "3515": 45, "351821": 45, "351883": 46, "3520": 45, "3521": [12, 17, 26], "352100": 38, "352930": [16, 21, 30, 31], "353": [1, 43, 54], "35375221": 49, "353961": 33, "354114": [35, 37, 46], "354604": 34, "3547": 38, "354759e": 35, "35561437": 42, "356689": [36, 37], "35671794": 37, "357": [16, 21, 30], "3573886": 42, "357500": [16, 21, 30, 31], "3576": [12, 17, 26], "35771821": 42, "357823": [12, 17, 26], "358": [12, 17, 26, 33], "358032": 37, "3582": [45, 48], "358264": [35, 37, 46], "3583": 48, "358333": [15, 20, 29], "358500": 38, "358913": 31, "3589134": 31, "359": [15, 29, 33], "3590": 33, "359784": 33, "359887": 39, "359992": [15, 20, 29], "35p": [12, 17, 26], "36": [15, 16, 20, 21, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 42, 44, 45], "360": [1, 31, 54], "360000": 23, "360918": 44, "361": 45, "361718": 34, "362": [23, 45], "362009": 44, "362185e": 35, "362553": 38, "36269995": 31, "362700": 31, "363": 45, "363192": [15, 20, 29], "363913": 34, "364": [44, 45], "364352": 32, "365": 44, "36525": 37, "365420": 48, "365603": 32, "365623": [15, 20, 29], "365898": 24, "365925": 24, "366": [31, 44, 45], "366005": 34, "366071": 16, "3663": 45, "366626": [15, 20, 29], "36695134": 42, "367": 44, "367329e": 45, "367423": 33, "368": [44, 48], "3681": 37, "368304": 32, "3684": 45, "368922": 40, "369": 35, "369875": [15, 20, 29], "369896": 43, "37": [16, 21, 23, 25, 30, 31, 32, 35, 38, 42, 44, 45, 48, 53], "37050406": 8, "370643": 34, "370842": 23, "371": [38, 44], "3717": 37, "371722": 37, "372": [16, 21, 30], "372706": 44, "372763": [35, 37, 46], "373031": [15, 20, 29], "373275": 44, "373318": 24, "373411": 23, "373623580": 25, "373656": 44, "374": [16, 21, 30], "374584": 43, "374995": 34, "37546": 37, "376": [16, 21, 25, 30, 35], "376089": 35, "37647072": 36, "3768": 48, "3769": 48, "377032": 35, "377619": 33, "377619120792": 33, "37797291": 31, "377973": 31, "37807203": 42, "378159": 35, "378764": [15, 20, 29], "378971e": 35, "37903": 25, "37906": 34, "379416e": 35, "379875e": 35, "38": [8, 15, 16, 20, 21, 23, 29, 30, 32, 34, 35, 38, 42, 44, 45], "3803": 45, "380436": 31, "38043616": 31, "380495": [15, 20, 29], "380504": [16, 21, 30, 31], "380643": [15, 20, 29], "381190": 38, "3814": 31, "381416e": 45, "381428": [35, 37, 46], "381676": [15, 20, 29], "38192364": 39, "381924": 39, "382558": 34, "3828125": 42, "383": [16, 21, 30, 38], "384111": 48, "384127": [15, 20, 29], "384528": 24, "384613e": 33, "3851": 34, "3856": [15, 20, 29], "385639": 39, "386": 33, "386071e": 35, "386530": [37, 46], "387": 33, "388023": 34, "388169": 38, "38853": 35, "3889": 31, "389": [33, 38], "389065": 37, "389349": 38, "389736": [16, 21, 30, 31], "39": [15, 20, 29, 33, 34, 35, 39, 42, 44], "390428669205": 33, "390429": 33, "390691": 23, "390725": 35, "39095422e": 37, "391": [16, 21, 30], "3912": 45, "391304": 23, "39163": 34, "391996": 43, "392": [12, 17, 26, 45], "392082": 37, "392221": 32, "392385": 45, "392612": 35, "392893": [15, 29, 33], "393": [13, 23, 25, 27, 31], "3932": 45, "39375": 44, "394113e": 35, "394920": [16, 21, 30], "395282e": 35, "395686e": 35, "395688": 45, "395697e": 35, "396": [16, 21, 25, 30, 45], "396266": 43, "396752e": 35, "396991": [16, 21, 30, 31], "397": 45, "398": 38, "398495": 44, "398915": 24, "39896994": 31, "398970": 31, "399": [16, 21, 23, 30], "3990": [13, 14, 19, 27, 28, 51], "3991": 35, "39931": 37, "399827": 34, "39x15": 42, "3blue1brown": 43, "3d": [38, 43], "3f": [13, 14, 15, 16, 18, 19, 20, 21, 27, 28, 29, 30, 34, 35, 41, 42, 48], "3h": 44, "3m": 43, "3rd": 42, "3ssnporch": [35, 37, 46], "3v": 49, "4": [0, 1, 8, 9, 12, 16, 17, 21, 23, 25, 26, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 54], "40": [8, 12, 15, 16, 17, 20, 24, 25, 26, 29, 32, 33, 34, 35, 36, 37, 38, 40, 44, 45, 46, 52, 54], "400": [13, 16, 21, 23, 27, 30, 33, 46], "40000": [43, 44], "400000": [16, 23, 33, 44], "400047": 45, "400157": 38, "400164": 43, "400649628005": 33, "400650": 33, "400881e": 23, "401": [15, 23, 29, 33], "4011": 42, "401102": 44, "401541": 34, "401623": 35, "401729": 24, "4018": 54, "401830": 37, "401895": 33, "402": [12, 17, 26], "402101": 23, "402258": 23, "402808": 37, "404": [15, 20, 29, 38], "405": [36, 54], "405227e": 35, "405415": [15, 20, 29], "405650": 35, "406": 43, "406202": 33, "40689": 38, "407": 34, "407234": 43, "40725012": 43, "4074": 54, "407510": 34, "40756124": 36, "407862": 45, "4084": 45, "409": 54, "409430": 23, "40_000": 43, "40b5a809b05a": 45, "41": [15, 16, 20, 21, 29, 30, 34, 35, 37, 38, 39, 41, 44, 45], "410": [16, 21, 30], "410240": [34, 37], "410599": 38, "410714": 16, "411412": 35, "41150573": 35, "412": [12, 15, 17, 26, 29, 33], "41210938": 42, "412500": 38, "413050": 43, "413718": 45, "413796": 35, "413958": 34, "414": 48, "4143": 45, "414405": 24, "415": 25, "4151": 36, "4153": 38, "4158382658": [21, 30, 48], "416": 37, "4165": 36, "4169": 45, "418": 42, "418031": [15, 20, 29], "418069": 33, "41901484361": 33, "419015": 33, "419355": 32, "4195": 37, "4197": [13, 14, 19, 27, 28, 32, 51], "42": [12, 13, 14, 15, 16, 17, 19, 20, 21, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 49, 51, 52], "420": 33, "420000": [12, 17, 26], "42060": 38, "421": 43, "42104086": 37, "421215": 39, "42121526": 39, "421875": 32, "422": 35, "422222": 16, "4234": 37, "4236": 37, "4238": 34, "423852": 34, "424222": 35, "424337e": 35, "425": 36, "425365": 45, "42541681": 49, "425419": 35, "426067": [16, 21, 30], "426410": [15, 20, 29], "427": 45, "427516": 24, "4276": 47, "428": 45, "428279": 24, "429": [35, 37, 46], "429217": 34, "429634": 45, "4296875": 42, "43": [15, 20, 29, 32, 33, 34, 35, 44, 45], "430": [33, 35, 37, 45, 46], "430323": [16, 21, 30], "430571": 34, "430704": 39, "4307043": 39, "430868": 32, "431": [28, 45], "4310": [15, 16, 21, 29, 30, 33], "431104": 24, "431137": 32, "4314": 34, "432": 45, "433": 45, "433514": 44, "433814": 45, "434": [15, 29, 32, 33, 45], "43445": 38, "435": 45, "435186": [15, 20, 29], "435489": 34, "435792": 33, "436": 45, "436492": 35, "43697758253484614": 32, "4372": 39, "437367": [16, 21, 30, 31], "4375": [38, 41], "437500": 41, "437684": 44, "438": 41, "438231": 43, "438275": 31, "43827545": 31, "43833466": 35, "438592": [37, 46], "438906": 37, "439": [16, 21, 30], "4390": [15, 29, 33], "439209": 34, "439254e": 25, "439360": [16, 21, 30], "439779": 34, "44": [14, 15, 16, 19, 20, 21, 28, 29, 30, 32, 34, 35, 38, 42, 44, 45, 48], "440": [33, 44], "440897": 23, "441": 35, "441404": 43, "441445": 38, "442": 23, "442377e": 35, "442806": [15, 20, 29], "442917": 24, "4430": 45, "44311": 38, "4432": 38, "443317": [15, 20, 29], "443419": [35, 37, 46], "444297": 38, "4443": 16, "444444": [16, 21, 30], "4448": 38, "445": 33, "445111e": 35, "445124e": 35, "44586935": 36, "44586935141902073": 36, "446216": 38, "446284e": 35, "446869": 38, "447": [16, 21, 30, 37], "447461": 44, "447517": 37, "44787197": 42, "4482": [12, 17, 26], "4484": [15, 20, 29], "448757": 45, "449262": 24, "449666": [15, 20, 29], "44966612": [15, 20, 29], "45": [8, 13, 14, 15, 16, 19, 20, 27, 28, 29, 32, 34, 35, 42, 44, 45, 47, 51], "450000": 41, "450000e": 23, "450132": 44, "450739": 35, "450822": 38, "451888": 34, "452600": 38, "453367": 38, "4537": 45, "454427": [16, 21, 30, 31], "454677": 39, "45467725": 39, "454788": [37, 46], "454966": 34, "455": 31, "455026455026455": 25, "4552": 37, "45555535": 37, "455652": 23, "45587": 44, "45588": 44, "45589": 44, "45590": 44, "45591": 44, "456": 43, "456419": 38, "45653693": 31, "456537": 31, "457435": 44, "45756": 48, "458": [16, 21, 30], "458333": 41, "458524": 45, "459": [25, 35], "4591": [16, 21, 30], "459214e": 35, "459873": 45, "459937": 42, "45a": 44, "45am": 44, "46": [8, 13, 14, 15, 16, 19, 20, 21, 25, 27, 28, 29, 30, 31, 32, 34, 35, 44, 45, 48, 51, 53], "460047": 45, "46019608e": 37, "46021": 48, "46075": 48, "4608": [13, 14, 19, 27, 28, 51], "460950": 39, "461": [16, 21, 30, 33], "462060": 45, "462545": 37, "462963": 32, "46299": 48, "463": 34, "46357616": 25, "463582": 36, "464104e": 35, "465279e": 35, "46530779": 31, "465308": 31, "466246": 43, "4664": [12, 17, 26], "46666667": 25, "46729488": 35, "467379": 37, "467628": 38, "468": [15, 29, 33, 37], "468232": 44, "4687": 38, "46880": 48, "468995": 24, "469": [16, 21, 30, 34], "469383": 34, "4695": 34, "469571": 38, "47": [1, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 30, 32, 33, 35, 38], "470": [16, 21, 30, 48], "4700": 33, "470060": 35, "470666": 35, "471000": 23, "471032": 37, "472": 48, "47242662": 49, "4726": 45, "472603": 35, "472790": 34, "473": 42, "473691": [15, 20, 29], "474": [25, 34], "474552": [15, 20, 29], "47491": 34, "475": 25, "475099": 37, "475540": 42, "476": [13, 18, 25, 27], "4760": 33, "47606": 38, "476092": [35, 37, 46], "476406": 37, "476412": 39, "47641249": 39, "477": [25, 33], "477291": 38, "47799": 48, "478": 25, "478060": 44, "478515": 24, "479": 25, "479109": [15, 20, 29], "479132": 38, "479773": 42, "48": [13, 14, 15, 19, 20, 27, 28, 29, 32, 34, 35, 41, 44, 45, 51, 54], "480": [25, 35], "4800": [12, 17, 26], "480249": [15, 20, 29], "4806334": 42, "48073598": 39, "4809": 33, "481": [16, 21, 25, 30], "4810": 47, "4813": [14, 19, 28, 32], "481514": 35, "481793": [16, 21, 30], "481893": 34, "481960": 34, "482": 25, "4820": 23, "4822": 45, "483": 25, "48344371": 25, "483751": [15, 20, 29], "48390": 48, "484": 25, "48407": 48, "484937": 32, "485": [25, 43], "485191": 24, "48535": 48, "4854": 37, "485722": 42, "486": [25, 37], "4861": [16, 21, 30, 31, 53], "486266": [16, 21, 30], "486664": 42, "487": [16, 21, 30], "48721": 48, "487740": 42, "4879": 48, "488": [16, 21, 25, 30], "488163": 42, "488753": 44, "489": 25, "489130": 32, "489593": 42, "49": [15, 16, 20, 29, 32, 34, 35, 38, 44, 45], "490": [25, 38, 49], "490000": [16, 21, 30], "490033": 35, "490568": 33, "490797": 42, "490930": 42, "491217": 34, "491366": [37, 46], "491379": [16, 21, 30, 38], "491968": 42, "492": [16, 21, 30, 34], "492270": 31, "492307": 42, "492551": 42, "493": [16, 21, 27, 28, 30], "493489": 42, "493544": [16, 21, 30], "493921": 31, "494": [15, 16, 21, 29, 30, 33], "4943": 33, "494309": 23, "495524": 24, "49575": 34, "496": 38, "496213": 35, "49668874": 25, "496757": 37, "497143": 42, "497386": [15, 20, 29], "497787": 35, "497949": 42, "498": [34, 47], "498133e": 35, "498164": 24, "498562": [15, 20, 29], "499900": [16, 21, 30], "4f": [15, 20, 29, 31, 34, 42], "4m": 43, "4th": [34, 36, 37], "4x": 54, "5": [1, 4, 23, 24, 26, 32, 33, 35, 36, 40, 41, 44, 48, 49, 50, 51, 54], "50": [1, 12, 15, 16, 17, 20, 21, 23, 25, 26, 29, 30, 31, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 54], "500": [12, 14, 16, 17, 21, 26, 30, 34, 36, 37, 38], "5000": [12, 13, 17, 23, 26, 27, 47], "50000": 44, "500000": [15, 16, 21, 23, 30, 31, 34, 35, 40, 44, 48], "500000e": [23, 33], "500001": [16, 21, 30], "5002": 35, "500625": [15, 20, 29], "50062e": [15, 29], "500924": [16, 21, 30, 31], "501": [16, 21, 30, 48], "501071": 43, "501191": 42, "501250": [15, 20, 29], "501304e": 35, "5014": 12, "501875": [15, 20, 29], "5024752475247525": 33, "502500": [15, 20, 29], "502985": 34, "503000": [16, 21, 30], "503090": 34, "503125": [15, 29], "503750": [15, 20, 29], "503807": 42, "504": [15, 20, 29, 38], "504231": 45, "504375": [20, 29], "504429": 31, "504644": 33, "50475372e": 37, "504fde4fcf8": 45, "505000": 15, "505026": 23, "505180": 42, "505335": 34, "505592e": 35, "505625": [15, 20, 29], "5057": 35, "50596432e": 49, "506023": 36, "506035e": 35, "506079e": 35, "506084e": 35, "506211": [16, 21, 30, 33], "506250": 20, "506410": 32, "506875": [15, 20, 29], "507130": 33, "507359": [16, 21, 30, 33], "507500": [15, 29], "50774": 33, "507740": [16, 21, 30], "50775": 33, "507750": 33, "507752": [16, 21, 30, 33], "507995": 32, "508": [16, 21, 30, 35], "508125": [15, 20, 29], "508133": [16, 21, 30, 33], "508371": 33, "508534": 42, "508741": 42, "508750": 20, "50884": 38, "50899": 33, "509000": [12, 17, 26], "509001": 35, "509045": 23, "509317": [16, 21, 30, 33], "5098": 42, "509859": 42, "509930": 44, "50k": [34, 36, 37], "51": [15, 16, 20, 21, 29, 30, 31, 33, 34, 35, 37, 39, 44, 45, 46, 53], "5100": 23, "510000": [13, 15, 23, 27, 29, 33], "510421": 42, "510505": 42, "5106": 48, "510625": 20, "510697e": 23, "5107": 23, "510836": 33, "5109": 37, "511": 9, "5112": [13, 23, 27], "51137414e": 37, "51143": 38, "51150": 34, "511620e": 35, "5118": 37, "511875": 20, "512": 43, "5120": [12, 17, 26], "512000": [15, 29, 33], "51226051": 39, "5123": 42, "512319": [16, 21, 30], "512408": [35, 37, 46], "512897": [15, 20, 29], "512x640": 43, "513": [16, 21, 30], "5131": 42, "513125": 15, "513333": 25, "513678": 45, "513750": 15, "514150": 42, "514155": [16, 21, 30, 31, 35], "514347": 42, "514598e": 35, "5146": 32, "514950": 25, "515000": 29, "51503393": 31, "515034": 31, "515351e": 35, "5156": [16, 21, 30, 38], "515755": 25, "515848": 38, "516199": 42, "516394": 38, "516556": 25, "516788": 24, "516858": 42, "517273": 42, "517346": 34, "518113": 42, "519000": 23, "519029": 34, "519129": 24, "52": [15, 16, 20, 21, 29, 30, 32, 34, 35, 38, 44, 45, 48], "520495": 42, "52061": 44, "520700": 42, "520782": 42, "5208": [13, 23, 27], "520857": 34, "5209": 35, "5212": 35, "521284e": 35, "521567e": 35, "521578e": 35, "521743e": 35, "521772": 42, "522": 35, "522563e": 35, "5227966": 42, "523595": 42, "523684": 42, "5238095238095238": [13, 18, 27], "52398": 38, "524": [13, 18, 27, 41], "524364": 45, "525": 25, "5253": 37, "525554": 38, "525757": [15, 20, 29], "526046": 42, "526078": [16, 21, 30, 31], "526214": 37, "526442": 24, "526596": 38, "526602": 35, "526783": 24, "5274": 45, "527500": [16, 21, 30], "528": 35, "5282": 45, "528403": [15, 20, 29], "52881619": [15, 20, 29], "529210": 34, "529388e": 35, "5294": 36, "529412": [16, 21, 30], "53": [23, 32, 35, 44], "530052": 33, "530978": 34, "531": 46, "5310": 16, "531116e": 35, "531353": 43, "5315": 33, "53187": 47, "532034": 35, "533027": 24, "533333": 16, "533454": 43, "533498": [15, 20, 29], "534114": 33, "534342": 38, "5345": 23, "535": [16, 21, 30, 38], "535014": [16, 21, 30], "53520104": [15, 20, 29], "535604": [16, 21, 30], "535622": 38, "536362": 39, "53636249": 39, "537267": [16, 21, 30], "537732": 42, "538000": [13, 23, 27], "538702": [15, 20, 29], "538816": 34, "5390": [34, 37], "5391": [16, 21, 30, 38], "539116": 44, "539258": 24, "539376": 45, "539459": 48, "539989": 23, "54": [35, 44, 45], "540": 44, "540000": [16, 21, 30], "540039": 42, "540359": 38, "541117": 35, "541347": 42, "541488": 38, "54152": 34, "541667": 31, "541795": 34, "542": 46, "54240": 34, "542624": 37, "542873": [16, 21, 30, 31], "543297": 33, "543351": 37, "543464": 42, "543678": 24, "544": 33, "544079": 24, "544462": 37, "545": 35, "546": [16, 21, 30], "5461": 35, "546150": 24, "546473": 32, "546610": [15, 20, 29], "54676006e": 37, "547": [33, 35, 37], "547090": 42, "547993": 34, "548831": 37, "549682": 34, "5498": [15, 20, 29], "549946": 42, "55": [13, 14, 15, 19, 20, 27, 28, 29, 32, 34, 35, 36, 37, 44, 45, 46, 51], "55000": 33, "550000": [16, 21, 30, 31, 33], "550004": 36, "550616": 34, "55101": 44, "5513": 33, "5514": [36, 37], "5515": 45, "551579e": 35, "551862e": 35, "551975": 35, "552": [16, 21, 30, 35], "552492": 23, "552721": 36, "553": 23, "553125": 15, "553965": 37, "553979": 34, "5540": 45, "5541306485809793": 36, "55413065": 36, "554180": 44, "554463": 42, "554621": 38, "5551": 32, "555180": 23, "555740": [15, 20, 29], "5566": [16, 21, 30, 31, 53], "556716": 25, "557197": 43, "557242": 34, "557739": 35, "558": [35, 37, 38, 46], "558564": 34, "55862988e": 37, "55873324": 43, "5588": [12, 17, 26], "558824": 34, "558889": 35, "559": [33, 35, 37, 46], "559284": 23, "56": [15, 20, 29, 31, 34, 35, 44, 45], "560": 23, "560053": 23, "560225": [16, 21, 30], "560625": 20, "560768": 35, "5609808539232339": 16, "561": [1, 15, 29, 33, 37, 38], "561467": [16, 21, 30, 31], "561602": 37, "561645e": 35, "562112": [16, 21, 30], "5623062252998352": 42, "562712": 42, "563": 1, "5630224174651539": 32, "5630921721458435": 42, "563125": 15, "5631500400": 23, "563314": [35, 37, 46], "563467": [16, 21, 30], "5644": 35, "564483": 38, "565": 38, "5650": [13, 23, 27], "565062": 45, "56521734": 8, "565625": 20, "565679": 34, "565746": 45, "565888": [16, 21, 30], "566": [16, 21, 30], "566092": [16, 21, 30], "566222": 43, "5667": 34, "567724": 43, "567856e": 35, "568": 43, "568009": [15, 20, 29], "56804591": 35, "568125": 15, "568663": 35, "5690201394302518": 37, "56902014": 37, "569375": 29, "5694": 38, "57": [15, 16, 20, 21, 23, 29, 30, 31, 34, 35, 37, 44, 45, 46, 53], "57000": 45, "570015": 35, "570449": 34, "570473": 38, "5707": 45, "570739": 38, "571": [25, 39, 49], "571431": 42, "571500": 38, "571800": 23, "571875": 20, "571901e": 35, "571969": 38, "572": 1, "572105": [15, 20, 29], "572500": 15, "572549": [16, 21, 30], "572962": 45, "573": 49, "573050": 34, "573125": 15, "573129": [35, 37, 46], "5732": [34, 47], "573542": 38, "573818": 34, "574": 23, "57415": 44, "574260": 38, "575000": 41, "575043": 23, "57510": 38, "5755444169044495": 42, "575636": 25, "575907": 38, "576": [16, 21, 30], "57640869": 31, "576409": 31, "576921": 42, "577500": 15, "578452": 24, "578523": 32, "578569": 24, "578654": 34, "5789": 35, "579091": 38, "579245": 42, "579432": 32, "579559e": 35, "579660": 36, "5798": 36, "57994": 34, "58": [13, 14, 15, 19, 20, 27, 28, 29, 32, 35, 44, 45, 51], "580": 43, "580302e": 23, "5804311633110046": 42, "580539e": 35, "580625": 15, "581": 37, "5813": 23, "58137177": 31, "581372": 31, "5814": [12, 17, 26], "581687": 38, "581787": 45, "582": [12, 17, 26, 36], "582090": 34, "5824530720710754": 42, "582469": 35, "582570": 25, "583": 23, "583125": 15, "58387198": 39, "583872": 39, "583972": 24, "584": [16, 21, 30], "584615": [16, 21, 30, 38], "585": [16, 21, 30], "585187": 25, "585513": 32, "5857": 45, "586095": [16, 21, 30, 31], "586875": 20, "587773": 34, "588": [15, 29, 33], "588125": 29, "588235": 32, "588307": [16, 21, 30], "589286": 48, "59": [1, 12, 15, 16, 17, 20, 29, 35, 44, 45, 54], "590": 23, "590243": 42, "59049": 34, "59050": 34, "590618": 38, "590625": 15, "59082668": 31, "590827": 31, "5915": 31, "592": 48, "592401": [12, 17, 26], "59243876": 36, "592507": 24, "5925410985946655": 42, "59300": 38, "5931": 35, "593370": 35, "593508": 39, "5938": [16, 21, 30], "594": [16, 21, 30], "5941": 23, "5944": 23, "594595": [15, 20, 29], "594982": 34, "594995": 34, "5950": [16, 21, 30], "595000": 20, "595427": 43, "595569e": 35, "595625": 15, "596088e": 35, "596151": 38, "596810": [15, 20, 29], "596864": 35, "596875": 20, "5970": 36, "59700": 34, "597015": 32, "59708": 34, "597326": 34, "597555": [12, 17, 26], "597924": [35, 37, 46], "598": [16, 21, 30], "598057": 25, "59810": 34, "598100": 32, "598149": [35, 37, 46], "598750": 29, "599": 48, "5993570685386658": 42, "599492": 32, "599860": [15, 20, 29], "599894": 44, "59pm": [12, 17], "5fin": 35, "5th": [34, 36, 37], "5unf": 35, "6": [1, 8, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 54], "60": [8, 12, 16, 17, 21, 26, 30, 34, 35, 37, 38, 39, 41, 42, 44, 45, 46], "600": [16, 21, 30, 32, 42], "60000": 44, "600000": [14, 15, 20, 28, 29, 33, 44], "600193": 34, "60023631": 35, "600288": 24, "600625": 20, "600k": 35, "601": 33, "601042": [12, 17, 26], "601504": 32, "601712": 34, "601790": 32, "602": [16, 21, 23, 30, 31, 53], "602000": [16, 21, 30], "602649": [15, 20, 29], "6028": 34, "602941": 34, "602954": 36, "603125": 20, "6031432151794434": 42, "60319915": 49, "603243": 23, "603684e": 33, "603739": 23, "603970": 45, "604": [15, 20, 29], "6040": [15, 29, 33], "604000": [13, 23, 27], "604032": 34, "60429913": 35, "604320": 32, "60455": 44, "604619": 32, "604797": 32, "6048": 44, "604807": 45, "60495488": [15, 20, 29], "605060": 34, "6051": [16, 21, 30, 31, 53], "605100": 32, "605101": 32, "605102": 32, "605263": [15, 20, 29], "605625": 29, "605696": 32, "606": [16, 21, 30], "606061": 32, "6063088774681091": 42, "606557": 32, "606567": 32, "606811": 33, "606875": 29, "606902": 32, "607062": 44, "608050": 32, "608125": 29, "6082": [16, 21, 30], "608468": 32, "608532": 43, "608565": 45, "60860": [16, 21, 30], "6086405515670776": 42, "609": [16, 21, 30], "6092": [12, 17, 26], "6093292236328125": 42, "609375": 29, "60943": 34, "60k": 35, "61": [15, 20, 29, 31, 32, 34, 35, 39, 44, 45], "610000": 15, "610142": 24, "61029914": 35, "610407": 34, "610931": 40, "611": 31, "611007": 43, "6111123561859131": 42, "611178": 44, "612349": 31, "61234944": 31, "6124": 45, "612500": 20, "612546": 34, "612621": 32, "612755": [15, 20, 29], "613507": 32, "613738": 33, "613738418384": 33, "614": [16, 21, 30], "61420598": 31, "614206": 31, "614567": 38, "614872": 24, "615": [16, 21, 30], "615000": 20, "6154": [16, 38], "615730": 36, "616": 33, "616099": 33, "6168": [13, 23, 27], "617342": 45, "617431": 40, "6176": 34, "617647": 34, "618": [16, 21, 30], "618000e": 23, "618012": 33, "6186580061912537": 42, "618967": 42, "619": 48, "61912405": 37, "619375": 20, "62": [15, 16, 20, 25, 29, 33, 34, 35, 44, 45], "620726": 24, "6210": 23, "622255": [16, 21, 30], "622454": 33, "622500": [15, 29], "6226": 38, "622612": 34, "622709": 32, "623000": [16, 21, 30], "62320": 44, "62352928": 36, "624049": 35, "6241": [12, 17, 26], "624375": 29, "624450e": 35, "624615": 35, "6250": [16, 21, 30], "625387": 33, "6257": 45, "626206": 35, "62657": 44, "626875": 29, "62688064": 37, "627": 45, "6273": 33, "6275": [13, 14, 19, 27, 28, 51], "627722": 37, "627966": [16, 21, 30], "628032": 38, "628139": 34, "62873917": 37, "629792e": 35, "63": [15, 20, 29, 33, 34, 35, 44, 45, 48], "6303": [16, 21, 30, 31, 53], "6306": [16, 21, 30, 38], "630625": 15, "631899": 45, "632": 48, "6320": 32, "6320979595184326": 42, "6322": 38, "632296": 24, "632353": 34, "632786": 44, "63316788": 49, "63362": 35, "633933424949646": 42, "634397": 32, "634490": 31, "634686": 34, "635": [16, 21, 30], "635200": 38, "635239": [16, 21, 30, 31], "635648": 32, "636": [12, 16, 17, 21, 26, 30, 31, 45, 53], "636364": [16, 48], "636410": 36, "636849e": 35, "637": 43, "637982": [15, 20, 29], "638169": 37, "6389": [16, 21, 30, 38], "6391518364256": 45, "6392": 38, "639754": 35, "64": [10, 15, 16, 20, 29, 32, 35, 43, 44, 45], "640": [33, 43], "6400": [16, 21, 30], "640000": [34, 48], "640266": [16, 21, 30, 31], "640625": 15, "640x480": [15, 20, 29], "641216": 44, "6414100192": 23, "641538": 45, "641873": 35, "642071": 24, "642676": 44, "642965": 34, "643": 33, "6431": 38, "643311e": 35, "643750": 15, "644106": 34, "64417243": 43, "644375": 20, "64454": 34, "644770": 40, "645519": 34, "6458": [13, 14, 19, 27, 28, 51], "645963": 33, "646050": 37, "6464": 45, "646617": 46, "647796": 38, "648": [15, 16, 21, 29, 30, 33], "6480": 36, "648195": 34, "648550": 43, "649658": 37, "64994": 44, "65": [13, 27, 31, 35, 45], "650": 34, "65000": 33, "650000": 33, "65000e": [15, 29], "65013704": 39, "650743": 23, "651": 23, "651250": 15, "65125032": 49, "6513": 37, "651359e": 23, "651446": 44, "651875": 20, "65243": 35, "652487": 38, "6526853": 35, "652828": 33, "652986": 38, "653": [16, 21, 30], "653205": 33, "653205232272": 33, "654": [16, 21, 30], "65424895": 35, "654375": 20, "65486": 42, "656297e": 35, "656349": [15, 20, 29], "656827": 34, "656873": 23, "657675": 38, "658047": 32, "658645": 32, "659056": 35, "66": [13, 14, 16, 19, 21, 27, 28, 30, 32, 34, 35, 43, 44, 51], "6600060120": 23, "6601256728172302": 42, "660171": [15, 20, 29], "6604": [16, 21, 30, 31, 53], "660714": 31, "661023": 42, "66214339": [15, 20, 29], "66221": 44, "6622507572174072": 42, "662450": 34, "662541e": 35, "662745": [16, 21, 30], "662879": 36, "66368": 37, "663680": [35, 37, 46], "6637": 45, "6638": 45, "663822": 37, "6639": 45, "6639009118080139": 42, "6641": 45, "6642": 45, "664207": 34, "6643": 45, "6644": 45, "6645": 45, "664625": 42, "664707": 32, "66473": 44, "665": [16, 21, 30], "665307": 42, "665351e": 35, "665625": 29, "665882": 36, "666": [16, 21, 30, 31], "666166": 44, "6666666666666666": 43, "666667": [14, 16, 21, 28, 30, 41], "666754": 43, "667450": 44, "668": 42, "668787": [15, 20, 29], "6688": [12, 17, 26], "669614": 34, "669805e": 35, "67": [13, 14, 19, 27, 28, 31, 32, 34, 35, 44, 45], "670344": [15, 20, 29], "6709133982658386": 42, "671272e": 23, "67186503136": 35, "6731126308441162": 42, "673277": 33, "6733067729083665": 25, "6733849048614502": 42, "6734487414360046": 42, "674": 25, "6744": 37, "674490": 33, "674721": 36, "675000": [12, 17, 26], "67501": 44, "67512181": 35, "67562658": 31, "675627": 31, "675676": 41, "675814": [15, 20, 29], "676": 46, "676250": 29, "67672595": 35, "677": [16, 21, 25, 30], "6771429181098938": 42, "6772": 45, "677268": 45, "677567": 23, "677579": [15, 20, 29], "677601": 33, "677629": [15, 20, 29], "6778583526611328": 42, "678": [15, 29, 33], "678000": 23, "678689": 32, "679240": 23, "679478": [16, 21, 30], "679877": [35, 37, 46], "68": [13, 14, 15, 19, 20, 27, 28, 29, 31, 34, 35, 37, 39, 40, 44, 45, 49], "680000": [12, 17, 26], "6800296306610107": 42, "680657": [16, 21, 30], "681223": [15, 20, 29], "681428": 24, "681716": 42, "683015": 36, "683171": 34, "68323": 33, "68339": 44, "684211": [15, 20, 29], "684447": [16, 21, 30], "684960": [16, 21, 30, 31], "685": 23, "685103e": 35, "68523": 44, "685786": 36, "6858": 32, "686": [16, 21, 30], "686348e": 35, "687": 35, "687055": 34, "687307": 33, "687500": [14, 28], "687504": 42, "688": 33, "6880359361853475": 32, "688043475151062": 42, "688135": 33, "688484": 23, "689338": [35, 37, 46], "69": [13, 14, 15, 19, 20, 27, 28, 29, 31, 35, 39, 44, 45], "690": 48, "69027185e": 37, "690402": 33, "690778": 37, "691241": 34, "691617": 42, "691640": [15, 20, 29], "691877": 33, "691924": 39, "69192445": 39, "692131": 24, "692308": [16, 21, 30], "692500": 15, "693": [16, 21, 30], "693498": 33, "693590": 31, "6938": [12, 17, 26, 44], "693890": 44, "693898": 44, "693936": 31, "69393613": 31, "694": 25, "69411": 38, "694155": [15, 20, 29], "694334": 36, "6950": 37, "695532": [16, 21, 30], "695783": 42, "696": 25, "696034e": 35, "6962": [16, 21, 30], "6963": 37, "696373": [16, 21, 30], "696429": 34, "696712": 44, "696859": 33, "696875": 29, "696970": 32, "69698010e": 37, "697": [16, 21, 30, 38], "697248": 34, "6973": [16, 21, 30], "698": [16, 21, 30], "698125": 15, "698167": 44, "698206": 35, "698384608345687": 33, "698385": 33, "6984": 38, "698857": 33, "699224": [15, 20, 29], "6993": 23, "699706": 43, "699901396097971": 40, "6th": [34, 36, 37], "7": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50], "70": [13, 14, 19, 23, 24, 27, 28, 31, 34, 35, 39, 40, 44, 45, 46], "70000": 44, "700000": 44, "700000e": 23, "700855": 34, "701128": 44, "701173": 33, "701186e": 35, "70162085e": 37, "7017": 45, "701863": 33, "702703": [15, 20, 29], "703406": 45, "704": [15, 16, 20, 21, 29, 30, 35], "704099": 31, "7041": 42, "7042": 45, "7043": 45, "7046136400143138": 32, "70472": 38, "704969": 33, "705000": [16, 21, 30], "705470": 42, "705511": 33, "70560276": 31, "705603": 31, "70568": 35, "705696": [15, 20, 29], "705882": [14, 19, 28, 33], "70588235": [14, 19, 28], "705898": 38, "706": 31, "706128": [15, 20, 29], "706444": 34, "706489": 23, "706783": 31, "70678332": 31, "706966": 44, "707681": [15, 20, 29], "707712": 45, "707899": 39, "70789903": 39, "70799": 33, "708": [16, 21, 30, 31, 33, 36, 53], "708075": 33, "708527": [16, 21, 30], "708978": 33, "709185": [15, 20, 29], "70978": 38, "709874": 33, "709880": 33, "709893": 44, "7099": 38, "71": [12, 13, 14, 17, 19, 26, 27, 28, 31, 32, 34, 35, 39, 44, 45], "710000": [16, 21, 30], "710031": 37, "710526": [15, 20, 29], "710896": 34, "71096": 38, "711": [31, 33], "711077": [16, 21, 30], "711086": 33, "711356": 23, "711717": 33, "711754": [16, 21, 30, 31], "711819": 42, "711852": 38, "71199006": 35, "712": [16, 21, 30], "712074": 33, "71219761": 31, "712198": 31, "712324": 33, "712402": 36, "7129": 33, "7129300520": 23, "713": 31, "71327467": 35, "714": 43, "714077": [16, 21, 30, 31], "714286": 33, "714375": 20, "714745": 34, "715072": 43, "71517": 33, "7153": 45, "715424": 33, "715728": 34, "715992": 43, "716157": 34, "716655": 33, "716657": 33, "716792": 34, "716985": [15, 20, 29], "717289": 33, "717391": 33, "717829": [16, 21, 30], "718242": 33, "718266": 33, "718524": 44, "71866979": 35, "718750": 29, "7188": 31, "719": [12, 16, 17, 21, 26, 30, 38], "719056": 36, "719427e": 35, "719500": [15, 20, 29], "719747": 34, "719915905190645": 23, "72": [13, 14, 15, 19, 20, 27, 28, 29, 34, 35, 44, 45, 51], "7200": 23, "720357": 44, "72036": 44, "720497": 33, "720859": [16, 21, 30], "720893": 45, "720904": 44, "7210": [13, 23, 27], "721006": 33, "721008": 33, "721250": 20, "7212512828409691": 32, "721616": 33, "721705": [16, 21, 30], "7218": [13, 14, 19, 27, 28, 51], "721818": 38, "721917": 23, "721921": [16, 21, 30], "722": [16, 21, 30], "722241": 33, "722249": 33, "722803": 23, "722873": 23, "723": [16, 21, 30], "72345029": 35, "723602": 33, "723613": [15, 20, 29], "723951": 23, "724068": 23, "7242": [13, 23, 27], "724410": 23, "724458": 33, "724539": 44, "724891": 34, "725": [32, 33], "7250894": 49, "726": [16, 21, 30, 34, 38], "726269": 24, "726412": [16, 21, 30, 31], "726441": 24, "726474": 43, "726573": 33, "726583": 33, "726634": 34, "726659": 23, "7266666666666667": 49, "726788": 35, "727014": 44, "727198": 33, "727273": [15, 16, 20, 29], "727554": 33, "7277854625841886": 45, "727821": 33, "7278214718381631": 33, "727829": 33, "727992": 24, "728": [16, 21, 30, 34], "728235": [16, 21, 30, 31], "7283": 34, "728324": 34, "728777": [15, 20, 29], "729": 33, "729109": 48, "729143": 34, "7292": 38, "729374": 23, "729814": 33, "73": [13, 14, 19, 27, 28, 31, 32, 33, 34, 35, 40, 44, 45], "730025": 23, "730383": 34, "730704": 23, "731498": 45, "7315": 32, "7315558717766282": 33, "731572": 32, "731583": [15, 20, 29], "73183": 42, "7328": [16, 21, 30], "732919": 33, "733102": [16, 21, 30, 31], "733333": [14, 16, 21, 28, 30, 31], "733746": 33, "734": [33, 35, 45], "734011": 33, "734048": 23, "734385": 34, "734816": 44, "734986": 23, "735": 35, "735043": 34, "735261": 33, "7352614272253524": 33, "735637": 23, "7356575131416321": 42, "735667": 34, "735879": 33, "7363681793212891": 42, "736498": 33, "736900": [16, 21, 30], "737285": 23, "7379": [13, 23, 27], "738": [16, 19, 21, 30, 35], "738564": 44, "738701": [16, 21, 30, 31], "738715": 45, "738839": 32, "738977": 33, "739264": [16, 21, 30, 38], "7395977155164125": 33, "739598": 33, "739938": 33, "74": [13, 14, 16, 19, 21, 27, 28, 30, 31, 32, 33, 34, 35, 40, 53], "740319": 23, "740542": [12, 17, 26], "740844": 33, "741": 45, "741037": 44, "741060": 23, "741250": 29, "741463": 33, "7418": 37, "741935": 48, "742084": 33, "742088": 33, "742703": 33, "742981": 34, "743": [15, 16, 21, 29, 30, 33, 45, 48], "743133": [15, 20, 29], "743135": 34, "743321": 33, "743323": 33, "743324": 33, "743391": [15, 20, 29], "743555": 37, "7436": [13, 14, 19, 27, 28, 51], "743917": [16, 21, 30, 31], "7440": [12, 17, 26], "744201": 34, "744565": 33, "745": 36, "745178": 33, "745925": 23, "746114": 36, "746328": [15, 20, 29], "747": [12, 17, 26], "74720920774": 35, "74798624e": 37, "748510": 34, "748725": 45, "748749e": 33, "748797": 32, "749118": 37, "75": [8, 12, 13, 14, 15, 16, 17, 19, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 44, 45, 46, 53], "750": [12, 17, 26], "7500": 35, "750000": [16, 23, 35], "7503": [13, 23, 27], "7504": 48, "750401": 42, "751": 48, "752169": 23, "7524": 44, "752728": 23, "753": 25, "753286": [16, 21, 30, 31], "754": [16, 21, 30], "754165": 48, "754386": 34, "754620": 23, "754874": 38, "754938": 23, "755": [14, 45], "755000": 35, "7551": 33, "755364": [15, 20, 29], "755418": 33, "755477": [15, 20, 29], "756": 45, "7562": [12, 17, 26], "75625": 44, "757": 34, "7574257425742574": 33, "75745416": 39, "757545": 35, "757591": 44, "757932": 45, "757985": [36, 37], "758": [36, 37, 45], "758029": 24, "758062e": 35, "758259": 23, "75826": [36, 37], "758514": 33, "7588186": 43, "7588527798652649": 42, "759043": 34, "759561": 39, "75956122": 39, "7599": 32, "76": [14, 16, 19, 21, 28, 30, 32, 33, 34, 35, 37, 38, 45], "760": 45, "760262": 33, "760678": 44, "760966": 23, "76161": 33, "761945e": 35, "762": [28, 45], "7620": [12, 17, 23, 26], "762093e": 35, "76270194": 37, "763": [16, 21, 30], "763480": 23, "7639": [13, 23, 27], "764052": 38, "76470588": [14, 19, 28], "764706": [14, 15, 19, 20, 28, 29, 33], "765": 34, "765591": 34, "765601": 35, "766317e": 35, "766318": 23, "766423": 35, "766430": [15, 20, 29], "767": [35, 37, 46], "767742": 32, "767802": 33, "767819": 44, "767852": [15, 20, 29], "768": [16, 21, 30, 31, 35, 37, 46, 53], "768176": 45, "768184": 23, "768279": 46, "768512": 34, "769030": 23, "76908228": 36, "769231": [16, 21, 30], "77": [13, 14, 18, 19, 27, 28, 31, 32, 34, 35, 40, 44, 45, 50], "770": [13, 23, 27], "770163": 23, "7706532429048965": 36, "770833": 41, "770898": 33, "771": [16, 21, 30], "771969": [15, 20, 29], "772185": 23, "772532": 34, "7728396574320712": 23, "773017": [35, 37, 46], "773125": 20, "7736": 33, "773851": 44, "774261": 44, "774844": 31, "77484447": 31, "7750553478074826": 44, "775270": 35, "7752884548630529": 32, "775311": 37, "77536150e": 37, "7758": 33, "776": 33, "7763": [16, 21, 30, 38], "776427": 45, "77694295": 36, "77709": 33, "777600": 23, "777934": [15, 20, 29], "7781845435415525": 44, "779": [16, 21, 30, 38], "779271": 38, "78": [12, 13, 14, 16, 17, 18, 19, 21, 26, 27, 28, 30, 31, 34, 35, 38, 39, 44, 45, 50], "7800": 33, "780000": 36, "780296": 35, "780298": 35, "780316": 35, "780497": 35, "78058051e": 37, "780864": 34, "781": [16, 21, 30], "781004": [15, 20, 29], "781531": 34, "7816": 35, "781975": 24, "782183": 35, "782219": [15, 20, 29], "7827": 34, "783282": 33, "783582": [15, 20, 29], "783784": 41, "783789": [15, 20, 29], "784424": 32, "784573": 38, "785": 31, "785105": 35, "785108": 35, "785134": 35, "78521263": 42, "785399": 35, "785483": 44, "785714": [16, 21, 30], "786115": 38, "78617028": 36, "786555": 35, "787": [16, 21, 30], "787574": 35, "787879": [15, 20, 29, 32], "787933": 35, "788": 28, "788374": 43, "788647472858429": 42, "7887": 37, "7891381897690047": 32, "789436": [16, 21, 30], "789657": 44, "79": [13, 14, 16, 19, 21, 27, 28, 30, 31, 32, 34, 35, 44, 45, 51], "790": 34, "790000": [16, 21, 30], "79041": 35, "790481e": 25, "790521": 23, "790721": 46, "790731": 32, "791017": 45, "791467": [16, 21, 30], "792": 49, "792023": [37, 46], "79250": [16, 21, 30], "792500": 15, "792577": 35, "792603": [15, 20, 29], "792828": 35, "793": 38, "793243": [16, 21, 30], "79378": 34, "7938": 31, "794": 45, "794118": [15, 20, 29], "794236": [16, 21, 30], "794820": [16, 21, 30], "795": [14, 15, 29, 33], "79500e": [15, 29], "7951": 33, "7951559890417761": 35, "795902": 44, "796": [16, 21, 30], "7964215270662811": 32, "797": [16, 21, 30], "797355": [16, 21, 30, 31], "7978563117812038": [16, 21, 30], "798": [16, 21, 30], "7982": [15, 20, 29], "7986546": 35, "799983": [15, 20, 29], "79998417": 49, "7f688092391a": 43, "7l": 21, "7pm": 38, "7th": [34, 36, 37], "8": [1, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 52], "80": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 44, 45, 46, 50], "800": [12, 17, 19, 25, 26, 28, 33, 42], "800000": [33, 44], "8001": 32, "800190": [15, 20, 29], "80062924": [15, 20, 29], "800k": 46, "801219e": 35, "801666": 34, "801863": [15, 20, 29], "802502": 38, "802902": 35, "802987": [15, 20, 29], "803": [15, 16, 20, 21, 29, 30, 48], "803617": 34, "804": [15, 20, 29, 45, 48], "804818": [16, 21, 30, 31], "80482065": 31, "804821": 31, "805198": 35, "805342": 44, "805414": 24, "805970": [15, 20, 29, 32], "806": 31, "8062": [13, 23, 27], "806899": 43, "8076": 35, "807684": [15, 20, 29], "807735": 34, "8078": [12, 17, 26], "808": 45, "8080": [13, 23, 27], "808208": 34, "808958": [15, 20, 29], "809": [16, 21, 30], "8098": 45, "81": [13, 14, 15, 19, 20, 23, 27, 28, 29, 31, 32, 33, 34, 35, 37, 39, 44, 45, 46], "810073": [35, 37], "810098": 38, "810368": [15, 20, 29], "81071706": 33, "810811": 41, "8112": [12, 17, 26], "812272": 35, "812363": 35, "812500": [14, 28], "812593": 43, "812875": 45, "813": [16, 21, 30], "813586": 34, "815669": 34, "816200": 24, "8162831858407079": 47, "816717791411044": 45, "817": 36, "817034": 48, "817558": [16, 21, 30, 31], "8180": [16, 21, 30], "818041": 45, "818868": [16, 21, 30], "819152": [15, 20, 29], "819213": 45, "8195": 32, "819549": [15, 20, 29], "819584": [15, 20, 29], "81970188": 31, "819702": 31, "82": [13, 18, 27, 31, 33, 34, 40, 44, 45], "820": [15, 20, 29], "820033": 35, "820143": 32, "82025568e": 37, "820564": 35, "821040": 37, "821327": 42, "821807": 35, "8219": [16, 21, 30], "8221": 31, "8225": 48, "82273995": 31, "822740": 31, "823511": 34, "823529": [14, 15, 19, 20, 28, 29, 32], "82352941": [14, 19, 28], "823543": 38, "824849": 34, "824884": 35, "825": [16, 21, 30], "825123": 38, "8253": [15, 20, 29], "825306": 33, "825470": 45, "825697": 35, "826142": 35, "826203": 32, "826216": 35, "826513": 44, "826553": 35, "82670": 44, "826739": 35, "826758": 35, "826760": 35, "827039": 32, "827068": 32, "827130": 34, "827261": 35, "827842": 32, "827907": 33, "828": [23, 25], "8280229354283182": 35, "82804": 33, "828332": [35, 37, 46], "828358": [15, 20, 29], "828405": 44, "828682": 33, "82869879": 42, "828891": 33, "828976": 33, "829": 25, "83": [13, 14, 18, 19, 27, 28, 31, 33, 34, 40, 41, 42, 44, 45, 50], "830": 25, "830382": 34, "830712e": 35, "831": 25, "831135": [15, 20, 29], "831611": [35, 37], "831989": 33, "832": [16, 21, 25, 30], "832320": 32, "832370": 34, "832866": 35, "833": [15, 25, 29, 33], "83320": 44, "8334": 37, "833913": 23, "834": 25, "8340": [15, 20, 29], "834109": 33, "834356e": 35, "83437": 35, "834455": [15, 20, 29], "835": 25, "8356": 37, "835651": 33, "835749": [35, 37], "835876": 23, "83603": [35, 37], "8361313": 35, "836189": [15, 20, 29], "836735": 34, "836878e": 35, "836880e": 35, "837022e": 35, "837838": [15, 20, 29], "837848": [15, 20, 29], "838": [15, 29, 33], "83848729e": 43, "83876": 33, "8388866943476283": 32, "838951": 35, "8389756947416362": 32, "839225": 35, "84": [13, 14, 18, 19, 23, 27, 28, 31, 44, 45, 49, 50], "840": [16, 21, 30], "84002795": 31, "840028": 31, "840074": [14, 19, 28], "840183": 35, "840492": [35, 37, 46], "84062193": 37, "841": 35, "841208": 33, "841886": 33, "841983": 33, "842": [16, 21, 30], "842028": 34, "842064": 45, "842105": [15, 20, 29], "843": 36, "843281": 37, "843284": [15, 20, 29, 32], "843842": [16, 21, 30, 31], "843992": [35, 37], "844409": 31, "84440919": 31, "844444": 16, "844921": 39, "845": 33, "846154": [16, 21, 30, 48], "8462": 38, "846260e": 35, "846650": 35, "84679073": [15, 20, 29], "84698489": 43, "847178": 34, "847287": 33, "8475": 44, "84772": 34, "847799": 33, "847808": 34, "8478316682480326": 44, "848": [36, 37], "8481": 48, "848214": 16, "84893192": 33, "849": [36, 37], "849102e": 35, "849438e": 35, "849612": 33, "85": [13, 14, 18, 19, 27, 28, 31, 34, 35, 36, 37, 38, 44, 45, 50], "850": [12, 17, 26, 36, 37], "8502": 33, "850283": 44, "850503": 33, "850746": [15, 20, 29], "851460": 35, "851852": 32, "852": [45, 48], "852053": 33, "852104": 35, "852941": 32, "853125": 29, "853399": 34, "854129": 35, "854167": 41, "854500": 45, "8546143543902771": 45, "854744525547446": 45, "854749": 44, "85545875": [15, 20, 29], "85597188": 31, "855972": 31, "856": 33, "856175": [16, 21, 30], "856589": 33, "856722": 24, "857": 35, "857457": 24, "857874": 33, "858": 32, "8580": [16, 21, 30, 31, 53], "858209": [15, 20, 29, 32], "858915": 33, "859": 36, "859318": 35, "859439": 39, "85943906": 39, "859455": 45, "85969": 33, "859799": 33, "86": [13, 15, 18, 27, 29, 31, 32, 33, 34, 38, 44, 45], "860": [34, 37], "86000e": [15, 29], "8601643854446082": 35, "860677": 34, "861": [16, 21, 30], "86102": 44, "861157": 46, "861348": 33, "862432": 35, "862552": [16, 21, 30], "8625888648969532": 45, "86267067": 31, "862671": 31, "862997": 38, "863014": 32, "863889": 44, "863941": 35, "864": 36, "86400": 44, "8641864337292489": 45, "864205": 37, "864292": 24, "865562": 45, "8661": 48, "866110": 32, "866667": [14, 28, 34], "866980": 35, "867434": 43, "867558": 38, "868003": 35, "868281": 35, "868305": 35, "868308": 35, "869077": 31, "86907725": 31, "869094": 33, "8691": 31, "869531": [15, 20, 29], "869964": 33, "87": [13, 16, 21, 27, 30, 31, 34, 44, 45], "870": [36, 37], "870503": 43, "871": [33, 36], "871094": 44, "8711": 34, "871200": 23, "872": [36, 37], "872093": 33, "872603": 43, "872722908439952": 37, "8727229084399575": 37, "872961060": 35, "8729610607986": 35, "873": 36, "8731": [35, 37, 46], "873103": [15, 20, 29], "873182": 44, "873356": [15, 20, 29], "873643": 33, "873704": 35, "874062": 31, "87406235": 31, "874305": 44, "874516": 33, "874532": 35, "874767e": 35, "874962": 24, "875": 34, "8750": [16, 21, 30, 38], "875000": [14, 16, 28], "876065": 33, "876540": 45, "876566e": 23, "876574": [16, 21, 30, 31], "87681182": 42, "877046": 38, "877390": 37, "877519": 33, "877551": 34, "878183": [15, 20, 29], "87844893": 35, "87849316": 32, "879": [16, 21, 30], "87907": 33, "879938": 33, "88": [13, 14, 16, 19, 21, 27, 28, 30, 31, 32, 34, 38, 45, 53], "880": 38, "8801": 42, "880348": 33, "880831": 44, "881395": 33, "881720": 34, "883138": 33, "884586": 33, "885": [12, 17, 26, 31], "885044": [35, 37, 46], "885968": 45, "886047": 33, "886759": 32, "887": 36, "887017": 34, "887159": 44, "8873": 34, "887324": 34, "887343": [15, 20, 29], "887597": 33, "887701": 34, "8878117": 31, "887812": 31, "888": [33, 36, 37], "888066": 37, "888372": 33, "888513": 34, "888811": 33, "888889": [16, 21, 30, 32], "888961": 37, "889086": 35, "889147": 33, "889429": 44, "889921": 44, "89": [13, 14, 18, 19, 27, 28, 31, 34, 40, 44, 45, 50], "890": [25, 36], "890456": 23, "890457": 35, "890933": 45, "891001": 34, "891557": 33, "892476": 34, "892477": [15, 20, 29], "892491": [16, 21, 30], "89270": 38, "892733": 44, "892961": 38, "893000": [16, 21, 30], "893260": 31, "8937442459553657": 37, "894": [16, 21, 30], "894587": 46, "894960": 23, "895": 36, "895349": 33, "895541": 35, "89572": 44, "895833": 34, "895963": 32, "897010": [16, 21, 30, 31], "89706451e": 37, "897674": 33, "898": 37, "898016": 33, "898243": 24, "898703e": 35, "899": [16, 21, 30, 31, 33, 36, 53], "8994": 37, "8997": 35, "899736": 23, "899969": 44, "8m": 43, "8th": [34, 36, 37], "9": [1, 4, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 54], "90": [8, 12, 13, 14, 15, 17, 18, 19, 20, 26, 27, 28, 29, 31, 34, 35, 40, 41, 44, 45, 50], "900": [31, 33, 34], "90000": 44, "900000": [14, 19, 28, 44], "900000e": 23, "900662": [14, 19, 28], "901085": 32, "9010852321946792": 32, "901262": 44, "90159483": 39, "901595": 39, "902343": 24, "902401": 33, "903101": 33, "903422": 24, "904": [15, 20, 29, 33], "90403853": 31, "904039": 31, "904226": [15, 20, 29], "904565": 24, "9047619047619048": [13, 18, 27], "904902": 43, "904930e": 23, "905": [15, 16, 20, 21, 29, 30], "905000": 20, "905327": 44, "906667": [14, 19, 24, 28], "90669": 38, "906865": [14, 19, 28], "907": 45, "907143": 48, "907595": 44, "908": [16, 21, 30], "908140": [16, 21, 30, 31], "908215": 35, "909091": [16, 21, 30], "90982": 38, "91": [13, 14, 16, 18, 19, 21, 23, 27, 28, 30, 31, 33, 34, 38, 39, 44, 50], "910": [13, 23, 27], "9100": 44, "910018": 35, "910174": 35, "9103": 44, "910456e": 35, "91063776": 37, "910714": 48, "9108334653214172": 23, "910843": 35, "911": 25, "911615": 35, "911846": 35, "912": [16, 21, 30], "912395": 37, "913333": [14, 19, 24, 28], "913767": 35, "913849": 35, "914003": 37, "914451894267": 35, "914585": 37, "91515735": 35, "915714e": 35, "915952": 35, "916254": [15, 20, 29], "916347": 24, "916722": 37, "917526": 34, "917837": 34, "918": [23, 36], "918124": 34, "918191": 43, "9182": 44, "919198": 37, "9196": [12, 17, 26], "92": [13, 14, 18, 19, 27, 28, 31, 34, 40, 43, 44, 45, 50], "920000": [14, 19, 24, 28], "9203": 33, "920305": 38, "920462": 37, "9212": 16, "92120500e": 49, "921422": 45, "921435": 24, "921438": 35, "921850": 35, "92195464": 37, "921955": 37, "922": 31, "923077": 34, "923283": [16, 21, 30, 31], "923432": 37, "924485": 38, "9245": [14, 19, 28, 32], "925272e": 35, "925288e": 35, "925593": [15, 20, 29], "925768": 34, "926657": 35, "926667": 24, "926733e": 35, "926829": 34, "928": 33, "92809": 38, "92852376": [15, 20, 29], "929": 33, "9295": 33, "93": [13, 14, 18, 19, 27, 28, 31, 32, 33, 39, 44, 45, 50], "930000": [16, 21, 30], "930062": 23, "930123": [15, 20, 29], "930561": [15, 20, 29], "9308647034083802": 23, "931439e": 35, "931786": 32, "931896": 23, "932": [16, 21, 30], "932070": 45, "932124": [15, 20, 29], "932143": 48, "93279": 44, "933275": 34, "933333": 24, "9336": [16, 21, 30], "934": 25, "934205": [15, 20, 29], "934269": [16, 21, 30, 31], "934783": 34, "9351": 38, "935512": 45, "935802": [15, 20, 29], "93665": 44, "937429": 46, "9375": [14, 19, 28], "937500": [14, 19, 28, 31], "938": 34, "938201": 23, "9383": [15, 20, 29, 32], "93869659": 31, "938697": 31, "939006": 34, "9391": 35, "939394": [15, 20, 29, 32], "939805": 23, "94": [13, 14, 16, 18, 19, 21, 27, 28, 30, 31, 32, 33, 34, 35, 44, 50, 53], "940000": 24, "9401": 44, "9406": [13, 14, 19, 27, 28, 51], "941": 45, "9410": 23, "941176": [14, 19, 28, 31], "94117647": [14, 19, 28], "942": 25, "943609": 38, "944": [12, 17, 26], "944092": 34, "944354": 31, "945000": 24, "945968": 24, "946667": 24, "946783": [15, 20, 29], "947": [16, 21, 30, 33, 48], "9471": 33, "948482": 45, "94888": 34, "949": [16, 21, 30], "9490": [16, 21, 30], "9492": 35, "94933723": 35, "94959681": 31, "949597": 31, "95": [13, 14, 18, 19, 27, 28, 31, 34, 40, 44, 45, 46], "950000": [16, 21, 30], "950088": 38, "9505": 37, "950564": 38, "9506": 37, "950696": 45, "950733": [15, 20, 29], "951294": 35, "951574": 38, "951644": 38, "951667": 24, "951669": 38, "951696": [15, 20, 29], "953": 36, "9530973451327434": 47, "953333": 24, "95511263": [15, 20, 29], "955113": [15, 20, 29], "9558": 44, "956": [16, 21, 30], "956966": 38, "957075": 38, "9573": 44, "9576": [12, 17, 26], "957886": 43, "957919": [15, 20, 29], "957987": [15, 20, 29], "9583333333333334": 43, "958393": [16, 21, 30, 38], "95886206e": 43, "959": [16, 21, 25, 30], "959139": 37, "959402e": 35, "959870": 34, "959873": 45, "96": [13, 27, 31, 32, 33, 34, 38, 44], "960": [25, 32], "960000e": 25, "961": 25, "961109802000133": 40, "961404": [16, 21, 30, 31], "961498": [35, 37, 46], "961771": 32, "961898": 32, "962": 25, "962036": 34, "963": 25, "963024": 23, "963097": 34, "96319": 44, "96320": 44, "96321": 44, "96322": 44, "96323": 44, "96325": 44, "963333": 24, "963689": 38, "964": 25, "96554": 38, "9661": 35, "966131": [16, 21, 30, 31], "9664": [13, 14, 19, 27, 28, 51], "966667": 24, "966812": 23, "967907": 34, "968": [16, 21, 30], "968233": 38, "968236": 34, "96833": 42, "968333": 24, "96834506": [15, 20, 29], "968493": 45, "968514e": 35, "96875": 43, "969048e": 35, "9691": 35, "9692602666681306": 32, "96965253": 37, "969653": 37, "97": [13, 14, 16, 19, 27, 28, 31, 32, 33, 37, 40, 44, 45], "970518": 34, "970683": 38, "971": 31, "97203586": 31, "972036": 31, "97217": 44, "972198": 33, "97223953": 31, "972240": 31, "972440": 34, "97253": 44, "9730": 31, "973225": 34, "973280": 31, "97328024": 31, "973294": 25, "973333": 24, "973482e": 33, "973750": [15, 29], "974": [16, 21, 30], "974183": 24, "974480": 38, "974531": 24, "9748": 32, "974801e": 35, "975104": 25, "975895": 44, "976": [16, 21, 30, 34, 36], "976667": 24, "977": [16, 21, 30, 44], "977278": 38, "9773": [13, 14, 15, 19, 20, 27, 28, 29, 51], "978": 32, "9781449369880": 44, "9781789957211": 43, "97823755": 32, "9785299": 42, "978738": 38, "979": [36, 37], "979562": 45, "98": [13, 16, 21, 27, 30, 31, 32, 35, 37, 39, 42, 44, 45, 46], "980": 44, "980000": 24, "98001": 23, "98007": [12, 17, 26], "98010": 23, "98024": 23, "98027": 23, "98028": [13, 23, 27], "98033": 23, "98038": 23, "98039": 23, "98045": [12, 17, 26], "98052": [12, 17, 23, 26], "98055": [12, 17, 26], "980634": 45, "98065": 23, "98072": [12, 17, 26], "98074": [13, 23, 27], "98075": [12, 17, 26], "98077": 23, "9808": 32, "980962": 24, "98102": 23, "98103": 23, "98107": [12, 17, 26], "98112": [12, 17, 26], "98115": 23, "98116": [12, 17, 26], "98117": 23, "98118": 23, "981195": 44, "98125": [13, 23, 27], "98136": [13, 23, 27], "98144": 23, "98146": 23, "98148": 23, "981643": 23, "981735": 32, "98178": [13, 23, 27], "98199": 23, "982": 31, "982184": 33, "982570": 45, "983": 43, "983333": 24, "983340": 23, "9837": [14, 19, 28, 32], "984": 33, "984653": 32, "984664": 35, "985000": 24, "985283": 33, "9854": [13, 14, 19, 27, 28, 32, 51], "985457": 45, "985816": [14, 28], "986047": 33, "9862": 48, "986207": 33, "987": [33, 43], "987062": 35, "987597": 33, "9876": [36, 37], "987681": 38, "988": 38, "9881": [13, 14, 19, 27, 28, 51], "988333": 24, "988381": 33, "988841": 33, "988901": 35, "989": [13, 18, 27], "989147": 33, "989156": 33, "989443": 45, "989922": 33, "989973": 32, "99": [13, 14, 16, 19, 21, 25, 27, 28, 30, 31, 33, 34, 44], "990631": 44, "990754": 44, "9912": [15, 20, 29, 32], "9915": 44, "991667": 24, "991810": 23, "991966": 45, "992": [28, 33], "992220": 23, "992254": 33, "99240562": 37, "992406": 33, "992569": 25, "9926": 31, "992857": [14, 28], "992908": 28, "993023": 33, "993029": 33, "993065": 45, "9931": [13, 14, 19, 27, 28, 51], "993333": 24, "9934531067299874": 32, "993666": 37, "993969": [35, 37, 46], "994": [12, 17, 26], "994266": 33, "994574": 33, "994764": 44, "995": [38, 43], "9950": 38, "9951": [13, 14, 19, 27, 28, 51], "99515": 44, "995434": 35, "996424": 23, "996487": 23, "996588e": 35, "996765": 37, "996788": 45, "996820": 45, "996899": 33, "99744241e": 37, "9977957422135844": 37, "998": [34, 45, 48], "9983": 34, "998302": 34, "998370": 23, "998440": 23, "99845": 33, "998451": 33, "999": [32, 48], "99907": 33, "999122": 34, "9991338290544213": 23, "999147": 34, "999172": 34, "999178": 23, "999183": 34, "999185": 34, "999192": 34, "999210": 34, "999213": 23, "999214": 34, "999221": 34, "999223": 34, "999225": 33, "999254": 34, "999298": 34, "999317": 34, "99931882": 35, "999335": 34, "999438": 23, "9994394006711425": 23, "999480": 23, "999518": 23, "999535": 33, "999539": 23, "999544": 23, "999545": 23, "999546": 23, "999558": 23, "999562": 23, "999567": 23, "999577": 44, "999622": [16, 21, 30], "9999": [12, 17], "9am": 38, "9th": [34, 36, 37], "A": [0, 1, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 49, 50, 54], "AND": [0, 35], "AS": 0, "And": [12, 13, 17, 26, 27, 33, 35, 42, 44, 45, 46, 51, 52], "As": [4, 14, 19, 20, 28, 31, 33, 35, 36, 37, 41, 44, 45, 46, 47, 49, 52, 54], "At": [4, 12, 14, 17, 23, 25, 26, 28, 32, 34, 36, 38, 39, 43, 44], "BE": [0, 42], "BUT": [0, 8], "BY": [0, 1], "Be": [7, 12, 15, 17, 20, 29, 37, 46, 47, 50, 52], "Being": 43, "But": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 52, 54], "By": [11, 12, 14, 15, 17, 19, 20, 24, 26, 28, 29, 31, 34, 36, 39, 42, 43, 45, 46, 52], "FOR": 0, "For": [0, 1, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 54], "IN": [0, 14, 19, 28, 32], "IT": 32, "If": [4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "In": [1, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54], "Ines": 48, "It": [2, 4, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 52, 54], "Its": 45, "NEAR": [16, 21, 30, 31, 38, 53], "NO": 0, "NOT": [0, 8, 31, 32], "No": [0, 12, 13, 17, 18, 25, 26, 27, 35, 36, 37, 38, 40, 44, 45, 46, 50], "Not": [34, 35, 36, 37, 38, 39, 41, 44, 45], "OF": 0, "OR": [0, 8, 35], "Of": [9, 31, 33], "On": [4, 7, 12, 16, 17, 21, 23, 24, 25, 26, 30, 31, 33, 34, 35, 36, 37, 38, 40, 43, 45, 46, 48], "One": [5, 8, 13, 14, 18, 19, 25, 27, 28, 31, 32, 33, 34, 37, 39, 40, 45, 50], "Or": [15, 20, 24, 29, 31, 33, 46, 52], "Such": [6, 41, 44], "THE": [0, 14, 19, 28], "TO": [0, 42], "That": [13, 14, 16, 18, 19, 21, 27, 28, 30, 32, 33, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47], "The": [0, 2, 5, 7, 8, 11, 12, 13, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31, 34, 35, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54], "Their": 5, "Then": [13, 18, 27, 32, 36, 39, 44, 47], "There": [1, 2, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 21, 25, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 54], "These": [4, 10, 13, 14, 15, 18, 19, 20, 27, 28, 29, 32, 34, 35, 36, 37, 38, 39, 41, 44, 46], "To": [8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 38, 40, 42, 43, 44, 46, 47, 48, 52, 54], "WITH": 0, "Will": [34, 45, 48, 50], "With": [0, 12, 13, 15, 16, 17, 18, 20, 21, 24, 26, 27, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 43, 45, 49, 52], "_": [36, 42, 43, 45, 48], "__array__": 25, "__call__": 31, "__class__": [32, 44], "__finalize__": 45, "__getitem__": [21, 28, 30, 48], "__name__": [32, 44], "__sklearn_tags__": 25, "__testing_word2vec": 42, "_array_api": 25, "_asarray_with_ord": 25, "_assert_all_finit": 25, "_assert_all_finite_element_wis": 25, "_astype_nansaf": 45, "_base": 25, "_california_housing_dataset": 32, "_call_func_on_transform": 31, "_check_i": 25, "_classif": 25, "_column_transform": 31, "_constructor_from_mgr": 45, "_data": 33, "_deprecate_force_all_finit": 25, "_distn_infrastructur": 33, "_encod": 31, "_estim": 25, "_fit": 25, "_fit_context": 25, "_get_sequential_output": 31, "_i": 43, "_is_numpy_namespac": 25, "_logist": 49, "_mgr": 45, "_proba": 36, "_score": 31, "_scorer": 31, "_set_output": 31, "_time_fit_was_cal": 45, "_transform": 31, "_transform_on": 31, "_valid": 31, "_validate_param": 25, "_valu": 25, "_x_subset": 14, "ab": [32, 34, 35, 37], "abbrevi": 42, "abdelrahman": [1, 54], "abil": [12, 17, 26, 31, 33, 37, 42, 44, 52], "abl": [8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 52], "about": [1, 2, 4, 7, 13, 14, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54], "abov": [0, 5, 8, 10, 12, 13, 14, 15, 17, 18, 19, 20, 23, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 49, 52, 54], "absenc": [31, 37, 41], "absolut": [11, 25, 32, 34, 35, 37, 39, 48], "abspath": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52], "academ": [1, 7, 38, 47], "accept": [5, 8, 25, 34, 35, 42, 47], "accept_large_spars": 25, "accept_spars": [25, 31], "access": [1, 10, 12, 14, 17, 19, 21, 28, 30, 33, 36, 39, 41, 42, 44, 46, 47, 48], "accessori": 44, "accident": [15, 16, 20, 21, 29, 30, 47], "accomod": 7, "accompani": [7, 12, 13, 17, 26, 27], "accomplish": [24, 47], "accord": [32, 34, 35, 38, 41, 45, 54], "account": [1, 7, 12, 14, 17, 28, 34, 38, 41, 45, 47, 50], "accur": [12, 14, 17, 19, 26, 28, 36, 37, 38, 41, 45, 46, 50, 51], "accuraci": [11, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 33, 34, 36, 37, 38, 40, 43, 45, 46, 48, 50, 51, 54], "accuracy_scor": 34, "acdm": [34, 36, 37], "acf": 44, "achiev": [8, 15, 20, 29, 34, 47], "acinonyx": [12, 17, 26, 43], "acoust": [15, 16, 21, 29, 30, 33], "acquir": 11, "acquisit": 41, "across": [12, 13, 14, 16, 17, 18, 19, 21, 26, 27, 28, 30, 34, 37, 43, 54], "act": [32, 54], "action": [0, 12, 17, 26, 36, 37, 39, 41, 42, 45, 54], "activ": [4, 10, 26, 33, 48, 50, 54], "actor": [41, 42], "actual": [7, 12, 17, 26, 32, 34, 36, 37, 39, 41, 42, 44, 45, 46], "ad": [31, 32, 33, 34, 36, 37, 38, 40, 42, 43, 45, 48], "adapt": [0, 16, 21, 30, 31, 34, 36, 42, 44, 46, 48], "add": [7, 8, 10, 14, 16, 21, 30, 31, 34, 35, 36, 37, 38, 40, 42, 44, 45, 47, 48, 53], "add_pip": 48, "addit": [0, 4, 12, 17, 35, 41, 46, 54], "addition": [51, 52, 54], "address": [40, 47], "adelaid": 44, "adio": 46, "adj": [42, 48], "adject": 42, "adjust": [15, 20, 24, 29, 33, 40, 44, 52], "adm": [34, 36, 37], "admin": [1, 54], "administr": 1, "admit": [14, 28], "adopt": [6, 41], "adp": [42, 48], "adult": [34, 36, 37], "adult_df_larg": [36, 37], "adv": 42, "advanc": [11, 31, 33, 39, 40, 41, 42, 43, 51], "advantag": [11, 16, 21, 30, 31, 32, 36, 40, 41, 42, 50], "advic": 45, "advis": [12, 17, 26], "advisor": 54, "af": 37, "affect": [10, 15, 16, 20, 21, 29, 30, 32, 33, 34, 39, 44, 45, 47, 52], "affix": 42, "aft": 47, "after": [4, 6, 10, 14, 16, 19, 21, 28, 30, 31, 34, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 54], "ag": [12, 17, 25, 26, 32, 34, 35, 36, 37, 38, 41], "again": [10, 14, 16, 18, 19, 21, 23, 24, 25, 27, 28, 30, 40, 41, 42, 43, 45, 47, 52], "against": [41, 42, 44], "agenc": [42, 48], "agent": 1, "agglomerativeclust": 40, "aggress": 42, "agnost": 37, "ago": [43, 44], "agre": 52, "agreement": [45, 54], "ahm": [1, 54], "ai": [7, 9, 34, 38, 42, 43], "aight": [12, 17, 26], "aim": [25, 50], "ain": 42, "airplan": 46, "airport": [34, 47], "aka": [32, 45], "al": [36, 42], "alain": [1, 54], "alamine_aminotransferas": [12, 17, 26], "alan": 1, "alaska": 32, "alberta": 42, "album": 33, "albumin": [12, 17, 26], "albumin_and_globulin_ratio": [12, 17, 26], "alburi": 44, "alexand": 46, "alexnet": 43, "algebra": [41, 42], "algorithm": [2, 11, 12, 14, 16, 17, 21, 24, 26, 28, 30, 31, 34, 35, 36, 37, 40, 42, 43, 46, 47, 51, 52, 53], "align": [8, 12, 13, 14, 17, 18, 19, 26, 27, 28], "align_kei": 45, "alison": [1, 54], "aliv": 47, "alkaline_phosphotas": [12, 17, 26], "all": [0, 1, 4, 5, 6, 7, 8, 10, 14, 15, 18, 19, 20, 21, 23, 24, 25, 28, 29, 31, 33, 35, 36, 37, 38, 42, 43, 44, 45, 47, 48, 49, 52, 53, 54], "all_cap": 48, "all_featur": 44, "allei": [35, 37, 46], "allen": 48, "alley_grvl": 35, "alley_miss": 35, "alley_pav": 35, "alloc": [8, 42, 43], "allow": [5, 7, 10, 14, 16, 21, 25, 28, 30, 33, 34, 38, 42, 44, 45, 47, 51, 52, 54], "allow_nan": 25, "allow_nd": 25, "allpub": [35, 37, 46], "allya": [1, 54], "almost": [32, 33, 35, 38, 40, 41, 42], "along": [7, 13, 27, 31, 34, 43, 44, 46, 51], "alpha": [15, 16, 20, 21, 24, 29, 30, 44, 52], "alpha_": 35, "alphabet": 32, "alphago": [12, 17, 26, 39], "alq": [35, 37, 46], "alreadi": [4, 8, 10, 11, 12, 17, 34, 35, 37, 39, 42, 44, 45, 46, 48, 51], "also": [1, 2, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "altar": 43, "altern": [8, 24, 33, 39, 46, 54], "although": [14, 19, 28, 36, 39, 41, 45], "alwai": [12, 13, 15, 17, 18, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 48, 50, 51, 52, 54], "am": [16, 17, 21, 30, 39, 42, 46, 48, 54], "amatriain": 41, "amaz": 25, "amazon": [12, 17, 26, 39, 41, 48], "ambienc": 25, "ambigu": 42, "amer": 34, "america": [31, 42], "american": [25, 39], "amirali": [1, 54], "aml": [16, 21, 30], "among": [12, 13, 17, 18, 26, 27, 33, 34, 36, 37, 41], "amongst": 48, "amount": [4, 12, 14, 17, 19, 26, 28, 32, 33, 34, 35, 37, 39, 43, 44, 45, 47], "amp": [36, 37], "amplifi": [34, 42], "amuel": [16, 21, 30], "an": [0, 1, 2, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 53, 54], "anaconda": [10, 37, 48], "anaconda3": 18, "analogi": [20, 40, 42, 46], "analysi": [1, 2, 9, 11, 13, 27, 34, 35, 39, 40, 42, 46], "analyt": 44, "analyz": [11, 34, 38, 44, 45, 46], "anatinu": 43, "anca": [1, 54], "ancestor": 38, "ancestr": 54, "ancuta": [1, 54], "andrea": [1, 9], "andrew": [1, 9, 24, 33, 38, 54], "anemon": 43, "angel": [45, 48], "ani": [0, 10, 13, 14, 16, 18, 19, 21, 23, 25, 27, 28, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54], "anim": [24, 34, 43], "animal_fac": [24, 43], "anneal": 38, "annot": [37, 39], "announc": 7, "annoyingli": 35, "annual": 48, "anomali": [34, 35, 39], "anonym": 44, "anoth": [8, 10, 13, 15, 18, 20, 27, 29, 32, 33, 34, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 50, 51, 53], "answer": [4, 6, 7, 12, 13, 14, 17, 19, 26, 27, 28, 33, 36, 39, 41, 42, 44, 46, 49, 51, 52, 54], "anteat": 43, "anti": 45, "anymor": [35, 39, 41, 52], "anyon": [12, 46, 47], "anyth": [0, 12, 14, 17, 19, 25, 28, 31, 34, 41, 42, 45, 47], "anytim": 54, "anywher": 31, "ap": [11, 50], "ap_lr": 34, "ap_svc": 34, "apart": [15, 20, 29, 40], "apeendixa": 38, "api": [25, 34, 42, 44, 50], "app": [12, 13, 17, 18, 27, 50], "appeal": 42, "appear": [2, 7, 31, 36, 47, 52, 54], "append": [4, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 48, 51, 52, 53], "appendix_b": 42, "appendixb": 43, "appl": 42, "appli": [0, 2, 6, 9, 11, 12, 13, 14, 17, 18, 19, 25, 26, 27, 28, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 53], "applic": [0, 5, 12, 17, 26, 31, 33, 34, 35, 37, 38, 42, 45, 47, 50, 54], "appreci": [11, 39, 54], "approach": [1, 11, 14, 15, 16, 20, 21, 24, 25, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 42, 43, 50, 52], "appropri": [0, 4, 10, 11, 13, 14, 18, 19, 23, 27, 28, 31, 34, 35, 39, 40, 44, 45, 47, 50, 54], "approv": [34, 54], "approx": [15, 20, 29, 37], "approxim": [13, 18, 27, 33, 38, 47], "apr": 1, "april": 44, "apt": 5, "ar": [0, 1, 2, 4, 6, 7, 8, 9, 10, 14, 15, 18, 19, 20, 23, 24, 25, 28, 29, 31, 33, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "arang": [8, 14, 15, 19, 20, 23, 24, 28, 29, 32, 33, 34, 35, 52], "arbitrari": [37, 39, 40, 44], "architectur": 43, "area": [33, 35, 36, 38, 39, 46], "aren": [7, 35, 38, 39, 42, 43, 44, 48], "arena": 38, "arg": [14, 19, 24, 25, 28, 31], "argh": 45, "argmax": 24, "argmin": [14, 15, 19, 20, 28, 29, 34, 39], "argsort": [37, 42], "argu": [17, 39, 42], "argument": [8, 13, 18, 27, 31, 33, 34, 35, 37, 46, 48, 50, 53], "arima": 44, "arima_model": 44, "aris": [0, 12, 26, 42], "aristotl": [15, 20, 29], "arithmet": 8, "aroth85": 22, "around": [7, 15, 20, 29, 31, 34, 35, 44, 45, 51], "aroundn": [12, 26], "arr": [25, 45], "arr1": 8, "arr2": 8, "arrai": [13, 14, 15, 16, 18, 19, 20, 21, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49], "array_equ": 8, "array_orig": 25, "arriv": 38, "art": 46, "arthur": [12, 17, 26], "articl": [1, 13, 14, 16, 18, 21, 27, 28, 30, 34, 39, 41, 42, 43, 46], "articul": [46, 50], "artifici": [1, 42], "artist": [15, 16, 21, 29, 30, 33], "as_fram": [15, 20, 24, 29, 52], "asarrai": 25, "ascend": [8, 23, 31, 32, 33, 35, 36, 37, 38, 44, 45, 50], "ased": 40, "asia": 31, "asid": [4, 14, 19, 28, 36, 52], "ask": [3, 7, 10, 12, 13, 14, 15, 17, 18, 19, 26, 27, 28, 29, 31, 34, 38, 39, 41, 42, 45, 46, 48, 51, 54], "asleep": 32, "aspartate_aminotransferas": [12, 17, 26], "aspect": [32, 37, 38, 40, 41, 45, 46, 50], "assault": 54, "assert": [7, 31, 34, 36, 37], "assess": [1, 6, 11, 12, 13, 14, 16, 17, 18, 19, 21, 25, 26, 27, 28, 30, 34, 37, 39, 46, 54], "assign": [1, 4, 6, 8, 10, 12, 13, 15, 16, 17, 18, 20, 21, 24, 27, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 50, 51, 53], "assist": [12, 17, 26], "assoc": [34, 36, 37], "associ": [0, 12, 14, 15, 17, 18, 19, 20, 26, 28, 29, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 47, 50, 54], "assum": [12, 13, 17, 26, 27, 31, 32, 34, 35, 40, 41, 42, 44, 46, 50], "assumpt": 45, "asterisk": 33, "astyp": [8, 24, 25, 44, 45], "astype_arrai": 45, "astype_array_saf": 45, "astype_is_view": 25, "atratu": 43, "attack": [13, 18, 27], "attempt": [14, 19, 24, 28], "attend": 54, "attent": [6, 42, 47], "attic": 35, "attract": 42, "attribut": [0, 1, 12, 13, 15, 16, 17, 18, 20, 21, 26, 27, 29, 30, 32, 33, 38, 39, 42, 43], "attrit": 45, "auc": [11, 45, 47, 50], "audienc": [11, 46, 47], "audio": [43, 54], "audit": [47, 54], "auditor": 54, "augment": 34, "august": 44, "austin": 42, "australia": 44, "authent": 39, "author": [0, 42, 54], "auto": [12, 17, 26, 33, 34, 38, 39, 46], "autocorrel": 44, "autom": [13, 18, 27, 35, 42, 46], "automat": [16, 21, 30, 31, 35, 38, 42, 44, 45, 46], "autoregress": 32, "autumn": 44, "autumn_month": 44, "aux": [42, 48], "av": [35, 37, 42, 46], "avail": [0, 1, 7, 9, 10, 12, 14, 17, 18, 19, 28, 31, 33, 34, 35, 40, 41, 42, 43, 44, 45, 50, 54], "avebedrm": 32, "aveoccup": 32, "averag": [11, 14, 15, 19, 20, 28, 29, 31, 32, 33, 35, 37, 39, 40, 42, 45, 47, 48, 50, 52], "average_precis": 34, "average_precision_scor": 34, "average_word_length": 48, "averaging_model": 36, "averaging_model_ndt": 36, "averoom": 32, "avg": [34, 41, 44], "avg_sent_emb": 42, "avocado": 46, "avoid": [7, 8, 13, 16, 21, 27, 30, 34, 35, 40, 44, 45, 46, 47, 49, 50, 52, 54], "aw": 47, "awai": [4, 6, 13, 18, 27, 32, 39, 41, 43, 45, 46, 47, 50], "awar": [31, 45, 46, 54], "awesom": 9, "ax": [14, 15, 19, 20, 24, 28, 29, 32, 34, 39, 40, 43, 45, 46, 52], "axi": [7, 8, 12, 13, 14, 16, 17, 18, 19, 21, 24, 26, 27, 28, 30, 31, 32, 37, 39, 40, 42, 43, 44, 46], "axvlin": 39, "az": 48, "b": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46], "b3": [30, 37, 48], "babe": [12, 17, 26], "babi": [38, 42], "bachelor": [34, 36, 37], "back": [8, 16, 21, 23, 24, 30, 33, 42, 50], "backdrop": 44, "background": [11, 27, 46, 47], "bad": [8, 13, 14, 15, 18, 19, 20, 25, 27, 28, 29, 31, 34, 35, 36, 37, 38, 39, 43, 44], "badgeryscreek": 44, "bag": [25, 38, 42, 43, 50], "bai": [16, 21, 30, 31, 38], "baidu": [14, 28], "bal_scor": 34, "balanc": [6, 15, 20, 25, 29, 36, 39, 41, 49], "ballarat": 44, "balltre": 25, "balust": 43, "balustrad": 43, "bambi": 41, "banist": 43, "bank": [34, 37, 44, 45], "bannist": 43, "bar": [34, 35, 37, 43, 44, 45, 46, 47], "baranski": 48, "barbu": [1, 54], "barri": 32, "base": [5, 8, 10, 11, 13, 14, 16, 18, 19, 20, 21, 24, 25, 27, 28, 30, 31, 32, 33, 34, 35, 37, 39, 40, 42, 45, 46, 47, 48, 50, 51, 54], "base_scor": 36, "base_valu": 37, "baseblockmanag": 45, "baselin": [24, 45, 47, 50, 51, 53], "baseline_hazard_": 45, "bash": 5, "basi": [13, 15, 18, 20, 27, 29], "basic": [2, 8, 12, 13, 17, 18, 27, 33, 38, 41, 43, 45, 48], "batch": [24, 42, 43], "batch_siz": [24, 43], "batch_t": 43, "bath": [12, 17, 26], "bathroom": [12, 13, 17, 23, 26, 27, 32], "bayesian": 33, "bayesopt": 33, "bazazeh": [1, 54], "beagl": [12, 17, 26, 43], "bear": 43, "beat": [36, 45], "beauti": [41, 42, 46], "becam": 43, "becaus": [1, 7, 8, 10, 14, 15, 16, 20, 21, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54], "becom": [4, 14, 15, 19, 20, 28, 29, 32, 33, 34, 37, 38, 39, 42], "bed": [34, 47], "bedroom": [12, 13, 17, 18, 23, 26, 27, 32], "bedroomabvgr": [35, 37, 46], "bedrooms_per_household": [16, 21, 30, 31, 53], "beef": [25, 42], "been": [1, 4, 6, 12, 13, 16, 17, 21, 26, 27, 30, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 52, 54], "befor": [1, 4, 10, 13, 14, 15, 18, 19, 20, 25, 26, 27, 28, 29, 31, 32, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47, 51, 52], "begin": [25, 27, 32, 38, 41, 44, 45, 50], "beginn": 43, "behav": [33, 37], "behavior": [21, 28, 30, 34, 41, 47, 48], "behaviour": 31, "behind": [11, 12, 17, 26, 32, 54], "being": [4, 12, 14, 16, 17, 19, 21, 26, 28, 30, 34, 35, 36, 37, 40, 42, 45, 46, 52, 54], "belief": 46, "believ": [23, 33, 37, 44], "bell": 43, "belong": [13, 27, 32, 40, 51], "below": [1, 5, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54], "bench": 43, "benchmark": [23, 43], "bendigo": 44, "benefici": [31, 46], "benefit": [4, 15, 29, 36, 40, 42, 46, 50], "bengio": 33, "ber": 42, "bergstra": 33, "berri": 42, "bertop": 42, "best": [2, 13, 14, 15, 18, 19, 20, 21, 23, 27, 28, 29, 33, 34, 35, 36, 37, 39, 40, 41, 45, 46, 47, 51, 52], "best_alpha": 35, "best_c": 24, "best_depth": [14, 19, 23, 28], "best_estimator_": [33, 35], "best_k": 24, "best_n_neighbour": [15, 20, 29], "best_param": [33, 46], "best_paramet": 33, "best_params_": [33, 35, 46], "best_scor": 33, "best_score_": [33, 35], "best_svr": 46, "bestalpha_coeff": 35, "better": [6, 12, 13, 15, 16, 17, 18, 20, 21, 24, 25, 26, 27, 29, 30, 31, 32, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 54], "between": [2, 8, 10, 11, 12, 14, 17, 18, 19, 21, 23, 24, 25, 26, 28, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 52], "bewar": 42, "beyond": [14, 19, 28, 33, 38, 46], "bhatt": [1, 54], "bia": [32, 34, 37, 45, 47, 50], "bias": [11, 34, 37, 42, 45], "bicycl": [13, 18, 27, 44], "big": [7, 15, 20, 25, 29, 31, 33, 34, 36, 38, 39, 40, 41, 42, 43, 45, 46, 52], "bigalpha_coeff": 35, "bigger": [15, 20, 29, 31, 32, 35, 37, 40, 42, 43, 44], "biggest": [35, 38], "bike": 44, "bill": 43, "billboard": 44, "billie_holidai": 42, "billion": 35, "billionth": 44, "bin": [16, 21, 25, 30, 33, 35, 38, 44, 45, 46, 48, 51], "binar": [13, 18, 27, 31], "binari": [13, 16, 18, 21, 25, 27, 30, 31, 32, 43, 45, 46, 49, 50], "binary_feat": [25, 31], "binary_featur": [34, 36, 37], "binary_transform": [34, 36, 37], "bincount": [34, 36], "bind": [15, 20, 24, 29, 52], "binomi": 33, "biolog": 38, "biologi": 31, "bit": [10, 13, 14, 16, 18, 19, 21, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 43, 44, 45, 46], "black": [15, 20, 29, 37, 39, 43, 44], "blackhawk": 42, "bldgtype": [35, 37, 46], "bldgtype_1fam": 35, "bldgtype_2fmcon": 35, "bldgtype_duplex": 35, "bldgtype_twnh": 35, "bldgtype_twnhs": 35, "blei": 42, "blend": 42, "blindli": [34, 35], "blob": [12, 49], "block": [32, 45], "blog": [42, 44], "bloomberg": [1, 9], "blq": [35, 37, 46], "blue": [13, 15, 18, 20, 27, 29, 33, 34, 37, 38, 39, 44], "bluesman": 42, "bmatrix": [38, 41], "board": 4, "boathous": 43, "bob_dylan": 42, "boggl": 36, "bold": 46, "bond": [34, 47], "bonu": 36, "book": [9, 34, 35, 41, 42, 44, 46, 54], "bool": [35, 44], "bool_t": 25, "boom": 48, "boost": [42, 47, 50], "booster": 36, "bootstrap": [10, 46], "border": [13, 27, 32, 40, 42, 49, 51], "bore": 32, "boston": 32, "both": [2, 6, 13, 14, 15, 18, 19, 20, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 50, 53, 54], "bother": 37, "bottom": 40, "bought": 41, "bound": [38, 45], "boundari": [14, 19, 28, 40, 42, 46, 47, 52], "bow_df": 31, "box": [9, 37, 50], "boxplot": 37, "boyc": [18, 27], "br": 42, "bracket": 8, "brain": [38, 43], "branch": [13, 18, 27, 40, 42, 45], "brand": 46, "break": [1, 21, 34, 50, 52], "breakdown": 17, "breakwat": 43, "breath": 50, "breathtak": 42, "breed": 50, "breiman": 36, "brief": [4, 32, 36], "briefli": [12, 17, 26, 34, 36, 38], "bring": [6, 23, 37, 40, 47, 48, 50], "british": [1, 42], "british_columbia": 42, "broad": [15, 20, 24, 29, 42, 52], "broadcast": 42, "broader": [2, 36, 42], "broadest": 42, "broadli": [13, 15, 18, 20, 27, 29, 32, 34, 36, 39, 40, 42], "broth": 25, "brownle": 38, "browser": 10, "brush": 43, "bsmtcond": [35, 37, 46], "bsmtexposur": [35, 37, 46], "bsmtfinsf1": [35, 37, 46], "bsmtfinsf2": [35, 37, 46], "bsmtfintype1": [35, 37, 46], "bsmtfintype2": [35, 37, 46], "bsmtfullbath": [35, 37, 46], "bsmthalfbath": [35, 37, 46], "bsmtqual": [35, 37, 46], "bsmtunfsf": [35, 37, 46], "btw": 37, "bubbl": [41, 43], "bucket": [38, 48], "budget": [33, 41], "bug": [4, 8], "bui": [41, 47], "build": [0, 2, 10, 11, 14, 16, 19, 21, 28, 30, 31, 36, 38, 39, 42, 44, 46, 49, 52], "built": [8, 12, 13, 14, 17, 18, 26, 27, 28, 32, 33, 37, 44, 46, 47], "bullshit": [1, 45], "bulwark": 43, "bunch": [8, 10, 13, 18, 23, 27, 35, 36, 43, 45, 46, 47, 52], "bundl": [7, 10], "bureau": 32, "busi": [34, 39, 45, 48], "businesswoman": 42, "bustl": 44, "butterfli": 40, "buzz": [12, 17, 26], "bypass": 54, "c": [0, 1, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 21, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 52, 54], "c1": 40, "c2": 40, "c_1": 39, "c_2": 39, "c_3": 39, "c_log": [15, 20, 24, 29, 52], "c_val": 24, "c_valu": 24, "c_widget": [15, 20, 24, 29, 52], "ca": [1, 5, 9, 12, 17, 47, 48, 54], "ca_transform": 31, "cache_s": 46, "cal_hous": 32, "calcul": [7, 14, 15, 16, 19, 20, 21, 23, 28, 29, 30, 34, 35, 36, 37, 38, 39, 40, 41, 44, 47, 48, 49, 50, 52], "calgary_flam": 42, "calibr": 47, "california": [16, 21, 30, 38], "california_h": 38, "californian": [16, 21, 30], "call": [1, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52], "callback": 36, "caller": 47, "calm": 50, "came": 44, "camera": 31, "campu": [38, 54], "can": [1, 4, 6, 7, 10, 12, 13, 15, 17, 18, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54], "canada": [5, 14, 15, 19, 20, 28, 29, 31, 32, 42, 46, 48, 50], "canada_usa_c": [13, 14, 15, 19, 20, 27, 28, 29, 32, 51], "canadian": [25, 42], "canadien": 42, "canberra": 44, "cancel": 54, "cancer": [12, 17, 26, 38], "candid": [23, 33, 36, 42, 52], "cannot": [0, 8, 12, 14, 15, 17, 19, 20, 28, 29, 33, 34, 36, 37, 38, 40, 44, 45, 46, 54], "canuck": 42, "canva": [1, 7, 12, 13, 17, 47], "capabl": 9, "capit": [34, 36, 37], "caption": [7, 43], "captiv": 42, "captur": [11, 14, 16, 19, 21, 28, 30, 32, 36, 38, 40, 41, 42, 44, 45, 50], "car": [12, 17, 26, 42, 43, 47], "card": [12, 13, 17, 18, 26, 27, 34, 45, 46], "care": [5, 7, 14, 16, 19, 21, 28, 30, 33, 34, 35, 37, 38, 39, 44, 45, 50], "carefulli": [1, 12, 17, 34, 35, 54], "carpentri": 5, "carri": [13, 14, 15, 18, 19, 20, 23, 25, 27, 28, 29, 31, 33, 34, 35, 36, 39, 41, 42, 44, 47, 48, 52], "caruana": 37, "case": [6, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 25, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 49, 50, 54], "cash": [12, 17, 26], "cast": [33, 41, 48], "castl": 43, "cat": [12, 17, 24, 26, 34, 36, 42, 43, 48, 50], "catamount": [12, 17, 26, 43], "catboost": [11, 37, 46, 50], "catboostclassifi": 36, "catboostregressor": 36, "catch": [34, 54], "categor": [13, 18, 23, 27, 33, 34, 35, 36, 38, 39, 41, 42, 45, 46, 50, 52, 53], "categori": [15, 16, 20, 21, 24, 25, 29, 30, 34, 35, 36, 37, 38, 39, 43, 46, 50], "categorical_feat": [25, 31, 33, 50], "categorical_featur": [31, 34, 35, 36, 37, 44, 45, 46], "categorical_transform": [31, 34, 35, 36, 37, 44, 46], "categories_": [16, 21, 30, 31], "cater": 39, "caus": [34, 37, 38, 41, 45, 54], "causal": [37, 38], "caution": 44, "cbar": 32, "cbtf": [1, 54], "cc": [0, 1], "cc_df": 34, "cconj": 42, "ccp_alpha": 46, "cell": [7, 8, 12, 16, 17, 21, 23, 24, 25, 26, 30, 31, 33, 34, 35, 36, 37, 38, 41, 43, 45, 46, 48, 51, 52], "censor": [1, 11, 46, 47, 50], "censu": [32, 34, 36, 37], "census_df": 34, "cent": 35, "center": [15, 20, 29, 39, 40, 43, 49], "centercrop": 43, "centers_idx": 39, "central": [5, 12], "centralair": [35, 37, 46], "centralair_i": 35, "centralair_n": 35, "centric": [11, 46], "centroid": [39, 40], "centroids_idx": 39, "centroids_idx_init": 39, "centuri": 42, "certain": [10, 15, 20, 29, 32, 33, 34, 37, 38, 39, 42, 45, 46], "certainli": 51, "certainti": 34, "cezannec": 43, "chaat": 42, "chain": 31, "challeng": [6, 11, 14, 17, 28, 38, 39, 41, 43, 44, 47, 50], "chanc": [14, 27, 28, 33, 34, 35, 38, 39, 45, 46, 47], "chang": [0, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 27, 28, 29, 30, 33, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 51, 52, 54], "channel": [1, 10, 43], "chapter": 1, "charact": [31, 34, 42], "characterist": [13, 14, 18, 19, 27, 28, 32], "charg": [0, 12, 17, 26, 45], "charl": 32, "charm": 42, "chart": [37, 44, 45, 46], "chat": 54, "chatgpt": [12, 42], "che210d": 9, "cheaper": 38, "cheat": 9, "check": [1, 4, 7, 10, 12, 13, 14, 16, 17, 18, 19, 21, 26, 27, 28, 30, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 52], "check_arrai": 25, "check_assumpt": 45, "check_consistent_length": 25, "check_invers": 31, "check_param": 25, "check_x_i": 25, "check_y_param": 25, "checklist": 50, "checkmark": 41, "checkout": 33, "cheetah": [12, 17, 26, 43], "chegini": [1, 54], "cherri": 46, "chest": [14, 19, 28], "chetah": [12, 17, 26, 43], "chi": 45, "chicago": 48, "chicken": 39, "child": [34, 37], "children": 41, "chines": [25, 42], "chn": 8, "choic": [2, 19, 33, 35, 36, 37, 39, 40, 41, 44, 48, 52, 53], "choos": [12, 26, 33, 34, 36, 40, 46, 47, 50, 52], "chop": [33, 42, 46], "choreograph": 48, "chose": [23, 46], "chosen": [14, 19, 28, 33, 34, 45, 46, 50], "chrbv": 45, "christin": 48, "christma": 48, "chrome": [12, 17], "chunki": 39, "churn": [46, 50], "ciml": 1, "cinematographi": 42, "cinereu": 43, "circl": [15, 20, 29, 34], "circumst": 7, "citat": 7, "cite": 45, "citi": [13, 14, 15, 19, 20, 27, 28, 29, 42, 44, 46, 50, 51], "citibik": 44, "cities_df": [15, 20, 29, 32], "citizen": 45, "cityscap": 44, "civ": [34, 36, 37], "clai": 37, "claim": [0, 33, 34], "clarif": 39, "clarifi": 50, "clariti": 11, "class": [1, 4, 5, 10, 13, 14, 15, 16, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31, 32, 38, 39, 42, 44, 45, 46, 47, 51, 52], "class_attend": [13, 14, 18, 19, 27, 28, 50], "class_attendance_enc": 31, "class_attendance_level": 31, "class_label": 34, "class_labels_fil": [12, 17, 26], "class_nam": [13, 15, 18, 20, 24, 27, 29, 36, 43], "class_sep": 34, "class_weight": [36, 46], "classes_": [32, 34, 36, 37, 43, 49], "classic": [15, 20, 29, 43, 49], "classif": [1, 2, 11, 14, 15, 16, 19, 20, 21, 23, 25, 28, 29, 30, 31, 32, 35, 36, 37, 38, 41, 42, 44, 45, 46, 49, 51, 52], "classifi": [14, 15, 16, 19, 20, 21, 24, 28, 29, 30, 31, 33, 34, 37, 43, 46, 49, 51, 53], "classification_df": [13, 14, 18, 19, 27, 28], "classification_report": [34, 43], "classifiers_ndt": 36, "classify_imag": [12, 17, 26, 43], "classmat": [6, 52, 53, 54], "classroom": [1, 47], "clean": [2, 12, 17, 23, 25, 26, 40, 46, 54], "clean_text": 42, "cleaned_hm": [34, 47], "cleaned_restaurant_data": 25, "cleaner": [34, 37], "clear": [7, 11, 34, 39, 47, 52], "clearli": [4, 6, 7, 33, 36, 37, 44], "cleric": [34, 36, 37], "clever": 46, "clf": [12, 13, 15, 17, 18, 20, 26, 27, 29, 32, 43], "click": [1, 5, 7, 34, 41, 46, 47], "client": [41, 47], "clinic": [13, 18, 27], "clip": [12, 17, 24, 26], "clone": [5, 7, 10], "close": [2, 12, 14, 15, 19, 20, 24, 28, 29, 32, 33, 34, 39, 40, 42, 44, 48, 49, 52, 54], "close_default_lr": 34, "close_zero_svm": 34, "closer": [15, 16, 20, 21, 29, 30, 32, 41, 51, 54], "closest": [15, 16, 19, 20, 21, 29, 30, 34, 39, 40, 42, 44], "cloth": 44, "cloud": [12, 13, 14, 16, 17, 18, 19, 20, 21, 26, 27, 31, 32, 33, 34, 35, 36, 48, 54], "cloud3pm": 44, "cloud9am": 44, "clust_label": 39, "cluster": [1, 2, 11, 41, 42, 44, 47], "cluster_cent": 39, "cluster_centers_": 39, "cluster_std": [40, 43], "clutter": [13, 27], "cm": [15, 20, 24, 29, 32, 34, 37, 41, 52], "cmap": [16, 21, 30, 33, 34, 37, 43], "cmn": 35, "cmp": 45, "cnn": [43, 44], "co": [31, 42], "coast": 43, "cockpit": 46, "code": [4, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53], "codecademi": 9, "coef": [44, 45, 48], "coef0": 46, "coef_": [32, 35, 36, 37, 38, 41, 43, 44, 45, 48, 49], "coef_df": [32, 37], "coef_nonzero": 44, "coeff": 32, "coeff_df": 44, "coeffici": [35, 36, 38, 41, 43, 44, 45, 46, 48, 49, 50], "coefs_df": 38, "coher": 39, "col": [13, 18, 27, 31, 32, 41, 44, 50], "col1": 8, "col2": 8, "col3": 8, "col4": 8, "col5": 8, "col6": 8, "cold": [16, 21, 30], "colinear": 37, "collabor": [5, 11, 41, 54], "collaps": 37, "colleagu": [8, 9], "collect": [11, 12, 13, 16, 17, 18, 21, 25, 26, 27, 30, 31, 34, 36, 37, 38, 41, 42, 43, 44, 45, 47, 50], "colleg": [34, 36, 37], "collinear": 38, "color": [32, 37, 38, 39, 40, 44, 46], "color_continuous_scal": 38, "color_threshold": 40, "colorbar": [16, 21, 30, 32], "colour": [31, 32, 33, 37, 39, 40, 43], "colsample_bylevel": 36, "colsample_bynod": 36, "colsample_bytre": 36, "columbia": [1, 9, 42], "column": [7, 12, 13, 14, 15, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 53], "column_nam": 31, "column_stack": 38, "columntranform": 53, "columntransform": [1, 16, 21, 25, 30, 33, 34, 35, 36, 37, 38, 44, 45, 46, 48], "columntransformer__countvectorizer__max_featur": 33, "columntransformercolumntransform": [31, 33, 35, 36, 38, 48], "columntransformerifittedcolumntransform": [31, 35, 46], "columntransformerinot": [31, 36], "com": [0, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 26, 27, 31, 32, 33, 34, 35, 36, 43, 44, 45, 47, 48, 54], "comat": 42, "combin": [13, 16, 18, 21, 25, 27, 30, 31, 33, 34, 38, 41, 43, 44, 45, 46, 51, 52], "come": [10, 12, 13, 16, 17, 18, 21, 23, 25, 26, 27, 30, 31, 34, 38, 41, 42, 43, 44, 45, 46, 51], "comedi": 41, "comfort": 5, "command": [4, 10, 34, 42, 47], "comment": [8, 9, 25], "commerci": 0, "commit": [7, 34, 54], "common": [1, 8, 11, 13, 14, 15, 18, 19, 20, 24, 27, 28, 29, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 47, 49, 52, 54], "commonli": [13, 16, 18, 21, 27, 30, 33, 34, 39, 45], "commonwealth": 42, "commun": [1, 2, 10, 11, 31, 33, 35, 47, 54], "commut": 8, "comp_dict": 34, "compact": [33, 38], "compani": [34, 39, 41, 42, 45, 48], "compar": [8, 11, 13, 14, 15, 16, 18, 19, 20, 21, 23, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 49, 50], "comparison": [25, 40, 43, 45, 50], "compassion": 54, "compat": [8, 37], "compatibitl": 8, "compel": 44, "compet": 48, "competit": [36, 43, 49], "complain": [6, 48], "complaint": [6, 54], "complement": 42, "complet": [1, 6, 7, 12, 16, 17, 19, 21, 25, 26, 30, 33, 36, 37, 38, 40, 42, 45, 46, 51, 52, 54], "complex": [11, 13, 15, 18, 20, 24, 25, 27, 29, 32, 33, 35, 36, 37, 38, 40, 42, 43, 44, 47, 52], "complex_warn": 25, "complexwarn": 25, "compli": 0, "complic": [4, 13, 14, 18, 24, 25, 27, 28, 33, 35, 38], "compon": [31, 34, 41, 44, 46, 47, 54], "components_": 42, "compos": [15, 24, 25, 29, 31, 33, 34, 35, 36, 37, 38, 43, 44, 45, 46, 53], "composit": 31, "compound": [42, 43, 45, 48], "comprehend": [24, 42], "comprehens": [39, 50, 54], "compress": [31, 39, 42], "compris": [12, 13, 17, 18, 26, 27, 39], "comput": [1, 7, 9, 10, 11, 24, 26, 31, 33, 34, 36, 37, 38, 39, 40, 42, 44, 46, 47, 49, 54], "computation": 38, "compute_class_weight": 34, "computer_programm": 42, "coms4995": [16, 21, 30], "con": [39, 42, 43, 46], "concat": [12, 15, 16, 17, 20, 21, 26, 29, 30, 31, 32, 37], "concaten": [31, 42], "concav": 38, "concensu": [14, 28], "concentr": [33, 50], "concept": [1, 11, 13, 14, 18, 19, 25, 27, 28, 37, 38, 39, 44, 50, 52, 54], "conceptnet": 42, "conceptu": [36, 46], "concern": [4, 11, 17, 23, 31, 36, 54], "concess": [1, 7], "concis": [13, 18, 27, 47], "conclus": 46, "concord": 45, "concordance_index": 45, "concordance_index_": 45, "concret": [12, 17, 26, 46], "conda": [12, 17, 24, 26, 34, 35, 36, 37, 39, 42, 45, 48], "condens": 18, "condit": [0, 12, 13, 17, 18, 23, 26, 27, 31, 38, 42, 45], "condition1": [35, 37, 46], "condition1_arteri": 35, "condition1_feedr": 35, "condition1_norm": 35, "condition1_posa": 35, "condition1_posn": 35, "condition1_rra": 35, "condition1_rran": 35, "condition1_rrn": 35, "condition1_rrnn": 35, "condition2": [35, 37, 46], "condition2_arteri": 35, "condition2_feedr": 35, "condition2_norm": 35, "condition2_posa": 35, "condition2_posn": [35, 37], "condition2_rra": 35, "condition2_rran": 35, "condition2_rrnn": 35, "conditional_aft": 45, "conduct": [11, 17], "confer": 42, "confid": [12, 14, 17, 19, 26, 28, 37, 45, 47, 50, 52], "confidenti": 34, "config": 10, "config_context": 25, "configur": [33, 35, 36], "confirm": 10, "conflict": [10, 40, 54], "confound": 38, "confus": [8, 15, 20, 29, 31, 35, 39, 47, 52], "confusingli": [12, 17], "confusion_matrix": [34, 43, 45], "confusionmatrixdisplai": 34, "congrat": 31, "conjunct": 38, "connect": [0, 13, 18, 27, 40, 41, 47], "connot": 42, "conort": 38, "consciou": 54, "consecut": 44, "consequ": [7, 12, 17, 26, 31, 34, 41, 46], "consid": [4, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 50, 52, 54], "consider": [2, 11, 34, 36, 39, 41, 45, 46, 47], "consist": [6, 7, 13, 14, 16, 18, 19, 21, 25, 27, 28, 30, 39, 47, 48], "const": 42, "constant": [13, 18, 27, 34, 35, 36, 37, 44, 45, 46], "constitu": 36, "constitut": [42, 54], "construct": 41, "constructor": [13, 16, 21, 27, 30], "consult": [15, 20, 24, 29, 52, 54], "consum": [12, 17, 26, 38, 39, 41, 47, 50], "consumpt": 44, "contact": [12, 17, 26, 54], "contain": [8, 10, 12, 13, 16, 17, 18, 21, 25, 26, 27, 30, 31, 32, 35, 41, 42, 43, 47, 48, 49], "container": 47, "content": [1, 4, 10, 11, 17, 39, 42, 43, 47, 50, 54], "contest": 6, "context": [11, 13, 16, 18, 21, 27, 30, 32, 33, 34, 36, 37, 38, 40, 41, 43, 44, 46, 50, 52], "contextu": 11, "contin": 31, "conting": 40, "continu": [25, 31, 33, 35, 36, 38, 42, 44, 46], "contract": [0, 45], "contract_month": 45, "contract_on": 45, "contract_two": 45, "contrast": [11, 50], "contribut": [15, 20, 29, 32, 37, 43, 54], "control": [5, 8, 13, 14, 15, 18, 19, 20, 27, 28, 29, 31, 32, 35, 36, 43, 54], "convei": 11, "conveni": [8, 12, 17, 33, 34, 39, 42, 44, 45, 46, 47], "converg": 39, "convers": [34, 35, 37, 42, 47], "convert": [12, 16, 17, 21, 25, 26, 30, 31, 32, 36, 37, 38, 42, 44, 45, 54], "convinc": [31, 46], "convolut": [38, 43], "convolutional_neural_network": 43, "cooccurrencematrix": 42, "cook": 39, "cool": 43, "coolwarm": 32, "coordin": [17, 54], "copi": [0, 7, 8, 10, 13, 18, 25, 27, 33, 36, 37, 39, 41, 43, 44, 45, 46, 54], "copyright": 0, "cor": 37, "coral": 43, "core": [9, 11, 16, 21, 25, 28, 30, 31, 33, 34, 35, 38, 40, 41, 44, 45, 47, 50], "corefer": 42, "corei": 47, "corgi": [12, 17, 26, 43], "corona_nlp_test": 48, "coronapocalyps": 48, "coronaviru": 48, "corpor": [5, 48], "corpora": [31, 42], "corpu": [31, 34, 42], "corr": 37, "corr_df": 37, "correct": [7, 12, 13, 14, 15, 17, 18, 19, 20, 26, 27, 28, 29, 34, 36, 37, 45, 46, 51, 52], "correctli": [1, 10, 13, 14, 18, 19, 27, 28, 34], "correl": [44, 50], "correspond": [1, 12, 13, 14, 15, 17, 18, 19, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 39, 41, 44, 52, 54], "cosin": 42, "cosine_similar": 42, "cost": [8, 12, 17, 26, 43, 46, 54], "cost_rep": 8, "costco": 42, "costli": 34, "cot": 43, "cote": 43, "could": [6, 8, 13, 14, 15, 16, 18, 19, 20, 21, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 41, 42, 44, 45, 46, 47, 52, 54], "couldn": 42, "count": [8, 13, 16, 18, 21, 23, 25, 27, 30, 31, 34, 35, 38, 42, 43, 44, 45, 47, 48, 49, 52, 54], "counter": 34, "counti": [23, 52], "countri": [14, 15, 19, 20, 28, 29, 31, 32, 34, 36, 37, 42, 54], "country_columbia": 37, "country_dominican": 37, "country_guatemala": 37, "country_hondura": 37, "country_hong": 37, "country_hungari": 37, "country_india": 37, "country_iran": 37, "country_miss": [36, 37], "country_puerto": 37, "country_scotland": 37, "country_south": 37, "country_taiwan": 37, "country_thailand": 37, "country_trinadad": [36, 37], "country_unit": [36, 37], "country_vietnam": [36, 37], "country_yugoslavia": [36, 37], "countvector": [12, 17, 25, 26, 32, 33, 34, 42, 47, 48, 50], "countvectorizercountvector": [31, 33, 48], "countvectorizeroriginaltweet": 48, "countvectorizersong_titl": 33, "coupl": [4, 13, 27, 33, 40, 48], "cour": 42, "cours": [2, 4, 5, 6, 7, 10, 13, 14, 18, 19, 23, 24, 25, 27, 28, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 48, 50, 51, 52], "coursera": [1, 9], "coursework": 54, "court": 42, "covari": [13, 18, 27, 45], "cover": [8, 11, 17, 34, 36, 39, 43, 44, 54], "coverag": 34, "covid": 48, "covid2019": 48, "cow": 46, "cox": 11, "coxph_fitt": 45, "coxphfitt": 45, "cph": [45, 46, 50], "cph_param": 45, "cpsc": [9, 10, 13, 18, 26, 27, 36, 38, 42, 43, 44, 46, 47, 48, 54], "cpsc330": [0, 1, 10, 12, 17, 18, 22, 24, 25, 26, 27, 28, 31, 33, 37, 42, 43, 45, 47, 48, 54], "cpsc330env": 10, "cpu": [24, 33, 43], "craft": [15, 20, 29, 34, 36, 37, 39, 52], "crash": 1, "crate": 43, "crazi": [25, 47], "creat": [8, 9, 10, 12, 15, 16, 17, 20, 21, 23, 24, 25, 26, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53], "create_lag_df": 44, "create_lag_featur": 44, "create_y_from_r": 41, "creativ": [1, 42], "credenc": 46, "credit": [0, 13, 18, 27, 34, 36, 42, 44, 45, 46], "creditcard": 34, "crime": 32, "crimin": 37, "criteria": [13, 18, 27, 40], "criterion": [40, 46], "critic": [11, 46], "cross": [13, 15, 18, 25, 27, 29, 31, 33, 35, 36, 37, 39, 41, 45, 46, 47, 48, 50, 53], "cross_val": 36, "cross_val_predict": [34, 36, 45], "cross_val_scor": [16, 21, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38, 44, 45, 46, 50, 53], "cross_valid": [15, 16, 20, 21, 23, 24, 25, 29, 30, 31, 32, 33, 34, 36, 37, 38, 41, 44, 45, 46, 47, 48, 50, 52, 53], "cross_validate_std": [14, 19, 28], "crowd": [36, 40], "crown": 54, "crown_princ": 42, "crucial": [12, 14, 17, 19, 26, 28, 32, 37, 39, 40, 41, 42], "crude": 42, "cs189": 9, "cs189_ch7": 9, "csr": 25, "css": 47, "csv": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53], "ct": 31, "cuda": [24, 43], "cui": [1, 54], "cuisin": 47, "cultiv": 11, "cultur": [43, 54], "curios": [12, 17, 26], "curiou": [12, 17, 26, 52], "curl": 47, "current": [1, 36, 42, 43, 44, 45, 46, 47, 48], "curriculum": 11, "curs": 46, "curv": [7, 8, 11, 39, 46, 50, 52], "custom": [5, 8, 12, 13, 17, 18, 25, 26, 27, 31, 34, 35, 41, 47, 48, 50], "custom_plot_tre": [13, 14, 18, 19, 27, 28, 36, 37], "customerid": 45, "customiz": 48, "cut": 40, "cv": [14, 19, 23, 24, 28, 31, 34, 35, 36, 37, 38, 44, 45, 46, 47, 50, 52], "cv_feat": 48, "cv_results_": [33, 35], "cv_score": [14, 19, 24, 28, 35], "cv_train_scor": [23, 52], "cv_valid_scor": [23, 52], "cycl": 8, "cyclic": 44, "cycling_data": 8, "cygnu": 43, "d": [4, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47], "d3": 39, "da": [12, 17, 26], "dabeaz": 9, "dad": 38, "dai": [4, 8, 14, 25, 38, 43, 45, 46, 50, 54], "daili": [45, 50], "dall": 44, "damag": [0, 34], "dan": 42, "danceabl": [15, 16, 21, 29, 30, 33], "dark": 48, "darker": 33, "dashboard": [15, 20, 24, 29, 52], "data": [1, 2, 5, 7, 8, 9, 10, 11, 24, 40, 42, 45, 49, 50, 51, 53, 54], "data_dict": 32, "data_dir": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52], "data_to_wrap": 31, "data_transform": [24, 43], "data_transforms_bw": 43, "data_url": 34, "datacamp": 9, "datafram": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 52, 53], "dataload": [24, 43], "dataloaders_bw": 43, "datapoint": 32, "dataquest": 9, "dataset": [8, 11, 12, 14, 15, 17, 19, 20, 23, 24, 25, 26, 28, 29, 36, 37, 38, 39, 40, 45, 47, 48, 49, 50, 52], "dataset2": 39, "dataset_s": [24, 43], "dataviz": 46, "date": [7, 10, 12, 13, 17, 23, 26, 27, 41, 42, 45, 47, 48, 50, 52, 54], "date_rang": 44, "dates_rain": 44, "datetim": 45, "datetime64": 44, "datetimeindex": 44, "datum": 42, "daughter": [34, 47], "daum\u00e9": 1, "daunt": 41, "dave": 42, "david": [1, 42, 46], "day_nam": 44, "daylight": 44, "dayofweek": 44, "days_sinc": 44, "dbscan": [11, 47], "dc": [44, 45, 48], "dcc": 32, "dd": 44, "de": [42, 44], "deactiv": 10, "deadlin": [14, 17, 54], "deal": [0, 14, 15, 16, 19, 20, 21, 25, 28, 29, 30, 35, 42, 45, 46, 47, 50, 53], "death": 54, "debat": [8, 17, 37], "debbi": 48, "debug": [4, 37], "decad": 43, "decemb": [23, 44], "decid": [8, 13, 15, 18, 20, 27, 29, 32, 36, 37, 38, 39, 40, 42, 44, 45, 50], "decis": [1, 2, 6, 14, 16, 19, 21, 28, 30, 33, 34, 36, 38, 43, 49, 50, 51, 53, 54], "decision_boundari": 49, "decision_funct": 34, "decisiontreeclassifi": [14, 15, 16, 19, 20, 21, 24, 28, 29, 30, 31, 32, 33, 37, 51, 52, 53], "decisiontreeclassifierdecisiontreeclassifi": 36, "decisiontreeregressor": [13, 18, 23, 27, 35, 51, 52], "decisiontreeregressorifitteddecisiontreeregressor": 23, "deck": 9, "declar": 54, "decomposit": [40, 41, 42], "decor": 25, "decreas": [14, 19, 23, 28, 32, 33, 36, 37, 39, 52], "deduct": 7, "deem": 6, "deep": [2, 9, 33, 37, 38, 42, 45, 47], "deepen": [50, 54], "deeper": [2, 12, 17, 33, 34, 35, 37], "deepexplain": 37, "def": [14, 15, 16, 19, 20, 21, 24, 25, 28, 29, 30, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 47, 48, 52], "default": [5, 10, 12, 13, 14, 17, 18, 19, 24, 27, 28, 31, 32, 33, 34, 35, 36, 39, 40, 43, 44, 45, 46, 49, 54], "default_check_param": 25, "default_threshold": 34, "defaultdict": 41, "defin": [13, 15, 16, 20, 21, 25, 27, 29, 30, 31, 34, 36, 37, 39, 40, 41, 44, 47], "definit": [8, 15, 20, 29, 37, 39, 42, 44, 49, 50, 51], "degre": 34, "degrees_freedom": 45, "degrees_of_freedom": 45, "del": 36, "delai": [1, 10, 38], "deleg": 42, "delet": [4, 7, 16, 21, 30, 46], "delgado": 36, "delight": 42, "deliver": 7, "delv": [11, 42], "demo": [1, 17, 36, 46, 54], "demograph": [13, 18, 27, 41], "demonstr": [13, 14, 16, 18, 19, 21, 24, 25, 27, 28, 30, 32, 33, 35, 36, 39, 41, 42, 43], "denois": 12, "denomin": [35, 48], "denot": [13, 18, 27, 41], "dens": [40, 42], "densenet": [24, 43], "densenet121": [24, 43], "densenet121_weight": [24, 43], "densiti": [37, 40, 50], "dep": 42, "department": 54, "departur": 38, "depend": [2, 8, 10, 13, 14, 15, 18, 19, 20, 27, 28, 29, 31, 33, 34, 35, 36, 37, 39, 40, 42, 44, 45, 46], "dependence_plot": 37, "dependents_no": 45, "dependents_y": 45, "deploi": [14, 19, 23, 28, 34, 41, 46, 50], "deploy": [11, 37, 44], "deprec": [21, 28, 30, 34, 35, 45, 48, 49], "deprecationwarn": [36, 45], "depth": [1, 13, 14, 18, 19, 23, 27, 28, 33, 36, 40, 51, 52], "dequ": [36, 37], "deriv": [0, 13, 18, 27, 32, 34, 41, 45, 50], "descend": [8, 40, 43, 50], "descent": 44, "descr": 32, "describ": [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 32, 34, 35, 41, 42, 44, 47, 52], "descript": [1, 35, 45, 48], "desenet": 24, "deserv": 6, "design": [11, 18, 27, 37, 40, 43, 46, 54], "desir": [25, 34, 42, 45, 53], "desk": 54, "despit": [38, 42], "det": [42, 48], "detach": [24, 43], "detail": [15, 20, 29, 31, 36, 42, 43, 47, 54], "detect": [12, 13, 17, 18, 23, 26, 27, 34, 35, 39, 40, 44, 47], "determin": [15, 18, 20, 24, 29, 39, 40, 42, 45, 46, 52, 54], "detriment": [34, 41], "dev": [14, 28, 49], "develop": [1, 9, 11, 12, 14, 16, 17, 19, 21, 26, 28, 30, 31, 33, 34, 35, 36, 42, 43, 46, 47, 48, 50], "devianc": 45, "deviat": [6, 14, 16, 19, 21, 28, 30, 36, 37], "devic": [24, 25, 36, 43], "deviceprotect": 45, "deviceprotection_no": 45, "deviceprotection_y": 45, "df": [12, 13, 14, 16, 17, 19, 21, 23, 25, 26, 27, 28, 30, 31, 33, 34, 35, 37, 38, 43, 44, 45, 46, 47, 48, 51], "df_concat": [12, 17, 26], "df_float_1": 8, "df_float_2": 8, "df_hour_week_ohe_poli": 44, "df_locat": 44, "di": 45, "diagnos": [14, 28, 37, 50], "diagnosi": 34, "diagnost": [45, 47], "diagon": [15, 20, 29, 34, 37], "diagram": [31, 33, 36, 37], "dialogu": 42, "dict": [34, 41], "dict_kei": 36, "dictionari": [8, 16, 21, 30, 33, 34, 36, 37, 47], "did": [6, 12, 13, 15, 17, 18, 20, 27, 29, 37, 39, 42, 44, 48, 52, 54], "didn": [25, 33, 36, 37, 40, 42, 44, 45, 47], "die": 48, "diet": [13, 18, 27, 42], "diff": 44, "differ": [1, 2, 5, 7, 8, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 23, 25, 26, 27, 28, 29, 31, 32, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 51, 52], "differenti": [11, 12, 13, 17, 18, 26, 27], "difficult": [4, 6, 7, 34, 38, 39, 46], "difficulti": [39, 50], "dig": [34, 35], "digit": [44, 46], "dilemma": 41, "dim": [24, 25, 43], "dimens": [8, 32, 38], "dimension": [2, 8, 18, 24, 32, 33, 34, 36, 38, 39, 42], "dine": 47, "direct": [21, 32, 37, 38, 40, 42, 48], "direct_bilirubin": [12, 17, 26], "directli": [1, 8, 25, 31, 35, 43, 45, 47, 54], "director": 41, "directori": [10, 13, 14, 16, 19, 21, 24, 27, 28, 30], "dirichlet": [42, 43], "disabl": 42, "disadvantag": [33, 36, 40, 41, 53], "disast": [12, 26], "discard": [38, 42], "disciplin": [34, 38], "disclos": [48, 54], "discourag": 8, "discours": 41, "discov": [38, 39], "discoveri": [12, 17, 26], "discret": [13, 18, 25, 27, 38], "discrete_scatt": [13, 14, 15, 18, 19, 20, 24, 27, 28, 29, 32, 39, 40, 43, 49, 51, 52], "discretization_feat": 38, "discrimin": 36, "discuss": [4, 14, 15, 16, 19, 20, 21, 28, 29, 30, 32, 37, 38, 39, 40, 44, 50, 52, 53, 54], "diseas": [13, 18, 27, 34, 45], "dislik": [25, 46], "displaci": [42, 48], "displai": [7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 41, 43, 44, 45, 51, 52, 53], "display_heatmap": 33, "display_label": 34, "displaystyl": 42, "disput": 42, "disrespect": 4, "dissemin": 47, "dist": [15, 20, 24, 29, 39, 40], "distanc": [8, 16, 21, 24, 30, 38, 40, 41, 42], "distinct": [34, 38, 44, 46], "distinguish": [13, 15, 18, 20, 24, 27, 29, 31, 34, 52], "distract": 54, "distribut": [0, 10, 12, 14, 19, 23, 25, 28, 34, 37, 38, 40, 42, 43, 44, 54], "district": [16, 21, 30, 32], "districtdatalab": 39, "disturb": [12, 17, 26], "dive": 37, "divers": [11, 36, 39, 41, 44], "divid": [32, 34, 36, 37, 44, 52], "divis": [18, 37], "divorc": [36, 37], "dktal": 45, "dlwqn": 45, "dmp": 54, "do": [0, 1, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 17, 18, 19, 20, 23, 24, 26, 27, 28, 29, 32, 35, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54], "dobj": 42, "doc": [8, 9, 12, 37, 42, 43, 47, 48, 54], "doc_id": 42, "docker": 47, "doctor": [34, 36, 37], "document": [0, 1, 7, 12, 13, 14, 16, 17, 19, 21, 23, 24, 25, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 48, 50, 54], "document_top": 42, "documentari": 41, "doe": [5, 8, 10, 12, 14, 15, 16, 17, 20, 21, 24, 25, 26, 28, 29, 30, 33, 35, 36, 37, 38, 39, 41, 42, 44, 45, 47, 48, 50, 52, 54], "doesn": [7, 8, 12, 14, 16, 19, 21, 28, 30, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 50], "dog": [24, 34, 43], "dolist": 47, "dollar": [4, 32, 35, 46], "dolli": 48, "domain": [0, 12, 17, 26, 37, 39, 42], "domin": [16, 21, 30, 35, 43], "domingo": [1, 14, 28, 38], "dominican_republ": 42, "don": [4, 12, 13, 14, 16, 17, 19, 23, 24, 25, 26, 28, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], "done": [5, 10, 12, 14, 17, 19, 28, 31, 33, 34, 43, 44, 46, 50, 53], "dont": 48, "door": 43, "dosa": 42, "dot": [15, 20, 29, 32, 34, 36, 37, 38, 40, 42], "dot_product": 42, "doubl": 33, "down": [14, 19, 28, 34, 37, 42, 45, 46, 52, 54], "downfal": 41, "download": [5, 7, 10, 12, 13, 16, 17, 21, 23, 26, 27, 30, 32, 34, 35, 37, 42, 43, 46, 48, 52], "downright": 46, "dpi": [24, 38], "dr": 42, "draft": 1, "drag": 7, "drama": 41, "drastic": 34, "draw": [32, 33, 42, 46], "drawback": [11, 37, 41], "drawn": 36, "dream": 43, "dreampharmaceut": 42, "drink": 46, "drinker": 42, "drive": [12, 17, 26, 37], "driven": [10, 33, 34], "droit": 42, "drop": [7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 44, 45, 46, 47, 48, 50, 52, 53, 54], "drop_dupl": [15, 20, 29, 33], "drop_feat": [25, 31, 50], "drop_featur": [34, 35, 36, 37, 44, 45, 46, 48], "dropdrop": [31, 35, 36, 46, 48], "drope": [16, 21, 30], "dropna": [34, 44, 47], "dropoff": 39, "drug": [12, 17, 26, 47], "dsci": [1, 9, 37, 46, 49], "dsl": 45, "dt": [23, 52], "dt_best": 52, "dt_final": 23, "dt_pipe": 33, "dt_regr": 23, "dtype": [13, 14, 15, 16, 18, 19, 20, 21, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48], "dtypelik": 25, "dual": 34, "duan": [1, 54], "duck": [43, 46], "duckbil": 43, "due": [7, 12, 13, 14, 16, 17, 32, 36, 38, 41, 54], "dummi": [13, 15, 16, 18, 20, 21, 23, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 43, 44, 45, 46, 51, 53], "dummy_clf": [13, 18, 27, 51], "dummy_regr": 23, "dummy_scor": [15, 20, 29], "dummy_valid_accuraci": [15, 20, 29], "dummyclassifi": [14, 15, 16, 19, 20, 21, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 43, 46, 47, 48, 51, 52, 53], "dummyregressor": [23, 31, 36, 37, 38, 46, 47, 53], "dump": 47, "dun": [12, 17, 26], "dunno": [12, 17, 26], "duplex": 35, "duplic": 8, "durat": [7, 38, 44, 45], "duration_col": 45, "duration_m": [15, 16, 21, 29, 30, 33], "dure": [1, 4, 8, 12, 13, 15, 17, 18, 20, 23, 26, 27, 29, 31, 32, 33, 36, 37, 38, 41, 42, 47, 50, 51, 52, 53, 54], "dwell": 35, "e": [6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50], "e737c5242822": 45, "e_": [14, 19, 28], "each": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54], "eager": 47, "earli": [37, 45, 46, 54], "earlier": [16, 21, 30, 36, 38, 44, 45], "early_stopping_round": 36, "earnest": 54, "easi": [7, 15, 16, 20, 21, 29, 30, 32, 36, 37, 38, 39, 40, 42, 46, 48], "easier": [5, 7, 34, 37, 38, 41, 46], "easiest": [37, 45], "easili": [36, 38, 44, 46, 47, 51], "east": 25, "eat_out_freq": 25, "echidna": 43, "econom": [31, 44], "ecosystem": 43, "eda": [14, 19, 23, 25, 28, 42, 45, 50], "edg": [13, 18, 27, 33], "edgecolor": [33, 44], "edit": [33, 42], "edu": 9, "educ": [34, 36, 37, 41], "education_level": [34, 36, 37], "effect": [15, 20, 23, 24, 29, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 47, 50, 52, 54], "effici": 33, "effort": [4, 10, 33, 38, 39, 41, 43, 54], "egg": 39, "either": [4, 13, 14, 15, 18, 19, 20, 24, 27, 28, 29, 31, 34, 37, 39, 40, 42, 43, 44, 52], "elast": 45, "elbow": 40, "elect": 42, "electr": [35, 37, 46], "electrical_engin": 42, "electrical_fusea": 35, "electrical_fusef": 35, "electrical_fusep": 35, "electrical_miss": 35, "electrical_mix": 35, "electrical_sbrkr": 35, "electron": [45, 54], "eleg": [16, 21, 30, 42, 46], "elegantli": 42, "element": [0, 1, 9, 14, 28, 31, 42, 51], "eli5": 37, "elif": [13, 18, 27, 44, 45], "elimin": 11, "els": [13, 18, 24, 25, 27, 31, 34, 43, 44, 45, 48], "email": [1, 12, 13, 14, 17, 19, 26, 28, 34, 47, 54], "emb": [7, 15, 20, 29, 34, 39, 40], "embed": [1, 11, 31, 43, 47, 50], "emoji": 48, "emoticon": [38, 39], "emp": 37, "empathi": 42, "emphas": 11, "emphasi": [47, 54], "emploi": [24, 44, 45, 47, 50], "employ": 41, "employe": [13, 18, 27], "empti": [24, 32, 42, 43, 44], "en": [44, 45, 46, 48], "en_core_web_lr": 42, "en_core_web_md": [42, 48], "enabl": [10, 41, 42, 44], "enable_categor": 36, "enable_halving_search_cv": 33, "enc": [16, 21, 30, 31, 44], "enclosedporch": [35, 37, 46], "encod": [12, 14, 17, 19, 23, 25, 26, 28, 33, 34, 35, 37, 41, 45, 50, 53], "encompass": [45, 46, 50], "encount": [31, 33], "encourag": 10, "end": [4, 8, 11, 12, 14, 15, 17, 19, 20, 24, 26, 28, 29, 32, 33, 34, 38, 39, 40, 41, 42, 44, 45, 46, 47, 52, 54], "endors": 0, "endpoint": 45, "energi": [15, 16, 21, 29, 30, 33, 44], "engag": 54, "engin": [1, 9, 11, 31, 34, 35, 39, 41, 42, 45, 47], "england": 48, "english": [12, 16, 17, 21, 26, 30, 33, 34, 42, 43, 47, 48], "enhanc": 54, "enjoi": [1, 32], "enjoy_class": 31, "enjoy_cours": [31, 50], "enjoy_course_enc": 31, "enjoy_the_mo": [34, 47], "enough": [7, 15, 20, 29, 31, 34, 35, 36, 39, 41, 50], "enrol": 54, "ensembl": [1, 11, 25, 35, 37, 38, 40, 41, 44, 45, 46, 47], "ensiti": 40, "ensur": [7, 11, 16, 21, 23, 30, 36, 44], "ensure_2d": 25, "ensure_all_finit": 25, "ensure_min_featur": 25, "ensure_min_sampl": 25, "ensure_non_neg": 25, "ent": [42, 48], "enter": [31, 45, 46], "enterpris": 5, "entertain": 42, "enthusiast": [12, 17, 26, 46], "entir": [4, 8, 12, 14, 17, 19, 28, 35, 43, 44, 46, 47, 48, 54], "entiti": [38, 41, 42, 48], "entitl": 31, "entlebuch": [12, 17, 26, 43], "entri": [15, 16, 20, 21, 29, 30, 31, 32, 34, 35, 38, 41, 44, 45], "entropi": [13, 18, 27, 46], "enumer": 36, "env": [10, 18, 24, 25, 27, 28, 31, 33, 37, 45, 48, 49], "environ": [3, 5, 8, 12, 16, 17, 21, 23, 24, 25, 26, 30, 31, 33, 34, 35, 36, 37, 38, 42, 43, 45, 46, 48, 54], "environemnt": 10, "environment": 50, "ep": [13, 14, 15, 19, 20, 27, 28, 29, 32, 40, 51], "epoch": 44, "epsilon": [40, 46], "equal": [8, 15, 20, 29, 31, 34, 35, 36, 37, 40, 41, 44, 50, 54], "equat": [4, 12, 17, 32], "equip": [15, 20, 29, 45, 54], "equival": [8, 34, 36], "erik": 42, "err": 42, "error": [4, 6, 7, 8, 10, 11, 13, 15, 18, 20, 25, 27, 29, 31, 32, 36, 37, 38, 42, 45, 46, 47, 50, 52], "error_": [14, 19, 28], "erupt": [12, 26], "erythrocebu": [12, 17, 26, 43], "es": 44, "eskimo": 34, "esl": 1, "especi": [2, 15, 18, 20, 27, 29, 33, 34, 36, 38, 41, 44], "essenti": [45, 50], "establish": 23, "estat": [13, 18, 27], "estim": [14, 15, 20, 25, 28, 29, 31, 32, 33, 38, 39, 45, 46, 47, 50], "estimator_nam": 25, "estimators_": 36, "et": [36, 42], "etc": [1, 2, 7, 8, 13, 18, 27, 38, 42, 43, 44, 45, 46, 47, 48, 54], "ethic": [1, 11, 47], "euclidean": [39, 40, 42], "euclidean_dist": [15, 16, 20, 21, 29, 30, 39, 40, 42], "ev": 48, "eva": 41, "eva_model": 41, "eval": 43, "eval_metr": [36, 37], "eval_on_featur": 44, "evalu": [1, 8, 11, 13, 14, 18, 19, 23, 27, 28, 33, 35, 37, 39, 44, 46, 47, 52], "evapor": 44, "even": [0, 7, 11, 12, 13, 14, 17, 18, 19, 25, 27, 28, 32, 33, 34, 38, 39, 40, 41, 44, 45, 46, 48, 50, 52, 53, 54], "event": [0, 34, 35, 54], "event_col": 45, "event_observ": 45, "ever": [13, 18, 27, 49], "everi": [8, 12, 13, 14, 17, 18, 19, 27, 28, 36, 40, 44, 52], "everydai": [8, 42], "everyon": [6, 37, 46, 50], "everyth": [12, 17, 31, 34, 41, 44, 47], "everywher": 44, "evict": 48, "evo": 47, "evocarshar": 47, "evok": 42, "ex": [35, 37, 46], "ex1_idx": 37, "ex2_idx": 37, "exact": [4, 45], "exactli": [7, 12, 14, 17, 18, 19, 26, 28, 37, 52], "exagger": 46, "exam": [1, 6, 12, 17, 46, 47], "examin": [14, 15, 16, 19, 20, 21, 23, 24, 25, 28, 29, 30, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49], "exampl": [0, 4, 5, 6, 7, 8, 10, 19, 24, 25, 35, 40, 41, 43, 44, 47, 49, 50, 51, 52, 54], "example1": [13, 18, 27], "example2": [13, 18, 27], "exceedingli": 52, "excel": [31, 32, 35, 37, 45, 50, 53], "except": [0, 1, 7, 8, 14, 19, 25, 28, 44, 45, 54], "exception": 4, "exchang": [34, 50], "excit": 41, "execut": [4, 7, 39, 47], "exercis": [1, 7, 9, 12, 17, 42, 47, 48, 52, 53, 54], "exist": [8, 34, 38, 45, 47], "exp": [32, 45, 46], "expand": [1, 13, 18, 27, 54], "expect": [1, 4, 7, 8, 12, 14, 15, 16, 17, 19, 20, 21, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 49, 50, 52, 54], "expected_valu": 37, "expenditur": 44, "expens": [12, 17, 26, 34, 35, 38, 39, 41], "experi": [12, 17, 26, 33, 41, 42, 54], "experienc": 54, "experiment": [33, 47], "expert": [12, 13, 14, 17, 18, 19, 26, 27, 28, 33, 37, 38], "explain": [4, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 50], "explan": [4, 14, 15, 20, 28, 29, 50], "explanatori": [13, 18, 27], "explicit": [34, 45], "explicitli": [8, 12, 17, 26, 47], "exploit": 6, "explor": [13, 14, 19, 23, 24, 27, 28, 31, 33, 34, 37, 38, 41, 42, 43, 47, 52], "exploratori": [35, 45, 47, 50], "explos": 48, "expm1": [35, 46], "expon": 33, "exponenti": 33, "export_graphviz": [13, 18, 27, 51], "exposur": 41, "express": [0, 8, 31, 32, 38, 42, 46], "extend": [42, 43, 49, 54], "extend_block": 45, "extens": [1, 12, 15, 17, 20, 24, 29, 34, 37, 39, 40, 42, 44, 52, 54], "extent": [39, 42], "extercond": [35, 37, 46], "exterior": 37, "exterior1st": [35, 37, 46], "exterior1st_asbshng": 35, "exterior1st_asphshn": 35, "exterior1st_brkcomm": 35, "exterior1st_brkfac": 35, "exterior1st_cblock": 35, "exterior1st_cemntbd": 35, "exterior1st_hdboard": 35, "exterior1st_imstucc": [35, 37], "exterior1st_metalsd": 35, "exterior1st_plywood": 35, "exterior1st_ston": 35, "exterior1st_stucco": 35, "exterior1st_vinylsd": 35, "exterior1st_wd": 35, "exterior1st_wdsh": 35, "exterior2nd": [35, 37, 46], "exterior2nd_asbshng": 35, "exterior2nd_asphshn": 35, "exterior2nd_brk": 35, "exterior2nd_brkfac": 35, "exterior2nd_cblock": 35, "exterior2nd_cmentbd": 35, "exterior2nd_hdboard": 35, "exterior2nd_imstucc": 35, "exterior2nd_metalsd": 35, "exterior2nd_oth": 35, "exterior2nd_plywood": [35, 46], "exterior2nd_ston": [35, 46], "exterior2nd_stucco": [35, 46], "exterior2nd_vinylsd": [35, 46], "exterior2nd_wd": [35, 46], "external_tool": 47, "exterqu": [35, 37, 46], "extra": [4, 39, 44, 47, 54], "extract": [24, 38, 39, 41, 42, 43, 48, 54], "extractor": 50, "extrapol": [44, 45], "extratreesclassifi": 36, "extrem": [6, 31, 34, 36, 37, 41, 45, 48], "ey": 48, "f": [8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 34, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 52], "f1": [11, 35, 50], "f1_score": 34, "fa": [35, 37, 46], "fac": 48, "face": [12, 13, 15, 17, 24, 26, 27, 29, 41, 43], "facebook": [41, 42, 54], "facial": [15, 29], "facil": 54, "facilit": [8, 54], "fact": [12, 26, 33, 34, 36, 43, 44, 45, 46], "factor": [13, 18, 27, 33, 37, 38, 40, 41, 45], "fail": [1, 7, 8, 10, 14, 16, 19, 21, 28, 30, 31, 38, 40, 42, 45, 46], "failur": [7, 12, 17, 26, 45, 54], "fair": [6, 14, 16, 19, 21, 28, 30, 35, 37, 39, 47, 50, 54], "fairli": [14, 19, 28, 33, 34, 37, 47], "fake": [15, 20, 29], "fall": [15, 20, 29, 39, 42, 44], "fals": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 50], "famili": [12, 17, 26, 33, 34, 35, 36, 37, 39, 47, 54], "familiar": [8, 10, 11, 13, 16, 18, 21, 27, 30, 46, 52, 54], "famou": [1, 9, 42, 43], "fanci": [4, 12, 17, 26, 33], "fancier": 38, "far": [13, 15, 16, 20, 21, 27, 29, 30, 31, 32, 34, 37, 38, 39, 40, 42, 43, 44, 45, 49, 50, 52], "farm": 34, "farthest": [13, 18, 27], "fashion": [18, 36, 42], "fast": [14, 15, 19, 28, 29, 32, 36, 37, 42, 45, 47, 54], "faster": [12, 17, 26, 33, 36, 38, 43], "fastest": 36, "fasttext": 42, "favour": 47, "favourit": 42, "fc": 32, "fcluster": 40, "feat": [25, 33, 44, 48], "feat1": 39, "feat2": 39, "feat_nam": [25, 44, 48], "feat_vec": 41, "featur": [1, 11, 14, 19, 23, 24, 28, 34, 36, 39, 40, 42, 45, 47, 49, 52, 53, 54], "feature_extract": [12, 17, 25, 26, 31, 32, 33, 34, 42, 47, 48], "feature_import": 23, "feature_importances_": [23, 38], "feature_nam": [13, 14, 18, 19, 23, 27, 28, 32, 36, 37, 38, 42], "feature_names_in_": 23, "feature_names_out": 31, "feature_select": 38, "feature_typ": 36, "features_lag": 44, "features_nonzero": 44, "features_poli": 44, "feb": [1, 16], "februari": [23, 44], "feder": [34, 37, 42, 44], "feed": [24, 25], "feedback": [18, 27, 50], "feel": [5, 6, 14, 19, 28, 39, 47, 50], "feli": [12, 17, 26, 43], "fell": 32, "femal": [34, 36, 37, 45], "female_cm": 34, "female_pr": 34, "fenc": [35, 37, 43, 46], "fernandez": 36, "fetch_california_h": 32, "few": [1, 8, 12, 17, 25, 26, 32, 35, 36, 38, 41, 42, 43, 44, 45, 47, 51], "fewer": [10, 36, 38, 40], "feynman": 46, "fiber": 45, "fiction": 48, "field": [2, 4, 11, 12, 17, 26, 31, 42, 43, 44, 47], "fig": [14, 15, 19, 20, 24, 28, 29, 32, 34, 38, 39, 40, 43, 52], "figsiz": [13, 14, 15, 16, 18, 19, 20, 21, 24, 25, 27, 28, 29, 30, 32, 34, 37, 38, 39, 40, 43, 44, 45, 46, 52], "figur": [4, 8, 10, 12, 13, 15, 17, 18, 20, 24, 26, 27, 29, 33, 35, 37, 38, 39, 40, 43, 44, 45, 46, 52], "file": [0, 1, 4, 5, 7, 8, 10, 12, 13, 17, 25, 27, 31, 34, 37, 43, 45, 47], "file_nam": 24, "filenam": 43, "fill": [15, 20, 23, 24, 25, 29, 32, 33, 41, 47, 52, 54], "fill_diagon": [15, 20, 29], "fill_valu": [34, 35, 36, 37, 44, 46], "film": [42, 48], "filter": [4, 11, 12, 14, 17, 19, 26, 28, 39, 44, 50], "filterwarn": [15, 17, 19, 20, 29, 45], "final": [1, 6, 7, 12, 14, 16, 17, 19, 21, 23, 28, 30, 36, 38, 46, 47, 51, 53], "final_estim": 36, "final_estimator_": 36, "financ": [43, 44], "find": [1, 7, 8, 12, 13, 16, 17, 18, 21, 24, 25, 26, 27, 30, 33, 35, 36, 37, 39, 40, 41, 42, 46, 48, 49, 54], "fine": [7, 16, 21, 30, 31, 34, 41, 43, 44, 47], "finish": [12, 17, 26, 35], "fira": [0, 1], "firasm": 34, "firefox": [12, 17], "fireplac": [35, 37, 46], "fireplacequ": [35, 37, 46], "first": [1, 4, 8, 13, 15, 18, 20, 25, 27, 29, 31, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54], "first_dai": 44, "first_day_retail": 44, "first_pass_isfinit": 25, "firth": 42, "fish": [34, 37], "fist": 44, "fit": [0, 12, 14, 15, 17, 19, 20, 23, 24, 25, 26, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54], "fit_intercept": 34, "fit_method": 25, "fit_predict": 40, "fit_resampl": 34, "fit_tim": [14, 15, 16, 19, 20, 21, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 44, 45, 48], "fit_transform": [16, 21, 30, 31, 34, 36, 37, 38, 40, 41, 42, 44, 50], "fittedcolumntransform": [31, 36], "fittedpipelin": [31, 33, 35], "fittedvotingclassifi": 36, "fitter": 45, "five": 33, "fix": [16, 21, 25, 30, 31, 36, 45, 47, 49, 52, 54], "flag": 45, "flagstaff": 48, "flaki": 34, "flashcard": 50, "flask": 47, "flat": 40, "flatten": [24, 36, 37, 40, 44], "flatten_train": 43, "flatten_transform": 43, "flatten_valid": 43, "flaw": [14, 16, 19, 21, 28, 30], "flawless": 32, "flexibl": [7, 12, 26, 38, 43, 50, 54], "flibbertigibbet": 42, "flickr_cat_000002": 43, "flight": 38, "flip": [1, 14, 28, 34, 35, 47], "flip_i": 34, "float": [8, 25, 35, 38, 45, 48], "float32": [42, 43], "float64": [13, 15, 16, 20, 21, 24, 25, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 41, 44, 45], "floatlogslid": [15, 20, 29, 52], "floatslid": [15, 20, 24, 29, 34, 39, 40, 52], "floor": [12, 13, 17, 23, 26, 27, 54], "flower": [15, 20, 24, 29, 34, 47, 52], "fmt": 33, "fn": 34, "fnlwgt": [34, 36, 37], "focu": [1, 11, 12, 16, 17, 21, 25, 26, 30, 31, 32, 37, 40, 41, 42, 44, 50, 52, 53, 54], "focus": [12, 26, 32, 39, 42, 50], "fold": [14, 16, 19, 21, 28, 30, 31, 33, 34, 35, 36, 47, 52], "folder": [5, 6, 21, 28, 30, 37, 47, 48], "folk": [45, 47, 54], "follow": [0, 5, 6, 7, 8, 10, 15, 16, 18, 20, 21, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54], "font": [12, 13, 14, 17, 18, 19, 26, 27, 28, 39, 40, 41, 44, 45, 46], "font_scal": 37, "fontsiz": [13, 14, 15, 18, 19, 20, 23, 24, 27, 28, 29, 34, 36, 37, 39, 43, 46, 51, 52], "food": [25, 39, 42, 43, 54], "food_typ": 25, "foot": [35, 37], "footag": 32, "footstal": 43, "forc": [34, 37, 52], "force_all_finit": 25, "force_plot": 37, "force_writ": 25, "forecast": [11, 13, 18, 27, 45, 46, 50], "forest": [11, 34, 35, 43, 44, 45, 47, 50], "forev": 44, "forg": [10, 34, 35, 36, 37, 42, 45, 48], "forget": [13, 15, 16, 18, 27, 31, 36], "form": [1, 12, 17, 20, 31, 34, 38, 40, 41, 42, 45, 46, 47, 50], "formal": 54, "format": [0, 1, 13, 18, 23, 25, 27, 34, 40, 42, 44, 45], "former": 45, "formul": [4, 33], "formula": [32, 35, 43, 49], "forum": [12, 17], "forward": [45, 47], "found": [1, 7, 14, 19, 22, 23, 25, 28, 31, 33, 35, 39, 41, 42, 48, 50, 54], "foundat": [1, 9, 11, 34, 35, 37, 46], "foundation_brktil": 35, "foundation_cblock": 35, "foundation_pconc": 35, "foundation_slab": 35, "foundation_ston": 35, "foundation_wood": 35, "fountain": 43, "four": [13, 14, 18, 27, 28, 38, 40, 47, 50], "fourth": 40, "foxhound": [12, 17, 26, 43], "foyer": 35, "fp": 34, "fpr": 34, "fpr_lr": 34, "fpr_svc": 34, "frac": [13, 18, 27, 32, 34, 35, 39, 42, 43], "fractal": 38, "fraction": [31, 34, 41], "fragment": 52, "frame": [16, 21, 30, 31, 34, 35, 38, 44, 45, 46, 47], "framework": [27, 33], "fraud": [13, 18, 27, 34, 35, 39, 44], "fraudul": [13, 18, 27, 34, 46], "frederick": [1, 54], "free": [0, 5, 31, 35, 42, 45, 47], "freedom": [0, 48], "french": [16, 21, 30, 42], "freq": 44, "frequenc": [31, 42, 44, 45, 50], "frequent": [13, 16, 18, 21, 27, 30, 41, 42, 45], "fresh": [41, 42], "fri": [12, 44], "fridai": [14, 17, 54], "friend": [13, 14, 18, 27, 28, 34, 37, 40, 41, 47, 50, 54], "from": [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54], "from_block": 45, "from_estim": 34, "front": 54, "fruit": 42, "frustrat": [4, 6, 33], "full": [23, 33, 36, 43, 44, 45, 54], "fullbath": [35, 37, 46], "fulli": 40, "fun": [34, 42, 43], "func": [8, 31, 32, 35, 46], "function": [2, 12, 13, 14, 15, 17, 18, 19, 20, 24, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 50, 52], "functiontransform": [25, 31, 45], "fund": 48, "fundament": [1, 2, 9, 11, 16, 21, 30, 32, 33, 35, 38, 43, 45, 54], "funni": [12, 26, 36, 48], "furnish": 0, "furnitur": 50, "further": [23, 34, 36, 38, 39, 42, 43, 45, 47, 52, 54], "furthermor": 46, "fusion": 25, "futur": [11, 14, 17, 19, 21, 28, 30, 33, 35, 45, 48, 50], "futurewarn": [21, 28, 30, 35, 37, 48, 49], "fuyi": [12, 13, 14, 16, 54], "fyi": 45, "g": [6, 7, 8, 11, 12, 13, 16, 17, 18, 21, 23, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50], "g26r0dcx4b35vf3nk31216hc0000gr": [30, 37, 48], "gain": [6, 11, 13, 18, 27, 34, 36, 37], "game": [13, 18, 27, 37, 42], "gamma": [24, 32, 33, 36, 46, 52], "gamma_log": [15, 20, 24, 29, 52], "gamma_widget": [15, 20, 24, 29, 52], "gap": [14, 19, 23, 28, 44, 45, 46, 50, 52], "garagearea": [35, 37, 46], "garagecar": [35, 37, 46], "garagecond": [35, 37, 46], "garagefinish": [35, 37, 46], "garagefinish_fin": 35, "garagefinish_miss": 35, "garagefinish_rfn": 35, "garagefinish_unf": 35, "garagequ": [35, 37, 46], "garagetyp": [35, 37, 46], "garagetype_2typ": 35, "garagetype_attchd": 35, "garagetype_bas": 35, "garagetype_builtin": 35, "garagetype_carport": 35, "garagetype_detchd": 35, "garagetype_miss": 35, "garageyrblt": [35, 37, 46], "garlic": 39, "gaurav": [1, 54], "gauss": 42, "gaussian": 40, "gaussianmixtur": 40, "gave": [41, 44], "gbr": 8, "gca": [39, 40, 45], "gd": [12, 17, 26, 35, 37, 46], "gdprv": [35, 37, 46], "gdwo": [35, 37, 46], "gelbart": [0, 1, 18, 27, 42], "gender": [12, 17, 26, 31, 34, 42, 44, 45], "gender_femal": 45, "gender_mal": 45, "gener": [7, 9, 12, 13, 16, 18, 21, 23, 25, 27, 30, 31, 33, 34, 35, 37, 40, 42, 43, 44, 45, 46, 47, 49, 50, 52, 54], "genet": 38, "genom": 38, "genr": 41, "gensim": 42, "gentl": 11, "geog": [1, 54], "geograph": [32, 47], "geometr": [13, 27], "georg": 42, "geq": 32, "ger": 8, "german": 42, "get": [1, 4, 5, 6, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54], "get_avg_word_length": 48, "get_cmap": [16, 21, 30], "get_depth": [23, 52], "get_dummi": [16, 21, 30], "get_featur": [24, 43], "get_feature_names_out": [16, 21, 25, 30, 31, 34, 35, 36, 37, 38, 42, 44, 45, 46, 48], "get_length_in_word": 48, "get_lr_data_per_us": 41, "get_param": 24, "get_permutation_import": 37, "get_relative_length": 48, "get_season": 44, "get_senti": 48, "get_stat": 41, "get_tag": 25, "get_user_profil": 41, "getattr": 45, "ghassemi": [1, 54], "gif": [39, 40], "gift": 48, "gigaword": 42, "gini": [13, 18, 27, 37, 46], "git": [3, 8, 12, 17], "github": [0, 1, 7, 9, 10, 12, 16, 17, 21, 22, 23, 24, 25, 26, 30, 31, 33, 34, 35, 36, 37, 38, 43, 46, 47, 48], "githubusercont": 8, "gitlf": 34, "giulia": [0, 1, 54], "give": [0, 12, 13, 14, 17, 18, 19, 21, 23, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 51, 52], "given": [0, 14, 15, 16, 19, 20, 21, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52], "gladwel": 39, "glass": 46, "glob": [12, 17, 24, 26, 43], "global": [16, 21, 30, 34, 36, 39, 42, 50], "global_skip_valid": 25, "glove": [11, 42], "glq": [35, 37, 46], "gmail": [12, 17, 26, 39], "go": [1, 5, 7, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52], "goal": [2, 11, 15, 16, 20, 21, 29, 30, 33, 34, 39, 40, 41, 42, 47, 48], "goe": [2, 12, 14, 15, 17, 19, 20, 28, 29, 31, 34, 36, 37, 40, 41, 43, 46, 47], "gold": 8, "goldcoast": 44, "golden": [15, 23, 29, 47, 50, 52], "good": [9, 10, 13, 14, 15, 16, 18, 19, 20, 21, 23, 25, 27, 28, 29, 30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53], "good_serv": 25, "goodarzvand": [1, 54], "googl": [1, 4, 12, 13, 17, 18, 26, 27, 36, 37, 38, 39, 42, 46, 48], "google_news_vector": 42, "got": [15, 20, 29, 32, 33, 34, 35, 43], "gotten": 45, "gov": [34, 36, 37], "govern": [42, 54], "gpe": 42, "gpt": [41, 42], "gpu": [36, 42, 43], "grad": [34, 36, 37], "grade": [1, 3, 7, 12, 14, 16, 19, 23, 26, 28, 31, 33, 46, 50, 52, 53], "grader": 6, "grades_df": 50, "gradescop": [1, 6, 12, 13, 17, 54], "gradient": [47, 50], "gradientboostingclassifi": 36, "gradientboostingregressor": [36, 46], "gradientexplain": 37, "grading_concern": 6, "graduat": 43, "grai": 43, "grain": [32, 37], "gram": 42, "grammat": 42, "grandma": 38, "grandmoth": [34, 47], "grant": 0, "grant_macewan": 42, "granular": 40, "graph": [1, 24, 43, 44], "graphic": 43, "graphic_design": 42, "graphviz": [13, 18, 27, 51], "grasp": [11, 50], "grayscal": 43, "great": [12, 15, 17, 19, 20, 26, 27, 29, 31, 32, 37, 38, 42, 43, 44, 46, 48], "greater": [10, 38, 39], "greater_is_bett": 35, "greedili": 40, "green": [15, 20, 29, 33, 39, 46, 49], "grei": 54, "grid": [32, 35, 44, 45, 50], "grid_result": 46, "grid_search": [33, 46], "gridsearchcv": [15, 20, 29, 36, 37], "gridsearchcvifittedgridsearchcv": 33, "grinberg": 47, "grip": 42, "grlivarea": [35, 37, 46], "groak": 42, "groceri": [43, 48], "groin": 43, "ground": [14, 19, 28, 38, 40, 41, 54], "ground_truth_categori": [34, 47], "group": [7, 11, 13, 15, 16, 18, 20, 24, 27, 29, 31, 32, 36, 38, 50, 52, 53], "groupbi": 44, "grow": [33, 36, 38], "grow_polici": 36, "growth": [44, 45], "groyn": 43, "grv": 35, "gsc": 46, "gt": [31, 32, 33, 34, 35, 36], "gtl": 37, "gtoti": 18, "guarante": [33, 34, 36, 39, 43], "guenon": 43, "guess": [15, 16, 20, 21, 29, 30, 42, 48], "guid": [1, 7, 9, 12, 17, 38, 43, 47, 54], "guidanc": 37, "guidelin": [16, 37, 38, 47], "guido": 1, "h": [23, 34, 36, 37, 39, 42, 43, 45, 47, 48], "ha": [1, 2, 5, 6, 13, 14, 16, 18, 19, 21, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 52, 54], "hab": 42, "habit": [31, 46, 47], "hacki": [43, 49], "had": [12, 16, 17, 21, 26, 30, 31, 32, 34, 41, 42, 43, 44, 45, 47], "hadn": [42, 45], "haidilao": 25, "hal": 1, "half": [1, 6, 12, 13, 17, 18, 27, 32, 38, 40], "halfbath": [35, 37, 46], "halvingrandomsearchcv": 33, "halvingrandomsearchcvifittedhalvingrandomsearchcv": 33, "ham": [12, 17, 26], "hand": [4, 9, 11, 25, 34, 41, 54], "handi": 34, "handl": [11, 23, 25, 36, 37, 40, 45, 47, 49, 50, 52], "handle_unknow": 31, "handle_unknown": [16, 21, 25, 30, 31, 33, 34, 35, 36, 37, 44, 45, 46, 50], "handler": [34, 37], "handrail": 43, "handwritten": [34, 46], "hang": 34, "happen": [4, 6, 12, 15, 20, 25, 26, 29, 31, 33, 36, 37, 38, 41, 44, 45, 46, 50, 54], "happi": [23, 25, 34, 39, 45], "happier": [47, 54], "happydb": [34, 47], "hard": [8, 12, 14, 15, 16, 17, 19, 20, 21, 26, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 46, 47, 48, 50], "hardi": [1, 54], "hardli": 41, "hardwar": 43, "harmon": 34, "harri": [1, 42, 54], "has_emoji": 48, "has_nan_error": 25, "hasn": [4, 41, 42, 45], "hassl": [8, 37, 44], "hat": [32, 35, 36], "have": [0, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54], "haven": [14, 19, 25, 28, 42, 45, 46, 47, 50], "haylei": [18, 27], "hazard": 11, "hc_truncation_toy_demo": 40, "hdbscan": 40, "he": [14, 19, 28, 31, 42], "head": [8, 12, 13, 14, 15, 16, 17, 18, 19, 21, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 50, 53], "header": 47, "headlin": [42, 46], "health": 42, "healthcar": 37, "healthi": [42, 46], "heard": [14, 19, 28], "heart": [13, 18, 27, 48], "hearti": 25, "heat": [33, 35, 37, 46], "heating_floor": 35, "heating_gasa": 35, "heating_gasw": 35, "heating_grav": 35, "heating_othw": [35, 37], "heating_wal": 35, "heatingqc": [35, 37, 46], "heatmap": 37, "heavi": [36, 48], "heavili": [41, 43, 44], "heeren": 42, "height": [13, 14, 18, 19, 24, 27, 28, 34, 42, 48, 51], "hell": 48, "help": [3, 7, 10, 12, 14, 16, 17, 19, 21, 25, 26, 28, 30, 31, 33, 34, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53, 54], "henc": [5, 34, 35, 37, 39], "her": [12, 17, 26, 41, 42], "here": [1, 4, 5, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 20, 21, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54], "herebi": 0, "herself": [42, 48], "herta": [15, 29], "hesist": 46, "hesit": 46, "heurist": [13, 18, 27, 33], "hi": [42, 52], "hidden": [38, 42, 43, 46], "hide": [8, 43], "hier_label": 40, "hier_labels1": 40, "hier_labels2": 40, "hierarch": [11, 50], "hierarchi": [13, 18, 27, 40], "high": [6, 11, 14, 15, 18, 19, 20, 25, 28, 29, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47], "high_corr": 37, "higher": [13, 14, 15, 18, 19, 20, 27, 28, 29, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 52], "highest": [36, 37, 41, 42, 43, 46, 49, 52], "highland": 48, "highli": [1, 10, 16, 21, 30, 37, 41], "highlight": [4, 43, 46, 50], "highwai": 32, "him": 42, "himself": 42, "hinder": 54, "hindi": [16, 21, 30], "hint": [37, 52], "hist": [16, 21, 25, 30, 33, 35, 38, 45], "histgradientboostingclassifi": [25, 36], "histgradientboostingregressor": 36, "histogram": 45, "histor": 50, "histori": [32, 41, 44, 54], "hit": [12, 17, 26, 33], "hitter": 48, "hl": [35, 37, 46], "hmid": [34, 47], "hmmm": 45, "hockei": 42, "hold": [25, 46, 47], "holder": 0, "holdout": 34, "holi": 46, "holidai": [41, 54], "home": [13, 18, 24, 27, 32, 34, 43, 47], "homemak": 42, "homepag": 1, "homework": [1, 3, 4, 6, 8, 10, 15, 29, 32, 33, 42, 47, 50, 54], "honest": 46, "honour": 54, "hood": [14, 19, 25, 28, 47], "hope": [14, 19, 28, 46, 47], "hopefulli": 47, "hopeless": 38, "hopelessli": [15, 20, 29], "horizont": [13, 18, 25, 27, 31], "host": [5, 45, 47], "hot": [14, 19, 25, 28, 31, 37, 50], "hound": [12, 17, 26, 43], "hour": [1, 4, 10, 12, 34, 36, 37, 38, 41, 44, 47, 50, 54], "hourli": [45, 50], "hous": [18, 23, 35, 37, 38, 45, 46, 52], "houseag": 32, "household": [16, 21, 30, 31, 32, 38, 53], "housestyl": [35, 37, 46], "housestyle_1": 35, "housestyle_1stori": 35, "housestyle_2": 35, "housestyle_2stori": 35, "housestyle_sfoy": 35, "housestyle_slvl": 35, "housewif": 42, "housing_df": [13, 16, 21, 23, 27, 30, 31, 38, 52, 53], "housing_median_ag": [16, 21, 30, 31, 38, 53], "houston": 48, "how": [0, 3, 8, 10, 11, 12, 17, 23, 24, 26, 31, 33, 34, 35, 39, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54], "howard": 39, "howev": [2, 8, 16, 21, 24, 30, 31, 34, 35, 37, 39, 41, 44, 45, 47, 49, 52], "hsjcy": 45, "hstack": 44, "html": [7, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 43, 45, 46, 47, 48, 51, 53], "htrz": 54, "http": [0, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 43, 44, 45, 46, 47, 48, 54], "hug": 41, "huge": [31, 35, 42, 43, 44, 45], "human": [0, 12, 15, 16, 17, 21, 26, 29, 30, 31, 32, 33, 34, 37, 38, 39, 42, 43], "humidity3pm": 44, "humidity3pm_lag1": 44, "humidity9am": 44, "hummu": [39, 42], "humour": [1, 42], "hundr": 32, "hurrican": [12, 26], "husband": [34, 36, 37], "hussar": [12, 17, 26, 43], "hw": [12, 16, 26], "hw1": [1, 4, 13, 14, 16, 51], "hw2": [1, 14, 15, 16, 21, 29, 30], "hw3": [1, 16], "hw4": 1, "hw5": 1, "hw6": 1, "hw6a": 7, "hw6b": 7, "hw7": 1, "hw8": 1, "hw9": 1, "hybrid": 41, "hyper": 46, "hyperband": 33, "hyperopt": 33, "hyperparamet": [1, 14, 19, 24, 28, 34, 40, 41, 42, 43, 46, 47], "hyperparameter_": 46, "hyperparamt": [14, 19, 28, 33, 45], "hyperparlan": 32, "hyperplan": 32, "hypothesi": [42, 45, 47], "hypothet": [32, 39], "i": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 18, 20, 23, 24, 25, 27, 29, 32, 35, 40, 43, 44, 45, 49, 50, 51, 52, 53, 54], "i1": 36, "i2": 36, "ia": 48, "ibm": 48, "ic": 42, "icc": [1, 54], "iclick": 1, "id": [12, 13, 17, 23, 26, 27, 35, 37, 41, 46, 52], "idea": [8, 13, 14, 16, 18, 19, 21, 23, 24, 25, 27, 28, 30, 33, 37, 39, 40, 41, 42, 43, 44, 45, 47, 50, 52], "ideal": [4, 16, 25, 34, 36, 38, 41, 45, 47], "ident": [24, 42, 43], "identif": [12, 17, 26, 48], "identifi": [11, 13, 14, 15, 16, 18, 19, 21, 23, 27, 28, 29, 30, 33, 34, 35, 39, 40, 42, 43, 44, 46, 47, 50], "idf": 31, "idli": 42, "idx": [24, 43], "idxmax": [15, 20, 23, 29], "if_binari": [25, 31, 34, 36, 37, 50, 53], "ifram": [14, 19, 28, 34], "igloo": 42, "ignor": [13, 15, 16, 17, 18, 19, 20, 21, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 42, 44, 45, 46, 50], "ignore_index": 8, "ii": 34, "iii": 1, "ij": [32, 41], "ik": 36, "ill": 54, "illus": 34, "illustr": [40, 44], "iloc": [8, 13, 14, 15, 16, 18, 19, 20, 21, 27, 28, 29, 30, 31, 36, 37, 42, 44, 48, 51], "im": 48, "imag": [7, 11, 14, 19, 21, 28, 34, 37, 38, 39, 40, 44, 46, 50], "image_dataset": [24, 43], "image_datasets_bw": 43, "image_fil": 24, "image_s": [24, 43], "imagefold": [24, 43], "imagenet": 49, "imagenet1k_v1": [24, 43], "imagenet_class": [12, 17, 26, 43], "imagin": [12, 13, 14, 16, 17, 18, 19, 21, 26, 27, 28, 30, 32, 34, 37, 38, 39, 42, 45, 46, 47, 50, 51], "imaginari": [14, 19, 28, 42], "imbal": [39, 45], "imbalanc": [34, 35, 49], "imblearn": 34, "img": [12, 17, 24, 26, 43], "img_classifi": [12, 17, 26], "img_ind": 24, "img_path": [12, 17, 26], "img_t": 43, "immedi": [37, 41, 54], "imp": [16, 21, 30, 31, 44], "impact": [7, 11, 31, 32, 36, 37, 40, 44, 46, 52, 54], "implement": [2, 4, 12, 16, 17, 21, 26, 30, 34, 35, 36, 38, 40, 41, 42, 45, 46, 47, 49], "impli": [0, 45], "implic": [11, 16, 21, 30, 47, 50], "implicit": 42, "import": [8, 11, 49, 53, 54], "importance_typ": 36, "importances_mean": 37, "impos": [16, 21, 30], "imposs": 39, "impress": 37, "improv": [11, 23, 25, 33, 34, 35, 36, 38, 39, 40, 41, 44, 45, 46, 47, 50, 54], "impur": [13, 18, 23, 27, 36], "imput": [14, 19, 25, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 44, 45, 46, 47, 50, 53], "imread": 43, "imshow": [12, 17, 24, 26, 43], "inabl": 17, "inbox": [14, 19, 28], "inc": [37, 42], "incept": [41, 43], "inception": 43, "incl": 35, "includ": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 18, 21, 24, 27, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 52, 53, 54], "include_bia": [38, 44], "incom": [14, 19, 28, 32, 34, 36, 37], "incomplet": 45, "inconsist": 31, "incorpor": [33, 35, 38, 45, 47, 50], "incorrect": [45, 46], "incorrectli": [12, 17, 26, 34], "increament": 47, "increas": [8, 14, 15, 19, 20, 23, 28, 29, 31, 32, 36, 37, 38, 39, 40, 43, 52], "increasingli": [12, 17, 26], "incred": 43, "increment": 47, "inde": 37, "independ": [8, 9, 13, 17, 18, 27, 33, 35, 36, 38, 44, 54], "index": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 48, 52], "index_col": [8, 15, 16, 21, 29, 30, 33, 34, 41, 47], "india": 42, "indian": [25, 34], "indian_liver_pati": [12, 17, 26], "indic": [0, 25, 31, 39, 41, 42, 43, 44, 45], "indirectli": 46, "individu": [25, 36, 37, 39, 41, 42, 45, 47, 54], "industri": [36, 38, 42, 43], "inequ": 34, "inertia_": 39, "inertia_valu": 39, "inf": [15, 20, 29, 45], "infeas": 33, "infer": [13, 27, 42, 43, 44, 47, 51], "infin": [15, 20, 29, 46], "infinit": 33, "inflamm": 9, "inflat": 37, "inflect": [39, 42], "influenc": [13, 14, 18, 19, 27, 28, 33, 37, 39, 41, 45, 52], "info": [1, 3, 8, 16, 21, 30, 31, 34, 35, 38, 42, 44, 45, 52], "infom": 42, "infor_m": 42, "inform": [1, 4, 7, 10, 12, 13, 16, 18, 21, 24, 27, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 52, 54], "informa_t": 42, "informaion": 42, "informaiton": 42, "informationabout": 42, "informationon": 42, "inhabit": 54, "inher": [18, 34, 44, 45], "initi": [24, 40, 43], "initj": 37, "inject": [38, 41, 50], "ink": 46, "inland": [16, 21, 30, 31, 38, 53], "inlin": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 51, 52], "inner": [31, 33, 42], "inplac": [8, 12, 13, 17, 26, 27, 33], "input": [8, 13, 16, 18, 21, 24, 25, 27, 30, 32, 36, 37, 40, 42, 43, 44, 47, 48, 50], "input_img": 43, "input_nam": 25, "input_tag": 25, "inputs_bw": 43, "insid": [9, 31, 34], "insight": [2, 11, 15, 20, 29, 34, 37, 39], "inspct": 34, "inspect": [37, 40], "inspir": [13, 27, 34, 36], "instal": [12, 15, 17, 24, 25, 26, 29, 34, 35, 36, 37, 39, 42, 43, 45, 47, 48], "instanc": [12, 13, 14, 17, 18, 19, 24, 25, 26, 27, 28, 31, 32, 34, 39, 40, 41, 42, 43, 44, 49], "instanti": [23, 33, 52], "instead": [5, 8, 10, 13, 14, 16, 18, 21, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 49, 52], "institut": [42, 48], "instruct": [3, 4, 5, 10, 12, 15, 16, 17, 29, 46, 47, 54], "instructor": [4, 6, 12, 17, 26, 46, 47, 54], "instrument": [15, 16, 21, 29, 30, 33], "int": [16, 21, 30, 31, 34, 36, 37, 42, 44, 48], "int32": [15, 20, 29, 39, 40, 44], "int64": [13, 15, 16, 18, 23, 25, 27, 29, 31, 34, 35, 41, 42, 44, 45, 47, 48], "integ": [8, 16, 21, 28, 30, 33, 36, 37, 44, 48], "integr": [11, 47], "intellig": [1, 42], "intelligen": 42, "intend": [0, 46, 54], "intens": 42, "inter": 48, "interact": [9, 12, 15, 17, 20, 24, 29, 33, 34, 37, 39, 40, 41, 44, 47, 48, 52], "interaction_constraint": 36, "interaction_onli": [38, 44], "interactive_plot": [15, 20, 24, 29, 52], "intercept": [37, 43, 49], "intercept_": [32, 36, 43, 49], "intercept_sc": 34, "interest": [2, 12, 14, 17, 19, 25, 26, 28, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 52], "interfac": [36, 47], "intermedi": [40, 43], "intern": [0, 1, 13, 18, 27, 43, 44, 45], "internet": [45, 46, 47], "internetservic": 45, "internetservice_dsl": 45, "internetservice_fib": 45, "internetservice_no": 45, "internship": [12, 17, 26], "interpret": [1, 10, 11, 15, 16, 20, 21, 23, 29, 30, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46], "interv": [11, 44, 45, 50], "interweb": 47, "intrins": 44, "intro": [1, 42, 43], "introduc": [31, 34, 45], "introduct": [1, 9, 10, 11, 23, 44, 45, 52], "intslid": [15, 20, 24, 29, 52], "intuit": [11, 15, 16, 20, 21, 29, 30, 31, 33, 35, 37, 39, 40, 45, 48], "invalid": 33, "inventori": 50, "invers": [32, 35], "inverse_func": [35, 46], "investig": [15, 20, 24, 29, 37, 52], "involv": [2, 4, 33, 35, 36, 40, 42, 43], "io": [9, 16, 21, 22, 30, 43, 45, 48], "ipykernel_10188": 25, "ipykernel_13054": 48, "ipykernel_19402": 37, "ipykernel_32469": 30, "ipykernel_70329": 21, "ipykernel_79734": 28, "ipynb": [7, 8, 12, 17], "ipython": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31, 32, 34, 42, 51, 53], "ipywidget": [15, 20, 29, 52], "ir1": [35, 37, 46], "ir2": [35, 37, 46], "iri": [15, 20, 24, 29, 52], "iris_df": [15, 20, 24, 29, 52], "irregular": 11, "irregularli": 50, "irrelev": [15, 20, 29, 38, 42], "irrelevant_po": 42, "irrespect": [14, 19, 28, 32, 54], "is_avail": [24, 43], "is_classifi": 25, "is_leap_year": 44, "is_stop": 42, "is_year_end": 44, "isinst": [25, 45], "island": [16, 21, 30, 31], "isn": [14, 15, 20, 28, 29, 34, 35, 36, 42, 46], "isnul": [16, 21, 25, 30], "isol": [10, 34, 35, 37, 46], "issu": [4, 6, 7, 12, 17, 23, 36, 41, 45, 50, 54], "issubclass": 45, "isupp": 48, "itali": 42, "italian": 25, "item": [12, 17, 24, 26, 36, 37, 39, 41, 42, 43, 45, 50], "item_inverse_mapp": 41, "item_kei": 41, "item_mapp": 41, "iter": [24, 33, 38, 39, 40, 43, 47], "iterable_with_config": 31, "iterrow": 41, "its": [8, 11, 12, 14, 15, 17, 20, 21, 24, 25, 26, 28, 29, 31, 32, 34, 37, 39, 40, 42, 43, 44, 45, 48, 49, 52, 54], "itself": [7, 34, 36, 40, 42], "j": [8, 32, 37, 38, 39, 41, 43], "jackin": 33, "jackpot": 31, "jaguar": [12, 17, 26, 43], "jalebi": 42, "jam": 33, "jame": [42, 45, 48], "jan": [1, 12, 13, 16], "januari": [12, 17, 44], "japan": 42, "jargon": [13, 18, 27], "jason": [1, 38], "javascript": 37, "jazz_musician": 42, "jellyfish": 43, "jennif": 48, "jerri": 41, "jet": [16, 21, 30], "jetti": 43, "jieba": 42, "jim": 41, "jmlr": 33, "joan_baez": 42, "job": [31, 44, 45], "joblib": [31, 47], "joei": 25, "john": 36, "johnny_cash": 42, "join": [12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 54], "jointli": 44, "joke": [12, 17, 26, 41], "jolen": 48, "joni_mitchel": 42, "journal": 42, "journei": [1, 40, 54], "jpg": [24, 43], "json": 47, "ju": [12, 17, 26], "jubatu": [12, 17, 26, 43], "judg": 38, "judgment": 46, "juic": 42, "juli": 44, "june": 44, "jupyt": [1, 7, 8, 9, 10, 16, 21, 23, 24, 25, 26, 30, 31, 33, 34, 35, 36, 37, 38, 43, 46, 47, 48], "jupyter_notebook": 45, "jupyterlab": 37, "jurafski": 42, "jurisdict": 42, "just": [4, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 50, 52, 54], "justic": [37, 42], "k": [1, 7, 11, 14, 19, 24, 25, 28, 32, 34, 35, 36, 38, 42, 43, 45, 47, 48, 49, 52], "k_neighbor": 34, "k_valu": [15, 20, 29], "kaggl": [13, 16, 21, 24, 27, 30, 34, 35, 36, 37, 38, 43, 46], "kaggler": 38, "kangaroo": 43, "kaplan": 11, "kaplanmeierfitt": 45, "kazmi": [1, 54], "kb": [31, 35, 45], "kbinsdiscret": 38, "kbinsdiscretizer__latitude_0": 38, "kbinsdiscretizer__latitude_1": 38, "kbinsdiscretizer__latitude_2": 38, "kbinsdiscretizer__latitude_3": 38, "kbinsdiscretizer__latitude_4": 38, "kbinsdiscretizer__latitude_5": 38, "kbinsdiscretizer__latitude_6": 38, "kbinsdiscretizer__latitude_7": 38, "kbinsdiscretizer__latitude_8": 38, "kbinsdiscretizer__latitude_9": 38, "kbinsdiscretizer__longitude_11": 38, "kbinsdiscretizer__longitude_12": 38, "kbinsdiscretizer__longitude_13": 38, "kbinsdiscretizer__longitude_14": 38, "kbinsdiscretizer__longitude_15": 38, "kbinsdiscretizer__longitude_16": 38, "kbinsdiscretizer__longitude_17": 38, "kbinsdiscretizer__longitude_18": 38, "kbinsdiscretizer__longitude_19": 38, "kbinsdiscretizerkbinsdiscret": 38, "kc_house_data": [12, 13, 17, 23, 26, 27, 52], "kdtree": 25, "keep": [1, 14, 15, 16, 19, 20, 21, 23, 28, 29, 30, 31, 34, 36, 37, 38, 39, 41, 42, 45, 47, 52, 53, 54], "keep_empty_featur": 41, "kei": [9, 11, 13, 15, 16, 18, 20, 21, 27, 28, 29, 30, 33, 34, 35, 36, 41, 42, 45, 48], "kelbowvisu": 39, "kellei": 32, "kept": [14, 19, 28], "kera": 37, "kernel": [1, 7, 16, 21, 24, 30, 32, 33, 37, 38, 46, 52], "kernelexplain": 37, "keyword": [4, 33, 48], "kfold": 34, "kick": 42, "kilian": 37, "kill": 45, "kimia": [1, 54], "kind": [0, 12, 13, 14, 16, 17, 18, 19, 21, 26, 27, 28, 30, 31, 32, 34, 35, 37, 39, 40, 41, 43, 44, 45, 47, 49], "king": [23, 41, 42, 52], "kitchenabvgr": [35, 37, 46], "kitchenqu": [35, 37, 46], "kiwi": 42, "kk": 39, "km": [45, 46, 50], "km_label": 39, "kmean": [39, 40, 50], "kmf": 45, "kmqfw": 45, "kneighbor": 24, "kneighborregressor": [16, 21, 30], "kneighborsclassifi": [16, 21, 25, 30, 31, 32, 38, 52, 53], "kneighborsclassifierifittedkneighborsclassifi": 25, "kneighborsregressor": [16, 21, 30, 31, 32, 53], "kneighborsregressorkneighborsregressor": [16, 21, 30, 31], "knew": 39, "knn": [2, 14, 15, 16, 19, 20, 21, 28, 29, 30, 31, 32, 37, 38, 41, 43, 47, 49, 50], "knn1": [15, 20, 29], "knn100": [15, 20, 29], "knn_pipe": 31, "knn_scale": [16, 21, 30], "knn_unscal": [16, 21, 30], "knn_valid_accuraci": [15, 20, 29], "knnimput": 41, "knob": [13, 18, 27, 46], "know": [1, 8, 12, 13, 14, 15, 16, 17, 18, 20, 21, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54], "knowledg": [8, 12, 13, 17, 18, 27, 31, 33, 38, 39, 42, 46, 50], "knowleg": 50, "known": [24, 41, 42, 45], "koala": 43, "kolhatkar": [0, 1, 18, 42], "kr9rkqfj4w78h49djkz8yy9r0000gp": 28, "ksatr": 45, "kvarada": [10, 27, 28, 31, 33, 37, 42, 43, 45, 48, 49], "kvarada01": 10, "kwantlen": 42, "kwarg": [14, 16, 19, 21, 25, 28, 30, 31, 45, 48], "l": 10, "l1": 45, "l123": 4, "l17": 4, "l1_ratio": 34, "l2": [34, 42, 45], "l9": 4, "la": 46, "lab": [10, 12, 13, 14, 17, 19, 27, 28, 39, 41], "lab1": [13, 14, 18, 19, 27, 28, 31, 50], "lab2": [13, 14, 18, 19, 27, 28, 31, 50], "lab3": [13, 14, 18, 19, 27, 28, 31, 50], "lab4": [13, 14, 18, 19, 27, 28, 31, 50], "label": [7, 8, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 48, 53], "label_": [42, 48], "label_encod": [36, 37], "label_n_clust": 40, "labelencod": [36, 37], "labels": [34, 39], "labels_": [39, 40], "lack": [14, 19, 28, 41, 46], "lag": [45, 50], "lag_df": 44, "lakehead_univers": 42, "lakeshor": 43, "lakesid": 43, "lamb": 25, "lambda": [8, 13, 18, 27, 32, 40, 43, 44, 45, 48], "land": 45, "landcontour": [35, 37, 46], "landcontour_bnk": 35, "landcontour_hl": 35, "landcontour_low": 35, "landcontour_lvl": 35, "landmark": 50, "landown": 48, "landscap": [39, 42], "landslop": [35, 37, 46], "landslope_gtl": [35, 37], "landslope_mod": [35, 37], "landslope_sev": [35, 37], "langara_colleg": 42, "languag": [2, 9, 16, 21, 30, 31, 41, 43, 47, 48], "language_enc": [16, 21, 30], "language_english": [16, 21, 30], "language_french": [16, 21, 30], "language_hindi": [16, 21, 30], "language_mandarin": [16, 21, 30], "language_spanish": [16, 21, 30], "language_vietnames": [16, 21, 30], "laptop": [12, 17, 26, 47], "lar": [12, 17, 26], "larg": [12, 14, 15, 16, 17, 19, 20, 21, 23, 26, 28, 29, 30, 32, 34, 35, 39, 40, 42, 43, 47, 50, 52], "larger": [13, 14, 15, 16, 19, 20, 21, 27, 28, 29, 30, 32, 33, 35, 36, 37, 39, 40, 45], "largest": 35, "larvatu": [12, 17, 26, 43], "last": [8, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 25, 27, 28, 29, 30, 31, 34, 37, 41, 43, 44, 45, 46, 47, 52, 54], "last_row": 8, "lastp": 40, "lat": [12, 13, 17, 23, 26, 27], "late": [17, 34, 54], "latent": [41, 42, 43], "latentdirichletalloc": 42, "later": [10, 13, 18, 27, 31, 34, 43, 44, 47, 52], "latest": [31, 37, 45], "latex": [4, 7, 12, 17], "latin": [12, 17, 26, 34], "latitud": [14, 15, 16, 19, 20, 21, 28, 29, 30, 31, 32, 38, 53], "latitude_0": 38, "latitude_1": 38, "latitude_10": 38, "latitude_11": 38, "latitude_12": 38, "latitude_13": 38, "latitude_14": 38, "latitude_15": 38, "latitude_16": 38, "latitude_17": 38, "latitude_18": 38, "latitude_19": 38, "latitude_2": 38, "latitude_3": 38, "latitude_4": 38, "latitude_5": 38, "latitude_6": 38, "latitude_7": 38, "latitude_8": 38, "latitude_9": 38, "latter": 35, "launch": [12, 17], "lauvagrand": 48, "law": [25, 42], "lawsuit": 42, "layer": [24, 43], "layout": [15, 20, 24, 29, 52], "lazi": [15, 20, 29], "lbfg": 34, "lda": 43, "ldot": 33, "lead": [1, 8, 14, 19, 28, 32, 35, 40, 41, 42, 45, 46], "leaf": [13, 18, 27, 40, 42], "leagu": 42, "leak": [16, 21, 30, 45, 50], "leakag": 50, "leaner": [14, 19, 28], "learn": [2, 9, 10, 25, 48, 49, 50, 51, 52, 53, 54], "learner": [14, 15, 19, 20, 28, 29, 36], "learning_method": 42, "learning_r": 36, "learnxinyminut": 9, "least": [1, 4, 14, 15, 19, 20, 28, 29, 34, 35, 37, 38, 39, 40, 46], "least_confident_i": 32, "least_confident_x": 32, "leav": [7, 13, 18, 27, 40, 43, 45, 46, 49], "lectur": [5, 7, 8, 10, 22, 50], "lecun": 37, "lecuy": 1, "lee": 37, "left": [7, 12, 17, 26, 33, 34, 35, 39, 40, 42, 44, 45, 46, 54], "legal": [0, 42], "legend": [7, 8, 15, 20, 29, 32, 34, 35, 38, 39, 43, 44, 45, 46, 49], "legendari": 48, "leisur": [34, 47], "lemma": 42, "lemma_": 42, "lemmat": 42, "lemon": 39, "len": [12, 14, 16, 19, 21, 24, 28, 30, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 46, 48], "length": [13, 14, 15, 18, 19, 20, 23, 24, 27, 28, 29, 32, 35, 37, 39, 40, 42, 44, 45, 48, 52], "leo": 36, "leopard": [12, 17, 26, 43], "leq": [38, 39], "less": [1, 5, 6, 12, 15, 17, 20, 26, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 45, 46, 50, 52], "lesson": [9, 16, 21, 30, 48], "lesssim": [14, 19, 28], "let": [12, 13, 14, 17, 18, 19, 23, 24, 26, 27, 28, 32, 33, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54], "letter": [32, 48], "lev": 35, "level": [11, 15, 20, 29, 32, 34, 35, 36, 37, 38, 40, 42, 43, 44, 46, 47], "leverag": [37, 41], "lewi": 48, "lexic": 42, "lexicon": 48, "lgbm": [11, 36, 37, 50], "lgbmclassifi": [12, 17, 26, 36, 37], "lgbmclassifierifittedlgbmclassifi": [12, 17, 26, 37], "lgbmclassifierlgbmclassifi": 36, "lgbmregressor": [12, 17, 26, 36], "li": [1, 32, 54], "liabil": 0, "liabl": 0, "liao": [12, 17, 26], "lib": [18, 24, 25, 27, 28, 31, 33, 37, 45, 49], "librari": [4, 8, 10, 14, 19, 23, 25, 28, 34, 37, 38, 42, 43, 44, 46, 48, 52], "licensor": 0, "life": [13, 25, 27, 32, 39, 41, 46, 47, 51, 54], "lifelin": [11, 45], "lifetim": 45, "lighter": 33, "lightgbm": [12, 17, 26, 37, 47], "lightweight": 42, "like": [1, 2, 4, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54], "likelihood": 45, "likewis": 7, "lime": 37, "limit": [0, 12, 13, 14, 17, 19, 26, 27, 28, 31, 36, 37, 46, 47, 48, 50, 51, 54], "linalg": 42, "line": [4, 8, 10, 12, 13, 17, 18, 25, 27, 31, 32, 33, 34, 35, 39, 42, 43, 44, 45, 46, 52], "line2d": 8, "linear": [1, 33, 34, 36, 38, 40, 41, 43, 44, 45, 46, 47, 49, 50], "linear_model": [12, 17, 26, 32, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 49], "linear_svc": 32, "linearli": [32, 38, 44], "linearregress": [32, 35, 38, 45], "linestyl": [39, 44], "linewidth": [44, 46], "linger": [15, 29], "lingual": 42, "linguist": 31, "link": [0, 4, 5, 7, 12, 13, 14, 16, 17, 18, 19, 20, 21, 26, 27, 31, 32, 33, 34, 35, 36, 40, 45, 46, 47, 54], "linkag": 40, "linkage_arrai": 40, "linkage_typ": 40, "linkedin": 41, "linspac": [32, 33, 35, 38, 46], "lion": 41, "list": [4, 7, 8, 10, 14, 15, 16, 19, 21, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 45, 46, 54], "listedcolormap": 32, "literatur": 36, "littl": [8, 34, 43, 46, 47], "live": [1, 10, 12, 15, 16, 17, 21, 29, 30, 31, 33, 39, 45, 46, 47], "liver": [13, 18, 27], "livestream": 54, "ll": [1, 6, 7, 10, 12, 13, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 54], "llazx": 45, "lo": 48, "load": [8, 12, 15, 16, 17, 20, 21, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 42, 43, 46, 48, 52, 53], "load_breast_canc": 38, "load_citibik": 44, "load_digit": 46, "load_iri": [15, 20, 24, 29, 52], "loan": 34, "loc": [8, 15, 20, 29, 32, 34, 37, 41, 44, 45, 46], "local": [5, 7, 10, 24, 25, 34, 36, 37, 38, 43, 48], "locat": [8, 24, 31, 39, 41, 42, 44, 48, 54], "location_katherin": 44, "location_mountginini": 44, "location_townsvil": 44, "location_witchcliff": 44, "location_wollongong": 44, "lock": [14, 19, 28], "log": [12, 13, 15, 20, 24, 25, 29, 35, 36, 45, 46, 47, 52], "log10": 35, "log1p": [35, 46], "log2": 45, "log_likelihood_ratio_test": 45, "log_loss": 46, "logarithm": [15, 20, 24, 29, 52], "logic": 38, "logical_xor": 38, "login": 41, "logisit": 43, "logist": [36, 37, 44, 45, 46, 47, 48, 49, 50], "logisticregress": [12, 17, 26, 32, 35, 36, 37, 38, 42, 43, 47, 48, 49], "logisticregressionifittedlogisticregress": 43, "logisticregressionlogisticregress": [34, 36, 43, 48], "logloss": 37, "lognorm": 33, "logspac": [24, 33], "loguniform": 33, "lol": 31, "london": 48, "lone": 40, "long": [0, 12, 13, 17, 18, 23, 26, 27, 32, 34, 36, 40, 41, 45, 47, 50, 54], "longer": [7, 33, 34, 43, 45, 46, 47], "longest": [13, 18, 27], "longitud": [14, 15, 16, 19, 20, 21, 28, 29, 30, 31, 32, 38, 53], "longitude_0": 38, "longitude_1": 38, "longitude_10": 38, "longitude_11": 38, "longitude_12": 38, "longitude_13": 38, "longitude_14": 38, "longitude_15": 38, "longitude_16": 38, "longitude_17": 38, "longitude_18": 38, "longitude_19": 38, "longitude_2": 38, "longitude_3": 38, "longitude_4": 38, "longitude_5": 38, "longitude_6": 38, "longitude_7": 38, "longitude_8": 38, "longitude_9": 38, "look": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52], "lookatm": [12, 17, 26], "loop": [33, 36, 44, 49, 50], "loos": [40, 47], "lose": [6, 31], "loss": [2, 34, 35, 36, 37, 42, 45], "lot": [5, 9, 12, 13, 15, 17, 18, 19, 20, 25, 26, 27, 29, 31, 32, 33, 34, 35, 37, 38, 40, 43, 44, 45, 46, 47, 54], "lotarea": [35, 37, 46], "lotconfig": [35, 37, 46], "lotconfig_corn": 35, "lotconfig_culdsac": 35, "lotconfig_fr2": 35, "lotconfig_fr3": 35, "lotconfig_insid": 35, "lotfrontag": [35, 37, 46], "lotshap": [35, 37, 46], "lotshape_ir1": [35, 46], "lotshape_ir2": [35, 46], "lotshape_ir3": [35, 46], "lotshape_reg": [35, 46], "loud": [15, 16, 21, 25, 29, 30, 33, 50], "loui": 44, "lourenzutti": 33, "love": [47, 48], "low": [6, 14, 15, 19, 20, 25, 28, 29, 33, 34, 35, 37, 38, 39, 40, 45, 46, 47], "lower": [14, 15, 19, 20, 28, 29, 34, 35, 37, 39, 41, 42, 45, 46], "lowerbound_peopl": 25, "lowercas": [16, 21, 30, 31], "lowest": [52, 54], "lowqualfinsf": [35, 37, 46], "lr": [32, 34, 35, 37, 43, 44, 45, 48, 49], "lr_1": 38, "lr_2": 38, "lr_3": 38, "lr_coef": [37, 44, 45], "lr_coefs_landslop": 37, "lr_flatten_pip": 43, "lr_item": 41, "lr_pipe": [35, 37, 44], "lr_pred": [34, 35], "lr_scale": 37, "lr_schedul": 43, "lr_x": 41, "lr_y": 41, "ls15hb": [12, 17, 26], "lstm": 44, "lt": [14, 16, 19, 21, 28, 30, 31, 33, 34, 35, 36, 37, 38, 45], "ltorgo": 32, "luck": 47, "lucki": [15, 20, 29, 33], "lundberg": 37, "luster": 40, "lvert": 42, "lvl": [35, 37, 46], "lwq": [35, 37, 46], "lynx": [12, 17, 26, 43], "l\u00e9cuyer": [42, 54], "m": [10, 12, 14, 17, 19, 23, 24, 25, 26, 28, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], "m_neighbor": 34, "ma": [33, 42], "macaqu": [12, 17, 26, 43], "macbook": 10, "mach": 42, "machin": [2, 9, 10, 11, 16, 21, 24, 25, 30, 31, 33, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 48, 50, 52, 54], "machine_learn": 46, "mackworth": 1, "made": [0, 6, 7, 8, 12, 13, 17, 18, 26, 27, 34, 36, 37, 41, 42, 43, 44, 46, 47], "magazin": 42, "magnitud": [21, 33, 35, 37, 42, 44], "maguir": 41, "mahsa": [1, 54], "mai": [0, 1, 7, 8, 10, 13, 14, 15, 16, 18, 19, 20, 21, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 47, 51, 52, 53, 54], "mail": 45, "main": [8, 10, 12, 13, 15, 17, 18, 20, 23, 27, 29, 31, 36, 39, 40, 50, 54], "mainland": 32, "mainli": 54, "maintain": [36, 41, 46, 50], "mainten": 36, "maissan": [1, 54], "maj1": [35, 37, 46], "maj2": [35, 37, 46], "major": [2, 14, 15, 16, 19, 20, 21, 28, 29, 30, 31, 42, 50, 51], "major_biologi": 31, "major_comput": 31, "major_econom": 31, "major_linguist": 31, "major_mathemat": 31, "major_mechan": 31, "major_phys": 31, "major_psychologi": 31, "make": [2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54], "make_blob": [15, 20, 29, 39, 40, 43, 49], "make_circl": 40, "make_classif": [15, 20, 29, 34], "make_column_transform": [25, 33, 34, 35, 36, 37, 38, 44, 45, 46, 48, 53], "make_forg": [15, 20, 29], "make_grid": [24, 43], "make_imb_pipelin": 34, "make_moon": 40, "make_num_tree_plot": 36, "make_pipelin": [12, 17, 25, 26, 31, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 53], "make_scor": [35, 38], "maker": 46, "malcolm": [39, 41], "malcom": 39, "male": [34, 36, 37, 45], "male_cm": 34, "male_pr": 34, "mall": 48, "mamba": [24, 25], "man": [41, 42], "manag": [5, 11, 44, 45, 46, 50], "mandarin": [16, 21, 30], "mango": 42, "mani": [1, 2, 5, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 54], "manipul": 46, "manner": [0, 36], "manual": [10, 12, 17, 18, 24, 26, 31, 34, 38, 39, 40, 42], "manual_se": 24, "manufactur": 43, "map": [1, 13, 14, 18, 19, 27, 28, 31, 33, 41], "mape": [47, 50], "mape_scor": 35, "maple_leaf": 42, "mapper": 41, "mar": 1, "march": 44, "marit": [34, 36, 37], "mark": [6, 7, 17, 33, 34, 40, 54], "markdown": [12, 17], "marker": [15, 20, 29, 32, 39], "markers": [32, 34], "market": [12, 17, 26, 39, 43, 44, 46, 47], "markov": 42, "marri": [34, 36, 37], "martin": 42, "mask": 33, "massiv": [31, 33], "master": [8, 33, 34, 36, 37, 42], "masvnrarea": [35, 37, 46], "masvnrtyp": [35, 37, 46], "masvnrtype_brkcmn": 35, "masvnrtype_brkfac": 35, "masvnrtype_miss": 35, "masvnrtype_ston": 35, "match": [31, 32, 34, 36, 37, 44], "materi": [8, 10, 12, 13, 14, 15, 17, 20, 26, 27, 28, 29, 39, 42, 45, 47, 50, 54], "matern": 38, "math": [2, 39, 41, 45], "mathcal": [15, 29], "mathemat": [2, 31, 36, 47, 50], "mathematician": 42, "mathia": [1, 54], "matlab": 8, "matplotlib": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 50, 51, 52, 53], "matplotlibdeprecationwarn": 37, "matric": [12, 15, 17, 20, 29, 34, 41], "matrix": [25, 31, 40, 42, 47, 50], "matter": [16, 21, 30, 31, 34, 36, 40, 46, 50, 54], "max": [8, 14, 16, 19, 21, 23, 25, 28, 30, 32, 33, 34, 35, 36, 39, 40, 44], "max_bin": 36, "max_cat_threshold": 36, "max_cat_to_onehot": 36, "max_clust": 40, "max_colwidth": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 40, 41, 51, 52, 53], "max_delta_step": 36, "max_depth": [14, 15, 19, 20, 23, 24, 28, 29, 33, 36, 37, 46, 51, 52], "max_depth_widget": [15, 20, 24, 29, 52], "max_df": 31, "max_displai": 37, "max_featur": [12, 17, 26, 31, 33, 36, 46], "max_it": [12, 17, 26, 34, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 49], "max_leaf_nod": [13, 18, 27, 46], "max_leav": 36, "max_opt": [15, 20, 29, 34, 39, 40], "max_row": 45, "max_sampl": 46, "maxabsscal": 25, "maxclust": 40, "maxent": 49, "maxim": [12, 17, 26, 34, 35, 39], "maximum": [13, 16, 18, 21, 25, 27, 30, 35, 36, 39, 40, 52], "maxosx": 10, "maxtemp": 44, "may": 1, "mayb": [34, 37, 44, 46, 54], "maybe_coerce_valu": 45, "mb": [16, 21, 30, 31, 34, 38, 44, 45], "mcld": 54, "mcml": [1, 54], "md": [10, 12, 13, 27, 42], "me": [8, 12, 17, 26, 33, 42, 46, 47, 48], "mean": [5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 41, 43, 44, 45, 47, 48, 49, 50, 52, 54], "mean_absolute_error": 47, "mean_absolute_percentage_error": 35, "mean_cv_error": [14, 19, 28], "mean_cv_scor": [15, 20, 24, 29, 32, 33], "mean_fit_tim": [33, 35], "mean_scor": [14, 16, 19, 21, 28, 30, 33, 48], "mean_score_tim": [33, 35], "mean_squared_error": [35, 38], "mean_std_cross_val_scor": [14, 16, 19, 21, 28, 30, 31, 36, 37, 45, 48], "mean_test_neg_mean_squared_error": 35, "mean_test_scor": [33, 35], "mean_train_error": [14, 19, 28], "mean_train_neg_mean_squared_error": 35, "mean_train_scor": [15, 20, 24, 29, 32, 33, 35], "meaning": [11, 15, 20, 24, 29, 31, 34, 37, 39, 42, 53], "meaningless": 40, "measur": [0, 12, 13, 14, 15, 17, 18, 19, 20, 26, 27, 28, 29, 34, 35, 37, 39, 40, 41, 42, 44, 45, 46, 47, 50, 52], "meat": 25, "mechan": [31, 50], "mechanical_engin": 42, "medal": 8, "media": 46, "median": [13, 16, 18, 21, 25, 27, 30, 31, 32, 35, 37, 38, 44, 45, 46], "median_house_valu": [16, 21, 30, 31, 38, 53], "median_incom": [16, 21, 30, 31, 38, 53], "mediat": 46, "medic": [34, 39, 54], "medinc": 32, "medit": [34, 47], "medium": [0, 15, 20, 25, 29, 45, 50], "meet": 42, "meier": 11, "melbourneairport": 44, "member": [32, 36, 54], "membership": [31, 39, 40], "memori": [8, 16, 21, 25, 30, 31, 34, 35, 36, 38, 43, 44, 45, 50], "mental": 46, "mention": [0, 4, 32, 45, 46], "menu": [10, 47], "merchant": 0, "merg": [0, 5, 10, 40], "meshgrid": 38, "mess": [41, 45], "messag": [4, 6, 10, 14, 19, 25, 28, 31], "messi": [38, 42], "met": 54, "meta": 36, "metacademi": 1, "method": [2, 11, 13, 15, 16, 18, 20, 21, 23, 24, 27, 29, 30, 32, 34, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50], "methodologi": [16, 21, 30, 44], "metric": [1, 11, 15, 20, 25, 29, 31, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47], "mexican": 25, "mexico": 34, "mglearn": [13, 14, 15, 16, 18, 19, 20, 21, 24, 27, 28, 29, 30, 31, 32, 33, 34, 39, 42, 43, 44, 49, 51, 52], "mi": [12, 17, 26, 33, 34, 46], "microsoft": 48, "midnight": 44, "midterm": [1, 6, 12, 17], "might": [1, 6, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48, 50, 52, 54], "mightn": 42, "miguel": 47, "mike": [0, 1, 9, 18, 27, 47], "mikolov": 42, "milk": 42, "mill": 36, "millennia": 54, "million": 43, "min": [1, 21, 23, 25, 32, 35, 40, 44], "min1": [35, 37, 46], "min2": [35, 37, 46], "min_child_weight": 36, "min_df": 31, "min_impurity_decreas": 46, "min_impurity_split": 46, "min_sampl": 40, "min_samples_leaf": [13, 18, 27, 46], "min_samples_split": [13, 18, 27, 46], "min_token_len": 42, "min_token_length": 42, "min_weight_fraction_leaf": 46, "mind": [14, 16, 19, 21, 28, 30, 31, 36, 37, 41, 45, 46, 47, 50, 54], "mine": 1, "minibatchkmean": 40, "miniconda": 10, "miniconda3": [10, 48], "miniforge3": [27, 28, 31, 33, 37, 45, 49], "minim": [5, 13, 18, 27, 35, 39, 40, 46], "minimum": [8, 14, 16, 19, 21, 28, 30, 40, 42], "minmaxscal": [16, 21, 25, 30, 31, 46], "minor": [6, 45], "mintemp": 44, "minut": [4, 12, 13, 17, 18, 27, 38, 45, 50], "miracl": 48, "miscalcul": 1, "miscfeatur": [35, 37, 46], "miscfeature_gar2": 35, "miscfeature_miss": 35, "miscfeature_othr": 35, "miscfeature_sh": 35, "miscfeature_tenc": 35, "misconduct": 54, "miscval": [35, 37, 46], "mishaal": [1, 54], "mislead": [14, 19, 28, 34], "miss": [10, 15, 16, 20, 21, 23, 25, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 44, 45, 46, 50, 52, 54], "mistak": [16, 21, 30, 36, 45, 46, 52], "mit": [0, 1], "mitig": [11, 41], "mitlp": 45, "mitt": 42, "mitten": 42, "mix": [12, 17, 35, 46, 47], "mixtur": [40, 42, 43], "ml": [1, 2, 9, 11, 13, 16, 18, 21, 27, 30, 36, 40, 42, 43, 47], "ml_experi": [13, 14, 18, 19, 27, 28, 31, 50], "mlpclassifi": 43, "mlpregressor": 43, "mm": 44, "mmsto": [12, 17, 26], "mn": [35, 37, 46], "mnprv": [35, 37, 46], "mnww": [35, 37, 46], "mo": 42, "mobil": [31, 43], "mobilenet": 43, "mod": [35, 37, 46], "mode": [15, 16, 21, 29, 30, 33], "model": [1, 2, 11, 20, 33, 34, 39, 40, 41, 44, 46, 49, 51], "model_nam": 41, "model_select": [12, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 41, 43, 44, 45, 46, 47, 52, 53], "modern": [1, 15, 20, 29, 42, 46], "modif": 45, "modifi": [0, 10, 34, 45, 47, 54], "modul": [9, 14, 18, 19, 24, 25, 27, 28, 34, 48], "moe": 33, "mole": 43, "mom": 38, "moment": [34, 54], "moment_predictor": 47, "mon": 44, "monarch": 42, "monarchi": 42, "mondai": [1, 44, 54], "monei": [8, 45], "monitor": 42, "monkei": [12, 17, 26, 43], "monotone_constraint": 36, "montani": 48, "month": [14, 28, 31, 35, 45], "month_nam": [23, 44], "monthli": 45, "monthlycharg": 45, "montreal": [42, 48], "moon": 40, "moosvi": [0, 1, 42], "moral": [0, 39], "more": [1, 2, 5, 6, 7, 8, 10, 12, 14, 17, 24, 25, 28, 33, 36, 37, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54], "morn": [12, 17, 26], "morpholog": 42, "moskowitz": 39, "mosold": [35, 37, 46], "mosold_1": 35, "mosold_10": 35, "mosold_11": 35, "mosold_12": 35, "mosold_2": 35, "mosold_3": 35, "mosold_4": 35, "mosold_5": 35, "mosold_6": 35, "mosold_7": 35, "mosold_8": 35, "mosold_9": 35, "most": [7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 54], "most_confident_i": 32, "most_confident_x": 32, "most_frequ": [13, 15, 16, 18, 20, 21, 25, 27, 29, 30, 34, 35, 37, 46, 51], "most_similar": 42, "mostli": [8, 31, 44], "motiv": [12, 17, 26, 31], "mountginini": 44, "move": [7, 32, 37, 38, 51, 54], "movi": [32, 42, 48], "movie_feats_df": 41, "movie_id": 41, "movie_nam": 41, "movies_rated_by_pat": 41, "movies_to_pr": 41, "movieto": 48, "mpimg": 43, "mri": 50, "mrtssm448usn": 44, "mse": [13, 18, 27, 41, 47, 50], "msg": [31, 45], "msg_dtype": 25, "msg_err": 25, "mssubclass": [35, 37, 46], "mssubclass_120": 35, "mssubclass_160": 35, "mssubclass_180": 35, "mssubclass_190": 35, "mssubclass_20": 35, "mssubclass_30": 35, "mssubclass_40": 35, "mssubclass_45": 35, "mssubclass_50": 35, "mssubclass_60": 35, "mssubclass_70": 35, "mssubclass_75": 35, "mssubclass_80": 35, "mssubclass_85": 35, "mssubclass_90": 35, "mszone": [35, 37, 46], "mszoning_c": [35, 37], "mszoning_fv": 35, "mszoning_rh": 35, "mszoning_rl": 35, "mszoning_rm": 35, "much": [4, 5, 8, 13, 14, 15, 16, 18, 19, 20, 21, 27, 28, 29, 30, 31, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 54], "mueller": 1, "multi": [35, 37, 39, 42, 44, 47], "multi_class": [34, 49], "multi_output": 25, "multi_strategi": 36, "multiclass": [43, 47, 49], "multicoliniar": 37, "multicultur": 42, "multilevel": 35, "multimod": 39, "multinomi": 49, "multipl": [7, 8, 14, 19, 23, 28, 32, 33, 36, 37, 42, 43, 44, 45], "multiplelin": 45, "multiplelines_no": 45, "multiplelines_y": 45, "multipli": [32, 33, 34, 36, 38, 45], "music": [25, 41, 48], "musqueam": 54, "must": [0, 6, 7, 8, 12, 13, 14, 16, 17, 18, 21, 27, 28, 30, 37, 40, 42, 45], "mustn": 42, "mutual": 40, "my": [6, 10, 12, 17, 26, 33, 34, 39, 42, 46, 47, 48, 54], "my_heatmap": 33, "my_map": 35, "mypreprocessor": 42, "myself": [27, 42, 46], "m\u00fcller": 9, "n": [1, 13, 15, 18, 20, 24, 25, 27, 29, 32, 33, 35, 36, 37, 38, 40, 41, 42, 44, 46, 48, 49, 52], "n_bin": 38, "n_class": [15, 20, 29, 34], "n_cluster": [39, 40], "n_clusters_per_class": 34, "n_compon": 42, "n_constitu": 36, "n_estim": [38, 44, 45, 46], "n_estimators_valu": 46, "n_exampl": 39, "n_feat": [15, 20, 29], "n_featur": [15, 20, 29, 34, 39], "n_features_to_select": 38, "n_imag": 24, "n_inform": 34, "n_init": 39, "n_job": [31, 34, 35, 36, 46], "n_neighbor": [24, 41, 52], "n_neighbors_selector": [15, 20, 29], "n_neighbors_widget": [15, 20, 24, 29, 52], "n_peopl": 25, "n_redund": 34, "n_rental": 44, "n_rentalsin3hour": 44, "n_rentalsin6hour": 44, "n_repeat": 37, "n_resourc": 33, "n_sampl": [15, 20, 29, 34, 39, 40, 43, 49], "n_split": 44, "n_threshold": 34, "n_topic": 42, "n_train": 44, "n_word": [42, 48], "na": [35, 37, 46], "nafter": 42, "nah": 31, "naiv": 40, "name": [1, 4, 5, 6, 7, 8, 10, 13, 15, 16, 18, 20, 21, 23, 24, 25, 27, 29, 30, 31, 33, 34, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 52, 54], "named_estimators_": 36, "named_step": [32, 34, 35, 36, 37, 38, 44, 46, 48], "named_transformers_": [31, 34, 35, 36, 37, 38, 44, 45, 46, 48], "namespac": 25, "nan": [16, 21, 25, 30, 31, 34, 35, 36, 37, 38, 41, 44, 45, 46, 48, 50], "nanmean": 41, "nanosecond": 44, "narr": 42, "narrow": [12, 17, 41, 46], "nasali": [12, 17, 26, 43], "nation": 54, "nativ": [25, 34, 36, 37, 43, 49], "natur": [2, 11, 12, 25, 26, 31, 34, 36, 38, 43, 47, 49], "navig": [7, 10, 47], "nbsp": [12, 17, 26, 30, 31, 33, 34, 35, 36, 37, 38, 43, 46, 48], "nbviewer": [12, 16, 17, 21, 23, 24, 25, 26, 30, 31, 33, 34, 35, 36, 37, 38, 43, 46, 48], "nc": 1, "ncol": 32, "ndarrai": [8, 25, 31], "ndate": 48, "ndframe": [38, 45], "ndim": [8, 25], "ne": 44, "nearbi": [15, 20, 29, 39], "nearest": [24, 25, 34, 40, 52], "nearestneighbor": 24, "nearestneighborsifittednearestneighbor": 24, "nearli": 23, "necessari": [0, 7, 13, 25, 27, 33, 50, 53], "necessarili": [14, 19, 28, 35, 36, 41, 47], "necvq": 45, "need": [5, 7, 8, 10, 12, 13, 15, 17, 18, 20, 23, 24, 25, 26, 27, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 53, 54], "needn": 42, "neg": [13, 14, 15, 18, 19, 20, 27, 28, 29, 32, 35, 36, 37, 42, 44, 45, 48, 52], "neg_mean_absolute_percentage_error": 35, "neg_mean_squared_error": [35, 46], "neg_root_mean_square_error": 35, "neg_root_mean_squared_error": 35, "neigh": [15, 20, 24, 29], "neighbor": [15, 16, 20, 21, 24, 25, 29, 30, 31, 32, 34, 38, 40, 52, 53], "neighborhood": [32, 35, 37, 46], "neighborhood_blmngtn": 35, "neighborhood_bluest": 35, "neighborhood_brdal": 35, "neighborhood_brksid": 35, "neighborhood_clearcr": 35, "neighborhood_collgcr": 35, "neighborhood_crawfor": 35, "neighborhood_edward": 35, "neighborhood_gilbert": 35, "neighborhood_idotrr": 35, "neighborhood_meadowv": 35, "neighborhood_mitchel": 35, "neighborhood_nam": 35, "neighborhood_noridg": [35, 37], "neighborhood_npkvil": 35, "neighborhood_nridght": [35, 37], "neighborhood_nwam": 35, "neighborhood_oldtown": [35, 37], "neighborhood_sawy": [35, 37], "neighborhood_sawyerw": [35, 37], "neighborhood_somerst": [35, 37], "neighborhood_stonebr": [35, 37], "neighborhood_swisu": [35, 37], "neighborhood_timb": [35, 37], "neighborhood_veenk": [35, 37], "neighborsbas": 25, "neighbour": [14, 24, 28, 37, 39, 40, 42, 52], "neighbourhood": [32, 38, 40, 53], "neither": [14, 19, 28, 31, 41], "neo": [1, 54], "neq": [37, 41], "ner": 42, "nervou": [13, 18, 27], "nest": [33, 50], "net": [43, 45], "netflix": [41, 48], "network": [1, 11, 12, 17, 26, 31, 36, 38, 39, 41, 42, 44, 47], "neu": 48, "neural": [1, 11, 38, 44], "neutral": 48, "never": [34, 36, 37, 41, 43, 45], "nevertheless": 54, "new": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 50, 53], "new_cent": 39, "new_column": [35, 37, 44, 45, 46], "new_data": 45, "new_df": 44, "new_exampl": [13, 18, 27, 39], "new_feature_nam": 44, "new_valu": 45, "newaxi": 8, "newcastl": 48, "newer": 35, "newli": [16, 21, 30, 35, 38, 40], "newsgroup": 42, "newswir": 42, "next": [1, 10, 13, 14, 15, 16, 18, 20, 21, 24, 25, 27, 28, 29, 30, 31, 34, 35, 36, 42, 43, 44, 46, 53, 54], "nfeat": [15, 20, 29], "nfeats_accuraci": [15, 20, 29], "ng": [1, 9, 33, 38], "ngram": 38, "ngram_rang": 31, "nhl": 42, "nhqxu": 45, "nice": [4, 12, 17, 33, 34, 36, 37, 40, 43, 45, 46, 47], "nicki": 33, "night": [34, 44, 47], "nightmar": 46, "niki": [1, 54], "nlemma": 42, "nlp": [31, 43, 48], "nltk": [42, 48], "nltk_data": [42, 48], "nmax": 46, "nn": [1, 16, 21, 24, 30, 43, 52], "nne": 44, "nnw": 44, "nnz": 31, "no_grad": [24, 43], "no_val_x": 25, "nobodi": [12, 26], "node": [13, 18, 27, 36, 40, 43, 51], "nois": [40, 50, 52], "noise_cat": 25, "noise_level": 25, "noise_ord": 25, "non": [1, 8, 12, 13, 14, 16, 17, 18, 19, 21, 26, 27, 28, 30, 32, 33, 34, 35, 36, 38, 40, 41, 43, 44, 45, 47, 50, 54], "noncommerci": 1, "none": [1, 14, 16, 19, 21, 25, 28, 30, 31, 32, 33, 34, 36, 38, 40, 44, 45, 46], "noninfring": 0, "nonzero": 31, "noodl": 25, "noqa": 33, "nor": [7, 14, 19, 28, 31, 42], "norg": [42, 48], "norm": [25, 33, 42], "normal": [6, 21, 24, 25, 34, 35, 36, 37, 39, 40, 42, 43, 44, 46, 48], "north": 42, "north_america": 25, "norvig": 1, "notat": [15, 29], "note": [0, 1, 3, 7, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 41, 47, 49, 50, 54], "notebook": [5, 7, 9, 10, 13, 14, 15, 16, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 43, 46, 48, 53], "notic": [0, 25, 31, 32, 34, 35, 38], "notion": [15, 20, 29, 33, 39, 41], "notna": 44, "noun": [42, 48], "nov": 44, "novel": 50, "novemb": 44, "novic": 9, "now": [8, 10, 12, 14, 15, 16, 17, 19, 20, 21, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 51, 52, 53], "np": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52, 53], "nperson": 48, "npie": 8, "npo": 42, "npr": [38, 42, 50], "npt": 25, "nsubj": 42, "ntest": [15, 20, 24, 29, 33, 52], "ntoken": 42, "ntree": 36, "null": [16, 21, 30, 31, 34, 35, 38, 44, 45], "null_distribut": 45, "num": [34, 36, 37], "num_output_channel": 43, "num_parallel_tre": 36, "num_sent": [34, 47], "num_work": [24, 43], "number": [1, 4, 6, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 45, 47, 50, 52, 54], "number_test": 33, "numberbatch": 42, "numer": [2, 13, 16, 18, 21, 24, 25, 27, 30, 31, 32, 34, 35, 36, 41, 42, 44, 45, 46, 52, 53], "numeric_feat": [25, 31, 33, 38, 50], "numeric_featur": [31, 34, 35, 36, 37, 44, 45, 46, 48], "numeric_looking_column": 35, "numeric_transform": [31, 34, 35, 36, 37, 44, 46], "numpi": [9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53], "numpy_dtyp": 45, "nuniqu": 23, "nutrit": 42, "nw": 44, "nwith": [15, 20, 29], "ny": 48, "nyt": 46, "o": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53], "obelisk": 43, "object": [14, 16, 19, 21, 23, 25, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 48, 50, 51, 52], "observ": [12, 13, 14, 15, 17, 18, 19, 20, 24, 26, 27, 28, 29, 36, 37, 39, 40, 44, 45, 52], "obtain": [0, 24, 32, 39, 40, 41, 45, 52], "obviou": [40, 42], "occasion": 34, "occup": [34, 36, 37], "occupation_farm": 37, "occupation_miss": 37, "occupation_priv": 37, "occupi": 54, "occur": [8, 13, 14, 18, 19, 27, 28, 31, 42, 45], "occurr": [42, 45], "ocean": [16, 21, 30, 31, 38, 53], "ocean_proxim": [16, 21, 30, 31, 38, 53], "ocean_proximity_": [16, 21, 30, 31], "ocean_proximity_inland": [16, 21, 30, 31], "ocean_proximity_island": [16, 21, 30, 31], "ocean_proximity_near": [16, 21, 30, 31], "oct": 32, "octob": [23, 44], "oe": [31, 50], "oe_encod": 50, "off": [11, 24, 32, 33, 34, 35, 38, 39, 42, 43, 45, 46, 50], "offens": 4, "offer": [8, 36, 41, 42, 45, 54], "offic": [1, 4, 10, 12, 50, 54], "offici": [42, 54], "offlin": 41, "offset": 32, "often": [8, 12, 14, 15, 16, 17, 19, 20, 21, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52], "ogunrind": [12, 17, 26], "oh": [25, 37, 38, 43, 44, 45, 47, 50, 54], "ohe_column": [35, 37, 46], "ohe_enc": 31, "ohe_encod": 50, "ohe_feat": 25, "ohe_feature_nam": [37, 44], "ohehotencod": 31, "ois": 40, "ok": [12, 15, 17, 20, 26, 29, 35, 44, 45, 47, 50], "okai": [39, 47], "ola": 42, "old": [9, 36, 37], "old_cent": 39, "older": 35, "olymp": 8, "omit": 37, "omw": 42, "onc": [6, 7, 8, 10, 13, 14, 16, 18, 19, 21, 24, 27, 28, 30, 31, 33, 38, 40, 41, 42, 43, 47, 54], "onca": [12, 17, 26, 43], "one": [6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 54], "one_c": [15, 20, 29], "one_ex_preprocess": 37, "one_ex_preprocessed_perturb": 37, "one_exampl": 37, "one_example_perturb": 37, "onehot": [31, 38], "onehotencod": [16, 21, 25, 30, 32, 33, 34, 35, 36, 37, 38, 44, 45, 46, 50, 53], "onehotencoder__major_biologi": 31, "onehotencoder__major_comput": 31, "onehotencoder__major_econom": 31, "onehotencoder__major_linguist": 31, "onehotencoder__major_mathemat": 31, "onehotencoder__major_mechan": 31, "onehotencoder__major_phys": 31, "onehotencoder__major_psychologi": 31, "onehotencoderonehotencod": [31, 33, 35, 36, 46], "ones": [8, 12, 15, 16, 17, 20, 21, 23, 24, 26, 29, 30, 36, 37, 39, 41, 42, 52], "onevsoneclassifi": 49, "onevsrestclassifi": 49, "onli": [2, 4, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 52, 53, 54], "onlin": [3, 5, 7, 10, 18, 27, 42, 54], "onlinebackup": 45, "onlinebackup_no": 45, "onlinebackup_y": 45, "onlinesecur": 45, "onlinesecurity_no": 45, "onlinesecurity_y": 45, "onrend": 47, "ontario": 42, "ontonot": 42, "oob_scor": 46, "op": 34, "open": [5, 6, 10, 12, 17, 26, 43, 47, 54], "openporchsf": [35, 37, 46], "oper": [4, 8, 10, 31, 38, 42, 47], "operand": 8, "opinion": 36, "opportun": [23, 41], "oppos": [35, 36], "opposit": [8, 35, 36, 37], "opt": [10, 24, 25, 36], "optic": 45, "optim": [1, 2, 13, 14, 15, 18, 19, 20, 24, 27, 28, 29, 31, 34, 36, 37, 38, 39, 40, 43, 45, 46, 47], "optimist": 33, "option": [1, 7, 8, 13, 17, 18, 27, 35, 39, 42, 46], "orang": 32, "orch": 54, "order": [5, 7, 8, 12, 13, 14, 16, 17, 18, 19, 21, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 46, 47, 50], "ordering_ordinal_oth": [35, 37, 46], "ordering_ordinal_reg": [35, 37, 46], "ordin": [35, 50, 53], "ordinal_feat": [25, 31], "ordinal_featur": [34, 36, 37], "ordinal_features_oth": [35, 37, 46], "ordinal_features_reg": [35, 37, 46], "ordinal_transform": [25, 34, 36, 37], "ordinal_transformer_oth": [35, 37, 46], "ordinal_transformer_reg": [35, 37, 46], "ordinalencod": [16, 21, 25, 30, 31, 34, 35, 36, 37, 38, 44, 45, 46, 50, 53], "ordinalencoderordinalencod": [31, 35, 36, 46], "ordinari": 35, "oreilli": [43, 44], "org": [9, 12, 14, 16, 17, 19, 21, 23, 24, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 38, 42, 43, 46, 48], "organ": [12, 13, 16, 17, 18, 21, 26, 27, 30, 42, 46, 47], "orgin": 8, "orig_featur": 44, "orig_pr": 37, "orig_scor": 34, "origin": [12, 16, 17, 21, 30, 31, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 48, 52, 54], "original_hm": [34, 47], "originaltweet": 48, "ornithorhynchu": 43, "oscar": 32, "ostblom": 42, "other": [0, 1, 4, 5, 6, 7, 10, 12, 13, 14, 16, 17, 18, 19, 21, 23, 24, 25, 27, 28, 30, 31, 32, 33, 34, 36, 37, 40, 41, 43, 47, 48, 49, 50, 52, 54], "otherwis": [0, 7, 31], "ounc": [12, 17, 26, 43], "our": [5, 6, 8, 10, 12, 13, 15, 17, 18, 20, 23, 24, 25, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 50, 51, 52, 54], "ourselv": [13, 18, 27, 34, 42, 43, 44], "out": [0, 1, 4, 7, 8, 10, 12, 13, 14, 15, 17, 18, 19, 20, 23, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 48, 50, 52, 54], "out_col": [14, 16, 19, 21, 28, 30, 48], "out_step": 34, "outer": 48, "outlier": [25, 35, 40, 47, 50], "outlook": 45, "output": [7, 8, 10, 12, 13, 14, 17, 18, 19, 25, 26, 27, 28, 31, 32, 34, 36, 37, 42, 43, 44, 46, 47, 50, 54], "outsid": [7, 34, 36, 37, 41, 42, 44, 45], "over": [14, 28, 33, 35, 42, 43, 44, 45, 46, 47, 50, 54], "over_confident_i": 32, "over_confident_x": 32, "over_sampl": 34, "overal": [10, 25, 34, 37, 39, 42, 43, 46, 50, 54], "overallcond": [35, 37, 46], "overallqu": [35, 37, 46], "overconfid": [37, 38, 47], "overcrowd": 54, "overfit": [1, 11, 15, 20, 23, 24, 29, 32, 35, 36, 38, 43, 47, 52], "overflow": 7, "overhead": 31, "overlap": [2, 14, 19, 28, 39, 47], "overli": [15, 20, 24, 29, 33, 52], "overload": [41, 45], "overpredict": 35, "oversample_pip": 34, "overshadow": 42, "overst": 46, "overus": 36, "overview": [39, 40, 41, 42], "overwhelm": 39, "overzeal": 6, "own": [4, 5, 8, 12, 14, 16, 17, 21, 28, 30, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49], "p": [32, 33, 40, 42, 45, 47], "p_i": 39, "p_value_threshold": 45, "pace": [32, 39, 42, 54], "packag": [5, 8, 11, 18, 24, 25, 27, 28, 31, 33, 34, 37, 39, 40, 41, 42, 43, 45, 47, 48, 49], "pad": [24, 43], "page": [1, 4, 7, 12, 16, 17, 21, 23, 24, 25, 26, 30, 31, 33, 34, 35, 36, 37, 38, 42, 43, 46, 48, 54], "pai": [37, 47], "pain": [4, 43, 44, 46], "pair": [40, 42, 49], "pairwis": [15, 20, 29, 40], "panda": [9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53], "pane": [15, 20, 24, 29, 52], "panel": [15, 20, 24, 29, 34, 37, 39, 40, 52], "panic": 48, "panther": [12, 17, 26, 43], "panthera": [12, 17, 26, 43], "paper": [7, 37, 38, 42, 43, 45, 47, 48], "paperlessbil": 45, "paperlessbilling_no": 45, "paperlessbilling_y": 45, "paradigm": [12, 13, 17, 18, 26, 27, 39, 42], "paradox": 41, "paragraph": 42, "paraleg": 42, "parallel": [31, 33, 36], "param": [15, 20, 24, 29, 31, 33, 35, 52], "param_columntransformer__countvectorizer__max_featur": 33, "param_dist": 33, "param_distribut": 33, "param_grid": [14, 15, 19, 20, 28, 29, 33, 35, 46], "param_grid1": 33, "param_grid2": 33, "param_grid3": 33, "param_grid4": 33, "param_ridge__alpha": 35, "param_svc__c": 33, "param_svc__gamma": 33, "paramet": [15, 16, 20, 21, 24, 25, 29, 30, 31, 35, 36, 37, 39, 40, 42, 44, 45, 46, 48, 51, 52], "parametr": 40, "params_": 45, "params_str": 33, "paramter": [15, 20, 29], "pardu": [12, 17, 26, 43], "parent": 40, "park": [38, 43, 47, 48], "pars": 42, "parse_d": [8, 44], "parser": 42, "part": [1, 4, 9, 10, 16, 21, 30, 31, 32, 33, 34, 36, 37, 38, 40, 42, 44, 46, 47, 48, 54], "part1": 41, "part2": 41, "parti": 42, "partial": [4, 45, 46], "particip": 54, "particular": [0, 9, 10, 16, 21, 30, 31, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 52], "particularli": [36, 41, 54], "partit": [31, 39, 40], "partner": [45, 54], "partner_no": 45, "partner_y": 45, "parton": 48, "pass": [8, 14, 15, 16, 19, 20, 21, 24, 25, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 42, 43, 52, 54], "passthrough": [31, 33, 45, 48], "passthrough__ml_experi": 31, "passthrough_feat": [31, 33, 50], "passthrough_featur": [45, 48], "passthroughpassthrough": [31, 33, 48], "past": [13, 14, 18, 19, 27, 28, 36, 44, 45, 46, 50], "pat": 41, "pat_i": 41, "pat_model": 41, "pat_x": 41, "pata": [12, 17, 26, 43], "path": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53], "patial": 40, "patient": [13, 18, 27, 47], "patio": 43, "patric": 37, "patrick": [1, 54], "pattern": [12, 13, 14, 17, 18, 19, 23, 26, 27, 28, 31, 33, 38, 39, 42, 44, 46, 52], "pav_bhaji": 42, "pave": [35, 37, 46], "paveddr": [35, 37, 46], "paveddrive_i": 35, "paveddrive_n": 35, "paveddrive_p": 35, "paymentmethod": 45, "paymentmethod_bank": 45, "paymentmethod_credit": 45, "paymentmethod_electron": 45, "paymentmethod_mail": 45, "pca": [34, 40, 41], "pcarter": 9, "pd": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53], "pdf": [7, 9], "peac": 42, "pedest": 43, "pedro": [1, 14, 28, 38], "peer": [47, 50, 54], "pembrok": [12, 17, 26, 43], "penal": [6, 45], "penalti": [34, 42, 54], "peopl": [4, 13, 14, 16, 18, 19, 21, 27, 28, 30, 32, 34, 36, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 54], "per": [8, 32, 34, 35, 36, 37, 41, 43, 44, 46, 49, 50], "perceiv": 6, "percent": 35, "percent_error": 35, "percentag": [13, 18, 27, 34, 41, 46], "perfect": [6, 13, 14, 18, 19, 23, 27, 28, 34, 35, 37, 41, 45, 48], "perfectli": [2, 41, 42], "perform": [11, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48, 50, 51, 53], "performac": [14, 19, 28], "perhap": [35, 44, 49], "perimet": 38, "period": [42, 44, 45, 48, 54], "perm_sorted_idx": 37, "perman": 8, "permiss": [0, 54], "permit": [0, 16, 21, 30, 34, 54], "permut": 37, "persist": 41, "person": [0, 1, 4, 6, 12, 17, 26, 34, 39, 42, 43, 44, 45, 47, 48, 54], "perspect": [36, 41], "pertain": 5, "perthairport": 44, "perturb": [25, 37, 40], "perturbed_pr": 37, "pete_seeg": 42, "peter": 1, "ph": 42, "pharma": 47, "phascolarcto": 43, "phase": [14, 19, 28], "phd": 42, "phdei": 45, "phenomenon": [41, 45, 52], "philippin": 48, "philosoph": 42, "phone": [12, 17, 26, 45, 54], "phoneservic": 45, "phoneservice_no": 45, "phoneservice_y": 45, "photo": [48, 50], "photograph": 54, "phrase": 42, "physic": [31, 44], "pi": 8, "piazza": [1, 6, 7, 12, 13, 17], "pick": [13, 18, 23, 27, 32, 34, 36, 37, 38, 39, 40, 43, 46, 47, 49, 51, 52], "pictur": [36, 37, 40, 42, 44, 46], "pie": 8, "piec": [32, 45], "pil": [12, 17, 24, 26, 43], "pin": [7, 43], "pineappl": 42, "pip": [10, 37, 42, 43, 47, 48], "pipe": [16, 21, 30, 31, 32, 33, 34, 36, 42, 43, 48], "pipe_bestalpha": 35, "pipe_bigalpha": 35, "pipe_catboost": 36, "pipe_dt": [36, 37], "pipe_forward": 38, "pipe_knn": 25, "pipe_lgbm": [36, 37], "pipe_lr": [34, 36, 37, 47], "pipe_lr_all_feat": 38, "pipe_lr_balanc": 34, "pipe_lr_model_bas": 38, "pipe_lr_weight": 34, "pipe_ohe_knn": 25, "pipe_ordinal_knn": 25, "pipe_rf": [36, 37], "pipe_rf_demo": 36, "pipe_ridg": [32, 35], "pipe_sklearn_gb": 36, "pipe_sklearn_histgb": 36, "pipe_smallalpha": 35, "pipe_svc": 34, "pipe_svm": 33, "pipe_xgb": [36, 37], "pipe_xor": 38, "pipelin": [1, 2, 11, 12, 14, 17, 19, 26, 28, 31, 32, 33, 34, 35, 36, 37, 38, 43, 44, 45, 46, 47, 48, 53], "pipeline__lab1": 31, "pipeline__lab2": 31, "pipeline__lab3": 31, "pipeline__lab4": 31, "pipeline__quiz1": 31, "pipeline__rooms_per_household": 38, "pipeline__university_year": 31, "pipelineifittedpipelin": [16, 21, 30, 31, 33, 34, 38, 43, 48], "pipelineinot": [31, 33, 35], "pipelinepipelin": 33, "pitch": 46, "pitfal": [44, 46], "pixel": 37, "pizza": 42, "pkg": 10, "pla": 42, "place": [5, 42, 44, 54], "plagiar": 54, "plai": [13, 15, 18, 20, 27, 29, 33, 37, 40, 42, 51, 52], "plain": 39, "plan": [10, 12, 17, 26, 35, 38, 45, 47, 48, 53, 54], "plane": [18, 32], "plant": 50, "plastic": 42, "platform": 4, "platypu": 43, "player": [37, 42, 43], "pleas": [1, 4, 7, 10, 12, 16, 17, 21, 23, 24, 25, 26, 30, 31, 33, 34, 35, 36, 37, 38, 43, 46, 47, 48, 54], "plinth": 43, "plot": [7, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35, 38, 40, 41, 42, 43, 44, 46, 47, 52], "plot_2d_scor": 32, "plot_2d_separ": [15, 20, 24, 29, 32, 52], "plot_confusion_matrix": 34, "plot_confusion_matrix_exampl": 34, "plot_cross_valid": [14, 19, 28, 44], "plot_dbscan": 40, "plot_dbscan_with_label": 40, "plot_dendrogram_clust": 40, "plot_elbow": 39, "plot_example_dist": 39, "plot_fruit_tre": [13, 27], "plot_grid_search_overview": 33, "plot_improper_process": 25, "plot_k_means_dbscan_comparison": 40, "plot_km_initi": 39, "plot_km_it": 39, "plot_km_iter": 39, "plot_kmean": 40, "plot_knn_clf": [15, 20, 29], "plot_knn_decision_boundari": [15, 20, 29], "plot_knn_regress": [15, 20, 29], "plot_lda_w_vector": 42, "plot_linkage_criteria": 40, "plot_logistic_regress": 32, "plot_logistic_regression_graph": 43, "plot_loss_diagram": 46, "plot_multiclass_lr_ovr": 49, "plot_original_clust": 40, "plot_partial_effects_on_outcom": 45, "plot_proper_process": 25, "plot_result": [15, 20, 24, 29, 52], "plot_sample_img": 24, "plot_scal": [16, 21, 30], "plot_silhouette_dist": 39, "plot_single_hidden_layer_graph": 43, "plot_support_vector": [15, 20, 29], "plot_survival_funct": 45, "plot_svc_c": [15, 20, 29], "plot_svc_gamma": [15, 20, 29], "plot_time_spacing_distribut": 44, "plot_train_test_point": [15, 20, 29], "plot_tre": 23, "plot_tree_decision_boundari": [14, 19, 28], "plot_tree_decision_boundary_and_tre": [13, 14, 18, 19, 27, 28, 51], "plot_two_hidden_layer_graph": 43, "plot_typ": 37, "plot_x_dendrogram": 40, "plotli": [38, 42], "plotting_funct": [13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 43, 46, 49, 51, 52, 53], "plotting_functions_unsup": [39, 40, 41, 42], "plt": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 49, 50, 51, 52, 53], "plu": [32, 43], "plural": 31, "pm": [1, 12, 16, 17, 44, 54], "pmltt": 1, "pn": [15, 20, 24, 29, 34, 39, 40, 52], "po": [21, 28, 30, 32, 35, 37, 42, 46, 48], "pobox": [12, 17, 26], "poet": 42, "point": [1, 4, 11, 12, 13, 14, 16, 17, 18, 21, 23, 25, 26, 27, 28, 30, 31, 32, 33, 35, 38, 40, 45, 46, 47, 49, 50, 52, 54], "point_ind": 39, "point_index": 39, "polarity_scor": 48, "pole": 43, "polici": [3, 4, 7, 17, 54], "polit": [41, 42, 43], "poly_transform": 44, "polynomialfeatur": [38, 44], "pomegran": 43, "pool": 1, "poolarea": [35, 37, 46], "poolqc": [35, 37, 46], "poor": [31, 35, 38, 50, 53], "poorli": [15, 20, 29, 35, 40, 44], "pope": 42, "popul": [16, 21, 30, 31, 32, 38, 44, 53], "popular": [8, 11, 14, 15, 16, 20, 21, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 46, 48], "population_per_household": [16, 21, 30, 31, 53], "port": 47, "porter": 42, "porterstemm": 42, "portion": [0, 14, 16, 19, 21, 28, 30, 33, 35, 37, 46, 54], "portug": [34, 37], "pos_": [42, 48], "pos_label": 35, "posit": [13, 14, 15, 19, 20, 21, 27, 28, 29, 30, 32, 35, 36, 37, 42, 44, 45, 48], "posix": 45, "possess": 46, "possibl": [4, 5, 6, 8, 12, 13, 14, 16, 17, 18, 19, 21, 23, 25, 26, 27, 28, 30, 33, 34, 36, 37, 38, 40, 41, 42, 43, 45, 46, 50, 52, 53, 54], "possibli": [7, 42], "post": [1, 4, 6, 7, 8, 12, 17, 42, 44, 47, 54], "postprocess": 43, "potenti": [11, 15, 16, 20, 21, 23, 29, 30, 39, 42, 46, 47], "powder": 42, "power": [8, 14, 19, 25, 28, 36, 41, 42, 43, 46], "pplicat": 40, "pr": 50, "practic": [0, 1, 6, 9, 12, 14, 16, 19, 21, 28, 30, 38, 43, 46, 47, 50, 53, 54], "practition": 46, "prairielearn": [1, 12, 17, 54], "pre": [1, 10, 12, 17, 24, 26, 36, 38, 42, 46, 47, 48, 50], "precipit": 47, "precis": [11, 35, 46, 47, 50], "precision_lr": 34, "precision_recall_curv": 34, "precision_scor": 34, "precision_svc": 34, "precisionrecallcurvedisplai": 34, "precisionrecalldisplai": 34, "pred": [34, 35, 41, 44, 45], "pred_df": [12, 17, 26, 41], "pred_dict": [12, 17, 26], "pred_g": 41, "pred_lin_reg": 41, "pred_train": 35, "pred_x": 41, "prediciton": 45, "predict": [2, 11, 14, 15, 16, 19, 20, 21, 23, 25, 28, 29, 30, 33, 34, 35, 38, 39, 40, 42, 44, 46, 47, 48, 50, 52, 53], "predict_expect": 45, "predict_for_usr": 41, "predict_proba": [34, 36, 37, 43, 49], "predict_survival_funct": 45, "predicted_categori": [34, 47], "predicted_n_rent": 44, "predicted_quiz2": [13, 18, 27], "predicted_sal": 44, "predicted_target": [12, 17, 26], "predictor": [13, 18, 27, 50], "prefer": [12, 17, 26, 36, 39, 41], "prefer_skip_nested_valid": 25, "prefix": 8, "preliminari": [16, 21, 30, 38], "prepar": [16, 21, 30, 38, 43], "prepend": 10, "preprocess": [1, 11, 14, 15, 19, 20, 23, 24, 25, 28, 29, 32, 33, 34, 36, 37, 38, 40, 41, 43, 45, 52, 53], "preprocess_featur": 44, "preprocessing_fin": 45, "preprocessing_notenur": 45, "preprocessor": [25, 31, 33, 34, 35, 36, 37, 44, 45, 46, 48, 53], "preprocessor1": 38, "preprocessor2": 38, "preprocessor3": 38, "prereq": 47, "prerequisit": [2, 45, 54], "preschool": [34, 36, 37], "presenc": [31, 37, 45], "present": [7, 14, 19, 24, 28, 34, 41, 42, 43, 44, 45, 46, 47, 50, 52], "preserv": [34, 39], "pressure3pm": 44, "pressure9am": 44, "pretend": [13, 14, 19, 27, 28, 44], "pretrain": [42, 43, 48], "pretti": [13, 18, 25, 27, 31, 32, 34, 36, 39, 42, 44, 45], "prevent": [33, 42, 45, 54], "previou": [12, 13, 17, 18, 23, 27, 35, 36, 39, 40, 44, 45, 46, 50], "previous": [41, 43, 44], "price": [8, 16, 18, 21, 23, 25, 30, 32, 35, 37, 38, 45, 46, 52], "primari": [8, 15, 20, 29], "primarili": [12, 13, 17, 18, 27, 37, 43, 47], "prime": [12, 17, 26], "princ": 42, "princess": 42, "principl": [9, 11, 13, 27, 50], "print": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 52], "print_top": 42, "prior": [39, 44, 50], "priorit": [38, 50], "privaci": [0, 11, 39, 47], "privat": [7, 34, 36, 37], "privileg": 6, "prize": 31, "pro": [39, 43, 46], "prob": [32, 36], "proba": 43, "probabilist": [2, 42], "probabl": [12, 15, 16, 17, 20, 21, 25, 26, 29, 30, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 50], "problem": [1, 4, 6, 11, 12, 17, 23, 25, 26, 31, 32, 34, 35, 36, 37, 39, 40, 42, 43, 45, 46, 49, 50, 52, 54], "problemat": [34, 37, 45], "probosci": [12, 17, 26, 43], "proce": [24, 54], "procedur": 36, "proceed": [14, 28], "process": [2, 5, 7, 11, 13, 15, 16, 18, 20, 21, 23, 24, 27, 29, 30, 31, 33, 38, 39, 40, 43, 46, 47, 48, 52], "procfil": 47, "prod": [31, 33], "produc": [2, 7, 18, 25, 35, 37, 40, 45, 46, 50, 52], "product": [5, 33, 41, 42, 46, 48], "prof": [34, 36, 37], "profession": [41, 47], "profil": 35, "profile_df": 41, "profilereport": 35, "profit": 46, "program": [0, 4, 9, 10, 12, 17, 26, 42, 54], "programm": 42, "progress": 39, "project": [10, 16, 21, 30, 36, 38, 43, 46, 47, 50, 54], "promin": 42, "promis": [12, 17, 23, 26, 42, 44, 47], "promot": 45, "prompt": [10, 12, 54], "pron": [42, 48], "prone": 33, "proper": [43, 51], "properli": [7, 12, 17, 45, 46], "properti": [13, 18, 27, 35, 37, 38], "prophet": 44, "propn": [42, 48], "proport": [11, 13, 14, 18, 19, 27, 28, 31, 32, 34, 35, 36, 37, 46], "proportional_hazard_test": 45, "prostitut": 42, "protocol": 47, "prototyp": [47, 50], "prove": 34, "provid": [0, 5, 7, 10, 11, 13, 14, 18, 19, 24, 27, 28, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 46, 50, 54], "provinc": [31, 42], "provinci": 42, "proxi": [14, 19, 28], "proxim": [32, 42, 54], "prune": 38, "psychologi": [31, 50], "pt": [32, 33, 43], "public": [0, 4, 7, 42, 48], "publish": [0, 1, 32, 42], "puck": 42, "pud": 35, "pull": [10, 32, 42], "punct": [42, 48], "punctuat": [31, 42], "punish": 46, "punkt": 48, "punkt_tab": 48, "purchas": [12, 17, 24, 26, 41, 47], "pure": [13, 18, 27, 44], "purpos": [0, 13, 14, 16, 18, 19, 21, 27, 28, 30, 41, 42, 44, 47, 50, 51, 52, 54], "pursuit": 46, "push": [7, 37], "put": [7, 8, 10, 13, 14, 16, 19, 21, 24, 25, 27, 28, 30, 31, 38, 39, 40, 41, 47], "px": [38, 42], "py": [13, 18, 21, 24, 25, 27, 28, 30, 31, 33, 36, 37, 39, 40, 45, 47, 48, 49], "pybo": 33, "pydata": 38, "pyplot": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 50, 51, 52, 53], "pysurviv": 45, "python": [1, 3, 4, 11, 26, 33, 35, 41, 42, 43, 44, 45, 46, 47, 48, 54], "python3": [9, 18, 24, 25, 27, 28, 31, 33, 37, 45, 49], "pythonwarn": 35, "pytorch": [12, 17, 26, 43], "pyviz": 34, "q": 1, "qualit": 25, "qualiti": [34, 37, 39, 40, 46], "quantifi": 34, "quantil": 25, "quantit": 25, "quebecoi": 25, "queen": 42, "queen_consort": 42, "queri": [16, 21, 24, 30, 34, 36, 39, 41, 42, 44, 45, 54], "query_img": 24, "query_point": [15, 20, 29], "quest": 38, "question": [1, 6, 7, 54], "queuepredictor": 47, "quick": [4, 12, 17, 42, 47, 54], "quickli": [13, 15, 16, 18, 20, 21, 27, 29, 30, 33, 40, 45, 50, 54], "quickstart": 9, "quirk": [14, 19, 28], "quit": [6, 12, 13, 16, 18, 21, 24, 26, 27, 30, 33, 34, 35, 37, 38, 40, 42, 43, 44, 45, 46, 48], "quiz": [1, 12, 16, 17, 42, 54], "quiz1": [13, 14, 18, 19, 27, 28, 31, 50], "quiz2": [14, 19, 28, 31, 50], "quizz": [13, 15, 18, 27], "r": [11, 13, 18, 27, 31, 32, 34, 44, 46], "r1": 36, "r2": [23, 35, 36, 50, 52], "r2_score": [35, 38], "r4": 36, "race": [31, 34, 36, 37, 54], "radial": [15, 20, 29], "radiu": [38, 40], "rail": 43, "rain": 44, "rain_df": 44, "rain_df_modifi": 44, "rainfal": 44, "rainfall_lag1": 44, "rainfall_lag2": 44, "rainfall_lag3": 44, "raintodai": 44, "raintoday_miss": 44, "raintoday_no": 44, "raintoday_y": 44, "raintomorrow": 44, "rais": [6, 17, 25, 31, 34, 44, 45], "rand": [8, 36], "randint": 33, "randn": [32, 38], "random": [6, 8, 11, 14, 15, 19, 20, 24, 28, 29, 32, 34, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50], "random_forest_data": 36, "random_search": 33, "random_st": [12, 15, 16, 17, 20, 21, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53], "randomforestclassifi": [37, 38, 44, 46], "randomforestclassifierrandomforestclassifi": 36, "randomforestregressor": [35, 36, 37, 38, 44, 45, 46, 47], "randomhorizontalflip": 43, "randomizedsearchcv": [15, 20, 29, 36, 37, 46], "randomizedsearchcvifittedrandomizedsearchcv": 33, "randomli": [14, 19, 28, 32, 33, 34, 36, 45], "randomoversampl": 34, "randomresizedcrop": 43, "randomst": [38, 40], "randomundersampl": 34, "rang": [4, 8, 11, 14, 15, 16, 19, 20, 21, 25, 28, 29, 30, 31, 32, 36, 39, 41, 42, 43, 44, 45, 46, 48], "rangeindex": [31, 38, 44, 45], "rank": [34, 38, 41, 42, 45], "rank_test_mape_scor": 35, "rank_test_neg_mean_squared_error": 35, "rank_test_scor": [33, 35], "ranking_": 38, "rare": [31, 34, 35, 39, 42, 50], "rate": [12, 17, 26, 32, 34, 36, 39, 45, 46, 50], "rated_item": 41, "rather": [12, 17, 25, 26, 31, 33, 34, 35, 36, 37, 39, 42, 43, 54], "ratings_df": 41, "ratio": [34, 36, 42, 45], "ravel": [24, 34, 50], "raw": [8, 31, 34, 37, 38, 42, 43, 46, 49], "raw_model_output": 32, "raw_scor": 37, "rbf": [1, 14, 16, 19, 21, 28, 30, 32, 33, 36, 37, 38, 46, 47, 50, 52], "rcparam": [12, 13, 14, 17, 18, 19, 26, 27, 28, 34, 39, 40, 41, 43, 44, 45, 46, 51], "re": [4, 7, 8, 10, 12, 13, 14, 17, 18, 19, 26, 27, 28, 31, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 47, 50, 51], "reach": [1, 6, 39, 54], "read": [1, 4, 7, 12, 15, 16, 17, 20, 21, 24, 29, 30, 31, 34, 35, 36, 37, 42, 44, 46, 47], "read_csv": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53], "read_excel": 8, "read_html": 8, "read_img_dataset": 24, "read_json": 8, "readabl": [0, 8], "reader": 11, "readi": [7, 12, 14, 15, 16, 19, 20, 21, 28, 29, 30, 32], "readlin": 43, "readm": 45, "readthedoc": 45, "real": [14, 15, 16, 18, 19, 20, 21, 25, 28, 29, 30, 31, 32, 34, 37, 39, 40, 41, 42, 43, 46, 48, 50], "realdonaldtrump": 48, "realist": [16, 21, 30, 44, 47], "realiti": [14, 19, 28, 35, 45], "realiz": 46, "realli": [8, 14, 19, 28, 32, 33, 36, 38, 40, 41, 43, 44, 45, 47], "reason": [0, 2, 4, 8, 11, 14, 16, 19, 21, 28, 30, 33, 34, 35, 37, 39, 41, 42, 44, 45, 46, 47, 50, 54], "rec": [35, 37, 46], "recal": [11, 13, 14, 15, 16, 19, 21, 25, 27, 28, 29, 30, 31, 32, 35, 39, 44, 47, 50], "recall_lr": 34, "recall_scor": 34, "recall_svc": 34, "receiv": [6, 7, 17, 31, 40, 43, 44, 47], "recent": [8, 10, 12, 17, 25, 26, 31, 38, 41, 42, 44, 45], "recip": [14, 19, 28], "recogn": [11, 14, 19, 28, 40, 44, 46, 54], "recognit": [12, 13, 15, 17, 26, 27, 29, 34, 42, 54], "recommend": [1, 2, 4, 8, 10, 11, 14, 15, 19, 24, 26, 28, 29, 33, 34, 39, 42, 43, 46, 47], "record": [13, 18, 27, 45], "rectangular": 39, "recurr": 44, "recurs": 11, "red": [13, 15, 18, 20, 27, 29, 34, 37, 38, 39, 44], "redbon": 33, "redefin": 45, "redistribut": 0, "reduc": [7, 8, 12, 15, 17, 20, 26, 29, 33, 34, 35, 36, 37, 38, 41, 42, 43, 49, 52, 54], "reduct": [2, 34, 36, 38, 39], "redund": [32, 37], "ref": [34, 45], "refer": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 27, 28, 29, 30, 31, 32, 34, 37, 39, 41, 42, 43, 52, 54], "referenc": 54, "referenti": 42, "refin": [15, 20, 24, 29, 52], "refit": 35, "reflect": [15, 20, 29, 35, 37, 42, 52, 54], "reflection_period": [34, 47], "reg": [13, 18, 27, 36], "reg_model": [13, 18, 27], "regard": 54, "regardless": 7, "regex": 42, "regim": 47, "region": [13, 18, 27, 34, 40, 44, 47, 49], "region_data": 44, "regist": [12, 17, 47, 54], "registered_nurs": 42, "regrad": [6, 17], "regress": [1, 2, 11, 12, 16, 17, 21, 23, 26, 30, 31, 37, 38, 41, 44, 45, 46, 47, 48, 49, 50, 52], "regression_df": [13, 18, 27], "regressor": [13, 16, 18, 21, 23, 25, 27, 30, 31, 35, 44], "regular": [15, 20, 29, 31, 32, 36, 42, 44, 45, 46, 50], "regulatori": 37, "reinforc": [12, 17, 26, 39], "reject": 34, "rel": [19, 25, 32, 37, 40, 42, 48, 49], "rel_char_len": 48, "relabel": 39, "relat": [2, 6, 10, 12, 17, 26, 32, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 48, 54], "relationship": [11, 34, 36, 37, 38, 42, 44, 46, 48, 50, 51, 52, 54], "relationship_husband": 37, "relationship_own": 37, "releas": [1, 7, 14, 15, 16], "relev": [1, 4, 8, 11, 13, 15, 16, 18, 20, 21, 27, 29, 30, 33, 37, 44, 54], "reli": [14, 15, 19, 20, 24, 28, 29, 38, 40, 41, 44, 52], "reliabl": [12, 17, 19, 26, 39], "religi": 42, "remain": [5, 35, 38, 41, 44, 46], "remaind": 6, "rememb": [7, 15, 17, 20, 29, 31, 33, 34, 37, 38, 40, 43, 44, 45, 51, 52], "remind": 51, "remix": 0, "remov": [7, 16, 21, 24, 30, 34, 36, 37, 38, 42, 43, 45, 49], "renam": [12, 17, 26, 34, 37, 44, 47], "render": [4, 7, 12, 16, 17, 21, 23, 24, 25, 26, 30, 31, 33, 34, 35, 36, 37, 38, 39, 42, 43, 46, 48], "rent": 44, "rental": [44, 47], "rentals_df": 44, "rentals_lag5": 44, "rentals_lag5_i": 44, "rentals_lag5_x": 44, "rentals_model": 44, "repair": [34, 36, 37], "repeat": [8, 38, 39, 40, 43, 47], "repeatedli": 6, "rephras": 46, "replac": [12, 16, 17, 21, 25, 26, 30, 34, 36, 37, 41, 45], "replic": 47, "repo": [1, 34, 47], "report": [6, 13, 18, 27, 33, 35, 38, 44, 48], "repositori": [0, 1, 5, 10, 12, 17, 24, 25, 32, 34, 47, 54], "repres": [13, 14, 15, 16, 18, 19, 20, 21, 27, 28, 29, 30, 31, 32, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50], "represent": [12, 13, 16, 17, 18, 21, 23, 24, 25, 26, 27, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42, 46, 47, 48, 50], "reproduc": [4, 14, 19, 28, 33, 36, 47, 54], "republ": 37, "request": [6, 17, 42, 54], "requir": [5, 7, 15, 16, 20, 21, 24, 25, 29, 30, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 50, 52, 54], "rerun": [12, 16, 17, 21, 23, 24, 25, 26, 30, 31, 33, 34, 35, 36, 37, 38, 43, 46, 48], "res_mean": [14, 19, 28], "resampl": 34, "research": [12, 14, 17, 19, 26, 28, 33, 41, 42, 47], "reserv": [44, 54], "reset": 25, "reset_index": [12, 17, 26], "reshap": [8, 25, 32, 33, 43, 44], "resid": 32, "residu": 36, "resiz": [24, 43], "resnet": 43, "resolut": 42, "resolv": 54, "resort": 32, "resourc": [1, 3, 5, 27, 36, 37, 42, 43, 47, 50], "respect": [32, 33, 34, 36, 37], "respons": [4, 7, 13, 18, 27, 39, 42, 46, 54], "rest": [32, 33, 43, 45, 47, 50], "restart": [7, 10], "restaur": [25, 41, 47], "restaurant_df": 25, "restaurant_nam": 25, "restrict": [0, 35, 36, 42], "resubmit": 17, "result": [1, 2, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 47, 48, 52, 54], "result_block": 45, "result_img": 43, "results_df": [14, 15, 19, 20, 23, 24, 28, 29, 32, 52], "results_dict": [14, 15, 16, 19, 20, 21, 24, 28, 29, 30, 31, 33], "results_single_valid_df": [23, 52], "retail": [48, 50], "retail_df": 44, "retail_df_test": 44, "retail_df_train": 44, "retail_lag_5": 44, "retail_model": 44, "retail_test_5": 44, "retail_test_5_pr": 44, "retail_train_5": 44, "retail_train_5_d": 44, "retail_train_5_i": 44, "retail_train_5_x": 44, "retent": 45, "retrain": [33, 47], "return": [5, 8, 10, 13, 14, 15, 16, 18, 19, 20, 21, 24, 25, 27, 28, 29, 30, 31, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 52], "return_gener": 31, "return_predict": 47, "return_train_scor": [14, 15, 16, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 44, 45, 48, 52], "reus": [34, 54], "revenu": 41, "revers": [31, 35], "review": [1, 4, 32, 39, 46, 48, 50, 54], "revisit": [34, 50], "revok": 0, "reward": [12, 17, 26, 31, 39], "rf": [44, 45], "rf_imp_df": 37, "rfe_cv": 38, "rfe_pip": 38, "rfecv": 38, "rgb": [12, 17, 26], "rhode_island": 42, "rich": [37, 42, 45, 46, 50], "richard": 46, "rico": 37, "rid": [10, 25, 31, 36, 37, 42, 45], "ridg": [37, 38, 41, 44, 45, 46, 47], "ridge__alpha": 35, "ridge_pr": 35, "ridge_tun": 35, "ridgecv": 38, "ridgecv_pip": 35, "ridgeridg": [35, 38], "right": [0, 1, 11, 12, 17, 23, 25, 26, 32, 33, 34, 35, 38, 39, 40, 41, 42, 46, 47, 50], "rightarrow": [13, 15, 20, 27, 29, 32, 34, 35, 36, 39, 40, 41, 42, 46, 47, 50], "rindfleischetikettierungs\u00fcberwachungsaufgaben\u00fcbertragungsgesetz": 42, "rise": [38, 42], "risk": [1, 34, 38, 46, 52], "riti": [17, 18, 19, 20, 21, 54], "river": 32, "rl": [35, 37, 46], "rmse": [41, 50], "rng": [38, 40], "rnn": 44, "ro": 34, "roast": 39, "robot": [41, 42], "robust": [12, 14, 15, 16, 17, 19, 20, 21, 25, 26, 28, 29, 30, 33, 36, 40, 52], "robustscal": 25, "roc": [11, 47, 50], "roc_auc": 34, "roc_auc_scor": 34, "roc_curv": 34, "roc_lr": 34, "roc_svc": 34, "roccurvedisplai": 34, "rodolfo": 33, "rodr\u00edguez": 42, "roger": 38, "role": [32, 33, 37, 43], "roman": 41, "romanc": 41, "romant": 41, "ronald": 32, "roof": 37, "roofmatl": [35, 37, 46], "roofmatl_clytil": [35, 37], "roofmatl_compshg": [35, 37], "roofmatl_membran": 35, "roofmatl_met": 35, "roofmatl_rol": 35, "roofmatl_tar": 35, "roofmatl_wdshak": 35, "roofmatl_wdshngl": [35, 37], "roofstyl": [35, 37, 46], "roofstyle_flat": 35, "roofstyle_g": 35, "roofstyle_gambrel": 35, "roofstyle_hip": 35, "roofstyle_mansard": 35, "roofstyle_sh": 35, "room": [12, 13, 17, 18, 26, 27, 32, 35, 38, 47, 48, 54], "rooms_per_household": [16, 21, 30, 31, 38, 53], "rooms_per_household_0": 38, "rooms_per_household_1": 38, "rooms_per_household_10": 38, "rooms_per_household_11": 38, "rooms_per_household_12": 38, "rooms_per_household_13": 38, "rooms_per_household_14": 38, "rooms_per_household_15": 38, "rooms_per_household_16": 38, "rooms_per_household_17": 38, "rooms_per_household_18": 38, "rooms_per_household_19": 38, "rooms_per_household_2": 38, "rooms_per_household_3": 38, "rooms_per_household_4": 38, "rooms_per_household_5": 38, "rooms_per_household_6": 38, "rooms_per_household_7": 38, "rooms_per_household_8": 38, "rooms_per_household_9": 38, "root": [10, 13, 15, 18, 20, 24, 27, 29, 41, 43, 50], "rose": 42, "rostin": [1, 54], "rotat": 44, "roth": [1, 54], "rough": 4, "roughli": [5, 14, 28, 42, 47, 50], "round": [8, 15, 16, 20, 21, 24, 29, 30, 33, 34, 36, 40, 43, 52], "rout": [5, 13, 18, 27, 44], "row": [13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54], "rry": 42, "rsh": 33, "ru": [8, 34], "rubric": [17, 32], "rule": [1, 8, 12, 13, 15, 17, 18, 23, 26, 27, 29, 32, 34, 36, 42, 47, 50, 52], "run": [1, 4, 5, 7, 10, 12, 14, 15, 17, 19, 24, 26, 28, 29, 31, 33, 34, 35, 37, 39, 40, 42, 43, 47, 48, 49, 51, 52], "runtimewarn": 33, "ruscorpora": 42, "rush": 38, "russel": 1, "rv": 33, "rv_continuous_frozen": 33, "rv_discrete_frozen": 33, "rvert_2": 42, "s1": [8, 42], "s19": [16, 21, 30], "s2": [8, 42], "s_lag": 44, "sa": 1, "sabr": 42, "sabrina": 1, "sadli": 42, "safe": [16, 21, 30], "safeti": 43, "sai": [8, 13, 15, 16, 18, 20, 21, 27, 29, 30, 31, 34, 35, 36, 37, 42, 44, 46, 50], "said": [14, 16, 19, 21, 28, 30, 32, 37, 40, 41, 42, 46], "sal": [35, 37, 46], "sale": [8, 23, 34, 35, 44, 46, 52], "salecondit": [35, 37, 46], "salecondition_abnorml": 35, "salecondition_adjland": 35, "salecondition_alloca": 35, "salecondition_famili": 35, "salecondition_norm": 35, "salecondition_parti": 35, "salepric": [35, 37, 46], "sales_data": 44, "salesforc": 48, "saleswoman": 42, "saletyp": [35, 37, 46], "saletype_cod": 35, "saletype_con": 35, "saletype_conld": 35, "saletype_conli": 35, "saletype_conlw": 35, "saletype_cwd": 35, "saletype_new": 35, "saletype_oth": 35, "saletype_wd": 35, "salt": [32, 37], "sam": 41, "same": [6, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52], "samosa": 42, "sampl": [12, 13, 15, 16, 18, 19, 20, 21, 24, 25, 27, 29, 30, 32, 33, 37, 40, 43, 44, 45, 46, 47, 51, 52], "sample_df": [34, 47], "sample_text": 48, "sampling_strategi": 34, "samuel": [12, 17, 26], "sand": 43, "sandbar": 43, "saniti": [13, 18, 27, 45], "sarah": 1, "sat": 44, "satisfactori": 39, "satisfi": 39, "satur": 46, "saturdai": 44, "sauc": 25, "save": [7, 8, 31, 33, 37, 42, 43, 44, 46, 48, 53], "saw": [16, 21, 30, 32, 33, 34, 40, 50], "sb": 38, "scalabl": [12, 17, 26, 40], "scalar": 8, "scale": [14, 15, 19, 20, 23, 24, 28, 29, 31, 33, 34, 35, 36, 38, 40, 43, 45, 46, 47, 50, 52, 53], "scale_pos_weight": 36, "scaler": [16, 21, 25, 30, 37, 38], "scan": 50, "scari": 47, "scatter": [16, 21, 30, 35, 37, 38], "scatter_3d": 38, "scatterplot": [38, 47], "scc": 42, "scenario": [11, 14, 19, 28, 31, 36, 37, 38, 40, 44, 45, 47, 50], "schafer": 47, "schedul": [45, 50, 54], "schmidt": 33, "school": [12, 17, 26, 34, 36, 37, 41], "schoolteach": 42, "scienc": [1, 2, 9, 10, 11, 31, 39, 44, 46, 50, 52], "scientif": [41, 42], "scientist": [1, 9, 40], "scikit": [9, 10, 11, 13, 15, 18, 20, 25, 27, 29, 32, 33, 34, 36, 39, 40, 43, 44, 46, 48, 49], "scipi": [10, 33, 40, 42], "scm": 5, "scope": [12, 17, 42, 44], "score": [11, 12, 15, 16, 17, 20, 21, 23, 24, 25, 26, 29, 30, 31, 36, 37, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 54], "score_func": 35, "score_gb_test": 46, "score_gb_train": 46, "score_lr_print_coeff": 44, "score_param": 31, "score_rf_test": 46, "score_rf_train": 46, "score_tim": [14, 15, 16, 19, 20, 21, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 44, 45, 48], "scorer": [31, 35], "scores_dict": 32, "scores_imag": 32, "scoring_method": 45, "scoring_metr": [36, 37, 48], "scotland": 42, "scott": 46, "scratch": [2, 43, 47], "screen": 7, "screennam": 48, "screenplai": 42, "screenporch": [35, 37, 46], "screenshot": 46, "script": 10, "scroog": 48, "sdng": [35, 46], "se": [44, 45], "sea": 43, "seaborn": [37, 38, 39, 40, 41], "seacoast": 43, "search": [4, 5, 10, 35, 42, 50], "search_multi": 35, "seashor": 43, "season_autumn": 44, "season_fal": 44, "season_summ": 44, "season_wint": 44, "seat": [43, 54], "seattl": 48, "seawal": 43, "second": [4, 6, 13, 17, 18, 27, 32, 36, 37, 40, 43, 44, 46], "secondari": [12, 17, 26], "secpompeo": 48, "section": [1, 7, 10, 14, 18, 27, 28, 38, 54], "secur": [37, 47, 54], "see": [1, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 47, 50, 51, 52, 54], "seed": [24, 32, 33, 39, 40, 47], "seem": [13, 15, 16, 18, 20, 21, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 44, 45, 48, 49, 52], "seemingli": 34, "seen": [8, 12, 14, 15, 16, 17, 19, 20, 21, 26, 28, 29, 30, 31, 32, 38, 40, 41, 45, 50, 52], "segment": [11, 34, 42, 43, 45, 47, 50], "segmentspher": 47, "select": [1, 5, 6, 10, 11, 14, 15, 16, 18, 19, 20, 21, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 43, 44, 45, 46, 47], "select_dtyp": 35, "select_knn": 38, "select_rf": 38, "select_svc": 38, "selectfrommodel": 38, "self": [12, 17, 25, 26, 31, 45, 54], "sell": [0, 8, 13, 18, 27, 46], "semant": [11, 39, 40, 42], "semest": [12, 17, 54], "semi": [1, 12, 42], "semicolon": 8, "semilogx": 35, "send": [4, 12, 17, 26], "senior": 45, "seniorcitizen": 45, "sens": [6, 14, 19, 28, 31, 32, 34, 35, 37, 38, 39, 41, 42, 44, 45, 47, 49], "sensibl": [7, 47], "sensit": [14, 16, 19, 21, 28, 30, 33, 34, 35, 39, 45], "sent": [12, 17, 26, 42], "sent_token": 42, "sentenc": [42, 46], "sentiment": [13, 27, 32, 42, 48], "sentimentintensityanalyz": 48, "sepal": [15, 20, 24, 29, 52], "separ": [13, 14, 16, 18, 19, 21, 25, 27, 28, 30, 31, 32, 34, 38, 39, 41, 42, 44, 49, 50, 51, 52, 53], "septemb": 44, "sequenc": [14, 19, 28, 31, 43, 44], "sequenti": [13, 18, 27, 36, 44, 45, 50], "sequentialfeatureselector": 38, "ser": [21, 28, 30, 45, 48], "seri": [1, 2, 11, 14, 16, 19, 21, 28, 30, 31, 34, 38, 43, 45, 47, 48], "serial": 36, "seriou": [6, 34, 41, 42, 45, 47, 54], "serv": [5, 11, 13, 18, 27, 37, 54], "server": 5, "servic": [25, 36, 37, 41, 45, 48], "session": [12, 13, 39, 50, 54], "set": [1, 7, 8, 9, 13, 15, 16, 18, 20, 21, 24, 26, 27, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 52, 53], "set_config": [33, 36], "set_index": [14, 15, 19, 20, 24, 28, 29, 33, 34, 35], "set_opt": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 40, 41, 51, 52, 53], "set_properti": [12, 17, 26], "set_se": 24, "set_titl": [15, 20, 24, 29, 32, 34, 43, 52], "set_xlabel": [15, 20, 24, 29, 32, 39, 52], "set_ylabel": [15, 20, 24, 29, 32, 39, 52], "setup": [3, 7, 10, 12, 17, 51], "sev": [35, 37, 46], "sever": [10, 16, 21, 30, 32, 39, 40, 42, 43, 44, 49, 54], "sex": [34, 36, 37, 38], "sexual": 54, "sfu": 42, "shall": [0, 42], "shallow": 36, "shan": 42, "shap": 47, "shape": [13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52], "shape_df": [14, 19, 28], "shape_dict": [14, 19, 28], "share": [0, 25, 38, 47, 54], "sharealik": 1, "sharex": [16, 21, 30], "she": [12, 17, 26, 41, 42, 48], "shed": [35, 37, 46], "sheet": [9, 47, 50], "shelf": [36, 42], "shell": [5, 9, 12, 17], "shelv": 48, "shift": 44, "shipyard": 25, "shit": 48, "shng": [35, 46], "shop": 41, "short": [1, 10, 14, 28, 33, 36, 42, 54], "shorter": 45, "shorthand": [16, 21, 30], "shortli": 47, "shot": 38, "should": [5, 7, 8, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 37, 38, 39, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54], "shouldn": [34, 36, 42, 52], "show": [4, 7, 10, 12, 14, 16, 17, 19, 21, 23, 24, 25, 26, 28, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 45, 47, 48, 50, 52], "show_nearest_neighbor": 24, "show_plot": 45, "showcas": 42, "shown": [7, 10, 12, 13, 15, 17, 18, 20, 26, 27, 29, 34, 36, 39, 40, 44, 46], "shrink": [33, 38, 46], "shuffl": [14, 19, 24, 28, 43, 44], "si": [12, 17, 26], "sibl": 38, "sick": [39, 48], "sid": 48, "side": [6, 43, 46], "sift": 41, "sigma": 43, "sign": [4, 35, 37, 43, 52, 54], "signal": [14, 19, 28, 42], "signific": [11, 16, 21, 25, 30, 43, 46], "significantli": [31, 34, 41], "sigoptsearchcv": 33, "silhouett": 40, "silhouettevisu": [39, 40], "sim": 37, "sim_word": 42, "simard": 37, "similar": [1, 10, 13, 14, 17, 18, 19, 24, 27, 28, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 46, 49], "similarity_": 42, "similarli": [37, 39, 45], "simon_fras": 42, "simp": 44, "simpl": [1, 13, 15, 16, 18, 20, 21, 27, 29, 30, 34, 35, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 50, 51], "simplefilt": [36, 37], "simpleimput": [16, 21, 30, 31, 32, 33, 34, 35, 36, 37, 38, 44, 45, 46, 50, 53], "simpleimputersimpleimput": [16, 21, 30, 31, 35, 36, 38, 46], "simpler": [23, 32, 33, 47, 52], "simplest": 31, "simpli": [16, 21, 30, 38, 39, 42], "simplic": [13, 18, 27, 31, 41], "simplist": [15, 20, 24, 29, 37, 52], "simul": 38, "sin": 8, "sinc": [5, 12, 17, 24, 32, 35, 37, 38, 39, 41, 43, 44, 45, 46, 49, 50, 51], "singer_songwriter_bob_dylan": 42, "singl": [8, 15, 16, 20, 21, 24, 29, 30, 32, 33, 34, 36, 37, 40, 44, 45, 50, 51, 52], "sit": 54, "sitarist_ravi_shankar": 42, "site": [5, 12, 18, 24, 25, 27, 28, 31, 33, 37, 45, 49, 54], "situat": [6, 12, 17, 26, 34, 36, 39, 43, 45, 54], "six": [14, 28, 36, 44, 47], "size": [12, 13, 14, 15, 17, 18, 19, 20, 24, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52, 54], "skeleton": 46, "skeptic": 46, "skew": 35, "skill": [11, 36, 47], "skin": 48, "skip_check_arrai": 25, "skip_parameter_valid": 25, "skipna": 45, "sklearn": [1, 12, 14, 15, 17, 19, 20, 23, 24, 26, 28, 29, 32, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "sklearn_gb": 36, "sklearn_histgb": 36, "sktime": 44, "skyblu": 44, "skyscrap": 44, "sl": 42, "slice": 8, "slide": [1, 9, 16, 21, 22, 30, 43, 54], "slightli": [24, 25, 31, 32, 34, 36, 45], "slipper": 46, "slope": 32, "sloppi": [16, 21, 30], "slot": 54, "slow": [15, 20, 29, 36, 38, 43], "slower": [36, 39], "sm": [12, 17, 26, 31], "smac": 33, "small": [10, 14, 15, 19, 20, 24, 25, 28, 29, 31, 33, 35, 36, 37, 38, 39, 41, 43, 45, 50, 52], "small_citi": [15, 20, 29], "small_train_df": [15, 20, 29], "smallalpha_coeff": 35, "smaller": [15, 16, 20, 21, 23, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 52], "smallest": [32, 35, 39, 40], "smart": [39, 46, 48], "smile": 48, "smooth": [15, 20, 29, 52], "smoothli": 10, "smote_pip": 34, "sms_df": [12, 17, 26], "sn": [37, 39, 40], "snake": [32, 43], "snake_length": 32, "snakes_df": 32, "snbf": 36, "snippet": [7, 12, 17], "snow": [12, 17, 26, 43], "snp": 38, "so": [0, 1, 4, 5, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54], "social": [39, 40, 41, 44], "societ": 11, "societi": [34, 42], "sofist": 52, "soft": [25, 32, 36], "softmax": 50, "softwar": [1, 5, 10, 45], "solar": 41, "sold": [8, 35], "sole": [34, 40], "solidifi": 50, "solut": [12, 14, 17, 18, 19, 26, 27, 28, 36, 39, 45, 46, 47, 50, 54], "solv": [4, 12, 13, 15, 17, 18, 19, 20, 26, 27, 29, 38, 42, 46, 47, 52, 54], "solver": 34, "some": [4, 6, 7, 8, 10, 12, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54], "someon": [12, 13, 14, 17, 18, 19, 26, 27, 28, 38, 45, 46], "someth": [4, 7, 10, 13, 18, 27, 31, 34, 35, 36, 37, 39, 44, 45, 46, 47, 50, 54], "sometim": [6, 13, 14, 18, 19, 27, 28, 31, 32, 33, 36, 37, 42, 46, 47], "somewhat": 35, "somewher": [12, 17, 26, 35], "song": [15, 16, 21, 29, 30, 41, 48], "song_titl": [15, 16, 21, 29, 30, 33], "soon": [12, 15, 16, 17, 20, 21, 26, 29, 30, 44, 47], "sopha": [12, 17, 26], "sophist": [33, 37, 42], "sort": [1, 5, 13, 14, 16, 19, 21, 27, 28, 30, 37, 41, 42, 43, 44, 47], "sort_index": [8, 33, 35, 44], "sort_valu": [16, 21, 23, 30, 31, 32, 33, 35, 36, 37, 38, 44, 45, 48], "sound": [37, 38], "soundtrack": 42, "sourc": [10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 25, 26, 27, 28, 29, 30, 31, 33, 36, 37, 38, 39, 40, 41, 42, 43, 48, 51, 54], "south": 31, "space": [15, 18, 20, 29, 32, 33, 38, 39, 40, 42, 48, 54], "spaci": 38, "spacymoji": 48, "spam": [14, 19, 28, 34, 39], "spam_predict": [12, 17, 26], "span": [42, 44], "spanish": [16, 21, 30], "spars": [12, 15, 17, 20, 25, 29, 32, 36, 41, 42, 50], "sparse_output": [16, 21, 25, 30, 31, 34, 35, 36, 37, 44, 45, 46, 50], "spatial": 32, "speak": [5, 47], "spearmint": 33, "speci": [15, 20, 24, 29, 50, 52], "special": [11, 12, 17, 26, 31, 41, 42, 43, 44, 45, 52], "specialti": [34, 36, 37], "specif": [8, 11, 13, 14, 18, 19, 25, 27, 28, 33, 34, 37, 39, 41, 42, 43, 44, 45, 46, 47, 50, 52], "specifi": [8, 13, 14, 18, 19, 24, 27, 28, 31, 33, 34, 39, 40, 43, 46, 47], "spectrogram": 38, "speech": [38, 42, 48], "speechi": [15, 16, 21, 29, 30, 33], "speed": [8, 13, 18, 27, 36, 43, 47], "spell": [12, 17, 26], "spend": [12, 16, 17, 21, 25, 26, 30, 38, 46, 48, 54], "spent": [6, 16, 21, 30, 38], "spheric": [40, 50], "spici": 39, "spini": 43, "spit": 43, "split": [11, 13, 15, 18, 20, 27, 29, 31, 32, 33, 35, 36, 38, 41, 42, 45, 47, 48, 50], "split0_test_r2": 35, "split0_test_scor": 33, "split0_train_neg_mean_squared_error": 35, "split0_train_scor": 33, "split1_test_r2": 35, "split1_test_scor": 33, "split1_train_neg_mean_squared_error": 35, "split1_train_scor": 33, "split2_test_r2": 35, "split2_test_scor": 33, "split2_train_neg_mean_squared_error": 35, "split2_train_scor": 33, "split3_test_r2": 35, "split3_test_scor": 33, "split3_train_neg_mean_squared_error": 35, "split3_train_scor": 33, "split4_test_scor": 33, "split4_train_neg_mean_squared_error": 35, "split4_train_scor": 33, "spoken": 31, "sport": [42, 43, 44], "spot": [34, 35, 47, 52], "spotifi": [15, 29, 41], "spotify_df": [15, 16, 21, 29, 30, 33], "spotlight": [5, 10], "spous": [34, 36, 37], "spread": 40, "spring_month": 44, "sqft": 37, "sqft_abov": [12, 13, 17, 23, 26, 27], "sqft_basement": [12, 13, 17, 23, 26, 27], "sqft_live": [12, 13, 17, 23, 26, 27], "sqft_living15": [12, 13, 17, 23, 26, 27], "sqft_lot": [12, 13, 17, 23, 26, 27], "sqft_lot15": [12, 13, 17, 23, 26, 27], "sqrt": [15, 20, 29, 35, 37, 41, 42], "squar": [8, 11, 13, 15, 18, 20, 27, 29, 32, 37, 41, 45, 46, 48, 50], "squash": [32, 43], "squeez": [8, 45], "src": [19, 28, 34], "sse": 44, "ssw": 44, "st": [44, 48], "stabil": 10, "stabl": [14, 19, 25, 28, 34, 36, 52], "stack": [7, 11, 25, 47, 50], "stacking_model": 36, "stacking_model_tre": 36, "stackingclassifi": 36, "stackingregressor": 36, "staff": 6, "stai": [12, 17, 34, 45], "stakehold": [11, 46, 47], "stale": 39, "stand": [15, 20, 29, 33, 42, 47], "standard": [4, 6, 14, 16, 19, 21, 28, 30, 33, 36, 37, 38, 42, 47], "standardscal": [25, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 48, 50, 53], "standardscalerstandardscal": [16, 21, 30, 31, 33, 34, 35, 36, 38, 43, 46, 48], "stanford": 42, "star": [15, 20, 29, 39, 41, 48], "start": [7, 8, 10, 13, 14, 15, 18, 19, 20, 24, 25, 27, 28, 29, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53], "startswith": 37, "starttim": 44, "stat": [33, 45], "state": [6, 8, 14, 19, 28, 34, 36, 37, 41, 42, 47, 48], "statement": [7, 14, 15, 16, 18, 19, 20, 21, 28, 29, 30, 31, 32, 33, 34, 35, 38, 43, 45, 46], "static": [12, 17, 47], "station": 44, "statist": [1, 9, 11, 13, 18, 27, 32, 37, 41, 42, 45], "statistician": [15, 20, 29], "statlib": 32, "statsmodel": [44, 45], "statu": [34, 36, 37], "status_marri": 37, "status_nev": 37, "std": [14, 15, 16, 19, 20, 21, 23, 24, 25, 28, 29, 30, 34, 35, 43, 44, 48, 49], "std_cv_error": [14, 19, 28], "std_cv_score": [15, 20, 24, 29], "std_fit_tim": [33, 35], "std_score": [14, 16, 19, 21, 28, 30, 48], "std_score_tim": [33, 35], "std_test_neg_mean_squared_error": 35, "std_test_scor": [14, 19, 28, 33], "std_train_error": [14, 19, 28], "std_train_neg_mean_squared_error": 35, "std_train_scor": [14, 15, 19, 20, 24, 28, 29, 33], "stdki": 45, "stem": 42, "step": [7, 12, 14, 15, 16, 19, 20, 21, 24, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54], "stereotyp": 42, "stick": [13, 44], "still": [4, 10, 18, 33, 34, 35, 36, 38, 39, 44, 45, 48, 52, 53], "stipul": 46, "stochast": [38, 39], "stock": [12, 17, 26, 44], "stop": [8, 23, 25, 39, 42, 43, 45, 52], "stop_word": [33, 34, 42, 47, 48], "stopword": 42, "storag": [15, 29], "store": [7, 8, 15, 16, 20, 21, 29, 30, 31, 33, 34, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48], "stori": [35, 36, 48], "storylin": 42, "str": [24, 33, 37, 42, 44, 45, 48], "straight": [45, 47], "straightforward": 37, "strain": 7, "strang": [37, 45], "strata": 45, "strategi": [13, 15, 16, 18, 20, 21, 25, 27, 29, 30, 31, 34, 35, 37, 39, 41, 44, 45, 46, 47, 50, 51], "stratif": 45, "stratifi": 45, "stratifiedkfold": [14, 19, 28, 34], "stream": 45, "streamingmovi": 45, "streamingmovies_no": 45, "streamingmovies_y": 45, "streamingtv": 45, "streamingtv_no": 45, "streamingtv_y": 45, "street": [35, 37, 46], "street_grvl": 35, "street_pav": 35, "strength": [42, 50], "stress": 39, "strftime": [44, 45], "string": [8, 10, 15, 20, 25, 29, 34, 35, 36, 37, 42, 44, 45, 52], "strip": [37, 43], "strong": [36, 45, 50], "stronger": 36, "strongli": 36, "structur": [8, 39, 42, 43], "struggl": [39, 44], "stuart": [1, 36], "stuck": [4, 8], "student": [1, 4, 5, 6, 7, 11, 12, 13, 17, 18, 26, 27, 32, 34, 35, 37, 38, 39, 40, 41, 43, 47, 48, 54], "studi": [12, 17, 26, 31, 38, 42, 45], "stuff": [15, 20, 24, 29, 43, 45], "stump": [13, 14, 15, 18, 19, 20, 23, 27, 28, 29, 36, 51], "stupid": 48, "style": [26, 35, 38, 39, 41, 42, 43, 47, 48], "sub": [33, 39, 42, 45, 47, 50], "subdirectori": [37, 47], "subgroup": 45, "subject": [0, 1, 45, 54], "sublicens": 0, "submiss": [3, 54], "submit": [1, 8, 16, 17, 47, 54], "subplot": [14, 15, 19, 20, 24, 28, 29, 32, 34, 39, 43, 45, 46, 52], "subplot_kw": [14, 19, 24, 28], "subprocess": 35, "subscrib": 45, "subscript": [44, 45], "subset": [13, 14, 18, 19, 24, 27, 28, 33, 36, 43, 44, 49, 52], "substanti": 0, "substitut": 0, "subtl": 42, "subtleti": [14, 19, 28, 35], "subtract": [15, 17, 20, 29, 34, 37], "suburb": 48, "subword": 42, "succe": [38, 54], "success": [5, 8, 10, 12, 17, 26, 34, 36, 41, 42, 43, 44, 47], "successfulli": [10, 12, 17, 26, 48], "sudo": 5, "suei": 33, "suffer": 33, "suffici": [7, 42], "suggest": [0, 1, 13, 18, 27, 41, 45, 47], "suicid": 42, "suit": [21, 41], "suitabl": [10, 11, 12, 17, 23, 26, 39, 41, 47, 50], "sultan": 42, "sum": [8, 15, 16, 20, 21, 29, 30, 31, 32, 36, 37, 39, 43, 48], "sum_": [15, 20, 29, 35, 39, 42, 43], "sum_i": [37, 42], "sum_prob_ex1_class_0": 36, "sum_prob_ex1_class_1": 36, "summar": [1, 12, 17, 26, 32, 34, 35, 39, 42, 47], "summari": [0, 49, 50, 52], "summary_plot": 37, "summat": [36, 46], "summer": [41, 44], "summer_month": 44, "sun": [42, 44], "sundai": 44, "sundial": 43, "sunshin": 44, "sunstrum": [1, 54], "super": [31, 50], "superfici": [15, 20, 29], "superior": 11, "supermarket": 48, "supervis": [11, 16, 21, 25, 30, 31, 33, 34, 35, 38, 40, 42, 44, 45, 50, 54], "suppli": 54, "support": [10, 13, 16, 18, 21, 24, 25, 27, 30, 34, 36, 37, 38, 40, 42, 46, 48, 49, 52, 54], "support_": [15, 20, 29, 38], "suppos": [12, 13, 14, 15, 16, 17, 19, 20, 21, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 46, 50, 51], "suppress": 8, "suprem": 42, "supr\u00eam": 42, "sure": [4, 7, 8, 10, 13, 14, 15, 16, 20, 28, 29, 31, 34, 35, 36, 37, 40, 43, 44, 46, 47, 52, 54], "surfac": 18, "surgeri": 45, "surpris": [37, 41], "surprisingli": [31, 32], "surround": [4, 11, 46], "survei": [25, 39], "surviv": [1, 2, 11, 46, 47], "survival_function_": 45, "suscept": [40, 47], "suspect": 33, "svc": [15, 16, 20, 21, 24, 25, 29, 30, 31, 32, 33, 36, 37, 38, 43, 52, 53], "svc__c": 33, "svc__gamma": 33, "svc_pipe": 33, "svc_pred": 34, "svcsvc": [31, 33, 34], "svm": [1, 14, 16, 19, 21, 25, 28, 30, 31, 33, 36, 37, 38, 43, 44, 46, 47, 49, 50, 52, 53], "svm_estim": 34, "svr": [15, 20, 29, 31, 37, 46], "svr_c_pipe": 31, "svr_pipe": 31, "sw": 44, "swai": [12, 26], "swamp": [15, 20, 29], "swan": 43, "swcarpentri": 9, "sweep": 34, "sweet": 48, "switch": [13, 37, 39, 44, 45, 46], "swng": [1, 54], "sy": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 50, 51, 52, 53], "sydnei": 44, "syllabu": [3, 7, 12, 13, 15, 16, 17], "symbol": [18, 27], "symmetri": 38, "sync": 5, "synonym": 42, "synopsi": 42, "syntact": 42, "syntax": [4, 8, 12, 17, 26, 38, 45], "synthet": [38, 49], "system": [1, 2, 4, 5, 6, 10, 11, 12, 14, 15, 17, 19, 24, 26, 28, 29, 31, 34, 37, 39, 44, 46, 47], "systemat": [13, 18, 27, 31, 33, 37, 42], "t": [1, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52], "t2a": 54, "t2b": 54, "t2c": 54, "t2d": 54, "t2e": 54, "t2f": 54, "t2g": 54, "t2h": 54, "t2i": 54, "t2j": 54, "t2k": 54, "ta": [7, 12, 17, 26, 35, 37, 46, 47, 51, 52, 53], "tab": [12, 17], "tabbi": [12, 17, 26, 43], "tabl": [7, 25], "tabular": [8, 12, 17, 24, 26, 43, 44], "tackl": [14, 16, 19, 21, 28, 30, 34, 40, 52], "taco": 38, "tag": [4, 42, 48], "tail": [8, 44], "tailor": [11, 39, 46, 47], "take": [2, 4, 5, 6, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54], "taken": [44, 49, 54], "talk": [13, 14, 16, 18, 19, 21, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 54], "tall": 42, "target": [14, 15, 16, 19, 20, 21, 24, 25, 28, 29, 30, 32, 33, 34, 36, 37, 38, 41, 43, 44, 45, 46, 47, 50, 52, 53], "target_column": [36, 37, 45], "target_nam": 34, "target_names_toi": 34, "target_tag": 25, "tariff": 42, "task": [11, 16, 21, 23, 24, 30, 31, 32, 33, 37, 38, 39, 41, 43, 44, 45, 46, 47, 48, 50], "tast": [25, 39, 41], "tasti": 25, "taught": [31, 42, 54], "tax": 46, "tba": 1, "teach": [4, 12, 16, 17, 21, 26, 30, 42, 50], "team": [4, 8, 12, 17, 26, 36, 37, 42], "tech": [15, 29, 34, 37], "technic": [46, 47, 54], "techniqu": [1, 11, 12, 15, 20, 29, 33, 38, 41, 43, 45, 47, 49, 50], "technolog": 0, "technologi": 42, "techsupport": 45, "techsupport_no": 45, "techsupport_y": 45, "ted": 39, "tediou": 40, "telco": 45, "telecom": 45, "telephon": 42, "tell": [14, 15, 16, 19, 21, 28, 29, 30, 32, 34, 37, 38, 41, 42, 44, 45, 46, 47, 52], "temp3pm": 44, "temp9am": 44, "temperatur": [13, 18, 27], "templat": 47, "tempo": [15, 16, 21, 29, 30, 33], "tempor": [45, 50], "tend": [14, 15, 19, 20, 28, 29, 32, 36, 38, 41, 44, 45, 54], "tendenc": [14, 19, 28], "tensor": [24, 43], "tensorflow": [10, 37, 43], "tent": 12, "tenur": [45, 46, 50], "tenure_lm": 45, "tenure_predict": 45, "term": [0, 2, 13, 15, 18, 20, 27, 29, 31, 32, 34, 37, 38, 41, 42, 45, 46, 47, 50], "termin": [5, 10, 13, 27, 39, 47], "terminologi": [14, 28, 34, 50, 51], "terrac": 43, "terribl": [35, 41], "territori": 54, "tesoro": 33, "test": [1, 7, 8, 10, 12, 13, 15, 16, 17, 18, 20, 21, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 40, 45, 46, 47, 49, 50, 52, 54], "test_accuraci": 34, "test_average_precis": 34, "test_df": [12, 16, 17, 21, 26, 30, 31, 32, 34, 35, 36, 37, 38, 44, 45, 46, 47, 48, 53], "test_df_churn": 45, "test_df_nan": [34, 36, 37], "test_df_sort": 44, "test_df_surv": 45, "test_exampl": 36, "test_f1": 34, "test_format": [15, 20, 29], "test_g50k": 36, "test_idx": 24, "test_imag": [12, 17, 26, 43], "test_l50k": 36, "test_mape_scor": 35, "test_nam": 45, "test_neg_mean_squared_error": 35, "test_neg_root_mean_square_error": 35, "test_point": [15, 20, 29, 49], "test_precis": 34, "test_r2": 35, "test_recal": 34, "test_roc_auc": 34, "test_scor": [14, 15, 16, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 44, 45, 48, 52], "test_shap_valu": 37, "test_siz": [12, 15, 16, 17, 20, 21, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 43, 44, 46, 47, 48, 49, 52, 53], "test_sklearn": 35, "test_statist": 45, "test_x": 45, "testabl": 17, "text": [1, 7, 11, 12, 13, 17, 18, 21, 26, 27, 32, 33, 34, 35, 36, 37, 38, 41, 43, 46, 47, 50], "text_feat": 33, "text_featur": 48, "text_pp": 42, "textbook": [3, 9, 46], "textrm": [14, 19, 28], "textual": 11, "textur": 38, "tf": 31, "tfidfvector": 32, "th": [12, 17, 32, 41], "thai": 25, "than": [6, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 49, 51, 52, 54], "thank": [12, 17, 26, 42, 52], "thankfulli": 44, "thei": [1, 7, 8, 13, 14, 15, 17, 18, 19, 20, 25, 27, 28, 29, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54], "theirs": 42, "them": [1, 2, 4, 7, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 54], "theme": 42, "themselv": [39, 40, 42], "theoret": [16, 21, 30, 34, 36, 50], "theori": 37, "thepopbreak": 48, "therefor": [17, 52], "thermostat": [13, 18, 27], "thi": [0, 1, 2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 18, 19, 20, 24, 27, 28, 29, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54], "thick": [25, 39], "thing": [1, 5, 7, 8, 12, 13, 14, 15, 17, 18, 19, 20, 27, 28, 29, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 52], "think": [4, 12, 13, 14, 15, 17, 18, 19, 20, 25, 26, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 41, 43, 44, 45, 46, 47, 50, 51, 52], "third": 40, "thk": [12, 17, 26], "thorough": 10, "thoroughli": 50, "those": [5, 8, 10, 11, 12, 16, 17, 21, 30, 35, 36, 37, 41, 42, 45, 46, 47, 54], "though": [14, 18, 19, 25, 28, 31, 32, 39, 40, 41, 47, 48], "thought": [4, 15, 20, 29, 37, 45, 50], "thousand": [32, 40, 41], "thrasher": 42, "threahold": 38, "threaten": 48, "three": [8, 13, 16, 21, 24, 27, 30, 32, 34, 36, 37, 38, 39, 40, 42, 43, 44, 49, 50, 54], "thresh": 8, "threshold": [13, 18, 27, 32, 36, 38, 40, 42, 45], "thresholds_lr": 34, "thresholds_svc": 34, "through": [1, 7, 10, 12, 13, 17, 18, 27, 34, 35, 38, 40, 41, 42, 43, 46, 54], "throughout": [14, 19, 28, 46], "throught": [17, 54], "throw": [31, 43, 45, 46, 50], "thu": [1, 6, 12, 33, 44, 45, 54], "thumb": [13, 18, 27, 48], "thursdai": [12, 54], "ti": 31, "tianyu": [1, 54], "tick": 44, "tick_label": 37, "tick_param": 39, "tiffin": 42, "tiger": [12, 17, 26, 43], "tight": [15, 20, 24, 29, 40, 52], "tight_layout": [43, 46], "tightrop": [15, 20, 24, 29, 52], "tile": 37, "till": [15, 20, 29, 42, 45], "timber": 42, "time": [1, 2, 4, 8, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 51, 52, 54], "time_diff": 44, "time_signatur": [15, 16, 21, 29, 30, 33], "timedelta": 44, "timeit": [8, 49], "timelin": 46, "timeseri": [43, 44], "timeseriessplit": [44, 45, 50], "timestamp": 44, "timezon": [1, 45], "tinder": 41, "tini": [7, 14, 19, 28, 34, 40], "tip": 42, "tire": 48, "titan": 41, "titi": [12, 17, 26], "titl": [7, 14, 15, 19, 20, 23, 24, 28, 29, 32, 35, 38, 40, 43, 44, 45, 46, 52], "tldr": [12, 17], "tmp": 25, "tn": 34, "to_datetim": [23, 44], "to_html": [12, 13, 14, 17, 19, 26, 27, 28], "to_notebook_ifram": 35, "to_numpi": [15, 20, 29, 41, 44], "to_str": [12, 17, 26, 43], "toarrai": [31, 37, 44], "tobago": [36, 37], "todai": [13, 18, 27, 41, 43, 44, 45, 47, 50], "todens": [37, 38], "togeth": [5, 8, 12, 13, 15, 16, 17, 18, 20, 21, 25, 27, 29, 30, 31, 39, 42, 52], "toi": [8, 14, 15, 19, 20, 28, 29, 38, 39, 40, 41, 44, 50], "toilet": [43, 48], "token": [7, 17, 48, 54], "token_pattern": 31, "tol": [34, 38, 46], "told": [5, 54], "tolist": [12, 13, 14, 17, 18, 19, 23, 24, 25, 26, 27, 28, 31, 32, 34, 35, 36, 37, 38, 39, 41, 44, 45, 48], "tomasbeuzen": 8, "tomorrow": [13, 16, 18, 27, 44, 45, 50], "ton": 33, "tone": 48, "too": [6, 7, 14, 15, 19, 20, 21, 24, 28, 29, 31, 33, 35, 36, 37, 42, 44, 45, 46, 47, 52, 54], "took": 44, "tool": [1, 7, 8, 10, 11, 31, 32, 34, 35, 37, 40, 41, 43, 44, 45, 47, 50, 54], "toolbox": [15, 20, 29, 36, 42], "toolkit": 42, "top": [13, 18, 27, 31, 33, 34, 40, 44, 46, 47], "topi": 42, "topic": [1, 2, 8, 11, 13, 18, 27, 34, 35, 39, 41, 43, 47, 50, 54], "topic2vec": 42, "topics_per_chunk": 42, "topn": [12, 17, 26, 43], "torch": [24, 43], "torchvis": [12, 17, 24, 26, 43], "toronto": [42, 46, 48], "tort": 0, "total": [1, 8, 13, 16, 18, 21, 27, 30, 31, 34, 35, 36, 37, 38, 42, 44, 45, 46], "total_bedroom": [16, 21, 30, 31, 38, 53], "total_bilirubin": [12, 17, 26], "total_protien": [12, 17, 26], "total_room": [16, 21, 30, 31, 38, 53], "total_second": 44, "totalbsmtsf": [35, 37, 46], "totalcharg": 45, "totem": 43, "totensor": [24, 43], "toti": [0, 1, 42, 54], "totrmsabvgrd": [35, 37, 46], "touch": 47, "toward": [32, 37, 42, 54], "towardsdatasci": [43, 45], "town": 48, "townsvil": 44, "toy_clust": 42, "toy_clust_df": 39, "toy_df": [31, 42], "toy_lda_data": 42, "toy_movie_feat": 41, "toy_rat": 41, "toy_spam": 31, "toy_x": 42, "tp": 34, "tpot": 33, "tpr": 34, "tpr_lr": 34, "tpr_svc": 34, "tr_score": [23, 52], "traceback": [4, 8, 25, 31, 45], "track": [1, 31, 47, 54], "trade": [11, 32, 34, 38, 39, 50], "tradeoff": [15, 16, 20, 21, 23, 29, 30, 32, 35, 38, 39, 43], "tradit": [12, 17, 26, 41, 43, 45, 54], "tradition": 54, "trail": 8, "train": [7, 15, 16, 20, 21, 23, 24, 25, 29, 30, 33, 35, 36, 37, 38, 39, 41, 42, 45, 48, 49, 50, 51, 52, 53], "train_accuraci": 34, "train_dataload": 43, "train_df": [12, 16, 17, 21, 26, 30, 31, 32, 34, 35, 36, 37, 38, 44, 45, 46, 47, 48, 53], "train_df_churn": 45, "train_df_nan": [34, 36, 37], "train_df_ord": 44, "train_df_sort": 44, "train_df_surv": 45, "train_df_surv_not_churn": 45, "train_dir": 24, "train_f1": 34, "train_flatten": 43, "train_for_usr": 41, "train_load": 43, "train_mape_scor": 35, "train_mat": 41, "train_mat_imp": 41, "train_neg_mean_squared_error": 35, "train_neg_root_mean_square_error": 35, "train_precis": 34, "train_r2": 35, "train_recal": 34, "train_scor": [14, 15, 16, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 44, 45, 48, 52], "train_shap_valu": 37, "train_sklearn": 35, "train_test_split": [12, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 43, 44, 45, 46, 47, 48, 49, 52, 53], "train_x": 41, "transact": [13, 18, 27, 34, 44, 46], "transfer": [45, 47], "transfer_learning_tutori": 43, "transform": [0, 15, 20, 24, 25, 29, 33, 34, 36, 37, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53], "transformed_exampl": 36, "transformed_oh": [16, 21, 30], "transformedtargetregressor": [35, 38, 46, 50], "transformedtargetregressortransformedtargetregressor": 35, "translat": [1, 9, 12, 17, 26], "transpar": [34, 50], "transpos": [24, 38, 43], "trasform": [16, 21, 30], "trash": 51, "traumat": 54, "treat": [8, 16, 21, 28, 30, 31, 34, 35, 41, 44, 45, 46, 48, 50], "treati": 54, "treatment": 31, "tree": [1, 2, 14, 15, 16, 19, 20, 21, 24, 28, 29, 30, 31, 32, 33, 35, 38, 40, 43, 44, 45, 47, 49, 50, 51, 53], "tree1": 36, "tree2": 36, "tree3": 36, "tree_numeric_transform": 37, "treeexplain": 37, "trend": [11, 45, 50], "tri": [18, 36, 37, 46, 49], "trial": [33, 45], "triangl": [15, 20, 29, 39], "trick": [5, 35], "tricki": [31, 33, 37, 41], "trigger": [15, 20, 29], "trigram": 42, "trivial": 40, "troubl": 10, "true": [8, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 49, 52], "truli": [35, 42], "truncat": 40, "truncate_mod": 40, "truncation_mod": 40, "trust": [12, 16, 17, 21, 23, 24, 25, 26, 30, 31, 33, 34, 35, 36, 37, 38, 41, 43, 46, 48], "trustworthi": 40, "truth": [36, 38, 39, 40, 41, 44], "try": [1, 4, 5, 8, 10, 12, 13, 14, 15, 17, 18, 19, 20, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 50, 51, 52, 54], "tsa": 44, "tscv": 44, "tslearn": 44, "tsunami": [12, 26], "ttr": 35, "ttr_pipe": 35, "tue": [1, 12, 13, 44, 54], "tuesdai": [1, 12, 17, 38, 44, 54], "tuggeranong": 44, "tumor": 50, "tune": [14, 19, 23, 28, 33, 36, 40, 41, 43, 46, 47], "turn": [4, 14, 19, 24, 28, 42, 43, 45, 53, 54], "tusker": 43, "tutori": [1, 4, 5, 9, 10, 12, 17, 41, 43, 47, 50, 54], "tweak": [15, 20, 24, 29, 52], "tweet": [42, 48], "tweetat": 48, "twice": [8, 14, 28, 31, 32], "twinx": 46, "twist": 42, "twitter": 42, "twitter_allowed_char": 48, "two": [4, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 27, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 53, 54], "two_citi": [15, 20, 29], "two_song": [16, 21, 30], "two_songs_subset": [16, 21, 30], "tx": [32, 48], "tx_i": 46, "txt": [12, 17, 26, 43, 47], "typ": [35, 37, 46], "type": [4, 8, 10, 11, 13, 15, 16, 18, 21, 25, 27, 29, 30, 31, 33, 36, 38, 40, 41, 42, 43, 47, 50, 52, 53], "typeerror": 45, "typic": [2, 7, 12, 13, 15, 16, 17, 18, 20, 21, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 39, 41, 44, 46, 47], "u": [4, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 51, 52, 53], "u6": [13, 18, 27], "u_1": [15, 20, 29], "u_2": [15, 20, 29], "u_i": [15, 20, 29], "u_n": [15, 20, 29], "ubc": [0, 4, 5, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53, 54], "ubc_img": 43, "ubc_okanagan": 42, "ubco": 42, "ubyssei": 42, "ucsb": 9, "ud036": 9, "udac": 9, "ufunc": 35, "ufv": 42, "uint8": 24, "ultim": [4, 14, 19, 28, 46], "ultralyt": 43, "uluru": 44, "umbrella": 41, "un": [35, 45], "unabl": [12, 16, 17, 21, 23, 24, 25, 26, 30, 31, 33, 34, 35, 36, 37, 38, 40, 43, 45, 46, 48, 54], "unambigu": 42, "unassign": [39, 40], "unbias": 34, "unced": 54, "uncertain": 32, "uncertainti": [32, 34, 46, 47], "unchang": 37, "uncia": [12, 17, 26, 43], "uncomfort": 41, "uncorrel": 37, "under": [0, 1, 7, 13, 14, 19, 25, 27, 28, 35, 42, 43, 45, 47], "under_sampl": 34, "underestim": 45, "underfit": [15, 20, 23, 24, 29, 32, 33, 43, 52], "underli": [2, 37, 38, 39], "underneath": 7, "underpredict": 35, "undersample_pip": 34, "understand": [0, 1, 4, 7, 11, 12, 13, 14, 15, 17, 20, 23, 24, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 54], "understood": 34, "unemploi": 45, "unexpect": [31, 32, 33, 42], "unexplain": 35, "unf": [35, 37, 46], "unfinish": 35, "unfortun": [6, 33, 37, 39, 40], "uniform": [33, 34, 40], "unimport": [33, 37], "uninstal": 10, "uninterpret": 37, "unintuit": 8, "union": 8, "uniqu": [16, 21, 30, 31, 34, 35, 36, 37, 41, 42, 44, 45], "unit": [25, 32, 34, 35, 36, 37, 42, 43, 45, 48], "unitless": 35, "univers": [1, 9, 42], "university_year": [31, 50], "unix": [5, 44], "unknown": [6, 42, 50], "unlabel": [12, 14, 17, 19, 26, 28, 40], "unless": [7, 17, 54], "unlik": [8, 12, 14, 15, 17, 19, 20, 28, 29, 31, 35, 37, 39, 40], "unlimit": 44, "unlucki": [14, 19, 28], "unmarri": [36, 37], "unnam": [12, 17, 26], "uno": 25, "unoffici": 54, "unqualifi": 34, "unreason": [6, 17, 35], "unrecogniz": [12, 17], "unreli": [14, 19, 28], "unrespond": [12, 17], "unscal": [16, 21, 30], "unseen": [13, 27, 38, 39, 43, 47, 52], "unsqueez": 43, "unstructur": 42, "unsupervis": [12, 17, 26, 41, 42, 43, 47, 54], "unsur": [7, 46], "until": [4, 13, 14, 18, 19, 27, 28, 33, 38, 39, 40, 42, 45, 46, 47], "unus": 52, "unusu": 25, "unwieldi": [13, 16, 18, 21, 27, 30], "unzip": [37, 48], "uoft": 42, "up": [7, 8, 13, 16, 18, 21, 23, 25, 26, 27, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 50, 51, 54], "uparrow": 40, "upcom": 39, "updat": [10, 15, 16, 20, 21, 24, 29, 30, 31, 36, 39, 52], "update_cent": 39, "update_plot": [15, 20, 24, 29, 52], "update_z": 39, "upei": 42, "upgrad": 42, "upload": 7, "upon": [0, 13, 14, 18, 19, 27, 28, 31, 34, 36, 37, 38, 39, 40, 42], "upper": [34, 45], "upperbound_pric": 25, "uppercas": 48, "upto": 44, "ur": [12, 17, 26], "urgent": [31, 42], "url": [4, 14, 19, 28, 34, 45, 47], "us": [0, 1, 2, 4, 5, 10, 11, 23, 25, 32, 33, 37, 40, 41, 44, 45, 47, 48, 50, 52, 53], "usa": [8, 14, 15, 19, 20, 28, 29, 32, 42], "usabl": 47, "usag": [16, 21, 30, 31, 34, 35, 38, 42, 44, 45], "usec_": 45, "useless": [33, 37, 38], "user": [10, 12, 16, 17, 18, 21, 24, 26, 27, 28, 30, 31, 33, 36, 37, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50], "user_id": 41, "user_inverse_mapp": 41, "user_kei": 41, "user_mapp": 41, "user_nam": 41, "usernam": 48, "userwarn": [18, 24, 27, 28, 31, 36, 37], "usf": 31, "using_copy_on_writ": [25, 45], "using_cow": 45, "usual": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 54], "utc": [44, 45], "utcnow": 45, "util": [5, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 43, 45, 46, 50, 51, 52, 53], "utilities_allpub": 35, "utilities_nosewa": 35, "utility_mat": 41, "uvic": 42, "v": [1, 3, 7, 23, 24, 31, 32, 40, 42, 44, 45, 46, 50], "v1": [12, 17, 26, 34], "v10": 34, "v11": 34, "v12": 34, "v13": 34, "v14": 34, "v15": 34, "v16": 34, "v17": 34, "v18": 34, "v19": 34, "v2": [12, 17, 26, 34], "v20": 34, "v21": 34, "v22": 34, "v23": 34, "v24": 34, "v25": 34, "v26": 34, "v27": 34, "v28": 34, "v3": 34, "v4": 34, "v5": 34, "v6": 34, "v7": 34, "v8": 34, "v9": 34, "v_1": [15, 20, 29], "v_2": [15, 20, 29], "v_i": [15, 20, 29], "v_n": [15, 20, 29], "vacat": 32, "vaccin": [46, 48], "vada_pav": 42, "vader": 48, "vader_lexicon": 48, "vader_senti": 48, "vain": 33, "val": [41, 45], "valenc": [15, 16, 21, 29, 30, 33, 48], "valid": [1, 15, 18, 20, 24, 25, 27, 29, 31, 35, 36, 37, 38, 39, 41, 43, 45, 46, 47, 48, 50, 53], "valid_dataload": 43, "valid_dir": 24, "valid_flatten": 43, "valid_load": 43, "valid_mat": 41, "valid_sample_df": 36, "valid_sample_i": 36, "valid_sample_x": 36, "valid_scor": [23, 52], "valid_x": 41, "validate_data": 25, "validate_separ": 25, "valu": [7, 8, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "valuabl": [11, 38, 40, 54], "value_count": [13, 18, 23, 25, 27, 31, 34, 36, 37, 44, 45, 47, 48], "value_throttl": [15, 20, 24, 29, 52], "valueerror": [8, 16, 21, 25, 30, 31, 45], "values_format": 34, "vancouv": [42, 46], "vancouver_canuck": 42, "vanilla": 32, "var": [21, 28, 30, 37, 48], "var_": 37, "varada": [0, 1, 18], "vari": [11, 13, 18, 27, 33, 36, 40, 45, 52], "variabl": [7, 8, 13, 16, 18, 21, 23, 27, 30, 31, 32, 33, 35, 37, 38, 44, 45, 46, 52], "varianc": [35, 37, 40, 44, 52], "variant": [37, 40], "variat": [14, 19, 28, 32, 34, 35, 38], "varieti": [12, 17, 26, 36, 42], "variou": [11, 12, 15, 17, 20, 24, 26, 29, 35, 37, 43, 44, 45, 46, 47, 50, 52], "vault": [14, 19, 28], "ve": [7, 8, 12, 14, 15, 17, 19, 20, 23, 24, 26, 28, 29, 34, 35, 37, 41, 42, 43, 44, 46, 47, 49], "vec": [31, 42, 43], "vec1": 42, "vec1_i": 42, "vec2": 42, "vec2_i": 42, "vec8": 31, "vec8_binari": 31, "vec_binari": 31, "vecom": 33, "vector": [13, 18, 21, 24, 27, 32, 34, 41, 43, 46, 52], "verb": [42, 48], "verbos": [12, 17, 26, 34, 36, 37, 46], "veri": [2, 4, 5, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 54], "versa": [35, 52], "version": [1, 4, 5, 7, 8, 10, 12, 18, 21, 25, 28, 30, 32, 33, 35, 37, 40, 42, 44, 45, 48, 49], "versu": 9, "vert": 37, "vertic": [13, 18, 27, 34, 44], "vgg": 43, "vgg16": [24, 43], "vgg16_weight": 43, "via": [4, 7, 10, 12, 17, 34, 38, 54], "vibe": 25, "vice": [35, 52], "video": [1, 7, 8, 9, 10, 23, 41, 43, 45, 46, 47, 52, 54], "vietnames": [16, 21, 30], "view": [6, 7, 10, 12, 13, 17, 23, 26, 27, 37, 40, 43, 44, 45, 46], "viewpoint": 41, "vif": 37, "vikski": 42, "violat": [16, 21, 30, 31, 45, 47, 54], "virginia": 43, "viridi": 33, "vision": [1, 47, 49], "visit": [8, 54], "visual": [1, 11, 13, 14, 15, 18, 19, 20, 23, 27, 28, 29, 31, 32, 34, 35, 36, 37, 39, 40, 43, 44, 45, 48, 50, 53], "viu": 42, "viz": 46, "voc": [34, 36, 37], "vocab": 42, "vocabulari": [31, 32, 42], "vocabulary_": 31, "voic": [12, 17, 26], "volcano": [12, 26], "volum": 47, "vote": [15, 16, 20, 21, 29, 30, 36, 49], "voting_ndt": 36, "votingclassifi": 36, "votingclassifierinot": 36, "votingregressor": 36, "vyfj": [26, 27, 31, 32, 33, 34, 35, 36], "w": [10, 31, 32, 35, 39, 42, 44, 46, 47], "w_0": 32, "w_1": 32, "w_1x_1": 32, "w_2x_2": 32, "w_3x_3": 32, "w_4x_4": 32, "w_d": 32, "w_dx_d": 32, "w_j": 32, "wa": [4, 5, 10, 14, 16, 17, 18, 19, 21, 24, 25, 27, 28, 30, 32, 34, 36, 37, 41, 42, 43, 45, 46, 48, 49, 51, 52, 54], "wa_fn": 45, "wai": [0, 2, 6, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 52, 54], "wait": [4, 12, 15, 17, 18, 20, 26, 27, 29, 31, 45, 47, 54], "waitlist": [13, 54], "walk": [15, 20, 24, 29, 34, 47, 52], "walker": [12, 17, 26, 43], "wallabi": 43, "wang": [1, 54], "want": [4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 53, 54], "war": 41, "ward": 40, "warm": [16, 21, 30], "warm_start": [34, 46], "warn": [6, 12, 15, 17, 19, 20, 24, 28, 29, 31, 35, 36, 37, 45, 49], "warranti": 0, "washington": 48, "washroom": 54, "wasn": 42, "wast": [4, 31, 46], "watch": [1, 10, 12, 15, 17, 29, 32, 41, 42, 50], "watchfil": 24, "water": 46, "waterfal": 37, "waterfront": [12, 13, 17, 23, 26, 27], "wavelet": 38, "wb": 47, "wd": [35, 37, 46], "we": [1, 4, 5, 6, 7, 10, 12, 13, 15, 17, 18, 20, 24, 25, 26, 27, 29, 40, 42, 43, 44, 48, 49, 50, 51, 52, 53, 54], "weak": 50, "weather": [13, 18, 27, 44, 47], "weatherau": 44, "web": [5, 12, 17, 42, 50], "web_api": 47, "web_appl": 47, "weblog": 42, "websit": [4, 10], "wed": 44, "wednesdai": [44, 54], "week": [1, 6, 14, 15, 16, 17, 20, 21, 28, 29, 30, 31, 34, 35, 36, 37, 41, 42, 44, 46, 54], "weekdai": 44, "weekend": [8, 44, 46], "weekli": [12, 48], "weight": [15, 17, 20, 24, 29, 36, 38, 41, 42, 43, 54], "weighted_averag": 34, "weinberg": 37, "weird": 35, "welcom": [51, 54], "well": [4, 5, 13, 14, 15, 16, 18, 19, 20, 21, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 47, 50, 54], "wellyanto": [1, 54], "welsh": [12, 17, 26, 43], "went": [35, 48], "were": [0, 6, 12, 17, 25, 31, 32, 34, 35, 42, 43, 44, 45, 46, 54], "weren": 42, "what": [7, 8, 9, 13, 15, 18, 20, 23, 24, 25, 27, 29, 33, 40, 43, 44, 48, 49, 50, 51, 52, 53, 54], "whatev": 38, "when": [4, 6, 7, 10, 12, 13, 14, 15, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53, 54], "wher": 48, "where": [0, 1, 7, 10, 13, 14, 15, 18, 19, 20, 21, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 46, 47, 50, 52], "wherea": [2, 13, 18, 25, 27, 32, 33, 35, 37, 40, 46], "whether": [0, 4, 7, 8, 13, 14, 16, 18, 19, 21, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 40, 42, 44, 45, 47, 48, 51, 54], "which": [4, 6, 8, 10, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 33, 35, 37, 38, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "whichev": 36, "while": [14, 18, 19, 21, 27, 28, 32, 33, 34, 36, 37, 39, 41, 42, 45, 48], "white": [34, 36, 37, 40, 42], "whitespac": [42, 45], "who": [4, 5, 6, 12, 17, 26, 34, 37, 39, 40, 42, 44, 45, 46, 47, 48, 50, 54], "whole": [14, 19, 28, 33, 35, 37, 41, 47], "whom": [0, 42, 48], "whose": 4, "why": [8, 14, 15, 18, 20, 23, 25, 28, 29, 34, 35, 36, 39, 40, 42, 44, 45, 50, 51, 52, 53], "wid": [34, 47], "wide": [10, 32, 33, 36, 38, 41, 43, 46], "wider": [15, 20, 24, 29, 52], "widespread": 42, "widget": [15, 20, 24, 29, 34, 39, 40, 52], "width": [13, 14, 15, 18, 19, 20, 24, 27, 28, 29, 34, 42, 51, 52], "wife": [12, 26, 34, 36, 37], "wiki": [42, 46], "wiki_df": 42, "wiki_dict": 42, "wikipedia": [42, 43, 46], "wikipedia2vec": 42, "wild": [12, 14, 17, 19, 24, 26, 28, 43], "willing": 34, "win": [15, 20, 29, 31, 36, 37, 38, 41, 49], "wind": [13, 18, 27], "winddir3pm": 44, "winddir3pm_miss": 44, "winddir3pm_ss": 44, "winddir3pm_ssw": 44, "winddir3pm_sw": 44, "winddir3pm_w": 44, "winddir3pm_wnw": 44, "winddir3pm_wsw": 44, "winddir9am": 44, "windgustdir": 44, "windgustspe": 44, "window": 45, "windsor": 48, "windspeed3pm": 44, "windspeed9am": 44, "wine_1": 8, "winter": 44, "winter_month": 44, "wire": 41, "wisdom": 36, "wish": [12, 13, 17, 18, 26, 27, 39, 46, 54], "within": [13, 16, 18, 21, 24, 27, 30, 32, 36, 38, 39, 40, 45, 47, 50], "without": [0, 7, 12, 13, 17, 18, 26, 27, 34, 36, 37, 38, 41, 43, 44, 45, 46, 47, 54], "wnw": 44, "wolv": 40, "woman": 42, "wombat": 43, "won": [5, 10, 12, 13, 14, 15, 17, 18, 19, 20, 27, 28, 29, 31, 32, 38, 41, 42, 43, 44, 45, 47, 48], "wonder": [12, 14, 17, 26, 28], "wooddecksf": [35, 37, 46], "word": [11, 12, 17, 23, 25, 26, 32, 33, 34, 38, 39, 40, 41, 43, 44, 45, 46, 50, 54], "word1": 42, "word2": 42, "word2vec": [11, 42, 43], "word3": 42, "word_pair": 42, "word_token": [42, 48], "wordnet": 42, "wordnetlemmat": 42, "work": [0, 4, 5, 7, 8, 10, 12, 15, 16, 17, 20, 21, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 47, 48, 50, 54], "workclass": [34, 36, 37], "workclass_feder": [36, 37], "workclass_loc": [36, 37], "workclass_miss": 37, "workclass_nev": [36, 37], "workclass_priv": [36, 37], "workclass_self": 37, "workclass_st": 37, "workclass_without": 37, "workflow": [13, 18, 27, 47, 54], "worksheet": 47, "world": [15, 16, 19, 20, 21, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 50], "worm": 43, "worri": [12, 17, 26, 39, 40, 41], "wors": [13, 18, 27, 33, 35, 36, 45, 51], "worst": [34, 38, 39], "worth": [13, 15, 18, 20, 27, 29, 34, 35], "worthi": 32, "would": [4, 12, 13, 15, 16, 17, 18, 20, 21, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 52, 53, 54], "wouldn": [31, 33, 42, 45], "wow": 37, "wrangl": 25, "wrap": 31, "wrapper": [25, 38], "write": [4, 7, 11, 12, 17, 26, 33, 37, 38, 39, 42, 46, 47, 48, 52, 54], "written": [7, 31, 37, 44, 46], "wrong": [10, 14, 19, 25, 28, 32, 35, 38, 39, 45, 46], "wrote": [42, 44], "wsw": 44, "wtf": 47, "www": [9, 32], "x": [4, 8, 10, 14, 15, 16, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52], "x0": 38, "x0_male": 34, "x1": [38, 41], "x1x2": 38, "x2": [38, 40, 41], "x27": [16, 21, 30, 31, 33, 34, 35, 36, 38, 43, 46, 48], "x_": 32, "x_1": [32, 38, 39], "x_1x_2": 38, "x_2": [32, 38, 39], "x_anim_train": 24, "x_anim_valid": 24, "x_binari": [13, 18, 27], "x_citi": [15, 20, 29], "x_count": 31, "x_d": 32, "x_femal": 34, "x_hour": 44, "x_hour_week": 44, "x_hour_week_onehot": 44, "x_hour_week_onehot_poli": 44, "x_hour_week_onehot_poly_lag": 44, "x_i": [32, 41], "x_imp_ohe_train": [16, 21, 30], "x_init": 39, "x_int": 31, "x_label": [13, 14, 15, 18, 19, 20, 27, 28, 29, 51], "x_lag_featur": 44, "x_lag_features_imp": 44, "x_male": 34, "x_mask": 31, "x_multi": 49, "x_n": 38, "x_orig": 40, "x_re": 34, "x_small_citi": [15, 20, 29], "x_spotifi": [15, 29, 33], "x_subset": [13, 14, 18, 19, 27, 28], "x_test": [12, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 43, 44, 45, 46, 48, 49, 52, 53], "x_test_big": 33, "x_test_cat": 25, "x_test_cat_oh": 25, "x_test_enc": [37, 44, 45, 46], "x_test_happi": [34, 47], "x_test_imp": [16, 21, 30], "x_test_multi": 49, "x_test_num": 25, "x_test_num_imp": 25, "x_test_num_imp_sc": 25, "x_test_pr": 44, "x_test_predict": [16, 21, 30], "x_test_scal": [16, 21, 30], "x_test_transform": [16, 21, 30], "x_toi": [15, 16, 20, 21, 29, 30, 31, 44], "x_toy_oh": [16, 21, 30], "x_toy_ord": [16, 21, 30, 31], "x_tr": [23, 52], "x_train": [12, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 43, 44, 45, 46, 48, 49, 52, 53], "x_train_big": 34, "x_train_cat": 25, "x_train_cat_oh": 25, "x_train_enc": [34, 35, 37, 44, 45, 46], "x_train_happi": [34, 47], "x_train_hous": 38, "x_train_imp": [16, 21, 30], "x_train_imp_sc": [16, 21, 30], "x_train_multi": 49, "x_train_num": 25, "x_train_num_imp": 25, "x_train_num_imp_sc": 25, "x_train_oversampl": 34, "x_train_perm": 37, "x_train_pp": 31, "x_train_predict": [16, 21, 30], "x_train_scal": [16, 21, 30, 38], "x_train_subsampl": 34, "x_train_tini": 33, "x_train_transform": [16, 21, 30], "x_train_usr": 41, "x_transform": 31, "x_valid": [23, 24, 34, 41, 52], "x_vari": 40, "x_xor": 38, "xanni": 33, "xavier": [38, 41], "xcode": 5, "xgbclassifi": [36, 37], "xgbclassifierxgbclassifi": 36, "xgboost": 37, "xgbregressor": [12, 17, 26, 36], "xlabel": [8, 13, 14, 15, 18, 19, 20, 24, 27, 28, 29, 32, 33, 34, 35, 37, 40, 43, 44, 45, 46, 49, 51], "xlim": 45, "xor": [32, 38], "xp": 25, "xt": 31, "xtick": [14, 19, 24, 28, 34, 44], "xticklabel": 33, "xticks_rot": 34, "xwm\u0259\u03b8kw\u0259y": 54, "xx": [38, 39], "y": [8, 14, 15, 16, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52], "y_": 41, "y_citi": [15, 20, 29], "y_femal": 34, "y_hat": [32, 36], "y_i": [35, 36, 38, 41], "y_init": 39, "y_label": [13, 14, 15, 18, 19, 20, 27, 28, 29, 51], "y_male": 34, "y_mat": 41, "y_multi": 49, "y_numer": 25, "y_pred": [34, 44], "y_pred_lower_threshold": 34, "y_pred_toi": 34, "y_pred_train": 44, "y_re": 34, "y_small_citi": [15, 20, 29], "y_spotifi": 33, "y_test": [12, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 43, 44, 45, 46, 48, 49, 52, 53], "y_test_big": 33, "y_test_happi": [34, 47], "y_test_multi": 49, "y_test_num": [36, 37], "y_toi": [15, 20, 29, 44], "y_tr": [23, 52], "y_train": [12, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 43, 44, 45, 46, 48, 49, 52, 53], "y_train_big": 34, "y_train_happi": [34, 47], "y_train_hous": 38, "y_train_multi": 49, "y_train_num": [36, 37], "y_train_ord": 44, "y_train_oversampl": 34, "y_train_subsampl": 34, "y_train_tini": 33, "y_train_usr": 41, "y_true": 46, "y_true_toi": 34, "y_valid": [23, 24, 34, 41, 43, 52], "y_vari": 40, "y_xor": 38, "yale": 42, "yan": [1, 54], "yann": 37, "ycxmx": 45, "ye": [4, 12, 13, 16, 17, 18, 21, 25, 26, 27, 30, 31, 37, 39, 40, 41, 43, 44, 46, 47, 48, 50], "year": [12, 13, 17, 18, 27, 41, 42, 43, 44, 45], "yearbuilt": [35, 37, 46], "yearremodadd": [35, 37, 46], "yellow": 33, "yellowbrick": [39, 40], "yesterdai": 44, "yet": [1, 10, 11, 25, 32, 37, 41, 44, 45, 52], "yifei": [1, 54], "ylabel": [8, 13, 14, 15, 18, 19, 20, 23, 24, 27, 28, 29, 32, 33, 34, 35, 40, 43, 44, 45, 46, 49, 51, 52], "ylim": [45, 46], "yml": 10, "yolo": 43, "yolo8": 43, "yolo_input": 43, "yolo_result": 43, "yolo_test": 43, "yolov8n": 43, "york": [44, 48], "you": [0, 1, 4, 5, 6, 7, 8, 10, 23, 24, 37, 42, 48, 49, 50, 51, 52, 53, 54], "your": [0, 1, 2, 4, 6, 7, 8, 10, 14, 15, 16, 19, 20, 21, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54], "your_miniconda_path": 48, "your_nam": 10, "yourself": [4, 11, 31, 34, 41, 42, 46, 54], "yourselv": 42, "youtub": [1, 12, 17, 41, 42, 46, 54], "yr_built": [12, 13, 17, 23, 26, 27], "yr_renov": [12, 13, 17, 23, 26, 27], "yrpxn": 45, "yrsold": [35, 37, 46], "ytick": [14, 19, 24, 28, 34], "yticklabel": 33, "yy": [38, 44], "yyyi": 44, "z": [8, 24, 32, 38, 39, 40, 41, 43, 45], "z_i": 43, "z_j": 43, "z_km": 39, "z_train": [24, 43], "z_valid": [24, 43], "zachari": 45, "zarei": [1, 54], "zefeng": [1, 54], "zeng": [1, 54], "zero": [8, 14, 19, 28, 31, 33, 41, 42, 46], "zero_divis": 34, "zhiyanov": [1, 54], "zip": [15, 20, 24, 29, 32, 41, 48, 52], "zipcod": [12, 13, 17, 23, 26, 27, 52], "zone": 44, "zoom": 7, "\u0259m": 54, "\u03bc": 49}, "titles": ["LICENSE", "UBC CPSC 330: Applied Machine Learning (2024W2)", "CPSC 330 vs. CPSC 340", "CPSC 330 Documents", "How to ask for help", "What are git and GitHub?", "CPSC 330 grading policies", "Homework info &amp; submission guidelines", "CPSC 330 Python notes", "Reference material", "Setting up coding environment", "Course Learning Objectives", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "&lt;no title&gt;", "Lecture 3: ML Fundamentals Class Demo", "Lecture 4: Class demo", "Lecture 5 and 6: Class demo", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 12: Ensembles", "Lecture 13: Feature importances and model transparency", "Lecture 14: Feature engineering and feature selection", "Lecture 15: K-Means Clustering", "Lecture 16: More Clustering", "Lecture 17: Recommender Systems", "Lecture 18: Introduction to natural language processing", "Lecture 19: Multi-class classification and introduction to computer vision", "Lecture 20: Time series", "Lecture 21: Survival analysis", "Lecture 22: Communication", "Lecture 24: Deployment and conclusion", "Appendix A: Demo of feature engineering for text data", "Appendix B: Multi-class, meta-strategies", "Final exam preparation: guiding questions", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Syllabus"], "titleterms": {"": [12, 14, 15, 16, 17, 20, 21, 25, 26, 28, 29, 30, 31, 34, 35, 37, 44, 46], "0": 36, "1": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 45, 46, 50, 51, 52, 53], "10": 35, "12": 36, "13": 37, "14": 38, "15": [39, 46, 47], "16": 40, "17": 41, "18": 42, "19": 43, "2": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 41, 45, 46, 50, 51, 52, 53], "20": [44, 46, 47], "2024w2": 1, "21": 45, "22": 46, "24": 47, "3": [12, 13, 14, 16, 17, 18, 19, 21, 23, 26, 27, 28, 30, 38, 39, 40, 45, 51, 52, 53], "330": [1, 2, 3, 6, 8, 12, 17, 47], "340": [2, 12, 17, 47], "4": [13, 14, 15, 18, 19, 20, 24, 27, 28, 29, 46, 51, 52, 53], "5": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 27, 28, 29, 30, 31, 34, 37, 38, 39, 42, 43, 45, 46, 52, 53], "6": [25, 31, 52], "7": 32, "8": 33, "9": 34, "A": [4, 34, 40, 44, 48], "No": 8, "Not": 50, "One": [16, 21, 30, 44, 49], "The": [1, 14, 19, 28, 32, 33, 36, 38, 39], "__": 33, "about": [8, 12, 17, 38, 41, 46], "academ": 54, "access": [7, 32, 54], "accommod": 54, "acknowledg": 54, "activ": [12, 17, 23, 34, 37, 38, 39, 42, 46], "actual": 31, "ad": 8, "addit": [7, 37], "address": 34, "advantag": 33, "advic": 38, "ai": 54, "aka": 46, "algorithm": [13, 15, 18, 20, 27, 29, 38, 39], "all": [12, 13, 16, 17, 26, 27, 30, 32, 34, 39, 40, 41, 46], "alpha": [32, 35], "alreadi": 47, "altern": [13, 16, 18, 21, 25, 27, 30], "an": [36, 46, 48], "analogi": [15, 29], "analysi": [23, 25, 44, 45, 47, 50, 52], "angl": 46, "announc": [12, 13, 14, 15, 16, 20, 27, 29, 31, 32, 36], "answer": 45, "ap": 34, "api": [16, 21, 30, 47], "app": 47, "appendix": [48, 49], "appli": [1, 8, 16, 21, 30, 31, 35, 46], "applic": 39, "applymap": 8, "approach": [41, 44, 45, 46, 47, 49], "approxim": [14, 19, 28], "ar": [5, 12, 13, 16, 17, 21, 26, 27, 30, 32, 34, 39, 40, 41], "area": 34, "argument": [14, 15, 19, 20, 28, 29], "around": 46, "arrai": 8, "articl": 9, "asap": 46, "ask": 4, "assess": 23, "assign": [7, 54], "associ": 32, "assum": 45, "attent": [13, 15, 18, 20, 27, 29], "attribut": [37, 46], "auc": 34, "autom": 33, "averag": [34, 36, 41], "avoid": [14, 19, 28], "b": [39, 49], "backward": 38, "bad": 33, "bag": [31, 48], "balanc": 34, "base": [15, 29, 36, 38, 41, 44], "baselin": [13, 16, 18, 21, 23, 27, 30, 34, 36, 37, 41, 52], "basic": 42, "befor": [12, 16, 17, 21, 30], "best": 38, "better": [14, 19, 28, 33, 34, 38, 46], "between": [13, 15, 20, 27, 29, 47, 51], "beyond": [37, 41], "bia": [14, 19, 28, 33], "big": [13, 14, 16, 18, 19, 21, 27, 28, 30], "binari": 34, "book": 1, "boost": [36, 46], "bootstrap": 36, "bottom": 46, "boundari": [13, 15, 18, 20, 24, 27, 29, 32, 51], "bow": 31, "box": 43, "break": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 27, 28, 29, 30, 31, 38, 42, 43, 45, 46, 47], "broadcast": 8, "browser": [12, 17], "build": [12, 13, 17, 18, 23, 26, 27, 35, 41, 47], "c": [15, 20, 29, 33], "calcul": 32, "california": [31, 32, 53], "can": [8, 14, 16, 19, 21, 28, 30, 36, 37, 38, 39], "canada": [13, 27, 51], "care": [41, 46], "carri": [16, 21, 30, 38], "case": [31, 32, 40], "catboost": 36, "categor": [16, 21, 25, 30, 31, 37, 44], "categori": 31, "censor": 45, "centr": 54, "certain": 31, "cfa": 54, "chang": 34, "charact": [12, 17, 26], "characterist": 34, "cheatsheet": 8, "checklist": [12, 17], "choos": [15, 20, 29, 39], "chunk": 46, "churn": 45, "cite": 7, "citi": 32, "claim": 46, "class": [12, 17, 23, 24, 25, 33, 34, 35, 36, 37, 41, 43, 49, 54], "class_attend": 31, "class_weight": 34, "classif": [13, 18, 24, 27, 34, 43, 47, 50], "classifi": [13, 18, 25, 27, 32, 36, 48], "clearli": 38, "cluster": [39, 40, 50], "co": [1, 54], "code": [10, 54], "coeffici": [32, 37], "color": [51, 52, 53], "column": [8, 16, 21, 30, 31, 44], "columntransform": [31, 53], "com": 15, "combin": 36, "come": [14, 15, 19, 20, 28, 29], "command": 5, "comment": [13, 18, 27, 33, 34, 35, 39, 40, 41], "common": [16, 21, 30, 39], "commonli": 42, "commun": [12, 17, 46, 50], "compact": [16, 21, 30], "companion": 9, "complet": 41, "complex": [14, 19, 28], "complic": 44, "compon": 32, "comprehens": 53, "comput": [12, 17, 43, 50], "con": [15, 20, 29, 40, 50], "concept": [23, 46], "concern": 6, "concess": 54, "conclus": 47, "conda": 10, "conduct": 54, "confid": [32, 46], "confus": [34, 46], "consid": 45, "construct": 36, "content": 41, "context": 42, "continu": [13, 18, 27], "conveni": 31, "corpu": 47, "correct": 39, "correl": 37, "countri": [13, 27, 51], "countvector": 31, "cours": [1, 9, 11, 12, 17, 26, 47, 54], "cover": [41, 45, 47], "cox": 45, "cpsc": [1, 2, 3, 6, 8, 12, 17], "creat": [7, 13, 14, 18, 19, 27, 28, 31, 41, 47], "credit": 10, "cross": [14, 16, 19, 21, 23, 28, 30, 34, 38, 44, 52], "cross_val_scor": [14, 19, 28], "cross_valid": [14, 19, 28, 35], "csv": 8, "curs": [15, 20, 29], "curv": [34, 45], "custom": [39, 45], "cv": 33, "dai": 44, "data": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 46, 47, 48, 52], "datafram": [8, 31], "dataset": [7, 13, 16, 18, 21, 27, 30, 31, 32, 33, 34, 35, 43, 44, 46, 53], "date": [1, 44], "datetim": 44, "dbscan": 40, "deal": [31, 34], "debug": 10, "decis": [13, 15, 18, 20, 23, 24, 27, 29, 32, 37, 46, 52], "decisiontreeclassifi": [13, 18, 27, 36], "decreas": 34, "deep": [43, 44], "defin": 38, "definit": [12, 17, 26], "deliver": [1, 12, 17], "demo": [23, 24, 25, 38, 44, 47, 48], "demonstr": 34, "dendrogram": 40, "depend": 38, "deploi": 47, "deploy": [14, 19, 28, 47, 50], "descript": 54, "desktop": 5, "detail": [19, 34, 35, 40], "detect": 43, "df": 8, "did": [14, 16, 19, 21, 28, 30, 31, 34, 35, 41, 45, 46, 47], "differ": [16, 21, 30, 33, 34, 35, 37, 47, 50], "dimens": [15, 20, 29], "dimension": [15, 20, 29], "directori": 47, "discuss": [23, 25, 33, 34, 41, 42, 46, 47], "diseas": [12, 17, 26], "distanc": [15, 20, 29, 39], "distribut": 33, "do": [16, 21, 25, 30, 31, 33, 34, 36, 37, 38, 46, 47], "document": [3, 8, 39], "doe": [13, 18, 19, 27, 32, 40, 46], "domain": 38, "drop": 8, "due": 1, "dummi": [24, 25, 48], "dummyclassifi": [13, 18, 27, 36, 44, 45], "dummyregressor": [13, 16, 18, 21, 27, 30, 35], "eda": [16, 21, 30, 34, 35, 47, 52], "effect": [36, 46], "elbow": 39, "element": 8, "elimin": 38, "embed": 42, "encod": [16, 21, 30, 31, 38, 44], "engin": [38, 44, 48, 50], "ensembl": [36, 50], "enter": 25, "environ": [10, 47], "equal": 46, "error": [14, 19, 28, 33, 34, 35, 41], "estim": [16, 21, 30, 36], "ethic": 50, "euclidean": [15, 20, 29], "eva": [12, 14, 17, 26, 28], "evalu": [34, 40, 41, 45, 50], "evalut": 34, "event": 45, "everyon": 45, "exactli": 32, "exam": [50, 54], "examin": [31, 35, 46, 50], "exampl": [12, 13, 14, 15, 16, 17, 18, 20, 21, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 42, 45, 46, 48], "exercis": [13, 14, 15, 16, 18, 19, 20, 21, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 41, 43, 45, 51], "exhaust": 33, "experi": 46, "explain": [37, 46], "explan": [37, 46], "explor": [15, 20, 29, 39], "exploratori": [23, 25, 44, 52], "extract": [31, 44], "extractor": 43, "f1": 34, "failur": 40, "fair": 34, "fancier": 33, "farewel": 47, "faster": 8, "fastest": 8, "featur": [12, 13, 15, 16, 17, 18, 20, 21, 25, 26, 27, 29, 30, 31, 32, 35, 37, 38, 41, 43, 44, 46, 48, 50], "feature_importances_": 37, "few": [34, 40, 46], "fictiti": [12, 17, 26], "figur": 7, "filter": [8, 41], "final": [13, 18, 27, 33, 39, 40, 41, 44, 50, 52, 54], "find": [15, 20, 29, 38], "first": [12, 16, 17, 21, 30], "fit": [13, 16, 18, 21, 27, 30, 36], "flatten": 43, "follow": [12, 13, 14, 17, 19, 23, 26, 27, 28, 39, 40, 41], "font": [51, 52, 53], "forecast": 44, "forest": [36, 37, 46], "format": [7, 8, 12, 17], "formul": 41, "forward": 38, "from": [8, 46, 48], "full": 47, "function": [8, 32, 35], "fundament": [14, 15, 19, 20, 23, 28, 29, 36, 50], "further": [44, 48], "futur": 44, "fuyi": 15, "gamma": [15, 20, 29], "garbag": 38, "gb": 46, "gener": [4, 6, 14, 15, 19, 20, 28, 29, 32, 36, 38], "geometr": [15, 20, 29], "get": 37, "git": [5, 10], "github": 5, "given": [12, 13, 17, 18, 26, 27], "global": 41, "goal": [14, 19, 28], "golden": [14, 16, 19, 21, 28, 30, 31], "good": [34, 46], "grade": [4, 6, 13, 17, 18, 27, 54], "gradescop": 7, "gradient": [36, 46], "grid": [33, 46], "gridsearchcv": [33, 35, 46], "group": [23, 34, 39], "guid": 50, "guidelin": [4, 6, 7], "ha": [12, 17, 26], "halv": 33, "handl": 34, "have": [36, 37, 46], "hazard": 45, "heatmap": 33, "help": [4, 38], "here": [14, 19, 28], "hierarch": 40, "home": 40, "homework": [7, 12, 17], "hot": [16, 21, 30, 38, 44], "hous": [12, 13, 16, 17, 21, 26, 27, 30, 31, 32, 53], "how": [4, 7, 13, 14, 15, 16, 18, 19, 20, 21, 25, 27, 28, 29, 30, 32, 36, 37, 38, 40, 46], "http": 15, "hyper": 33, "hyperparamet": [13, 15, 18, 20, 23, 27, 29, 31, 32, 33, 35, 36, 39, 50, 52], "i": [12, 14, 16, 17, 19, 21, 26, 28, 30, 31, 33, 34, 36, 37, 38, 39, 41, 42, 46, 47, 48], "iclick": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 45, 54], "idea": [15, 20, 29, 34, 36, 38, 46], "identifi": [31, 37], "imag": [12, 17, 24, 26, 43], "imagenet": 43, "imbal": [34, 35, 36, 37], "import": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52], "improv": 48, "imput": [16, 21, 30, 41], "incorpor": [25, 31], "increas": 34, "index": 8, "inertia": 39, "info": 7, "inform": [37, 44], "initi": [39, 47], "inject": 36, "input": [12, 17, 26, 39], "instal": [5, 10], "instruct": [0, 7], "instructor": 1, "interact": 38, "intercept": 32, "interest": 46, "interim": [34, 37, 38, 44], "interpret": [32, 37, 47], "intra": 39, "intro": 41, "introduct": [8, 12, 17, 26, 37, 38, 39, 40, 42, 43, 46, 50], "intuit": 32, "involv": [44, 46], "issu": 46, "join": 15, "jupyt": [12, 17], "jupyterlab": 10, "k": [15, 16, 20, 21, 29, 30, 39, 40, 41], "kaplan": 45, "kei": [37, 46, 47], "kernel": [15, 20, 29], "kind": 36, "kneighborsclassifi": [15, 20, 24, 29], "knn": [24, 25], "label": [12, 17, 26, 39, 46], "lag": 44, "land": 54, "languag": 42, "larg": 33, "late": 7, "latitud": [13, 27, 51], "lda": 42, "learn": [1, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47], "least": 32, "lectur": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 54], "let": [15, 16, 20, 21, 25, 29, 30, 31, 34, 35, 37, 46], "licens": [0, 1], "lightgbm": 36, "limit": [6, 32, 40], "line": 5, "linear": [32, 35, 37], "link": 1, "list": 9, "liver": [12, 17, 26], "ll": [14, 19, 28], "lo": [14, 16, 19, 20, 21, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 47], "load": 47, "local": 47, "localhost": 47, "logist": [32, 34, 43], "logisticregress": [34, 44, 45, 46], "longitud": [13, 27, 51], "look": [34, 39], "loop": 8, "loss": 46, "lower": 33, "mac": 5, "machin": [1, 12, 13, 14, 15, 17, 18, 19, 20, 23, 26, 27, 28, 29, 34, 39, 47], "maco": 10, "macro": 34, "magnitud": 32, "mai": 38, "main": [32, 41, 46], "make": [8, 32, 46], "make_column_transform": 31, "make_pipelin": [16, 21, 30], "mani": [31, 33], "manual": 33, "mape": 35, "materi": [0, 1, 9], "matplotlib": 8, "matric": 31, "matrix": [34, 41], "matter": 19, "max_depth": [13, 18, 27], "mean": [35, 39, 40, 42, 46], "measur": 38, "media": 42, "meet": [12, 17, 26, 54], "meier": 45, "messag": [12, 17, 26, 40], "meta": 49, "method": [8, 25, 33, 38, 39], "metric": [34, 35, 50], "midterm": [39, 54], "might": 45, "min": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 27, 28, 29, 30, 31, 34, 37, 38, 39, 42, 43, 45, 46, 47], "minor": 34, "misc": [1, 9], "miscellan": 41, "mislead": 46, "ml": [12, 14, 15, 17, 19, 20, 23, 26, 28, 29, 34, 37, 46, 50], "model": [12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 42, 43, 45, 47, 48, 50, 52], "model_select": 33, "moment": 47, "month": 44, "more": [13, 15, 16, 18, 19, 20, 21, 27, 29, 30, 31, 32, 34, 35, 38, 40, 44], "most": 32, "motiv": [14, 15, 16, 19, 20, 21, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 46], "movi": 41, "mse": 35, "much": 33, "multi": [34, 43, 49], "multiclass": 50, "multipl": [15, 20, 29, 31, 35], "multipli": 8, "n_estim": 36, "n_iter": 33, "n_job": 33, "n_neighbor": [15, 20, 29], "name": [14, 19, 28, 35, 41], "natur": 42, "nearest": [15, 16, 20, 21, 29, 30, 39, 41], "need": [16, 21, 30, 33], "neg": 34, "neighbour": [15, 16, 20, 21, 29, 30, 41], "nest": 8, "netflix": 36, "network": 43, "neural": 43, "new": [46, 47], "next": [12, 17, 47], "nlp": [42, 50], "nn": [15, 20, 29], "non": [15, 20, 29, 31, 37], "notat": 8, "note": [8, 14, 28, 44, 52], "notebook": [12, 17], "now": 45, "number": [36, 39, 44], "numer": [37, 38], "numpi": 8, "object": [11, 13, 18, 27, 36, 42, 43, 44, 45, 46, 47], "observ": 34, "occasion": [16, 21, 30], "off": [14, 15, 19, 20, 28, 29, 36], "oh": [16, 21, 30, 31], "ok": [16, 21, 30, 31], "onc": 34, "one": [31, 38], "onehotencod": 31, "onli": [31, 45], "onlin": [1, 9], "oper": 34, "optim": [23, 33, 50], "option": [10, 15, 16, 20, 21, 29, 30, 33, 34, 36, 38, 45, 47], "ordin": [1, 16, 21, 25, 30, 31, 37, 54], "other": [8, 15, 20, 29, 35, 38, 39, 42, 44, 45, 46], "our": [7, 14, 16, 19, 21, 28, 30, 46, 47, 48], "out": [16, 21, 30, 38, 43, 46, 47], "outcom": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41], "outlin": [51, 52, 53], "output": 39, "over": [8, 15, 20, 29, 32, 34], "overfit": [14, 19, 28, 33], "oversampl": 34, "overview": [15, 20, 29, 34], "ovo": 49, "ovr": 49, "packag": [10, 44], "panda": 8, "pandas_profil": 35, "paper": [34, 36], "paradigm": [16, 21, 30], "paramet": [13, 18, 27, 32, 33, 34, 50], "parametr": [15, 20, 29], "pars": 44, "part": 50, "pass": 33, "patient": [12, 17, 26], "perfect": 39, "perhap": 46, "permutation_import": 37, "persona": [12, 17, 26], "piazza": 4, "pick": [14, 19, 28, 33], "pictur": [13, 14, 16, 18, 19, 21, 27, 28, 30], "piec": 46, "pipelin": [16, 21, 25, 30, 42], "plan": 40, "playground": [15, 20, 24, 29, 52], "plot": [8, 37, 39, 45], "point": [15, 20, 29, 34, 37, 39, 44], "polici": 6, "poll": 39, "popular": [12, 17, 26], "posit": 34, "posix": 44, "possibl": [31, 35, 39, 48], "post": 9, "pr": 34, "practic": [15, 18, 27, 29], "pre": 43, "precis": 34, "predict": [12, 13, 17, 18, 26, 27, 31, 32, 36, 37, 41, 43, 45, 49, 51], "predict_proba": [32, 46], "predictor": 47, "prefer": 46, "prepar": [7, 50], "preprocess": [16, 21, 30, 31, 35, 42, 44, 46, 47, 50], "prerequisit": [12, 17], "preval": [12, 17, 26], "price": [12, 13, 17, 26, 27], "principl": 46, "prize": 36, "pro": [15, 20, 29, 40, 50], "probabl": [32, 33], "problem": [13, 14, 15, 16, 18, 19, 20, 21, 27, 28, 29, 30, 33, 38, 41, 44, 47, 48], "procedur": 34, "process": 42, "product": [12, 17, 26], "profil": 41, "program": [13, 18, 27], "project": 48, "properli": 25, "proport": 45, "python": [8, 9, 10, 12, 17], "q": 4, "qualiti": 38, "queri": [8, 15, 20, 29], "question": [4, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53], "quick": [15, 29], "quiz": [13, 18, 27], "quiz2": [13, 18, 27], "quot": 38, "r": 35, "random": [33, 36, 37, 46], "random_st": [14, 19, 28], "randomforestclassifi": [36, 45], "randomizedsearchcv": [33, 35], "rang": 33, "rate": 41, "raw": 32, "rbf": [15, 20, 24, 29], "re": 46, "read": [8, 13, 18, 27, 33, 43], "reader": 46, "real": [13, 27, 47, 51], "realist": 31, "reason": 6, "recal": 34, "recap": [13, 15, 18, 27, 29, 40, 45, 46, 51, 53], "receiv": 34, "recip": 47, "recommend": [12, 16, 17, 21, 30, 41, 50], "record": 54, "recurs": 38, "red": [51, 52, 53], "refer": [1, 9, 45], "reflect": [13, 14, 18, 19, 27, 28, 39, 40], "registr": [12, 17, 54], "regress": [13, 15, 18, 20, 27, 29, 32, 34, 35, 36, 43], "regressor": [15, 20, 29], "relat": [4, 13, 15, 18, 20, 27, 29, 46], "relev": [9, 34, 36, 38], "remark": 44, "rememb": 39, "remind": [13, 27, 41], "remov": 8, "renam": 8, "render": 47, "report": [7, 34], "repositori": 7, "represent": [31, 43], "request": 47, "requir": [12, 17, 47], "rescu": [14, 19, 28], "resourc": [9, 12, 17, 33, 34, 38, 39, 40, 41], "rest": 49, "result": [33, 46], "retail": 44, "reus": 46, "review": 47, "revis": 23, "rf": 46, "rfe": 38, "ridg": [32, 35], "ridgecv": 35, "right": 45, "rmse": 35, "roc": 34, "root": 35, "row": 8, "rule": [14, 16, 19, 21, 28, 30, 31], "run": [16, 21, 30, 46], "same": 8, "sampl": [34, 36, 39], "sauc": 39, "save": [12, 17, 26, 47], "scale": [12, 16, 17, 21, 25, 26, 30, 32, 37], "schedul": 1, "scheme": 54, "scikit": [14, 16, 19, 21, 28, 30, 31, 35], "score": [13, 14, 18, 19, 27, 28, 32, 33, 34, 35, 38, 39, 48], "search": [15, 20, 29, 33, 38, 46], "season": 44, "segment": 39, "select": [12, 13, 17, 26, 27, 38, 39, 40, 41, 50], "send": 47, "separ": [35, 37, 46], "seri": [8, 44, 50], "server": 47, "servic": 47, "set": [5, 10, 12, 14, 17, 19, 23, 28, 33, 34, 47], "set_config": 31, "shap": 37, "shape": [8, 40], "shaplei": 37, "short": 9, "should": [36, 41, 46], "show": [37, 46], "sigmoid": [32, 43], "sign": 32, "silhouett": 39, "similar": [15, 20, 29], "simpl": [14, 19, 28, 48], "simplefeatur": 37, "simpleimput": 25, "singl": [14, 19, 23, 28], "size": 8, "sklearn": [13, 16, 18, 21, 25, 27, 30, 31, 33, 34, 36, 37], "slowest": 8, "small": 46, "smote": 34, "social": 42, "softmax": 43, "softwar": [0, 43, 44], "solv": 33, "some": [13, 18, 27, 33, 34, 36, 38, 47], "sort": 8, "sort_valu": 8, "sourc": 7, "space": 44, "spaci": [42, 48], "spaghetti": 39, "spam": [12, 17, 26, 31], "spars": 31, "specif": [4, 38], "split": [14, 16, 19, 21, 23, 25, 28, 30, 34, 44, 52], "spotifi": [16, 21, 30, 33], "squar": 35, "stack": 36, "standardscal": [16, 21, 30], "statement": [12, 13, 17, 26, 27, 39, 40, 41], "statist": 47, "step": [13, 18, 23, 27, 42, 53], "strategi": [36, 49], "stratifi": 34, "strength": [32, 36], "structur": 47, "studi": 50, "style": [12, 17], "submiss": 7, "submit": 7, "success": 33, "summari": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], "supervis": [12, 13, 14, 15, 17, 18, 19, 20, 23, 26, 27, 28, 29, 39, 41, 47], "support": [15, 20, 29], "surviv": [45, 50], "svc": 34, "svm": [15, 20, 24, 29, 32], "syllabu": [1, 54], "syntax": [16, 21, 30, 31, 33], "synthet": 34, "system": [41, 50], "ta": [1, 54], "tabular": [13, 15, 18, 20, 27, 29, 47], "tackl": 35, "take": 40, "takeawai": 47, "target": [12, 13, 17, 18, 26, 27, 31, 35, 39], "task": 42, "teach": [1, 54], "team": [1, 54], "techniqu": [16, 21, 30, 34], "templat": 7, "tempor": 44, "tent": 1, "terminologi": [13, 18, 27, 43], "test": [5, 14, 19, 23, 28, 33, 44], "test_df": [14, 19, 28], "test_siz": [14, 19, 28], "text": [25, 31, 42, 48], "than": [31, 33, 38, 46], "thei": 36, "them": 8, "thi": [8, 12, 16, 17, 21, 23, 25, 26, 30, 31, 37, 46, 47], "thing": [16, 21, 30, 46], "threshold": 34, "time": [6, 12, 17, 26, 44, 45, 50], "tip": 50, "todai": [14, 16, 19, 21, 28, 30, 31, 34, 35, 46], "toi": [13, 18, 27, 31, 34, 42], "token": 42, "tool": 42, "topic": 42, "trade": [14, 15, 19, 20, 28, 29, 36], "tradeoff": [14, 19, 28, 34, 36], "tradit": [13, 18, 27, 44], "train": [12, 13, 14, 17, 18, 19, 26, 27, 28, 31, 32, 34, 43, 44, 46, 47], "train_df": [14, 19, 28], "train_siz": [14, 19, 28], "transfer": 43, "transform": [16, 21, 30, 31, 35, 38, 46], "transpar": [37, 47], "tree": [13, 18, 23, 27, 36, 37, 46, 52], "trend": 44, "true": [12, 17, 26, 39, 40, 41], "try": [16, 21, 25, 30, 35, 46, 47], "tune": [35, 39, 52], "tutori": [20, 51, 52, 53], "two": 31, "type": [12, 14, 17, 19, 26, 28, 34, 35, 37, 39, 44, 45, 46], "typic": [14, 19, 23, 28, 42], "u": 46, "ubc": 1, "ubuntu": 5, "under": 34, "underfit": [14, 19, 28], "undersampl": 34, "understand": 47, "unequ": 44, "unknown": 31, "unlabel": 39, "unseen": [12, 14, 17, 19, 26, 28], "unsupervis": [13, 18, 27, 39], "up": [5, 10, 12, 14, 15, 17, 19, 20, 28, 29, 46, 47], "updat": 7, "url": 8, "us": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 26, 27, 28, 29, 30, 31, 34, 35, 36, 38, 39, 42, 43, 46, 49, 51, 54], "usa": [13, 27, 51], "user": [5, 41], "usual": 38, "util": 41, "v": [2, 12, 13, 14, 15, 17, 18, 19, 20, 27, 28, 29, 34, 37, 39, 43, 47, 49], "valid": [14, 16, 19, 21, 23, 28, 30, 33, 34, 44, 52], "varianc": [14, 19, 28], "vector": [8, 15, 20, 29, 42], "video": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 32, 34, 35, 36, 39, 40, 42], "view": [15, 20, 29, 31], "violat": [14, 19, 28], "virtual": 10, "vision": [43, 50], "visual": [9, 33, 46], "wai": [33, 38, 46], "waitlist": [12, 17], "want": [31, 37, 45], "warn": [13, 18, 27, 38], "watch": 46, "we": [8, 14, 16, 19, 21, 23, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47], "weak": 36, "web": 47, "websit": [12, 17], "weight": [32, 34], "what": [5, 10, 12, 14, 16, 17, 19, 21, 26, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 45, 46, 47], "when": [8, 16, 21, 30, 33, 46], "where": [31, 45], "whether": [12, 17, 26], "which": [12, 13, 17, 26, 27, 34, 36, 39, 40, 41], "why": [10, 12, 17, 19, 26, 31, 33, 37, 38, 41, 43, 46], "window": [5, 10], "wise": 8, "without": 39, "word": [31, 42, 48], "work": [13, 18, 27, 36, 40, 46], "workflow": [12, 14, 19, 26, 28, 34], "would": [14, 19, 25, 28, 47], "wrapper": 49, "write": [13, 18, 27], "x": [12, 13, 17, 18, 26, 27, 35, 37, 46], "xgboost": 36, "y": [12, 13, 17, 18, 26, 27, 35, 37, 46], "ye": 45, "yield": 33, "you": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47], "your": [5, 12, 13, 17, 18, 23, 27, 46]}})