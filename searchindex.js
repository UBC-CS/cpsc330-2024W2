Search.setIndex({"alltitles": {"": [[26, "id1"]], "(Optional) Changing the data": [[39, "optional-changing-the-data"]], "(Optional) Evaluation": [[50, "optional-evaluation"]], "(Optional) Evaluation metrics for multi-class classification": [[39, "optional-evaluation-metrics-for-multi-class-classification"]], "(Optional) Example 1: Optimization bias": [[38, "optional-example-1-optimization-bias"]], "(Optional) Example 2: Optimization bias": [[38, "optional-example-2-optimization-bias"]], "(Optional) Fancier methods": [[38, "optional-fancier-methods"]], "(Optional) Fitting in boosted regression trees.": [[41, "optional-fitting-in-boosted-regression-trees"]], "(Optional) Forward or backward selection": [[43, "optional-forward-or-backward-selection"]], "(Optional) Macro average and weighted average": [[39, "optional-macro-average-and-weighted-average"]], "(Optional) Parametric vs non parametric": [[15, "optional-parametric-vs-non-parametric"], [22, "optional-parametric-vs-non-parametric"], [34, "optional-parametric-vs-non-parametric"]], "(Optional) Passing probability distributions to random search": [[38, "optional-passing-probability-distributions-to-random-search"]], "(Optional) Prediction in boosted regression trees": [[41, "optional-prediction-in-boosted-regression-trees"]], "(Optional) Problems with feature selection": [[43, "optional-problems-with-feature-selection"]], "(Optional) Search and score": [[43, "optional-search-and-score"]], "(Optional) Searching for optimal parameters with successive halving\u00b6": [[38, "optional-searching-for-optimal-parameters-with-successive-halving"]], "(Optional) Setting up a directory structure and environment": [[52, "optional-setting-up-a-directory-structure-and-environment"]], "(Optional) Some more details": [[39, "optional-some-more-details"]], "(Supervised) machine learning: popular definition": [[12, "supervised-machine-learning-popular-definition"], [19, "supervised-machine-learning-popular-definition"], [31, "supervised-machine-learning-popular-definition"]], "(iClicker) Exercise 14.1": [[43, "id1"]], "(iClicker) Exercise 21.1": [[50, "iclicker-exercise-21-1"]], "(iClicker) Exercise 21.2": [[50, "iclicker-exercise-21-2"]], "(iClicker) Exercise 4.1": [[22, "iclicker-exercise-4-1"], [34, "iclicker-exercise-4-1"]], "(iClicker) Exercise 4.1 https://join.iclicker.com/FUYI": [[15, "iclicker-exercise-4-1-https-join-iclicker-com-fuyi"]], "(iClicker) Exercise 4.2": [[22, "iclicker-exercise-4-2"], [34, "iclicker-exercise-4-2"]], "(iClicker) Exercise 4.2 https://join.iclicker.com/FUYI": [[15, "iclicker-exercise-4-2-https-join-iclicker-com-fuyi"]], "(iClicker) Exercise 5.1": [[16, "iclicker-exercise-5-1"], [23, "iclicker-exercise-5-1"], [35, "iclicker-exercise-5-1"]], "(iClicker) Exercise 5.2": [[16, "iclicker-exercise-5-2"], [23, "iclicker-exercise-5-2"], [35, "iclicker-exercise-5-2"]], "(iClicker) Exercise 5.3": [[16, "iclicker-exercise-5-3"], [23, "iclicker-exercise-5-3"], [35, "iclicker-exercise-5-3"]], "(iClicker) Exercise 6.1": [[17, "iclicker-exercise-6-1"], [24, "iclicker-exercise-6-1"], [36, "iclicker-exercise-6-1"]], "(iClicker) Exercise 6.2": [[17, "iclicker-exercise-6-2"], [24, "iclicker-exercise-6-2"], [36, "iclicker-exercise-6-2"]], "(iClicker) Exercise 7.1": [[18, "iclicker-exercise-7-1"], [37, "iclicker-exercise-7-1"]], "(iClicker) Exercise 7.2": [[18, "iclicker-exercise-7-2"], [37, "iclicker-exercise-7-2"]], "(iClicker) Exercise 8.1": [[38, "iclicker-exercise-8-1"]], "(iClicker) Midterm poll": [[44, "iclicker-midterm-poll"]], "15.1 Select all of the following statements which are True (iClicker)": [[44, "select-all-of-the-following-statements-which-are-true-iclicker"]], "15.2 Select all of the following statements which are True (iClicker)": [[44, "id1"]], "15.3 Select all of the following statements which are True (iClicker)": [[44, "id3"]], "16.1 Select all of the following statements which are True (iClicker)": [[45, "select-all-of-the-following-statements-which-are-true-iclicker"]], "16.2 Select all of the following statements which are True (iClicker)": [[45, "id2"]], "16.3 Select all of the following statements which are True": [[45, "select-all-of-the-following-statements-which-are-true"]], "330 vs. 340": [[52, "vs-340"]], "<font color='red'>Question 1</font>": [[56, "question-1"], [57, "question-1"]], "<font color='red'>Question 2: Baseline model</font>": [[57, "question-2-baseline-model"]], "<font color='red'>Question 2</font>": [[56, "question-2"]], "<font color='red'>Question 3: Decision tree</font>": [[57, "question-3-decision-tree"]], "<font color='red'>Question 3</font>": [[56, "question-3"]], "<font color='red'>Question 4: Hyperparameter tuning</font>": [[57, "question-4-hyperparameter-tuning"]], "<font color='red'>Question 4</font>": [[56, "question-4"]], "<font color='red'>Question 5: Cross-validation</font>": [[57, "question-5-cross-validation"]], "<font color='red'>Question 6: Hyperparameters playground</font>": [[57, "question-6-hyperparameters-playground"]], "<font color='red'>Recap Questions</font>": [[56, "recap-questions"]], "<font color='red'>Recap/comprehension questions</font>": [[58, "recap-comprehension-questions"]], "A few comments on PR curve": [[39, "a-few-comments-on-pr-curve"]], "A few comments on clustering evaluation": [[45, "a-few-comments-on-clustering-evaluation"]], "AP score": [[39, "ap-score"]], "AP vs. F1-score": [[39, "ap-vs-f1-score"]], "API on the localhost": [[52, "api-on-the-localhost"]], "About this course": [[12, "about-this-course"], [19, "about-this-course"]], "About this document": [[8, "about-this-document"]], "Academic concessions": [[59, "academic-concessions"]], "Accessing homework assignments": [[7, "accessing-homework-assignments"]], "Accessing learned parameters": [[18, "accessing-learned-parameters"], [37, "accessing-learned-parameters"]], "Activity": [[12, "activity"], [19, "activity"]], "Activity (~5 mins)": [[42, "activity-5-mins"], [42, "id3"]], "Activity: Context and word meaning": [[47, "activity-context-and-word-meaning"]], "Activity: Discuss the following questions in your group": [[26, "activity-discuss-the-following-questions-in-your-group"]], "Activity: How can you measure quality of the data? (~3 mins)": [[43, "activity-how-can-you-measure-quality-of-the-data-3-mins"]], "Activity: explaining GridSearchCV (15 min)": [[51, "activity-explaining-gridsearchcv-15-min"]], "Adding/removing columns with [] and drop()": [[8, "adding-removing-columns-with-and-drop"]], "Adding/removing rows with [] and drop()": [[8, "adding-removing-rows-with-and-drop"]], "Additional submission instructions": [[7, "additional-submission-instructions"]], "Addressing class imbalance": [[39, "addressing-class-imbalance"]], "Advantages of RandomizedSearchCV": [[38, "advantages-of-randomizedsearchcv"], [38, "id1"]], "Alternative and more compact syntax: make_pipeline": [[16, "alternative-and-more-compact-syntax-make-pipeline"], [23, "alternative-and-more-compact-syntax-make-pipeline"], [35, "alternative-and-more-compact-syntax-make-pipeline"]], "Alternative methods for scaling": [[28, "alternative-methods-for-scaling"]], "Alternative terminology for examples, features, targets, and training": [[13, "alternative-terminology-for-examples-features-targets-and-training"], [20, "alternative-terminology-for-examples-features-targets-and-training"], [32, "alternative-terminology-for-examples-features-targets-and-training"]], "An effective strategy": [[41, "an-effective-strategy"]], "An example from a project": [[53, "an-example-from-a-project"]], "An example of a bootstrap samples": [[41, "an-example-of-a-bootstrap-samples"]], "An introduction to Grid Search": [[51, "an-introduction-to-grid-search"]], "Analogy-based algorithms in practice": [[15, "analogy-based-algorithms-in-practice"], [34, "analogy-based-algorithms-in-practice"]], "Analogy-based models": [[15, "analogy-based-models"], [34, "analogy-based-models"]], "Announcements": [[12, "announcements"], [13, "announcements"], [14, "announcements"], [16, "announcements"], [17, "announcements"], [18, "announcements"], [37, "announcements"]], "Appendix A: Demo of feature engineering for text data": [[53, null]], "Appendix B: Multi-class, meta-strategies": [[54, null]], "Applying feature transformations": [[40, "applying-feature-transformations"], [51, "applying-feature-transformations"]], "Applying functions to a dataframe with df.apply() and df.applymap()": [[8, "applying-functions-to-a-dataframe-with-df-apply-and-df-applymap"]], "Approach 1: Only consider the examples where \u201cChurn\u201d=Yes": [[50, "approach-1-only-consider-the-examples-where-churn-yes"]], "Approach 2: Assume everyone churns right now": [[50, "approach-2-assume-everyone-churns-right-now"]], "Approach 3: Survival analysis": [[50, "approach-3-survival-analysis"]], "Approach from all angles": [[51, "approach-from-all-angles"]], "Are we doing better with class_weight=\"balanced\"?": [[39, "are-we-doing-better-with-class-weight-balanced"]], "Area under the curve (AUC)": [[39, "area-under-the-curve-auc"]], "Assessing on the test set": [[26, "assessing-on-the-test-set"]], "Assignments": [[59, "assignments"]], "Attention": [[13, null], [13, null], [15, null], [20, null], [20, null], [22, null], [32, null], [32, null], [32, null], [34, null]], "Attribution": [[51, "attribution"]], "Automated hyperparameter optimization": [[38, "automated-hyperparameter-optimization"], [38, "id3"]], "Averaging": [[41, "averaging"]], "Bad range for hyperparameters": [[38, "bad-range-for-hyperparameters"]], "Bag of words (BOW) representation": [[17, "bag-of-words-bow-representation"], [24, "bag-of-words-bow-representation"], [36, "bag-of-words-bow-representation"]], "Bag-of-words model": [[53, "bag-of-words-model"]], "Baseline": [[39, "baseline"], [42, "baseline"]], "Baseline Approaches": [[46, "baseline-approaches"]], "Baseline model": [[26, "baseline-model"]], "Baselines": [[13, "baselines"], [20, "baselines"], [32, "baselines"], [41, "baselines"]], "Baselines [video]": [[13, "baselines-video"], [20, "baselines-video"], [32, "baselines-video"]], "Basic text preprocessing [video]": [[47, "basic-text-preprocessing-video"]], "Better features usually help more than a better model.": [[43, "better-features-usually-help-more-than-a-better-model"]], "Beyond error rate in recommendation systems": [[46, "beyond-error-rate-in-recommendation-systems"]], "Bias vs variance tradeoff": [[14, "bias-vs-variance-tradeoff"], [21, "bias-vs-variance-tradeoff"], [33, "bias-vs-variance-tradeoff"]], "Big picture and datasets": [[13, "big-picture-and-datasets"], [20, "big-picture-and-datasets"], [32, "big-picture-and-datasets"]], "Big picture and motivation": [[14, "big-picture-and-motivation"], [21, "big-picture-and-motivation"], [33, "big-picture-and-motivation"]], "Books": [[1, "books"]], "Bottom-up explanations": [[51, "bottom-up-explanations"]], "Break (5 min)": [[8, "break-5-min"], [12, "break-5-min"], [13, "break-5-min"], [14, "break-5-min"], [15, "break-5-min"], [16, "break-5-min"], [17, "break-5-min"], [19, "break-5-min"], [20, "break-5-min"], [21, "break-5-min"], [22, "break-5-min"], [24, "break-5-min"], [32, "break-5-min"], [33, "break-5-min"], [34, "break-5-min"], [35, "break-5-min"], [36, "break-5-min"], [43, "break-5-min"], [47, "break-5-min"], [48, "break-5-min"], [50, "break-5-min"], [51, "break-5-min"]], "Break (~15 min)": [[52, "break-15-min"]], "Broadcasting in numpy": [[8, "broadcasting-in-numpy"]], "Building a model": [[52, "building-a-model"]], "Building a supervise machine learning model": [[12, "building-a-supervise-machine-learning-model"], [19, "building-a-supervise-machine-learning-model"], [31, "building-a-supervise-machine-learning-model"]], "Building and deploying a web app": [[52, "building-and-deploying-a-web-app"]], "Building decision trees with sklearn": [[13, "building-decision-trees-with-sklearn"], [20, "building-decision-trees-with-sklearn"], [32, "building-decision-trees-with-sklearn"]], "Building user profiles": [[46, "building-user-profiles"]], "CPSC 330 Documents": [[3, null]], "CPSC 330 Python notes": [[8, null]], "CPSC 330 grading policies": [[6, null]], "CPSC 330 vs. 340": [[12, "cpsc-330-vs-340"], [19, "cpsc-330-vs-340"]], "CPSC 330 vs. CPSC 340": [[2, null]], "Can we learn without targets?": [[44, "can-we-learn-without-targets"]], "Can we use this feature in the model?": [[16, "can-we-use-this-feature-in-the-model"], [23, "can-we-use-this-feature-in-the-model"], [35, "can-we-use-this-feature-in-the-model"]], "Cases where it\u2019s OK to break the golden rule": [[17, "cases-where-it-s-ok-to-break-the-golden-rule"], [24, "cases-where-it-s-ok-to-break-the-golden-rule"], [36, "cases-where-it-s-ok-to-break-the-golden-rule"]], "CatBoost": [[41, "catboost"]], "Categorical features": [[28, "categorical-features"], [42, "categorical-features"]], "Categorical features [video]": [[16, "categorical-features-video"], [23, "categorical-features-video"], [35, "categorical-features-video"]], "Categorical features with only two possible categories": [[17, "categorical-features-with-only-two-possible-categories"], [24, "categorical-features-with-only-two-possible-categories"], [36, "categorical-features-with-only-two-possible-categories"]], "Censoring and survival analysis": [[50, "censoring-and-survival-analysis"]], "Centre for Accessibility (CfA) Exam Accommodations": [[59, "centre-for-accessibility-cfa-exam-accommodations"]], "Changing the training procedure": [[39, "changing-the-training-procedure"]], "Characters in this course?": [[12, "characters-in-this-course"], [19, "characters-in-this-course"], [31, "characters-in-this-course"]], "Checklist for you before next class": [[12, "checklist-for-you-before-next-class"], [19, "checklist-for-you-before-next-class"]], "Choosing K [video]": [[44, "choosing-k-video"]], "Choosing n_neighbors": [[15, "choosing-n-neighbors"], [22, "choosing-n-neighbors"], [34, "choosing-n-neighbors"]], "Citing sources": [[7, "citing-sources"]], "Class imbalance in training sets": [[39, "class-imbalance-in-training-sets"]], "Class meetings": [[59, "class-meetings"]], "Classification report": [[39, "classification-report"]], "Classification vs. Regression": [[13, "classification-vs-regression"], [20, "classification-vs-regression"], [32, "classification-vs-regression"]], "Classification with KNeighborsClassifier": [[27, "classification-with-kneighborsclassifier"]], "Clustering": [[55, "clustering"]], "Clustering Activity (~5 mins)": [[44, "clustering-activity-5-mins"]], "Clustering motivation [video]": [[44, "clustering-motivation-video"]], "Clustering: Input and (possible) output": [[44, "clustering-input-and-possible-output"]], "Code of conduct": [[59, "code-of-conduct"]], "Coefficients and intercept": [[18, "coefficients-and-intercept"], [37, "coefficients-and-intercept"]], "ColumnTransformer example": [[17, "columntransformer-example"], [24, "columntransformer-example"], [36, "columntransformer-example"]], "ColumnTransformer on the California housing dataset": [[36, "columntransformer-on-the-california-housing-dataset"], [58, "columntransformer-on-the-california-housing-dataset"]], "ColumnTransformer: Transformed data": [[17, "columntransformer-transformed-data"], [24, "columntransformer-transformed-data"], [36, "columntransformer-transformed-data"]], "Coming up \u2026": [[14, "coming-up"], [21, "coming-up"], [33, "coming-up"]], "Coming up:": [[15, "coming-up"], [22, "coming-up"], [34, "coming-up"]], "Command-line git": [[5, "command-line-git"]], "Common applications": [[44, "common-applications"]], "Common preprocessing techniques": [[16, "common-preprocessing-techniques"], [23, "common-preprocessing-techniques"], [35, "common-preprocessing-techniques"]], "Communication": [[55, "communication"]], "Communications": [[12, "communications"], [19, "communications"]], "Completing the utility matrix with content-based filtering": [[46, "completing-the-utility-matrix-with-content-based-filtering"]], "Components of a linear classifier": [[18, "components-of-a-linear-classifier"], [37, "components-of-a-linear-classifier"]], "Concepts then labels, not the other way around": [[51, "concepts-then-labels-not-the-other-way-around"]], "Concepts we revised in this demo": [[26, "concepts-we-revised-in-this-demo"]], "Conclusion & farewell": [[52, "conclusion-farewell"]], "Confidence and predict_proba (20 min)": [[51, "confidence-and-predict-proba-20-min"]], "Confusing and perhaps misleading visualization of results": [[51, "confusing-and-perhaps-misleading-visualization-of-results"]], "Confusion matrix": [[39, "confusion-matrix"]], "Confusion matrix with cross-validation": [[39, "confusion-matrix-with-cross-validation"]], "Cons of k-NNs for supervised learning": [[15, "cons-of-k-nns-for-supervised-learning"], [22, "cons-of-k-nns-for-supervised-learning"], [34, "cons-of-k-nns-for-supervised-learning"]], "Content-based filtering": [[46, "content-based-filtering"]], "Convenient make_column_transformer syntax": [[17, "convenient-make-column-transformer-syntax"], [24, "convenient-make-column-transformer-syntax"], [36, "convenient-make-column-transformer-syntax"]], "Course Learning Objectives": [[11, null]], "Course co-ordinator": [[1, "course-co-ordinator"], [59, "course-co-ordinator"]], "Course description": [[59, "course-description"]], "Course format": [[12, "course-format"], [19, "course-format"]], "Course review / conclusion (~20 min)": [[52, "course-review-conclusion-20-min"]], "Course website": [[12, "course-website"], [19, "course-website"]], "Cox proportional hazards model": [[50, "cox-proportional-hazards-model"]], "Create X and y": [[13, "create-x-and-y"], [20, "create-x-and-y"], [32, "create-x-and-y"]], "Create a classifier object": [[13, "create-a-classifier-object"], [20, "create-a-classifier-object"], [32, "create-a-classifier-object"]], "Create a column transformer": [[17, "create-a-column-transformer"], [24, "create-a-column-transformer"], [36, "create-a-column-transformer"]], "Creating train_df and test_df": [[14, "creating-train-df-and-test-df"], [21, "creating-train-df-and-test-df"], [33, "creating-train-df-and-test-df"]], "Creating utility matrix": [[46, "creating-utility-matrix"]], "Credit": [[10, "credit"]], "Cross validation with different metrics": [[39, "cross-validation-with-different-metrics"]], "Cross-validation": [[26, "cross-validation"], [49, "cross-validation"], [49, "id4"]], "Cross-validation [video]": [[14, "cross-validation-video"], [21, "cross-validation-video"], [33, "cross-validation-video"]], "Cross-validation to the rescue!!": [[14, "cross-validation-to-the-rescue"], [21, "cross-validation-to-the-rescue"], [33, "cross-validation-to-the-rescue"]], "Cross-validation using scikit-learn": [[14, "cross-validation-using-scikit-learn"], [21, "cross-validation-using-scikit-learn"], [33, "cross-validation-using-scikit-learn"]], "Curse of dimensionality": [[15, "curse-of-dimensionality"], [22, "curse-of-dimensionality"], [34, "curse-of-dimensionality"]], "Customer churn": [[50, "customer-churn"]], "Customer segmentation": [[44, "customer-segmentation"]], "DBSCAN [video]": [[45, "dbscan-video"]], "DBSCAN introduction": [[45, "dbscan-introduction"]], "DBSCAN: failure cases": [[45, "dbscan-failure-cases"], [45, "id1"]], "Data": [[17, "data"], [18, "data"], [24, "data"], [36, "data"], [37, "data"], [41, "data"], [42, "data"], [42, "id1"]], "Data Splitting [video]": [[14, "data-splitting-video"], [21, "data-splitting-video"], [33, "data-splitting-video"]], "Data and main approaches": [[46, "data-and-main-approaches"]], "Data and splitting": [[28, "data-and-splitting"]], "Data exploration": [[44, "data-exploration"]], "Data splitting": [[26, "data-splitting"], [57, "data-splitting"]], "Dataframe summaries": [[8, "dataframe-summaries"]], "Dataset": [[48, "dataset"], [51, "dataset"]], "Dataset [video]": [[40, "dataset-video"]], "Dataset for demonstration": [[39, "dataset-for-demonstration"]], "Dataset, splitting, and baseline": [[16, "dataset-splitting-and-baseline"], [23, "dataset-splitting-and-baseline"], [35, "dataset-splitting-and-baseline"]], "Datasets": [[7, "datasets"]], "Dealing with class imbalance [video]": [[39, "dealing-with-class-imbalance-video"]], "Dealing with unknown categories": [[17, "dealing-with-unknown-categories"], [24, "dealing-with-unknown-categories"], [36, "dealing-with-unknown-categories"]], "Debugging": [[10, "debugging"]], "Decision boundaries playground": [[27, "decision-boundaries-playground"]], "Decision boundary": [[13, "decision-boundary"], [20, "decision-boundary"], [32, "decision-boundary"]], "Decision boundary for max_depth=1": [[13, "decision-boundary-for-max-depth-1"], [20, "decision-boundary-for-max-depth-1"], [32, "decision-boundary-for-max-depth-1"]], "Decision boundary for max_depth=2": [[13, "decision-boundary-for-max-depth-2"], [20, "decision-boundary-for-max-depth-2"], [32, "decision-boundary-for-max-depth-2"]], "Decision boundary for max_depth=5": [[13, "decision-boundary-for-max-depth-5"], [20, "decision-boundary-for-max-depth-5"], [32, "decision-boundary-for-max-depth-5"]], "Decision boundary of SVMs": [[15, "decision-boundary-of-svms"], [22, "decision-boundary-of-svms"], [34, "decision-boundary-of-svms"]], "Decision boundary of logistic regression": [[18, "decision-boundary-of-logistic-regression"], [37, "decision-boundary-of-logistic-regression"]], "Decision tree algorithm": [[13, "decision-tree-algorithm"], [20, "decision-tree-algorithm"], [32, "decision-tree-algorithm"]], "Decision tree feature importances": [[42, "decision-tree-feature-importances"]], "Decision tree for regression problems": [[13, "decision-tree-for-regression-problems"], [20, "decision-tree-for-regression-problems"], [32, "decision-tree-for-regression-problems"]], "Decision tree model": [[26, "decision-tree-model"]], "Decision tree with max_depth=1": [[13, "decision-tree-with-max-depth-1"], [20, "decision-tree-with-max-depth-1"], [32, "decision-tree-with-max-depth-1"]], "Decision tree with max_depth=3": [[13, "decision-tree-with-max-depth-3"], [20, "decision-tree-with-max-depth-3"], [32, "decision-tree-with-max-depth-3"]], "Decision trees [video]": [[13, "decision-trees-video"], [20, "decision-trees-video"], [32, "decision-trees-video"]], "Decision trees with continuous features": [[13, "decision-trees-with-continuous-features"], [20, "decision-trees-with-continuous-features"], [32, "decision-trees-with-continuous-features"]], "DecisionTreeClassifier baseline": [[41, "decisiontreeclassifier-baseline"]], "DecisionTreeClassifier on quiz2 grade prediction toy dataset": [[13, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"], [20, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"], [32, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"]], "Decisions involve a few key pieces": [[51, "decisions-involve-a-few-key-pieces"]], "Decreasing the threshold": [[39, "decreasing-the-threshold"]], "Deep learning": [[49, "deep-learning"]], "Deep learning software": [[48, "deep-learning-software"]], "Deliverable due dates (tentative)": [[1, "deliverable-due-dates-tentative"]], "Demo of creating a new web service": [[52, "demo-of-creating-a-new-web-service"]], "Demo of feature engineering with numeric features": [[43, "demo-of-feature-engineering-with-numeric-features"]], "Demo: A more complicated dataset": [[49, "demo-a-more-complicated-dataset"]], "Demo: Deploying moment classification model": [[52, "demo-deploying-moment-classification-model"]], "Demo: Model interpretation of linear classifiers": [[29, "demo-model-interpretation-of-linear-classifiers"], [30, "demo-model-interpretation-of-linear-classifiers"]], "Dendrogram": [[45, "dendrogram"]], "Deploying the API on a server (not covered)": [[52, "deploying-the-api-on-a-server-not-covered"]], "Deployment (Not examinable)": [[55, "deployment-not-examinable"]], "Difference between Statistics and Machine Learning": [[52, "difference-between-statistics-and-machine-learning"]], "Different models": [[42, "different-models"]], "Different range for hyperparameters yields better results!": [[38, "different-range-for-hyperparameters-yields-better-results"]], "Different scoring functions with cross_validate": [[40, "different-scoring-functions-with-cross-validate"]], "Dimensions in ML problems": [[15, "dimensions-in-ml-problems"], [22, "dimensions-in-ml-problems"], [34, "dimensions-in-ml-problems"]], "Discuss the following questions in your group": [[26, "discuss-the-following-questions-in-your-group"]], "Discussion": [[52, "discussion"]], "Discussion question": [[47, "discussion-question"]], "Discussion questions": [[28, "discussion-questions"]], "Discussion questions:": [[51, "discussion-questions"]], "Distance between feature vectors": [[15, "distance-between-feature-vectors"], [22, "distance-between-feature-vectors"], [34, "distance-between-feature-vectors"]], "Do we actually want to use certain features for prediction?": [[17, "do-we-actually-want-to-use-certain-features-for-prediction"], [36, "do-we-actually-want-to-use-certain-features-for-prediction"]], "Do we have class imbalance?": [[41, "do-we-have-class-imbalance"], [42, "do-we-have-class-imbalance"]], "Do we have correlated features?": [[42, "do-we-have-correlated-features"]], "Document clustering": [[44, "document-clustering"]], "Domain-specific transformations": [[43, "domain-specific-transformations"]], "Dummy Classifier": [[28, "dummy-classifier"]], "Dummy classifier": [[53, "dummy-classifier"]], "Dummy model": [[27, "dummy-model"]], "DummyClassifier": [[13, "dummyclassifier"], [20, "dummyclassifier"], [32, "dummyclassifier"], [49, "dummyclassifier"], [50, "dummyclassifier"]], "DummyClassifier baseline": [[41, "dummyclassifier-baseline"]], "DummyClassifier on quiz2 grade prediction toy dataset": [[13, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"], [20, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"], [32, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"]], "DummyRegressor": [[13, "dummyregressor"], [20, "dummyregressor"], [32, "dummyregressor"], [40, "dummyregressor"]], "EDA": [[16, "eda"], [23, "eda"], [35, "eda"], [39, "eda"], [40, "eda"]], "EDA: Exploratory Data Analysis": [[57, "eda-exploratory-data-analysis"]], "Encoding text data": [[17, "encoding-text-data"], [24, "encoding-text-data"], [36, "encoding-text-data"]], "Encoding time as a number": [[49, "encoding-time-as-a-number"]], "Encoding time of day as a categorical feature": [[49, "encoding-time-of-day-as-a-categorical-feature"]], "Ensembles": [[55, "ensembles"]], "Equally good": [[51, "equally-good"]], "Ethics": [[55, "ethics"]], "Euclidean distance": [[15, "euclidean-distance"], [22, "euclidean-distance"], [34, "euclidean-distance"]], "Evaluating DBSCAN clusters": [[45, "evaluating-dbscan-clusters"]], "Evaluation": [[46, "evaluation"], [46, "id3"]], "Evaluation metrics": [[55, "evaluation-metrics"]], "Evaluation metrics for binary classification: Motivation": [[39, "evaluation-metrics-for-binary-classification-motivation"]], "Evalution metrics overview": [[39, "evalution-metrics-overview"]], "Examining learned coefficients": [[29, "examining-learned-coefficients"], [30, "examining-learned-coefficients"]], "Examining the preprocessed data": [[40, "examining-the-preprocessed-data"], [51, "examining-the-preprocessed-data"]], "Examining the vocabulary": [[29, "examining-the-vocabulary"], [30, "examining-the-vocabulary"]], "Example": [[18, "example"], [37, "example"], [41, "example"]], "Example 1: Predicting whether a patient has a liver disease or not": [[12, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"], [19, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"], [31, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"]], "Example 1: What is \u201ccorrect\u201d grouping?": [[44, "example-1-what-is-correct-grouping"]], "Example 1: quiz 2 grade prediction": [[13, "example-1-quiz-2-grade-prediction"], [20, "example-1-quiz-2-grade-prediction"], [32, "example-1-quiz-2-grade-prediction"]], "Example 2: Predicting country using the longitude and latitude": [[13, "example-2-predicting-country-using-the-longitude-and-latitude"], [32, "example-2-predicting-country-using-the-longitude-and-latitude"]], "Example 2: Predicting the label of a given image": [[12, "example-2-predicting-the-label-of-a-given-image"], [19, "example-2-predicting-the-label-of-a-given-image"], [31, "example-2-predicting-the-label-of-a-given-image"]], "Example 3: Predicting housing prices": [[12, "example-3-predicting-housing-prices"], [19, "example-3-predicting-housing-prices"], [31, "example-3-predicting-housing-prices"]], "Example showing how can we interpret coefficients of scaled features.": [[42, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"]], "Example: Is \u201cRelevance\u201d clearly defined?": [[43, "example-is-relevance-clearly-defined"]], "Example: Predict whether a message is spam or not": [[12, "example-predict-whether-a-message-is-spam-or-not"], [19, "example-predict-whether-a-message-is-spam-or-not"], [31, "example-predict-whether-a-message-is-spam-or-not"]], "Example: Supervised vs unsupervised learning": [[44, "example-supervised-vs-unsupervised-learning"]], "Example: Tabular data for grade prediction": [[13, "example-tabular-data-for-grade-prediction"], [20, "example-tabular-data-for-grade-prediction"], [32, "example-tabular-data-for-grade-prediction"]], "Example: Tabular data for the housing price prediction": [[13, "example-tabular-data-for-the-housing-price-prediction"], [32, "example-tabular-data-for-the-housing-price-prediction"]], "Example: class_weight parameter of sklearn LogisticRegression": [[39, "example-class-weight-parameter-of-sklearn-logisticregression"]], "Example: k-nearest neighbours on the Spotify dataset": [[16, "example-k-nearest-neighbours-on-the-spotify-dataset"], [23, "example-k-nearest-neighbours-on-the-spotify-dataset"], [35, "example-k-nearest-neighbours-on-the-spotify-dataset"]], "Examples": [[12, "examples"], [19, "examples"], [31, "examples"]], "Exercise 17.1 Select all of the following statements which are True (iClicker)": [[46, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 17.2 Select all of the following statements which are True (iClicker)": [[46, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 2.1 Select all of the following statements which are examples of supervised machine learning": [[13, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"], [32, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"]], "Exercise 2.3": [[20, "exercise-2-3"]], "Exercise 2.4": [[13, "exercise-2-4"], [32, "exercise-2-4"]], "Exercise 8.2": [[38, "exercise-8-2"]], "Exercise: Predicting country using the longitude and latitude": [[56, "exercise-predicting-country-using-the-longitude-and-latitude"]], "Exhaustive grid search: sklearn.model_selection.GridSearchCV": [[38, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"]], "Explaining a prediction": [[42, "explaining-a-prediction"]], "Explanation 1": [[51, "explanation-1"]], "Explanation 2": [[51, "explanation-2"]], "Exploratory Data Analysis": [[26, "exploratory-data-analysis"]], "Exploratory data analysis": [[28, "exploratory-data-analysis"], [49, "exploratory-data-analysis"]], "Extracting BOW features using scikit-learn": [[17, "extracting-bow-features-using-scikit-learn"], [24, "extracting-bow-features-using-scikit-learn"], [36, "extracting-bow-features-using-scikit-learn"]], "Extracting date and time information": [[49, "extracting-date-and-time-information"]], "F1-score": [[39, "f1-score"]], "Faster method: vectorize the loop over rows": [[8, "faster-method-vectorize-the-loop-over-rows"]], "Fastest method: broadcasting": [[8, "fastest-method-broadcasting"]], "Feature crosses for one-hot encoded features": [[43, "feature-crosses-for-one-hot-encoded-features"]], "Feature engineering": [[49, "feature-engineering"]], "Feature engineering and selection": [[55, "feature-engineering-and-selection"]], "Feature engineering for date/time columns": [[49, "feature-engineering-for-date-time-columns"]], "Feature engineering: Encoding date/time as feature(s)": [[49, "feature-engineering-encoding-date-time-as-feature-s"]], "Feature engineering: Motivation": [[43, "feature-engineering-motivation"]], "Feature importances": [[42, "feature-importances"], [55, "feature-importances"]], "Feature importances in linear models": [[42, "feature-importances-in-linear-models"], [42, "id2"]], "Feature interactions and feature crosses": [[43, "feature-interactions-and-feature-crosses"]], "Feature names of transformed data": [[40, "feature-names-of-transformed-data"]], "Feature selection: Introduction and motivation": [[43, "feature-selection-introduction-and-motivation"]], "Feature transformations and the golden rule": [[16, "feature-transformations-and-the-golden-rule"], [23, "feature-transformations-and-the-golden-rule"], [35, "feature-transformations-and-the-golden-rule"]], "Feature types": [[40, "feature-types"], [40, "id1"], [51, "feature-types"]], "Feature vectors": [[15, "feature-vectors"], [34, "feature-vectors"]], "Figures": [[7, "figures"]], "Filtering a dataframe with [] and df.query()": [[8, "filtering-a-dataframe-with-and-df-query"]], "Final comments and summary": [[38, "final-comments-and-summary"], [46, "final-comments-and-summary"]], "Final comments, summary, and reflection": [[13, "final-comments-summary-and-reflection"], [20, "final-comments-summary-and-reflection"], [32, "final-comments-summary-and-reflection"], [44, "final-comments-summary-and-reflection"], [45, "final-comments-summary-and-reflection"]], "Final exam": [[59, "final-exam"]], "Final exam preparation: guiding questions": [[55, null]], "Final note": [[57, "final-note"]], "Final remarks": [[49, "final-remarks"]], "Finding the distances to a query point": [[15, "finding-the-distances-to-a-query-point"], [22, "finding-the-distances-to-a-query-point"], [34, "finding-the-distances-to-a-query-point"]], "Finding the nearest neighbour": [[15, "finding-the-nearest-neighbour"], [22, "finding-the-nearest-neighbour"], [34, "finding-the-nearest-neighbour"]], "First deliverables": [[12, "first-deliverables"], [19, "first-deliverables"]], "Forecasting further into the future": [[49, "forecasting-further-into-the-future"]], "Forecasting further into the future on a retail dataset": [[49, "forecasting-further-into-the-future-on-a-retail-dataset"]], "Formulating the problem of recommender systems": [[46, "formulating-the-problem-of-recommender-systems"]], "GB better than RF": [[51, "gb-better-than-rf"]], "Garbage in, garbage out.": [[43, "garbage-in-garbage-out"]], "General advice on finding relevant features": [[43, "general-advice-on-finding-relevant-features"]], "General guidelines": [[6, "general-guidelines"]], "General idea": [[41, "general-idea"]], "General idea of k-nearest neighbours algorithm": [[15, "general-idea-of-k-nearest-neighbours-algorithm"], [22, "general-idea-of-k-nearest-neighbours-algorithm"], [34, "general-idea-of-k-nearest-neighbours-algorithm"]], "General idea of search and score methods": [[43, "general-idea-of-search-and-score-methods"]], "General questions": [[4, "general-questions"]], "Generalization [video]": [[14, "generalization-video"], [21, "generalization-video"], [33, "generalization-video"]], "Generalization: Fundamental goal of ML": [[14, "generalization-fundamental-goal-of-ml"], [21, "generalization-fundamental-goal-of-ml"], [33, "generalization-fundamental-goal-of-ml"]], "Generalizing to more features": [[18, "generalizing-to-more-features"], [37, "generalizing-to-more-features"]], "Generalizing to unseen data": [[14, "generalizing-to-unseen-data"], [21, "generalizing-to-unseen-data"], [33, "generalizing-to-unseen-data"]], "Geometric view of tabular data and dimensions": [[15, "geometric-view-of-tabular-data-and-dimensions"], [22, "geometric-view-of-tabular-data-and-dimensions"], [34, "geometric-view-of-tabular-data-and-dimensions"]], "Git": [[10, "git"]], "GitHub Desktop": [[5, "github-desktop"]], "Global average baseline": [[46, "global-average-baseline"]], "Golden rule violation: Example 1": [[14, "golden-rule-violation-example-1"], [33, "golden-rule-violation-example-1"]], "Golden rule violation: Example 2": [[14, "golden-rule-violation-example-2"], [33, "golden-rule-violation-example-2"]], "Grades": [[19, "grades"]], "Gradient boosted trees [video]": [[41, "gradient-boosted-trees-video"]], "Gradient boosting in sklearn": [[41, "gradient-boosting-in-sklearn"]], "Grading concerns: time limit": [[6, "grading-concerns-time-limit"]], "Grading scheme": [[59, "grading-scheme"]], "Grading-related questions": [[4, "grading-related-questions"]], "Handling imbalance": [[39, "handling-imbalance"]], "Here is the workflow we\u2019ll generally follow.": [[14, "here-is-the-workflow-we-ll-generally-follow"], [21, "here-is-the-workflow-we-ll-generally-follow"], [33, "here-is-the-workflow-we-ll-generally-follow"]], "Hierarchical clustering [video]": [[45, "hierarchical-clustering-video"]], "Homework info & submission guidelines": [[7, null]], "How are we making predictions?": [[18, "how-are-we-making-predictions"], [37, "how-are-we-making-predictions"]], "How can we avoid violating golden rule?": [[14, "how-can-we-avoid-violating-golden-rule"], [21, "how-can-we-avoid-violating-golden-rule"], [33, "how-can-we-avoid-violating-golden-rule"]], "How can we get feature importances for non sklearn models?": [[42, "how-can-we-get-feature-importances-for-non-sklearn-models"]], "How do they work?": [[41, "how-do-they-work"]], "How do we carry out feature selection?": [[43, "how-do-we-carry-out-feature-selection"]], "How does fit work?": [[13, "how-does-fit-work"], [13, "id2"], [20, "how-does-fit-work"], [32, "how-does-fit-work"], [32, "id2"]], "How does it work?": [[45, "how-does-it-work"], [51, "how-does-it-work"]], "How does logistic regression calculate these probabilities?": [[18, "how-does-logistic-regression-calculate-these-probabilities"], [37, "how-does-logistic-regression-calculate-these-probabilities"]], "How does predict work?": [[13, "how-does-predict-work"], [20, "how-does-predict-work"], [32, "how-does-predict-work"]], "How to approximate generalization error?": [[14, "how-to-approximate-generalization-error"], [21, "how-to-approximate-generalization-error"], [33, "how-to-approximate-generalization-error"]], "How to ask for help": [[4, null]], "How to carry out cross-validation?": [[16, "how-to-carry-out-cross-validation"], [23, "how-to-carry-out-cross-validation"], [35, "how-to-carry-out-cross-validation"]], "How to choose n_neighbors?": [[15, "how-to-choose-n-neighbors"], [22, "how-to-choose-n-neighbors"], [34, "how-to-choose-n-neighbors"]], "How to pick a model that would generalize better?": [[14, "how-to-pick-a-model-that-would-generalize-better"], [21, "how-to-pick-a-model-that-would-generalize-better"], [33, "how-to-pick-a-model-that-would-generalize-better"]], "How to submit": [[7, "how-to-submit"]], "How would you do it properly? Enter sklearn pipelines!!": [[28, "how-would-you-do-it-properly-enter-sklearn-pipelines"]], "Hyperparameter alpha of Ridge": [[18, "hyperparameter-alpha-of-ridge"], [37, "hyperparameter-alpha-of-ridge"]], "Hyperparameter optimization": [[26, "hyperparameter-optimization"], [55, "hyperparameter-optimization"]], "Hyperparameter optimization motivation": [[38, "hyperparameter-optimization-motivation"]], "Hyperparameter tuning for the number of clusters": [[44, "hyperparameter-tuning-for-the-number-of-clusters"]], "Hyperparameters of SVM": [[15, "hyperparameters-of-svm"], [22, "hyperparameters-of-svm"], [34, "hyperparameters-of-svm"]], "Hyperparameters: the problem": [[38, "hyperparameters-the-problem"]], "Identify the transformations we want to apply": [[17, "identify-the-transformations-we-want-to-apply"], [24, "identify-the-transformations-we-want-to-apply"], [36, "identify-the-transformations-we-want-to-apply"]], "Image classification using KNNs and SVM RBF": [[27, "image-classification-using-knns-and-svm-rbf"]], "ImageNet": [[48, "imagenet"]], "Import": [[53, "import"]], "Importance of scaling": [[18, "importance-of-scaling"], [37, "importance-of-scaling"]], "Important hyperparameters": [[41, "important-hyperparameters"]], "Important hyperparameters of CountVectorizer": [[17, "important-hyperparameters-of-countvectorizer"], [24, "important-hyperparameters-of-countvectorizer"], [36, "important-hyperparameters-of-countvectorizer"]], "Important links": [[1, "important-links"]], "Important points to remember": [[44, "important-points-to-remember"]], "Imports": [[12, "imports"], [13, "imports"], [14, "imports"], [15, "imports"], [15, "id1"], [16, "imports"], [17, "imports"], [18, "imports"], [19, "imports"], [20, "imports"], [21, "imports"], [22, "imports"], [23, "imports"], [24, "imports"], [26, "imports"], [27, "imports"], [28, "imports"], [29, "imports"], [30, "imports"], [31, "imports"], [32, "imports"], [33, "imports"], [34, "imports"], [35, "imports"], [36, "imports"], [37, "imports"], [38, "imports"], [39, "imports"], [40, "imports"], [41, "imports"], [42, "imports"], [43, "imports"], [44, "imports"], [45, "imports"], [46, "imports"], [47, "imports"], [48, "imports"], [49, "imports"], [50, "imports"], [51, "imports"], [52, "imports"], [55, "imports"], [56, "imports"], [57, "imports"]], "Imports and LO": [[38, "imports-and-lo"], [40, "imports-and-lo"], [48, "imports-and-lo"], [49, "imports-and-lo"]], "Imports and LOs": [[39, "imports-and-los"], [52, "imports-and-los"]], "Imports and learning outcomes": [[44, "imports-and-learning-outcomes"]], "Imports, Announcements, LOs": [[32, "imports-announcements-los"]], "Imports, Announcements, and LO": [[24, "imports-announcements-and-lo"], [36, "imports-announcements-and-lo"], [37, "imports-announcements-and-lo"]], "Imports, LOs": [[14, "imports-los"], [16, "imports-los"], [21, "imports-los"], [23, "imports-los"], [33, "imports-los"], [35, "imports-los"], [42, "imports-los"]], "Imports, and LO": [[17, "imports-and-lo"], [18, "imports-and-lo"]], "Imports, announcements, LOs": [[41, "imports-announcements-los"]], "Imports, announcements, and LOs": [[22, "imports-announcements-and-los"], [34, "imports-announcements-and-los"]], "Imputation": [[16, "imputation"], [23, "imputation"], [35, "imputation"]], "Imputation and scaling [video]": [[16, "imputation-and-scaling-video"], [23, "imputation-and-scaling-video"], [35, "imputation-and-scaling-video"]], "Incorporating ordinal feature class_attendance": [[17, "incorporating-ordinal-feature-class-attendance"], [24, "incorporating-ordinal-feature-class-attendance"], [36, "incorporating-ordinal-feature-class-attendance"]], "Incorporating text features": [[28, "incorporating-text-features"]], "Increasing the threshold": [[39, "increasing-the-threshold"]], "Indexing Dataframes": [[8, "indexing-dataframes"]], "Indexing cheatsheet": [[8, "indexing-cheatsheet"]], "Inertia": [[44, "inertia"]], "Initial analysis, EDA, preprocessing": [[52, "initial-analysis-eda-preprocessing"]], "Initialization of K-Means": [[44, "initialization-of-k-means"]], "Inject randomness in the classifier construction": [[41, "inject-randomness-in-the-classifier-construction"]], "Input data": [[12, "input-data"], [19, "input-data"], [31, "input-data"]], "Input features X and target y": [[12, "input-features-x-and-target-y"], [19, "input-features-x-and-target-y"], [31, "input-features-x-and-target-y"]], "Installing Python packages": [[10, "installing-python-packages"]], "Instructional Material": [[0, "instructional-material"]], "Instructors": [[1, "instructors"]], "Interesting to you != useful to the reader (aka it\u2019s not about you)": [[51, "interesting-to-you-useful-to-the-reader-aka-it-s-not-about-you"]], "Interim summary": [[39, "interim-summary"], [42, "interim-summary"], [43, "interim-summary"], [49, "interim-summary"]], "Interpretation of coefficients": [[18, "interpretation-of-coefficients"], [37, "interpretation-of-coefficients"]], "Interpretation of coefficients in linear models": [[18, "interpretation-of-coefficients-in-linear-models"], [37, "interpretation-of-coefficients-in-linear-models"]], "Interpreting coefficients of numeric features": [[42, "interpreting-coefficients-of-numeric-features"]], "Introduction": [[45, "introduction"], [55, "introduction"]], "Introduction to NLP": [[55, "introduction-to-nlp"]], "Introduction to computer vision": [[48, "introduction-to-computer-vision"]], "Introduction to neural networks": [[48, "introduction-to-neural-networks"]], "Introduction to pandas": [[8, "introduction-to-pandas"]], "Introduction to unsupervised learning": [[44, "introduction-to-unsupervised-learning"]], "Is it possible to further improve the scores?": [[53, "is-it-possible-to-further-improve-the-scores"]], "Is stratifying a good idea?": [[39, "is-stratifying-a-good-idea"]], "Is this a realistic representation of text data?": [[17, "is-this-a-realistic-representation-of-text-data"], [24, "is-this-a-realistic-representation-of-text-data"], [36, "is-this-a-realistic-representation-of-text-data"]], "Is this misleading?": [[51, "is-this-misleading"]], "Is \u201cRelevance\u201d clearly defined?": [[43, "is-relevance-clearly-defined"], [43, "id2"], [43, "id3"], [43, "id4"], [43, "id5"], [43, "id6"], [43, "id7"]], "K-Means algorithm": [[44, "k-means-algorithm"]], "K-Means clustering [video]": [[44, "k-means-clustering-video"]], "K-Means example": [[44, "k-means-example"]], "K-Means limitations": [[45, "k-means-limitations"]], "K-Means limitations: Shape of K-Means clusters": [[45, "k-means-limitations-shape-of-k-means-clusters"]], "K-Means recap": [[45, "k-means-recap"]], "K-Means: failure case 1": [[45, "k-means-failure-case-1"]], "K-Means: failure case 2": [[45, "k-means-failure-case-2"]], "K-Means: failure case 3": [[45, "k-means-failure-case-3"]], "Kaplan-Meier survival curve": [[50, "kaplan-meier-survival-curve"]], "Key point": [[42, "key-point"]], "LDA topics in social media": [[47, "lda-topics-in-social-media"]], "LICENSE": [[0, null]], "Labeled vs. Unlabeled data": [[44, "labeled-vs-unlabeled-data"]], "Lag-based features": [[49, "lag-based-features"], [49, "id5"]], "Land acknowledgement": [[59, "land-acknowledgement"]], "Large datasets solve many of these problems": [[38, "large-datasets-solve-many-of-these-problems"]], "Late submissions": [[7, "late-submissions"]], "Learned coefficients associated with all features": [[18, "learned-coefficients-associated-with-all-features"], [37, "learned-coefficients-associated-with-all-features"]], "Learned model": [[26, "learned-model"]], "Learning git": [[5, "learning-git"]], "Learning objectives": [[47, "learning-objectives"], [48, "learning-objectives"], [49, "learning-objectives"], [50, "learning-objectives"], [51, "learning-objectives"], [52, "learning-objectives"]], "Learning outcomes": [[12, "learning-outcomes"], [13, "learning-outcomes"], [14, "learning-outcomes"], [15, "learning-outcomes"], [16, "learning-outcomes"], [17, "learning-outcomes"], [18, "learning-outcomes"], [19, "learning-outcomes"], [20, "learning-outcomes"], [21, "learning-outcomes"], [22, "learning-outcomes"], [23, "learning-outcomes"], [24, "learning-outcomes"], [31, "learning-outcomes"], [32, "learning-outcomes"], [33, "learning-outcomes"], [34, "learning-outcomes"], [35, "learning-outcomes"], [36, "learning-outcomes"], [37, "learning-outcomes"], [38, "learning-outcomes"], [39, "learning-outcomes"], [40, "learning-outcomes"], [42, "learning-outcomes"], [43, "learning-outcomes"], [44, "learning-outcomes"], [45, "learning-outcomes"]], "Learning outcomes <a name=\"lo\"></a>": [[46, "learning-outcomes"]], "Least confident cases": [[18, "least-confident-cases"], [37, "least-confident-cases"]], "Lecture 10: Regression metrics": [[40, null]], "Lecture 12: Ensembles": [[41, null]], "Lecture 13: Feature importances and model transparency": [[42, null]], "Lecture 14: Feature engineering and feature selection": [[43, null]], "Lecture 15: K-Means Clustering": [[44, null]], "Lecture 16: More Clustering": [[45, null]], "Lecture 17: Recommender Systems": [[46, null]], "Lecture 18: Introduction to natural language processing": [[47, null]], "Lecture 19: Multi-class classification and introduction to computer vision": [[48, null]], "Lecture 1: Course Introduction": [[12, null], [19, null], [31, null]], "Lecture 20: Time series": [[49, null]], "Lecture 21: Survival analysis": [[50, null]], "Lecture 22: Communication": [[51, null]], "Lecture 24: Deployment and conclusion": [[52, null]], "Lecture 2: Terminology, Baselines, Decision Trees": [[13, null], [20, null], [32, null]], "Lecture 3: ML Fundamentals Class Demo": [[26, null]], "Lecture 3: Machine Learning Fundamentals": [[14, null], [21, null], [33, null]], "Lecture 4: Class demo": [[27, null]], "Lecture 4: k-Nearest Neighbours and SVM RBFs": [[15, null], [22, null], [34, null]], "Lecture 5 and 6: Class demo": [[28, null]], "Lecture 5: Preprocessing and sklearn pipelines": [[16, null], [23, null], [35, null]], "Lecture 6: sklearn ColumnTransformer and Text Features": [[17, null], [24, null], [36, null]], "Lecture 7: Linear Models": [[18, null], [37, null]], "Lecture 8: Hyperparameter Optimization and Optimization Bias": [[38, null]], "Lecture 9: Classification metrics": [[39, null]], "Lecture and homework format: Jupyter notebooks": [[12, "lecture-and-homework-format-jupyter-notebooks"], [19, "lecture-and-homework-format-jupyter-notebooks"]], "Lecture learning objectives": [[41, "lecture-learning-objectives"]], "Lecture plan and learning outcomes": [[45, "lecture-plan-and-learning-outcomes"]], "Lecture recordings": [[59, "lecture-recordings"]], "Lecture schedule (tentative)": [[1, "lecture-schedule-tentative"]], "Lecture style": [[12, "lecture-style"], [19, "lecture-style"]], "Lectures 7: Class demo": [[29, null], [30, null]], "Let\u2019s do it on our housing data": [[16, "let-s-do-it-on-our-housing-data"], [23, "let-s-do-it-on-our-housing-data"], [35, "let-s-do-it-on-our-housing-data"]], "Let\u2019s examine the transformed data": [[17, "let-s-examine-the-transformed-data"], [24, "let-s-examine-the-transformed-data"], [36, "let-s-examine-the-transformed-data"]], "Let\u2019s explore SVM RBFs": [[15, "let-s-explore-svm-rbfs"], [22, "let-s-explore-svm-rbfs"], [34, "let-s-explore-svm-rbfs"]], "Let\u2019s first run our baseline model DummyRegressor": [[16, "let-s-first-run-our-baseline-model-dummyregressor"], [23, "let-s-first-run-our-baseline-model-dummyregressor"], [35, "let-s-first-run-our-baseline-model-dummyregressor"]], "Let\u2019s identify feature types": [[42, "let-s-identify-feature-types"]], "Let\u2019s look at all the scores at once": [[39, "let-s-look-at-all-the-scores-at-once"]], "Let\u2019s separate X and y": [[40, "let-s-separate-x-and-y"], [42, "let-s-separate-x-and-y"], [51, "let-s-separate-x-and-y"]], "Let\u2019s try KNN on this data": [[28, "let-s-try-knn-on-this-data"]], "Let\u2019s try a linear model: Ridge": [[40, "let-s-try-a-linear-model-ridge"]], "Let\u2019s try cross-validation with our pipeline": [[16, "let-s-try-cross-validation-with-our-pipeline"], [23, "let-s-try-cross-validation-with-our-pipeline"], [35, "let-s-try-cross-validation-with-our-pipeline"]], "License": [[1, "license"]], "LightGBM": [[41, "lightgbm"]], "Limitations of linear models": [[18, "limitations-of-linear-models"], [37, "limitations-of-linear-models"]], "Linear SVM": [[18, "linear-svm"], [37, "linear-svm"]], "Linear models [video]": [[18, "linear-models-video"], [37, "linear-models-video"]], "Linear regression": [[18, "linear-regression"], [37, "linear-regression"]], "Lists of resources": [[9, "lists-of-resources"]], "Loading our saved model": [[52, "loading-our-saved-model"]], "Logistic regression [video]": [[18, "logistic-regression-video"], [37, "logistic-regression-video"]], "Logistic regression intuition": [[18, "logistic-regression-intuition"], [37, "logistic-regression-intuition"]], "Logistic regression on the cities data": [[18, "logistic-regression-on-the-cities-data"], [37, "logistic-regression-on-the-cities-data"]], "Logistic regression with flattened representation of images": [[48, "logistic-regression-with-flattened-representation-of-images"]], "LogisticRegression": [[49, "logisticregression"], [50, "logisticregression"]], "MAPE": [[40, "mape"]], "ML and decision-making (5 min)": [[51, "ml-and-decision-making-5-min"]], "ML fairness activity (~5 mins)": [[39, "ml-fairness-activity-5-mins"]], "ML fundamentals": [[55, "ml-fundamentals"]], "Mac Users": [[5, "mac-users"]], "Machine learning workflow": [[12, "machine-learning-workflow"], [31, "machine-learning-workflow"], [39, "machine-learning-workflow"]], "Magnitude of the coefficients": [[18, "magnitude-of-the-coefficients"], [37, "magnitude-of-the-coefficients"]], "Main hyperparameter of logistic regression": [[18, "main-hyperparameter-of-logistic-regression"], [37, "main-hyperparameter-of-logistic-regression"]], "Main hyperparameters": [[18, "main-hyperparameters"], [37, "main-hyperparameters"]], "Main issues in ML-related communication": [[51, "main-issues-in-ml-related-communication"]], "Manual hyperparameter optimization": [[38, "manual-hyperparameter-optimization"]], "Mean intra-cluster distance (a)": [[44, "mean-intra-cluster-distance-a"]], "Mean nearest-cluster distance (b)": [[44, "mean-nearest-cluster-distance-b"]], "Mean squared error (MSE)": [[40, "mean-squared-error-mse"]], "Meet Eva (a fictitious persona)!": [[12, "meet-eva-a-fictitious-persona"], [19, "meet-eva-a-fictitious-persona"], [31, "meet-eva-a-fictitious-persona"]], "Method 1: The Elbow method": [[44, "method-1-the-elbow-method"]], "Method 2: The Silhouette method": [[44, "method-2-the-silhouette-method"]], "Midterms": [[59, "midterms"]], "Misc": [[1, "misc"], [9, "misc"]], "Miscellaneous comments on content-based filtering": [[46, "miscellaneous-comments-on-content-based-filtering"]], "Model building": [[40, "model-building"], [52, "model-building"]], "Model building on the dataset": [[29, "model-building-on-the-dataset"], [30, "model-building-on-the-dataset"]], "Model complexity and training error": [[14, "model-complexity-and-training-error"], [21, "model-complexity-and-training-error"], [33, "model-complexity-and-training-error"]], "Model deployment": [[52, "model-deployment"], [52, "id1"]], "Model interpretability beyond linear models": [[42, "model-interpretability-beyond-linear-models"]], "Model predictions on unseen data": [[12, "model-predictions-on-unseen-data"], [19, "model-predictions-on-unseen-data"], [31, "model-predictions-on-unseen-data"]], "Model transparency and interpretation": [[52, "model-transparency-and-interpretation"]], "Model-based selection": [[43, "model-based-selection"]], "Modeling": [[28, "modeling"]], "More comments on tackling class imbalance": [[40, "more-comments-on-tackling-class-imbalance"]], "More details": [[21, "more-details"]], "More details on DBSCAN": [[45, "more-details-on-dbscan"]], "More on feature transformations": [[17, "more-on-feature-transformations"], [24, "more-on-feature-transformations"], [36, "more-on-feature-transformations"]], "More on k-NNs [video]": [[15, "more-on-k-nns-video"], [22, "more-on-k-nns-video"], [34, "more-on-k-nns-video"]], "More terminology [video]": [[13, "more-terminology-video"], [20, "more-terminology-video"], [32, "more-terminology-video"]], "More than one ordinal columns?": [[17, "more-than-one-ordinal-columns"], [24, "more-than-one-ordinal-columns"], [36, "more-than-one-ordinal-columns"]], "Most confident cases": [[18, "most-confident-cases"], [37, "most-confident-cases"]], "Most negative review": [[29, "most-negative-review"], [30, "most-negative-review"]], "Most positive review": [[29, "most-positive-review"], [30, "most-positive-review"]], "Motivating example": [[18, "motivating-example"], [37, "motivating-example"]], "Motivation": [[38, "motivation"], [49, "motivation"], [51, "motivation"]], "Motivation [video]": [[41, "motivation-video"]], "Motivation and big picture [video]": [[16, "motivation-and-big-picture-video"], [23, "motivation-and-big-picture-video"], [35, "motivation-and-big-picture-video"]], "Motivation and context": [[47, "motivation-and-context"]], "Motivation and distances [video]": [[15, "motivation-and-distances-video"], [22, "motivation-and-distances-video"], [34, "motivation-and-distances-video"]], "Movie features": [[46, "movie-features"]], "Multi-class classification": [[48, "multi-class-classification"]], "Multiclass classification and computer vision": [[55, "multiclass-classification-and-computer-vision"]], "Multiple transformations in a transformer": [[17, "multiple-transformations-in-a-transformer"], [24, "multiple-transformations-in-a-transformer"], [36, "multiple-transformations-in-a-transformer"]], "NOTE:": [[8, "note"]], "New ideas in small chunks": [[51, "new-ideas-in-small-chunks"]], "No-loop method: make them the same size, and multiply element-wise": [[8, "no-loop-method-make-them-the-same-size-and-multiply-element-wise"]], "Note": [[14, null], [14, null], [33, null], [33, null], [49, null]], "Number of trees and fundamental trade-off": [[41, "number-of-trees-and-fundamental-trade-off"]], "Numpy array shapes": [[8, "numpy-array-shapes"]], "Numpy arrays": [[8, "numpy-arrays"]], "OHE with many categories": [[17, "ohe-with-many-categories"], [36, "ohe-with-many-categories"]], "Object detection": [[48, "object-detection"]], "Observations": [[39, "observations"]], "One Vs. One approach": [[54, "one-vs-one-approach"]], "One Vs. One prediction": [[54, "one-vs-one-prediction"]], "One vs. Rest": [[54, "one-vs-rest"]], "One-hot encoding (OHE)": [[16, "one-hot-encoding-ohe"], [23, "one-hot-encoding-ohe"], [35, "one-hot-encoding-ohe"]], "One-hot encoding of the month": [[49, "one-hot-encoding-of-the-month"]], "One-hot encoding seasons": [[49, "one-hot-encoding-seasons"]], "OneHotEncoder and sparse features": [[17, "onehotencoder-and-sparse-features"], [24, "onehotencoder-and-sparse-features"], [36, "onehotencoder-and-sparse-features"]], "Online courses": [[1, "online-courses"], [9, "online-courses"]], "Operating point": [[39, "operating-point"]], "Optimization bias of hyper-parameter learning": [[38, "optimization-bias-of-hyper-parameter-learning"]], "Optimization bias of parameter learning": [[38, "optimization-bias-of-parameter-learning"]], "Optimization bias on the Spotify dataset": [[38, "optimization-bias-on-the-spotify-dataset"]], "Optimization bias/Overfitting of the validation set": [[38, "optimization-bias-overfitting-of-the-validation-set"]], "Optional readings and resources": [[38, "optional-readings-and-resources"]], "Ordinal encoding (occasionally recommended)": [[16, "ordinal-encoding-occasionally-recommended"], [23, "ordinal-encoding-occasionally-recommended"], [35, "ordinal-encoding-occasionally-recommended"]], "Ordinal features": [[28, "ordinal-features"], [42, "ordinal-features"]], "Other applications": [[44, "other-applications"]], "Other approaches / what did we not cover?": [[50, "other-approaches-what-did-we-not-cover"]], "Other commonly used preprocessing steps": [[47, "other-commonly-used-preprocessing-steps"]], "Other possible preprocessing?": [[40, "other-possible-preprocessing"]], "Other software package": [[49, "other-software-package"]], "Other tools for preprocessing": [[47, "other-tools-for-preprocessing"]], "Other typical NLP tasks": [[47, "other-typical-nlp-tasks"]], "Other useful arguments of KNeighborsClassifier": [[15, "other-useful-arguments-of-kneighborsclassifier"], [22, "other-useful-arguments-of-kneighborsclassifier"], [34, "other-useful-arguments-of-kneighborsclassifier"]], "Other ways to search": [[43, "other-ways-to-search"]], "Our typical supervised learning set up is as follows:": [[14, "our-typical-supervised-learning-set-up-is-as-follows"], [21, "our-typical-supervised-learning-set-up-is-as-follows"], [33, "our-typical-supervised-learning-set-up-is-as-follows"]], "Outline": [[56, "outline"], [57, "outline"], [58, "outline"]], "Over confident cases": [[18, "over-confident-cases"], [37, "over-confident-cases"]], "Overfitting": [[14, "overfitting"], [21, "overfitting"], [33, "overfitting"]], "Overfitting of the validation data": [[38, "overfitting-of-the-validation-data"]], "Overfitting of the validation error": [[38, "overfitting-of-the-validation-error"]], "Oversampling": [[39, "oversampling"]], "Overview": [[15, "overview"], [22, "overview"], [34, "overview"]], "POSIX time feature": [[49, "posix-time-feature"]], "PR curves for logistic regression and SVC": [[39, "pr-curves-for-logistic-regression-and-svc"]], "Pandas DataFrames": [[8, "pandas-dataframes"]], "Pandas Series": [[8, "pandas-series"]], "Parameters": [[13, "parameters"], [20, "parameters"], [32, "parameters"]], "Parameters and hyperparameters: Summary": [[13, "parameters-and-hyperparameters-summary"], [20, "parameters-and-hyperparameters-summary"], [32, "parameters-and-hyperparameters-summary"]], "Parsing datetimes": [[49, "parsing-datetimes"]], "Part 1": [[55, "part-1"]], "Part 2": [[55, "part-2"]], "Piazza-specific Q&A guidelines": [[4, "piazza-specific-q-a-guidelines"]], "Pipelines": [[16, "pipelines"], [23, "pipelines"], [35, "pipelines"]], "Playground": [[15, "playground"], [34, "playground"]], "Playground (in tutorial)": [[22, "playground-in-tutorial"]], "Plotting with matplotlib": [[8, "plotting-with-matplotlib"]], "Practice exercises": [[20, "practice-exercises"], [32, "practice-exercises"]], "Precision": [[39, "precision"]], "Precision and recall: toy example": [[39, "precision-and-recall-toy-example"]], "Precision, recall, f1 score": [[39, "precision-recall-f1-score"]], "Precision-recall curve": [[39, "precision-recall-curve"], [39, "id1"]], "Precision/Recall tradeoff": [[39, "precision-recall-tradeoff"]], "Predicting on unseen data using the trained model": [[12, "predicting-on-unseen-data-using-the-trained-model"], [19, "predicting-on-unseen-data-using-the-trained-model"], [31, "predicting-on-unseen-data-using-the-trained-model"]], "Predicting probability scores [video]": [[18, "predicting-probability-scores-video"], [37, "predicting-probability-scores-video"]], "Predicting with learned weights": [[18, "predicting-with-learned-weights"], [37, "predicting-with-learned-weights"]], "Prediction": [[50, "prediction"]], "Prediction of linear regression": [[18, "prediction-of-linear-regression"], [37, "prediction-of-linear-regression"]], "Prediction with learned parameters": [[18, "prediction-with-learned-parameters"], [37, "prediction-with-learned-parameters"]], "Predictions": [[48, "predictions"]], "Preferences in LogisticRegression": [[51, "preferences-in-logisticregression"]], "Preparation": [[7, "preparation"]], "Preprocessing": [[17, "preprocessing"], [24, "preprocessing"], [36, "preprocessing"], [49, "preprocessing"], [55, "preprocessing"]], "Preprocessing the targets?": [[17, "preprocessing-the-targets"], [24, "preprocessing-the-targets"], [36, "preprocessing-the-targets"]], "Prevalence of ML": [[12, "prevalence-of-ml"], [19, "prevalence-of-ml"], [31, "prevalence-of-ml"]], "Principles of effective communication": [[51, "principles-of-effective-communication"]], "Principles of good explanations (~15 min)": [[51, "principles-of-good-explanations-15-min"]], "Problem formulation": [[46, "problem-formulation"]], "Problem: Different transformations on different columns": [[16, "problem-different-transformations-on-different-columns"], [23, "problem-different-transformations-on-different-columns"], [35, "problem-different-transformations-on-different-columns"]], "Problems with exhaustive grid search": [[38, "problems-with-exhaustive-grid-search"]], "Problems with single train/validation split": [[14, "problems-with-single-train-validation-split"], [21, "problems-with-single-train-validation-split"], [33, "problems-with-single-train-validation-split"]], "Pros of k-NNs for supervised learning": [[15, "pros-of-k-nns-for-supervised-learning"], [22, "pros-of-k-nns-for-supervised-learning"], [34, "pros-of-k-nns-for-supervised-learning"]], "Pros, cons, parameters and hyperparameters of different ML models": [[55, "pros-cons-parameters-and-hyperparameters-of-different-ml-models"]], "Python and Conda": [[10, "python-and-conda"]], "Python requirements/resources": [[12, "python-requirements-resources"], [19, "python-requirements-resources"]], "Python resources": [[9, "python-resources"]], "Question": [[15, "question"], [22, "question"], [34, "question"]], "Question for you": [[45, "question-for-you"]], "Question for you to ponder on": [[29, "question-for-you-to-ponder-on"], [30, "question-for-you-to-ponder-on"]], "Questions for class discussion": [[46, "questions-for-class-discussion"]], "Questions for class discussion (hyperparameter optimization)": [[38, "questions-for-class-discussion-hyperparameter-optimization"]], "Quick recap": [[15, "quick-recap"], [34, "quick-recap"]], "RF better than GB": [[51, "rf-better-than-gb"]], "RFE algorithm": [[43, "rfe-algorithm"]], "R^2 (not in detail)": [[40, "r-2-not-in-detail"]], "Random forest feature importances": [[42, "random-forest-feature-importances"]], "Random forests": [[41, "random-forests"]], "Random forests: number of trees (n_estimators) and the fundamental tradeoff": [[41, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"]], "RandomForestClassifier": [[41, "randomforestclassifier"], [50, "randomforestclassifier"]], "Randomized hyperparameter search": [[38, "randomized-hyperparameter-search"]], "Range of C": [[38, "range-of-c"]], "Raw scores": [[18, "raw-scores"], [37, "raw-scores"]], "Reading from .csv": [[8, "reading-from-csv"]], "Reading from other formats": [[8, "reading-from-other-formats"]], "Reading from url": [[8, "reading-from-url"]], "Reading the data": [[13, "reading-the-data"], [20, "reading-the-data"], [32, "reading-the-data"], [48, "reading-the-data"]], "Real boundary between Canada and USA": [[13, "real-boundary-between-canada-and-usa"], [32, "real-boundary-between-canada-and-usa"], [56, "real-boundary-between-canada-and-usa"]], "Reasonable grading concerns": [[6, "reasonable-grading-concerns"]], "Recall": [[39, "recall"]], "Recap": [[50, "recap"], [51, "recap"]], "Recap and motivation [video]": [[45, "recap-and-motivation-video"]], "Recap: Supervised machine learning": [[13, "recap-supervised-machine-learning"], [20, "recap-supervised-machine-learning"], [32, "recap-supervised-machine-learning"]], "Receiver Operating Characteristic (ROC) curve": [[39, "receiver-operating-characteristic-roc-curve"]], "Recipe to approach a supervised learning problem with tabular data": [[52, "recipe-to-approach-a-supervised-learning-problem-with-tabular-data"]], "Recommended browser": [[12, "recommended-browser"], [19, "recommended-browser"]], "Recommender systems": [[55, "recommender-systems"]], "Recommender systems intro and motivation": [[46, "recommender-systems-intro-and-motivation"]], "Recommender systems problem": [[46, "recommender-systems-problem"]], "Recursive feature elimination (RFE)": [[43, "recursive-feature-elimination-rfe"]], "Reference Material": [[1, "reference-material"]], "Reference material": [[9, null]], "References": [[50, "references"]], "Registration": [[59, "registration"]], "Registration, waitlist and prerequisites": [[12, "registration-waitlist-and-prerequisites"], [19, "registration-waitlist-and-prerequisites"]], "Regression scoring functions": [[40, "regression-scoring-functions"]], "Regression with k-nearest neighbours (k-NNs)": [[15, "regression-with-k-nearest-neighbours-k-nns"], [22, "regression-with-k-nearest-neighbours-k-nns"], [34, "regression-with-k-nearest-neighbours-k-nns"]], "Relation of C and the fundamental trade-off": [[15, "relation-of-c-and-the-fundamental-trade-off"], [22, "relation-of-c-and-the-fundamental-trade-off"], [34, "relation-of-c-and-the-fundamental-trade-off"]], "Relation of gamma and the fundamental trade-off": [[15, "relation-of-gamma-and-the-fundamental-trade-off"], [22, "relation-of-gamma-and-the-fundamental-trade-off"], [34, "relation-of-gamma-and-the-fundamental-trade-off"]], "Relevant companion materials": [[9, "relevant-companion-materials"]], "Relevant papers": [[41, "relevant-papers"]], "Relevant papers and resources": [[39, "relevant-papers-and-resources"]], "Relevant resources": [[43, "relevant-resources"]], "Reminder": [[46, "reminder"]], "Renaming columns with df.rename()": [[8, "renaming-columns-with-df-rename"]], "Render set-up (I already did these):": [[52, "render-set-up-i-already-did-these"]], "Report format": [[7, "report-format"]], "Requirements (I already did these)": [[52, "requirements-i-already-did-these"]], "Resources": [[44, "resources"], [45, "resources"], [46, "resources"]], "Reuse your running examples": [[51, "reuse-your-running-examples"]], "Ridge": [[18, "ridge"], [37, "ridge"]], "Ridge on the California housing dataset": [[18, "ridge-on-the-california-housing-dataset"], [37, "ridge-on-the-california-housing-dataset"]], "RidgeCV": [[40, "ridgecv"]], "Root mean squared error or RMSE": [[40, "root-mean-squared-error-or-rmse"]], "SHAP  (SHapley Additive exPlanations) introduction": [[42, "shap-shapley-additive-explanations-introduction"]], "SHAP plots": [[42, "shap-plots"]], "SMOTE idea": [[39, "smote-idea"]], "SMOTE: Synthetic Minority Over-sampling Technique": [[39, "smote-synthetic-minority-over-sampling-technique"]], "SVM Regressor": [[15, "svm-regressor"], [22, "svm-regressor"], [34, "svm-regressor"]], "Saving the model": [[52, "saving-the-model"]], "Saving time and scaling products": [[12, "saving-time-and-scaling-products"], [19, "saving-time-and-scaling-products"], [31, "saving-time-and-scaling-products"]], "Scaling": [[16, "scaling"], [23, "scaling"], [35, "scaling"]], "Scaling using scikit-learn\u2019s StandardScaler": [[16, "scaling-using-scikit-learn-s-standardscaler"], [23, "scaling-using-scikit-learn-s-standardscaler"], [35, "scaling-using-scikit-learn-s-standardscaler"]], "Search over multiple hyperparameters": [[15, "search-over-multiple-hyperparameters"], [22, "search-over-multiple-hyperparameters"], [34, "search-over-multiple-hyperparameters"]], "Seasonality and trends": [[49, "seasonality-and-trends"]], "Select all of the following statements which are True (iClicker)": [[12, "select-all-of-the-following-statements-which-are-true-iclicker"], [19, "select-all-of-the-following-statements-which-are-true-iclicker"], [31, "select-all-of-the-following-statements-which-are-true-iclicker"]], "Sending a request to the API": [[52, "sending-a-request-to-the-api"]], "Setting up": [[5, "setting-up"]], "Setting up a virtual environment: Conda environments": [[10, "setting-up-a-virtual-environment-conda-environments"]], "Setting up coding environment": [[10, null]], "Setting up your computer for the course": [[12, "setting-up-your-computer-for-the-course"], [19, "setting-up-your-computer-for-the-course"]], "Short posts/articles": [[9, "short-posts-articles"]], "Sigmoid vs. Softmax": [[48, "sigmoid-vs-softmax"]], "Sign of the coefficients": [[18, "sign-of-the-coefficients"], [37, "sign-of-the-coefficients"]], "Silhouette distance for a sample": [[44, "silhouette-distance-for-a-sample"]], "Similarity between examples": [[15, "similarity-between-examples"], [22, "similarity-between-examples"], [34, "similarity-between-examples"]], "Simple feature engineering for our problem.": [[53, "simple-feature-engineering-for-our-problem"]], "Simple train/test split": [[14, "simple-train-test-split"], [21, "simple-train-test-split"], [33, "simple-train-test-split"]], "SimpleFeature correlations": [[42, "simplefeature-correlations"]], "Single validation set": [[26, "single-validation-set"]], "Slowest method: nested loop": [[8, "slowest-method-nested-loop"]], "Software": [[0, "software"]], "Some important hyperparameters:": [[41, "some-important-hyperparameters"]], "Some key takeaways": [[52, "some-key-takeaways"]], "Some quotes on feature engineering": [[43, "some-quotes-on-feature-engineering"]], "Some terminology related to trees": [[13, "some-terminology-related-to-trees"], [20, "some-terminology-related-to-trees"], [32, "some-terminology-related-to-trees"]], "Some ways to pick hyperparameters:": [[38, "some-ways-to-pick-hyperparameters"]], "Sorting a dataframe with df.sort_values()": [[8, "sorting-a-dataframe-with-df-sort-values"]], "Spam/non spam toy example": [[17, "spam-non-spam-toy-example"], [24, "spam-non-spam-toy-example"], [36, "spam-non-spam-toy-example"]], "Specific questions": [[4, "specific-questions"]], "Stacking": [[41, "stacking"]], "Step 1": [[58, "step-1"]], "Step 2": [[58, "step-2"]], "Step 3": [[58, "step-3"]], "Step 4": [[58, "step-4"]], "Step 5": [[58, "step-5"]], "Steps to train a classifier using sklearn": [[13, "steps-to-train-a-classifier-using-sklearn"], [20, "steps-to-train-a-classifier-using-sklearn"], [32, "steps-to-train-a-classifier-using-sklearn"]], "Stratified Splits": [[39, "stratified-splits"]], "Strengths and weaknesses": [[41, "strengths-and-weaknesses"]], "Strengths of linear models": [[18, "strengths-of-linear-models"], [37, "strengths-of-linear-models"]], "Study tips": [[55, "study-tips"]], "Submitting on Gradescope": [[7, "submitting-on-gradescope"]], "Summary": [[12, "summary"], [15, "summary"], [19, "summary"], [22, "summary"], [31, "summary"], [34, "summary"], [41, "summary"], [47, "summary"], [48, "summary"], [50, "summary"]], "Summary and reflection": [[14, "summary-and-reflection"], [21, "summary-and-reflection"], [33, "summary-and-reflection"]], "Summary of linear models": [[18, "summary-of-linear-models"], [37, "summary-of-linear-models"]], "Summary of train, validation, test, and deployment data": [[14, "summary-of-train-validation-test-and-deployment-data"], [21, "summary-of-train-validation-test-and-deployment-data"], [33, "summary-of-train-validation-test-and-deployment-data"]], "Summary: Pros and cons": [[45, "summary-pros-and-cons"]], "Supervised approach to rating prediction": [[46, "supervised-approach-to-rating-prediction"]], "Supervised learning": [[44, "supervised-learning"]], "Supervised learning (Reminder)": [[13, "supervised-learning-reminder"], [32, "supervised-learning-reminder"]], "Supervised learning vs. Unsupervised learning": [[13, "supervised-learning-vs-unsupervised-learning"], [20, "supervised-learning-vs-unsupervised-learning"], [32, "supervised-learning-vs-unsupervised-learning"]], "Supervised machine learning": [[12, "supervised-machine-learning"], [19, "supervised-machine-learning"], [31, "supervised-machine-learning"]], "Support Vector Machines (SVMs) with RBF kernel [video]": [[15, "support-vector-machines-svms-with-rbf-kernel-video"], [22, "support-vector-machines-svms-with-rbf-kernel-video"], [34, "support-vector-machines-svms-with-rbf-kernel-video"]], "Support vectors": [[15, "support-vectors"], [22, "support-vectors"], [34, "support-vectors"]], "Survival analysis": [[55, "survival-analysis"]], "Survival plots": [[50, "survival-plots"]], "Syllabus": [[1, "syllabus"], [59, null]], "TAs": [[1, "tas"], [59, "tas"]], "Tabular data": [[13, "tabular-data"], [20, "tabular-data"], [32, "tabular-data"]], "Take-home message": [[45, "take-home-message"]], "Teaching Team": [[59, "teaching-team"]], "Terminology": [[48, "terminology"]], "Terminology [video]": [[13, "terminology-video"], [20, "terminology-video"], [32, "terminology-video"]], "Testing your git installation": [[5, "testing-your-git-installation"]], "The Netflix prize": [[41, "the-netflix-prize"]], "The __ syntax": [[38, "the-syntax"]], "The best features may be dependent on the model you use.": [[43, "the-best-features-may-be-dependent-on-the-model-you-use"]], "The golden rule <a name=\"4\"></a>": [[14, "the-golden-rule"], [21, "the-golden-rule"], [33, "the-golden-rule"]], "The random forests classifier": [[41, "the-random-forests-classifier"]], "The sigmoid function": [[18, "the-sigmoid-function"], [37, "the-sigmoid-function"]], "The teaching team": [[1, "the-teaching-team"]], "The \u201cfundamental tradeoff\u201d of supervised learning:": [[14, "the-fundamental-tradeoff-of-supervised-learning"], [21, "the-fundamental-tradeoff-of-supervised-learning"], [33, "the-fundamental-tradeoff-of-supervised-learning"]], "The \u201cperfect\u201d spaghetti sauce": [[44, "the-perfect-spaghetti-sauce"]], "Things to watch out for": [[51, "things-to-watch-out-for"]], "Time series": [[55, "time-series"]], "Time to event and censoring": [[50, "time-to-event-and-censoring"]], "Tokenization": [[47, "tokenization"]], "Topic modeling": [[47, "topic-modeling"]], "Topic modeling motivation": [[47, "topic-modeling-motivation"]], "Topic modeling pipeline": [[47, "topic-modeling-pipeline"]], "Topic modeling toy example": [[47, "topic-modeling-toy-example"]], "Toy datasets": [[13, "toy-datasets"], [32, "toy-datasets"]], "Traditional time series approaches": [[49, "traditional-time-series-approaches"]], "Train/test split for temporal data": [[49, "train-test-split-for-temporal-data"]], "Train/test splits": [[49, "train-test-splits"]], "Train/validation/test split": [[14, "train-validation-test-split"], [21, "train-validation-test-split"], [33, "train-validation-test-split"]], "Training a supervised machine learning model with X and y": [[12, "training-a-supervised-machine-learning-model-with-x-and-y"], [19, "training-a-supervised-machine-learning-model-with-x-and-y"], [31, "training-a-supervised-machine-learning-model-with-x-and-y"]], "Training data for the motivating example": [[18, "training-data-for-the-motivating-example"], [37, "training-data-for-the-motivating-example"]], "Training error vs. Generalization error": [[14, "training-error-vs-generalization-error"], [21, "training-error-vs-generalization-error"], [33, "training-error-vs-generalization-error"]], "Training models with transformed data": [[17, "training-models-with-transformed-data"], [24, "training-models-with-transformed-data"], [36, "training-models-with-transformed-data"]], "Training on the full corpus": [[52, "training-on-the-full-corpus"]], "Training random forests and gradient boosted trees": [[51, "training-random-forests-and-gradient-boosted-trees"]], "Transfer learning": [[48, "transfer-learning"]], "Transformations on the toy data": [[17, "transformations-on-the-toy-data"], [24, "transformations-on-the-toy-data"], [36, "transformations-on-the-toy-data"]], "Transforming the targets": [[40, "transforming-the-targets"]], "Transparency and explainability of ML models: Motivation": [[42, "transparency-and-explainability-of-ml-models-motivation"]], "Tree-based ensemble models": [[41, "tree-based-ensemble-models"]], "Tree-based models": [[41, "tree-based-models"]], "Try out this moment predictor": [[52, "try-out-this-moment-predictor"]], "Tuning alpha hyperparameter of Ridge": [[40, "tuning-alpha-hyperparameter-of-ridge"]], "Tutorial 1": [[56, null]], "Tutorial 2": [[57, null]], "Tutorial 3": [[58, null]], "Types of censoring": [[50, "types-of-censoring"]], "Types of errors": [[14, "types-of-errors"], [21, "types-of-errors"], [33, "types-of-errors"]], "Types of machine learning": [[12, "types-of-machine-learning"], [19, "types-of-machine-learning"], [31, "types-of-machine-learning"], [44, "types-of-machine-learning"]], "Types of problems involving time series": [[49, "types-of-problems-involving-time-series"]], "Types of questions we might want to answer:": [[50, "types-of-questions-we-might-want-to-answer"]], "Typical steps to build a supervised machine learning model": [[26, "typical-steps-to-build-a-supervised-machine-learning-model"]], "UBC CPSC 330: Applied Machine Learning (2024W2)": [[1, null]], "Ubuntu Users": [[5, "ubuntu-users"]], "Underfitting": [[14, "underfitting"], [21, "underfitting"], [33, "underfitting"]], "Underfitting, overfitting, the fundamental trade-off, the golden rule [video]": [[14, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"], [21, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"], [33, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"]], "Undersampling": [[39, "undersampling"]], "Understanding the problem": [[52, "understanding-the-problem"]], "Unequally spaced time points": [[49, "unequally-spaced-time-points"]], "Unsupervised learning": [[44, "unsupervised-learning"]], "Updates to assignments": [[7, "updates-to-assignments"]], "Use of AI in the course": [[59, "use-of-ai-in-the-course"]], "Use our template to create a repository": [[7, "use-our-template-to-create-a-repository"]], "Using OVR and OVO as wrappers": [[54, "using-ovr-and-ovo-as-wrappers"]], "Using SMOTE": [[39, "using-smote"]], "Using Silhouette scores to select the number of clusters": [[44, "using-silhouette-scores-to-select-the-number-of-clusters"]], "Using multiple metrics in GridSearchCV or RandomizedSearchCV": [[40, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"]], "Using pre-trained models as feature extractor": [[48, "using-pre-trained-models-as-feature-extractor"]], "Using pre-trained models out-of-the-box": [[48, "using-pre-trained-models-out-of-the-box"]], "Using regression metrics with scikit-learn": [[40, "using-regression-metrics-with-scikit-learn"]], "Viewing the transformed data as a dataframe": [[17, "viewing-the-transformed-data-as-a-dataframe"], [24, "viewing-the-transformed-data-as-a-dataframe"], [36, "viewing-the-transformed-data-as-a-dataframe"]], "Virtual environment": [[10, "virtual-environment"]], "Visualization": [[9, "visualization"]], "Visualizing the parameter grid as a heatmap": [[38, "visualizing-the-parameter-grid-as-a-heatmap"]], "Visualizing your results": [[51, "visualizing-your-results"]], "Warning": [[13, null], [20, null], [32, null]], "Warnings about feature selection": [[43, "warnings-about-feature-selection"], [43, "id8"]], "Weaknesses": [[41, "weaknesses"]], "Web app on a real server": [[52, "web-app-on-a-real-server"]], "Web app on local server": [[52, "web-app-on-local-server"]], "What all transformations we need to apply on the dataset?": [[16, "what-all-transformations-we-need-to-apply-on-the-dataset"], [35, "what-all-transformations-we-need-to-apply-on-the-dataset"]], "What and Why": [[10, "what-and-why"]], "What are git and GitHub?": [[5, null]], "What are the options?": [[16, "what-are-the-options"], [23, "what-are-the-options"], [35, "what-are-the-options"]], "What are we exactly learning?": [[18, "what-are-we-exactly-learning"], [37, "what-are-we-exactly-learning"]], "What did we cover?": [[46, "what-did-we-cover"], [52, "what-did-we-cover"]], "What did we learn today?": [[14, "what-did-we-learn-today"], [16, "what-did-we-learn-today"], [17, "what-did-we-learn-today"], [21, "what-did-we-learn-today"], [23, "what-did-we-learn-today"], [24, "what-did-we-learn-today"], [33, "what-did-we-learn-today"], [35, "what-did-we-learn-today"], [36, "what-did-we-learn-today"], [39, "what-did-we-learn-today"], [40, "what-did-we-learn-today"], [51, "what-did-we-learn-today"]], "What does this have to do with applied ML?": [[51, "what-does-this-have-to-do-with-applied-ml"]], "What does this mean for us, when we\u2019re trying to make claims about our data?": [[51, "what-does-this-mean-for-us-when-we-re-trying-to-make-claims-about-our-data"]], "What if we apply OHE?": [[17, "what-if-we-apply-ohe"], [24, "what-if-we-apply-ohe"], [36, "what-if-we-apply-ohe"]], "What is Natural Language Processing (NLP)?": [[47, "what-is-natural-language-processing-nlp"]], "What is a recommender system?": [[46, "what-is-a-recommender-system"]], "What is clustering?": [[44, "what-is-clustering"]], "What is deployment?": [[52, "what-is-deployment"]], "What is feature engineering?": [[43, "what-is-feature-engineering"]], "What is feature selection?": [[43, "what-is-feature-selection"]], "What is grid search?": [[51, "what-is-grid-search"]], "What is model interpretability?": [[42, "what-is-model-interpretability"]], "What is supervised machine learning (ML)?": [[12, "what-is-supervised-machine-learning-ml"], [19, "what-is-supervised-machine-learning-ml"], [31, "what-is-supervised-machine-learning-ml"]], "What is \u201cpositive\u201d and \u201cnegative\u201d?": [[39, "what-is-positive-and-negative"]], "What kind of estimators can we combine?": [[41, "what-kind-of-estimators-can-we-combine"]], "What next?": [[52, "what-next"]], "What should be the loss? (Activity: 4 mins)": [[51, "what-should-be-the-loss-activity-4-mins"]], "What to look for in these plots?": [[44, "what-to-look-for-in-these-plots"]], "What transformations do we need to apply on the dataset?": [[23, "what-transformations-do-we-need-to-apply-on-the-dataset"]], "What would I do differently?": [[52, "what-would-i-do-differently"]], "What\u2019s the problem?": [[16, "what-s-the-problem"], [23, "what-s-the-problem"], [35, "what-s-the-problem"]], "When can we use broadcasting?": [[8, "when-can-we-use-broadcasting"]], "When experimenting, show the results asap": [[51, "when-experimenting-show-the-results-asap"]], "When is it OK to do things before splitting?": [[16, "when-is-it-ok-to-do-things-before-splitting"], [23, "when-is-it-ok-to-do-things-before-splitting"], [35, "when-is-it-ok-to-do-things-before-splitting"]], "When test score is much lower than CV score": [[38, "when-test-score-is-much-lower-than-cv-score"]], "Which model should I use?": [[41, "which-model-should-i-use"]], "Which type of error is more important?": [[39, "which-type-of-error-is-more-important"]], "Why do we need a test set?": [[38, "why-do-we-need-a-test-set"]], "Why do we want this information?": [[42, "why-do-we-want-this-information"]], "Why does it matter": [[21, "why-does-it-matter"]], "Why feature selection?": [[43, "why-feature-selection"]], "Why machine learning (ML)? [video]": [[12, "why-machine-learning-ml-video"], [19, "why-machine-learning-ml-video"], [31, "why-machine-learning-ml-video"]], "Why model transparency/interpretability?": [[42, "why-model-transparency-interpretability"]], "Why neural networks?": [[48, "why-neural-networks"], [48, "id1"]], "Why not neural networks?": [[48, "why-not-neural-networks"], [48, "id2"]], "Why should I use it?": [[51, "why-should-i-use-it"]], "Why should we care about effective communication?": [[51, "why-should-we-care-about-effective-communication"]], "Why should we care about recommendation systems?": [[46, "why-should-we-care-about-recommendation-systems"]], "Why sparse matrices?": [[17, "why-sparse-matrices"], [24, "why-sparse-matrices"], [36, "why-sparse-matrices"]], "Windows": [[10, "windows"]], "Windows Users": [[5, "windows-users"]], "Word embeddings": [[47, "word-embeddings"]], "Word vectors with spaCy": [[47, "word-vectors-with-spacy"]], "Writing a traditional program to predict quiz2 grade": [[13, "writing-a-traditional-program-to-predict-quiz2-grade"], [20, "writing-a-traditional-program-to-predict-quiz2-grade"], [32, "writing-a-traditional-program-to-predict-quiz2-grade"]], "XGBoost": [[41, "xgboost"]], "[Optional] Jupyterlab and Python": [[10, "optional-jupyterlab-and-python"]], "[] notation": [[8, "notation"]], "announcements": [[15, "announcements"]], "class_weight=\"balanced\"": [[39, "class-weight-balanced"]], "cross_val_score": [[14, "cross-val-score"], [21, "cross-val-score"], [33, "cross-val-score"]], "cross_validate": [[14, "cross-validate"], [21, "cross-validate"], [33, "cross-validate"]], "fit and transform paradigm for transformers": [[16, "fit-and-transform-paradigm-for-transformers"], [23, "fit-and-transform-paradigm-for-transformers"], [35, "fit-and-transform-paradigm-for-transformers"]], "fit the classifier": [[13, "fit-the-classifier"], [20, "fit-the-classifier"], [32, "fit-the-classifier"]], "fit, predict , and score summary": [[13, "fit-predict-and-score-summary"], [20, "fit-predict-and-score-summary"], [32, "fit-predict-and-score-summary"]], "iClicker": [[59, "iclicker"]], "iClicker Exercise 10.1": [[40, "iclicker-exercise-10-1"]], "iClicker Exercise 10.2": [[40, "iclicker-exercise-10-2"]], "iClicker Exercise 12.0": [[41, "iclicker-exercise-12-0"]], "iClicker Exercise 12.1": [[41, "iclicker-exercise-12-1"]], "iClicker Exercise 14.1": [[43, "iclicker-exercise-14-1"]], "iClicker Exercise 19.1": [[48, "iclicker-exercise-19-1"]], "iClicker Exercise 2.1 Supervised vs unsupervised": [[20, "iclicker-exercise-2-1-supervised-vs-unsupervised"]], "iClicker Exercise 2.2 Classification vs regression": [[20, "iclicker-exercise-2-2-classification-vs-regression"]], "iClicker Exercise 2.2 Supervised vs unsupervised": [[13, "iclicker-exercise-2-2-supervised-vs-unsupervised"], [32, "iclicker-exercise-2-2-supervised-vs-unsupervised"]], "iClicker Exercise 2.3 Classification vs regression": [[13, "iclicker-exercise-2-3-classification-vs-regression"], [32, "iclicker-exercise-2-3-classification-vs-regression"]], "iClicker Exercise 2.4: Baselines and decision trees": [[20, "iclicker-exercise-2-4-baselines-and-decision-trees"]], "iClicker Exercise 2.5: Baselines and decision trees": [[13, "iclicker-exercise-2-5-baselines-and-decision-trees"], [32, "iclicker-exercise-2-5-baselines-and-decision-trees"]], "iClicker Exercise 3.1": [[14, "iclicker-exercise-3-1"], [21, "iclicker-exercise-3-1"], [33, "iclicker-exercise-3-1"]], "iClicker Exercise 3.2": [[14, "iclicker-exercise-3-2"], [21, "iclicker-exercise-3-2"], [33, "iclicker-exercise-3-2"]], "iClicker Exercise 9.1": [[39, "iclicker-exercise-9-1"]], "iClicker Exercise 9.2": [[39, "iclicker-exercise-9-2"]], "k-Nearest Neighbours (k-NNs) [video]": [[15, "k-nearest-neighbours-k-nns-video"], [22, "k-nearest-neighbours-k-nns-video"], [34, "k-nearest-neighbours-k-nns-video"]], "k-nearest neighbours imputation": [[46, "k-nearest-neighbours-imputation"]], "macOS": [[10, "macos"]], "n_iter": [[38, "n-iter"]], "n_jobs=-1": [[38, "n-jobs-1"]], "pandas_profiler": [[40, "pandas-profiler"]], "predict the target of given examples": [[13, "predict-the-target-of-given-examples"], [20, "predict-the-target-of-given-examples"], [32, "predict-the-target-of-given-examples"]], "predict_proba": [[18, "predict-proba"], [37, "predict-proba"]], "random_state argument": [[14, "random-state-argument"], [21, "random-state-argument"], [33, "random-state-argument"]], "score your model": [[13, "score-your-model"], [20, "score-your-model"], [32, "score-your-model"]], "sklearn API summary: estimators": [[16, "sklearn-api-summary-estimators"], [23, "sklearn-api-summary-estimators"], [35, "sklearn-api-summary-estimators"]], "sklearn API summary: transformers": [[16, "sklearn-api-summary-transformers"], [23, "sklearn-api-summary-transformers"], [35, "sklearn-api-summary-transformers"]], "sklearn set_config": [[17, "sklearn-set-config"], [24, "sklearn-set-config"], [36, "sklearn-set-config"]], "sklearn\u2019s ColumnTransformer": [[17, "sklearn-s-columntransformer"], [24, "sklearn-s-columntransformer"], [36, "sklearn-s-columntransformer"]], "sklearn\u2019s SimpleImputer": [[28, "sklearn-s-simpleimputer"]], "sklearn\u2019s feature_importances_ and permutation_importance": [[42, "sklearn-s-feature-importances-and-permutation-importance"]], "sklearn\u2019s feature_importances_ attribute vs permutation_importance": [[42, "sklearn-s-feature-importances-attribute-vs-permutation-importance"]], "spaCy": [[53, "spacy"]], "test score vs. cross-validation score": [[14, "test-score-vs-cross-validation-score"], [21, "test-score-vs-cross-validation-score"], [33, "test-score-vs-cross-validation-score"]], "test_size, train_size arguments": [[14, "test-size-train-size-arguments"], [21, "test-size-train-size-arguments"], [33, "test-size-train-size-arguments"]], "\u201cDeployment\u201d data": [[14, "deployment-data"], [21, "deployment-data"], [33, "deployment-data"]], "\u2753\u2753 Questions for group discussion": [[39, "questions-for-group-discussion"]], "\u2753\u2753 Questions for you": [[12, "questions-for-you"], [13, "questions-for-you"], [13, "id1"], [13, "id3"], [14, "questions-for-you"], [14, "id1"], [15, "questions-for-you"], [15, "id2"], [16, "questions-for-you"], [16, "id1"], [16, "id2"], [17, "questions-for-you"], [17, "id1"], [18, "questions-for-you"], [18, "id1"], [18, "id2"], [19, "questions-for-you"], [20, "questions-for-you"], [20, "id1"], [21, "questions-for-you"], [21, "id1"], [22, "questions-for-you"], [22, "id1"], [23, "questions-for-you"], [23, "id1"], [23, "id2"], [24, "questions-for-you"], [24, "id1"], [29, "questions-for-you"], [30, "questions-for-you"], [31, "questions-for-you"], [32, "questions-for-you"], [32, "id1"], [32, "id3"], [33, "questions-for-you"], [33, "id1"], [34, "questions-for-you"], [34, "id1"], [35, "questions-for-you"], [35, "id1"], [35, "id2"], [36, "questions-for-you"], [36, "id1"], [37, "questions-for-you"], [37, "id1"], [37, "id2"], [38, "questions-for-you"], [38, "id2"], [39, "questions-for-you"], [39, "id2"], [40, "questions-for-you"], [40, "id2"], [41, "questions-for-you"], [41, "id1"], [41, "id2"], [43, "questions-for-you"], [44, "questions-for-you"], [44, "id2"], [45, "questions-for-you"], [45, "id3"], [46, "questions-for-you"], [46, "id1"], [46, "id2"], [48, "questions-for-you"], [49, "questions-for-you"], [49, "id1"], [49, "id2"], [49, "id3"], [50, "questions-for-you"], [50, "id1"], [50, "id2"], [50, "id3"], [50, "id4"], [51, "questions-for-you"], [51, "id1"], [52, "questions-for-you"], [52, "id2"]], "\ud83e\udd14 Eva\u2019s questions": [[12, "eva-s-questions"], [14, "eva-s-questions"], [19, "eva-s-questions"], [31, "eva-s-questions"], [33, "eva-s-questions"]]}, "docnames": ["LICENSE", "README", "docs/330_vs_340", "docs/README", "docs/asking_for_help", "docs/git_installation", "docs/grades", "docs/homework_instructions", "docs/python_notes", "docs/resources", "docs/setup", "learning-objectives", "lectures/201-Lecuyer-lectures/01_intro", "lectures/201-Lecuyer-lectures/02_terminology-decision-trees", "lectures/201-Lecuyer-lectures/03_ml-fundamentals", "lectures/201-Lecuyer-lectures/04_kNNs-SVM-RBF", "lectures/201-Lecuyer-lectures/05_preprocessing-pipelines", "lectures/201-Lecuyer-lectures/06_column-transformer-text-feats", "lectures/201-Lecuyer-lectures/07_linear-models", "lectures/202-203-Giulia-lectures/01_intro", "lectures/202-203-Giulia-lectures/02_terminology-decision-trees", "lectures/202-203-Giulia-lectures/03_ml-fundamentals", "lectures/202-203-Giulia-lectures/04_kNNs-SVM-RBF", "lectures/202-203-Giulia-lectures/05_preprocessing-pipelines", "lectures/202-203-Giulia-lectures/06_column-transformer-text-feats", "lectures/204-Andy-lectures/README", "lectures/204-Andy-lectures/class_demos/demo_03-ml-fundamentals", "lectures/204-Andy-lectures/class_demos/demo_04-kNNs-SVMs", "lectures/204-Andy-lectures/class_demos/demo_05-06-preprocessing", "lectures/204-Andy-lectures/class_demos/demo_07-linear-models_clean", "lectures/204-Andy-lectures/class_demos/demo_07-linear-models_filled", "lectures/notes/01_intro", "lectures/notes/02_terminology-decision-trees", "lectures/notes/03_ml-fundamentals", "lectures/notes/04_kNNs-SVM-RBF", "lectures/notes/05_preprocessing-pipelines", "lectures/notes/06_column-transformer-text-feats", "lectures/notes/07_linear-models", "lectures/notes/08_hyperparameter-optimization", "lectures/notes/09_classification-metrics", "lectures/notes/10_regression-metrics", "lectures/notes/12_ensembles", "lectures/notes/13_feat-importances", "lectures/notes/14_feature-engineering-selection", "lectures/notes/15_K-Means", "lectures/notes/16_DBSCAN-hierarchical", "lectures/notes/17_recommender-systems", "lectures/notes/18_natural-language-processing", "lectures/notes/19_intro_to_computer-vision", "lectures/notes/20_time-series", "lectures/notes/21_survival-analysis", "lectures/notes/22_communication", "lectures/notes/24_deployment-conclusion", "lectures/notes/appendixA_feature-engineering-text-data", "lectures/notes/appendixB_multiclass-strategies", "lectures/notes/final-exam-review-guiding-question", "lectures/tutorials/01_decision_boundaries", "lectures/tutorials/02_ML_fundamentals", "lectures/tutorials/03_Preprocessing", "syllabus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["LICENSE.md", "README.md", "docs/330_vs_340.md", "docs/README.md", "docs/asking_for_help.md", "docs/git_installation.md", "docs/grades.md", "docs/homework_instructions.md", "docs/python_notes.ipynb", "docs/resources.md", "docs/setup.md", "learning-objectives.md", "lectures/201-Lecuyer-lectures/01_intro.ipynb", "lectures/201-Lecuyer-lectures/02_terminology-decision-trees.ipynb", "lectures/201-Lecuyer-lectures/03_ml-fundamentals.ipynb", "lectures/201-Lecuyer-lectures/04_kNNs-SVM-RBF.ipynb", "lectures/201-Lecuyer-lectures/05_preprocessing-pipelines.ipynb", "lectures/201-Lecuyer-lectures/06_column-transformer-text-feats.ipynb", "lectures/201-Lecuyer-lectures/07_linear-models.ipynb", "lectures/202-203-Giulia-lectures/01_intro.ipynb", "lectures/202-203-Giulia-lectures/02_terminology-decision-trees.ipynb", "lectures/202-203-Giulia-lectures/03_ml-fundamentals.ipynb", "lectures/202-203-Giulia-lectures/04_kNNs-SVM-RBF.ipynb", "lectures/202-203-Giulia-lectures/05_preprocessing-pipelines.ipynb", "lectures/202-203-Giulia-lectures/06_column-transformer-text-feats.ipynb", "lectures/204-Andy-lectures/README.md", "lectures/204-Andy-lectures/class_demos/demo_03-ml-fundamentals.ipynb", "lectures/204-Andy-lectures/class_demos/demo_04-kNNs-SVMs.ipynb", "lectures/204-Andy-lectures/class_demos/demo_05-06-preprocessing.ipynb", "lectures/204-Andy-lectures/class_demos/demo_07-linear-models_clean.ipynb", "lectures/204-Andy-lectures/class_demos/demo_07-linear-models_filled.ipynb", "lectures/notes/01_intro.ipynb", "lectures/notes/02_terminology-decision-trees.ipynb", "lectures/notes/03_ml-fundamentals.ipynb", "lectures/notes/04_kNNs-SVM-RBF.ipynb", "lectures/notes/05_preprocessing-pipelines.ipynb", "lectures/notes/06_column-transformer-text-feats.ipynb", "lectures/notes/07_linear-models.ipynb", "lectures/notes/08_hyperparameter-optimization.ipynb", "lectures/notes/09_classification-metrics.ipynb", "lectures/notes/10_regression-metrics.ipynb", "lectures/notes/12_ensembles.ipynb", "lectures/notes/13_feat-importances.ipynb", "lectures/notes/14_feature-engineering-selection.ipynb", "lectures/notes/15_K-Means.ipynb", "lectures/notes/16_DBSCAN-hierarchical.ipynb", "lectures/notes/17_recommender-systems.ipynb", "lectures/notes/18_natural-language-processing.ipynb", "lectures/notes/19_intro_to_computer-vision.ipynb", "lectures/notes/20_time-series.ipynb", "lectures/notes/21_survival-analysis.ipynb", "lectures/notes/22_communication.ipynb", "lectures/notes/24_deployment-conclusion.ipynb", "lectures/notes/appendixA_feature-engineering-text-data.ipynb", "lectures/notes/appendixB_multiclass-strategies.ipynb", "lectures/notes/final-exam-review-guiding-question.ipynb", "lectures/tutorials/01_decision_boundaries.ipynb", "lectures/tutorials/02_ML_fundamentals.ipynb", "lectures/tutorials/03_Preprocessing.ipynb", "syllabus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 4, 5, 7, 8, 9, 10, 13, 18, 20, 21, 26, 27, 29, 30, 32, 37, 38, 41, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59], "0": [0, 1, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "00": [1, 12, 13, 15, 17, 18, 19, 24, 26, 28, 30, 31, 32, 34, 36, 37, 38, 39, 42, 45, 46, 49, 50, 51, 59], "000": [12, 14, 15, 16, 18, 19, 21, 22, 23, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 47, 48, 50, 53], "0000": [16, 18, 23, 30, 35, 37, 39, 47, 53], "00000": [30, 38, 49], "000000": [13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 26, 27, 28, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 49, 50], "00000000e": 42, "000000e": [28, 38], "000001": 40, "00000e": [15, 34], "000010": 40, "000011": 39, "000021": [16, 23, 35], "000036": 39, "000057": [16, 23, 35], "000065": 38, "000067": 38, "000077": 38, "000087": 37, "000089": 37, "0001": [18, 37, 39, 40, 50, 51], "000100": [16, 23, 35, 40], "000101": 18, "000102": 18, "000102e": 26, "000108": 37, "000113": 39, "000114": 38, "000116": 18, "000117": 40, "000128": 27, "000130": 37, "000136": 48, "000137": 38, "000140": 18, "000142": 18, "000144": 27, "000145": 38, "000146": 37, "000147": 38, "000149": [16, 23, 27, 35], "000150": 37, "000151": 38, "000153": 18, "000154": 27, "000155": [16, 23, 35, 39], "000156": 27, "000159": 38, "000162": 27, "000163": [27, 38], "000166": [18, 37, 38], "000175": 27, "000177": [35, 49], "000179": 27, "000180": 35, "000181": 38, "000182": 37, "000183": 37, "000187": [27, 37], "000188": 35, "000190": 49, "000192": [16, 49], "000194": 37, "000195": 35, "000196": 18, "000197": 16, "000198": 39, "000201": 38, "000203": 16, "000206": 38, "000208": [16, 23, 35], "000210": 38, "000212": 43, "000213": 37, "000218": [23, 37], "000221": 40, "000222": 23, "000225": 16, "000226": 40, "000227": 39, "000228": 23, "000231": 35, "000232": 48, "000234": [15, 34, 38], "000235": [27, 35, 39], "000236": 27, "000239": 18, "000240": [18, 35], "000241": [23, 27], "000245": 38, "000247": 48, "000248": [16, 27], "000255": 37, "000256": [18, 49], "000259": 35, "000260": 35, "000261": 16, "000265": 27, "000267": 16, "000270": 27, "000271": 49, "000273": 48, "000274": 48, "000278": [18, 23], "000279": 23, "000280": 18, "000281": [27, 37], "000283": 37, "000285": [23, 37], "000286": 38, "000289": [16, 23, 35], "000294": 38, "000296": 27, "000304": 16, "000306": 23, "000310": 27, "000312": [28, 39], "000313": 27, "000316": 27, "000318": 18, "000321": 27, "000328": 27, "000329": 27, "000332": [28, 40], "000336": 48, "000339": [28, 38], "000342": 23, "000348": 38, "000351": 18, "000353": [18, 38], "000354": 38, "000363": 48, "000366": 39, "000370": 38, "000371": 37, "000373": 40, "000374": 27, "000378": 37, "00038": 38, "000387": 27, "000397": [18, 40], "000399": 48, "000402": 18, "000412": 18, "000415": 28, "000416": 18, "000420": 27, "000423": 27, "000428": 27, "000432": [27, 28], "000433": 40, "000434": 14, "000435": [14, 48], "000437": 48, "000438": 14, "000441": [14, 27], "000445": 14, "000448": 14, "000450": 28, "000451": 14, "000452": 35, "000459": [14, 37], "000460": 27, "000463": 14, "000471": [14, 49], "000472": 48, "000475": 27, "000477": 21, "000480": [21, 27], "000489": 38, "000492": 39, "000496": 21, "000498": 49, "0005": 51, "000500": 14, "000502": [21, 23], "000503": [15, 38], "000507": 28, "000508": 38, "000511": 14, "000520": [27, 40], "000524": 14, "000528": 15, "000534": 21, "000540": 27, "000542": 27, "000545": 15, "000548": 15, "000549": 15, "000551": 21, "000556": 28, "000558": [21, 28], "000561": [15, 27], "000575": 49, "000579": 30, "00058": 38, "000580": 34, "000587": 16, "000602": 15, "000607": 15, "000609": 30, "000610": 21, "000612": 15, "000619": 30, "000625": 15, "000626": 14, "000630": 39, "000633": 34, "000636": 14, "000637": [14, 48], "000639": 14, "000640": 15, "000642": 14, "000644": 14, "000645": 27, "000646": 14, "000647": 34, "000650": 34, "000651": 34, "000652": [14, 40], "000654": 30, "000655": [14, 34], "000657": 14, "000661": 34, "000664": 14, "000666": 15, "000671": 34, "000675": [14, 22], "000678": 38, "000683": 15, "000685": 27, "000686": 14, "000691": 21, "000696": 21, "000697": 15, "000700": 22, "000701": [15, 21], "000707": 21, "000710": 22, "000711": 21, "000712": 21, "000713": [27, 40], "000714": 22, "000720": 21, "000722": 14, "000726": 39, "000727": 30, "000728": 22, "000736": 22, "000737": 49, "000739": 22, "000740": 27, "000742": 15, "000746": 15, "000747": 38, "000748": 35, "000752": [15, 34], "000757": 14, "000758": 48, "000765": 35, "000774": 35, "000786": 39, "000787": 34, "000789": 28, "00079": 38, "000794": 34, "000795": 34, "000797": 34, "000800": 14, "000803": 40, "000805": 15, "000812": [14, 27], "000815": 15, "000816": 21, "000820": 15, "000823": 21, "000829": [27, 34], "000831": 34, "000832": 40, "000839": [21, 22, 27], "000842": 15, "000851": 22, "000867": 35, "000869": 49, "000870": 21, "000873": 34, "000881": 23, "000889": 34, "000890": 27, "000891": 39, "000894": 23, "000902": 16, "000917": 38, "000927": 39, "000934": 27, "000936": 34, "000944": 15, "000945": 43, "000950": 22, "000952": 23, "000960": 48, "000964": 43, "000967": 22, "000969": 22, "000975": 14, "000976": 38, "000977": 34, "000982": 38, "000989": 30, "000997": 16, "001": [12, 14, 15, 16, 18, 19, 22, 23, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 48, 50, 51, 53], "0010": [18, 37], "00100": 38, "001000": [38, 40], "001002": 33, "001003": 30, "001006": 33, "001010": [30, 33], "001011": [14, 34, 40], "001014": [16, 33], "001016": 33, "001017": 33, "001021": 14, "001026": 33, "001027": 33, "001029": 33, "001031": 30, "001038": 33, "001043": 35, "001057": [33, 38], "001060": [16, 23, 35], "001063": 33, "001064": 48, "001068": 42, "001071": 33, "001078": 33, "001079": 23, "001082": 21, "001086": 33, "001087": 43, "001103": 33, "001109": 27, "001111": 33, "001113": 21, "001116": 22, "001126": 22, "001139": 34, "001144": 14, "001145": 15, "001146": 22, "001149": 33, "001155": 43, "001162": [38, 43], "001174": 33, "001178": 27, "001179": 15, "001200": 16, "001204": 15, "001205": 39, "001220": 37, "001224": 34, "001226": 48, "001230": 27, "001236": 38, "001239": 39, "001260": 15, "001266": 40, "001271": 15, "001272": 16, "001279": 43, "001282": 15, "001286": 39, "001294": 33, "001299": 33, "001302": 22, "001305": 33, "001307": 33, "001315": 33, "001317": 33, "001322": 33, "001323": 33, "001325": 34, "001329": 33, "001337": 33, "001338": [22, 37], "001344": 15, "001347": 38, "001352": 33, "001361": 37, "001362": 37, "001365": 34, "001371": 36, "001375": 27, "001390": 33, "001391": 33, "001392": 34, "001400": 36, "001406": 40, "001407": 33, "001412": 38, "001414": 34, "001416": 15, "001419": 27, "001421": 39, "001422": 40, "001423": 38, "001429": 33, "001433": 40, "001439": 30, "001441": 33, "001448": 36, "001453": 33, "00146": 38, "001466": 36, "001467": 38, "001492": 38, "001495": 34, "001511": 27, "001519": 15, "001521": 22, "001541": 22, "001563": 36, "001566": [27, 40], "001580": 22, "001585": 38, "001586": 34, "001591": 36, "001594": 38, "001595": 34, "001600": 34, "001604": 36, "001606": 36, "001608": 38, "001616": 38, "001620": 38, "001629": 38, "001641": 48, "001645": 37, "001647": 36, "001679": 38, "001682": 38, "001687": 27, "001693": 43, "001699": 33, "0017": 39, "001700": 39, "001710": 37, "001715": 36, "001730": 15, "001740": [18, 40], "001762": 18, "001769": 38, "001773": 34, "001776": 33, "001790": 40, "001792": 38, "001805": 15, "001807": 15, "001836": 15, "001847": 43, "001850": 37, "001873": 15, "001877": 34, "001882": 27, "001883": 17, "001888": 22, "001894": 40, "001900": 34, "001920": 36, "001922": 36, "001929": 17, "001933": 40, "001949": 43, "001952": 34, "001960": 17, "0019627889": 47, "001968": 33, "001994": 43, "002": [14, 18, 33, 37, 41, 42, 47, 50], "002003": 38, "002021": 24, "002022": 36, "002030": 34, "002035": 24, "002045": 38, "002057": [16, 23, 35, 36], "002059": 24, "002069": 24, "002070": 24, "002083": 34, "002088": 17, "002092": 17, "002096": 48, "002105": 38, "002114": 18, "002116": 36, "002118": 34, "002121": 18, "002123": 38, "002143": 33, "002146": 38, "002158": 43, "002159": 38, "002189": 17, "002197": 38, "002218": 17, "002221": 40, "002224": 22, "002225": 22, "002231": 17, "002238": 17, "002251": 15, "002272": 17, "002317": 24, "002321": [27, 37], "00234": 38, "002351": 17, "002355": 43, "002367": 24, "002385": 40, "002418": 27, "002441": 43, "002460": 48, "002477": 27, "002478": 24, "002481": 18, "002512": 24, "002516": 22, "002525": 48, "002549": 24, "002561": 38, "002564": 24, "002571": 24, "002643": 27, "002646": 43, "002664": 43, "002675": 38, "002682": 48, "002690": [16, 23, 35], "002692": 38, "002703": 18, "002704": 38, "002711": 48, "002716": 22, "002720": 22, "002746": 40, "002761": 18, "002783": 38, "002788": 36, "002789": 36, "002802": 27, "002807": 36, "002814": 23, "002818": 17, "002835": 38, "002842": 17, "002845": 24, "002848": 27, "002858": 36, "002867": 43, "002889": 39, "0029": 50, "002902": 17, "002910": 36, "002921": 27, "002928": 16, "002934": 37, "002940": 48, "002948": 34, "002949": 22, "002962": 48, "002965": 27, "002986": 48, "002987": 27, "002999": 38, "003": [38, 41], "003013": 36, "003014": 38, "003015": [24, 38], "003026": 18, "003027": 38, "003038": [27, 38], "003044": 27, "003052": 16, "003066": 16, "003083": 38, "003086": 36, "003088": 27, "003103": 18, "003106": 16, "003113": 16, "003115": 36, "003124": [39, 40], "003133": 40, "003146": 36, "003148": 37, "003166": [35, 43], "003181": 35, "003183": 43, "003185": 50, "003186": 36, "003188": [35, 36], "003194": [18, 37], "003210": 27, "003212": 35, "003218": 22, "003224": 22, "003232": 17, "003242": 48, "003257": 48, "003272": 27, "003273": 33, "003283": 48, "003284": 22, "003288": 40, "003300": [16, 23, 35], "003316": 23, "00332": 38, "003324": 35, "003365": 36, "003388": 23, "003401": 43, "003421": 38, "003423": 43, "003427": 43, "003442": 23, "003463": 27, "003472": 38, "003477": 48, "003479": [23, 38], "003483": 38, "003493": 43, "003507": 17, "003519": 24, "003528": 38, "003529": 38, "003540": 27, "003547": 40, "003561": [14, 21], "003563": 38, "003565": 24, "003586": 24, "003593": 27, "003633": 38, "003647": 48, "003663": 27, "003665": 17, "003666": [17, 23], "00369": 38, "003736": 24, "003748": 38, "003749": 17, "003757": 38, "003785": [27, 40], "003820": 24, "003877": 27, "003885": 38, "003898": 22, "003902": 17, "003904": 24, "003910": 27, "003913": 17, "003919": [27, 38], "003919287722401839": 38, "00392157": 48, "003923": 36, "003924": 43, "003933": 38, "003936": 17, "003949": 24, "003951": 17, "003968": 17, "003998": 38, "004": [15, 34, 38, 41, 42, 48], "004057": 38, "004065": 49, "004081": 17, "004082": 49, "004121": 40, "004143": 40, "004203": 24, "004262": 24, "004264": [14, 21, 33], "004293": 38, "004305": 38, "004337": 38, "00435173": 44, "004352": 44, "004358": 24, "004373": 17, "004398": 42, "004402": 38, "004438": 18, "004461": 27, "004462": 22, "004466": 38, "004469": 27, "004496": 38, "004521": 40, "004529": 42, "004556": 38, "004574": 40, "004594": 27, "004602": 40, "00461": 38, "004713": 17, "004714": 38, "004723": 42, "004745": 24, "004761": 42, "004769": [14, 21], "004770": [16, 23, 35], "004801": [16, 23, 35, 36], "004807": 36, "004826": 40, "004829": 40, "004848": 16, "004852": 27, "004854": 40, "004884": 48, "004919": 38, "004952": 38, "004959": 38, "00496": 38, "004964": 17, "005": [12, 19, 31, 41, 42, 50, 51], "005067": 35, "005071": 24, "005074": 48, "005093": 35, "005098": 40, "005103": 16, "005114": 40, "005126": 38, "005136": 26, "005151": 38, "005157": 35, "005167": 40, "005191": 16, "005196": 38, "005204": 16, "005241": 40, "00525962": [16, 23, 35], "005269": 40, "005270": 27, "005288": 36, "005290": 16, "005309": 22, "005313": 22, "005335": 38, "005336": 40, "005373": 23, "005377": 23, "005387": 39, "005398": 23, "005423": 38, "005426": 38, "00543825": [16, 23, 35], "005440": 48, "005443": 22, "005478": 42, "00548": 38, "005508": 24, "005525": 30, "005538": 40, "005563": 21, "005579": 40, "005593": 22, "005608": 17, "005622": 23, "005641": 40, "005674": 40, "005699": [14, 21, 33], "005708": 38, "00573": 38, "005734": 38, "005735": 38, "005767": 38, "005809": 49, "005834": 38, "005836": 35, "005868": 24, "005888": [16, 23, 35], "005963": 39, "006": [41, 42, 50], "006012": 38, "006046": 40, "006055": 38, "006067": 40, "006070": 27, "006106": [30, 38], "006110": [15, 34, 38, 40], "006208": 27, "006236": [27, 40], "006244": 38, "006250": 27, "006435": 38, "00644254": 30, "006452": [18, 37], "006465": 22, "006476": 40, "006505": 48, "006531": [14, 21, 33], "006545": 38, "006546893270012566": [18, 37], "006557": [18, 37], "006570": 23, "006578": [16, 23, 35, 36], "006649": 22, "006652": 38, "006667": [27, 38], "00667": 38, "006737": 24, "006744": 40, "006770": 27, "006805": [14, 21, 33], "006861": 38, "006904": 38, "00691": 38, "006973": 35, "006991": 17, "007": [23, 30, 35, 41, 42, 50, 53], "007068": 43, "007116": 24, "00715": 38, "00720988e": 42, "007228": 40, "007291": 36, "007316": [14, 21, 33], "007362": 38, "007434": 42, "007438": 39, "007458": [16, 23, 35, 36], "007517": 40, "007542": 26, "007544": 38, "007563": 38, "007588": 44, "00758803": 44, "00759438": 42, "007655": 38, "007666": 39, "00767": 38, "007737": 40, "007776": 40, "007794": 28, "007818": 38, "007926": 22, "007938": [14, 33], "007986": 40, "008": [16, 41, 42, 53], "008040": 49, "008120": 40, "008153": 38, "008167": [16, 23, 35, 36], "008286": 27, "00830586": [17, 24, 36], "008306": [17, 24, 36], "008322e": 50, "008333": 36, "008346": 40, "008377": 38, "008472": 40, "008498": 27, "008577": 48, "008581": 40, "008606": 40, "008617": 40, "008667": 38, "00871": 38, "008735": [15, 22, 34], "008785": 40, "008786": 39, "009": [36, 41, 50, 53], "009059": [14, 21, 33], "009063": 38, "009082": 38, "009090": 40, "009131": 27, "009132": 38, "009140": 40, "009260": 21, "009297": 38, "009305": 38, "009339": 40, "009422": [14, 33], "009512": 38, "009514e": 40, "009556": 39, "009664": 40, "009692": 48, "009703": 27, "009724": 43, "00pm": 1, "01": [15, 16, 18, 22, 23, 28, 34, 35, 37, 38, 39, 40, 42, 48, 49, 50, 51, 54, 59], "010": [12, 18, 19, 30, 31, 37, 38, 50], "0100": [18, 37], "01000": 38, "010000": [16, 23, 35, 38, 40], "010027": [18, 37], "010183": [16, 23, 35, 36], "0102": [15, 34, 38], "010208": 43, "010294": [14, 21, 33], "010547": 21, "010650": [14, 21, 33], "010679": [14, 33], "010688": 43, "010715": 38, "010750": 43, "011": [12, 19, 31, 36, 48, 50], "011210": 43, "011234": 39, "011248": 40, "011252": 43, "011269e": 40, "011287": 43, "011332": 50, "011336": [15, 22, 34], "011415": 27, "011440": 40, "011617": 38, "011678": 39, "011767": 40, "011773": 41, "012": [16, 23, 35, 36, 41, 42, 48, 50, 53], "012019": [21, 33], "012030": 43, "012065": 14, "012232": 40, "012240": 43, "012247": 27, "012252": 38, "012616": 38, "012624": 40, "012758": 40, "013": 16, "013031": 40, "01311996071": 40, "013120": 42, "013157": 38, "013161": 38, "013433": [15, 22, 34], "013629": 38, "013706928443177698": 38, "013707": 38, "013863": 38, "013888": 38, "014": [16, 23, 33, 35, 41, 42, 50], "014030": 40, "014081e": 40, "01409912": 47, "014305": 40, "01432486e": 42, "014337": 27, "014481": 38, "014503": 38, "014650": 50, "014730": 36, "01473536": [15, 22, 34], "014758": 50, "014990": 27, "015": [12, 16, 19, 23, 31, 35, 36, 41, 50, 53], "015003": 38, "015039": 39, "015056": 38, "015165": 40, "015372": 38, "015639": 27, "015724": 43, "015755": 38, "015819": 38, "016263": 38, "016330": 27, "016372": 38, "01647": 38, "016525": [40, 42, 51], "016555": [18, 37], "016587": 39, "016598": 38, "016602": 38, "016607": 38, "016660": 28, "016676": 44, "016688": [16, 23, 35, 43], "016693": 40, "016807": [18, 37], "016815": 38, "016918": 39, "016944": [15, 22, 34], "017": [36, 48], "017185": 38, "017226": 40, "017308": 38, "017427": 38, "017561": 39, "017610": 42, "017696": 42, "017737": 42, "017741": 42, "017795": 27, "017829": 49, "017837": 38, "01784": 38, "017927": 38, "017951": 27, "017959e": 40, "017972": [16, 23, 35], "018": 41, "018014": 42, "018077": 38, "018178": [15, 22, 34], "018243": 38, "018310": [15, 22, 34], "018434": 49, "018459e": 40, "018487": [18, 37], "0185": [18, 37], "018505": 38, "018507e": 40, "018558": 38, "018581": 40, "018622": 28, "018653": 38, "018745": [12, 19, 31], "018789": 38, "018846": 38, "018854": 39, "019": [41, 53], "019012": 38, "019163": 38, "019293": 27, "019381838999846482": 38, "019382": 38, "019390": 39, "019396": 38, "019444": 36, "019446": 38, "019531": 39, "019556": 50, "0195598": [18, 37], "019574": 38, "019603": 39, "019839": 38, "019963": 39, "019976": 30, "02": [15, 16, 18, 23, 26, 28, 34, 35, 36, 37, 38, 40, 42, 43, 49, 50, 58, 59], "020000": 27, "02000e": [15, 34], "020123": 40, "020273": 39, "020319": 39, "020403": 38, "020414": 38, "020641": 42, "020648": 40, "020653": [14, 21, 33], "020833": 46, "020862": 40, "020873": [16, 23, 35], "021": 41, "021082": 27, "021100": [16, 23, 35], "021281": 38, "021305": [15, 22, 34], "021345": 38, "021603": 48, "021721": 38, "021746": 38, "021862": 38, "021900": [15, 34, 38], "022039": 39, "022331": 42, "022433": 38, "022629": 38, "022686": 38, "022730": 27, "022848": [14, 21, 33], "022866": 39, "023": [41, 48], "023086": 50, "023105": 49, "023279": 28, "023305": 40, "023366": 43, "023511": 38, "023554": 40, "023636": 39, "023666": 38, "023810": 53, "02398696": 30, "024": 41, "024028": 38, "024122": 38, "024291": 49, "024351e": 40, "024390": 43, "02446630e": 42, "024540": [16, 23, 35], "024944": 27, "025": [35, 39], "025381": [42, 51], "025391": [16, 23, 35, 36], "025396": 38, "025460": 27, "025489": 42, "025689": 38, "025910": [15, 22, 34], "025998": [16, 23, 35, 36], "026": 50, "0261": [15, 34, 38], "026616": 27, "026620": 38, "026667": 27, "026777": 38, "02677733855112973": 38, "026793": [40, 42, 51], "026972": 40, "027070": 40, "027079": 27, "027112": 49, "027321": 43, "027484": 40, "027578": 40, "028023": 39, "02807617": 47, "028186": 27, "028337": 38, "028351": 38, "028420": 40, "028672": 43, "028772": 40, "029": 47, "029146": 39, "029164": 49, "029198": 38, "029264": 40, "029396": 27, "029409": 40, "029475": 40, "029909": [14, 33], "029950e": 40, "02d": 49, "03": [1, 16, 18, 26, 37, 38, 40, 42, 48, 49, 50, 53, 59], "030": 42, "03017665e": 42, "030200": [16, 23, 35], "030343": 40, "030349": 40, "030408": [15, 22, 34], "03049217": [15, 22, 34], "0305": [15, 22, 34], "030618": 21, "030739733331869412": [18, 37], "030786": 40, "030805": 40, "031": 36, "031070": 40, "031385": [15, 22, 34], "031483": 40, "031564": [16, 23, 35], "031794": 40, "031863": 40, "0319": 47, "031994": 40, "032000": 27, "032140": 40, "032320": 30, "032324": 38, "032404": 38, "032508": 39, "032566": [17, 24, 36], "03256625": [17, 24, 36], "032656": [15, 22, 34], "032660": 27, "032836": 39, "032874": [15, 22, 34], "033165": 40, "033222": 50, "033267": 49, "033279": 42, "033305": 48, "033322": 40, "033459": [15, 22, 34], "0335": 38, "033723": 40, "033739": 40, "033780": 50, "033815": 39, "033833": 39, "0339": [16, 23, 35], "033993": 27, "034071": 39, "03411038e": 42, "034132": 40, "0344": [15, 34, 38], "034894": 42, "034977": 40, "034979e": 40, "035": 48, "0351": [16, 23, 35], "03516073": 42, "035161": 42, "035223": 40, "035230": 49, "035722": 40, "036": [14, 16, 23, 35, 41, 48], "036136": 43, "0362": [16, 23, 35], "036646": 40, "036764": 39, "036886": 41, "0370": [16, 23, 35], "0373": [16, 23, 35], "037414": 49, "037785": 39, "0378": [16, 23, 35, 50], "038102": [18, 37], "038609": 40, "038707": 42, "038873": 27, "038948": 40, "039": 48, "039498": [18, 37], "039739": 27, "039741": 34, "0399": [16, 23, 35], "04": [16, 23, 26, 28, 35, 36, 38, 40, 42, 49, 50, 58, 59], "040": 41, "040000": 27, "040000e": 26, "040129": 50, "040497": 39, "040563": 27, "040634": 30, "040698e": 40, "040954": 50, "040984": 49, "041": [41, 48], "041031": 39, "04108378": [18, 37], "041084": [18, 37], "041129": [15, 22, 34], "041201": 39, "041488": 40, "041704": 42, "041769": 40, "042081": 42, "042382": 43, "042743": 40, "042957": [16, 23, 35, 36], "043": 38, "043257": 36, "043319": 42, "043509": 38, "043643": 30, "0437": [13, 14, 15, 21, 22, 32, 33, 34, 56], "043890": [15, 22, 34], "044": [15, 34, 38], "044029": [16, 23, 35, 36], "044166": [18, 37], "044253": 42, "044313": [16, 23, 35], "044409": 40, "044614": 38, "044873": [14, 21, 33], "045": [13, 26, 32, 48], "045267": 49, "045304": [15, 22, 34], "045415": 35, "045481": 49, "046": 48, "04600e": [15, 34], "046020": [15, 22, 34], "046114": 27, "046116": 38, "046193e": 40, "046216": 38, "046638": 36, "0468": 50, "0469": [16, 23, 35], "046945": 38, "04709519e": 42, "0474": [18, 37], "047567": 40, "047577": 16, "04774884": 44, "047749": 44, "047851": 23, "048": [14, 21, 33, 36], "048378": [14, 21, 33], "04861878": 44, "048630": 49, "048860": [16, 23, 35], "048889": 40, "048940": 14, "049": [36, 48], "049097": 27, "05": [15, 16, 23, 26, 28, 34, 35, 38, 39, 40, 45, 49, 50, 51, 59], "050": [12, 19, 31, 48], "050110e": 40, "050132": [16, 23, 35, 36], "051": 48, "051269": [16, 23, 35, 36], "05137470e": 42, "051392": 48, "051472": [15, 22, 34], "051620": [16, 23, 35], "051824": 40, "051925": 38, "052": [16, 23, 35], "052349": [16, 23, 35], "052607": 39, "052790": 39, "052819": 39, "05290827e": 42, "053156": 44, "05350962": 54, "0537": 38, "053763": [14, 21, 33], "053918": 38, "054054": 39, "054225": 28, "054461": 39, "054653": [17, 24, 36], "05465323": [17, 24, 36], "054654": 30, "054669": [40, 42, 51], "054784": [17, 24, 36], "05478443": [17, 24, 36], "055": [16, 23, 33, 35, 36], "055100": 38, "055398": 15, "055857": 30, "055915e": 40, "05598498": [17, 24, 36], "055985": [17, 24, 36], "056": 48, "056478": [16, 23, 35, 36], "05656664": 47, "056599": 27, "056703": 39, "057": [16, 23, 35, 48], "057003": [15, 22, 34], "057082": 40, "057254": 50, "057296": 39, "057331": 40, "057609": 30, "057646": [15, 22, 34], "057729": 39, "057732e": 50, "057793": [16, 23, 35, 36], "057910": [16, 23, 35, 36], "058": 41, "0580": [14, 18, 21, 33, 37], "058176": 51, "058298": 40, "059": [12, 16, 19, 23, 31, 35], "059077": 39, "0591": [16, 23, 35], "059242": [16, 23, 35, 36], "059360": 48, "059588": 38, "059863": [15, 22, 34], "06": [16, 23, 26, 35, 38, 40, 45, 47, 48, 49, 50, 54, 59], "060": 48, "060477": 40, "060543": 43, "061100": [16, 23, 35], "061206": 39, "061241": [15, 22, 34], "061312": 40, "061313": 48, "061724": 30, "061937": [15, 22, 34], "062": [12, 15, 19, 31, 34, 38], "062043": 38, "062449": 50, "062658e": 40, "062723": [21, 33], "062792": [15, 22, 34], "062793": 47, "063004": 43, "063110": [16, 23, 35, 36], "063173": 42, "064": [38, 42], "06405": 38, "064050": 38, "064200": [15, 22, 34], "064205": 14, "064307": 43, "064322": 30, "064452": [15, 22, 34], "065": 48, "065018": 16, "065169": 38, "065449": 40, "065463": 39, "066148": 30, "066166": 50, "066251": [21, 33], "066512": 27, "066605": 38, "066667": [16, 23, 35], "0667579112160865": [18, 37], "066810": 50, "066944": 38, "066960": 14, "067099": 27, "067112": 30, "067119": 35, "067120": [21, 33], "067600": 30, "06767839": 30, "06797961": 40, "067991": [16, 23, 35], "068": [12, 19, 31], "068214": [18, 37, 38], "068291": 48, "068428": 27, "068498": 38, "068775": 38, "068800e": 26, "068891": 38, "069": 26, "069150": 42, "06915047": 42, "069188": 50, "0694": [15, 34, 38], "069530": [15, 22, 34], "07": [1, 28, 38, 40, 43, 49, 50], "070047": 23, "070081": 38, "070195": 38, "070850": 39, "070898": 38, "070907": [14, 21, 33], "070929": 39, "071": 48, "071330": 49, "071541": [16, 23, 35, 36], "071654": 43, "07174469222": 40, "071745": 42, "071975": 43, "072": [16, 41], "072043": 38, "072243": 42, "0723": [16, 23, 35], "072396": 38, "07245741": 40, "072567": 30, "072595": 38, "072707": [14, 33], "072966": 16, "073016": 51, "073058": 35, "073233": [18, 37], "073366": 35, "074": [16, 23, 35, 41], "0741": [15, 22, 34], "074141": [15, 22, 34], "07418": 38, "074327": 41, "074418": 48, "074475": 35, "074556": 16, "074719": [17, 24, 36], "07471942": [17, 24, 36], "074773": 21, "074835": 16, "074853": 51, "075000": 46, "075170": 49, "075343": 30, "075453": 50, "075467": 50, "075668": 27, "075747": 38, "076018": 27, "076104": 40, "0762": [16, 23, 35], "076284": 44, "076358": 23, "07639": 38, "076533": 40, "076798": [15, 22, 34], "076938": 23, "077": [41, 48], "077204": 42, "077749": 47, "077761": 50, "077803": 38, "078": [18, 37, 41], "0780": [13, 14, 21, 32, 33, 56], "078052": 39, "07808506982896266": 40, "078243": 38, "078387": 50, "078552": 38, "078740": 38, "07877994e": 54, "078880": 36, "079": 38, "079181": 23, "079282": 38, "079377": 50, "0794": [15, 34, 38], "079471e": 40, "079852e": 40, "08": [16, 23, 35, 38, 40, 43, 45, 48, 49, 50], "080": 48, "08002986030": [17, 24, 36], "080084": 38, "080165": 38, "080319": [17, 24, 36], "08031924": [17, 24, 36], "080694": 42, "080734": 33, "0808": 38, "080847": 14, "081": [12, 19, 31], "08116": 38, "081167": 50, "081292": 49, "08151507e": 42, "081837": 50, "082": 35, "082100": 38, "082251": [18, 37], "082265e": 50, "082749": [15, 22, 34], "082835": 42, "082949": [15, 22, 34], "083": [15, 34, 38, 41], "083123": [16, 23, 35, 36], "083338": [14, 21, 33], "08338644": 47, "083545": 39, "083615": 38, "083813": [16, 23, 35, 36], "083836": 14, "084288": 38, "084490": 51, "084683": 27, "084746": [16, 23, 35, 36], "084870": 21, "085150": 49, "085415": [42, 51], "085477": 39, "085508": 40, "085546": 40, "085550": 40, "085551": 40, "085693": 38, "085698": 40, "086078": 27, "08613": 38, "08642578": 47, "086461": 43, "086517": 26, "086606": 30, "086656": 30, "086825": 30, "086932": 33, "087": 36, "087128": 38, "08740234": 47, "087668": 38, "087703": 30, "08791477": 47, "087996e": 38, "088": 48, "0880": [16, 23, 35], "088129": 30, "088151": 30, "088373": 14, "088543": 38, "088948": [15, 22, 34], "089136": 21, "089294": 38, "089313": 38, "089354": [14, 21], "089485": [21, 33], "089692": 30, "089892": 21, "09": [14, 21, 26, 33, 36, 38, 40, 49, 50], "090000": 39, "09009799": 40, "090231": 42, "090376e": 40, "090453": 39, "090473": 38, "090579": 27, "09058097218": [12, 19, 31], "090785": 40, "090951": 22, "090978": 26, "091": 48, "091243": 38, "091625": 43, "091632": 27, "091819": 33, "092": 41, "092072": 38, "092123": 38, "0922": [15, 34, 38], "092204": [14, 33], "092331": 14, "09245358900622544": 38, "092454": 38, "092604": [14, 21, 33], "092660": 50, "092669": 21, "092670": 38, "092729": 38, "092930": [17, 24, 36], "093051": 38, "0931": 38, "093228": 43, "093350": 51, "093390": [15, 22, 34], "093407": 39, "09345386": [17, 24, 36], "093454": [17, 24, 36], "093624": 33, "093787": 38, "093893": 38, "094": [12, 19, 31, 47], "094290": 50, "09430199": [17, 24, 36], "094302": [17, 24, 36], "094581": [17, 24, 36], "094586": 39, "094725": 38, "094863": 38, "095018": 38, "09503409246217484": 40, "095177": 38, "095345": 38, "09573445": 38, "09619141": 47, "096426": 21, "096462": 40, "096692": [16, 23, 35], "096722": 38, "096858": 38, "096927": 39, "096960": 40, "096990": 33, "096997": 48, "097": 48, "09706504": 48, "097088": 50, "097184": 38, "097293": [16, 23, 35, 36], "097516": [16, 23, 35], "097707": 38, "097763": 38, "097938": 21, "098": [18, 37, 48], "098019": 14, "098152": 38, "098307": 40, "098326": [15, 22, 34, 48], "098559": 38, "098629e": 38, "098663": 38, "098787": 27, "09891476780532049": 18, "0989147678053208": 37, "098915": [18, 37], "098950": 38, "098966": [16, 23, 35], "099": 41, "099230": 42, "099240": [16, 23, 35, 36], "099454": 38, "099558": [16, 23, 35, 36], "099685": 40, "099723": [16, 23, 35], "099729": 38, "099749": 49, "099802": 38, "099869": 38, "0x1227a36e0": 8, "0x1577111f0": 38, "0x16888d4c0": 38, "0x168921100": 38, "1": [1, 7, 8, 9, 10, 26, 27, 28, 29, 30, 42, 47, 49, 52, 53, 54, 59], "10": [1, 4, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59], "100": [12, 13, 15, 16, 17, 18, 22, 23, 24, 26, 27, 28, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 47, 48, 49, 50, 51], "1000": [12, 14, 15, 18, 21, 22, 30, 33, 34, 36, 37, 38, 39, 40, 42, 43, 48, 49, 50, 51, 53, 54], "10000": [12, 13, 18, 26, 29, 30, 32, 36, 37, 38, 40, 49], "100000": [12, 15, 17, 18, 22, 24, 34, 36, 37, 38, 40, 49], "1000000": [28, 38], "100103": 49, "100105": 38, "100139": [17, 24, 36], "100146": 49, "100248": [15, 22, 34], "100275": 43, "1004": [15, 22, 34], "1005": 49, "1006": 49, "1007": 49, "1008": 49, "10083": 26, "100882": 39, "1009": 49, "10092665203438746": 40, "101": [1, 9, 30, 44, 48, 50, 59], "1010": 49, "1012": 49, "101259": 40, "101387": 21, "1014": [27, 38, 48], "1015": [27, 48, 49], "1016": [27, 48, 49], "101688": 38, "1017": [27, 48, 49], "101772": 14, "101796": 40, "1018": [27, 48, 49], "101810": 33, "101832": 38, "101894": 39, "1019": [27, 48, 49], "102": [28, 39, 40], "1020": [26, 27, 38, 43, 48, 49], "102044": 43, "1021": [27, 48, 49], "102135": 39, "1022": [27, 48, 49], "1023": [27, 48, 49], "1024": [27, 36, 48, 49], "102435": [15, 22, 34, 40], "102474": [17, 24, 36], "10247431": [17, 24, 36], "1025": 49, "10254": 49, "1026": [18, 37, 49], "1027": 49, "10273": 40, "10274": 39, "1028": 49, "1029": 49, "103": 50, "103023": 38, "1031": 49, "103219": 43, "103222": 48, "1034": 43, "103439": [17, 24, 36], "103619": 28, "10361902": 28, "1039": 49, "104": [15, 16, 22, 23, 34, 35, 41, 44, 48], "1040": [16, 23, 35], "104070": 40, "1041": [40, 42, 49, 53], "10416666666666667": 46, "1042": 38, "1043": [17, 24], "1044": [12, 19, 31], "104596": 38, "104643": 40, "105": [26, 41], "1050": [13, 26, 32], "105080": 43, "105089": [17, 24, 36], "10513": 49, "1052": 28, "1053": [28, 53], "105314": 49, "1054": 28, "1055": 28, "10556679": 44, "1056": 28, "105656": 42, "1057": 28, "1058": 28, "10584063": 48, "1059": 28, "106": 28, "106000": [16, 23, 35], "106023": 40, "106112": 49, "106180": 49, "106319": 49, "106322": 49, "106424": 49, "10644531": 47, "106452": [15, 22, 34], "10645223": [15, 22, 34], "10653": 49, "106705": 49, "106764": 38, "1068": 53, "106816": 49, "1069": 53, "10693359": 47, "106996": 38, "107": 41, "1070": 43, "107050": 49, "107292": 49, "107502": 49, "1076": [26, 36], "107718": 38, "10781": [41, 42], "107917": 49, "10793260e": 48, "107947": 40, "107985": 40, "107991": 39, "108": [12, 19, 31], "1080": [12, 19, 31], "10800": [12, 19, 31], "1085": [18, 37], "10868": 49, "108681": [15, 22, 34], "1089": 40, "10910": 49, "10931": 36, "109526": 39, "109580": 27, "1099": 40, "10_000": 50, "10th": [38, 39, 41, 42], "10x": 39, "11": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 53, 55, 57, 59], "110": [18, 37, 48], "1101": [17, 24, 28], "1102": 28, "1103": 28, "110316": 49, "110319": 49, "1104": [15, 22, 28, 34], "11057": 49, "1106": [28, 43], "110645": 40, "1107": 28, "1108": 28, "1109": 28, "110915e": 40, "111": [16, 23, 35, 38, 39, 40, 50], "1110": 28, "1111": 28, "111111": 16, "1112": 28, "11121453": 44, "111215": 44, "111220": 49, "1114": 28, "111438": 43, "1115": 28, "111543": 40, "1116": 28, "112": [15, 16, 22, 34], "1122": [40, 42, 53], "1123": [38, 53], "112441": 38, "112490": 38, "112527": 42, "112848": 40, "1131": 26, "11331": 53, "11336331e": 42, "113600": [16, 23, 35, 36, 58], "1138": 43, "113837": 40, "1139": [40, 42, 51], "113949e": 50, "114": [16, 23, 35], "1140": [12, 19, 31, 40, 42, 51], "114000": [16, 23, 35, 43], "114079": 38, "114214": 38, "114507": 48, "11457": [40, 42, 51], "114757": 26, "114766": 42, "114836": 43, "114966": 42, "115": 36, "1150": [12, 19, 31], "115083": [16, 23, 35], "115089": 49, "11509": 40, "115090": 49, "115091": 49, "115092": 49, "115183": 38, "115276": 50, "115401": 40, "115406": [15, 22, 34], "115428": 49, "115956": [18, 37], "116": [16, 23, 35], "116145": 43, "116167": [18, 37], "116443": 43, "116497": 40, "11664": 53, "11693": 40, "117": [16, 18, 23, 28, 35, 36, 37, 43, 58], "117058": [18, 37], "117379": 38, "117380": [16, 23, 35], "117412": 40, "117528": 43, "11758": 49, "117612": 48, "117712": 49, "117816": [16, 23, 35], "117899e": 40, "1179": [16, 23, 35], "118": [16, 18, 23, 28, 35, 36, 37, 40, 42, 43, 51], "1180": [13, 26, 32], "118182": [16, 23, 35, 36], "118347": 40, "118450": 39, "118563": 43, "11886432": 38, "118874": 40, "118934": 39, "11898": 39, "119": [16, 18, 23, 35, 36, 37, 43, 49, 58], "1190": [16, 23, 26, 35], "119049": 49, "11909976": 44, "119100": 44, "119121": 27, "11914062": 47, "119189": 27, "119400": [16, 23, 35], "1195": [17, 24], "119570": 43, "119911": 49, "11th": [39, 41, 42], "12": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 59], "120": [15, 16, 18, 22, 23, 28, 30, 34, 35, 37, 40, 41, 48, 49, 54], "1204": [15, 22, 34], "120769e": 40, "121": [12, 16, 18, 19, 23, 26, 28, 31, 35, 36, 37, 38, 41, 43, 49], "1210": 38, "121056e": 40, "121084e": 40, "121351": 42, "12138": [16, 23, 35], "1214": 40, "121438": 50, "12150684": [18, 37], "121531": 39, "121599": 42, "121628": [15, 22, 34], "1217": 50, "12178": 43, "121846": 42, "121985": 40, "122": [12, 13, 14, 16, 19, 21, 23, 26, 28, 31, 32, 33, 35, 36, 43, 48, 56], "1220": [12, 16, 19, 23, 31, 35, 38], "1222": 38, "122307": [16, 23, 35, 36], "122331": 40, "122668": 38, "123": [4, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58], "123049e": 26, "123367": 40, "1235387316046016": 38, "123539": 38, "124": [16, 23, 28, 35, 47], "1240": [12, 19, 31], "1241": [40, 43], "1243": [16, 23, 35], "12436984": [17, 24, 36], "124370": [17, 24, 36], "1247": 38, "12498": 42, "124982": 43, "125": [8, 28, 40], "1250": [16, 23, 35, 36, 58], "125000": 26, "12508": [40, 42, 51], "125440e": 40, "125476": [15, 22, 34], "125523": 49, "1256": 54, "125617": 49, "125644": 40, "1258": 50, "126": [28, 43], "126238": 43, "126398": [16, 23, 35, 36], "126488": 44, "12649": [16, 23, 35], "126500": [16, 23, 35], "126563": 38, "126808": [16, 23, 35, 36], "127": [14, 16, 18, 21, 23, 28, 33, 35, 37, 38, 52], "127086": [16, 23, 35], "127087": 50, "1271": 41, "127107": 42, "127226": 36, "127242": 40, "1273": 42, "127326": 40, "1274": 43, "127418": 40, "127439": 40, "127441": 40, "127614": 40, "12761659": 40, "12768": 26, "127878": [15, 22, 34], "1279": 40, "1280": [16, 23, 35, 38, 40], "1281": 40, "128188": [16, 23, 35, 36], "128384": 40, "128528": 40, "1287": 26, "128820": 49, "128828": 49, "128829": 49, "128830": 49, "12890625": 47, "128984": 40, "129": [15, 18, 22, 34, 37, 43, 50], "1290": [16, 23, 35, 36], "12906": [12, 19, 31], "129257": 40, "12927": [12, 19, 31], "129300": [16, 23, 35, 36, 58], "129459": 43, "129600": 40, "129900": 39, "129904": 40, "129985": [16, 23, 35], "12th": [39, 41, 42], "13": [1, 8, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 26, 27, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 45, 46, 47, 49, 50, 53, 55, 58], "130": [12, 13, 14, 15, 16, 19, 21, 22, 23, 31, 32, 33, 34, 35, 36, 38, 40, 42, 43, 51, 56, 58], "1300": [40, 42, 51], "1302": 39, "130395": 49, "1304": [15, 22, 34, 50, 51], "130432": 49, "1306": 52, "130690e": 40, "1307": 40, "130991": 39, "131": [16, 23, 28, 35, 41, 49, 50], "131000": 40, "13107": 49, "131275": 39, "1313": 40, "1314": [40, 42, 51], "131607": [40, 42, 51], "131693": 30, "131773": 50, "13179824": 30, "1319796954314723": 41, "132": [16, 50], "1320": 43, "1321": [12, 19, 31], "132158": 40, "132292": 43, "13229595e": 42, "13255": 49, "132875": [16, 23, 35, 36], "132886": 49, "133": [38, 50], "133000": 40, "133210": 38, "133270": 40, "133337": 40, "133562": 50, "13392236": 48, "134": [13, 14, 18, 21, 32, 33, 36, 37, 56], "1340": [13, 26, 32], "134061": 43, "13407": 42, "13418": 16, "134287": 39, "13452": 30, "1346": [16, 23, 35, 40, 42, 43, 50, 53], "134615": [18, 37], "134658": [16, 23, 35], "1347": 53, "13476562": 47, "134798": 39, "134894": 49, "135": [49, 50], "1350": 26, "135134": 49, "135197": 49, "13521135": 42, "135299": 43, "135305": [16, 23, 35, 36], "135384": 40, "13540": 26, "135422": 40, "1357": [12, 19, 26, 31], "136": [16, 23, 35, 36], "1360": [13, 26, 32], "1364": 28, "1365": 28, "1366": 28, "13665": [16, 23, 35, 36, 58], "1367": 28, "136714": 39, "1368": 28, "1369": 28, "1370": [12, 15, 19, 28, 31, 34, 38, 50], "13704": [40, 42, 51], "1371": 28, "1372": [28, 51], "1373": 28, "137339": 39, "1374": 28, "137410": 44, "1375": 28, "137500": [16, 23, 35, 36, 58], "1376": 28, "1377": 28, "1378": [28, 40], "1379": 28, "138": 53, "1380": [12, 19, 28, 31], "1381": 28, "138103": 48, "1382": 28, "1383": [28, 38], "1384": 28, "1385": 28, "138503": 43, "138528": [18, 37], "138564": 26, "1386": 28, "1387": 28, "1388": 28, "138836": 30, "138876": 50, "1389": [16, 23, 28, 35, 40, 42], "139": [16, 17, 23, 24, 35, 53], "1390": [12, 19, 31], "139297": 39, "139317": 39, "139322": 39, "139349": 39, "13941": 39, "139554": 39, "1396": 38, "1397": 38, "14": [1, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 27, 28, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 45, 46, 47, 48, 49, 50, 55], "140": [16, 23, 35], "140185": 43, "140371": 27, "1404": [15, 22, 34, 50], "1405": 43, "1406": [16, 23, 35, 40, 42], "140641": 49, "140828": 26, "140953": 49, "141": [16, 18, 23, 35, 37], "1410": 26, "141232": 49, "14159265358979323": 8, "14160": 39, "141851": 49, "142": 41, "142051e": 26, "142193": 49, "142199": 49, "1423": 39, "142398": 49, "142467": [14, 21, 33], "1427": [26, 51], "142806": 49, "142857": 36, "14289": [16, 23, 35, 36, 58], "143": [38, 39], "143693": 49, "143803": 43, "1438387200": 49, "1438398000": 49, "1438408800": 49, "1438419600": 49, "1438430400": 49, "1438441200": 49, "1438452000": 49, "1438462800": 49, "1438473600": 49, "1438484400": 49, "143975": 49, "144": [12, 19, 31, 38], "144000": [40, 42, 51], "1441": 53, "144199": 49, "144686": 42, "14471": [16, 23, 35, 36, 58], "144729": 49, "144730": 49, "144731": 49, "144732": 49, "144733": 49, "144750": [15, 22, 34], "14485": 40, "145": [27, 49], "145186": 27, "1452": 43, "145425": 40, "145454": 49, "145455": 49, "145456": 49, "145457": 49, "145458": 49, "145459": 49, "145460": 49, "1457": [16, 23, 35, 36, 50, 58], "14579": 43, "1458": [16, 23, 35, 36, 58], "145833": 46, "146": [12, 19, 27, 31, 41, 51], "1460": [40, 50], "14648438": 47, "1465": [16, 23, 35, 36, 58], "146656": 49, "1467": 43, "146767": [39, 42], "146809": 39, "146830": 39, "14690": 36, "147": [27, 42, 51], "147166": [41, 42], "14716638": 42, "1472": 28, "147226": 27, "147616": 39, "147641": 40, "147737": 48, "147893": [16, 23, 35], "147898": 39, "147917": 39, "148": [15, 27, 28, 34, 38, 42, 54], "14813": 49, "148141": 41, "148343": 40, "148349": 50, "14841": 39, "149": [27, 50], "1490": 26, "149122": 52, "14970": [16, 23, 35], "149788": 42, "149822": [16, 23, 35, 36], "14999": [16, 23, 35], "14th": [12, 13, 19], "15": [1, 8, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 26, 27, 28, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 53, 55, 56, 59], "150": [15, 27, 34, 38, 40, 48, 51], "1500": 28, "150000": [39, 46], "150115": 38, "15026771": 40, "150395": [15, 22, 34], "1504": [15, 22, 34], "1505": [16, 23, 35], "1509": 26, "150mb": 39, "150p": [12, 19, 31], "151357": 43, "1514": 52, "152": [28, 49], "1520": 38, "1523300141": 26, "1523300157": 26, "152401": 39, "152691": 27, "15278": 16, "152859": 39, "153": 28, "1530": [12, 19, 26, 31], "1531": [17, 24], "1534": [16, 23, 35], "15377": [16, 23, 35, 43], "154": 28, "1540": [12, 19, 31], "154076": [39, 42], "154105": 43, "15429": 49, "154386": [16, 23, 35, 36], "1545": 43, "154795": [40, 42, 51], "154842": 50, "154883": 27, "155": [12, 19, 28, 31, 38], "15500": 40, "155178e": 40, "15559528e": 42, "155624": 40, "155900": 26, "156": [16, 23, 28, 35, 38, 39], "1560": 26, "1562": 38, "156311e": 40, "1564": 38, "15661": 49, "157": [12, 19, 28, 31, 38, 48], "157008": 40, "157157": 53, "157234": 43, "15725": [16, 23, 35, 43], "157572": 27, "157712": 39, "15775": 49, "1578": 42, "15795": [39, 42], "158": 38, "1580": [12, 19, 31], "1582": 42, "158867": 49, "158982": 40, "159": 38, "1590": [15, 34, 38], "15915": 49, "159751": 27, "15992": 42, "15pm": 1, "16": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 46, 47, 49, 50, 52, 53, 55, 56], "160": [14, 15, 18, 21, 30, 33, 34, 37, 38, 40, 42], "1600": 26, "160000": [40, 42, 51], "160258": [14, 21, 33], "160282": 43, "1604": [15, 22, 34], "160506": 39, "160634": 48, "16063983": [17, 24, 36], "160640": [17, 24, 36], "160727": 42, "160729": 49, "161": [16, 23, 28, 35], "1610243052583633": 18, "1610243052583638": 37, "16111330565237114": 18, "16111330565237164": 37, "1613": [16, 23, 35], "161300e": 26, "161429": 27, "16153": 49, "16157": 49, "16160": 49, "161606": [16, 23, 35, 36], "161782": 39, "1619": 38, "161931": [40, 42, 51], "162": [12, 19, 31], "162000": 40, "162007": 53, "162214": 51, "162330": 39, "162363": 39, "162667": [39, 42], "16269": 16, "1627": 43, "162904": 50, "163": 26, "1631": 38, "163195": [16, 23, 35, 36], "163397": [16, 23, 35, 36], "1634": [16, 23, 35, 36, 38, 58], "16358": 49, "164": [43, 48], "1645": [18, 37], "16460": 43, "164679": 39, "165": [18, 37, 40], "1650": [15, 34, 38], "16507": [18, 37, 43], "16508": [18, 37, 43], "16509": [18, 37, 43], "16510": [18, 37, 43], "16511": [18, 37, 43], "16512": [18, 37, 43], "165198e": 40, "1652": [14, 18, 21, 33, 37], "16533": 49, "165485": 42, "165617": 49, "165811": 38, "166": 21, "16630": 43, "166631": [16, 23, 35, 36], "16686": 16, "167": [14, 21, 28, 33], "167214": [15, 22, 34], "167241": 53, "167600": 43, "167620": 48, "168": [28, 40], "1680": [13, 26, 32], "168151": 48, "168196": [16, 23, 35, 36], "168244": 42, "1687": 38, "169": [14, 18, 21, 28, 33, 37, 43], "1690": [12, 13, 19, 26, 31, 32], "169269e": 50, "169421": 38, "169693": [15, 22, 34], "169748": [18, 37], "16991815": 8, "1699181533555938": 8, "17": [1, 4, 8, 13, 15, 16, 17, 18, 22, 23, 24, 26, 28, 32, 34, 35, 36, 37, 38, 39, 40, 43, 47, 49, 50, 55, 58], "170": [16, 23, 35, 45], "170100": [16, 23, 35, 36, 58], "170277": [41, 42], "1704": [15, 22, 34], "17054987": 48, "170670": 40, "170931": 48, "171": [12, 19, 31, 48], "17144": 49, "171468": [40, 42, 51], "1715": 38, "171657": [14, 21, 33], "171899": 50, "1720": [16, 23, 35], "17205": 49, "1724668": 47, "172792": 39, "17290": 26, "173": [15, 34, 38], "173025": 38, "17347071": 30, "173483": 30, "17393037": 8, "1739787032867638": 38, "173979": 38, "174": [12, 15, 19, 31, 34, 38], "174590": 39, "17476": 16, "174766": 43, "1750": [16, 23, 35, 52], "175000": [40, 42, 51], "17518": 49, "175459": 26, "176": [16, 23, 35], "176026": 27, "1766": 40, "176924": 50, "177": 43, "17730": [16, 23, 35, 43], "177709": 50, "178": [12, 19, 31, 40], "17847": 16, "178494": 40, "1788": 26, "17896": 49, "179": [41, 50], "179080": 39, "179123": [15, 22, 34], "179152": 28, "179300": [16, 23, 35], "179631": 26, "179730": 38, "17973005068132514": 38, "179802": 40, "18": [1, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 46, 49, 50, 51, 55, 58], "180": [38, 40, 48], "1800": [12, 13, 15, 19, 26, 31, 32, 34, 38], "18000": 49, "180000": [13, 26, 32], "180279e": 40, "180388": [15, 22, 34], "1804": [15, 22, 34], "18066406": 47, "180900": 43, "180926": 27, "18096": 49, "181": 50, "18113": 49, "18116": 49, "1813": 38, "182": [49, 50], "18201414": 42, "182382": 27, "18245": 49, "182639": 40, "182648": 40, "1830": 26, "18311": 49, "18313": 49, "18317085": 8, "183179": 50, "183423": [15, 22, 34], "183471e": 40, "18365": 36, "18391": [16, 23, 35, 36], "184": [49, 50], "1840": [12, 19, 26, 31], "184282": 30, "184405": 42, "1847": [17, 24, 36], "185": [14, 21, 50], "185000": 14, "185155": 42, "185175": 50, "18533": 49, "1854": 38, "185707": [15, 34, 38], "18571": [16, 23, 35, 36], "18572": [16, 23, 35, 36], "18573": [16, 23, 35, 36], "18574": [16, 23, 35, 36], "18575": [16, 23, 35, 36], "18576": [16, 23, 35, 36], "1858": 43, "185868": 43, "185975": 42, "18597545": 42, "186": 28, "186024": [12, 19, 31], "186814": 39, "186899": 39, "187": [14, 18, 21, 33, 37, 41], "1870": 38, "187000": [16, 23, 35], "1872": 40, "1875": [18, 37, 47], "187503": 49, "187663": [15, 22, 34], "187700": [16, 23, 35], "188": [12, 14, 18, 19, 21, 31, 33, 37], "1880": 38, "1886": [18, 37], "1887": [39, 42], "189": 28, "18955": 49, "189981": 40, "19": [1, 8, 12, 13, 14, 15, 17, 19, 22, 24, 26, 31, 32, 33, 34, 36, 38, 39, 40, 43, 46, 47, 49, 50, 53, 55], "190": [14, 21, 33, 40, 43], "1900": 26, "19000e": [15, 34], "1901": [12, 19, 31], "190319": 43, "19032": 49, "1904": [15, 22, 34], "190617": [16, 23, 35, 36], "190833": 21, "191": [16, 21, 23, 33, 35], "1910": 26, "1911": 43, "191169": [40, 42], "191204": 43, "191250": [14, 21, 33], "191396": [15, 22, 34], "191700": 43, "1918": [17, 24, 36], "191k": 42, "1920": [12, 19, 31], "19213263": [17, 24, 36], "192133": [17, 24, 36], "19266": 49, "1927": 53, "1928": 53, "193": 48, "1930": [12, 19, 31], "193021": 39, "193122": 39, "193247": 43, "1933": [13, 26, 32], "193346": 42, "1934": 26, "193427": 38, "19365": 49, "193704": 49, "19380": 49, "1940": [17, 24, 36], "194002": [15, 22, 34], "194034": 49, "194040": [16, 23, 35], "19422": 42, "19433594": 47, "1944": 26, "1945": 40, "194519": 30, "1946": [12, 19, 31, 40], "194710": 40, "1948": 26, "19485": [16, 23, 35], "194914": 27, "194985": 40, "195": [16, 23, 35], "1950": 40, "1951": [13, 26, 32], "195228": 36, "1953": [38, 40], "19536": 39, "1954": 47, "1954400510": 26, "1955": [13, 26, 32], "195564": 43, "1957": 47, "1959": [12, 19, 26, 31], "19591": 43, "1960": [13, 26, 32], "1962": 47, "1963": 38, "196385": 42, "1965": [13, 26, 32], "196599": 40, "1966": 40, "196717": 48, "196739": 49, "1968": [12, 19, 31], "196963": 27, "1970": [18, 37, 40, 49], "197083": 14, "1971": 26, "1972": 40, "1975": 26, "197500": 21, "197649": 43, "1977": [12, 19, 31, 50], "19777": [41, 42], "19781": 49, "197884": 28, "1979": 30, "198": 48, "198127": 40, "1984": 40, "1985": 40, "1986": 26, "198629": 48, "198645": 50, "1987": [12, 13, 19, 26, 31, 32], "1989": [12, 19, 31], "198924": [16, 23, 35, 36], "199": [12, 15, 19, 22, 31, 34, 39], "1990": [15, 18, 34, 37, 38], "1991": [13, 26, 32, 41], "1992": 49, "1993": 40, "199364": 39, "1994": [12, 19, 31], "199412": [27, 50], "199413": [15, 34, 38], "19966": [16, 23, 35, 36, 43], "1997": [18, 26, 37, 38], "199771": 42, "1_000_000_000": 38, "1d": [28, 48], "1e": [38, 40], "1e3": 38, "1e4": 38, "1h": [16, 23, 35, 36, 43], "1st": [8, 30, 39, 41, 42, 49], "1stflrsf": [40, 42, 51], "1v": 54, "1v2": 54, "1v3": 54, "2": [1, 4, 7, 8, 9, 10, 26, 27, 28, 30, 41, 42, 43, 47, 48, 49, 52, 53, 54, 59], "20": [1, 4, 8, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 53, 54, 55, 57, 58, 59], "200": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 47, 48, 51, 56, 57, 58], "2000": [15, 22, 28, 30, 34, 38, 39, 40, 41, 42, 43, 48, 52, 54], "200000": [38, 49], "200000e": 26, "2003": 26, "200326e": 40, "2004": [26, 40], "200458": 27, "200475": 39, "2005": 26, "2006": [40, 42, 51], "2007": [26, 40, 42, 49, 51], "2008": [26, 40, 42, 49, 51], "200876": [17, 24, 36], "20087625": [17, 24, 36], "2009": [26, 40, 42, 49, 51], "200978": [15, 22, 34], "201": [1, 15, 22, 34, 59], "2010": [30, 40, 42, 49], "20113": [16, 23, 35, 36, 58], "2012": [8, 16, 23, 35, 38, 59], "2013": [26, 47, 49], "201332": 45, "2014": [12, 19, 26, 31, 41, 49], "20140521t000000": 26, "20140623t000000": 26, "20141013t000000": 26, "20141015t000000": 26, "20141209t000000": 26, "2015": [26, 48, 49], "20150116t000000": 26, "20150218t000000": 26, "20150223t000000": 26, "20150225t000000": 26, "20150630": 49, "2016": [8, 48, 49], "20160101": 49, "2017": [42, 49], "201810": 39, "201862": 43, "202": [1, 15, 22, 34, 36, 59], "2020": 53, "2022": 49, "202247": 27, "2022w2": [12, 19], "2023": [1, 49], "2024": [0, 1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 56, 57, 58], "20248": [16, 23, 35], "2024w1": [0, 10, 12, 48], "2024w2": [10, 12, 19], "2025": 1, "20274": 49, "20277493": 28, "202775": 28, "202839": 39, "203": [1, 15, 22, 34, 59], "20310": 49, "20311": 43, "20319": 49, "203265": 42, "20334": 49, "203421": 40, "203500": [16, 23, 35], "20357847293371834": 18, "20357847293371892": 37, "204": [1, 13, 14, 15, 21, 22, 32, 33, 34, 38, 47, 56, 59], "204167": [14, 21, 33], "2043": 50, "204302": 49, "20433": 43, "204583": [14, 21, 33], "2046": 36, "204600": [15, 34, 38], "204692": 40, "204734": 39, "20485": 49, "205": [13, 14, 15, 21, 22, 28, 32, 33, 34, 56], "205000": [16, 23, 35, 36, 40, 42, 51, 58], "205059": 43, "20509": 49, "20514": 49, "205144": 43, "205323": 49, "205479": [18, 37], "205597": 40, "20564": 49, "206": [13, 14, 15, 21, 22, 32, 33, 34, 38, 39, 52, 56], "206019": 27, "206041": 42, "206073": 39, "206099": 38, "20620": 49, "206292": [16, 23, 35], "20639": 43, "2064": [16, 23, 35], "20640": [18, 37, 43], "206724": 50, "20683258": [18, 37], "20694": 49, "20699": 26, "207": [13, 14, 15, 16, 21, 22, 23, 32, 33, 34, 35, 38, 47, 48, 56], "207039e": 40, "2071": 43, "207814e": 40, "2079": 26, "20794": 49, "208": [13, 14, 15, 18, 21, 22, 32, 33, 34, 37, 38, 56], "209": [12, 13, 14, 15, 19, 21, 22, 31, 32, 33, 34, 38, 56], "209221": 51, "209583": 33, "209746": 39, "209903": 43, "20analysi": 50, "20assumpt": 50, "20hazard": 50, "20intro": 50, "20learn": 48, "20lifelin": 50, "20with": 50, "21": [1, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 28, 31, 32, 34, 35, 36, 39, 40, 43, 44, 46, 47, 49, 53, 59], "210": 38, "210000": 14, "210001": 39, "210240": 38, "210272": 43, "210286": 27, "210417": 21, "210591": [16, 23, 35, 36], "210779": 49, "21086181023099465": 18, "21086181023099526": 37, "211": 38, "2110": [16, 23, 35], "211250": [14, 21, 33], "211343": 43, "211544": 39, "211724": 27, "211892": [16, 23, 35, 36], "212": [1, 14, 33, 38, 59], "212385": 42, "212581": 43, "21274": 49, "212870": 40, "212975": 40, "213": [14, 38, 48, 49], "2130": [12, 19, 31], "21353": 49, "21382972": 41, "21389": 49, "213896": 26, "2139": [16, 23, 35, 36, 58], "214": [12, 19, 31, 36, 38], "21405": 49, "21436": 26, "2144": 38, "21450": 26, "214740": [16, 23, 35], "214769": 48, "214821": 49, "214852": 39, "2149": 28, "215": 38, "2150": 28, "2151": 28, "215167": 27, "2152": 28, "215245": 40, "2153": 28, "21530": 49, "2154": 28, "215412": 40, "21549": 49, "2155": 28, "2156": 28, "21571": 49, "21581": 49, "21582031": 47, "215865": 42, "21596": 49, "216": 38, "21603": 49, "21605": 49, "21608": 26, "21609": 26, "21610": 26, "21611": 26, "21612": 26, "216123": 50, "21613": [13, 26, 32], "21616484": 54, "21617": 49, "216250": 21, "216346": 42, "21634631": 42, "216585": [16, 23, 35], "216596": 49, "21668": 49, "21670": 49, "216718": 39, "216728": [16, 23, 35], "21694": 49, "21697": 49, "217": [28, 52], "2170": [13, 26, 32], "217083": 14, "217334": [17, 24, 36], "21733442": [17, 24, 36], "2173627": 47, "217500": 14, "21767954": 42, "21768": [42, 49], "217680": [41, 42], "21774": 49, "218": [17, 24, 28], "218207": [16, 23, 35, 36], "21847": 49, "21872": [40, 42, 51], "218760": 42, "218830": [16, 23, 35], "218867": 27, "219": [28, 43], "2190": [16, 23, 35], "2192": 38, "219500e": 26, "219512": 43, "219700": 43, "219714": 27, "21972656": 47, "219845e": 40, "22": [15, 16, 22, 23, 28, 34, 35, 36, 38, 39, 40, 41, 42, 43, 47, 49, 50, 53, 54, 58, 59], "220": [28, 33], "2200": 28, "22001": 42, "220392": 50, "22057": 49, "2206": 50, "22078": 49, "221": 28, "2210": [12, 19, 26, 31], "22114": 49, "221329": 40, "221348": 49, "2214": 53, "22154": 49, "221622": [16, 23, 35, 36], "22168237": 54, "221760": 27, "221900": [13, 26, 32], "222": [1, 28, 59], "22219": 49, "22221894": 40, "222222": [16, 23, 35], "22225": 49, "222307": [16, 23, 35], "222500": [21, 33], "22260": 49, "222647": [40, 42, 51], "2229": [18, 37], "222963e": 40, "223": 28, "22305705": 41, "22320": 49, "223333": [21, 33], "223460": 50, "223750": [21, 33], "223804": 42, "224": [28, 38, 48], "224072": 30, "22452": 49, "2246468746": 33, "224662": 40, "22471154513694652": 18, "22471154513694713": 37, "224865": [40, 42], "225": 48, "225301e": 40, "2254": [16, 23, 35], "22550": 49, "225646": 30, "226": 38, "226415": [16, 23, 35], "226789": 50, "2268": 41, "22697768": [17, 24, 36], "226978": [17, 24, 36], "2270": 38, "227143": [16, 23, 35], "2272": [39, 52], "227304": 49, "22741": 43, "227559": [40, 42, 51], "227836": 39, "22788": 49, "22811601": [18, 37], "22826": 49, "228329": 39, "2285": 49, "22851562": 47, "228603": 40, "228750": [14, 21, 33], "229": 48, "229000": [16, 23, 35], "22910": 49, "229102": 42, "229167": 14, "2293467570951035": 41, "2295": 49, "229583": [14, 21, 33], "229718": 42, "23": [1, 15, 16, 18, 22, 23, 26, 28, 34, 35, 36, 37, 38, 39, 40, 43, 47, 49, 50, 58], "230": [15, 34, 38], "2300": [12, 19, 31], "230000": 26, "23011": 42, "2305": 42, "2307": [14, 18, 21, 33, 37], "2309": 49, "23091772": 41, "231": [1, 59], "2310": [26, 49], "2311": 49, "2312": 49, "2313": 49, "23175": 49, "231815": 42, "232": 28, "232075": 27, "232143": 36, "232751": 50, "23290": 49, "233": [13, 26, 32], "2334": 16, "234": 50, "234040": 39, "234303": 26, "234436": 50, "235": [28, 43], "235096": [16, 23, 35, 36], "235152": [15, 22, 34], "235417": 33, "235706": 43, "235833": 14, "236": [15, 28, 34, 38, 50], "2360": 26, "236096": 48, "236174": 43, "236210": 44, "23621041": 44, "23640124": [18, 37], "236456": [16, 23, 35], "23654": [39, 42], "236960": 38, "237": [28, 39, 50], "237935": 42, "238": [28, 39, 50], "238192": [39, 42], "2388": 26, "2389": 36, "239": [28, 50], "23902": 49, "239082": 27, "23941": 49, "239676": 30, "239944e": 40, "24": [1, 10, 12, 15, 16, 19, 22, 23, 27, 28, 31, 34, 35, 39, 40, 41, 42, 43, 47, 48, 49, 50], "240": 50, "2401": 43, "240893": 43, "241": 50, "241489": 50, "241620": 39, "24182": 49, "242015": [41, 42], "242083": 33, "242169": 39, "242381": 49, "242740": 27, "24295676": [17, 24, 36], "242957": [17, 24, 36], "242996": [16, 23, 35, 36], "243": 49, "2431": 16, "243243": 40, "2435": 43, "2436": 43, "24395": [41, 42], "24397122221206388": 49, "244": 49, "244592": [15, 22, 34], "2447": 41, "244814": 50, "245": 49, "2451": 38, "245329": 40, "245521": 39, "245635": 27, "245686": 39, "246": [49, 53], "246332": 40, "246486": 28, "246646": 38, "246646103936": 38, "246653": 38, "247": 49, "247119": 49, "2471338": 30, "247439": 44, "24743939": 44, "247690828913": 38, "247691": 38, "248": 49, "2483": 30, "248328": 41, "248333": [21, 33], "2484": [12, 19, 31], "248457": [40, 42, 51], "248609": 40, "248664": 43, "2487200875": 26, "2488": [15, 22, 34], "248999": 50, "249": 53, "2496": [14, 18, 21, 33, 37], "249601e": 40, "249618e": 40, "249720": [15, 22, 34], "24h": [39, 52], "24th": [12, 19], "25": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58], "2500": [8, 28, 53], "250000": [16, 23, 26, 35, 39, 40], "25031": 49, "25037": 49, "250588": 28, "2506": [13, 14, 21, 32, 33, 56], "250900": 40, "251093": 38, "251158e": 40, "2516": 41, "2517": 30, "25176": 49, "251769": 48, "252": 52, "252042": 43, "25214": 49, "252160": [15, 22, 34], "252859": 42, "2530": [12, 19, 31], "2533": [14, 18, 21, 33, 37], "253312": [16, 23, 35, 36], "253432": 42, "253724": [15, 22, 34], "253914": 40, "254380": 50, "254443": 39, "25498295": 28, "254983": 28, "255": [16, 23, 27, 35], "2550": 26, "2551": 53, "255134": 48, "2556": 41, "255751": 43, "255889": 49, "256": [12, 19, 31, 48], "25622": 49, "256263": [41, 42], "256333": [16, 23, 35], "256437": 43, "25658": 43, "256813": [15, 22, 34], "257": [13, 26, 32], "2570": [12, 13, 19, 26, 31, 32], "257024": 38, "257103": 39, "2574": 43, "257787": 28, "2580": [12, 19, 31], "258225": 49, "25823": 39, "258387": 42, "2584": 47, "258427": [15, 22, 34], "259": [40, 43], "259026": 27, "25904": 49, "2590575478171884": [18, 37], "259085": 27, "259286": [15, 22, 34], "259500": [16, 23, 35], "259520": 27, "26": [8, 12, 15, 19, 22, 23, 28, 31, 34, 35, 38, 39, 40, 41, 42, 43, 44, 47, 49, 50, 53], "2600": [16, 23, 35, 36, 58], "260145": 30, "260258": 43, "26048": 42, "260572": 40, "26063": 49, "260890": [40, 42, 51], "261035": 40, "261953": 49, "262": [40, 42, 50, 51], "262079e": 40, "262156e": 40, "262269e": 40, "2623": 40, "262361": 43, "262500": 40, "262990": 39, "263": 40, "2630": [16, 23, 35], "263000018": 26, "263541": 50, "263600": [16, 23, 35], "26370005": [18, 37], "263736": 50, "263742e": 40, "26376": 49, "264042": 30, "264195": 50, "264283e": 40, "26447953": [17, 24, 36], "264480": [17, 24, 36], "265": 41, "265273": [18, 37], "265483": 27, "266120": 49, "266135": [16, 23, 35, 36], "2670": 38, "267612e": 40, "268": 38, "2683": 39, "26831": 49, "2691": [13, 14, 21, 32, 33, 56], "26919": 43, "269880": [15, 22, 34], "269972": [40, 42, 51], "27": [1, 8, 15, 16, 17, 22, 24, 26, 28, 34, 36, 38, 39, 40, 47, 49, 50], "270093": 38, "270093376167": 38, "27021": 49, "270270": 46, "27048": 39, "2705": 38, "271037": 43, "271287": 49, "271500": 43, "271738e": 40, "2720": [13, 26, 32], "27206": 49, "27263": 42, "272667": [16, 23, 35, 36], "2730": [16, 23, 35], "27304": 26, "273382": [16, 23, 35, 36], "273606": [16, 23, 35, 36], "273890": 48, "2739": [20, 27], "273962": 43, "274": [16, 23, 35, 36, 49, 58], "274404": [16, 23, 35], "275008": 49, "27502379069": 40, "275290": 39, "275352": [15, 22, 34], "275410": [18, 37], "2759": 42, "276": [16, 23, 35], "27610135": 47, "27638": 49, "27652": 39, "276687": 40, "27676": [39, 52], "27678": [39, 52], "276943e": 40, "27697": [39, 52], "2770": 38, "27705": [39, 52], "27715": [39, 52], "277381": [15, 22, 34], "2777": 50, "278": 53, "278441": 49, "278634": 39, "27874871715903093": 37, "27874871715903127": 18, "278755": [17, 24, 36], "27875502": [17, 24, 36], "2788": [14, 18, 21, 33, 37], "27901526": 30, "2794": [18, 37], "28": [1, 15, 16, 18, 22, 23, 34, 35, 36, 37, 38, 39, 40, 43, 44, 47, 49, 50], "280": [16, 23, 35, 43, 53], "2800": 8, "280028": 43, "280310": [16, 23, 35, 36], "2806": 38, "280618": 39, "2807": 50, "280801": 50, "281": [16, 23, 35], "28122025543": 40, "281583": 40, "2817": 42, "2820": 38, "282021e": 40, "2822": 42, "282600": 50, "283119e": 40, "28327": 49, "283421": 40, "2836": 42, "28362": 49, "283857": [15, 22, 34], "283921": [16, 23, 35], "284": [30, 43, 49], "2845": 50, "2846": 53, "2847": 53, "285": [16, 23, 35, 36, 49, 58], "285263": 42, "28526302": 42, "285467": [40, 42, 51], "28571429": [13, 20, 32], "286": [14, 15, 21, 33, 34, 38, 49], "286000": 38, "286200": 43, "286326": 27, "286416": 36, "2865025": 54, "286821": [15, 22, 34], "287": 49, "287031": 49, "287079e": 40, "287344": [16, 23, 35, 36], "287500": 43, "28753559": 47, "288": 49, "288002": 49, "288462": [18, 37], "28854": 49, "28868": 39, "289": 49, "2890": [15, 34, 38], "28953": 49, "289541": [40, 42, 51], "289799": [15, 22, 34], "29": [8, 15, 16, 22, 23, 26, 28, 34, 35, 39, 40, 47, 49, 50, 53], "290": [26, 49], "290002": 39, "290424": 40, "29045704": 40, "290961e": 40, "291": [18, 26, 37, 49], "291310100": 26, "291667": 46, "292": 49, "292587": 50, "293": 49, "29324459": 48, "293663": 39, "294": [16, 23, 35, 47], "294251": [17, 24, 36], "2948": [16, 23, 35, 36, 58], "294855": 42, "295193": 27, "2953863599856858": 18, "2953863599856862": 37, "295397": 39, "29545": 40, "2957": 28, "29572402": 47, "2958": 28, "2959": 28, "296": [16, 23, 35], "2960": 28, "2961": 28, "2962": 28, "2963": 28, "2964": 28, "296601": 43, "29691": 49, "297": [18, 37], "29802": [39, 42], "298043": 27, "298436": 27, "298561": 50, "298612": 49, "29881": 49, "299": [26, 48], "299164": 43, "2d": [20, 28, 48], "2d454e5fd9a5": 50, "2e": 1, "2f": [14, 21, 29, 30, 33, 38, 46, 49], "2m7m0lw97rvf654x1cwtdfmr0000gr": 23, "2nd": [30, 37], "2ndflrsf": [40, 42, 51], "2v": 54, "2v3": 54, "3": [1, 7, 8, 10, 15, 17, 18, 22, 24, 27, 28, 29, 30, 34, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 51, 52, 54, 55, 59], "30": [1, 4, 12, 14, 15, 18, 19, 21, 22, 28, 31, 33, 34, 37, 39, 40, 41, 42, 43, 47, 49, 50, 51, 53, 59], "300": [15, 22, 34, 45, 47, 51, 54], "3000": [28, 48], "300000": [16, 23, 35, 36, 49], "3000000": 47, "300464": 43, "300837": 39, "301": 50, "3010": 43, "301200": 38, "3014": 43, "30146": 49, "301563": 40, "30167": 49, "301784": 50, "3018": 59, "301838": 51, "3019": [13, 14, 18, 21, 32, 33, 37, 56], "301952": 43, "302": [40, 42, 51], "302043": 27, "302131": 40, "30279": 49, "302801": 50, "302844": 50, "303": [40, 42, 51], "303000": [16, 23, 35], "303004": 43, "303030": [18, 37], "303109": [17, 24, 36], "303161": 30, "303694": 27, "303790": 38, "3038": 53, "3038344082": 42, "303916": [15, 22, 34], "304": [15, 22, 34], "3040": 49, "3041": 49, "3042": 49, "3043": 49, "304358": 30, "3044": 49, "304784": 40, "305": [12, 19, 31], "30504657": 44, "305047": 44, "30530902": [15, 22, 34], "305346": [15, 22, 34], "305674": 43, "3057": [14, 18, 21, 33, 37], "30573": 43, "305851": 30, "306500": [15, 22, 34], "306564": 48, "307": [16, 23, 35], "307516": 48, "307521": [18, 37], "30792853": 47, "30798381": 47, "308120": [16, 23, 35], "30815": 40, "308216": 48, "308236": 27, "308448": [15, 22, 34], "3089": 38, "308900e": 26, "309": 43, "3092": [13, 14, 21, 32, 33, 56], "309249": 48, "309859": [18, 37], "30am": 12, "30pm": 1, "31": [1, 12, 15, 16, 18, 19, 22, 23, 26, 31, 34, 35, 36, 37, 39, 40, 41, 42, 44, 47, 49, 50, 53, 58], "310000": [16, 23, 35], "31000e": [15, 34], "310284": 42, "31029469": 28, "310295": 28, "31038074": 47, "310405": 39, "311": [16, 23, 35], "3110": [16, 23, 35], "31103996": 30, "311151": 50, "31127015": 42, "311310": [12, 19, 31], "311769": 43, "3119640638146517": 18, "31196406381465247": 37, "3120": [16, 23, 35], "3125": [16, 23, 35], "312500": [16, 46], "312501": [40, 42, 51], "312696": 53, "3129": 53, "31297381": [17, 24, 36], "312974": [17, 24, 36], "31298589e": 48, "313": [36, 40], "31384": 39, "314": [16, 23, 35], "3140": [16, 23, 35], "314000": 38, "31449687e": 42, "31454": 43, "314582": 42, "314840": 43, "314929": 49, "315000": 26, "315134": 49, "315630": 39, "316164": 43, "316230": 43, "31634363": 47, "316363": [15, 22, 34], "316395e": 40, "316426": 43, "316552": [17, 24, 36], "31655231": [17, 24, 36], "316798": 43, "317": [1, 16, 23, 35, 42, 59], "317277": 43, "31767136668453344": 26, "317761": 39, "318": [16, 23, 35], "3180": 38, "3180174485124284": [16, 23, 35], "318937": [16, 23, 35, 36], "319": [13, 16, 17, 23, 24, 26, 32, 35], "31908384": 48, "319481": 27, "319559": 26, "319630": 50, "31984311": 40, "31st": 49, "32": [8, 15, 16, 18, 22, 23, 27, 28, 34, 35, 36, 37, 38, 40, 44, 47, 49, 50, 58], "320": [16, 23, 35], "320155": 39, "320430": 40, "32064171": 41, "3209427041566191": 26, "321": 42, "321050": 26, "32127053": 40, "322": 43, "32240": [41, 42], "322465": 26, "32247597e": 42, "322585": 30, "322755": [15, 22, 34], "323045": [16, 23, 35, 36], "32323": [12, 19, 31], "32397724e": 42, "3245": [12, 31], "324762": 27, "325000": 26, "3252": 43, "325319": 43, "32561": 39, "326": [16, 23, 35, 43], "326616": 26, "326730": 39, "326741e": 50, "326911": 30, "326933": [15, 34, 38], "327188": 39, "3272": 50, "327283": 40, "32734": 43, "3274": 50, "327408": 39, "32791718": 47, "328": 43, "328000": 26, "328077e": 40, "328944": 30, "328953": [15, 22, 34], "3298721": 48, "3299": [47, 53], "33": [8, 12, 15, 16, 18, 19, 22, 23, 26, 31, 34, 35, 36, 37, 38, 39, 40, 43, 47, 49, 50], "330": [9, 10, 13, 20, 28, 31, 32, 48, 49, 51, 53, 59], "33000e": [15, 34], "330346": 50, "330_vs_340": 12, "3310": [16, 23, 35], "331588": 27, "33191802": 47, "332130": 40, "33223002": 47, "3322447": 47, "33224516": 47, "33224759": 47, "332671": 42, "3327": 49, "332710": 40, "332746": 50, "332791": 50, "332824": 40, "333": 28, "3330": [16, 23, 35], "33308783": [17, 24, 36], "333088": [17, 24, 36], "333139": 39, "333333": [13, 16, 20, 23, 27, 32, 35, 38, 46], "3333333333333333": [46, 48], "333340": [15, 22, 34], "33380649": 47, "33380754": 47, "33380761": 47, "33381373": 47, "33394593": 47, "3339473": 47, "33394769": 47, "33395626": 47, "33397112": 47, "334": 43, "33400489": 47, "33411086": 47, "33425967": 47, "33435326": 47, "33439238": 47, "33440682": 47, "334411": [15, 22, 34], "334576": 40, "33462759": 47, "334764": 27, "33476534": 47, "335": 41, "335309": 40, "3355": [16, 23, 35, 36, 58], "3356700488_183566145b": 48, "33590": 49, "336389": 42, "33641142": 42, "3364114233677307": 42, "336411423367732": 42, "33643394": 28, "336434": 28, "336735": 38, "336826": [17, 24, 36], "33682642": [17, 24, 36], "33683087": [18, 37], "336831": [18, 37], "337034": 43, "33726089": 40, "33732465": 47, "337625": 27, "33782315": 47, "33797555": 47, "338": [15, 34, 38], "33888659": 8, "339": 39, "339368": 50, "339889": 50, "34": [12, 15, 16, 18, 19, 22, 23, 28, 31, 34, 35, 36, 37, 39, 40, 43, 47, 49, 50, 58], "340": [1, 3, 13, 20, 32, 41, 43, 48, 49, 50], "34000e": [15, 34], "340480": 30, "340988": 39, "341109": 40, "341300": 43, "341556": 30, "341571": 50, "34161762": [40, 42], "341712": 49, "34182": 42, "3420": [16, 23, 35], "342200": 43, "342605e": 40, "3436": 49, "3437": 53, "3438": 53, "344": [16, 23, 35], "3442": 50, "34426571": 40, "34441": 40, "345": 42, "345136": [15, 22, 34], "345386e": 40, "3454": [50, 53], "3455": 53, "345831": [12, 19, 31], "346": [16, 23, 26, 35, 36, 58], "346850": 39, "34691": 49, "347001": 30, "347523": 38, "348": [16, 23, 35, 43], "34806": 40, "348569": 51, "34900": 40, "34924955": 47, "35": [15, 16, 18, 22, 23, 26, 34, 35, 37, 39, 40, 41, 42, 47, 49, 50, 57], "350": [12, 19, 31], "3500": [28, 57], "350000": [16, 23, 35], "351351": 46, "351366": 39, "3515": 50, "351821": 50, "351883": 51, "3520": 50, "3521": [12, 19, 31], "352100": 43, "352930": [16, 23, 35, 36], "353": [1, 48, 59], "35375221": 54, "353961": 38, "354114": [40, 42, 51], "354604": 39, "3547": 43, "354759e": 40, "35561437": 47, "356689": [41, 42], "35671794": 42, "357": [16, 23, 35], "3573886": 47, "357500": [16, 23, 35, 36], "3576": [12, 19, 31], "35771821": 47, "357823": [12, 19, 31], "358": [12, 19, 31, 38], "358032": 42, "3582": [50, 53], "358264": [40, 42, 51], "3583": 53, "358333": [15, 22, 34], "358500": 43, "358913": [17, 24, 36], "3589134": [17, 24, 36], "359": [15, 34, 38], "3590": 38, "359784": 38, "359887": 44, "359992": [15, 22, 34], "35p": [12, 19, 31], "36": [15, 16, 18, 22, 23, 26, 28, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 49, 50], "360": [1, 36, 59], "360000": 26, "360918": 49, "361": 50, "361718": 39, "362": [26, 50], "362009": 49, "362185e": 40, "362553": 43, "36269995": [17, 24, 36], "362700": [17, 24, 36], "363": 50, "363192": [15, 22, 34], "363913": 39, "364": [49, 50], "364352": [18, 37], "365": 49, "36525": 42, "365420": 53, "365603": [18, 37], "365623": [15, 22, 34], "365898": 27, "365925": 27, "366": [17, 24, 36, 49, 50], "366005": 39, "366071": 16, "3663": 50, "366626": [15, 22, 34], "36695134": 47, "367": 49, "367329e": 50, "367423": 38, "368": [49, 53], "3681": 42, "368304": [18, 37], "3684": 50, "368406": 28, "368922": 45, "369": 40, "369822": 30, "369875": [15, 22, 34], "369896": 48, "37": [16, 18, 23, 26, 28, 35, 36, 37, 40, 43, 47, 49, 50, 53, 58], "37050406": 8, "370643": 39, "370842": 26, "371": [43, 49], "3717": 42, "371722": 42, "372": [16, 23, 35], "372572": 30, "372706": 49, "372763": [40, 42, 51], "373031": [15, 22, 34], "373275": 49, "373318": 27, "373411": 26, "373623580": 28, "373656": 49, "374": [16, 23, 35], "374584": 48, "374995": 39, "37546": 42, "376": [16, 23, 28, 35, 40], "376089": 40, "37647072": 41, "3768": 53, "3769": 53, "377032": 40, "377619": 38, "377619120792": 38, "37797291": [17, 24, 36], "377973": [17, 24, 36], "37807203": 47, "378159": 40, "378764": [15, 22, 34], "378971e": 40, "37903": 28, "37906": 39, "379416e": 40, "379875e": 40, "38": [8, 15, 16, 18, 22, 23, 26, 34, 35, 37, 39, 40, 43, 47, 49, 50], "3803": 50, "380436": [17, 24, 36], "38043616": [17, 24, 36], "380495": [15, 22, 34], "380504": [16, 23, 35, 36], "380643": [15, 22, 34], "381190": 43, "3814": 36, "381416e": 50, "381428": [40, 42, 51], "381676": [15, 22, 34], "38192364": 44, "381924": 44, "382558": 39, "3828125": 47, "383": [16, 23, 35, 43], "384111": 53, "384127": [15, 22, 34], "384528": 27, "384613e": 38, "3851": 39, "3856": [15, 22, 34], "385639": 44, "386": 38, "386071e": 40, "386467": 30, "386530": [42, 51], "387": 38, "387502": 30, "388014": 30, "388023": 39, "388169": 43, "38853": 40, "3889": 36, "389": [38, 43], "389065": 42, "389349": 43, "389736": [16, 23, 35, 36], "39": [15, 22, 34, 38, 39, 40, 44, 47, 49], "390428669205": 38, "390429": 38, "390691": 26, "390725": 40, "39095422e": 42, "391": [16, 23, 35], "3912": 50, "391304": 26, "39163": 39, "391996": 48, "392": [12, 19, 31, 50], "392082": 42, "392221": [18, 37], "392385": 50, "392612": 40, "392893": [15, 34, 38], "393": [13, 26, 28, 32, 36], "3932": 50, "39375": 49, "394113e": 40, "394920": [16, 23, 35], "395282e": 40, "395686e": 40, "395688": 50, "395697e": 40, "396": [16, 23, 28, 35, 50], "396266": 48, "396752e": 40, "396991": [16, 23, 35, 36], "397": 50, "398": 43, "398495": 49, "398915": 27, "39896994": [17, 24, 36], "398970": [17, 24, 36], "399": [16, 23, 26, 35], "3990": [13, 14, 21, 32, 33, 56], "3991": 40, "39931": 42, "399827": 39, "39x15": 47, "3blue1brown": 48, "3d": [43, 48], "3f": [13, 14, 15, 16, 20, 21, 22, 23, 29, 30, 32, 33, 34, 35, 39, 40, 46, 47, 53], "3h": 49, "3m": 48, "3rd": [30, 47], "3ssnporch": [40, 42, 51], "3v": 54, "4": [0, 1, 8, 9, 12, 16, 17, 18, 19, 23, 24, 26, 28, 30, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 59], "40": [8, 12, 15, 16, 18, 19, 22, 27, 28, 31, 34, 37, 38, 39, 40, 41, 42, 43, 45, 49, 50, 51, 57, 59], "400": [13, 16, 23, 26, 32, 35, 38, 51], "40000": [48, 49], "400000": [16, 26, 38, 49], "400047": 50, "400157": 43, "400164": 48, "400649628005": 38, "400650": 38, "400881e": 26, "401": [15, 26, 34, 38], "4011": 47, "401102": 49, "401541": 39, "401623": 40, "401729": 27, "4018": 59, "401830": 42, "401895": 38, "402": [12, 19, 31], "402101": 26, "402258": 26, "402808": 42, "404": [15, 22, 34, 43], "405": [41, 59], "405227e": 40, "405415": [15, 22, 34], "405650": 40, "406": 48, "406202": 38, "40689": 43, "407": 39, "407234": 48, "40725012": 48, "4074": 59, "407510": 39, "40756124": 41, "407862": 50, "4084": 50, "409": 59, "409430": 26, "40_000": 48, "40b5a809b05a": 50, "41": [15, 16, 22, 23, 34, 35, 39, 40, 42, 43, 44, 46, 49, 50], "410": [16, 23, 35], "410240": [39, 42], "410599": 43, "410714": 16, "411412": 40, "41150573": 40, "412": [12, 15, 19, 31, 34, 38], "41210938": 47, "412500": 43, "413050": 48, "413718": 50, "413796": 40, "413958": 39, "414": 53, "4143": 50, "414405": 27, "415": 28, "4151": 41, "4153": 43, "415383": 30, "4158382658": [23, 35, 53], "415888": 30, "416": 42, "4165": 41, "4169": 50, "418": 47, "418031": [15, 22, 34], "418069": 38, "41901484361": 38, "419015": 38, "419355": [18, 37], "4195": 42, "4197": [13, 14, 18, 21, 32, 33, 37, 56], "42": [12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 27, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 54, 56, 57], "420": 38, "420000": [12, 19, 31], "42060": 43, "421": 48, "42104086": 42, "421215": 44, "42121526": 44, "421875": [18, 37], "422": 40, "422222": 16, "4234": 42, "4236": 42, "4238": 39, "423852": 39, "424222": 40, "424337e": 40, "425": 41, "425365": 50, "42541681": 54, "425419": 40, "426067": [16, 23, 35], "426410": [15, 22, 34], "427": 50, "427516": 27, "4276": 52, "428": 50, "428279": 27, "429": [40, 42, 51], "429217": 39, "429634": 50, "4296875": 47, "43": [15, 18, 22, 34, 37, 38, 39, 40, 49, 50], "430": [38, 40, 42, 50, 51], "430323": [16, 23, 35], "430571": 39, "430704": 44, "4307043": 44, "430868": [18, 37], "431": [33, 50], "4310": [15, 16, 23, 34, 35, 38], "431104": 27, "431137": [18, 37], "4314": 39, "432": 50, "433": 50, "433514": 49, "433814": 50, "434": [15, 18, 34, 37, 38, 50], "43445": 43, "435": 50, "435186": [15, 22, 34], "435489": 39, "435792": 38, "436": 50, "436492": 40, "43697758253484525": 18, "43697758253484614": 37, "4372": 44, "437367": [16, 23, 35, 36], "4375": [43, 46], "437500": 46, "437684": 49, "438": 46, "438231": 48, "438275": [17, 24, 36], "43827545": [17, 24, 36], "43833466": 40, "438592": [42, 51], "438906": 42, "439": [16, 23, 35], "4390": [15, 34, 38], "439209": 39, "439254e": 28, "439360": [16, 23, 35], "439779": 39, "44": [14, 15, 16, 18, 21, 22, 23, 33, 34, 35, 37, 39, 40, 43, 47, 49, 50, 53], "440": [38, 49], "440897": 26, "441": 40, "441404": 48, "441445": 43, "442": 26, "442377e": 40, "442806": [15, 22, 34], "442917": 27, "4430": 50, "44311": 43, "4432": 43, "443317": [15, 22, 34], "443419": [40, 42, 51], "444297": 43, "4443": 16, "444444": [16, 23, 35], "4448": 43, "445": 38, "445111e": 40, "445124e": 40, "44586935": 41, "44586935141902073": 41, "446216": 43, "446284e": 40, "446869": 43, "447": [16, 23, 35, 42], "447461": 49, "447517": 42, "44787197": 47, "4482": [12, 19, 31], "4484": [15, 22, 34], "448757": 50, "449262": 27, "449666": [15, 22, 34], "44966612": [15, 22, 34], "45": [8, 13, 14, 15, 16, 18, 21, 22, 32, 33, 34, 37, 39, 40, 47, 49, 50, 52, 56], "450000": 46, "450000e": 26, "450132": 49, "450739": 40, "450822": 43, "451888": 39, "452600": 43, "453367": 43, "4537": 50, "454427": [16, 23, 35, 36], "454677": 44, "45467725": 44, "454788": [42, 51], "454966": 39, "455": 36, "455026455026455": 28, "4552": 42, "455410": 30, "45555535": 42, "455652": 26, "45587": 49, "45588": 49, "45589": 49, "45590": 49, "45591": 49, "456": 48, "456419": 43, "45653693": [17, 24, 36], "456537": [17, 24, 36], "457435": 49, "45756": 53, "458": [16, 23, 35], "458333": 46, "458524": 50, "459": [28, 40], "4591": [16, 23, 35], "459214e": 40, "459873": 50, "459937": 47, "45a": 49, "45am": 49, "46": [8, 13, 14, 15, 16, 18, 21, 22, 23, 28, 32, 33, 34, 35, 36, 37, 39, 40, 49, 50, 53, 56, 58], "460047": 50, "46019608e": 42, "46021": 53, "46075": 53, "4608": [13, 14, 21, 32, 33, 56], "460950": 44, "461": [16, 23, 35, 38], "462060": 50, "462545": 42, "462963": [18, 37], "46299": 53, "463": 39, "46357616": 28, "463582": 41, "464104e": 40, "465279e": 40, "46530779": [17, 24, 36], "465308": [17, 24, 36], "466246": 48, "4664": [12, 19, 31], "46666667": 28, "46729488": 40, "467379": 42, "467628": 43, "468": [15, 34, 38, 42], "468232": 49, "4687": 43, "46880": 53, "468995": 27, "469": [16, 23, 35, 39], "469383": 39, "4695": 39, "469571": 43, "47": [1, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 26, 31, 32, 33, 34, 35, 37, 38, 40, 43], "470": [16, 23, 35, 53], "4700": 38, "470060": 40, "470666": 40, "471000": 26, "471032": 42, "472": [17, 24, 53], "47242662": 54, "4726": 50, "472603": 40, "472790": 39, "473": 47, "473691": [15, 22, 34], "474": [28, 39], "474552": [15, 22, 34], "47491": 39, "475": 28, "475099": 42, "475540": 47, "476": [13, 20, 28, 32], "4760": 38, "47606": 43, "476092": [40, 42, 51], "476406": 42, "476412": 44, "47641249": 44, "477": [28, 38], "477291": 43, "47799": 53, "478": 28, "478060": 49, "47810154525386317": 28, "478515": 27, "479": 28, "479109": [15, 22, 34], "479132": 43, "479773": 47, "48": [13, 14, 15, 18, 21, 22, 32, 33, 34, 37, 39, 40, 46, 49, 50, 56, 59], "480": [28, 40], "4800": [12, 19, 31], "480249": [15, 22, 34], "4806334": 47, "48073598": 44, "4809": 38, "481": [16, 23, 28, 35], "4810": 52, "4813": [14, 18, 21, 33, 37], "481514": 40, "481793": [16, 23, 35], "481893": 39, "481960": 39, "482": 28, "4820": 26, "4822": 50, "483": 28, "48344371": 28, "483751": [15, 22, 34], "48390": 53, "484": 28, "48407": 53, "484937": [18, 37], "485": [28, 48], "485191": 27, "48535": 53, "4854": 42, "485722": 47, "486": [28, 42], "4861": [16, 23, 35, 36, 58], "486266": [16, 23, 35], "486664": 47, "487": [16, 23, 35], "48721": 53, "487740": 47, "4879": 53, "488": [16, 23, 28, 35], "488163": 47, "488753": 49, "489": 28, "489130": [18, 37], "489593": 47, "49": [15, 16, 18, 22, 34, 37, 39, 40, 43, 49, 50], "490": [28, 43, 54], "490000": [16, 23, 35], "490033": 40, "490568": 38, "490797": 47, "490930": 47, "491217": 39, "491366": [42, 51], "491379": [16, 23, 35, 43], "491968": 47, "492": [16, 23, 35, 39], "492270": [17, 24, 36], "492307": 47, "492551": 47, "493": [16, 23, 32, 33, 35], "493489": 47, "493544": [16, 23, 35], "493921": [17, 24, 36], "494": [15, 16, 23, 34, 35, 38], "4943": 38, "494309": 26, "495524": 27, "49575": 39, "496": 43, "496213": 40, "49668874": 28, "496757": 42, "497143": 47, "497386": [15, 22, 34], "497787": 40, "497949": 47, "498": [39, 52], "498133e": 40, "498164": 27, "498562": [15, 22, 34], "499900": [16, 23, 35], "4f": [15, 17, 22, 24, 29, 30, 34, 36, 39, 47], "4m": 48, "4th": [30, 39, 41, 42], "4x": 59, "5": [1, 4, 18, 26, 27, 30, 31, 37, 38, 40, 41, 45, 46, 49, 53, 54, 55, 56, 59], "50": [1, 12, 15, 16, 17, 19, 22, 23, 24, 26, 28, 30, 31, 34, 35, 36, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 59], "500": [12, 14, 16, 19, 23, 29, 30, 31, 35, 39, 41, 42, 43], "5000": [12, 13, 19, 26, 30, 31, 32, 52], "50000": 49, "500000": [15, 16, 23, 26, 35, 36, 39, 40, 45, 49, 53], "500000e": [26, 38], "500001": [16, 23, 35], "5002": 40, "500625": [15, 22, 34], "50062e": [15, 34], "500924": [16, 23, 35, 36], "501": [16, 23, 35, 53], "501071": 48, "501191": 47, "501250": [15, 22, 34], "501304e": 40, "5014": 12, "501875": [15, 22, 34], "5024752475247525": 38, "502500": [15, 22, 34], "502985": 39, "503": 30, "503000": [16, 23, 35], "503090": 39, "503125": [15, 34], "50325": 30, "50350": 30, "503750": [15, 22, 34], "503807": 47, "504": [15, 22, 30, 34, 43], "504231": 50, "504375": [22, 34], "504429": [17, 24, 36], "504644": 38, "50475372e": 42, "504fde4fcf8": 50, "505000": 15, "505026": 26, "505180": 47, "505335": 39, "505592e": 40, "505625": [15, 22, 34], "5057": 40, "50596432e": 54, "506023": 41, "506035e": 40, "506052": 30, "506079e": 40, "506084e": 40, "506211": [16, 23, 35, 38], "506250": 22, "506410": [18, 37], "50666667": 28, "506875": [15, 22, 34], "507130": 38, "507359": [16, 23, 35, 38], "507500": [15, 34], "50774": 38, "507740": [16, 23, 35], "50775": 38, "507750": 38, "507752": [16, 23, 35, 38], "507995": [18, 37], "508": [16, 23, 35, 40], "508125": [15, 22, 34], "508133": [16, 23, 35, 38], "508371": 38, "508534": 47, "508741": 47, "508750": 22, "50884": 43, "50899": 38, "509000": [12, 19, 31], "509001": 40, "509045": 26, "509317": [16, 23, 35, 38], "5098": 47, "509859": 47, "509930": 49, "50k": [39, 41, 42], "51": [15, 16, 22, 23, 34, 35, 36, 38, 39, 40, 42, 44, 49, 50, 51, 58], "5100": 26, "510000": [13, 15, 26, 32, 34, 38], "510421": 47, "510505": 47, "5106": 53, "510625": 22, "510697e": 26, "5107": 26, "510836": 38, "5109": 42, "511": 9, "5112": [13, 26, 32], "51137414e": 42, "51143": 43, "51150": 39, "511620e": 40, "5118": 42, "511875": 22, "512": 48, "5120": [12, 19, 31], "512000": [15, 34, 38], "51226051": 44, "5123": 47, "512319": [16, 23, 35], "512408": [40, 42, 51], "512897": [15, 22, 34], "512x640": 48, "513": [16, 23, 35], "5131": 47, "513125": 15, "513333": 28, "513678": 50, "513750": 15, "514150": 47, "514155": [16, 23, 35, 36, 40], "514347": 47, "514598e": 40, "5146": [18, 37], "514950": 28, "515000": 34, "51503393": [17, 24, 36], "515034": [17, 24, 36], "515351e": 40, "5156": [16, 23, 35, 43], "515755": 28, "515848": 43, "516199": 47, "516394": 43, "516556": 28, "516788": 27, "516858": 47, "517273": 47, "517346": 39, "518113": 47, "519000": 26, "519029": 39, "519129": 27, "52": [15, 16, 18, 22, 23, 34, 35, 37, 39, 40, 43, 49, 50, 53], "520495": 47, "52061": 49, "520700": 47, "520782": 47, "5208": [13, 26, 32], "520857": 39, "5209": 40, "5212": 40, "521284e": 40, "521567e": 40, "521578e": 40, "521743e": 40, "521772": 47, "522": 40, "522563e": 40, "5227966": 47, "523595": 47, "523684": 47, "5238095238095238": [13, 20, 32], "52398": 43, "524": [13, 20, 32, 46], "524364": 50, "525": 28, "5253": 42, "525554": 43, "525757": [15, 22, 34], "526046": 47, "526078": [16, 23, 35, 36], "526214": 42, "526442": 27, "526596": 43, "526602": 40, "526783": 27, "5274": 50, "527500": [16, 23, 35], "528": 40, "5282": 50, "528403": [15, 22, 34], "52881619": [15, 22, 34], "529210": 39, "529388e": 40, "5294": 41, "529412": [16, 23, 35], "52980132": 28, "53": [18, 26, 37, 40, 49], "530052": 38, "530978": 39, "531": 51, "5310": 16, "531116e": 40, "531353": 48, "5315": 38, "53187": 52, "532034": 40, "533027": 27, "533333": 16, "533454": 48, "533498": [15, 22, 34], "534069": 30, "534114": 38, "534342": 43, "5345": 26, "535": [16, 23, 35, 43], "535014": [16, 23, 35], "53520104": [15, 22, 34], "535604": [16, 23, 35], "535622": 43, "536362": 44, "53636249": 44, "537267": [16, 23, 35], "537732": 47, "538000": [13, 26, 32], "538702": [15, 22, 34], "538816": 39, "5390": [39, 42], "5391": [16, 23, 35, 43], "539116": 49, "539258": 27, "539376": 50, "539459": 53, "539989": 26, "54": [40, 49, 50], "540": 49, "540000": [16, 23, 35], "540039": 47, "540359": 43, "541117": 40, "541347": 47, "541488": 43, "54152": 39, "541667": 36, "541795": 39, "542": 51, "54240": 39, "542624": 42, "542873": [16, 23, 35, 36], "543297": 38, "543351": 42, "543464": 47, "543678": 27, "544": 38, "544079": 27, "544462": 42, "545": 40, "546": [16, 23, 35], "5461": 40, "546150": 27, "546473": [18, 37], "546610": [15, 22, 34], "54676006e": 42, "547": [38, 40, 42], "547090": 47, "5471258278145695": 28, "547993": 39, "548831": 42, "54966887": 28, "549682": 39, "5498": [15, 22, 34], "549946": 47, "55": [13, 14, 15, 18, 21, 22, 32, 33, 34, 37, 39, 40, 41, 42, 49, 50, 51, 56], "55000": 38, "550000": [16, 23, 35, 36, 38], "550004": 41, "550616": 39, "55101": 49, "5513": 38, "5514": [41, 42], "5515": 50, "551579e": 40, "551862e": 40, "551975": 40, "552": [16, 23, 35, 40], "552492": 26, "552721": 41, "553": 26, "553125": 15, "553965": 42, "553979": 39, "5540": 50, "5541306485809793": 41, "55413065": 41, "554180": 49, "554463": 47, "554621": 43, "5551": [18, 37], "555180": 26, "555740": [15, 22, 34], "5566": [16, 23, 35, 36, 58], "556716": 28, "557197": 48, "557242": 39, "557739": 40, "558": [40, 42, 43, 51], "558564": 39, "55862988e": 42, "55873324": 48, "5588": [12, 19, 31], "558824": 39, "558889": 40, "559": [38, 40, 42, 51], "559284": 26, "56": [15, 22, 34, 36, 39, 40, 49, 50], "560": 26, "560053": 26, "560225": [16, 23, 35], "560625": 22, "560768": 40, "5609808539232339": 16, "561": [1, 15, 34, 38, 42, 43], "561467": [16, 23, 35, 36], "561602": 42, "561645e": 40, "562112": [16, 23, 35], "5623062252998352": 47, "562712": 47, "563": 1, "5630224174651539": 37, "5630224174651548": 18, "5630921721458435": 47, "563125": 15, "5631500400": 26, "563314": [40, 42, 51], "563467": [16, 23, 35], "5644": 40, "564483": 43, "565": 43, "5650": [13, 26, 32], "565062": 50, "56521734": 8, "565625": 22, "565679": 39, "565746": 50, "565888": [16, 23, 35], "566": [16, 23, 35], "566092": [16, 23, 35], "566222": 48, "5667": 39, "567724": 48, "567856e": 40, "568": 48, "568009": [15, 22, 34], "56804591": 40, "568125": 15, "568663": 40, "5690201394302518": 42, "56902014": 42, "569375": 34, "5694": 43, "57": [15, 16, 22, 23, 26, 34, 35, 36, 39, 40, 42, 49, 50, 51, 58], "57000": 50, "570015": 40, "570449": 39, "570473": 43, "570648": 30, "5707": 50, "570739": 43, "571": [28, 44, 54], "571431": 47, "571500": 43, "571800": 26, "571875": 22, "571901e": 40, "571969": 43, "572": 1, "572105": [15, 22, 34], "572500": 15, "572549": [16, 23, 35], "572962": 50, "573": 54, "573050": 39, "573125": 15, "573129": [40, 42, 51], "5732": [39, 52], "57333333": 28, "573542": 43, "573818": 39, "574": 26, "57415": 49, "574260": 43, "575000": 46, "575043": 26, "575046357615894": 28, "57510": 43, "5755444169044495": 47, "575636": 28, "575907": 43, "576": [16, 23, 35], "57615894": 28, "57640869": [17, 24, 36], "576409": [17, 24, 36], "576921": 47, "577500": 15, "578452": 27, "578523": [18, 37], "578569": 27, "578654": 39, "5789": 40, "579091": 43, "579245": 47, "579432": [18, 37], "579559e": 40, "579660": 41, "5798": 41, "57994": 39, "58": [13, 14, 15, 18, 21, 22, 32, 33, 34, 37, 40, 49, 50, 56], "580": 48, "580302e": 26, "5804311633110046": 47, "580539e": 40, "580625": 15, "581": 42, "5813": 26, "58137177": [17, 24, 36], "581372": [17, 24, 36], "5814": [12, 19, 31], "581687": 43, "581787": 50, "582": [12, 19, 31, 41], "582090": 39, "5824530720710754": 47, "582469": 40, "582570": 28, "583": 26, "583125": 15, "58387198": 44, "583872": 44, "583972": 27, "584": [16, 23, 35], "584615": [16, 23, 35, 43], "585": [16, 23, 35], "585157": 30, "585187": 28, "585513": [18, 37], "5857": 50, "586095": [16, 23, 35, 36], "586875": 22, "587773": 39, "588": [15, 34, 38], "588125": 34, "588235": [18, 37], "588307": [16, 23, 35], "589286": 53, "59": [1, 12, 15, 16, 18, 19, 22, 34, 40, 49, 50, 59], "590": 26, "590243": 47, "59049": 39, "59050": 39, "590618": 43, "590625": 15, "59082668": [17, 24, 36], "590827": [17, 24, 36], "5915": 36, "592": 53, "592401": [12, 19, 31], "59243876": 41, "592507": 27, "5925410985946655": 47, "59300": 43, "5931": 40, "593370": 40, "593508": 44, "5938": [16, 23, 35], "594": [16, 23, 35], "5941": 26, "5944": 26, "594595": [15, 22, 34], "594982": 39, "594995": 39, "5950": [16, 23, 35], "595000": 22, "595427": 48, "595569e": 40, "595625": 15, "596088e": 40, "596151": 43, "596810": [15, 22, 34], "596864": 40, "596875": 22, "5970": 41, "59700": 39, "597015": [18, 37], "59708": 39, "597326": 39, "597555": [12, 19, 31], "597924": [40, 42, 51], "598": [16, 23, 35], "598057": 28, "59810": 39, "598100": [18, 37], "598149": [40, 42, 51], "598750": 34, "599": 53, "5993570685386658": 47, "599492": [18, 37], "599860": [15, 22, 34], "599894": 49, "59pm": [12, 19], "5fin": 40, "5th": [39, 41, 42], "5unf": 40, "6": [1, 8, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 59], "60": [8, 12, 16, 19, 23, 31, 35, 39, 40, 42, 43, 44, 46, 47, 49, 50, 51], "600": [16, 18, 23, 35, 37, 47], "60000": 49, "600000": [14, 15, 22, 33, 34, 38, 49], "600193": 39, "60023631": 40, "600288": 27, "600625": 22, "600k": 40, "601": 38, "601042": [12, 19, 31], "601504": [18, 37], "601712": 39, "601790": [18, 37], "602": [16, 23, 26, 35, 36, 58], "602000": [16, 23, 35], "602649": [15, 22, 34], "6028": 39, "602941": 39, "602954": 41, "603125": 22, "6031432151794434": 47, "60319915": 54, "603243": 26, "603684e": 38, "603739": 26, "603970": 50, "604": [15, 22, 34], "6040": [15, 34, 38], "604000": [13, 26, 32], "604032": 39, "60429913": 40, "604320": [18, 37], "604421": 30, "60455": 49, "604619": [18, 37], "604797": [18, 37], "6048": 49, "604807": 50, "60495488": [15, 22, 34], "605060": 39, "6051": [16, 23, 35, 36, 58], "605100": [18, 37], "605101": [18, 37], "605102": [18, 37], "605263": [15, 22, 34], "605625": 34, "605696": [18, 37], "606": [16, 23, 35], "606061": [18, 37], "6063088774681091": 47, "606557": [18, 37], "606567": [18, 37], "606811": 38, "606875": 34, "606902": [18, 37], "607062": 49, "608050": [18, 37], "608125": 34, "6082": [16, 23, 35], "608468": [18, 37], "608532": 48, "608565": 50, "60860": [16, 23, 35], "6086405515670776": 47, "609": [16, 23, 35], "6092": [12, 19, 31], "6093292236328125": 47, "609375": 34, "60943": 39, "60k": 40, "61": [15, 17, 18, 22, 24, 34, 36, 37, 39, 40, 44, 49, 50], "610000": 15, "610142": 27, "61029914": 40, "610407": 39, "610931": 45, "611": 36, "611007": 48, "6111123561859131": 47, "611178": 49, "612349": [17, 24, 36], "61234944": [17, 24, 36], "6124": 50, "612500": 22, "612546": 39, "612621": [18, 37], "612755": [15, 22, 34], "613231": 28, "613507": [18, 37], "613738": 38, "613738418384": 38, "614": [16, 23, 35], "61420598": [17, 24, 36], "614206": [17, 24, 36], "614567": 43, "614872": 27, "615": [16, 23, 35], "615000": 22, "6154": [16, 43], "615730": 41, "616": 38, "616099": 38, "6168": [13, 26, 32], "617234": 30, "617342": 50, "617431": 45, "6176": 39, "617647": 39, "618": [16, 23, 35], "618000e": 26, "618012": 38, "6186580061912537": 47, "618967": 47, "619": 53, "61912405": 42, "619375": 22, "62": [15, 16, 22, 28, 34, 38, 39, 40, 49, 50], "620726": 27, "6210": 26, "622255": [16, 23, 35], "622454": 38, "622500": [15, 34], "6226": 43, "622612": 39, "622709": [18, 37], "623000": [16, 23, 35], "62320": 49, "62352928": 41, "624049": 40, "6241": [12, 19, 31], "624375": 34, "624450e": 40, "624615": 40, "6250": [16, 23, 35], "625387": 38, "6257": 50, "626206": 40, "62657": 49, "626875": 34, "62688064": 42, "627": 50, "6273": 38, "6275": [13, 14, 21, 32, 33, 56], "627722": 42, "627966": [16, 23, 35], "628032": 43, "628139": 39, "62873917": 42, "629792e": 40, "63": [15, 22, 34, 38, 39, 40, 49, 50, 53], "6303": [16, 23, 35, 36, 58], "6306": [16, 23, 35, 43], "630625": 15, "631899": 50, "632": 53, "6320": [18, 37], "6320979595184326": 47, "6322": 43, "632296": 27, "632353": [30, 39], "632786": 49, "63316788": 54, "63362": 40, "633933424949646": 47, "634397": [18, 37], "634490": 36, "634686": 39, "635": [16, 23, 35], "635200": 43, "635239": [16, 23, 35, 36], "635648": [18, 37], "636": [12, 16, 19, 23, 31, 35, 36, 50, 58], "636364": [16, 53], "636410": 41, "636849e": 40, "637": 48, "637982": [15, 22, 34], "638169": 42, "6389": [16, 23, 35, 43], "6391518364256": 50, "6392": 43, "639754": 40, "64": [10, 15, 16, 18, 22, 34, 37, 40, 48, 49, 50], "640": [38, 48], "6400": [16, 23, 35], "640000": [39, 53], "640266": [16, 23, 35, 36], "640625": 15, "640x480": [15, 22, 34], "641216": 49, "6414100192": 26, "641538": 50, "641873": 40, "642071": 27, "642676": 49, "642965": 39, "643": 38, "6431": 43, "643311e": 40, "643315": 28, "643750": 15, "644106": 39, "64417243": 48, "644375": 22, "64454": 39, "644770": 45, "6453951434878586": 28, "645519": 39, "6458": [13, 14, 21, 32, 33, 56], "645963": 38, "646050": 42, "6464": 50, "646617": 51, "647796": 43, "648": [15, 16, 23, 34, 35, 38], "6480": 41, "648195": 39, "648550": 48, "649658": 42, "64994": 49, "65": [13, 17, 24, 32, 36, 40, 50], "650": 39, "65000": 38, "650000": 38, "65000e": [15, 34], "65013704": 44, "650743": 26, "6507517": 28, "650752": 28, "651": 26, "651250": 15, "65125032": 54, "6513": 42, "651359e": 26, "651446": 49, "651875": 22, "65243": 40, "652487": 43, "6526853": 40, "652828": 38, "652986": 43, "653": [16, 23, 35], "653205": 38, "653205232272": 38, "654": [16, 23, 35], "65424895": 40, "654375": 22, "65486": 47, "656297e": 40, "656349": [15, 22, 34], "656827": 39, "656873": 26, "657675": 43, "658047": [18, 37], "658645": [18, 37], "659056": 40, "66": [13, 14, 16, 18, 21, 23, 32, 33, 35, 37, 39, 40, 48, 49, 56], "6600060120": 26, "6601256728172302": 47, "660171": [15, 22, 34], "6604": [16, 23, 35, 36, 58], "660714": 36, "661023": 47, "66214339": [15, 22, 34], "66221": 49, "6622507572174072": 47, "662450": 39, "662541e": 40, "662745": [16, 23, 35], "662879": 41, "66368": 42, "663680": [40, 42, 51], "6637": 50, "6638": 50, "663822": 42, "6639": 50, "6639009118080139": 47, "6641": 50, "6642": 50, "664207": 39, "6643": 50, "6644": 50, "6645": 50, "664625": 47, "664707": [18, 37], "66473": 49, "665": [16, 23, 35], "665307": 47, "665351e": 40, "665625": 34, "665882": 41, "666": [16, 23, 35, 36], "666166": 49, "6666666666666666": 48, "666667": [14, 16, 23, 33, 35, 46], "666754": 48, "667450": 49, "668": 47, "668787": [15, 22, 34], "6688": [12, 19, 31], "66941678": 28, "669417": 28, "669614": 39, "669805e": 40, "67": [13, 14, 17, 18, 21, 24, 32, 33, 36, 37, 39, 40, 49, 50], "670344": [15, 22, 34], "6709133982658386": 47, "671272e": 26, "67186503136": 40, "6731126308441162": 47, "673277": 38, "6733067729083665": 28, "6733849048614502": 47, "6734487414360046": 47, "674": 28, "6744": 42, "674490": 38, "674721": 41, "675000": [12, 19, 31], "67501": 49, "67512181": 40, "67562658": [17, 24, 36], "675627": [17, 24, 36], "675676": 46, "675814": [15, 22, 34], "6759470198675496": 28, "676": 51, "676250": 34, "67672595": 40, "677": [16, 23, 28, 35], "6771429181098938": 47, "6772": 50, "677268": 50, "677567": 26, "677579": [15, 22, 34], "677601": 38, "677629": [15, 22, 34], "6778583526611328": 47, "678": [15, 34, 38], "678000": 26, "678689": [18, 37], "679240": 26, "679478": [16, 23, 35], "679877": [40, 42, 51], "68": [13, 14, 15, 17, 21, 22, 24, 32, 33, 34, 36, 39, 40, 42, 44, 45, 49, 50, 54], "680000": [12, 19, 31], "6800296306610107": 47, "680657": [16, 23, 35], "681223": [15, 22, 34], "681428": 27, "681566": 30, "681716": 47, "683015": 41, "683171": 39, "68323": 38, "68339": 49, "684211": [15, 22, 34], "684447": [16, 23, 35], "684960": [16, 23, 35, 36], "685": 26, "685006": 28, "685103e": 40, "68523": 49, "685786": 41, "6858": [18, 37], "686": [16, 23, 35], "686348e": 40, "687": 40, "687055": 39, "687307": 38, "687500": [14, 33], "687504": 47, "688": 38, "6880359361853475": 37, "6880359361853483": 18, "688043475151062": 47, "688135": 38, "688484": 26, "68896004": 30, "689338": [40, 42, 51], "69": [13, 14, 15, 17, 21, 22, 24, 32, 33, 34, 36, 40, 44, 49, 50], "690": 53, "69027185e": 42, "690402": 38, "690778": 42, "691241": 39, "691617": 47, "691640": [15, 22, 34], "691877": 38, "691924": 44, "69192445": 44, "692131": 27, "692308": [16, 23, 35], "692500": 15, "693": [16, 23, 35], "6932538631346579": 28, "693498": 38, "693590": [17, 24, 36], "6938": [12, 19, 31, 49], "693890": 49, "693898": 49, "693936": [17, 24, 36], "69393613": [17, 24, 36], "694": 28, "69411": 43, "694155": [15, 22, 34], "694334": 41, "6950": 42, "695532": [16, 23, 35], "695783": 47, "696": 28, "696034e": 40, "6962": [16, 23, 35], "6963": 42, "696373": [16, 23, 35], "696429": 39, "696712": 49, "696859": 38, "696875": 34, "696970": [18, 37], "69698010e": 42, "697": [16, 23, 35, 43], "697248": 39, "6973": [16, 23, 35], "698": [16, 23, 35], "698125": 15, "698167": 49, "698206": 40, "698384608345687": 38, "698385": 38, "6984": 43, "698857": 38, "699224": [15, 22, 34], "6993": 26, "699706": 48, "699901396097971": 45, "6th": [39, 41, 42], "7": [1, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55], "70": [13, 14, 17, 21, 24, 26, 27, 30, 32, 33, 36, 39, 40, 44, 45, 49, 50, 51], "70000": 49, "700000": 49, "700000e": 26, "700855": 39, "701128": 49, "701173": 38, "701186e": 40, "70162085e": 42, "7017": 50, "701863": 38, "702703": [15, 22, 34], "703406": 50, "704": [15, 16, 22, 23, 34, 35, 40], "704099": [17, 24, 36], "7041": 47, "7042": 50, "7043": 50, "7046136400143138": 37, "7046136400143141": 18, "70472": 43, "704969": 38, "705000": [16, 23, 35], "705470": 47, "705511": 38, "70560276": [17, 24, 36], "705603": [17, 24, 36], "70568": 40, "705696": [15, 22, 34], "705882": [14, 21, 33, 38], "70588235": [14, 21, 33], "705898": 43, "706": 36, "706128": [15, 22, 34], "706444": 39, "706489": 26, "706783": [17, 24, 36], "70678332": [17, 24, 36], "706966": 49, "707681": [15, 22, 34], "707712": 50, "707850": 28, "707899": 44, "70789903": 44, "70799": 38, "708": [16, 23, 35, 36, 38, 41, 58], "708075": 38, "708527": [16, 23, 35], "708978": 38, "709185": [15, 22, 34], "70978": 43, "709874": 38, "709880": 38, "709893": 49, "7099": 43, "71": [12, 13, 14, 17, 18, 19, 21, 24, 31, 32, 33, 36, 37, 39, 40, 44, 49, 50], "710000": [16, 23, 35], "710031": 42, "710526": [15, 22, 34], "710896": 39, "71096": 43, "711": [36, 38], "711077": [16, 23, 35], "711086": 38, "711356": 26, "711717": 38, "711754": [16, 23, 35, 36], "711819": 47, "711852": 43, "71199006": 40, "712": [16, 23, 35], "712074": 38, "71219761": [17, 24, 36], "712198": [17, 24, 36], "712324": 38, "712402": 41, "7129": 38, "7129300520": 26, "713": 36, "71327467": 40, "714": 48, "714077": [16, 23, 35, 36], "714286": 38, "714375": 22, "714745": 39, "715072": 48, "71517": 38, "7153": 50, "715424": 38, "715728": 39, "715845": 28, "715992": 48, "716157": 39, "716655": 38, "716657": 38, "716792": 39, "716985": [15, 22, 34], "717289": 38, "717391": 38, "717829": [16, 23, 35], "718242": 38, "718266": 38, "718524": 49, "71866979": 40, "718750": 34, "7188": 36, "719": [12, 16, 19, 23, 31, 35, 43], "719056": 41, "719146": 30, "719427e": 40, "719500": [15, 22, 34], "719747": 39, "719915905190645": 26, "72": [13, 14, 15, 21, 22, 32, 33, 34, 39, 40, 49, 50, 56], "7200": 26, "720357": 49, "72036": 49, "720497": 38, "720859": [16, 23, 35], "720893": 50, "720904": 49, "72098474": 30, "7210": [13, 26, 32], "721006": 38, "721008": 38, "721250": 22, "7212512828409687": 18, "7212512828409691": 37, "721616": 38, "721705": [16, 23, 35], "7218": [13, 14, 21, 32, 33, 56], "721818": 43, "721917": 26, "721921": [16, 23, 35], "722": [16, 23, 35], "722241": 38, "722249": 38, "722803": 26, "722873": 26, "723": [16, 23, 35], "72345029": 40, "723602": 38, "723613": [15, 22, 34], "723951": 26, "724068": 26, "7242": [13, 26, 32], "724410": 26, "724434": 30, "724458": 38, "724539": 49, "724891": 39, "725": [18, 37, 38], "7250894": 54, "726": [16, 23, 35, 39, 43], "726269": 27, "726412": [16, 23, 35, 36], "726441": 27, "726474": 48, "726573": 38, "726583": 38, "726634": 39, "726659": 26, "7266666666666667": 54, "726788": 40, "727014": 49, "727198": 38, "727273": [15, 16, 22, 34], "727554": 38, "7277854625841886": 50, "727821": 38, "7278214718381631": 38, "727829": 38, "727992": 27, "728": [16, 23, 35, 39], "728235": [16, 23, 35, 36], "7283": 39, "728324": 39, "728777": [15, 22, 34], "729": 38, "729109": 53, "729143": 39, "7292": 43, "729374": 26, "729814": 38, "73": [13, 14, 17, 18, 21, 24, 32, 33, 36, 37, 38, 39, 40, 45, 49, 50], "730025": 26, "730383": 39, "730704": 26, "731498": 50, "7315": [18, 37], "7315558717766282": 38, "731572": [18, 37], "731583": [15, 22, 34], "73183": 47, "7328": [16, 23, 35], "732919": 38, "733102": [16, 23, 35, 36], "733333": [14, 16, 23, 33, 35, 36], "733746": 38, "734": [38, 40, 50], "734011": 38, "734048": 26, "734385": 39, "734816": 49, "734986": 26, "735": 40, "735043": 39, "735261": 38, "7352614272253524": 38, "735637": 26, "7356575131416321": 47, "735667": 39, "735879": 38, "7363681793212891": 47, "736498": 38, "736900": [16, 23, 35], "737285": 26, "7379": [13, 26, 32], "738": [16, 21, 23, 35, 40], "738564": 49, "738701": [16, 23, 35, 36], "738715": 50, "738839": [18, 37], "738977": 38, "739264": [16, 23, 35, 43], "7395977155164125": 38, "739598": 38, "739938": 38, "74": [13, 14, 16, 17, 18, 21, 23, 24, 32, 33, 35, 36, 37, 38, 39, 40, 45, 58], "740319": 26, "740542": [12, 19, 31], "740844": 38, "741": 50, "741037": 49, "741060": 26, "741250": 34, "741463": 38, "7418": 42, "741935": 53, "742084": 38, "742088": 38, "742703": 38, "742981": 39, "743": [15, 16, 23, 34, 35, 38, 50, 53], "743133": [15, 22, 34], "743135": 39, "743321": 38, "743323": 38, "743324": 38, "743391": [15, 22, 34], "743555": 42, "7436": [13, 14, 21, 32, 33, 56], "743917": [16, 23, 35, 36], "7440": [12, 19, 31], "744201": 39, "744565": 38, "745": 41, "745178": 38, "745925": 26, "746114": 41, "746328": [15, 22, 34], "747": [12, 19, 31], "74720920774": 40, "74798624e": 42, "748": 28, "748510": 39, "748725": 50, "748749e": 38, "748797": [18, 37], "749": 28, "749118": 42, "75": [8, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 24, 26, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 49, 50, 51, 58], "750": [12, 19, 28, 31], "7500": 40, "750000": [16, 26, 40], "7503": [13, 26, 32], "7504": 53, "750401": 47, "751": [28, 53], "752": 28, "752169": 26, "7524": 49, "752728": 26, "7528662": 30, "753": 28, "753286": [16, 23, 35, 36], "754": [16, 23, 35], "754165": 53, "754386": 39, "754620": 26, "754874": 43, "754938": 26, "755": [14, 50], "755000": 40, "7551": 38, "755364": [15, 22, 34], "755418": 38, "755477": [15, 22, 34], "756": 50, "7562": [12, 19, 31], "75625": 49, "757": 39, "7574257425742574": 38, "75745416": 44, "757545": 40, "757591": 49, "757932": 50, "757985": [41, 42], "758": [41, 42, 50], "758029": 27, "758062e": 40, "758259": 26, "75826": [41, 42], "758514": 38, "7588186": 48, "7588527798652649": 47, "759043": 39, "759561": 44, "75956122": 44, "7599": [18, 37], "76": [14, 16, 18, 21, 23, 33, 35, 37, 38, 39, 40, 42, 43, 50], "760": 50, "760262": 38, "760678": 49, "760966": 26, "76161": 38, "761945e": 40, "762": [33, 50], "7620": [12, 19, 26, 31], "762093e": 40, "76270194": 42, "763": [16, 23, 35], "763480": 26, "7639": [13, 26, 32], "764052": 43, "76470588": [14, 21, 33], "764706": [14, 15, 21, 22, 33, 34, 38], "765": 39, "765591": 39, "765601": 40, "766317e": 40, "766318": 26, "766423": 40, "766430": [15, 22, 34], "767": [40, 42, 51], "767742": [18, 37], "767802": 38, "767819": 49, "767852": [15, 22, 34], "768": [16, 23, 35, 36, 40, 42, 51, 58], "768176": 50, "768184": 26, "768279": 51, "768512": 39, "769030": 26, "76908228": 41, "769231": [16, 23, 35], "77": [13, 14, 17, 18, 20, 21, 24, 32, 33, 36, 37, 39, 40, 45, 49, 50, 55], "770": [13, 26, 32], "770163": 26, "7706532429048965": 41, "770833": 46, "770898": 38, "771": [16, 23, 35], "771969": [15, 22, 34], "772185": 26, "772532": 39, "7728396574320712": 26, "773017": [40, 42, 51], "773125": 22, "7736": 38, "773851": 49, "774261": 49, "774844": [17, 24, 36], "77484447": [17, 24, 36], "7750553478074826": 49, "775270": 40, "7752884548630529": 37, "7752884548630534": 18, "775311": 42, "77536150e": 42, "7758": 38, "776": 38, "7763": [16, 23, 35, 43], "776427": 50, "77694295": 41, "77709": 38, "777600": 26, "777934": [15, 22, 34], "7781845435415525": 49, "779": [16, 23, 35, 43], "779271": 43, "78": [12, 13, 14, 16, 17, 19, 20, 21, 23, 24, 31, 32, 33, 35, 36, 39, 40, 43, 44, 49, 50, 55], "7800": 38, "780000": 41, "780296": 40, "780298": 40, "780316": 40, "780497": 40, "78058051e": 42, "780864": 39, "781": [16, 23, 35], "781004": [15, 22, 34], "781531": 39, "7816": 40, "781975": 27, "782183": 40, "782219": [15, 22, 34], "7827": 39, "783282": 38, "783582": [15, 22, 34], "783784": 46, "783789": [15, 22, 34], "784424": [18, 37], "784573": 43, "785": 36, "785105": 40, "785108": 40, "785134": 40, "78521263": 47, "785399": 40, "785483": 49, "785714": [16, 23, 35], "786115": 43, "78617028": 41, "7862": 30, "786555": 40, "787": [16, 23, 35], "787574": 40, "787879": [15, 18, 22, 34, 37], "787933": 40, "788": 33, "788374": 48, "788647472858429": 47, "7887": 42, "7891381897690047": 37, "7891381897690053": 18, "789436": [16, 23, 35], "789657": 49, "79": [13, 14, 16, 17, 18, 21, 23, 24, 32, 33, 35, 36, 37, 39, 40, 49, 50, 56], "790": 39, "790000": [16, 23, 35], "79041": 40, "790481e": 28, "790521": 26, "790721": 51, "790731": [18, 37], "791017": 50, "791467": [16, 23, 35], "792": 54, "792023": [42, 51], "79250": [16, 23, 35], "792500": 15, "792577": 40, "792603": [15, 22, 34], "792828": 40, "793": 43, "793243": [16, 23, 35], "79378": 39, "7938": 36, "794": 50, "794118": [15, 22, 34], "794190": 30, "794236": [16, 23, 35], "794820": [16, 23, 35], "795": [14, 15, 34, 38], "79500e": [15, 34], "7951": 38, "7951559890417761": 40, "795902": 49, "796": [16, 23, 35], "7964215270662811": 37, "7964215270662817": 18, "797": [16, 23, 35], "797355": [16, 23, 35, 36], "7978563117812038": [16, 23, 35], "798": [16, 23, 35], "7982": [15, 22, 34], "7986546": 40, "799983": [15, 22, 34], "79998417": 54, "7f688092391a": 48, "7l": 23, "7pm": 43, "7th": [39, 41, 42], "8": [1, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 57], "80": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 49, 50, 51, 55], "800": [12, 19, 21, 28, 31, 33, 38, 47], "800000": [38, 49], "8001": [18, 37], "800190": [15, 22, 34], "80062924": [15, 22, 34], "800k": 51, "801219e": 40, "801666": 39, "801863": [15, 22, 34], "802502": 43, "802902": 40, "802987": [15, 22, 34], "803": [15, 16, 22, 23, 34, 35, 53], "803617": 39, "804": [15, 22, 34, 50, 53], "804818": [16, 23, 35, 36], "80482065": [17, 24, 36], "804821": [17, 24, 36], "805198": 40, "805342": 49, "805414": 27, "805970": [15, 18, 22, 34, 37], "806": 36, "8062": [13, 26, 32], "806899": 48, "8076": 40, "807684": [15, 22, 34], "807735": 39, "8078": [12, 19, 31], "808": 50, "8080": [13, 26, 32], "808208": 39, "808958": [15, 22, 34], "809": [16, 23, 35], "8098": 50, "81": [13, 14, 15, 17, 18, 21, 22, 24, 26, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 49, 50, 51], "810073": [40, 42], "810098": 43, "810368": [15, 22, 34], "81071706": 38, "810811": 46, "8112": [12, 19, 31], "812272": 40, "812363": 40, "812500": [14, 33], "812593": 48, "812875": 50, "813": [16, 23, 35], "813586": 39, "815669": 39, "816200": 27, "8162831858407079": 52, "816717791411044": 50, "817": 41, "817034": 53, "817558": [16, 23, 35, 36], "8180": [16, 23, 35], "818041": 50, "818868": [16, 23, 35], "819152": [15, 22, 34], "819213": 50, "8195": [18, 37], "819549": [15, 22, 34], "819584": [15, 22, 34], "81970188": [17, 24, 36], "819702": [17, 24, 36], "82": [13, 17, 20, 24, 32, 36, 38, 39, 45, 49, 50], "820": [15, 22, 34], "820033": 40, "820143": [18, 37], "82025568e": 42, "820564": 40, "821040": 42, "821327": 47, "821807": 40, "8219": [16, 23, 35], "822": 30, "8221": 36, "8225": 53, "82273995": [17, 24, 36], "822740": [17, 24, 36], "823364": 28, "82336432": 28, "823511": 39, "823529": [14, 15, 18, 21, 22, 33, 34, 37], "82352941": [14, 21, 33], "823543": 43, "8244": 30, "824849": 39, "824884": 40, "825": [16, 23, 35], "825123": 43, "8253": [15, 22, 34], "825306": 38, "825470": 50, "825697": 40, "826142": 40, "826203": [18, 37], "826216": 40, "82630": 30, "826513": 49, "82652929": 30, "826553": 40, "82670": 49, "826739": 40, "826758": 40, "826760": 40, "827039": [18, 37], "827068": [18, 37], "827130": 39, "827261": 40, "827842": [18, 37], "827907": 38, "828": [26, 28], "8280229354283182": 40, "82804": 38, "828332": [40, 42, 51], "828358": [15, 22, 34], "828405": 49, "828682": 38, "82869879": 47, "828891": 38, "828976": 38, "829": 28, "83": [13, 14, 17, 20, 21, 24, 32, 33, 36, 38, 39, 45, 46, 47, 49, 50, 55], "830": 28, "830382": 39, "8304": 30, "830712e": 40, "831": 28, "831135": [15, 22, 34], "831611": [40, 42], "831989": 38, "832": [16, 23, 28, 30, 35], "8320": 30, "832320": [18, 37], "832370": 39, "832866": 40, "833": [15, 28, 30, 34, 38], "83320": 49, "8334": [30, 42], "833913": 26, "834": 28, "8340": [15, 22, 34], "834109": 38, "834356e": 40, "83437": 40, "834455": [15, 22, 34], "835": 28, "8356": 42, "835651": 38, "835749": [40, 42], "835876": 26, "83603": [40, 42], "8361313": 40, "836189": [15, 22, 34], "836735": 39, "836878e": 40, "836880e": 40, "837": 30, "837022e": 40, "837838": [15, 22, 34], "837848": [15, 22, 34], "838": [15, 34, 38], "83848729e": 48, "83876": 38, "8388866943476283": 37, "8388866943476289": 18, "838951": 40, "8389756947416362": 37, "8389756947416367": 18, "839225": 40, "84": [13, 14, 17, 20, 21, 24, 26, 32, 33, 36, 49, 50, 54, 55], "840": [16, 23, 35], "84002795": [17, 24, 36], "840028": [17, 24, 36], "840074": [14, 21, 33], "840183": 40, "840492": [40, 42, 51], "84062193": 42, "841": 40, "841208": 38, "8418": 30, "841886": 38, "841983": 38, "842": [16, 23, 30, 35], "842028": 39, "842064": 50, "842105": [15, 22, 34], "843": [30, 41], "843281": 42, "843284": [15, 18, 22, 34, 37], "843842": [16, 23, 35, 36], "843992": [40, 42], "844409": [17, 24, 36], "84440919": [17, 24, 36], "844444": 16, "844921": 44, "845": 38, "846154": [16, 23, 35, 53], "8462": 43, "846260e": 40, "846650": 40, "84679073": [15, 22, 34], "84698489": 48, "847178": 39, "847287": 38, "8475": 49, "84772": 39, "847799": 38, "847808": 39, "8478316682480326": 49, "848": [41, 42], "8481": 53, "848214": 16, "84893192": 38, "849": [41, 42], "849102e": 40, "849438e": 40, "849612": 38, "85": [13, 14, 17, 20, 21, 24, 32, 33, 36, 39, 40, 41, 42, 43, 49, 50, 55], "850": [12, 19, 31, 41, 42], "8502": 38, "850283": 49, "850503": 38, "850746": [15, 22, 34], "851460": 40, "851852": [18, 37], "852": [50, 53], "852053": 38, "852104": 40, "852941": [18, 37], "853125": 34, "853399": 39, "854129": 40, "854167": 46, "854500": 50, "8546143543902771": 50, "854744525547446": 50, "854749": 49, "85545875": [15, 22, 34], "85597188": [17, 24, 36], "855972": [17, 24, 36], "856": 38, "856175": [16, 23, 35], "856589": 38, "856722": 27, "857": 40, "857457": 27, "857874": 38, "858": [18, 37], "8580": [16, 23, 35, 36, 58], "858209": [15, 18, 22, 34, 37], "858915": 38, "859": 41, "859318": 40, "859439": 44, "85943906": 44, "859455": 50, "85969": 38, "859799": 38, "86": [13, 15, 17, 18, 20, 24, 32, 34, 36, 37, 38, 39, 43, 49, 50], "860": [39, 42], "86000e": [15, 34], "8601643854446082": 40, "860677": 39, "861": [16, 23, 35], "86102": 49, "861157": 51, "861348": 38, "862432": 40, "862552": [16, 23, 35], "8625888648969532": 50, "86267067": [17, 24, 36], "862671": [17, 24, 36], "862997": 43, "863014": [18, 37], "863889": 49, "863941": 40, "864": 41, "86400": 49, "8641864337292489": 50, "864205": 42, "864292": 27, "865562": 50, "8661": 53, "866110": [18, 37], "866667": [14, 33, 39], "866980": 40, "867434": 48, "867558": 43, "868003": 40, "86820176": 30, "868281": 40, "868305": 40, "868308": 40, "869077": [17, 24, 36], "86907725": [17, 24, 36], "869094": 38, "8691": 36, "869531": [15, 22, 34], "869964": 38, "87": [13, 16, 17, 23, 24, 32, 35, 36, 39, 49, 50], "870": [41, 42], "870503": 48, "871": [38, 41], "871094": 49, "8711": 39, "871200": 26, "872": [41, 42], "872093": 38, "872603": 48, "872722908439952": 42, "8727229084399575": 42, "872961060": 40, "8729610607986": 40, "873": 41, "8731": [40, 42, 51], "873103": [15, 22, 34], "873182": 49, "873356": [15, 22, 34], "873643": 38, "873704": 40, "874062": [17, 24, 36], "87406235": [17, 24, 36], "874305": 49, "874516": 38, "874532": 40, "874767e": 40, "874962": 27, "875": 39, "8750": [16, 23, 35, 43], "875000": [14, 16, 33], "876065": 38, "876540": 50, "876566e": 26, "876574": [16, 23, 35, 36], "87681182": 47, "877046": 43, "877390": 42, "877519": 38, "877551": 39, "877887": 30, "878183": [15, 22, 34], "87844893": 40, "87849316": [18, 37], "879": [16, 23, 35], "87907": 38, "879938": 38, "88": [13, 14, 16, 17, 18, 21, 23, 24, 32, 33, 35, 36, 37, 39, 43, 50, 58], "880": 43, "8801": 47, "880348": 38, "880831": 49, "881395": 38, "881720": 39, "883138": 38, "884586": 38, "885": [12, 19, 31, 36], "885044": [40, 42, 51], "8859": [29, 30], "885968": 50, "886047": 38, "886759": [18, 37], "887": 41, "887017": 39, "887159": 49, "8873": 39, "887324": 39, "887343": [15, 22, 34], "887597": 38, "887701": 39, "8878117": [17, 24, 36], "887812": [17, 24, 36], "888": [38, 41, 42], "888066": 42, "888372": 38, "888513": 39, "888811": 38, "888889": [16, 18, 23, 35, 37], "888961": 42, "889086": 40, "889147": 38, "889429": 49, "889921": 49, "89": [13, 14, 17, 20, 21, 24, 32, 33, 36, 39, 45, 49, 50, 55], "890": [28, 41], "890456": 26, "890457": 40, "890933": 50, "891001": 39, "891557": 38, "892476": 39, "892477": [15, 22, 34], "892491": [16, 23, 35], "89270": 43, "892733": 49, "892961": 43, "893000": [16, 23, 35], "893260": [17, 24, 36], "8937442459553657": 42, "894": [16, 23, 35], "894587": 51, "894960": 26, "895": 41, "89515383": 28, "895154": 28, "895349": 38, "895541": 40, "89572": 49, "895833": 39, "895963": [18, 37], "897010": [16, 23, 35, 36], "89706451e": 42, "897674": 38, "898": 42, "898016": 38, "898243": 27, "898703e": 40, "899": [16, 23, 35, 36, 38, 41, 58], "8994": 42, "8997": 40, "899736": 26, "899969": 49, "8m": 48, "8th": [39, 41, 42], "9": [1, 4, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 59], "90": [8, 12, 13, 14, 15, 17, 19, 20, 21, 22, 24, 31, 32, 33, 34, 36, 39, 40, 45, 46, 49, 50, 55], "900": [17, 24, 36, 38, 39], "90000": 49, "900000": [14, 21, 33, 49], "900000e": 26, "900662": [14, 21, 33], "901085": [18, 37], "9010852321946792": 37, "9010852321946795": 18, "901262": 49, "90159483": 44, "901595": 44, "902343": 27, "902401": 38, "903101": 38, "903422": 27, "904": [15, 22, 34, 38], "90403853": [17, 24, 36], "904039": [17, 24, 36], "904226": [15, 22, 34], "904565": 27, "9047619047619048": [13, 20, 32], "904902": 48, "904930e": 26, "905": [15, 16, 22, 23, 34, 35], "905000": 22, "905327": 49, "906667": [14, 21, 27, 33], "90669": 43, "906865": [14, 21, 33], "907": 50, "907143": 53, "907595": 49, "908": [16, 23, 35], "908140": [16, 23, 35, 36], "908215": 40, "909091": [16, 23, 35], "90982": 43, "91": [13, 14, 16, 17, 20, 21, 23, 24, 26, 32, 33, 35, 36, 38, 39, 43, 44, 49, 55], "910": [13, 17, 24, 26, 32], "9100": 49, "910018": 40, "910174": 40, "9103": 49, "910456e": 40, "91063776": 42, "910714": 53, "9108334653214172": 26, "910843": 40, "911": 28, "911615": 40, "911846": 40, "912": [16, 23, 35], "912395": 42, "913333": [14, 21, 27, 33], "913767": 40, "913849": 40, "914003": 42, "914451894267": 40, "914585": 42, "91515735": 40, "915714e": 40, "915952": 40, "916254": [15, 22, 34], "916347": 27, "916722": 42, "917526": 39, "917837": 39, "918": [26, 41], "918124": 39, "918191": 48, "9182": 49, "918224": 28, "91835": 30, "919198": 42, "9196": [12, 19, 31], "92": [13, 14, 17, 20, 21, 24, 32, 33, 36, 39, 45, 48, 49, 50, 55], "920000": [14, 21, 27, 33], "9203": 38, "920305": 43, "920462": 42, "9212": 16, "92120500e": 54, "921422": 50, "921435": 27, "921438": 40, "921850": 40, "92195464": 42, "921955": 42, "922": 36, "923077": 39, "923283": [16, 23, 35, 36], "923432": 42, "924485": 43, "9245": [14, 18, 21, 33, 37], "925272e": 40, "925288e": 40, "925593": [15, 22, 34], "925768": 39, "926657": 40, "926667": 27, "926733e": 40, "926829": 39, "928": 38, "92809": 43, "92852376": [15, 22, 34], "929": 38, "9295": 38, "93": [13, 14, 17, 18, 20, 21, 24, 32, 33, 36, 37, 38, 44, 49, 50, 55], "930000": [16, 23, 35], "930062": 26, "930123": [15, 22, 34], "930561": [15, 22, 34], "9308647034083802": 26, "931439e": 40, "931786": [18, 37], "931896": 26, "932": [16, 23, 35], "932070": 50, "932124": [15, 22, 34], "932143": 53, "93232161": 30, "93279": 49, "933275": 39, "933333": 27, "9336": [16, 23, 35], "934": 28, "934205": [15, 22, 34], "934269": [16, 23, 35, 36], "934783": 39, "9351": 43, "935512": 50, "935802": [15, 22, 34], "93665": 49, "937429": 51, "9375": [14, 21, 33], "937500": [14, 17, 21, 24, 33, 36], "938": 39, "938201": 26, "9383": [15, 18, 22, 34, 37], "93869659": [17, 24, 36], "938697": [17, 24, 36], "939006": 39, "9391": 40, "939394": [15, 18, 22, 34, 37], "939805": 26, "94": [13, 14, 16, 17, 18, 20, 21, 23, 24, 32, 33, 35, 36, 37, 38, 39, 40, 49, 55, 58], "940000": 27, "9401": 49, "9406": [13, 14, 21, 32, 33, 56], "941": 50, "9410": 26, "941176": [14, 17, 21, 24, 33, 36], "94117647": [14, 21, 33], "942": 28, "943609": 43, "944": [12, 19, 31], "944092": 39, "944354": 36, "945000": 27, "945968": 27, "946667": 27, "946783": [15, 22, 34], "947": [16, 23, 35, 38, 53], "9471": 38, "948482": 50, "94888": 39, "949": [16, 17, 23, 24, 35], "9490": [16, 23, 35], "9492": 40, "94933723": 40, "94959681": [17, 24, 36], "949597": [17, 24, 36], "95": [13, 14, 17, 20, 21, 24, 32, 33, 36, 39, 45, 49, 50, 51], "950000": [16, 23, 35], "950088": 43, "9505": 42, "950564": 43, "9506": 42, "950696": 50, "950733": [15, 22, 34], "951294": 40, "951574": 43, "951644": 43, "951667": 27, "951669": 43, "951696": [15, 22, 34], "953": 41, "9530973451327434": 52, "953333": 27, "95511263": [15, 22, 34], "955113": [15, 22, 34], "9558": 49, "956": [16, 23, 35], "956966": 43, "957075": 43, "9573": 49, "9576": [12, 19, 31], "957886": 48, "957919": [15, 22, 34], "957987": [15, 22, 34], "9583333333333334": 48, "958393": [16, 23, 35, 43], "95886206e": 48, "959": [16, 23, 28, 35], "959139": 42, "959402e": 40, "959870": 39, "959873": 50, "96": [13, 17, 18, 24, 32, 36, 37, 38, 39, 43, 49], "960": [17, 18, 24, 28, 37], "960000e": 28, "961": 28, "961109802000133": 45, "961404": [16, 23, 35, 36], "961498": [40, 42, 51], "961771": [18, 37], "961898": [18, 37], "962": 28, "962036": 39, "963": 28, "963024": 26, "963097": 39, "96319": 49, "96320": 49, "96321": 49, "96322": 49, "96323": 49, "96325": 49, "963333": 27, "963689": 43, "964": 28, "96554": 43, "9661": 40, "966131": [16, 23, 35, 36], "9664": [13, 14, 21, 32, 33, 56], "966667": 27, "966812": 26, "967907": 39, "968": [16, 23, 35], "968233": 43, "968236": 39, "96833": 47, "968333": 27, "96834506": [15, 22, 34], "968493": 50, "968514e": 40, "96875": 48, "969048e": 40, "9691": 40, "9692602666681306": [18, 37], "96965253": 42, "969653": 42, "97": [13, 14, 16, 17, 18, 21, 24, 32, 33, 36, 37, 38, 42, 45, 49, 50], "970518": 39, "970683": 43, "971": 36, "97203586": [17, 24, 36], "972036": [17, 24, 36], "97217": 49, "972198": 38, "97223953": [17, 24, 36], "972240": [17, 24, 36], "972379": 28, "97237936": 28, "972440": 39, "97253": 49, "9730": 36, "973225": 39, "973280": [17, 24, 36], "97328024": [17, 24, 36], "973294": 28, "973333": 27, "973482e": 38, "973750": [15, 34], "974": [16, 23, 35], "974183": 27, "974480": 43, "974531": 27, "9748": [18, 37], "974801e": 40, "975104": 28, "975895": 49, "976": [16, 23, 35, 39, 41], "97601304": 30, "976667": 27, "977": [16, 23, 35, 49], "977278": 43, "9773": [13, 14, 15, 21, 22, 32, 33, 34, 56], "978": [18, 37], "9781449369880": 49, "9781789957211": 48, "97823755": [18, 37], "9785299": 47, "978738": 43, "979": [41, 42], "979562": 50, "98": [13, 16, 17, 18, 23, 24, 32, 35, 36, 37, 40, 42, 44, 47, 49, 50, 51], "980": 49, "980000": 27, "98001": 26, "98007": [12, 19, 31], "98010": 26, "98024": 26, "98027": 26, "98028": [13, 26, 32], "98033": 26, "98038": 26, "98039": 26, "98045": [12, 19, 31], "98052": [12, 19, 26, 31], "98055": [12, 19, 31], "980634": 50, "98065": 26, "98072": [12, 19, 31], "98074": [13, 26, 32], "98075": [12, 19, 31], "98077": 26, "9808": [18, 37], "980962": 27, "98102": 26, "98103": 26, "98107": [12, 19, 31], "98112": [12, 19, 31], "98115": 26, "98116": [12, 19, 31], "98117": 26, "98118": 26, "981195": 49, "98125": [13, 26, 32], "98136": [13, 26, 32], "98144": 26, "98146": 26, "98148": 26, "981643": 26, "981735": [18, 37], "98178": [13, 26, 32], "98199": 26, "982": 36, "982184": 38, "982570": 50, "983": 48, "983333": 27, "983340": 26, "9837": [14, 18, 21, 33, 37], "984": 38, "984653": [18, 37], "984664": 40, "985000": 27, "985283": 38, "9854": [13, 14, 18, 21, 32, 33, 37, 56], "985457": 50, "98565": 30, "985816": [14, 33], "986047": 38, "9862": 53, "986207": 38, "987": [38, 48], "987062": 40, "987597": 38, "9876": [41, 42], "987681": 43, "988": 43, "9881": [13, 14, 21, 32, 33, 56], "988333": 27, "988381": 38, "988841": 38, "988901": 40, "989": [13, 20, 32], "989147": 38, "989156": 38, "989443": 50, "989922": 38, "989973": [18, 37], "99": [13, 14, 16, 17, 21, 23, 24, 28, 32, 33, 35, 36, 38, 39, 49], "990631": 49, "990754": 49, "991": 30, "9912": [15, 18, 22, 34, 37], "9915": 49, "991667": 27, "991810": 26, "991966": 50, "992": [33, 38], "992220": 26, "992254": 38, "99240562": 42, "992406": 38, "992569": 28, "9926": 36, "992857": [14, 33], "992908": 33, "993023": 38, "993029": 38, "993065": 50, "9931": [13, 14, 21, 32, 33, 56], "993333": 27, "9934531067299874": [18, 37], "99355746": 30, "993666": 42, "993969": [40, 42, 51], "994": [12, 19, 31], "994266": 38, "994574": 38, "994764": 49, "995": [43, 48], "9950": 43, "9951": [13, 14, 21, 32, 33, 56], "99515": 49, "995434": 40, "996424": 26, "996487": 26, "996588e": 40, "996765": 42, "996788": 50, "996820": 50, "996899": 38, "99744241e": 42, "9977957422135844": 42, "998": [39, 50, 53], "9983": 39, "998302": 39, "998370": 26, "998440": 26, "99845": 38, "998451": 38, "999": [18, 37, 53], "99907": 38, "999122": 39, "9991338290544213": 26, "999147": 39, "999172": 39, "999178": 26, "999183": 39, "999185": 39, "999192": 39, "999210": 39, "999213": 26, "999214": 39, "999221": 39, "999223": 39, "999225": 38, "999254": 39, "999298": 39, "999317": 39, "99931882": 40, "999335": 39, "999438": 26, "9994394006711425": 26, "999480": 26, "999518": 26, "999535": 38, "999539": 26, "999544": 26, "999545": 26, "999546": 26, "999558": 26, "999562": 26, "999567": 26, "999577": 49, "999622": [16, 23, 35], "99975": 30, "99980": 30, "9999": [12, 19], "9am": 43, "9th": [39, 41, 42], "A": [0, 1, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 54, 55, 59], "AND": [0, 40], "AS": 0, "And": [12, 13, 19, 31, 32, 38, 40, 47, 49, 50, 51, 56, 57], "As": [4, 14, 17, 21, 22, 24, 33, 36, 38, 40, 41, 42, 46, 49, 50, 51, 52, 54, 57, 59], "At": [4, 12, 14, 18, 19, 26, 28, 31, 33, 37, 39, 41, 43, 44, 48, 49], "BE": [0, 47], "BUT": [0, 8], "BY": [0, 1], "Be": [7, 12, 15, 19, 22, 34, 42, 51, 52, 55, 57], "Being": 48, "But": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 57, 59], "By": [11, 12, 14, 15, 17, 19, 21, 22, 24, 27, 31, 33, 34, 36, 39, 41, 44, 47, 48, 50, 51, 57], "FOR": 0, "For": [0, 1, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 59], "IN": [0, 14, 18, 21, 33, 37], "IT": [18, 37], "If": [4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "In": [1, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59], "Ines": 53, "It": [2, 4, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 57, 59], "Its": 50, "NEAR": [16, 23, 35, 36, 43, 58], "NO": 0, "NOT": [0, 8, 17, 18, 24, 36, 37], "No": [0, 12, 13, 19, 20, 28, 31, 32, 40, 41, 42, 43, 45, 49, 50, 51, 55], "Not": [39, 40, 41, 42, 43, 44, 46, 49, 50], "OF": 0, "OR": [0, 8, 40], "Of": [9, 17, 24, 36, 38], "On": [4, 7, 12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 31, 35, 36, 38, 39, 40, 41, 42, 43, 45, 48, 50, 51, 53], "One": [5, 8, 13, 14, 17, 18, 20, 21, 24, 28, 29, 30, 32, 33, 36, 37, 38, 39, 42, 44, 45, 50, 55], "Or": [15, 17, 22, 27, 34, 36, 38, 51, 57], "Such": [6, 46, 49], "THE": [0, 14, 21, 33], "TO": [0, 47], "That": [13, 14, 16, 18, 20, 21, 23, 32, 33, 35, 37, 38, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52], "The": [0, 2, 5, 7, 8, 11, 12, 13, 15, 16, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 40, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59], "Their": 5, "Then": [13, 18, 20, 30, 32, 37, 41, 44, 49, 52], "There": [1, 2, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 28, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 59], "These": [4, 10, 13, 14, 15, 18, 20, 21, 22, 32, 33, 34, 37, 39, 40, 41, 42, 43, 44, 46, 49, 51], "To": [8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 43, 45, 47, 48, 49, 51, 52, 53, 57, 59], "WITH": 0, "Will": [39, 50, 53, 55], "With": [0, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 27, 31, 32, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 48, 50, 54, 57], "_": [41, 47, 48, 50, 53], "__array__": 28, "__call__": [17, 24, 36], "__class__": [18, 37, 49], "__finalize__": 50, "__getitem__": [23, 33, 35, 53], "__name__": [18, 37, 49], "__sklearn_tags__": 28, "__testing_word2vec": 47, "_array_api": 28, "_asarray_with_ord": 28, "_assert_all_finit": 28, "_assert_all_finite_element_wis": 28, "_astype_nansaf": 50, "_base": 28, "_california_housing_dataset": [18, 37], "_call_func_on_transform": [17, 24, 36], "_check_i": 28, "_classif": 28, "_column_transform": [17, 24, 36], "_constructor_from_mgr": 50, "_data": 38, "_deprecate_force_all_finit": 28, "_distn_infrastructur": 38, "_encod": [17, 24, 36], "_estim": 28, "_fit": 28, "_fit_context": 28, "_get_sequential_output": [17, 24, 36], "_i": 48, "_is_numpy_namespac": 28, "_logist": 54, "_mgr": 50, "_proba": 41, "_score": [17, 24, 36], "_scorer": [17, 24, 36], "_set_output": [17, 24, 36], "_time_fit_was_cal": 50, "_transform": [17, 24, 36], "_transform_on": [17, 24, 36], "_valid": [17, 24, 36], "_validate_param": 28, "_valu": 28, "_x_subset": 14, "ab": [18, 37, 39, 40, 42], "abbrevi": 47, "abdelrahman": [1, 59], "abil": [12, 17, 19, 24, 29, 30, 31, 36, 38, 42, 47, 49, 57], "abl": [8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 51, 52, 57], "about": [1, 2, 4, 7, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 59], "abov": [0, 5, 8, 10, 12, 13, 14, 15, 18, 19, 20, 21, 22, 26, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 54, 57, 59], "absenc": [17, 24, 36, 42, 46], "absolut": [11, 18, 28, 30, 37, 39, 40, 42, 44, 53], "abspath": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57], "absurd": 30, "academ": [1, 7, 43, 52], "accent": 30, "accept": [5, 8, 28, 39, 40, 47, 52], "accept_large_spars": 28, "accept_spars": [17, 24, 28, 36], "access": [1, 10, 12, 14, 19, 21, 23, 33, 35, 38, 41, 44, 46, 47, 49, 51, 52, 53], "accessori": 49, "accident": [15, 16, 22, 23, 34, 35, 52], "accomod": 7, "accompani": [7, 12, 13, 19, 31, 32], "accomplish": [27, 52], "accord": [18, 37, 39, 40, 43, 46, 50, 59], "account": [1, 7, 12, 14, 19, 33, 39, 43, 46, 50, 52, 55], "accur": [12, 14, 19, 21, 31, 33, 41, 42, 43, 46, 50, 51, 55, 56], "accuraci": [11, 13, 14, 15, 16, 20, 21, 22, 23, 26, 27, 32, 33, 34, 35, 38, 39, 41, 42, 43, 45, 48, 50, 51, 53, 55, 56, 59], "accuracy_scor": 39, "acdm": [39, 41, 42], "acf": 49, "achiev": [8, 15, 22, 34, 39, 52], "acinonyx": [12, 19, 31, 48], "ackland": 30, "acoust": [15, 16, 23, 34, 35, 38], "acquir": 11, "acquisit": 46, "across": [12, 13, 14, 16, 19, 20, 21, 23, 30, 31, 32, 33, 35, 39, 42, 48, 59], "act": [18, 29, 30, 37, 59], "action": [0, 12, 19, 30, 31, 41, 42, 44, 46, 47, 50, 59], "activ": [4, 10, 31, 38, 53, 55, 59], "actor": [46, 47], "actual": [7, 12, 18, 19, 24, 29, 30, 31, 37, 39, 41, 42, 44, 46, 47, 49, 50, 51], "ad": [17, 18, 24, 30, 36, 37, 38, 39, 41, 42, 43, 45, 47, 48, 50, 53], "adam": 30, "adapt": [0, 16, 17, 23, 24, 35, 36, 39, 41, 47, 49, 51, 53], "add": [7, 8, 10, 14, 16, 23, 30, 35, 36, 39, 40, 41, 42, 43, 45, 47, 49, 50, 52, 53, 58], "add_pip": 53, "addit": [0, 4, 12, 19, 40, 46, 51, 59], "addition": [56, 57, 59], "address": [45, 52], "adelaid": 49, "adio": 51, "adj": [47, 53], "adject": 47, "adjust": [15, 22, 27, 34, 38, 45, 49, 57], "adm": [39, 41, 42], "admin": [1, 59], "administr": 1, "admit": [14, 33], "adopt": [6, 46], "ador": 30, "adp": [47, 53], "adult": [39, 41, 42], "adult_df_larg": [41, 42], "adv": 47, "advanc": [11, 17, 24, 36, 38, 44, 45, 46, 47, 48, 56], "advantag": [11, 16, 17, 18, 23, 24, 29, 30, 35, 36, 37, 41, 45, 46, 47, 55], "advic": 50, "advis": [12, 19, 31], "advisor": 59, "af": 42, "affect": [10, 15, 16, 18, 22, 23, 34, 35, 37, 38, 39, 44, 49, 50, 52, 57], "affix": 47, "aft": 52, "after": [4, 6, 10, 14, 16, 17, 21, 23, 24, 28, 30, 33, 35, 36, 39, 40, 42, 44, 45, 47, 48, 49, 50, 51, 52, 53, 55, 59], "ag": [12, 18, 19, 28, 31, 37, 39, 40, 41, 42, 43, 46], "again": [10, 14, 16, 20, 21, 23, 26, 27, 28, 32, 33, 35, 45, 46, 47, 48, 50, 52, 57], "against": [46, 47, 49], "agenc": [47, 53], "agent": 1, "agglomerativeclust": 45, "aggress": 47, "agnost": 42, "ago": [48, 49], "agre": 57, "agreement": [50, 59], "ahm": [1, 59], "ai": [7, 9, 39, 43, 47, 48], "aight": [12, 19, 31], "aim": [28, 55], "ain": 47, "air": 30, "airplan": 51, "airport": [39, 52], "aka": [18, 37, 50], "al": [41, 47], "alain": [1, 59], "alamine_aminotransferas": [12, 19, 31], "alan": 1, "alaska": [18, 37], "alberta": 47, "album": 38, "albumin": [12, 19, 31], "albumin_and_globulin_ratio": [12, 19, 31], "alburi": 49, "alexand": 51, "alexnet": 48, "algebra": [46, 47], "algorithm": [2, 11, 12, 14, 16, 17, 19, 23, 24, 27, 31, 33, 35, 36, 39, 40, 41, 42, 45, 47, 48, 51, 52, 56, 57, 58], "align": [8, 12, 13, 14, 19, 20, 21, 31, 32, 33], "align_kei": 50, "alison": [1, 59], "aliv": 52, "alkaline_phosphotas": [12, 19, 31], "all": [0, 1, 4, 5, 6, 7, 8, 10, 14, 15, 17, 20, 21, 22, 23, 24, 26, 27, 28, 30, 33, 34, 36, 38, 40, 41, 42, 43, 47, 48, 49, 50, 52, 53, 54, 57, 58, 59], "all_cap": 53, "all_featur": 49, "allei": [40, 42, 51], "allen": 53, "alley_grvl": 40, "alley_miss": 40, "alley_pav": 40, "alloc": [8, 47, 48], "allow": [5, 7, 10, 14, 16, 23, 28, 33, 35, 38, 39, 43, 47, 49, 50, 52, 56, 57, 59], "allow_nan": 28, "allow_nd": 28, "allpub": [40, 42, 51], "allya": [1, 59], "almost": [18, 37, 38, 40, 43, 45, 46, 47], "alon": 30, "along": [7, 13, 17, 24, 30, 32, 36, 39, 48, 49, 51, 56], "alpha": [15, 16, 22, 23, 27, 34, 35, 49, 57], "alpha_": 40, "alphabet": [18, 37], "alphago": [12, 19, 31, 44], "alq": [40, 42, 51], "alreadi": [4, 8, 10, 11, 12, 19, 39, 40, 42, 44, 47, 49, 50, 51, 53, 56], "also": [1, 2, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "altar": 48, "altern": [8, 27, 38, 44, 51, 59], "although": [14, 21, 33, 41, 44, 46, 50], "alwai": [12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 53, 55, 56, 57, 59], "am": [16, 19, 23, 29, 30, 35, 44, 47, 51, 53, 59], "amateurish": 30, "amatriain": 46, "amaz": [28, 30], "amazon": [12, 19, 31, 44, 46, 53], "ambienc": 28, "ambigu": 47, "amer": 39, "america": [17, 36, 47], "american": [28, 44], "amicu": 30, "amirali": [1, 59], "aml": [16, 23, 35], "among": [12, 13, 19, 20, 31, 32, 38, 39, 41, 42, 46], "amongst": 53, "amount": [4, 12, 14, 18, 19, 21, 31, 33, 37, 38, 39, 40, 42, 44, 48, 49, 50, 52], "amp": [30, 41, 42], "amplifi": [39, 47], "amuel": [16, 23, 35], "an": [0, 1, 2, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 58, 59], "anaconda": [10, 42, 53], "anaconda3": [20, 24], "analogi": [22, 45, 47, 51], "analysi": [1, 2, 9, 11, 13, 32, 39, 40, 44, 45, 47, 51], "analyt": 49, "analyz": [11, 39, 43, 49, 50, 51], "anatinu": 48, "anca": [1, 59], "ancestor": 43, "ancestr": 59, "ancuta": [1, 59], "andrea": [1, 9], "andrew": [1, 9, 27, 38, 43, 59], "anemon": 48, "angel": [50, 53], "angl": 30, "ani": [0, 10, 13, 14, 16, 17, 18, 20, 21, 23, 24, 26, 28, 30, 32, 33, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59], "anim": [27, 39, 48], "animal_fac": [27, 48], "anita": 30, "anneal": 43, "annoi": 30, "annot": [42, 44], "announc": 7, "annoyingli": 40, "annual": 53, "anomali": [39, 40, 44], "anonym": 49, "anoth": [8, 10, 13, 15, 18, 20, 22, 32, 34, 37, 38, 39, 41, 42, 44, 45, 46, 48, 49, 50, 51, 52, 55, 56, 58], "answer": [4, 6, 7, 12, 13, 14, 19, 21, 29, 30, 31, 32, 33, 38, 41, 44, 46, 47, 49, 51, 54, 56, 57, 59], "anteat": 48, "anthologi": 30, "anti": 50, "anymor": [40, 44, 46, 57], "anyon": [12, 30, 51, 52], "anyth": [0, 12, 14, 17, 19, 21, 24, 28, 33, 36, 39, 46, 47, 50, 52], "anytim": 59, "anywher": [17, 24, 36], "ap": [11, 55], "ap_lr": 39, "ap_svc": 39, "apart": [15, 22, 30, 34, 45], "apeendixa": 43, "api": [28, 39, 47, 49, 55], "app": [12, 13, 19, 20, 32, 55], "appar": 30, "appeal": 47, "appear": [2, 7, 17, 24, 36, 41, 52, 57, 59], "append": [4, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 56, 57, 58], "appendix_b": 47, "appendixb": 48, "appl": 47, "appli": [0, 2, 6, 9, 11, 12, 13, 14, 18, 19, 20, 21, 28, 29, 30, 31, 32, 33, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 58], "applic": [0, 5, 12, 17, 19, 24, 31, 36, 38, 39, 40, 42, 43, 47, 50, 52, 55, 59], "appreci": [11, 44, 59], "approach": [1, 11, 14, 15, 16, 17, 18, 22, 23, 24, 27, 28, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 55, 57], "appropri": [0, 4, 10, 11, 13, 14, 17, 20, 21, 24, 26, 32, 33, 36, 39, 40, 44, 45, 49, 50, 52, 55, 59], "approv": [39, 59], "approx": [15, 22, 34, 42], "approxim": [13, 20, 32, 38, 43, 52], "apr": 1, "april": 49, "apt": 5, "ar": [0, 1, 2, 4, 6, 7, 8, 9, 10, 14, 15, 17, 20, 21, 22, 24, 26, 27, 28, 29, 30, 33, 34, 36, 38, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "arang": [8, 14, 15, 18, 21, 22, 26, 27, 29, 30, 33, 34, 37, 38, 39, 40, 57], "arbitrari": [42, 44, 45, 49], "architectur": 48, "area": [30, 38, 40, 41, 43, 44, 51], "aren": [7, 30, 40, 43, 44, 47, 48, 49, 53], "arena": 43, "arg": [14, 17, 21, 24, 27, 28, 33, 36], "argh": 50, "argmax": [27, 30], "argmin": [14, 15, 21, 22, 33, 34, 39, 44], "argsort": [42, 47], "argu": [19, 44, 47], "argument": [8, 13, 17, 20, 24, 32, 36, 38, 39, 40, 42, 51, 53, 55, 58], "arima": 49, "arima_model": 49, "aris": [0, 12, 31, 47], "aristotl": [15, 22, 34], "arithmet": 8, "arm": 30, "armi": 30, "aroth85": 25, "around": [7, 15, 17, 22, 24, 30, 34, 36, 39, 40, 49, 50, 56], "aroundn": [12, 31], "arr": [28, 50], "arr1": 8, "arr2": 8, "arrai": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54], "array_equ": 8, "array_orig": 28, "arriv": 43, "art": 51, "arthur": [12, 19, 31], "articl": [1, 13, 14, 16, 20, 23, 32, 33, 35, 39, 44, 46, 47, 48, 51], "articul": [51, 55], "artifici": [1, 47], "artist": [15, 16, 23, 34, 35, 38], "as_fram": [15, 22, 27, 34, 57], "asarrai": 28, "ascend": [8, 17, 18, 24, 26, 29, 30, 36, 37, 38, 40, 41, 42, 43, 49, 50, 55], "ased": 45, "asia": [17, 36], "asid": [4, 14, 21, 33, 41, 57], "ask": [3, 7, 10, 12, 13, 14, 15, 17, 19, 20, 21, 24, 30, 31, 32, 33, 34, 36, 39, 43, 44, 46, 47, 50, 51, 53, 56, 59], "asleep": [18, 37], "aspartate_aminotransferas": [12, 19, 31], "aspect": [18, 37, 42, 43, 45, 46, 50, 51, 55], "assault": 59, "assert": [7, 17, 24, 36, 39, 41, 42], "assess": [1, 6, 11, 12, 13, 14, 16, 19, 20, 21, 23, 28, 31, 32, 33, 35, 39, 42, 44, 51, 59], "assign": [1, 4, 6, 8, 10, 12, 13, 15, 16, 18, 19, 20, 22, 23, 27, 32, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 55, 56, 58], "assist": [12, 19, 31], "assoc": [39, 41, 42], "associ": [0, 12, 14, 15, 19, 20, 21, 22, 29, 30, 31, 33, 34, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 55, 59], "assum": [12, 13, 17, 18, 19, 24, 31, 32, 36, 37, 39, 40, 45, 46, 47, 49, 51, 55], "assumpt": 50, "asterisk": 38, "astyp": [8, 27, 28, 29, 30, 49, 50], "astype_arrai": 50, "astype_array_saf": 50, "astype_is_view": 28, "atmospher": 30, "atratu": 48, "attack": [13, 20, 30, 32], "attempt": [14, 21, 27, 33], "attend": 59, "attent": [6, 47, 52], "attic": 40, "attract": 47, "attribut": [0, 1, 12, 13, 15, 16, 18, 19, 20, 22, 23, 29, 30, 31, 32, 34, 35, 37, 38, 43, 44, 47, 48], "attrit": 50, "auc": [11, 50, 52, 55], "audienc": [11, 51, 52], "audio": [48, 59], "audit": [52, 59], "auditor": 59, "augment": 39, "august": 49, "austin": 47, "australia": 49, "auteur": 30, "authent": 44, "author": [0, 47, 59], "auto": [12, 19, 31, 38, 39, 43, 44, 51], "autocorrel": 49, "autom": [13, 20, 32, 40, 47, 51], "automat": [16, 17, 23, 24, 30, 35, 36, 40, 43, 47, 49, 50, 51], "autoregress": [18, 37], "autumn": 49, "autumn_month": 49, "aux": [47, 53], "av": [40, 42, 47, 51], "avail": [0, 1, 7, 9, 10, 12, 14, 17, 19, 20, 21, 24, 33, 36, 38, 39, 40, 45, 46, 47, 48, 49, 50, 55, 59], "avebedrm": [18, 37], "aveoccup": [18, 37], "averag": [11, 14, 15, 17, 18, 21, 22, 24, 33, 34, 36, 37, 38, 40, 42, 44, 45, 47, 50, 52, 53, 55, 57], "average_precis": 39, "average_precision_scor": 39, "average_word_length": 53, "averaging_model": 41, "averaging_model_ndt": 41, "averoom": [18, 37], "avg": [39, 46, 49], "avg_sent_emb": 47, "avocado": 51, "avoid": [7, 8, 13, 16, 23, 29, 30, 32, 35, 39, 40, 45, 49, 50, 51, 52, 54, 55, 57, 59], "aw": [28, 30, 52], "awai": [4, 6, 13, 18, 20, 32, 37, 44, 46, 48, 50, 51, 52, 55], "awar": [17, 24, 36, 50, 51, 59], "awesom": [9, 30], "ax": [14, 15, 18, 21, 22, 27, 33, 34, 37, 39, 44, 45, 48, 50, 51, 57], "axi": [7, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 27, 31, 32, 33, 35, 36, 37, 42, 44, 45, 47, 48, 49, 51], "axvlin": 44, "az": 53, "b": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51], "b3": [35, 42, 53], "babe": [12, 19, 31], "babi": [43, 47], "babysitt": 30, "bachelor": [39, 41, 42], "back": [8, 16, 23, 26, 27, 35, 38, 47, 55], "backdrop": 49, "background": [11, 32, 51, 52], "bad": [8, 13, 14, 15, 20, 21, 22, 28, 30, 32, 33, 34, 36, 39, 40, 41, 42, 43, 44, 48, 49], "badgeryscreek": 49, "bag": [28, 29, 30, 43, 47, 48, 55], "bai": [16, 23, 35, 36, 43], "baidu": [14, 33], "bal_scor": 39, "balanc": [6, 15, 22, 28, 29, 30, 34, 41, 44, 46, 54], "ballarat": 49, "balltre": 28, "balust": 48, "balustrad": 48, "bambi": 46, "banist": 48, "bank": [39, 42, 49, 50], "bannist": 48, "bar": [39, 40, 42, 48, 49, 50, 51, 52], "baranski": 53, "barbu": [1, 59], "bare": 30, "barrel": 30, "barri": [18, 37], "base": [5, 8, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 27, 28, 32, 33, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 50, 51, 52, 53, 55, 56, 59], "base_scor": 41, "base_valu": 42, "baseblockmanag": 50, "baselin": [27, 50, 52, 55, 56, 58], "baseline_hazard_": 50, "bash": 5, "basi": [13, 15, 20, 22, 32, 34], "basic": [2, 8, 12, 13, 19, 20, 30, 32, 38, 43, 46, 48, 50, 53], "batch": [27, 47, 48], "batch_siz": [27, 48], "batch_t": 48, "bath": [12, 19, 30, 31], "bathroom": [12, 13, 18, 19, 26, 31, 32, 37], "bayesian": 38, "bayesopt": 38, "bazazeh": [1, 59], "bbc": 30, "beagl": [12, 19, 31, 48], "bear": 48, "beat": [41, 50], "beatric": 30, "beauti": [30, 46, 47, 51], "becam": 48, "becaus": [1, 7, 8, 10, 14, 15, 16, 17, 18, 22, 23, 24, 27, 28, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 59], "becom": [4, 14, 15, 18, 21, 22, 33, 34, 37, 38, 39, 42, 43, 44, 47], "bed": [39, 52], "bedroom": [12, 13, 18, 19, 20, 26, 31, 32, 37], "bedroomabvgr": [40, 42, 51], "bedrooms_per_household": [16, 23, 35, 36, 58], "beef": [28, 47], "been": [1, 4, 6, 12, 13, 16, 17, 18, 19, 23, 24, 30, 31, 32, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 57, 59], "befor": [1, 4, 10, 13, 14, 15, 17, 18, 20, 21, 22, 24, 28, 30, 31, 32, 33, 34, 36, 37, 40, 41, 44, 45, 46, 47, 48, 49, 50, 52, 56, 57], "begin": [18, 28, 32, 37, 43, 46, 49, 50, 55], "beginn": 48, "behav": [38, 42], "behavior": [23, 33, 35, 39, 46, 52, 53], "behaviour": [17, 24, 36], "behind": [11, 12, 18, 19, 31, 37, 59], "being": [4, 12, 14, 16, 19, 21, 23, 31, 33, 35, 39, 40, 41, 42, 45, 47, 50, 51, 57, 59], "belief": 51, "believ": [26, 30, 38, 42, 49], "bell": 48, "belong": [13, 18, 32, 37, 45, 56], "below": [1, 5, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 59], "bench": 48, "benchmark": [26, 48], "bendigo": 49, "benefici": [17, 24, 36, 51], "benefit": [4, 15, 34, 41, 45, 47, 51, 55], "bengio": 38, "bennett": 30, "ber": 47, "bergammi": 30, "bergstra": 38, "berri": 47, "bertop": 47, "best": [2, 13, 14, 15, 20, 21, 22, 23, 26, 29, 30, 32, 33, 34, 38, 39, 40, 41, 42, 44, 45, 46, 50, 51, 52, 56, 57], "best_alpha": 40, "best_c": 27, "best_depth": [14, 21, 26, 33], "best_estimator_": [38, 40], "best_k": 27, "best_n_neighbour": [15, 22, 34], "best_param": [38, 51], "best_paramet": 38, "best_params_": [38, 40, 51], "best_scor": 38, "best_score_": [38, 40], "best_svr": 51, "bestalpha_coeff": 40, "better": [6, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 27, 28, 31, 32, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 55, 56, 57, 58, 59], "between": [2, 8, 10, 11, 12, 14, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 31, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 57], "bewar": 47, "beyond": [14, 21, 33, 38, 43, 51], "bhatt": [1, 59], "bia": [18, 37, 39, 42, 50, 52, 55], "bias": [11, 39, 42, 47, 50], "bicycl": [13, 20, 32, 49], "big": [7, 15, 17, 22, 24, 28, 29, 30, 34, 36, 38, 39, 41, 43, 44, 45, 46, 47, 48, 50, 51, 57], "bigalpha_coeff": 40, "bigger": [15, 17, 18, 22, 34, 36, 37, 40, 42, 45, 47, 48, 49], "biggest": [40, 43], "bigotri": 30, "bike": 49, "bill": 48, "billboard": 49, "billie_holidai": 47, "billion": 40, "billionth": 49, "bin": [16, 23, 28, 35, 38, 40, 43, 49, 50, 51, 53, 56], "binar": [13, 17, 20, 24, 32, 36], "binari": [13, 16, 17, 18, 20, 23, 24, 28, 32, 35, 36, 37, 48, 50, 51, 54, 55], "binary_feat": [17, 24, 28, 36], "binary_featur": [39, 41, 42], "binary_transform": [28, 39, 41, 42], "bincount": [39, 41], "bind": [15, 22, 27, 34, 57], "binomi": 38, "biolog": 43, "biologi": [17, 24, 36], "bird": 30, "bit": [10, 13, 14, 16, 17, 18, 20, 21, 23, 24, 27, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 44, 48, 49, 50, 51], "bite": 30, "black": [15, 22, 34, 42, 44, 48, 49], "blackhawk": 47, "bland": 30, "bldgtype": [40, 42, 51], "bldgtype_1fam": 40, "bldgtype_2fmcon": 40, "bldgtype_duplex": 40, "bldgtype_twnh": 40, "bldgtype_twnhs": 40, "blei": 47, "blend": 47, "blindli": [39, 40], "blob": [12, 54], "block": [18, 37, 50], "blog": [47, 49], "blood": 30, "bloomberg": [1, 9], "blq": [40, 42, 51], "blue": [13, 15, 20, 22, 32, 34, 38, 39, 42, 43, 44, 49], "bluesman": 47, "bmatrix": [43, 46], "board": 4, "boathous": 48, "bob_dylan": 47, "boggl": 41, "boi": 30, "bold": 51, "bond": [39, 52], "bonu": 41, "book": [9, 39, 40, 46, 47, 49, 51, 59], "bool": [29, 30, 40, 49], "bool_t": 28, "boom": 53, "boost": [47, 52, 55], "booster": 41, "bootstrap": [10, 51], "border": [13, 18, 32, 37, 45, 47, 54, 56], "bore": [18, 29, 30, 37], "boston": [18, 37], "both": [2, 6, 13, 14, 15, 17, 18, 20, 21, 22, 24, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 55, 58, 59], "bother": 42, "bottom": [30, 45], "bought": 46, "bound": [43, 50], "boundari": [14, 21, 33, 45, 47, 51, 52, 57], "bow": [29, 30], "bow_df": [17, 24, 36], "box": [9, 42, 55], "boxplot": 42, "boyc": [20, 32], "br": [29, 30, 47], "bracket": 8, "brain": [43, 48], "branch": [13, 20, 32, 45, 47, 50], "brand": 51, "breach": 30, "break": [1, 23, 29, 30, 39, 55, 57], "breakdown": 19, "breakwat": 48, "breath": 55, "breathtak": 47, "breed": 55, "breiman": 41, "bridg": 30, "brief": [4, 18, 37, 41], "briefli": [12, 19, 31, 39, 41, 43], "bring": [6, 26, 42, 45, 52, 53, 55], "british": [1, 47], "british_columbia": 47, "broad": [15, 22, 27, 34, 47, 57], "broadcast": 47, "broader": [2, 41, 47], "broadest": 47, "broadli": [13, 15, 18, 20, 22, 32, 34, 37, 39, 41, 44, 45, 47], "broken": 30, "broth": 28, "brownle": 43, "browser": 10, "bruno": 30, "brush": 48, "bryan": 30, "bsmtcond": [40, 42, 51], "bsmtexposur": [40, 42, 51], "bsmtfinsf1": [40, 42, 51], "bsmtfinsf2": [40, 42, 51], "bsmtfintype1": [40, 42, 51], "bsmtfintype2": [40, 42, 51], "bsmtfullbath": [40, 42, 51], "bsmthalfbath": [40, 42, 51], "bsmtqual": [40, 42, 51], "bsmtunfsf": [40, 42, 51], "btw": 42, "bubbl": [46, 48], "bucket": [43, 53], "buddi": 30, "budget": [38, 46], "bug": [4, 8], "bui": [46, 52], "build": [0, 2, 10, 11, 14, 16, 17, 21, 23, 24, 28, 33, 35, 36, 41, 43, 44, 47, 49, 51, 54, 57], "built": [8, 12, 13, 14, 18, 19, 20, 31, 32, 33, 37, 38, 42, 49, 51, 52], "bullshit": [1, 50], "bulwark": 48, "bunch": [8, 10, 13, 20, 26, 32, 40, 41, 48, 50, 51, 52, 57], "bundl": [7, 10], "bureau": [18, 37], "busi": [39, 44, 50, 53], "businesswoman": 47, "bustl": 49, "butterfli": 45, "buzz": [12, 19, 31], "bypass": 59, "c": [0, 1, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 57, 59], "c1": 45, "c2": 45, "c_1": 44, "c_2": 44, "c_3": 44, "c_log": [15, 22, 27, 34, 57], "c_val": 27, "c_valu": 27, "c_widget": [15, 22, 27, 34, 57], "ca": [1, 5, 9, 12, 19, 52, 53, 59], "ca_transform": [17, 24, 36], "cache_s": 51, "cal_hous": [18, 37], "calcul": [7, 14, 15, 16, 21, 22, 23, 26, 33, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 49, 52, 53, 54, 55, 57], "calgary_flam": 47, "calibr": 52, "california": [16, 23, 35, 43], "california_h": 43, "californian": [16, 23, 35], "call": [1, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57], "callback": 41, "caller": 52, "calm": 55, "came": 49, "camera": [17, 24, 30, 36], "campu": [43, 59], "can": [1, 4, 6, 7, 10, 12, 13, 15, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59], "canada": [5, 14, 15, 17, 18, 21, 22, 24, 33, 34, 36, 37, 47, 51, 53, 55], "canada_usa_c": [13, 14, 15, 18, 21, 22, 32, 33, 34, 37, 56], "canadian": [28, 47], "canadien": 47, "canberra": 49, "cancel": 59, "cancer": [12, 19, 31, 43], "candid": [26, 38, 41, 47, 57], "cannibalist": 30, "cannot": [0, 8, 12, 14, 15, 19, 21, 22, 33, 34, 38, 39, 41, 42, 43, 45, 49, 50, 51, 59], "canuck": 47, "canva": [1, 7, 12, 13, 19, 52], "capabl": 9, "capit": [39, 41, 42], "caption": [7, 48], "captiv": 47, "captur": [11, 14, 16, 18, 21, 23, 33, 35, 37, 41, 43, 45, 46, 47, 49, 50, 55], "car": [12, 19, 31, 47, 48, 52], "card": [12, 13, 19, 20, 31, 32, 39, 50, 51], "care": [5, 7, 14, 16, 21, 23, 33, 35, 38, 39, 40, 42, 43, 44, 49, 50, 55], "carefulli": [1, 12, 19, 39, 40, 59], "carpentri": 5, "carri": [13, 14, 15, 17, 20, 21, 22, 24, 26, 28, 32, 33, 34, 36, 38, 39, 40, 41, 44, 46, 47, 49, 52, 53, 57], "caruana": 42, "case": [6, 10, 11, 13, 14, 15, 16, 20, 21, 22, 23, 28, 29, 30, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 54, 55, 59], "cash": [12, 19, 30, 31], "cast": [30, 38, 46, 53], "castl": 48, "cat": [12, 19, 27, 31, 39, 41, 47, 48, 53, 55], "catamount": [12, 19, 31, 48], "catboost": [11, 42, 51, 55], "catboostclassifi": 41, "catboostregressor": 41, "catch": [39, 59], "categor": [13, 20, 26, 32, 38, 39, 40, 41, 43, 44, 46, 47, 50, 51, 55, 57, 58], "categori": [15, 16, 22, 23, 27, 28, 34, 35, 39, 40, 41, 42, 43, 44, 48, 51, 55], "categorical_feat": [17, 24, 28, 36, 38, 55], "categorical_featur": [36, 39, 40, 41, 42, 49, 50, 51], "categorical_transform": [28, 36, 39, 40, 41, 42, 49, 51], "categories_": [16, 17, 23, 24, 35, 36], "cater": 44, "caus": [39, 42, 43, 46, 50, 59], "causal": [42, 43], "caution": 49, "cbar": [18, 37], "cbtf": [1, 59], "cc": [0, 1], "cc_df": 39, "cconj": 47, "ccp_alpha": 51, "ceil": 30, "cell": [7, 8, 12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 31, 35, 36, 38, 39, 40, 41, 42, 43, 46, 48, 50, 51, 53, 56, 57], "censor": [1, 11, 51, 52, 55], "censu": [18, 37, 39, 41, 42], "census_df": 39, "cent": 40, "center": [15, 22, 34, 44, 45, 48, 54], "centercrop": 48, "centers_idx": 44, "central": [5, 12], "centralair": [40, 42, 51], "centralair_i": 40, "centralair_n": 40, "centric": [11, 51], "centroid": [44, 45], "centroids_idx": 44, "centroids_idx_init": 44, "centuri": 47, "certain": [10, 15, 18, 22, 29, 30, 34, 37, 38, 39, 42, 43, 44, 47, 50, 51], "certainli": 56, "certainti": 39, "cezannec": 48, "chaat": 47, "chain": [17, 24, 36], "challeng": [6, 11, 14, 19, 33, 43, 44, 46, 48, 49, 52, 55], "chambar": 28, "chanc": [14, 32, 33, 38, 39, 40, 43, 44, 50, 51, 52], "chang": [0, 5, 7, 8, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 27, 32, 33, 34, 35, 38, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51, 56, 57, 59], "channel": [1, 10, 48], "chapter": 1, "charact": [17, 24, 30, 36, 39, 47], "characterist": [13, 14, 18, 20, 21, 32, 33, 37], "charg": [0, 12, 19, 30, 31, 50], "charl": [18, 30, 37], "charm": [30, 47], "chart": [42, 49, 50, 51], "chat": 59, "chatgpt": [12, 47], "che210d": 9, "cheap": 30, "cheaper": 43, "cheat": 9, "check": [1, 4, 7, 10, 12, 13, 14, 16, 18, 19, 20, 21, 23, 31, 32, 33, 35, 37, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 57], "check_arrai": 28, "check_assumpt": 50, "check_consistent_length": 28, "check_invers": [17, 24, 36], "check_param": 28, "check_x_i": 28, "check_y_param": 28, "checklist": 55, "checkmark": 46, "checkout": 38, "cheetah": [12, 19, 31, 48], "chegini": [1, 59], "chemic": 30, "chemistri": 30, "cherri": 51, "chest": [14, 21, 33], "chetah": [12, 19, 31, 48], "chi": 50, "chicago": 53, "chicken": 44, "child": [30, 39, 42], "children": 46, "chill": 30, "chines": [28, 47], "chloe": 30, "chn": 8, "choic": [2, 21, 38, 40, 41, 42, 44, 45, 46, 49, 53, 57, 58], "choos": [12, 31, 38, 39, 41, 45, 51, 52, 55, 57], "chop": [38, 47, 51], "choreograph": 53, "chose": [26, 51], "chosen": [14, 21, 33, 38, 39, 50, 51, 55], "chrbv": 50, "christin": 53, "christma": 53, "christoph": 30, "chrome": [12, 19], "chunki": 44, "churn": [51, 55], "ciml": 1, "cinematographi": [30, 47], "cinereu": 48, "circl": [15, 22, 34, 39], "circumst": 7, "citat": 7, "cite": 50, "citi": [13, 14, 15, 21, 22, 32, 33, 34, 47, 49, 51, 55, 56], "citibik": 49, "cities_df": [15, 18, 22, 34, 37], "citizen": 50, "cityscap": 49, "civ": [39, 41, 42], "clai": 42, "claim": [0, 38, 39], "clarif": 44, "clarifi": 55, "clariti": 11, "class": [1, 4, 5, 10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 43, 44, 47, 49, 50, 51, 52, 56, 57], "class_attend": [13, 14, 20, 21, 32, 33, 55], "class_attendance_enc": [17, 24, 36], "class_attendance_level": [17, 24, 36], "class_label": 39, "class_labels_fil": [12, 19, 31], "class_nam": [13, 15, 20, 22, 27, 32, 34, 41, 48], "class_sep": 39, "class_weight": [41, 51], "classes_": [18, 29, 30, 37, 39, 41, 42, 48, 54], "classic": [15, 22, 30, 34, 48, 54], "classif": [1, 2, 11, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 28, 33, 34, 35, 36, 37, 40, 41, 42, 43, 46, 47, 49, 50, 51, 54, 56, 57], "classifi": [14, 15, 16, 17, 21, 22, 23, 24, 27, 33, 34, 35, 36, 38, 39, 42, 48, 51, 54, 56, 58], "classification_df": [13, 14, 20, 21, 32, 33], "classification_report": [39, 48], "classifiers_ndt": 41, "classify_imag": [12, 19, 31, 48], "classmat": [6, 57, 58, 59], "classroom": [1, 52], "claudio": 30, "clean": [2, 12, 19, 26, 28, 29, 30, 31, 45, 51, 59], "clean_text": 47, "cleaned_hm": [39, 52], "cleaned_restaurant_data": 28, "cleaner": [39, 42], "clear": [7, 11, 39, 44, 52, 57], "clearli": [4, 6, 7, 30, 38, 41, 42, 49], "cleric": [39, 41, 42], "clever": 51, "clf": [12, 13, 15, 18, 19, 20, 22, 31, 32, 34, 37, 48], "click": [1, 5, 7, 39, 46, 51, 52], "client": [46, 52], "clinic": [13, 20, 32], "clip": [12, 19, 27, 31], "cloak": 30, "clone": [5, 7, 10], "close": [2, 12, 14, 15, 18, 21, 22, 27, 33, 34, 37, 38, 39, 44, 45, 47, 49, 53, 54, 57, 59], "close_default_lr": 39, "close_zero_svm": 39, "closer": [15, 16, 18, 22, 23, 34, 35, 37, 46, 56, 59], "closest": [15, 16, 21, 22, 23, 34, 35, 39, 44, 45, 47, 49], "closet": 30, "cloth": 49, "cloud": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 36, 37, 38, 39, 40, 41, 53, 59], "cloud3pm": 49, "cloud9am": 49, "clust_label": 44, "cluster": [1, 2, 11, 46, 47, 49, 52], "cluster_cent": 44, "cluster_centers_": 44, "cluster_std": [45, 48], "clutter": [13, 32], "cm": [15, 18, 22, 27, 34, 37, 39, 42, 46, 57], "cmap": [16, 23, 35, 38, 39, 42, 48], "cmn": 40, "cmp": 50, "cnn": [48, 49], "co": [17, 24, 36, 47], "coast": 48, "cockpit": 51, "code": [4, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58], "codecademi": 9, "coef": [49, 50, 53], "coef0": 51, "coef_": [18, 29, 30, 37, 40, 41, 42, 43, 46, 48, 49, 50, 53, 54], "coef_df": [18, 37, 42], "coef_nonzero": 49, "coeff": [18, 29, 30, 37], "coeff_df": 49, "coeffici": [40, 41, 43, 46, 48, 49, 50, 51, 53, 54, 55], "coefs_df": 43, "coher": 44, "col": [13, 17, 18, 20, 24, 32, 36, 37, 46, 49, 55], "col1": 8, "col2": 8, "col3": 8, "col4": 8, "col5": 8, "col6": 8, "cold": [16, 23, 35], "colinear": 42, "collabor": [5, 11, 46, 59], "collaps": 42, "colleagu": [8, 9], "collect": [11, 12, 13, 16, 17, 19, 20, 23, 24, 28, 31, 32, 35, 36, 39, 41, 42, 43, 46, 47, 48, 49, 50, 52, 55], "colleg": [39, 41, 42], "collinear": 43, "color": [18, 37, 42, 43, 44, 45, 49, 51], "color_continuous_scal": 43, "color_threshold": 45, "colorbar": [16, 18, 23, 35, 37], "colour": [17, 18, 24, 36, 37, 38, 42, 44, 45, 48], "colsample_bylevel": 41, "colsample_bynod": 41, "colsample_bytre": 41, "columbia": [1, 9, 47], "column": [7, 12, 13, 14, 15, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 55, 56, 57, 58], "column_nam": [17, 24, 36], "column_stack": 43, "columntranform": 58, "columntransform": [1, 16, 23, 28, 35, 38, 39, 40, 41, 42, 43, 49, 50, 51, 53], "columntransformer__countvectorizer__max_featur": 38, "columntransformercolumntransform": [17, 24, 36, 38, 40, 41, 43, 53], "columntransformerifittedcolumntransform": [17, 24, 28, 36, 40, 51], "columntransformerinot": [17, 24, 36, 41], "com": [0, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 36, 37, 38, 39, 40, 41, 48, 49, 50, 52, 53, 59], "comat": 47, "combin": [13, 16, 20, 23, 28, 32, 35, 36, 38, 39, 43, 46, 48, 49, 50, 51, 56, 57], "come": [10, 12, 13, 16, 17, 19, 20, 23, 24, 26, 28, 30, 31, 32, 35, 36, 39, 43, 46, 47, 48, 49, 50, 51, 56], "comedi": [30, 46], "comfi": 28, "comfort": [5, 30], "command": [4, 10, 39, 47, 52], "comment": [8, 9, 28], "commerci": 0, "commit": [7, 39, 59], "common": [1, 8, 11, 13, 14, 15, 20, 21, 22, 27, 32, 33, 34, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 52, 54, 57, 59], "commonli": [13, 16, 20, 23, 32, 35, 38, 39, 44, 50], "commonwealth": 47, "commun": [1, 2, 10, 11, 17, 24, 36, 38, 40, 52, 59], "commut": 8, "comp_dict": 39, "compact": [38, 43], "compani": [39, 44, 46, 47, 50, 53], "compar": [8, 11, 13, 14, 15, 16, 18, 20, 21, 22, 23, 26, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 54, 55], "comparison": [28, 45, 48, 50, 55], "compassion": 59, "compat": [8, 42], "compatibitl": 8, "compel": 49, "compet": 53, "competit": [41, 48, 54], "complain": [6, 53], "complaint": [6, 59], "complement": 47, "complet": [1, 6, 7, 12, 16, 19, 21, 23, 28, 30, 31, 35, 38, 41, 42, 43, 45, 47, 50, 51, 56, 57, 59], "complex": [11, 13, 15, 18, 20, 22, 27, 28, 32, 34, 37, 38, 40, 41, 42, 43, 45, 47, 48, 49, 52, 57], "complex_warn": 28, "complexwarn": 28, "compli": 0, "complic": [4, 13, 14, 20, 27, 28, 32, 33, 38, 40, 43], "compon": [17, 24, 36, 39, 46, 49, 51, 52, 59], "components_": 47, "compos": [15, 17, 24, 27, 28, 34, 36, 38, 39, 40, 41, 42, 43, 48, 49, 50, 51, 58], "composit": [17, 24, 36], "compound": [47, 48, 50, 53], "comprehend": [27, 47], "comprehens": [44, 55, 59], "compress": [17, 24, 30, 36, 44, 47], "compris": [12, 13, 19, 20, 31, 32, 44], "comput": [1, 7, 9, 10, 11, 17, 24, 27, 31, 36, 38, 39, 41, 42, 43, 44, 45, 47, 49, 51, 52, 54, 59], "computation": 43, "compute_class_weight": 39, "computer_programm": 47, "coms4995": [16, 23, 35], "con": [44, 47, 48, 51], "concat": [12, 15, 16, 17, 18, 19, 22, 23, 24, 31, 34, 35, 36, 37, 42], "concaten": [17, 24, 36, 47], "concav": 43, "concensu": [14, 33], "concentr": [38, 55], "concept": [1, 11, 13, 14, 20, 21, 28, 32, 33, 42, 43, 44, 49, 55, 57, 59], "conceptnet": 47, "conceptu": [41, 51], "concern": [4, 11, 17, 19, 24, 26, 36, 41, 59], "concess": [1, 7], "concis": [13, 20, 32, 52], "conclus": 51, "concord": 50, "concordance_index": 50, "concordance_index_": 50, "concret": [12, 19, 31, 51], "conda": [12, 19, 27, 31, 39, 40, 41, 42, 44, 47, 50, 53], "condens": 20, "condit": [0, 12, 13, 17, 19, 20, 24, 26, 30, 31, 32, 36, 43, 47, 50], "condition1": [40, 42, 51], "condition1_arteri": 40, "condition1_feedr": 40, "condition1_norm": 40, "condition1_posa": 40, "condition1_posn": 40, "condition1_rra": 40, "condition1_rran": 40, "condition1_rrn": 40, "condition1_rrnn": 40, "condition2": [40, 42, 51], "condition2_arteri": 40, "condition2_feedr": 40, "condition2_norm": 40, "condition2_posa": 40, "condition2_posn": [40, 42], "condition2_rra": 40, "condition2_rran": 40, "condition2_rrnn": 40, "conditional_aft": 50, "conduct": [11, 19], "confer": 47, "confid": [12, 14, 19, 21, 29, 30, 31, 33, 42, 50, 52, 55, 57], "confidenti": 39, "config": 10, "config_context": 28, "configur": [38, 40, 41], "confirm": 10, "conflict": [10, 45, 59], "confound": 43, "confus": [8, 15, 17, 22, 24, 34, 36, 40, 44, 52, 57], "confusingli": [12, 19], "confusion_matrix": [39, 48, 50], "confusionmatrixdisplai": 39, "congrat": [17, 24, 36], "conjunct": 43, "connect": [0, 13, 20, 32, 45, 46, 52], "connot": 47, "conort": 43, "consciou": 59, "consecut": 49, "consequ": [7, 12, 17, 19, 31, 36, 39, 46, 51], "consid": [4, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 55, 57, 59], "consider": [2, 11, 30, 39, 41, 44, 46, 50, 51, 52], "consist": [6, 7, 13, 14, 16, 20, 21, 23, 28, 30, 32, 33, 35, 44, 52, 53], "const": 47, "constant": [13, 20, 28, 32, 39, 40, 41, 42, 49, 50, 51], "constitu": 41, "constitut": [47, 59], "construct": 46, "constructor": [13, 16, 23, 32, 35], "consult": [15, 22, 27, 34, 57, 59], "consum": [12, 19, 31, 43, 44, 46, 52, 55], "consumpt": 49, "contact": [12, 19, 31, 59], "contain": [8, 10, 12, 13, 16, 17, 18, 19, 20, 23, 24, 28, 30, 31, 32, 35, 36, 37, 40, 46, 47, 48, 52, 53, 54], "container": 52, "contamin": 30, "content": [1, 4, 10, 11, 19, 44, 47, 48, 52, 55, 59], "contest": 6, "context": [11, 13, 16, 18, 20, 23, 32, 35, 37, 38, 39, 41, 42, 43, 45, 46, 48, 49, 51, 55, 57], "contextu": 11, "contin": [17, 36], "conting": 45, "continu": [17, 24, 28, 36, 38, 40, 41, 43, 47, 49, 51], "contract": [0, 50], "contract_month": 50, "contract_on": 50, "contract_two": 50, "contrast": [11, 55], "contribut": [15, 18, 22, 34, 37, 42, 48, 59], "control": [5, 8, 13, 14, 15, 17, 18, 20, 21, 22, 24, 32, 33, 34, 36, 37, 40, 41, 48, 59], "convei": 11, "conveni": [8, 12, 19, 38, 39, 44, 47, 49, 50, 51, 52], "converg": 44, "convers": [39, 40, 42, 47, 52], "convert": [12, 16, 17, 18, 19, 23, 24, 28, 31, 35, 36, 37, 41, 42, 43, 47, 49, 50, 59], "convinc": [17, 24, 36, 51], "convolut": [43, 48], "convolutional_neural_network": 48, "cooccurrencematrix": 47, "cook": 44, "cool": [30, 48], "coolwarm": [18, 37], "coordin": [19, 59], "copi": [0, 7, 8, 10, 13, 20, 28, 32, 38, 41, 42, 44, 46, 48, 49, 50, 51, 59], "copyright": 0, "cor": 42, "coral": 48, "core": [9, 11, 16, 17, 23, 24, 28, 33, 35, 36, 38, 39, 40, 43, 45, 46, 49, 50, 52, 55], "corefer": 47, "corei": 52, "corgi": [12, 19, 31, 48], "corner": 30, "corona_nlp_test": 53, "coronapocalyps": 53, "coronaviru": 53, "corpor": [5, 53], "corpora": [17, 24, 36, 47], "corpu": [17, 24, 36, 39, 47], "corr": 42, "corr_df": 42, "correct": [7, 12, 13, 14, 15, 19, 20, 21, 22, 31, 32, 33, 34, 39, 41, 42, 50, 51, 56, 57], "correctli": [1, 10, 13, 14, 20, 21, 32, 33, 39], "correl": [49, 55], "correspond": [1, 12, 13, 14, 15, 17, 18, 19, 20, 21, 24, 27, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 46, 49, 57, 59], "cosin": 47, "cosine_similar": 47, "cost": [8, 12, 19, 30, 31, 48, 51, 59], "cost_rep": 8, "costco": 47, "costli": 39, "cot": 48, "cote": 48, "could": [6, 8, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 46, 47, 49, 50, 51, 52, 57, 59], "couldn": [30, 47], "count": [8, 13, 16, 17, 20, 23, 24, 26, 28, 30, 32, 35, 36, 39, 40, 43, 47, 48, 49, 50, 52, 53, 54, 57, 59], "counter": 39, "counti": [26, 57], "countri": [14, 15, 17, 18, 21, 22, 33, 34, 36, 37, 39, 41, 42, 47, 59], "country_columbia": 42, "country_dominican": 42, "country_guatemala": 42, "country_hondura": 42, "country_hong": 42, "country_hungari": 42, "country_india": 42, "country_iran": 42, "country_miss": [41, 42], "country_puerto": 42, "country_scotland": 42, "country_south": 42, "country_taiwan": 42, "country_thailand": 42, "country_trinadad": [41, 42], "country_unit": [41, 42], "country_vietnam": [41, 42], "country_yugoslavia": [41, 42], "countvector": [12, 18, 19, 28, 29, 30, 31, 37, 38, 39, 47, 52, 53, 55], "countvectorizercountvector": [17, 24, 30, 36, 38, 53], "countvectorizeroriginaltweet": 53, "countvectorizersong_titl": 38, "coupl": [4, 13, 32, 38, 45, 53], "cour": 47, "cours": [2, 4, 5, 6, 7, 10, 13, 14, 17, 18, 20, 21, 24, 26, 27, 28, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 53, 55, 56, 57], "coursera": [1, 9], "coursework": 59, "court": 47, "covari": [13, 20, 32, 50], "cover": [8, 11, 19, 39, 41, 44, 48, 49, 59], "coverag": 39, "covid": 53, "covid2019": 53, "cow": 51, "cox": 11, "coxph_fitt": 50, "coxphfitt": 50, "cph": [50, 51, 55], "cph_param": 50, "cpsc": [9, 10, 13, 20, 31, 32, 41, 43, 47, 48, 49, 51, 52, 53, 59], "cpsc330": [0, 1, 10, 12, 17, 19, 20, 24, 25, 27, 28, 31, 32, 33, 36, 38, 42, 47, 48, 50, 52, 53, 59], "cpsc330env": 10, "cpu": [27, 38, 48], "craft": [15, 22, 34, 39, 41, 42, 44, 57], "crash": 1, "crate": 48, "crawl": 30, "crazi": [28, 52], "creat": [8, 9, 10, 12, 15, 16, 18, 19, 22, 23, 26, 27, 28, 29, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58], "create_lag_df": 49, "create_lag_featur": 49, "create_y_from_r": 46, "creativ": [1, 30, 47], "credenc": 51, "credit": [0, 13, 20, 32, 39, 41, 47, 49, 50, 51], "creditcard": 39, "creepi": 30, "crime": [18, 37], "crimin": 42, "criteria": [13, 20, 32, 45], "criterion": [45, 51], "critic": [11, 51], "cross": [13, 15, 17, 20, 24, 28, 32, 34, 36, 38, 40, 41, 42, 44, 46, 50, 51, 52, 53, 55, 58], "cross_val": 41, "cross_val_predict": [39, 41, 50], "cross_val_scor": [16, 17, 18, 23, 24, 28, 29, 30, 35, 36, 37, 38, 39, 40, 41, 42, 43, 49, 50, 51, 55, 58], "cross_valid": [15, 16, 17, 18, 22, 23, 24, 26, 27, 28, 29, 30, 34, 35, 36, 37, 38, 39, 41, 42, 43, 46, 49, 50, 51, 52, 53, 55, 57, 58], "cross_validate_std": [14, 21, 33], "crowd": [41, 45], "crown": 59, "crown_princ": 47, "crucial": [12, 14, 18, 19, 21, 31, 33, 37, 42, 44, 45, 46, 47], "crude": 47, "cs189": 9, "cs189_ch7": 9, "csr": 28, "css": 52, "csv": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58], "ct": [17, 24, 36], "cuda": [27, 48], "cui": [1, 59], "cuisin": 52, "cultiv": 11, "cultur": [48, 59], "curios": [12, 19, 31], "curiou": [12, 19, 31, 57], "curl": 52, "current": [1, 41, 47, 48, 49, 50, 51, 52, 53], "curriculum": 11, "curs": 51, "curv": [7, 8, 11, 44, 51, 55, 57], "cush": 30, "custom": [5, 8, 12, 13, 17, 19, 20, 24, 28, 31, 32, 36, 39, 40, 46, 52, 53, 55], "custom_plot_tre": [13, 14, 20, 21, 32, 33, 41, 42], "customerid": 50, "customiz": 53, "cut": 45, "cv": [14, 17, 21, 24, 26, 27, 33, 36, 39, 40, 41, 42, 43, 49, 50, 51, 52, 55, 57], "cv_feat": 53, "cv_results_": [38, 40], "cv_score": [14, 21, 27, 33, 40], "cv_train_scor": [26, 57], "cv_valid_scor": [26, 57], "cycl": 8, "cyclic": 49, "cycling_data": 8, "cygnu": 48, "d": [4, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 50, 52], "d3": 44, "da": [12, 19, 31], "dabeaz": 9, "dad": 43, "daft": 30, "dai": [4, 8, 14, 28, 30, 43, 48, 50, 51, 55, 59], "daili": [50, 55], "dall": 49, "damag": [0, 39], "dan": 47, "danceabl": [15, 16, 23, 34, 35, 38], "dark": 53, "darker": 38, "dashboard": [15, 22, 27, 34, 57], "data": [1, 2, 5, 7, 8, 9, 10, 11, 27, 29, 30, 45, 47, 50, 54, 55, 56, 58, 59], "data_dict": [18, 37], "data_dir": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57], "data_to_wrap": [17, 24, 36], "data_transform": [27, 48], "data_transforms_bw": 48, "data_url": 39, "datacamp": 9, "datafram": [12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 57, 58], "dataload": [27, 48], "dataloaders_bw": 48, "datapoint": [18, 37], "dataquest": 9, "dataset": [8, 11, 12, 14, 15, 17, 19, 21, 22, 24, 26, 27, 28, 31, 33, 34, 41, 42, 43, 44, 45, 50, 52, 53, 54, 55, 57], "dataset2": 44, "dataset_s": [27, 48], "dataviz": 51, "date": [7, 10, 12, 13, 19, 26, 31, 32, 46, 47, 50, 52, 53, 55, 57, 59], "date_rang": 49, "dates_rain": 49, "datetim": 50, "datetime64": 49, "datetimeindex": 49, "datum": 47, "daughter": [30, 39, 52], "daum\u00e9": 1, "daunt": 46, "dave": 47, "david": [1, 47, 51], "dawn": 30, "day_nam": 49, "daylight": 49, "dayofweek": 49, "days_sinc": 49, "dbscan": [11, 52], "dc": [49, 50, 53], "dcc": [18, 37], "dd": 49, "de": [47, 49], "deactiv": 10, "dead": 30, "deadlin": [14, 19, 59], "deal": [0, 14, 15, 16, 21, 22, 23, 28, 33, 34, 35, 40, 47, 50, 51, 52, 55, 58], "death": 59, "debat": [8, 19, 42], "debbi": 53, "deborah": 30, "debug": [4, 42], "decad": 48, "decemb": [26, 49], "decent": 30, "decid": [8, 13, 15, 18, 20, 22, 30, 32, 34, 37, 41, 42, 43, 44, 45, 47, 49, 50, 55], "decis": [1, 2, 6, 14, 16, 21, 23, 29, 30, 33, 35, 38, 39, 41, 43, 48, 54, 55, 56, 58, 59], "decision_boundari": 54, "decision_funct": 39, "decisiontreeclassifi": [14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 33, 34, 35, 36, 37, 38, 42, 56, 57, 58], "decisiontreeclassifierdecisiontreeclassifi": 41, "decisiontreeregressor": [13, 20, 26, 32, 40, 56, 57], "decisiontreeregressorifitteddecisiontreeregressor": 26, "deck": 9, "declar": 59, "decomposit": [45, 46, 47], "decor": 28, "decreas": [14, 18, 21, 26, 33, 37, 38, 41, 42, 44, 57], "deduct": 7, "deem": 6, "deep": [2, 9, 38, 42, 43, 47, 50, 52], "deepen": [55, 59], "deeper": [2, 12, 19, 38, 39, 40, 42], "deepexplain": 42, "def": [14, 15, 16, 21, 22, 23, 27, 28, 29, 30, 33, 34, 35, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 52, 53, 57], "default": [5, 10, 12, 13, 14, 17, 18, 19, 20, 21, 24, 27, 32, 33, 36, 37, 38, 39, 40, 41, 44, 45, 48, 49, 50, 51, 54, 59], "default_check_param": 28, "default_threshold": 39, "defaultdict": 46, "defin": [13, 15, 16, 17, 22, 23, 24, 28, 32, 34, 35, 36, 39, 41, 42, 44, 45, 46, 49, 52], "definit": [8, 15, 22, 34, 42, 44, 47, 49, 54, 55, 56], "degre": 39, "degrees_freedom": 50, "degrees_of_freedom": 50, "del": 41, "delai": [1, 10, 43], "deleg": 47, "delet": [4, 7, 16, 23, 35, 51], "delgado": 41, "delight": 47, "deliver": 7, "delv": [11, 47], "demo": [1, 19, 41, 51, 59], "demograph": [13, 20, 32, 46], "demonstr": [13, 14, 16, 18, 20, 21, 23, 27, 28, 29, 30, 32, 33, 35, 37, 38, 40, 41, 44, 46, 47, 48], "denholm": 30, "denois": 12, "denomin": [40, 53], "denot": [13, 20, 32, 46], "dens": [45, 47], "densenet": [27, 48], "densenet121": [27, 48], "densenet121_weight": [27, 48], "densiti": [42, 45, 55], "dep": 47, "department": 59, "departur": 43, "depend": [2, 8, 10, 13, 14, 15, 17, 20, 21, 22, 24, 32, 33, 34, 36, 38, 39, 40, 41, 42, 44, 45, 47, 49, 50, 51], "dependence_plot": 42, "dependents_no": 50, "dependents_y": 50, "deploi": [14, 21, 26, 33, 39, 46, 51, 55], "deploy": [11, 42, 49], "deprec": [23, 33, 35, 39, 40, 50, 53, 54], "deprecationwarn": [41, 50], "depth": [1, 13, 14, 20, 21, 26, 32, 33, 38, 41, 45, 56, 57], "dequ": [41, 42], "deran": 30, "deriv": [0, 13, 18, 20, 32, 37, 39, 46, 50, 55], "descend": [8, 29, 30, 45, 48, 55], "descent": [30, 49], "descr": [18, 37], "describ": [8, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 26, 28, 31, 32, 33, 34, 35, 37, 39, 40, 46, 47, 49, 52, 57], "descript": [1, 40, 50, 53], "desenet": 27, "deserv": 6, "design": [11, 20, 32, 42, 45, 48, 51, 59], "desir": [28, 39, 47, 50, 58], "desk": 59, "despit": [43, 47], "det": [30, 47, 53], "detach": [27, 48], "detail": [15, 17, 22, 24, 34, 36, 41, 47, 48, 52, 59], "detect": [12, 13, 19, 20, 26, 31, 32, 39, 40, 44, 45, 49, 52], "determin": [15, 20, 22, 27, 34, 44, 45, 47, 50, 51, 57, 59], "detriment": [39, 46], "dev": [14, 33, 54], "develop": [1, 9, 11, 12, 14, 16, 17, 19, 21, 23, 24, 30, 31, 33, 35, 36, 38, 39, 40, 41, 47, 48, 51, 52, 53, 55], "devianc": 50, "deviat": [6, 14, 16, 21, 23, 33, 35, 41, 42], "devic": [27, 28, 41, 48], "deviceprotect": 50, "deviceprotection_no": 50, "deviceprotection_y": 50, "df": [12, 13, 14, 16, 17, 19, 21, 23, 24, 26, 28, 31, 32, 33, 35, 36, 38, 39, 40, 42, 43, 48, 49, 50, 51, 52, 53, 56], "df_concat": [12, 19, 31], "df_float_1": 8, "df_float_2": 8, "df_hour_week_ohe_poli": 49, "df_locat": 49, "di": 50, "diagnos": [14, 33, 42, 55], "diagnosi": 39, "diagnost": [50, 52], "diagon": [15, 22, 34, 39, 42], "diagram": [17, 24, 36, 38, 41, 42], "dialogu": [30, 47], "dict": [39, 46], "dict_kei": 41, "dictionari": [8, 16, 23, 35, 38, 39, 41, 42, 52], "did": [6, 12, 13, 15, 19, 20, 22, 30, 32, 34, 42, 44, 47, 49, 53, 57, 59], "didn": [28, 30, 38, 41, 42, 45, 47, 49, 50, 52], "die": 53, "diet": [13, 20, 32, 47], "diff": 49, "differ": [1, 2, 5, 7, 8, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 26, 28, 30, 31, 32, 33, 34, 36, 37, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 56, 57], "differenti": [11, 12, 13, 19, 20, 31, 32], "difficult": [4, 6, 7, 39, 43, 44, 51], "difficulti": [44, 55], "dig": [39, 40], "digit": [49, 51], "dilemma": 46, "dim": [27, 28, 48], "dimens": [8, 18, 37, 43], "dimension": [2, 8, 18, 20, 27, 37, 38, 39, 41, 43, 44, 47], "dine": 52, "direct": [18, 23, 29, 30, 37, 42, 43, 45, 47, 53], "direct_bilirubin": [12, 19, 31], "directli": [1, 8, 17, 24, 28, 36, 40, 48, 50, 52, 59], "director": [30, 46], "directori": [10, 13, 14, 16, 21, 23, 27, 32, 33, 35], "dirichlet": [47, 48], "disabl": 47, "disadvantag": [38, 41, 45, 46, 58], "disappoint": 30, "disast": [12, 31], "discard": [43, 47], "disciplin": [39, 43], "disclos": [53, 59], "discomfort": 30, "discourag": 8, "discours": 46, "discov": [43, 44], "discoveri": [12, 19, 31], "discret": [13, 20, 28, 32, 43], "discrete_scatt": [13, 14, 15, 18, 20, 21, 22, 27, 32, 33, 34, 37, 44, 45, 48, 54, 56, 57], "discretization_feat": 43, "discrimin": 41, "discuss": [4, 14, 15, 16, 18, 21, 22, 23, 33, 34, 35, 37, 42, 43, 44, 45, 49, 55, 57, 58, 59], "diseas": [13, 20, 32, 39, 50], "dislik": [28, 51], "dispers": 30, "displaci": [47, 53], "displai": [7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 45, 46, 48, 49, 50, 56, 57, 58], "display_heatmap": 38, "display_label": 39, "displaystyl": 47, "disput": 47, "disregard": 30, "disrespect": 4, "dissemin": 52, "dist": [15, 22, 27, 34, 44, 45], "distanc": [8, 16, 23, 27, 35, 43, 45, 46, 47], "distinct": [39, 43, 49, 51], "distinguish": [13, 15, 17, 20, 22, 24, 27, 32, 34, 36, 39, 57], "distract": 59, "distribut": [0, 10, 12, 14, 21, 26, 28, 33, 39, 42, 43, 45, 47, 48, 49, 59], "district": [16, 18, 23, 35, 37], "districtdatalab": 44, "disturb": [12, 19, 31], "dive": 42, "divers": [11, 41, 44, 46, 49], "divid": [18, 37, 39, 41, 42, 49, 57], "divis": [20, 42], "divorc": [41, 42], "dktal": 50, "dlwqn": 50, "dmp": 59, "do": [0, 1, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 18, 19, 20, 21, 22, 24, 26, 27, 30, 31, 32, 33, 34, 37, 40, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 59], "dobj": 47, "doc": [8, 9, 12, 29, 30, 42, 47, 48, 52, 53, 59], "doc_id": 47, "docker": 52, "doctor": [39, 41, 42], "document": [0, 1, 7, 12, 13, 14, 16, 17, 19, 21, 23, 24, 26, 27, 28, 30, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 53, 55, 59], "document_top": 47, "documentari": 46, "doe": [5, 8, 10, 12, 14, 15, 16, 19, 22, 23, 27, 28, 30, 31, 33, 34, 35, 38, 40, 41, 42, 43, 44, 46, 47, 49, 50, 52, 53, 55, 57, 59], "doesn": [7, 8, 12, 14, 16, 17, 21, 23, 24, 30, 33, 35, 36, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 55], "dog": [27, 39, 48], "dolist": 52, "dollar": [4, 18, 37, 40, 51], "dolli": 53, "domain": [0, 12, 19, 31, 42, 44, 47], "domin": [16, 23, 30, 35, 40, 48], "domingo": [1, 14, 33, 43], "dominican_republ": 47, "don": [4, 12, 13, 14, 16, 17, 19, 21, 24, 26, 27, 28, 30, 31, 33, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "done": [5, 10, 12, 14, 17, 19, 21, 24, 30, 33, 36, 38, 39, 48, 49, 51, 55, 58], "dont": 53, "door": 48, "dosa": 47, "dot": [15, 18, 22, 34, 37, 39, 41, 42, 43, 45, 47], "dot_product": 47, "doubl": [30, 38], "down": [14, 21, 28, 30, 33, 39, 42, 47, 50, 51, 57, 59], "downfal": 46, "download": [5, 7, 10, 12, 13, 16, 18, 19, 23, 26, 31, 32, 35, 37, 39, 40, 42, 47, 48, 51, 53, 57], "downright": 51, "dpi": [27, 43], "dr": 47, "draft": 1, "drag": 7, "drama": 46, "drastic": 39, "draw": [18, 37, 38, 47, 51], "drawback": [11, 42, 46], "drawn": 41, "dream": 48, "dreampharmaceut": 47, "drink": 51, "drinker": 47, "drive": [12, 19, 29, 30, 31, 42], "driven": [10, 38, 39], "droit": 47, "drop": [7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 49, 50, 51, 52, 53, 55, 57, 58, 59], "drop_dupl": [15, 22, 34, 38], "drop_feat": [17, 24, 28, 36, 55], "drop_feats_new": 28, "drop_featur": [39, 40, 41, 42, 49, 50, 51, 53], "dropdrop": [17, 24, 28, 36, 40, 41, 51, 53], "drope": [16, 23, 35], "dropna": [39, 49, 52], "dropoff": 44, "drought": [29, 30], "drug": [12, 19, 31, 52], "dsci": [1, 9, 42, 51, 54], "dsl": 50, "dt": [26, 57], "dt_best": 57, "dt_final": 26, "dt_pipe": 38, "dt_regr": 26, "dtype": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53], "dtypelik": 28, "dual": 39, "duan": [1, 59], "dub": 30, "duck": [48, 51], "duckbil": 48, "due": [7, 12, 13, 14, 16, 17, 18, 19, 37, 41, 43, 46, 59], "duffel": 30, "dull": 30, "dummi": [13, 15, 16, 17, 18, 20, 22, 23, 24, 26, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 48, 49, 50, 51, 56, 58], "dummy_clf": [13, 20, 32, 56], "dummy_regr": 26, "dummy_scor": [15, 22, 34], "dummy_valid_accuraci": [15, 22, 34], "dummyclassifi": [14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 48, 51, 52, 53, 56, 57, 58], "dummyregressor": [17, 24, 26, 36, 41, 42, 43, 51, 52, 58], "dump": 52, "dun": [12, 19, 31], "dunham": 30, "dunno": [12, 19, 31], "duplex": 40, "duplic": 8, "durat": [7, 43, 49, 50], "duration_col": 50, "duration_m": [15, 16, 23, 34, 35, 38], "dure": [1, 4, 8, 12, 13, 15, 17, 18, 19, 20, 22, 24, 26, 30, 31, 32, 34, 36, 37, 38, 41, 42, 43, 46, 47, 52, 55, 56, 57, 58, 59], "dwell": 40, "e": [6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55], "e737c5242822": 50, "e_": [14, 21, 33], "each": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59], "eager": 52, "earli": [30, 42, 50, 51, 59], "earlier": [16, 23, 30, 35, 41, 43, 49, 50], "early_stopping_round": 41, "earnest": 59, "easi": [7, 15, 16, 18, 22, 23, 34, 35, 37, 41, 42, 43, 44, 45, 47, 51, 53], "easier": [5, 7, 39, 42, 43, 46, 51], "easiest": [42, 50], "easili": [41, 43, 49, 51, 52, 56], "east": [28, 30], "eat": 30, "eat_out_freq": 28, "echidna": 48, "econom": [17, 24, 36, 49], "ecosystem": 48, "eda": [14, 21, 26, 28, 33, 47, 50, 55], "edg": [13, 20, 32, 38], "edgecolor": [38, 49], "edit": [38, 47], "edu": 9, "educ": [39, 41, 42, 46], "education_level": [39, 41, 42], "effect": [15, 18, 22, 26, 27, 30, 34, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 52, 55, 57, 59], "effici": 38, "effort": [4, 10, 38, 43, 44, 46, 48, 59], "egg": 44, "either": [4, 13, 14, 15, 17, 20, 21, 22, 24, 27, 32, 33, 34, 36, 39, 42, 44, 45, 47, 48, 49, 57], "elast": 50, "elbow": 45, "elect": 47, "electr": [40, 42, 51], "electrical_engin": 47, "electrical_fusea": 40, "electrical_fusef": 40, "electrical_fusep": 40, "electrical_miss": 40, "electrical_mix": 40, "electrical_sbrkr": 40, "electron": [50, 59], "eleg": [16, 23, 35, 47, 51], "elegantli": 47, "element": [0, 1, 9, 14, 17, 24, 30, 33, 36, 47, 56], "eli5": 42, "elif": [13, 20, 32, 49, 50], "elimin": 11, "elliott": 30, "els": [13, 17, 20, 24, 27, 28, 32, 36, 39, 48, 49, 50, 53], "email": [1, 12, 13, 14, 19, 21, 31, 33, 39, 52, 59], "emb": [7, 15, 22, 34, 39, 44, 45], "embarrass": 30, "embed": [1, 11, 17, 24, 36, 48, 52, 55], "emili": 30, "emoji": [29, 30, 53], "emoticon": [43, 44], "emp": 42, "empathi": 47, "emphas": 11, "emphasi": [52, 59], "emploi": [27, 49, 50, 52, 55], "employ": 46, "employe": [13, 20, 32], "empti": [18, 27, 37, 47, 48, 49], "en": [49, 50, 51, 53], "en_core_web_lr": 47, "en_core_web_md": [47, 53], "enabl": [10, 46, 47, 49], "enable_categor": 41, "enable_halving_search_cv": 38, "enc": [16, 17, 23, 24, 35, 36, 49], "enclosedporch": [40, 42, 51], "encod": [12, 14, 19, 21, 26, 28, 29, 30, 31, 33, 38, 39, 40, 42, 46, 50, 55, 58], "encompass": [50, 51, 55], "encount": [17, 24, 36, 38], "encourag": 10, "end": [4, 8, 11, 12, 14, 15, 18, 19, 21, 22, 27, 30, 31, 33, 34, 37, 38, 39, 43, 44, 45, 46, 47, 49, 50, 51, 52, 57, 59], "endors": 0, "endpoint": 50, "energi": [15, 16, 23, 34, 35, 38, 49], "engag": 59, "engin": [1, 9, 11, 17, 24, 36, 39, 40, 44, 46, 47, 50, 52], "england": 53, "english": [12, 16, 19, 23, 28, 29, 30, 31, 35, 38, 39, 47, 48, 52, 53], "enhanc": 59, "enjoi": [1, 18, 29, 30, 37], "enjoy_class": [17, 24, 36], "enjoy_cours": [17, 24, 36, 55], "enjoy_course_enc": [17, 24, 36], "enjoy_the_mo": [39, 52], "enough": [7, 15, 17, 22, 30, 34, 36, 39, 40, 41, 44, 46, 55], "enrol": 59, "ensembl": [1, 11, 28, 40, 42, 43, 45, 46, 49, 50, 51, 52], "ensiti": 45, "ensur": [7, 11, 16, 23, 26, 35, 41, 49], "ensure_2d": 28, "ensure_all_finit": 28, "ensure_min_featur": 28, "ensure_min_sampl": 28, "ensure_non_neg": 28, "ent": [47, 53], "enter": [17, 24, 36, 50, 51], "enterpris": 5, "entertain": [30, 47], "enthusiast": [12, 19, 31, 51], "entir": [4, 8, 12, 14, 19, 21, 30, 33, 40, 48, 49, 51, 52, 53, 59], "entiti": [43, 46, 47, 53], "entitl": [17, 24, 36], "entlebuch": [12, 19, 31, 48], "entri": [15, 16, 17, 18, 22, 23, 24, 34, 35, 36, 37, 39, 40, 43, 46, 49, 50], "entropi": [13, 20, 32, 51], "enumer": 41, "env": [10, 17, 20, 24, 27, 28, 32, 33, 36, 38, 42, 50, 53, 54], "environ": [3, 5, 8, 12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 31, 35, 36, 38, 39, 40, 41, 42, 43, 47, 48, 50, 51, 53, 59], "environemnt": 10, "environment": 55, "ep": [13, 14, 15, 18, 21, 22, 32, 33, 34, 37, 45, 56], "episod": 30, "epoch": 49, "epsilon": [45, 51], "equal": [8, 15, 17, 22, 34, 36, 39, 40, 41, 42, 45, 46, 49, 55, 59], "equat": [4, 12, 18, 19, 37], "equip": [15, 22, 34, 50, 59], "equival": [8, 39, 41], "erik": 47, "err": 47, "error": [4, 6, 7, 8, 10, 11, 13, 15, 17, 18, 20, 22, 24, 28, 32, 34, 36, 37, 41, 42, 43, 47, 50, 51, 52, 55, 57], "error_": [14, 21, 33], "erupt": [12, 31], "erythrocebu": [12, 19, 31, 48], "es": 49, "escap": 30, "eskimo": 39, "esl": 1, "especi": [2, 15, 20, 22, 30, 32, 34, 38, 39, 41, 43, 46, 49], "essenti": [50, 55], "establish": 26, "estat": [13, 20, 32], "estim": [14, 15, 17, 18, 22, 24, 28, 33, 34, 36, 37, 38, 43, 44, 50, 51, 52, 55], "estimator_nam": 28, "estimators_": 41, "et": [41, 47], "etc": [1, 2, 7, 8, 13, 20, 32, 43, 47, 48, 49, 50, 51, 52, 53, 59], "ethic": [1, 11, 52], "euclidean": [44, 45, 47], "euclidean_dist": [15, 16, 22, 23, 34, 35, 44, 45, 47], "ev": 53, "eva": 46, "eva_model": 46, "eval": 48, "eval_metr": [41, 42], "eval_on_featur": 49, "evalu": [1, 8, 11, 13, 14, 20, 21, 26, 32, 33, 38, 40, 42, 44, 49, 51, 52, 57], "evapor": 49, "even": [0, 7, 11, 12, 13, 14, 18, 19, 20, 21, 28, 30, 32, 33, 37, 38, 39, 43, 44, 45, 46, 49, 50, 51, 53, 55, 57, 58, 59], "evenli": 30, "event": [0, 39, 40, 59], "event_col": 50, "event_observ": 50, "ever": [13, 20, 30, 32, 54], "everi": [8, 12, 13, 14, 19, 20, 21, 30, 32, 33, 41, 45, 49, 57], "everydai": [8, 47], "everyon": [6, 42, 51, 55], "everyth": [12, 17, 19, 24, 36, 39, 46, 49, 52], "everywher": 49, "evict": 53, "evo": 52, "evocarshar": 52, "evok": 47, "ex": [40, 42, 51], "ex1_idx": 42, "ex2_idx": 42, "ex_df": [29, 30], "exact": [4, 50], "exactli": [7, 12, 14, 19, 20, 21, 30, 31, 33, 42, 57], "exagger": 51, "exam": [1, 6, 12, 19, 51, 52], "examin": [14, 15, 16, 18, 21, 22, 23, 26, 27, 28, 33, 34, 35, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54], "exampl": [0, 4, 5, 6, 7, 8, 10, 21, 27, 28, 29, 30, 40, 45, 46, 48, 49, 52, 54, 55, 56, 57, 59], "example1": [13, 20, 32], "example2": [13, 20, 32], "exceedingli": 57, "excel": [17, 18, 24, 29, 30, 36, 37, 40, 42, 50, 55, 58], "except": [0, 1, 7, 8, 14, 21, 28, 30, 33, 49, 50, 59], "exception": 4, "exchang": [39, 55], "excit": 46, "execut": [4, 7, 44, 52], "exercis": [1, 7, 9, 12, 19, 47, 52, 53, 57, 58, 59], "exist": [8, 39, 43, 50, 52], "exp": [18, 37, 50, 51], "expand": [1, 13, 20, 32, 59], "expect": [1, 4, 7, 8, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 27, 28, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 54, 55, 57, 59], "expected_valu": 42, "expenditur": 49, "expens": [12, 19, 31, 39, 40, 43, 44, 46], "experi": [12, 19, 31, 38, 46, 47, 59], "experienc": 59, "experiment": [30, 38, 52], "expert": [12, 13, 14, 19, 20, 21, 31, 32, 33, 38, 42, 43], "explain": [4, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55], "explan": [4, 14, 15, 22, 30, 33, 34, 55], "explanatori": [13, 20, 32], "explicit": [39, 50], "explicitli": [8, 12, 19, 31, 52], "exploit": 6, "explor": [13, 14, 17, 21, 24, 26, 27, 29, 30, 32, 33, 36, 38, 39, 42, 43, 46, 47, 48, 52, 57], "exploratori": [40, 50, 52, 55], "explos": 53, "expm1": [40, 51], "expon": 38, "exponenti": 38, "export_graphviz": [13, 20, 32, 56], "expos": [29, 30], "exposur": 46, "express": [0, 8, 17, 18, 24, 30, 36, 37, 43, 47, 51], "extend": [47, 48, 54, 59], "extend_block": 50, "extens": [1, 12, 15, 19, 22, 27, 34, 39, 42, 44, 45, 47, 49, 57, 59], "extent": [44, 47], "extercond": [40, 42, 51], "exterior": 42, "exterior1st": [40, 42, 51], "exterior1st_asbshng": 40, "exterior1st_asphshn": 40, "exterior1st_brkcomm": 40, "exterior1st_brkfac": 40, "exterior1st_cblock": 40, "exterior1st_cemntbd": 40, "exterior1st_hdboard": 40, "exterior1st_imstucc": [40, 42], "exterior1st_metalsd": 40, "exterior1st_plywood": 40, "exterior1st_ston": 40, "exterior1st_stucco": 40, "exterior1st_vinylsd": 40, "exterior1st_wd": 40, "exterior1st_wdsh": 40, "exterior2nd": [40, 42, 51], "exterior2nd_asbshng": 40, "exterior2nd_asphshn": 40, "exterior2nd_brk": 40, "exterior2nd_brkfac": 40, "exterior2nd_cblock": 40, "exterior2nd_cmentbd": 40, "exterior2nd_hdboard": 40, "exterior2nd_imstucc": 40, "exterior2nd_metalsd": 40, "exterior2nd_oth": 40, "exterior2nd_plywood": [40, 51], "exterior2nd_ston": [40, 51], "exterior2nd_stucco": [40, 51], "exterior2nd_vinylsd": [40, 51], "exterior2nd_wd": [40, 51], "external_tool": 52, "exterqu": [40, 42, 51], "extra": [4, 44, 49, 52, 59], "extract": [27, 43, 44, 46, 47, 48, 53, 59], "extractor": 55, "extrapol": [49, 50], "extratreesclassifi": 41, "extrem": [6, 17, 30, 36, 39, 41, 42, 46, 50, 53], "ey": 53, "f": [8, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 27, 28, 31, 32, 33, 34, 35, 36, 39, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 57], "f1": [11, 40, 55], "f1_score": 39, "fa": [40, 42, 51], "fac": 53, "face": [12, 13, 15, 19, 27, 30, 31, 32, 34, 46, 48], "facebook": [46, 47, 59], "facial": [15, 30, 34], "facil": 59, "facilit": [8, 59], "fact": [12, 31, 38, 39, 41, 48, 49, 50, 51], "factor": [13, 20, 32, 38, 42, 43, 45, 46, 50], "fail": [1, 7, 8, 10, 14, 16, 17, 21, 23, 24, 33, 35, 36, 43, 45, 47, 50, 51], "failur": [7, 12, 19, 31, 50, 59], "fair": [6, 14, 16, 21, 23, 33, 35, 40, 42, 44, 52, 55, 59], "fairli": [14, 21, 33, 38, 39, 42, 52], "fake": [15, 22, 29, 30, 34], "fake_review": [29, 30], "fall": [15, 22, 34, 44, 47, 49], "fals": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 55], "famili": [12, 19, 30, 31, 38, 39, 40, 41, 42, 44, 52, 59], "familiar": [8, 10, 11, 13, 16, 20, 23, 32, 35, 51, 57, 59], "famou": [1, 9, 29, 30, 47, 48], "fanci": [4, 12, 19, 31, 38], "fancier": 43, "fantast": 30, "far": [13, 15, 16, 17, 18, 22, 23, 24, 32, 34, 35, 36, 37, 39, 42, 43, 44, 45, 47, 48, 49, 50, 54, 55, 57], "farm": 39, "farthest": [13, 20, 32], "fashion": [20, 30, 41, 47], "fast": [14, 15, 18, 21, 30, 33, 34, 37, 41, 42, 47, 50, 52, 59], "faster": [12, 19, 31, 38, 41, 43, 48], "fastest": 41, "fasttext": 47, "favorit": 30, "favour": 52, "favourit": 47, "fc": [18, 37], "fcluster": 45, "fear": 30, "feat": [28, 38, 49, 53], "feat1": 44, "feat2": 44, "feat_nam": [28, 49, 53], "feat_vec": [29, 30, 46], "featur": [1, 11, 14, 21, 26, 27, 29, 30, 33, 39, 41, 44, 45, 47, 50, 52, 54, 57, 58, 59], "feature_extract": [12, 17, 18, 19, 24, 28, 29, 30, 31, 36, 37, 38, 39, 47, 52, 53], "feature_import": 26, "feature_importances_": [26, 43], "feature_nam": [13, 14, 18, 20, 21, 26, 29, 30, 32, 33, 37, 41, 42, 43, 47], "feature_names_in_": 26, "feature_names_out": [17, 24, 36], "feature_select": 43, "feature_typ": 41, "features_lag": 49, "features_nonzero": 49, "features_poli": 49, "feb": [1, 16, 18], "februari": [26, 49], "feder": [39, 42, 47, 49], "feed": [27, 28, 30], "feedback": [20, 32, 55], "feel": [5, 6, 14, 21, 28, 30, 33, 44, 52, 55], "feli": [12, 19, 31, 48], "fell": [18, 37], "felt": 28, "femal": [39, 41, 42, 50], "female_cm": 39, "female_pr": 39, "fenc": [40, 42, 48, 51], "fernandez": 41, "fest": 30, "fetch_california_h": [18, 37], "few": [1, 8, 12, 18, 19, 28, 29, 30, 31, 37, 40, 41, 43, 46, 47, 48, 49, 50, 52, 56], "fewer": [10, 41, 43, 45], "feynman": 51, "fiber": 50, "fiction": 53, "field": [2, 4, 11, 12, 17, 19, 24, 31, 36, 47, 48, 49, 52], "fig": [14, 15, 18, 21, 22, 27, 33, 34, 37, 39, 43, 44, 45, 48, 57], "fight": 30, "figsiz": [13, 14, 15, 16, 18, 20, 21, 22, 23, 27, 28, 32, 33, 34, 35, 37, 39, 42, 43, 44, 45, 48, 49, 50, 51, 57], "figur": [4, 8, 10, 12, 13, 15, 19, 20, 22, 27, 31, 32, 34, 38, 40, 42, 43, 44, 45, 48, 49, 50, 51, 57], "file": [0, 1, 4, 5, 7, 8, 10, 12, 13, 17, 19, 24, 28, 32, 36, 39, 42, 48, 50, 52], "file_nam": 27, "filenam": 48, "fill": [15, 18, 22, 26, 27, 28, 34, 37, 38, 46, 52, 57, 59], "fill_diagon": [15, 22, 34], "fill_valu": [28, 39, 40, 41, 42, 49, 51], "film": [30, 47, 53], "filter": [4, 11, 12, 14, 19, 21, 31, 33, 44, 49, 55], "filterwarn": [15, 19, 21, 22, 34, 50], "final": [1, 6, 7, 12, 14, 16, 19, 21, 23, 26, 30, 33, 35, 41, 43, 51, 52, 56, 58], "final_estim": 41, "final_estimator_": 41, "finalis": [29, 30], "financ": [48, 49], "find": [1, 7, 8, 12, 13, 16, 19, 20, 23, 27, 28, 29, 30, 31, 32, 35, 38, 40, 41, 42, 44, 45, 46, 47, 51, 53, 54, 59], "fine": [7, 16, 17, 23, 24, 30, 35, 36, 39, 46, 48, 49, 52], "finish": [12, 19, 30, 31, 40], "fira": [0, 1], "firasm": 39, "firefox": [12, 19], "fireplac": [40, 42, 51], "fireplacequ": [40, 42, 51], "first": [1, 4, 8, 13, 15, 17, 18, 20, 22, 24, 28, 29, 30, 32, 34, 36, 37, 38, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 59], "first_dai": 49, "first_day_retail": 49, "first_pass_isfinit": 28, "firth": 47, "fish": [39, 42], "fist": 49, "fit": [0, 12, 14, 15, 17, 18, 19, 21, 22, 24, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 59], "fit_intercept": 39, "fit_method": 28, "fit_predict": 45, "fit_resampl": 39, "fit_tim": [14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 28, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 49, 50, 53], "fit_transform": [16, 17, 23, 24, 28, 29, 30, 35, 36, 39, 41, 42, 43, 45, 46, 47, 49, 55], "fittedcolumntransform": [17, 24, 36, 41], "fittedpipelin": [36, 38, 40], "fittedvotingclassifi": 41, "fitter": 50, "five": 38, "fix": [16, 17, 23, 24, 28, 35, 36, 41, 50, 52, 54, 57, 59], "flag": 50, "flagstaff": 53, "flaki": 39, "flashcard": 55, "flask": 52, "flat": 45, "flatten": [27, 29, 30, 41, 42, 45, 49], "flatten_train": 48, "flatten_transform": 48, "flatten_valid": 48, "flaw": [14, 16, 21, 23, 33, 35], "flawless": [18, 29, 30, 37], "flesh": 30, "flexibl": [7, 12, 31, 43, 48, 55, 59], "flibbertigibbet": 47, "flickr_cat_000002": 48, "flight": 43, "flip": [1, 14, 33, 39, 40, 52], "flip_i": 39, "float": [8, 28, 40, 43, 50, 53], "float32": [47, 48], "float64": [13, 15, 16, 17, 18, 22, 23, 24, 27, 28, 30, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 46, 49, 50], "floatlogslid": [15, 22, 34, 57], "floatslid": [15, 22, 27, 34, 39, 44, 45, 57], "floor": [12, 13, 19, 26, 31, 32, 59], "flower": [15, 22, 27, 34, 39, 52, 57], "fly": 30, "fmt": 38, "fn": 39, "fnlwgt": [39, 41, 42], "focu": [1, 11, 12, 16, 17, 18, 19, 23, 24, 28, 31, 35, 36, 37, 42, 45, 46, 47, 49, 55, 57, 58, 59], "focus": [12, 18, 30, 31, 37, 44, 47, 55], "fog": 30, "foggi": 30, "fold": [14, 16, 17, 21, 23, 24, 33, 35, 36, 38, 39, 40, 41, 52, 57], "folder": [5, 6, 23, 33, 35, 42, 52, 53], "folk": [50, 52, 59], "follow": [0, 5, 6, 7, 8, 10, 15, 16, 17, 18, 20, 22, 23, 24, 28, 29, 30, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59], "font": [12, 13, 14, 19, 20, 21, 31, 32, 33, 44, 45, 46, 49, 50, 51], "font_scal": 42, "fontsiz": [13, 14, 15, 20, 21, 22, 26, 27, 32, 33, 34, 39, 41, 42, 44, 48, 51, 56, 57], "food": [28, 44, 47, 48, 59], "food_typ": 28, "food_type_canadian": 28, "food_type_chines": 28, "food_type_fus": 28, "food_type_indian": 28, "food_type_italian": 28, "food_type_mexican": 28, "food_type_nan": 28, "food_type_oth": 28, "food_type_quebecoi": 28, "food_type_thai": 28, "foot": [40, 42], "footag": [18, 30, 37], "footstal": 48, "forc": [39, 42, 57], "force_all_finit": 28, "force_plot": 42, "force_writ": 28, "forecast": [11, 13, 20, 32, 50, 51, 55], "forest": [11, 39, 40, 48, 49, 50, 52, 55], "forev": 49, "forg": [10, 39, 40, 41, 42, 47, 50, 53], "forget": [13, 15, 16, 17, 20, 24, 32, 36, 41], "form": [1, 12, 17, 19, 22, 24, 36, 39, 43, 45, 46, 47, 50, 51, 52, 55], "formal": 59, "format": [0, 1, 13, 20, 26, 28, 32, 39, 45, 47, 49, 50], "former": 50, "formul": [4, 38], "formula": [18, 37, 40, 48, 54], "forum": [12, 19], "forward": [50, 52], "found": [1, 7, 14, 17, 21, 24, 25, 26, 28, 33, 36, 38, 40, 44, 46, 47, 53, 55, 59], "foundat": [1, 9, 11, 39, 40, 42, 51], "foundation_brktil": 40, "foundation_cblock": 40, "foundation_pconc": 40, "foundation_slab": 40, "foundation_ston": 40, "foundation_wood": 40, "fountain": 48, "four": [13, 14, 20, 32, 33, 43, 45, 52, 55], "fourth": 45, "foxhound": [12, 19, 31, 48], "foyer": 40, "fp": 39, "fpr": 39, "fpr_lr": 39, "fpr_svc": 39, "frac": [13, 18, 20, 32, 37, 39, 40, 44, 47, 48], "fractal": 43, "fraction": [17, 24, 36, 39, 46], "fragasso": 30, "fragment": 57, "frame": [16, 17, 23, 24, 35, 36, 39, 40, 43, 49, 50, 51, 52], "framework": [32, 38], "franco": 30, "frank": 30, "fraud": [13, 20, 32, 39, 40, 44, 49], "fraudul": [13, 20, 32, 39, 51], "frederick": [1, 59], "free": [0, 5, 17, 24, 36, 40, 47, 50, 52], "freedom": [0, 53], "french": [16, 23, 35, 47], "freq": 49, "frequenc": [17, 24, 36, 47, 49, 50, 55], "frequent": [13, 16, 20, 23, 32, 35, 46, 47, 50], "fresh": [30, 46, 47], "fri": [12, 49], "fridai": [14, 19, 59], "fridg": 30, "friend": [13, 14, 20, 30, 32, 33, 39, 42, 45, 46, 52, 55, 59], "from": [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 56, 57, 58, 59], "from_block": 50, "from_estim": 39, "front": 59, "fruit": 47, "frustrat": [4, 6, 38], "fulci": 30, "full": [26, 38, 41, 48, 49, 50, 59], "full_pip": 28, "fullbath": [40, 42, 51], "fulli": 45, "fun": [30, 39, 47, 48], "func": [8, 17, 18, 24, 36, 37, 40, 51], "function": [2, 12, 13, 14, 15, 17, 19, 20, 21, 22, 24, 27, 31, 32, 33, 34, 36, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 57], "functiontransform": [17, 24, 28, 36, 50], "fund": 53, "fundament": [1, 2, 9, 11, 16, 18, 23, 35, 37, 38, 40, 43, 48, 50, 59], "funni": [12, 30, 31, 41, 53], "furnish": 0, "furnitur": 55, "further": [26, 39, 41, 43, 44, 47, 48, 50, 52, 57, 59], "furthermor": 51, "fusion": 28, "futur": [11, 14, 19, 21, 23, 33, 35, 38, 40, 50, 53, 55], "futurewarn": [23, 33, 35, 40, 42, 53, 54], "fuyi": [12, 13, 14, 16, 17, 18, 59], "fyi": 50, "g": [6, 7, 8, 11, 12, 13, 16, 17, 18, 19, 20, 23, 24, 26, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55], "g26r0dcx4b35vf3nk31216hc0000gr": [35, 42, 53], "gain": [6, 11, 13, 20, 32, 39, 41, 42], "game": [13, 20, 32, 42, 47], "gamma": [18, 27, 37, 38, 41, 51, 57], "gamma_log": [15, 22, 27, 34, 57], "gamma_widget": [15, 22, 27, 34, 57], "gap": [14, 21, 26, 33, 49, 50, 51, 55, 57], "garagearea": [40, 42, 51], "garagecar": [40, 42, 51], "garagecond": [40, 42, 51], "garagefinish": [40, 42, 51], "garagefinish_fin": 40, "garagefinish_miss": 40, "garagefinish_rfn": 40, "garagefinish_unf": 40, "garagequ": [40, 42, 51], "garagetyp": [40, 42, 51], "garagetype_2typ": 40, "garagetype_attchd": 40, "garagetype_bas": 40, "garagetype_builtin": 40, "garagetype_carport": 40, "garagetype_detchd": 40, "garagetype_miss": 40, "garageyrblt": [40, 42, 51], "garlic": 44, "gaudenzi": 30, "gaurav": [1, 59], "gauss": 47, "gaussian": 45, "gaussianmixtur": 45, "gave": [28, 30, 46, 49], "gbr": 8, "gca": [44, 45, 50], "gd": [12, 19, 31, 40, 42, 51], "gdprv": [40, 42, 51], "gdwo": [40, 42, 51], "gelbart": [0, 1, 20, 32, 47], "gender": [12, 17, 19, 31, 36, 39, 47, 49, 50], "gender_femal": 50, "gender_mal": 50, "gener": [7, 9, 12, 13, 16, 17, 20, 23, 24, 26, 28, 30, 32, 35, 36, 38, 39, 40, 42, 45, 47, 48, 49, 50, 51, 52, 54, 55, 57, 59], "genet": 43, "genom": 43, "genr": 46, "gensim": 47, "gentl": 11, "geog": [1, 59], "geograph": [18, 37, 52], "geometr": [13, 32], "georg": 47, "geq": [18, 37], "ger": 8, "german": 47, "get": [1, 4, 5, 6, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59], "get_avg_word_length": 53, "get_cmap": [16, 23, 35], "get_depth": [26, 57], "get_dummi": [16, 23, 35], "get_featur": [27, 48], "get_feature_names_out": [16, 17, 23, 24, 28, 29, 30, 35, 36, 39, 40, 41, 42, 43, 47, 49, 50, 51, 53], "get_length_in_word": 53, "get_lr_data_per_us": 46, "get_param": 27, "get_permutation_import": 42, "get_relative_length": 53, "get_season": 49, "get_senti": 53, "get_stat": 46, "get_tag": 28, "get_user_profil": 46, "getattr": 50, "ghassemi": [1, 59], "gif": [44, 45], "gift": 53, "gigaword": 47, "gini": [13, 20, 32, 42, 51], "git": [3, 8, 12, 19], "github": [0, 1, 7, 9, 10, 12, 16, 17, 19, 23, 24, 25, 26, 27, 28, 30, 31, 35, 36, 38, 39, 40, 41, 42, 43, 48, 51, 52, 53], "githubusercont": 8, "gitlf": 39, "giulia": [0, 1, 59], "give": [0, 12, 13, 14, 17, 18, 19, 20, 21, 23, 24, 26, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 56, 57], "given": [0, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57], "gladwel": 44, "glass": 51, "glob": [12, 19, 27, 31, 48], "global": [16, 23, 35, 39, 41, 44, 47, 55], "global_skip_valid": 28, "glove": [11, 47], "glq": [40, 42, 51], "gmail": [12, 19, 31, 44], "go": [1, 5, 7, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57], "goal": [2, 11, 15, 16, 22, 23, 34, 35, 38, 39, 44, 45, 46, 47, 52, 53], "goe": [2, 12, 14, 15, 17, 19, 21, 22, 24, 30, 33, 34, 36, 39, 41, 42, 45, 46, 48, 51, 52], "gold": 8, "goldcoast": 49, "golden": [15, 26, 29, 30, 34, 52, 55, 57], "good": [9, 10, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 26, 28, 30, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58], "good_serv": 28, "goodarzvand": [1, 59], "googl": [1, 4, 12, 13, 19, 20, 31, 32, 41, 42, 43, 44, 47, 51, 53], "google_news_vector": 47, "gore": 30, "gorgeou": 30, "gori": 30, "got": [15, 18, 22, 29, 30, 34, 37, 38, 39, 40, 48], "gotten": 50, "gov": [39, 41, 42], "govern": [47, 59], "gpe": 47, "gpt": [46, 47], "gpu": [41, 47, 48], "grad": [39, 41, 42], "grade": [1, 3, 7, 12, 14, 16, 17, 21, 24, 26, 30, 31, 33, 36, 38, 51, 55, 57, 58], "grader": 6, "grades_df": 55, "gradescop": [1, 6, 12, 13, 19, 59], "gradient": [52, 55], "gradientboostingclassifi": 41, "gradientboostingregressor": [41, 51], "gradientexplain": 42, "grading_concern": 6, "graduat": 48, "grai": 48, "grain": [18, 37, 42], "gram": 47, "grammat": 47, "grandma": 43, "grandmoth": [39, 52], "grant": 0, "grant_macewan": 47, "granular": 45, "graph": [1, 27, 48, 49], "graphic": 48, "graphic_design": 47, "graphviz": [13, 20, 32, 56], "grasp": [11, 55], "grass": 30, "grave": 30, "grayscal": 48, "great": [12, 15, 17, 18, 19, 21, 22, 24, 28, 30, 31, 32, 34, 36, 37, 42, 43, 47, 48, 49, 51, 53], "greater": [10, 43, 44], "greater_is_bett": 40, "greedili": 45, "green": [15, 22, 30, 34, 38, 44, 51, 54], "grei": 59, "grid": [18, 37, 40, 49, 50, 55], "grid_result": 51, "grid_search": [38, 51], "gridsearchcv": [15, 22, 34, 41, 42], "gridsearchcvifittedgridsearchcv": 38, "grinberg": 52, "grip": 47, "grlivarea": [40, 42, 51], "groak": 47, "groceri": [48, 53], "groin": 48, "ground": [14, 21, 30, 33, 43, 45, 46, 59], "ground_truth_categori": [39, 52], "group": [7, 11, 13, 15, 16, 17, 18, 20, 22, 27, 30, 32, 34, 36, 37, 41, 43, 55, 57, 58], "groupbi": 49, "grow": [38, 41, 43], "grow_polici": 41, "growth": [49, 50], "groyn": 48, "grv": 40, "gsc": 51, "gt": [17, 18, 24, 30, 36, 37, 38, 39, 40, 41], "gtl": 42, "gtoti": [20, 24], "guarante": [38, 39, 41, 44, 48], "guenon": 48, "guess": [15, 16, 22, 23, 34, 35, 47, 53], "gui": 30, "guid": [1, 7, 9, 12, 19, 43, 48, 52, 59], "guidanc": 42, "guidelin": [16, 42, 43, 52], "guido": 1, "gun": 30, "h": [26, 39, 41, 42, 44, 47, 48, 50, 52, 53], "ha": [1, 2, 5, 6, 13, 14, 16, 17, 18, 20, 21, 23, 24, 29, 30, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 57, 59], "hab": 47, "habit": [17, 24, 36, 51, 52], "hacki": [48, 54], "had": [12, 16, 17, 18, 19, 23, 24, 30, 31, 35, 36, 37, 39, 46, 47, 48, 49, 50, 52], "hadn": [47, 50], "haidilao": 28, "hal": 1, "half": [1, 6, 12, 13, 18, 19, 20, 30, 32, 37, 43, 45], "halfbath": [40, 42, 51], "halvingrandomsearchcv": 38, "halvingrandomsearchcvifittedhalvingrandomsearchcv": 38, "ham": [12, 19, 31], "hand": [4, 9, 11, 28, 30, 39, 46, 59], "handi": 39, "handl": [11, 26, 28, 30, 41, 42, 45, 50, 52, 54, 55, 57], "handle_unknow": [17, 24, 36], "handle_unknown": [16, 17, 23, 24, 28, 35, 36, 38, 39, 40, 41, 42, 49, 50, 51, 55], "handler": [39, 42], "handrail": 48, "handwritten": [39, 51], "hang": 39, "happen": [4, 6, 12, 15, 17, 22, 24, 28, 30, 31, 34, 36, 38, 41, 42, 43, 46, 49, 50, 51, 55, 59], "happi": [26, 28, 39, 44, 50], "happier": [52, 59], "happydb": [39, 52], "hard": [8, 12, 14, 15, 16, 18, 19, 21, 22, 23, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 51, 52, 53, 55], "hardi": [1, 59], "hardli": 46, "hardwar": 48, "harmon": 39, "harri": [1, 47, 59], "has_emoji": 53, "has_nan_error": 28, "hasn": [4, 46, 47, 50], "hassl": [8, 42, 49], "hat": [18, 37, 40, 41], "have": [0, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 59], "haven": [14, 21, 28, 33, 47, 50, 51, 52, 55], "haylei": [20, 32], "hazard": 11, "hc_truncation_toy_demo": 45, "hdbscan": 45, "he": [14, 17, 21, 24, 30, 33, 36, 47], "head": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51, 52, 53, 55, 58], "header": 52, "headlin": [47, 51], "health": 47, "healthcar": 42, "healthi": [47, 51], "heard": [14, 21, 33], "heart": [13, 20, 30, 32, 53], "hearti": 28, "heat": [38, 40, 42, 51], "heating_floor": 40, "heating_gasa": 40, "heating_gasw": 40, "heating_grav": 40, "heating_othw": [40, 42], "heating_wal": 40, "heatingqc": [40, 42, 51], "heatmap": 42, "heavi": [41, 53], "heavili": [30, 46, 48, 49], "heeren": 47, "hei": [29, 30], "height": [13, 14, 20, 21, 27, 32, 33, 39, 47, 53, 56], "helicopt": 30, "hell": 53, "help": [3, 7, 10, 12, 14, 16, 19, 21, 23, 28, 30, 31, 33, 35, 36, 38, 39, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 58, 59], "henc": [5, 39, 40, 42, 44], "her": [12, 19, 30, 31, 46, 47], "here": [1, 4, 5, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59], "herebi": 0, "herself": [47, 53], "herta": [15, 34], "hesist": 51, "hesit": 51, "heurist": [13, 20, 32, 38], "hi": [30, 47, 57], "hidden": [43, 47, 48, 51], "hide": [8, 30, 48], "hier_label": 45, "hier_labels1": 45, "hier_labels2": 45, "hierarch": [11, 55], "hierarchi": [13, 20, 32, 45], "high": [6, 11, 14, 15, 18, 20, 21, 22, 28, 33, 34, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52], "high_corr": 42, "higher": [13, 14, 15, 18, 20, 21, 22, 32, 33, 34, 37, 39, 40, 41, 42, 43, 44, 46, 50, 51, 52, 57], "highest": [29, 30, 41, 42, 46, 47, 48, 51, 54, 57], "highland": 53, "highli": [1, 10, 16, 23, 29, 30, 35, 42, 46], "highlight": [4, 48, 51, 55], "highwai": [18, 37], "him": [30, 47], "himself": [30, 47], "hinder": 59, "hindi": [16, 23, 35], "hint": [42, 57], "hist": [16, 23, 28, 35, 38, 40, 43, 50], "histgradientboostingclassifi": [28, 41], "histgradientboostingregressor": 41, "histogram": 50, "histor": 55, "histori": [18, 37, 46, 49, 59], "hit": [12, 19, 31, 38], "hitter": 53, "hl": [40, 42, 51], "hmid": [39, 52], "hmmm": 50, "hockei": 47, "hold": [28, 30, 51, 52], "holder": 0, "holdout": 39, "holi": 51, "holidai": [46, 59], "home": [13, 18, 20, 27, 28, 32, 37, 39, 48, 52], "homemak": 47, "homepag": 1, "homework": [1, 3, 4, 6, 8, 10, 15, 34, 37, 38, 47, 52, 55, 59], "honest": 51, "honour": 59, "hood": [14, 21, 28, 33, 52], "hook": 30, "hope": [14, 21, 30, 33, 51, 52], "hopefulli": 52, "hopeless": 43, "hopelessli": [15, 22, 34], "horizont": [13, 17, 20, 24, 28, 32, 36], "horror": 30, "host": [5, 50, 52], "hot": [14, 17, 21, 24, 28, 30, 33, 36, 42, 55], "hound": [12, 19, 31, 48], "hour": [1, 4, 10, 12, 30, 39, 41, 42, 43, 46, 49, 52, 55, 59], "hourli": [50, 55], "hous": [20, 26, 40, 42, 43, 50, 51, 57], "houseag": [18, 37], "household": [16, 18, 23, 35, 36, 37, 43, 58], "housestyl": [40, 42, 51], "housestyle_1": 40, "housestyle_1stori": 40, "housestyle_2": 40, "housestyle_2stori": 40, "housestyle_sfoy": 40, "housestyle_slvl": 40, "housewif": 47, "housing_df": [13, 16, 23, 26, 32, 35, 36, 43, 57, 58], "housing_median_ag": [16, 23, 35, 36, 43, 58], "houston": 53, "how": [0, 3, 8, 10, 11, 12, 17, 19, 24, 26, 27, 30, 31, 36, 38, 39, 40, 44, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 59], "howard": 44, "howev": [2, 8, 16, 17, 23, 24, 27, 30, 35, 36, 39, 40, 42, 44, 46, 49, 50, 52, 54, 57], "hsjcy": 50, "hstack": 49, "html": [7, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 48, 50, 51, 52, 53, 56, 58], "htrz": 59, "http": [0, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 48, 49, 50, 51, 52, 53, 59], "hug": 46, "huge": [17, 24, 36, 40, 47, 48, 49, 50], "human": [0, 12, 15, 16, 17, 18, 19, 23, 24, 30, 31, 34, 35, 36, 37, 38, 39, 42, 43, 44, 47, 48], "humidity3pm": 49, "humidity3pm_lag1": 49, "humidity9am": 49, "hummu": [44, 47], "humour": [1, 47], "hundr": [18, 37], "hungri": 28, "hurrican": [12, 31], "husband": [39, 41, 42], "hussar": [12, 19, 31, 48], "hw": [12, 16, 31], "hw1": [1, 4, 13, 14, 16, 17, 56], "hw2": [1, 14, 15, 16, 23, 34, 35], "hw3": [1, 16, 17, 18], "hw4": 1, "hw5": 1, "hw6": 1, "hw6a": 7, "hw6b": 7, "hw7": 1, "hw8": 1, "hw9": 1, "hybrid": 46, "hyper": 51, "hyperband": 38, "hyperopt": 38, "hyperparamet": [1, 14, 21, 27, 29, 30, 33, 39, 45, 46, 47, 48, 51, 52], "hyperparameter_": 51, "hyperparamt": [14, 21, 33, 38, 50], "hyperparlan": [18, 37], "hyperplan": [18, 37], "hypothesi": [47, 50, 52], "hypothet": [18, 37, 44], "i": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 18, 20, 22, 26, 27, 28, 29, 30, 32, 34, 37, 40, 45, 48, 49, 50, 54, 55, 56, 57, 58, 59], "i1": 41, "i2": 41, "ia": 53, "ibm": 53, "ic": 47, "icc": [1, 59], "iclick": 1, "id": [12, 13, 19, 26, 31, 32, 40, 42, 46, 51, 57], "idea": [8, 13, 14, 16, 20, 21, 23, 26, 27, 28, 30, 32, 33, 35, 38, 42, 44, 45, 46, 47, 48, 49, 50, 52, 55, 57], "ideal": [4, 16, 28, 39, 41, 43, 46, 50, 52], "ident": [27, 47, 48], "identif": [12, 19, 31, 53], "identifi": [11, 13, 14, 15, 16, 20, 21, 23, 26, 29, 30, 32, 33, 34, 35, 38, 39, 40, 44, 45, 47, 48, 49, 51, 52, 55], "idf": [17, 24, 36], "idli": 47, "idx": [27, 48], "idxmax": [15, 22, 26, 29, 30, 34], "if_binari": [17, 24, 28, 36, 39, 41, 42, 55, 58], "ifram": [14, 21, 33, 39], "igloo": 47, "ignor": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 47, 49, 50, 51, 55], "ignore_index": 8, "ii": 39, "iii": 1, "ij": [18, 29, 30, 37, 46], "ik": 41, "ill": 59, "illus": 39, "illustr": [45, 49], "iloc": [8, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 29, 30, 32, 33, 34, 35, 36, 41, 42, 47, 49, 53, 56], "im": 53, "imag": [7, 11, 14, 21, 23, 30, 33, 39, 42, 43, 44, 45, 49, 51, 55], "image_dataset": [27, 48], "image_datasets_bw": 48, "image_fil": 27, "image_s": [27, 48], "imagefold": [27, 48], "imagenet": 54, "imagenet1k_v1": [27, 48], "imagenet_class": [12, 19, 31, 48], "imagin": [12, 13, 14, 16, 18, 19, 20, 21, 23, 31, 32, 33, 35, 37, 39, 42, 43, 44, 47, 50, 51, 52, 55, 56], "imaginari": [14, 21, 33, 47], "imbal": [44, 50], "imbalanc": [39, 40, 54], "imblearn": 39, "imdb": [29, 30], "imdb_df": [29, 30], "imdb_mast": [29, 30], "img": [12, 19, 27, 31, 48], "img_classifi": [12, 19, 31], "img_ind": 27, "img_path": [12, 19, 31], "img_t": 48, "immedi": [28, 42, 46, 59], "imp": [16, 23, 35, 36, 49], "impact": [7, 11, 17, 18, 24, 36, 37, 41, 42, 45, 49, 51, 57, 59], "implement": [2, 4, 12, 16, 19, 23, 31, 35, 39, 40, 41, 43, 45, 46, 47, 50, 51, 52, 54], "impli": [0, 50], "implic": [11, 16, 23, 35, 52, 55], "implicit": 47, "import": [8, 11, 54, 58, 59], "importance_typ": 41, "importances_mean": 42, "impos": [16, 23, 35], "imposs": 44, "impress": 42, "improv": [11, 26, 28, 38, 39, 40, 41, 43, 44, 45, 46, 49, 50, 51, 52, 55, 59], "impur": [13, 20, 26, 32, 41], "imput": [14, 17, 18, 21, 24, 28, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 49, 50, 51, 52, 55, 58], "imread": 48, "imshow": [12, 19, 27, 31, 48], "inabl": 19, "inbox": [14, 21, 33], "inc": [42, 47], "incept": [46, 48], "inception": 48, "incl": 40, "includ": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 19, 20, 23, 24, 27, 32, 35, 36, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 57, 58, 59], "include_bia": [43, 49], "incom": [14, 18, 21, 33, 37, 39, 41, 42], "incomplet": 50, "inconsist": [17, 24, 36], "incorpor": [38, 40, 43, 50, 52, 55], "incorrect": [50, 51], "incorrectli": [12, 19, 31, 39], "increament": 52, "increas": [8, 14, 15, 17, 18, 21, 22, 24, 26, 29, 30, 33, 34, 36, 37, 41, 42, 43, 44, 45, 48, 57], "increasingli": [12, 19, 31], "incred": 48, "incredibli": 30, "increment": 52, "inde": 42, "independ": [8, 9, 13, 19, 20, 32, 38, 40, 41, 43, 49, 59], "index": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51, 53, 57], "index_col": [8, 15, 16, 23, 34, 35, 38, 39, 46, 52], "india": 47, "indian": [28, 39], "indian_liver_pati": [12, 19, 31], "indic": [0, 17, 24, 28, 29, 30, 36, 44, 46, 47, 48, 49, 50], "indirectli": 51, "individu": [28, 41, 42, 44, 46, 47, 50, 52, 59], "industri": [41, 43, 47, 48], "inept": 30, "ineptli": 30, "inequ": 39, "inertia_": 44, "inertia_valu": 44, "inf": [15, 22, 34, 50], "infeas": 38, "infer": [13, 32, 47, 48, 49, 52, 56], "infin": [15, 22, 34, 51], "infinit": 38, "inflamm": 9, "inflat": 42, "inflect": [44, 47], "influenc": [13, 14, 20, 21, 32, 33, 38, 42, 44, 46, 50, 57], "info": [1, 3, 8, 16, 17, 23, 24, 35, 36, 39, 40, 43, 47, 49, 50, 57], "infom": 47, "infor_m": 47, "inform": [1, 4, 7, 10, 12, 13, 16, 17, 18, 20, 23, 24, 27, 32, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 57, 59], "informa_t": 47, "informaion": 47, "informaiton": 47, "informationabout": 47, "informationon": 47, "ingrid": 30, "inhabit": 59, "inher": [20, 39, 49, 50], "initi": [27, 45, 48], "initj": 42, "inject": [43, 46, 55], "ink": 51, "inland": [16, 23, 35, 36, 43, 58], "inlin": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 56, 57], "inner": [17, 24, 36, 38, 47], "inplac": [8, 12, 13, 19, 31, 32, 38], "input": [8, 13, 16, 18, 20, 23, 27, 28, 32, 35, 37, 41, 42, 45, 47, 48, 49, 52, 53, 55], "input_img": 48, "input_nam": 28, "input_tag": 28, "inputs_bw": 48, "insid": [9, 17, 24, 30, 36, 39], "insight": [2, 11, 15, 22, 34, 39, 42, 44], "inspct": 39, "inspect": [42, 45], "inspir": [13, 32, 39, 41], "instal": [12, 15, 19, 27, 28, 31, 34, 39, 40, 41, 42, 44, 47, 48, 50, 52, 53], "instanc": [12, 13, 14, 17, 18, 19, 20, 21, 24, 27, 28, 31, 32, 33, 36, 37, 39, 44, 45, 46, 47, 48, 49, 54], "instanti": [26, 38, 57], "instead": [5, 8, 10, 13, 14, 16, 17, 18, 20, 23, 24, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 54, 57], "institut": [47, 53], "instruct": [3, 4, 5, 10, 12, 15, 16, 19, 34, 51, 52, 59], "instructor": [4, 6, 12, 19, 31, 51, 52, 59], "instrument": [15, 16, 23, 34, 35, 38], "int": [16, 17, 23, 24, 35, 36, 39, 41, 42, 47, 49, 53], "int32": [15, 22, 34, 44, 45, 49], "int64": [13, 15, 16, 17, 20, 24, 26, 28, 30, 32, 34, 36, 39, 40, 46, 47, 49, 50, 52, 53], "integ": [8, 16, 23, 33, 35, 38, 41, 42, 49, 53], "integr": [11, 52], "intellig": [1, 47], "intelligen": 47, "intend": [0, 51, 59], "intens": [30, 47], "inter": 53, "interact": [9, 12, 15, 19, 22, 27, 34, 38, 39, 42, 44, 45, 46, 49, 52, 53, 57], "interaction_constraint": 41, "interaction_onli": [43, 49], "interactive_plot": [15, 22, 27, 34, 57], "intercept": [42, 48, 54], "intercept_": [18, 37, 41, 48, 54], "intercept_sc": 39, "interest": [2, 12, 14, 19, 21, 28, 31, 33, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57], "interfac": [41, 52], "intermedi": [45, 48], "intern": [0, 1, 13, 20, 32, 48, 49, 50], "internet": [50, 51, 52], "internetservic": 50, "internetservice_dsl": 50, "internetservice_fib": 50, "internetservice_no": 50, "internship": [12, 19, 31], "interpret": [1, 10, 11, 15, 16, 22, 23, 26, 34, 35, 39, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51], "interv": [11, 49, 50, 55], "interweb": 52, "intestin": 30, "intrins": 49, "intro": [1, 47, 48], "introduc": [17, 24, 36, 39, 50], "introduct": [1, 9, 10, 11, 26, 49, 50, 57], "intslid": [15, 22, 27, 34, 57], "intuit": [11, 15, 16, 17, 22, 23, 24, 34, 35, 36, 38, 40, 42, 44, 45, 50, 53], "invalid": 38, "inventori": 55, "invers": [18, 37, 40], "inverse_func": [40, 51], "investig": [15, 22, 27, 34, 42, 57], "involv": [2, 4, 38, 40, 41, 45, 47, 48], "io": [9, 16, 23, 25, 35, 48, 50, 53], "ipykernel_13054": 53, "ipykernel_19402": 42, "ipykernel_22611": 28, "ipykernel_32469": 35, "ipykernel_70329": 23, "ipykernel_79734": 33, "ipynb": [7, 8, 12, 19], "ipython": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 39, 47, 56, 58], "ipywidget": [15, 22, 34, 57], "ir1": [40, 42, 51], "ir2": [40, 42, 51], "iri": [15, 22, 27, 34, 57], "iris_df": [15, 22, 27, 34, 57], "irregular": 11, "irregularli": 55, "irrelev": [15, 22, 34, 43, 47], "irrelevant_po": 47, "irrespect": [14, 18, 21, 33, 37, 59], "is_avail": [27, 48], "is_classifi": 28, "is_leap_year": 49, "is_stop": 47, "is_year_end": 49, "isinst": [28, 50], "island": [16, 23, 35, 36], "isn": [14, 15, 22, 30, 33, 34, 39, 40, 41, 47, 51], "isnul": [16, 23, 28, 35], "iso": [29, 30], "isol": [10, 39, 40, 42, 51], "issu": [4, 6, 7, 12, 19, 26, 41, 46, 50, 55, 59], "issubclass": 50, "isupp": 53, "itali": 47, "italian": [28, 30], "item": [12, 19, 27, 31, 41, 42, 44, 46, 47, 48, 50, 55], "item_inverse_mapp": 46, "item_kei": 46, "item_mapp": 46, "iter": [27, 38, 43, 44, 45, 48, 52], "iterable_with_config": [17, 24, 36], "iterrow": 46, "its": [8, 11, 12, 14, 15, 17, 18, 19, 22, 23, 24, 27, 28, 31, 33, 34, 36, 37, 39, 42, 44, 45, 47, 48, 49, 50, 53, 54, 57, 59], "itself": [7, 39, 41, 45, 47], "j": [8, 18, 37, 42, 43, 44, 46, 48], "jackin": 38, "jackpot": [17, 24, 36], "jaguar": [12, 19, 31, 48], "jake": 30, "jalebi": 47, "jam": 38, "jame": [47, 50, 53], "jan": [1, 12, 13, 16], "januari": [12, 19, 49], "japan": 47, "jargon": [13, 20, 32], "jason": [1, 43], "javascript": 42, "jazz_musician": 47, "jellyfish": 48, "jennif": 53, "jerri": 46, "jet": [16, 23, 35], "jetti": 48, "jieba": 47, "jim": 46, "jmlr": 38, "joan_baez": 47, "joanna": 30, "job": [17, 24, 30, 36, 49, 50], "joblib": [17, 24, 36, 52], "joei": 28, "john": [30, 41], "johnny_cash": 47, "join": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 59], "jointli": 49, "joke": [12, 19, 31, 46], "jolen": 53, "jon": 30, "joni_mitchel": 47, "joss": 30, "journal": 47, "journei": [1, 45, 59], "jpg": [27, 48], "json": 52, "ju": [12, 19, 31], "jubatu": [12, 19, 31, 48], "judg": 43, "judgment": 51, "juic": 47, "juli": 49, "jump": 30, "june": 49, "jupyt": [1, 7, 8, 9, 10, 16, 17, 23, 24, 26, 27, 28, 30, 31, 35, 36, 38, 39, 40, 41, 42, 43, 48, 51, 52, 53], "jupyter_notebook": 50, "jupyterlab": 42, "jurafski": 47, "jurisdict": 47, "just": [4, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 55, 57, 59], "justic": [42, 47], "k": [1, 7, 11, 14, 18, 21, 27, 28, 29, 30, 33, 37, 39, 40, 41, 43, 47, 48, 50, 52, 53, 54, 57], "k_neighbor": 39, "k_valu": [15, 22, 34], "kaggl": [13, 16, 23, 27, 32, 35, 39, 40, 41, 42, 43, 48, 51], "kaggler": 43, "kangaroo": 48, "kaplan": 11, "kaplanmeierfitt": 50, "kazmi": [1, 59], "kb": [17, 24, 36, 40, 50], "kbinsdiscret": 43, "kbinsdiscretizer__latitude_0": 43, "kbinsdiscretizer__latitude_1": 43, "kbinsdiscretizer__latitude_2": 43, "kbinsdiscretizer__latitude_3": 43, "kbinsdiscretizer__latitude_4": 43, "kbinsdiscretizer__latitude_5": 43, "kbinsdiscretizer__latitude_6": 43, "kbinsdiscretizer__latitude_7": 43, "kbinsdiscretizer__latitude_8": 43, "kbinsdiscretizer__latitude_9": 43, "kbinsdiscretizer__longitude_11": 43, "kbinsdiscretizer__longitude_12": 43, "kbinsdiscretizer__longitude_13": 43, "kbinsdiscretizer__longitude_14": 43, "kbinsdiscretizer__longitude_15": 43, "kbinsdiscretizer__longitude_16": 43, "kbinsdiscretizer__longitude_17": 43, "kbinsdiscretizer__longitude_18": 43, "kbinsdiscretizer__longitude_19": 43, "kbinsdiscretizerkbinsdiscret": 43, "kc_house_data": [12, 13, 19, 26, 31, 32, 57], "kdtree": 28, "keep": [1, 14, 15, 16, 17, 21, 22, 23, 24, 26, 30, 33, 34, 35, 36, 39, 41, 42, 43, 44, 46, 47, 50, 52, 57, 58, 59], "keep_empty_featur": 46, "kei": [9, 11, 13, 15, 16, 20, 22, 23, 32, 33, 34, 35, 38, 39, 40, 41, 46, 47, 50, 53], "kelbowvisu": 44, "kellei": [18, 37], "ken": 30, "kenni": 30, "kept": [14, 21, 33], "kera": 42, "kernel": [1, 7, 16, 18, 23, 27, 35, 37, 38, 42, 43, 51, 57], "kernelexplain": 42, "keyword": [4, 38, 53], "kfold": 39, "kick": 47, "kiddi": [29, 30], "kilian": 42, "kill": [30, 50], "killer": 30, "kimia": [1, 59], "kind": [0, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 31, 32, 33, 35, 36, 37, 39, 40, 42, 44, 45, 46, 48, 49, 50, 52, 54], "king": [26, 46, 47, 57], "kitchenabvgr": [40, 42, 51], "kitchenqu": [40, 42, 51], "kiwi": 47, "kk": 44, "km": [50, 51, 55], "km_label": 44, "kmean": [44, 45, 55], "kmf": 50, "kmqfw": 50, "kneighbor": 27, "kneighborregressor": [16, 23, 35], "kneighborsclassifi": [16, 17, 18, 23, 24, 28, 35, 36, 37, 43, 57, 58], "kneighborsclassifierifittedkneighborsclassifi": 28, "kneighborsregressor": [16, 17, 18, 23, 24, 35, 36, 37, 58], "kneighborsregressorkneighborsregressor": [16, 23, 35, 36], "knew": 44, "knn": [2, 14, 15, 16, 18, 21, 22, 23, 33, 34, 35, 36, 37, 42, 43, 46, 48, 52, 54, 55], "knn1": [15, 22, 34], "knn100": [15, 22, 34], "knn_pipe": 36, "knn_scale": [16, 23, 35], "knn_unscal": [16, 23, 35], "knn_valid_accuraci": [15, 22, 34], "knnimput": 46, "knob": [13, 20, 32, 51], "know": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59], "knowledg": [8, 12, 13, 17, 19, 20, 24, 32, 36, 38, 43, 44, 47, 51, 55], "knowleg": 55, "known": [27, 46, 47, 50], "koala": 48, "kolhatkar": [0, 1, 20, 47], "kr9rkqfj4w78h49djkz8yy9r0000gp": 33, "ksatr": 50, "kvarada": [10, 32, 33, 36, 38, 42, 47, 48, 50, 53, 54], "kvarada01": 10, "kwantlen": 47, "kwarg": [14, 16, 17, 21, 23, 24, 28, 33, 35, 36, 50, 53], "l": 10, "l1": 50, "l123": 4, "l17": 4, "l1_ratio": 39, "l2": [39, 47, 50], "l9": 4, "la": 51, "lab": [10, 12, 13, 14, 19, 21, 32, 33, 44, 46], "lab1": [13, 14, 17, 20, 21, 24, 32, 33, 36, 55], "lab2": [13, 14, 17, 20, 21, 24, 32, 33, 36, 55], "lab3": [13, 14, 17, 20, 21, 24, 32, 33, 36, 55], "lab4": [13, 14, 17, 20, 21, 24, 32, 33, 36, 55], "label": [7, 8, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 26, 27, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 53, 58], "label_": [47, 53], "label_encod": [41, 42], "label_n_clust": 45, "labelencod": [41, 42], "labels": [39, 44], "labels_": [44, 45], "lack": [14, 21, 30, 33, 46, 51], "lag": [50, 55], "lag_df": 49, "lakehead_univers": 47, "lakeshor": 48, "lakesid": 48, "lamb": 28, "lambda": [8, 13, 18, 20, 28, 32, 37, 45, 48, 49, 50, 53], "land": 50, "landcontour": [40, 42, 51], "landcontour_bnk": 40, "landcontour_hl": 40, "landcontour_low": 40, "landcontour_lvl": 40, "landmark": 55, "landown": 53, "landscap": [44, 47], "landslop": [40, 42, 51], "landslope_gtl": [40, 42], "landslope_mod": [40, 42], "landslope_sev": [40, 42], "langara_colleg": 47, "languag": [2, 9, 16, 17, 23, 24, 30, 35, 36, 46, 48, 52, 53], "language_enc": [16, 23, 35], "language_english": [16, 23, 35], "language_french": [16, 23, 35], "language_hindi": [16, 23, 35], "language_mandarin": [16, 23, 35], "language_spanish": [16, 23, 35], "language_vietnames": [16, 23, 35], "laptop": [12, 19, 31, 52], "lar": [12, 19, 31], "larg": [12, 14, 15, 16, 18, 19, 21, 22, 23, 26, 29, 30, 31, 33, 34, 35, 37, 39, 40, 44, 45, 47, 48, 52, 55, 57], "larger": [13, 14, 15, 16, 18, 21, 22, 23, 32, 33, 34, 35, 37, 38, 40, 41, 42, 44, 45, 50], "largest": 40, "larvatu": [12, 19, 31, 48], "last": [8, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 27, 28, 30, 32, 33, 34, 35, 36, 39, 42, 46, 48, 49, 50, 51, 52, 57, 59], "last_row": 8, "lastp": 45, "lat": [12, 13, 19, 26, 31, 32], "late": [19, 30, 39, 59], "latent": [46, 47, 48], "latentdirichletalloc": 47, "later": [10, 13, 17, 20, 24, 32, 36, 39, 48, 49, 52, 57], "latest": [17, 24, 36, 42, 50], "latex": [4, 7, 12, 19], "latin": [12, 19, 31, 39], "latitud": [14, 15, 16, 18, 21, 22, 23, 33, 34, 35, 36, 37, 43, 58], "latitude_0": 43, "latitude_1": 43, "latitude_10": 43, "latitude_11": 43, "latitude_12": 43, "latitude_13": 43, "latitude_14": 43, "latitude_15": 43, "latitude_16": 43, "latitude_17": 43, "latitude_18": 43, "latitude_19": 43, "latitude_2": 43, "latitude_3": 43, "latitude_4": 43, "latitude_5": 43, "latitude_6": 43, "latitude_7": 43, "latitude_8": 43, "latitude_9": 43, "latter": 40, "laugh": 30, "launch": [12, 19], "lauvagrand": 53, "law": [28, 47], "lawsuit": 47, "layer": [27, 48], "layout": [15, 22, 27, 34, 57], "lazi": [15, 22, 34], "lbfg": 39, "lda": 48, "ldot": 38, "lead": [1, 8, 14, 18, 21, 33, 37, 40, 45, 46, 47, 50, 51], "leaf": [13, 20, 32, 45, 47], "leagu": 47, "leak": [16, 23, 35, 50, 55], "leakag": 55, "leaner": [14, 21, 33], "learn": [2, 9, 10, 28, 53, 54, 55, 56, 57, 58, 59], "learner": [14, 15, 21, 22, 33, 34, 41], "learning_method": 47, "learning_r": 41, "learnxinyminut": 9, "least": [1, 4, 14, 15, 21, 22, 29, 30, 33, 34, 39, 40, 42, 43, 44, 45, 51], "least_confident_i": [18, 37], "least_confident_x": [18, 37], "leav": [7, 13, 20, 32, 45, 48, 50, 51, 54], "lectur": [5, 7, 8, 10, 25, 55], "lecun": 42, "lecuy": 1, "lee": [30, 42], "left": [7, 12, 19, 31, 38, 39, 40, 44, 45, 47, 49, 50, 51, 59], "leg": 30, "legal": [0, 47], "legend": [7, 8, 15, 18, 22, 34, 37, 39, 40, 43, 44, 48, 49, 50, 51, 54], "legendari": 53, "legless": 30, "leisur": [39, 52], "lemma": 47, "lemma_": 47, "lemmat": 47, "lemon": 44, "len": [12, 14, 16, 21, 23, 27, 33, 35, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 51, 53], "length": [13, 14, 15, 18, 20, 21, 22, 26, 27, 32, 33, 34, 37, 40, 42, 44, 45, 47, 49, 50, 53, 57], "leo": 41, "leopard": [12, 19, 31, 48], "leq": [43, 44], "less": [1, 5, 6, 12, 15, 17, 18, 19, 22, 24, 31, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 50, 51, 55, 57], "lesson": [9, 16, 23, 35, 53], "lesssim": [14, 21, 33], "let": [12, 13, 14, 18, 19, 20, 21, 26, 27, 29, 30, 31, 32, 33, 37, 38, 41, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59], "letter": [18, 37, 53], "lev": 40, "level": [11, 15, 18, 22, 30, 34, 37, 39, 40, 41, 42, 43, 45, 47, 48, 49, 51, 52], "leverag": [42, 46], "lewi": 53, "lexic": 47, "lexicon": 53, "lgbm": [11, 41, 42, 55], "lgbmclassifi": [12, 19, 31, 41, 42], "lgbmclassifierifittedlgbmclassifi": [12, 19, 31, 42], "lgbmclassifierlgbmclassifi": 41, "lgbmregressor": [12, 19, 31, 41], "li": [1, 18, 37, 59], "lia": 30, "liabil": 0, "liabl": 0, "liao": [12, 19, 31], "lib": [17, 20, 24, 27, 28, 32, 33, 36, 38, 42, 50, 54], "librari": [4, 8, 10, 14, 21, 26, 28, 33, 39, 42, 43, 47, 48, 49, 51, 53, 57], "licensor": 0, "life": [13, 18, 28, 32, 37, 44, 46, 51, 52, 56, 59], "lifeless": 30, "lifelin": [11, 50], "lifetim": 50, "light": 30, "lighter": 38, "lightgbm": [12, 19, 31, 42, 52], "lightweight": 47, "likabl": 30, "like": [1, 2, 4, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59], "likelihood": 50, "likewis": 7, "lime": 42, "limit": [0, 12, 13, 14, 17, 19, 21, 24, 31, 32, 33, 36, 41, 42, 51, 52, 53, 55, 56, 59], "linalg": 47, "line": [4, 8, 10, 12, 13, 17, 18, 19, 20, 24, 28, 30, 32, 36, 37, 38, 39, 40, 44, 47, 48, 49, 50, 51, 57], "line2d": 8, "linear": [1, 38, 39, 41, 43, 45, 46, 48, 49, 50, 51, 52, 54, 55], "linear_model": [12, 18, 19, 29, 30, 31, 37, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 54], "linear_svc": [18, 37], "linearli": [18, 37, 43, 49], "linearregress": [18, 37, 40, 43, 50], "linestyl": [44, 49], "linewidth": [49, 51], "linger": [15, 34], "lingual": 47, "linguist": [17, 24, 36], "link": [0, 4, 5, 7, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 36, 37, 38, 39, 40, 41, 45, 50, 51, 52, 59], "linkag": 45, "linkage_arrai": 45, "linkage_typ": 45, "linkedin": 46, "linspac": [18, 37, 38, 40, 43, 51], "lion": 46, "list": [4, 7, 8, 10, 14, 15, 16, 17, 18, 21, 23, 24, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48, 50, 51, 59], "listedcolormap": [18, 37], "liter": 30, "literatur": 41, "littl": [8, 30, 39, 48, 51, 52], "live": [1, 10, 12, 15, 16, 17, 19, 23, 24, 34, 35, 36, 38, 44, 50, 51, 52], "liver": [13, 20, 32], "livestream": 59, "ll": [1, 6, 7, 10, 12, 13, 15, 16, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 54, 55, 57, 59], "llazx": 50, "lo": 53, "load": [8, 12, 15, 16, 17, 18, 19, 22, 23, 24, 26, 27, 28, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 51, 53, 57, 58], "load_breast_canc": 43, "load_citibik": 49, "load_digit": 51, "load_iri": [15, 22, 27, 34, 57], "loan": 39, "loc": [8, 15, 18, 22, 34, 37, 39, 42, 46, 49, 50, 51], "local": [5, 7, 10, 27, 28, 39, 41, 42, 43, 48, 53], "locat": [8, 17, 24, 27, 30, 36, 44, 46, 47, 49, 53, 59], "location_katherin": 49, "location_mountginini": 49, "location_townsvil": 49, "location_witchcliff": 49, "location_wollongong": 49, "lock": [14, 21, 33], "log": [12, 13, 15, 22, 27, 28, 34, 40, 41, 50, 51, 52, 57], "log10": 40, "log1p": [40, 51], "log2": 50, "log_likelihood_ratio_test": 50, "log_loss": 51, "logarithm": [15, 22, 27, 34, 57], "logic": 43, "logical_xor": 43, "login": 46, "logisit": 48, "logist": [29, 30, 41, 42, 49, 50, 51, 52, 53, 54, 55], "logisticregress": [12, 18, 19, 29, 30, 31, 37, 40, 41, 42, 43, 47, 48, 52, 53, 54], "logisticregressionifittedlogisticregress": 48, "logisticregressionlogisticregress": [30, 39, 41, 48, 53], "logloss": 42, "lognorm": 38, "logspac": [27, 38], "loguniform": 38, "lol": [17, 24, 36], "london": 53, "lone": 45, "long": [0, 12, 13, 18, 19, 20, 26, 31, 32, 37, 39, 41, 45, 46, 50, 52, 55, 59], "longer": [7, 38, 39, 48, 50, 51, 52], "longest": [13, 20, 32], "longitud": [14, 15, 16, 18, 21, 22, 23, 33, 34, 35, 36, 37, 43, 58], "longitude_0": 43, "longitude_1": 43, "longitude_10": 43, "longitude_11": 43, "longitude_12": 43, "longitude_13": 43, "longitude_14": 43, "longitude_15": 43, "longitude_16": 43, "longitude_17": 43, "longitude_18": 43, "longitude_19": 43, "longitude_2": 43, "longitude_3": 43, "longitude_4": 43, "longitude_5": 43, "longitude_6": 43, "longitude_7": 43, "longitude_8": 43, "longitude_9": 43, "look": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57], "lookatm": [12, 19, 31], "loop": [38, 41, 49, 54, 55], "loos": [45, 52], "lose": [6, 17, 24, 36], "loss": [2, 39, 40, 41, 42, 47, 50], "lot": [5, 9, 12, 13, 15, 17, 18, 19, 20, 21, 22, 24, 28, 30, 31, 32, 34, 36, 37, 38, 39, 40, 42, 43, 45, 48, 49, 50, 51, 52, 59], "lotarea": [40, 42, 51], "lotconfig": [40, 42, 51], "lotconfig_corn": 40, "lotconfig_culdsac": 40, "lotconfig_fr2": 40, "lotconfig_fr3": 40, "lotconfig_insid": 40, "lotfrontag": [40, 42, 51], "lotshap": [40, 42, 51], "lotshape_ir1": [40, 51], "lotshape_ir2": [40, 51], "lotshape_ir3": [40, 51], "lotshape_reg": [40, 51], "loud": [15, 16, 23, 28, 34, 35, 38, 55], "loui": 49, "lourenzutti": 38, "love": [30, 52, 53], "low": [6, 14, 15, 21, 22, 28, 33, 34, 38, 39, 40, 42, 43, 44, 45, 50, 51, 52], "lower": [14, 15, 21, 22, 33, 34, 39, 40, 42, 44, 46, 47, 50, 51], "lowerbound_peopl": 28, "lowercas": [16, 17, 23, 24, 35, 36], "lowest": [57, 59], "lowqualfinsf": [40, 42, 51], "lr": [18, 29, 30, 37, 39, 40, 42, 48, 49, 50, 53, 54], "lr_1": 43, "lr_2": 43, "lr_3": 43, "lr_coef": [42, 49, 50], "lr_coefs_landslop": 42, "lr_flatten_pip": 48, "lr_item": 46, "lr_pipe": [40, 42, 49], "lr_pred": [39, 40], "lr_scale": 42, "lr_schedul": 48, "lr_x": 46, "lr_y": 46, "ls15hb": [12, 19, 31], "lstm": 49, "lt": [14, 16, 17, 21, 23, 24, 30, 33, 35, 36, 38, 39, 40, 41, 42, 43, 50], "ltorgo": [18, 37], "lucio": 30, "luck": 52, "lucki": [15, 22, 34, 38], "lundberg": 42, "luster": 45, "lvert": 47, "lvl": [40, 42, 51], "lwq": [40, 42, 51], "lynx": [12, 19, 31, 48], "l\u00e9cuyer": [47, 59], "m": [10, 12, 14, 19, 21, 26, 27, 28, 30, 31, 33, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "m_neighbor": 39, "ma": [38, 47], "macaqu": [12, 19, 31, 48], "macbook": 10, "mach": 47, "machet": 30, "machin": [2, 9, 10, 11, 16, 17, 23, 24, 27, 28, 30, 35, 36, 38, 40, 41, 42, 43, 46, 47, 48, 49, 50, 51, 53, 55, 57, 59], "machine_learn": 51, "mackworth": 1, "made": [0, 6, 7, 8, 12, 13, 19, 20, 31, 32, 39, 41, 42, 46, 47, 48, 49, 51, 52], "magazin": 47, "magnitud": [23, 29, 30, 38, 40, 42, 47, 49], "maguir": 46, "mahsa": [1, 59], "mai": [0, 1, 7, 8, 10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 52, 56, 57, 58, 59], "mail": 50, "main": [8, 10, 12, 13, 15, 17, 19, 20, 22, 24, 26, 32, 34, 36, 41, 44, 45, 55, 59], "mainland": [18, 37], "mainli": 59, "maintain": [41, 46, 51, 55], "mainten": 41, "maissan": [1, 59], "maj1": [40, 42, 51], "maj2": [40, 42, 51], "major": [2, 14, 15, 16, 17, 21, 22, 23, 24, 33, 34, 35, 36, 47, 55, 56], "major_biologi": [17, 24, 36], "major_comput": [17, 24, 36], "major_econom": [17, 24, 36], "major_linguist": [17, 24, 36], "major_mathemat": [17, 24, 36], "major_mechan": [17, 24, 36], "major_phys": [17, 24, 36], "major_psychologi": [17, 24, 36], "make": [2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59], "make_blob": [15, 22, 34, 44, 45, 48, 54], "make_circl": 45, "make_classif": [15, 22, 34, 39], "make_column_transform": [28, 38, 39, 40, 41, 42, 43, 49, 50, 51, 53, 58], "make_forg": [15, 22, 34], "make_grid": [27, 48], "make_imb_pipelin": 39, "make_moon": 45, "make_num_tree_plot": 41, "make_pipelin": [12, 17, 18, 19, 24, 28, 29, 30, 31, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 58], "make_scor": [40, 43], "maker": [30, 51], "malcolm": [44, 46], "malcom": 44, "male": [39, 41, 42, 50], "male_cm": 39, "male_pr": 39, "malkovich": 30, "mall": 53, "mamba": [27, 28], "man": [30, 46, 47], "manag": [5, 11, 49, 50, 51, 55], "mandarin": [16, 23, 35], "mango": 47, "mani": [1, 2, 5, 8, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 57, 59], "manipul": 51, "manner": [0, 41], "manual": [10, 12, 17, 19, 20, 24, 27, 31, 36, 39, 43, 44, 45, 47], "manual_se": 27, "manufactur": 48, "map": [1, 13, 14, 17, 20, 21, 24, 29, 30, 32, 33, 36, 38, 46], "mape": [52, 55], "mape_scor": 40, "maple_leaf": 47, "mapper": 46, "mar": 1, "march": 49, "marit": [39, 41, 42], "mark": [6, 7, 19, 38, 39, 45, 59], "markdown": [12, 19], "marker": [15, 18, 22, 34, 37, 44], "markers": [18, 37, 39], "market": [12, 19, 31, 44, 48, 49, 51, 52], "markov": 47, "marri": [39, 41, 42], "martin": 47, "mask": 38, "massiv": [17, 24, 36, 38], "master": [8, 38, 39, 41, 42, 47], "masvnrarea": [40, 42, 51], "masvnrtyp": [40, 42, 51], "masvnrtype_brkcmn": 40, "masvnrtype_brkfac": 40, "masvnrtype_miss": 40, "masvnrtype_ston": 40, "match": [17, 18, 24, 36, 37, 39, 41, 42, 49], "materi": [8, 10, 12, 13, 14, 15, 19, 22, 31, 32, 33, 34, 44, 47, 50, 52, 55, 59], "matern": 43, "math": [2, 44, 46, 50], "mathcal": [15, 34], "mathemat": [2, 17, 24, 36, 41, 52, 55], "mathematician": 47, "mathia": [1, 17, 59], "matlab": 8, "matplotlib": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 55, 56, 57, 58], "matplotlibdeprecationwarn": 42, "matric": [12, 15, 19, 22, 34, 39, 46], "matrix": [17, 24, 28, 30, 36, 45, 47, 52, 55], "mattei": 30, "matter": [16, 17, 23, 24, 35, 36, 39, 41, 45, 51, 55, 59], "max": [8, 14, 16, 18, 21, 23, 26, 28, 29, 30, 33, 35, 37, 38, 39, 40, 41, 44, 45, 49], "max_bin": 41, "max_cat_threshold": 41, "max_cat_to_onehot": 41, "max_clust": 45, "max_colwidth": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 45, 46, 56, 57, 58], "max_delta_step": 41, "max_depth": [14, 15, 21, 22, 26, 27, 33, 34, 38, 41, 42, 51, 56, 57], "max_depth_widget": [15, 22, 27, 34, 57], "max_df": [17, 24, 36], "max_displai": 42, "max_featur": [12, 17, 19, 24, 28, 29, 30, 31, 36, 38, 41, 51], "max_it": [12, 19, 30, 31, 39, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54], "max_leaf_nod": [13, 20, 32, 51], "max_leav": 41, "max_opt": [15, 22, 34, 39, 44, 45], "max_row": 50, "max_sampl": 51, "maxabsscal": 28, "maxclust": 45, "maxent": 54, "maxim": [12, 19, 31, 39, 40, 44], "maximum": [13, 16, 20, 23, 28, 29, 30, 32, 35, 40, 41, 44, 45, 57], "maxosx": 10, "maxtemp": 49, "may": 1, "mayb": [39, 42, 49, 51, 59], "maybe_coerce_valu": 50, "mb": [16, 23, 35, 36, 39, 43, 49, 50], "mcld": 59, "mcml": [1, 59], "md": [10, 12, 13, 32, 47], "me": [8, 12, 19, 30, 31, 38, 47, 51, 52, 53], "mean": [5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 46, 48, 49, 50, 52, 53, 54, 55, 57, 59], "mean_absolute_error": 52, "mean_absolute_percentage_error": 40, "mean_cv_error": [14, 21, 33], "mean_cv_scor": [15, 18, 22, 27, 29, 30, 34, 37, 38], "mean_fit_tim": [38, 40], "mean_scor": [14, 16, 21, 23, 33, 35, 38, 53], "mean_score_tim": [38, 40], "mean_squared_error": [40, 43], "mean_std_cross_val_scor": [14, 16, 21, 23, 33, 35, 36, 41, 42, 50, 53], "mean_test_neg_mean_squared_error": 40, "mean_test_scor": [38, 40], "mean_train_error": [14, 21, 33], "mean_train_neg_mean_squared_error": 40, "mean_train_scor": [15, 18, 22, 27, 29, 30, 34, 37, 38, 40], "meaning": [11, 15, 17, 22, 24, 27, 34, 36, 39, 42, 44, 47, 58], "meaningless": 45, "measur": [0, 12, 13, 14, 15, 19, 20, 21, 22, 31, 32, 33, 34, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 55, 57], "meat": 28, "mechan": [17, 24, 36, 55], "mechanical_engin": 47, "medal": 8, "media": 51, "median": [13, 16, 18, 20, 23, 28, 32, 35, 36, 37, 40, 42, 43, 49, 50, 51], "median_house_valu": [16, 23, 35, 36, 43, 58], "median_incom": [16, 23, 35, 36, 43, 58], "mediat": 51, "medic": [39, 44, 59], "medinc": [18, 37], "medit": [39, 52], "medium": [0, 15, 22, 28, 34, 50, 55], "meet": 47, "meier": 11, "melbourneairport": 49, "member": [18, 37, 41, 59], "membership": [17, 24, 36, 44, 45], "memori": [8, 16, 17, 23, 24, 28, 35, 36, 39, 40, 41, 43, 48, 49, 50, 55], "men": 30, "mental": 51, "mention": [0, 4, 18, 30, 37, 50, 51], "menu": [10, 52], "merchant": 0, "merg": [0, 5, 10, 45], "meshgrid": 43, "mess": [30, 46, 50], "messag": [4, 6, 10, 14, 17, 21, 24, 28, 33, 36], "messi": [43, 47], "met": 59, "meta": 41, "metacademi": 1, "metal": 30, "method": [2, 11, 13, 15, 16, 18, 20, 22, 23, 26, 27, 29, 30, 32, 34, 35, 37, 39, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55], "methodologi": [16, 23, 35, 49], "metric": [1, 11, 15, 17, 22, 24, 28, 34, 36, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52], "mexican": 28, "mexico": 39, "mglearn": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 44, 47, 48, 49, 54, 56, 57], "mi": [12, 19, 31, 38, 39, 51], "microsoft": 53, "middl": [29, 30], "midnight": 49, "midterm": [1, 6, 12, 18, 19], "might": [1, 6, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 55, 57, 59], "mightn": 47, "miguel": 52, "mike": [0, 1, 9, 20, 32, 52], "mikolov": 47, "milk": 47, "mill": 41, "millennia": 59, "million": 48, "min": [1, 18, 23, 26, 28, 37, 40, 45, 49], "min1": [40, 42, 51], "min2": [40, 42, 51], "min_child_weight": 41, "min_df": [17, 24, 36], "min_impurity_decreas": 51, "min_impurity_split": 51, "min_sampl": 45, "min_samples_leaf": [13, 20, 32, 51], "min_samples_split": [13, 20, 32, 51], "min_token_len": 47, "min_token_length": 47, "min_weight_fraction_leaf": 51, "mind": [14, 16, 17, 21, 23, 33, 35, 36, 41, 42, 46, 50, 51, 52, 55, 59], "mine": 1, "minibatchkmean": 45, "miniconda": 10, "miniconda3": [10, 17, 53], "miniforge3": [32, 33, 36, 38, 42, 50, 54], "minim": [5, 13, 20, 32, 40, 44, 45, 51], "minimum": [8, 14, 16, 21, 23, 30, 33, 35, 45, 47], "minmaxscal": [16, 17, 23, 24, 28, 35, 36, 51], "minor": [6, 50], "mintemp": 49, "minut": [4, 12, 13, 19, 20, 30, 32, 43, 50, 55], "miracl": 53, "miscalcul": 1, "miscfeatur": [40, 42, 51], "miscfeature_gar2": 40, "miscfeature_miss": 40, "miscfeature_othr": 40, "miscfeature_sh": 40, "miscfeature_tenc": 40, "misconduct": 59, "miscval": [40, 42, 51], "mishaal": [1, 59], "mislead": [14, 21, 33, 39], "miss": [10, 15, 16, 17, 18, 22, 23, 24, 26, 28, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 49, 50, 51, 55, 57, 59], "mist": 30, "mistak": [16, 23, 35, 41, 50, 51, 57], "mit": [0, 1], "mitig": [11, 46], "mitlp": 50, "mitt": 47, "mitten": 47, "mix": [12, 19, 40, 51, 52], "mixtur": [45, 47, 48], "ml": [1, 2, 9, 11, 13, 16, 20, 23, 32, 35, 41, 45, 47, 48, 52], "ml_experi": [13, 14, 17, 20, 21, 24, 32, 33, 36, 55], "mlpclassifi": 48, "mlpregressor": 48, "mm": 49, "mmsto": [12, 19, 31], "mn": [40, 42, 51], "mnprv": [40, 42, 51], "mnww": [40, 42, 51], "mo": 47, "mobil": [17, 24, 36, 48], "mobilenet": 48, "mod": [40, 42, 51], "mode": [15, 16, 23, 34, 35, 38], "model": [1, 2, 11, 22, 38, 39, 44, 45, 46, 49, 51, 54, 56], "model_nam": 46, "model_select": [12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 46, 48, 49, 50, 51, 52, 57, 58], "modern": [1, 15, 22, 34, 47, 51], "modif": 50, "modifi": [0, 10, 39, 50, 52, 59], "modul": [9, 14, 20, 21, 27, 28, 32, 33, 39, 53], "moe": 38, "mole": 48, "mom": 43, "moment": [39, 59], "moment_predictor": 52, "mon": 49, "monarch": 47, "monarchi": 47, "mondai": [1, 18, 49, 59], "mone": 30, "monei": [8, 30, 50], "monitor": 47, "monkei": [12, 19, 31, 48], "monotone_constraint": 41, "montani": 53, "month": [14, 17, 24, 33, 36, 40, 50], "month_nam": [26, 49], "monthli": 50, "monthlycharg": 50, "montreal": [47, 53], "moon": 45, "moosvi": [0, 1, 47], "moral": [0, 44], "more": [1, 2, 5, 6, 7, 8, 10, 12, 14, 19, 27, 28, 30, 33, 38, 41, 42, 44, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59], "morn": [12, 19, 31], "morpholog": 47, "morri": 30, "morton": 30, "moskowitz": 44, "mosold": [40, 42, 51], "mosold_1": 40, "mosold_10": 40, "mosold_11": 40, "mosold_12": 40, "mosold_2": 40, "mosold_3": 40, "mosold_4": 40, "mosold_5": 40, "mosold_6": 40, "mosold_7": 40, "mosold_8": 40, "mosold_9": 40, "most": [7, 8, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 59], "most_confident_i": [18, 37], "most_confident_x": [18, 37], "most_frequ": [13, 15, 16, 20, 22, 23, 28, 32, 34, 35, 39, 40, 42, 51, 56], "most_negative_id": [29, 30], "most_positive_id": [29, 30], "most_similar": 47, "mostli": [8, 17, 24, 36, 49], "motiv": [12, 17, 19, 24, 31, 36], "mountginini": 49, "move": [7, 18, 29, 30, 37, 42, 43, 56, 59], "movi": [18, 29, 30, 37, 47, 53], "movie_feats_df": 46, "movie_id": 46, "movie_nam": 46, "movies_rated_by_pat": 46, "movies_to_pr": 46, "movieto": 53, "mpimg": 48, "mr": 30, "mri": 55, "mrtssm448usn": 49, "mse": [13, 20, 32, 46, 52, 55], "msg": [17, 24, 36, 50], "msg_dtype": 28, "msg_err": 28, "mssubclass": [40, 42, 51], "mssubclass_120": 40, "mssubclass_160": 40, "mssubclass_180": 40, "mssubclass_190": 40, "mssubclass_20": 40, "mssubclass_30": 40, "mssubclass_40": 40, "mssubclass_45": 40, "mssubclass_50": 40, "mssubclass_60": 40, "mssubclass_70": 40, "mssubclass_75": 40, "mssubclass_80": 40, "mssubclass_85": 40, "mssubclass_90": 40, "mszone": [40, 42, 51], "mszoning_c": [40, 42], "mszoning_fv": 40, "mszoning_rh": 40, "mszoning_rl": 40, "mszoning_rm": 40, "much": [4, 5, 8, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 30, 32, 33, 34, 35, 36, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 57, 59], "mueller": 1, "multi": [40, 42, 44, 47, 49, 52], "multi_class": [39, 54], "multi_output": 28, "multi_strategi": 41, "multiclass": [48, 52, 54], "multicoliniar": 42, "multicultur": 47, "multilevel": 40, "multimod": 44, "multinomi": 54, "multipl": [7, 8, 14, 18, 21, 26, 33, 37, 38, 41, 42, 47, 48, 49, 50], "multiplelin": 50, "multiplelines_no": 50, "multiplelines_y": 50, "multipli": [18, 37, 38, 39, 41, 43, 50], "murder": 30, "music": [28, 30, 46, 53], "musqueam": 59, "must": [0, 6, 7, 8, 12, 13, 14, 16, 19, 20, 23, 30, 32, 33, 35, 42, 45, 47, 50], "mustn": 47, "mutual": 45, "my": [6, 10, 12, 19, 30, 31, 38, 39, 44, 47, 51, 52, 53, 59], "my_heatmap": 38, "my_map": 40, "mypreprocessor": 47, "myself": [32, 47, 51], "m\u00fcller": 9, "n": [1, 13, 15, 18, 20, 22, 27, 28, 29, 30, 32, 34, 37, 38, 40, 41, 42, 43, 45, 46, 47, 49, 51, 53, 54, 57], "n_bin": 43, "n_class": [15, 22, 34, 39], "n_cluster": [44, 45], "n_clusters_per_class": 39, "n_compon": 47, "n_constitu": 41, "n_estim": [43, 49, 50, 51], "n_estimators_valu": 51, "n_exampl": 44, "n_feat": [15, 22, 34], "n_featur": [15, 22, 34, 39, 44], "n_features_to_select": 43, "n_imag": 27, "n_inform": 39, "n_init": 44, "n_job": [17, 24, 36, 39, 40, 41, 51], "n_neighbor": [27, 46, 57], "n_neighbors_selector": [15, 22, 34], "n_neighbors_widget": [15, 22, 27, 34, 57], "n_peopl": 28, "n_redund": 39, "n_rental": 49, "n_rentalsin3hour": 49, "n_rentalsin6hour": 49, "n_repeat": 42, "n_resourc": 38, "n_sampl": [15, 22, 34, 39, 44, 45, 48, 54], "n_split": 49, "n_threshold": 39, "n_top_feat": [29, 30], "n_top_featur": [29, 30], "n_topic": 47, "n_train": 49, "n_word": [47, 53], "na": [40, 42, 51], "nafter": 47, "nah": [17, 24, 36], "naiv": 45, "name": [1, 4, 5, 6, 7, 8, 10, 13, 15, 16, 17, 20, 22, 23, 24, 26, 27, 28, 29, 30, 32, 34, 35, 36, 38, 39, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 57, 59], "named_estimators_": 41, "named_step": [18, 29, 30, 37, 39, 40, 41, 42, 43, 49, 51, 53], "named_transformers_": [17, 24, 28, 36, 39, 40, 41, 42, 43, 49, 50, 51, 53], "namespac": 28, "nan": [16, 17, 23, 24, 28, 35, 36, 39, 40, 41, 42, 43, 46, 49, 50, 51, 53, 55], "nanmean": 46, "nanosecond": 49, "narr": 47, "narrat": 30, "narrow": [12, 19, 46, 51], "nasali": [12, 19, 31, 48], "nation": 59, "nativ": [28, 39, 41, 42, 48, 54], "natur": [2, 11, 12, 17, 24, 28, 31, 36, 39, 41, 43, 48, 52, 54], "navig": [7, 10, 52], "nbsp": [12, 19, 31, 35, 36, 38, 39, 40, 41, 42, 43, 48, 51, 53], "nbviewer": [12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 31, 35, 36, 38, 39, 40, 41, 42, 43, 48, 51, 53], "nc": 1, "ncol": [18, 37], "ndarrai": [8, 17, 24, 28, 36], "ndate": 53, "ndframe": [43, 50], "ndim": [8, 28], "ne": 49, "nearbi": [15, 22, 34, 44], "nearest": [27, 28, 39, 45, 57], "nearestneighbor": 27, "nearestneighborsifittednearestneighbor": 27, "nearli": [26, 30], "necessari": [0, 7, 13, 28, 32, 38, 55, 58], "necessarili": [14, 21, 33, 40, 41, 46, 52], "neck": 30, "necvq": 50, "need": [5, 7, 8, 10, 12, 13, 15, 17, 19, 20, 22, 24, 26, 27, 28, 31, 32, 34, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 58, 59], "needn": 47, "neg": [13, 14, 15, 18, 20, 21, 22, 32, 33, 34, 37, 40, 41, 42, 47, 49, 50, 53, 57], "neg_mean_absolute_percentage_error": 40, "neg_mean_squared_error": [40, 51], "neg_prob": [29, 30], "neg_root_mean_square_error": 40, "neg_root_mean_squared_error": 40, "neigh": [15, 22, 27, 34], "neighbor": [15, 16, 17, 18, 22, 23, 24, 27, 28, 34, 35, 36, 37, 39, 43, 45, 57, 58], "neighborhood": [18, 37, 40, 42, 51], "neighborhood_blmngtn": 40, "neighborhood_bluest": 40, "neighborhood_brdal": 40, "neighborhood_brksid": 40, "neighborhood_clearcr": 40, "neighborhood_collgcr": 40, "neighborhood_crawfor": 40, "neighborhood_edward": 40, "neighborhood_gilbert": 40, "neighborhood_idotrr": 40, "neighborhood_meadowv": 40, "neighborhood_mitchel": 40, "neighborhood_nam": 40, "neighborhood_noridg": [40, 42], "neighborhood_npkvil": 40, "neighborhood_nridght": [40, 42], "neighborhood_nwam": 40, "neighborhood_oldtown": [40, 42], "neighborhood_sawy": [40, 42], "neighborhood_sawyerw": [40, 42], "neighborhood_somerst": [40, 42], "neighborhood_stonebr": [40, 42], "neighborhood_swisu": [40, 42], "neighborhood_timb": [40, 42], "neighborhood_veenk": [40, 42], "neighborsbas": 28, "neighbour": [14, 27, 33, 42, 44, 45, 47, 57], "neighbourhood": [18, 37, 43, 45, 58], "neither": [14, 17, 21, 24, 33, 36, 46], "neo": [1, 59], "neq": [42, 46], "ner": 47, "nervou": [13, 20, 32], "nest": [38, 55], "net": [48, 50], "netflix": [46, 53], "network": [1, 11, 12, 17, 19, 24, 31, 36, 41, 43, 44, 46, 47, 49, 52], "neu": 53, "neural": [1, 11, 43, 49], "neutral": 53, "never": [39, 41, 42, 46, 48, 50], "nevertheless": 59, "new": [1, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 55, 58], "new_cent": 44, "new_column": [40, 42, 49, 50, 51], "new_data": 50, "new_df": 49, "new_exampl": [13, 20, 32, 44], "new_feature_nam": 49, "new_valu": 50, "newaxi": 8, "newcastl": 53, "newer": 40, "newli": [16, 23, 35, 40, 43, 45], "newsgroup": 47, "newswir": 47, "next": [1, 10, 13, 14, 15, 16, 18, 20, 22, 23, 27, 28, 32, 33, 34, 35, 36, 39, 40, 41, 47, 48, 49, 51, 58, 59], "nfeat": [15, 22, 34], "nfeats_accuraci": [15, 22, 34], "ng": [1, 9, 38, 43], "ngram": 43, "ngram_rang": [17, 24, 36], "nhl": 47, "nhqxu": 50, "nice": [4, 12, 19, 30, 38, 39, 41, 42, 45, 48, 50, 51, 52], "nicki": 38, "night": [39, 49, 52], "nightmar": 51, "niki": [1, 59], "nlemma": 47, "nlp": [17, 24, 36, 48, 53], "nltk": [47, 53], "nltk_data": [47, 53], "nmax": 51, "nn": [1, 16, 23, 27, 29, 30, 35, 48, 57], "nne": 49, "nnw": 49, "nnz": [17, 24, 36], "no_grad": [27, 48], "no_val_x": 28, "nobodi": [12, 31], "node": [13, 20, 32, 41, 45, 48, 56], "nois": [45, 55, 57], "noise_cat": 28, "noise_level": 28, "non": [1, 8, 12, 13, 14, 16, 18, 19, 20, 21, 23, 31, 32, 33, 35, 37, 38, 39, 40, 41, 43, 45, 46, 48, 49, 50, 52, 55, 59], "noncommerci": 1, "none": [1, 14, 16, 17, 18, 21, 23, 24, 28, 30, 33, 35, 36, 37, 38, 39, 41, 43, 45, 49, 50, 51], "noninfring": 0, "nonzero": [17, 24, 36], "noodl": 28, "noqa": 38, "nor": [7, 14, 17, 21, 24, 33, 36, 47], "norg": [47, 53], "norm": [28, 38, 47], "normal": [6, 23, 27, 28, 39, 40, 41, 42, 44, 45, 47, 48, 49, 51, 53], "north": 47, "north_america": 28, "norvig": 1, "notat": [15, 34], "note": [0, 1, 3, 7, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 46, 52, 54, 55, 59], "notebook": [5, 7, 9, 10, 13, 14, 15, 16, 17, 21, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 48, 51, 53, 58], "noth": 30, "notic": [0, 17, 18, 24, 28, 30, 36, 37, 39, 40, 43], "notion": [15, 22, 34, 38, 44, 46], "notna": 49, "noun": [47, 53], "nov": 49, "novel": 55, "novemb": 49, "novic": 9, "now": [8, 10, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 56, 57, 58], "np": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58], "nperson": 53, "npie": 8, "npo": 47, "npr": [43, 47, 55], "npt": 28, "nsubj": 47, "ntest": [15, 22, 27, 34, 38, 57], "ntoken": 47, "ntree": 41, "null": [16, 17, 23, 24, 35, 36, 39, 40, 43, 49, 50], "null_distribut": 50, "num": [39, 41, 42], "num_output_channel": 48, "num_parallel_tre": 41, "num_sent": [39, 52], "num_work": [27, 48], "number": [1, 4, 6, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 50, 52, 55, 57, 59], "number_test": 38, "numberbatch": 47, "numer": [2, 13, 16, 17, 18, 20, 23, 24, 27, 28, 32, 35, 36, 37, 39, 40, 41, 46, 47, 49, 50, 51, 57, 58], "numeric_feat": [17, 24, 28, 36, 38, 43, 55], "numeric_featur": [36, 39, 40, 41, 42, 49, 50, 51, 53], "numeric_looking_column": 40, "numeric_transform": [28, 36, 39, 40, 41, 42, 49, 51], "numpi": [9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58], "numpy_dtyp": 50, "nuniqu": 26, "nutrit": 47, "nw": 49, "nwith": [15, 22, 34], "ny": 53, "nyre": 30, "nyt": 51, "o": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58], "obelisk": 48, "object": [14, 16, 17, 18, 21, 23, 24, 26, 28, 29, 30, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 53, 55, 56, 57], "observ": [12, 13, 14, 15, 19, 20, 21, 22, 27, 31, 32, 33, 34, 41, 42, 44, 45, 49, 50, 57], "obtain": [0, 18, 27, 29, 30, 37, 44, 45, 46, 50, 57], "obviou": [45, 47], "obvious": 30, "occasion": 39, "occup": [39, 41, 42], "occupation_farm": 42, "occupation_miss": 42, "occupation_priv": 42, "occupi": 59, "occur": [8, 13, 14, 17, 20, 21, 24, 32, 33, 36, 47, 50], "occurr": [47, 50], "ocean": [16, 23, 35, 36, 43, 58], "ocean_proxim": [16, 23, 35, 36, 43, 58], "ocean_proximity_": [16, 23, 35, 36], "ocean_proximity_inland": [16, 23, 35, 36], "ocean_proximity_island": [16, 23, 35, 36], "ocean_proximity_near": [16, 23, 35, 36], "oct": 37, "octob": [26, 49], "oe": [17, 24, 36, 55], "oe_encod": 55, "off": [11, 18, 27, 30, 37, 38, 39, 40, 43, 44, 47, 48, 50, 51, 55], "offens": 4, "offer": [8, 30, 41, 46, 47, 50, 59], "offic": [1, 4, 10, 12, 55, 59], "offici": [47, 59], "offlin": 46, "offset": [18, 37], "often": [8, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57], "ogunrind": [12, 19, 31], "oh": [28, 42, 43, 48, 49, 50, 52, 55, 59], "ohe_column": [40, 42, 51], "ohe_enc": [17, 24, 36], "ohe_encod": 55, "ohe_feat": 28, "ohe_feat_nam": 28, "ohe_feature_nam": [42, 49], "ohehotencod": [17, 24, 36], "ois": 45, "ok": [12, 15, 19, 22, 30, 31, 34, 40, 49, 50, 52, 55], "okai": [44, 52], "ola": 47, "old": [9, 30, 41, 42], "old_cent": 44, "older": 40, "olymp": 8, "omit": 42, "omw": 47, "onc": [6, 7, 8, 10, 13, 14, 16, 17, 20, 21, 23, 24, 27, 32, 33, 35, 36, 38, 43, 45, 46, 47, 48, 52, 59], "onca": [12, 19, 31, 48], "one": [6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 59], "one_c": [15, 22, 34], "one_ex_preprocess": 42, "one_ex_preprocessed_perturb": 42, "one_exampl": 42, "one_example_perturb": 42, "onehot": [17, 24, 36, 43], "onehotencod": [16, 18, 23, 28, 35, 37, 38, 39, 40, 41, 42, 43, 49, 50, 51, 55, 58], "onehotencoder__major_biologi": [17, 24, 36], "onehotencoder__major_comput": [17, 24, 36], "onehotencoder__major_econom": [17, 24, 36], "onehotencoder__major_linguist": [17, 24, 36], "onehotencoder__major_mathemat": [17, 24, 36], "onehotencoder__major_mechan": [17, 24, 36], "onehotencoder__major_phys": [17, 24, 36], "onehotencoder__major_psychologi": [17, 24, 36], "onehotencoderonehotencod": [17, 24, 28, 36, 38, 40, 41, 51], "ones": [8, 12, 15, 16, 19, 22, 23, 26, 27, 31, 34, 35, 41, 42, 44, 46, 47, 57], "onevsoneclassifi": 54, "onevsrestclassifi": 54, "onli": [2, 4, 8, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 57, 58, 59], "onlin": [3, 5, 7, 10, 20, 32, 47, 59], "onlinebackup": 50, "onlinebackup_no": 50, "onlinebackup_y": 50, "onlinesecur": 50, "onlinesecurity_no": 50, "onlinesecurity_y": 50, "onrend": 52, "ontario": 47, "ontonot": 47, "oob_scor": 51, "op": 39, "open": [5, 6, 10, 12, 19, 31, 48, 52, 59], "openporchsf": [40, 42, 51], "oper": [4, 8, 10, 17, 24, 36, 43, 47, 52], "opera": 30, "operand": 8, "opinion": 41, "opportun": [26, 46], "oppos": [40, 41], "opposit": [8, 40, 41, 42], "opt": [10, 27, 28, 41], "optic": 50, "optim": [1, 2, 13, 14, 15, 20, 21, 22, 27, 29, 30, 32, 33, 34, 36, 39, 41, 42, 43, 44, 45, 48, 50, 51, 52], "optimist": 38, "optimized_c": [29, 30], "option": [1, 7, 8, 13, 19, 20, 32, 40, 44, 47, 51], "orang": [18, 37], "orch": 59, "order": [5, 7, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 51, 52, 55], "ordering_ordinal_oth": [40, 42, 51], "ordering_ordinal_reg": [40, 42, 51], "ordin": [40, 55, 58], "ordinal_feat": [17, 24, 28, 36], "ordinal_featur": [39, 41, 42], "ordinal_features_oth": [40, 42, 51], "ordinal_features_reg": [40, 42, 51], "ordinal_transform": [28, 39, 41, 42], "ordinal_transformer_oth": [40, 42, 51], "ordinal_transformer_reg": [40, 42, 51], "ordinalencod": [16, 17, 23, 24, 28, 35, 36, 39, 40, 41, 42, 43, 49, 50, 51, 55, 58], "ordinalencoderordinalencod": [17, 24, 28, 36, 40, 41, 51], "ordinari": 40, "oreilli": [48, 49], "org": [9, 12, 14, 16, 17, 19, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 36, 38, 39, 40, 41, 42, 43, 47, 48, 51, 53], "organ": [12, 13, 16, 19, 20, 23, 31, 32, 35, 47, 51, 52], "orgin": 8, "orig_featur": 49, "orig_pr": 42, "orig_scor": 39, "origin": [12, 16, 17, 19, 23, 24, 35, 36, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 53, 57, 59], "original_hm": [39, 52], "originaltweet": 53, "ornithorhynchu": 48, "oscar": [18, 37], "ostblom": 47, "other": [0, 1, 4, 5, 6, 7, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 32, 33, 35, 36, 37, 38, 39, 41, 42, 45, 46, 48, 52, 53, 54, 55, 57, 59], "otherwis": [0, 7, 17, 24, 36], "ounc": [12, 19, 31, 48], "our": [5, 6, 8, 10, 12, 13, 15, 17, 18, 19, 20, 22, 24, 26, 27, 28, 29, 30, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 55, 56, 57, 59], "ourselv": [13, 20, 32, 39, 47, 48, 49], "out": [0, 1, 4, 7, 8, 10, 12, 13, 14, 15, 17, 19, 20, 21, 22, 24, 26, 28, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 53, 55, 57, 59], "out_col": [14, 16, 21, 23, 33, 35, 53], "out_step": 39, "outer": 53, "outlier": [28, 40, 45, 52, 55], "outlook": 50, "output": [7, 8, 10, 12, 13, 14, 17, 18, 19, 20, 21, 24, 28, 31, 32, 33, 36, 37, 39, 41, 42, 47, 48, 49, 51, 52, 55, 59], "outsid": [7, 39, 41, 42, 46, 47, 49, 50], "over": [14, 33, 38, 40, 47, 48, 49, 50, 51, 52, 55, 59], "over_confident_i": [18, 37], "over_confident_x": [18, 37], "over_sampl": 39, "overal": [10, 28, 29, 30, 39, 42, 44, 47, 48, 51, 55, 59], "overallcond": [40, 42, 51], "overallqu": [40, 42, 51], "overconfid": [42, 43, 52], "overcrowd": 59, "overfit": [1, 11, 15, 18, 22, 26, 27, 29, 30, 34, 37, 40, 41, 43, 48, 52, 57], "overflow": 7, "overhead": [17, 24, 36], "overlap": [2, 14, 21, 33, 44, 52], "overli": [15, 22, 27, 34, 38, 57], "overload": [46, 50], "overpredict": 40, "oversample_pip": 39, "overshadow": 47, "overst": 51, "overus": 41, "overview": [44, 45, 46, 47], "overwhelm": 44, "overzeal": 6, "own": [4, 5, 8, 12, 14, 16, 19, 23, 30, 33, 35, 39, 40, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54], "oz": 30, "p": [18, 30, 37, 38, 45, 47, 50, 52], "p_i": 44, "p_value_threshold": 50, "pace": [18, 30, 37, 44, 47, 59], "packag": [5, 8, 11, 17, 20, 24, 27, 28, 32, 33, 36, 38, 39, 42, 44, 45, 46, 47, 48, 50, 52, 53, 54], "pad": [27, 48], "page": [1, 4, 7, 12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 31, 35, 36, 38, 39, 40, 41, 42, 43, 47, 48, 51, 53, 59], "pai": [42, 52], "pain": [4, 48, 49, 51], "pair": [45, 47, 54], "pairwis": [15, 22, 34, 45], "panda": [9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58], "pane": [15, 22, 27, 34, 57], "panel": [15, 22, 27, 34, 39, 42, 44, 45, 57], "panic": 53, "panther": [12, 19, 31, 48], "panthera": [12, 19, 31, 48], "paper": [7, 42, 43, 47, 48, 50, 52, 53], "paperlessbil": 50, "paperlessbilling_no": 50, "paperlessbilling_y": 50, "paradigm": [12, 13, 19, 20, 31, 32, 44, 47], "paradox": 46, "paragraph": 47, "paraleg": 47, "parallel": [17, 24, 36, 38, 41], "param": [15, 17, 22, 24, 27, 34, 36, 38, 40, 57], "param_columntransformer__countvectorizer__max_featur": 38, "param_dist": 38, "param_distribut": 38, "param_grid": [14, 15, 21, 22, 33, 34, 38, 40, 51], "param_grid1": 38, "param_grid2": 38, "param_grid3": 38, "param_grid4": 38, "param_ridge__alpha": 40, "param_svc__c": 38, "param_svc__gamma": 38, "paramet": [15, 16, 17, 22, 23, 24, 27, 28, 34, 35, 36, 40, 41, 42, 44, 45, 47, 49, 50, 51, 53, 56, 57], "parametr": 45, "params_": 50, "params_str": 38, "paramter": [15, 22, 34], "pardu": [12, 19, 31, 48], "parent": [30, 45], "park": [43, 48, 52, 53], "pars": 47, "parse_d": [8, 49], "parser": 47, "part": [1, 4, 9, 10, 16, 17, 18, 23, 30, 35, 36, 37, 38, 39, 41, 42, 43, 45, 47, 49, 51, 52, 53, 59], "part1": 46, "part2": 46, "parti": 47, "partial": [4, 50, 51], "particip": 59, "particular": [0, 9, 10, 16, 17, 23, 24, 35, 36, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 57], "particularli": [30, 41, 46, 59], "partit": [17, 24, 36, 44, 45], "partner": [50, 59], "partner_no": 50, "partner_y": 50, "parton": 53, "pass": [8, 14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 28, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 47, 48, 57, 59], "passthrough": [17, 24, 36, 38, 50, 53], "passthrough__ml_experi": [17, 24, 36], "passthrough_feat": [17, 24, 36, 38, 55], "passthrough_featur": [50, 53], "passthroughpassthrough": [17, 24, 36, 38, 53], "past": [13, 14, 20, 21, 32, 33, 41, 49, 50, 51, 55], "pat": 46, "pat_i": 46, "pat_model": 46, "pat_x": 46, "pata": [12, 19, 31, 48], "path": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58], "patial": 45, "patient": [13, 20, 32, 52], "patio": 48, "patric": 42, "patricia": 30, "patrick": [1, 59], "pattern": [12, 13, 14, 17, 19, 20, 21, 24, 26, 31, 32, 33, 36, 38, 43, 44, 47, 49, 51, 57], "paus": 30, "pav_bhaji": 47, "pave": [40, 42, 51], "paveddr": [40, 42, 51], "paveddrive_i": 40, "paveddrive_n": 40, "paveddrive_p": 40, "paymentmethod": 50, "paymentmethod_bank": 50, "paymentmethod_credit": 50, "paymentmethod_electron": 50, "paymentmethod_mail": 50, "pca": [39, 45, 46], "pcarter": 9, "pd": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58], "pdf": [7, 9], "peac": 47, "peck": 30, "pedest": 48, "pedro": [1, 14, 33, 43], "peer": [52, 55, 59], "pembrok": [12, 19, 31, 48], "penal": [6, 50], "penalti": [39, 47, 59], "peopl": [4, 13, 14, 16, 18, 20, 21, 23, 30, 32, 33, 35, 37, 39, 41, 44, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 59], "per": [8, 18, 37, 39, 40, 41, 42, 46, 48, 49, 51, 54, 55], "perceiv": 6, "percent": 40, "percent_error": 40, "percentag": [13, 20, 32, 39, 46, 51], "perfect": [6, 13, 14, 20, 21, 26, 30, 32, 33, 39, 40, 42, 46, 50, 53], "perfectli": [2, 46, 47], "perform": [11, 13, 14, 15, 16, 18, 20, 21, 22, 23, 26, 27, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 55, 56, 58], "performac": [14, 21, 33], "perhap": [40, 49, 54], "perimet": 43, "period": [47, 49, 50, 53, 59], "perm_sorted_idx": 42, "perman": 8, "permiss": [0, 59], "permit": [0, 16, 23, 35, 39, 59], "permut": 42, "persist": 46, "person": [0, 1, 4, 6, 12, 19, 31, 39, 44, 47, 48, 49, 50, 52, 53, 59], "perspect": [41, 46], "pertain": 5, "perthairport": 49, "perturb": [28, 42, 45], "perturbed_pr": 42, "pertwe": 30, "pete_seeg": 47, "peter": [1, 30], "petter": 30, "ph": 47, "pharma": 52, "phascolarcto": 48, "phase": [14, 21, 33], "phd": 47, "phdei": 50, "phenomenon": [46, 50, 57], "philippin": [30, 53], "philosoph": 47, "phone": [12, 19, 31, 50, 59], "phoneservic": 50, "phoneservice_no": 50, "phoneservice_y": 50, "photo": [53, 55], "photograph": 59, "phrase": 47, "physic": [17, 24, 36, 49], "pi": 8, "piazza": [1, 6, 7, 12, 13, 19], "pick": [13, 18, 20, 26, 30, 32, 37, 39, 41, 42, 43, 44, 45, 48, 51, 52, 54, 56, 57], "pictur": [41, 42, 45, 47, 49, 51], "pie": 8, "piec": [18, 30, 37, 50], "pil": [12, 19, 27, 31, 48], "pile": 30, "pin": [7, 48], "pineappl": 47, "pip": [10, 42, 47, 48, 52, 53], "pipe": [16, 17, 18, 23, 24, 35, 36, 37, 38, 39, 41, 47, 48, 53], "pipe_bestalpha": 40, "pipe_bigalpha": 40, "pipe_catboost": 41, "pipe_dt": [41, 42], "pipe_forward": 43, "pipe_knn": 28, "pipe_lgbm": [41, 42], "pipe_lr": [29, 30, 39, 41, 42, 52], "pipe_lr_all_feat": 43, "pipe_lr_balanc": 39, "pipe_lr_model_bas": 43, "pipe_lr_weight": 39, "pipe_ohe_knn": 28, "pipe_ordinal_knn": 28, "pipe_rf": [41, 42], "pipe_rf_demo": 41, "pipe_ridg": [18, 37, 40], "pipe_sklearn_gb": 41, "pipe_sklearn_histgb": 41, "pipe_smallalpha": 40, "pipe_svc": [28, 39], "pipe_svm": 38, "pipe_xgb": [41, 42], "pipe_xor": 43, "pipelin": [1, 2, 11, 12, 14, 17, 18, 19, 21, 24, 29, 30, 31, 33, 36, 37, 38, 39, 40, 41, 42, 43, 48, 49, 50, 51, 52, 53, 58], "pipeline__lab1": [17, 24, 36], "pipeline__lab2": [17, 24, 36], "pipeline__lab3": [17, 24, 36], "pipeline__lab4": [17, 24, 36], "pipeline__quiz1": [17, 24, 36], "pipeline__rooms_per_household": 43, "pipeline__university_year": [17, 24, 36], "pipelineifittedpipelin": [16, 17, 23, 24, 30, 35, 36, 38, 39, 43, 48, 53], "pipelineinot": [36, 38, 40], "pipelinepipelin": 38, "pitch": 51, "pitfal": [49, 51], "pitt": 30, "pixel": 42, "pizza": 47, "pkg": 10, "pla": 47, "place": [5, 47, 49, 59], "plagiar": 59, "plagu": 30, "plai": [13, 15, 20, 22, 30, 32, 34, 38, 42, 45, 47, 56, 57], "plain": 44, "plan": [10, 12, 19, 31, 40, 43, 50, 52, 53, 58, 59], "plane": [18, 20, 37], "plant": 55, "plastic": 47, "platform": 4, "platypu": 48, "player": [42, 47, 48], "pleas": [1, 4, 7, 10, 12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 31, 35, 36, 38, 39, 40, 41, 42, 43, 48, 51, 52, 53, 59], "plenti": 30, "plinth": 48, "plot": [7, 13, 14, 15, 16, 18, 20, 21, 22, 23, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 43, 45, 46, 47, 48, 49, 51, 52, 57], "plot_2d_scor": [18, 37], "plot_2d_separ": [15, 18, 22, 27, 34, 37, 57], "plot_coeff_exampl": [29, 30], "plot_confusion_matrix": 39, "plot_confusion_matrix_exampl": 39, "plot_cross_valid": [14, 21, 33, 49], "plot_dbscan": 45, "plot_dbscan_with_label": 45, "plot_dendrogram_clust": 45, "plot_elbow": 44, "plot_example_dist": 44, "plot_fruit_tre": [13, 32], "plot_grid_search_overview": 38, "plot_improper_process": 28, "plot_k_means_dbscan_comparison": 45, "plot_km_initi": 44, "plot_km_it": 44, "plot_km_iter": 44, "plot_kmean": 45, "plot_knn_clf": [15, 22, 34], "plot_knn_decision_boundari": [15, 22, 34], "plot_knn_regress": [15, 22, 34], "plot_lda_w_vector": 47, "plot_linkage_criteria": 45, "plot_logistic_regress": [18, 37], "plot_logistic_regression_graph": 48, "plot_loss_diagram": 51, "plot_multiclass_lr_ovr": 54, "plot_original_clust": 45, "plot_partial_effects_on_outcom": 50, "plot_proper_process": 28, "plot_result": [15, 22, 27, 34, 57], "plot_sample_img": 27, "plot_scal": [16, 23, 35], "plot_silhouette_dist": 44, "plot_single_hidden_layer_graph": 48, "plot_support_vector": [15, 22, 34], "plot_survival_funct": 50, "plot_svc_c": [15, 22, 34], "plot_svc_gamma": [15, 22, 34], "plot_time_spacing_distribut": 49, "plot_train_test_point": [15, 22, 34], "plot_tre": 26, "plot_tree_decision_boundari": [14, 21, 33], "plot_tree_decision_boundary_and_tre": [13, 14, 20, 21, 32, 33, 56], "plot_two_hidden_layer_graph": 48, "plot_typ": 42, "plot_x_dendrogram": 45, "plotli": [43, 47], "plotting_funct": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 48, 51, 54, 56, 57, 58], "plotting_functions_unsup": [44, 45, 46, 47], "plt": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 54, 55, 56, 57, 58], "plu": [18, 30, 37, 48], "plural": [17, 24, 36], "pm": [1, 12, 16, 18, 19, 49, 59], "pmltt": 1, "pn": [15, 22, 27, 34, 39, 44, 45, 57], "po": [18, 23, 29, 30, 33, 35, 37, 40, 42, 47, 51, 53], "pobox": [12, 19, 31], "poet": 47, "point": [1, 4, 11, 12, 13, 14, 16, 17, 18, 19, 20, 23, 24, 26, 28, 31, 32, 33, 35, 36, 37, 38, 40, 43, 45, 50, 51, 52, 54, 55, 57, 59], "point_ind": 44, "point_index": 44, "polarity_scor": 53, "pole": 48, "polici": [3, 4, 7, 19, 59], "polit": [46, 47, 48], "poly_transform": 49, "polynomialfeatur": [43, 49], "pomegran": 48, "pool": [1, 29, 30], "poolarea": [40, 42, 51], "poolqc": [40, 42, 51], "poor": [17, 24, 30, 36, 40, 43, 55, 58], "poorli": [15, 22, 34, 40, 45, 49], "pope": 47, "popul": [16, 18, 23, 35, 36, 37, 43, 49, 58], "popular": [8, 11, 14, 15, 16, 17, 18, 22, 23, 24, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 51, 53], "population_per_household": [16, 23, 35, 36, 58], "port": 52, "porter": [30, 47], "porterstemm": 47, "portion": [0, 14, 16, 21, 23, 29, 30, 33, 35, 38, 40, 42, 51, 59], "portrait": 30, "portug": [39, 42], "pos_": [47, 53], "pos_label": 40, "pos_prob": [29, 30], "posit": [13, 14, 15, 18, 21, 22, 23, 32, 33, 34, 35, 37, 40, 41, 42, 47, 49, 50, 53], "posix": 50, "possess": 51, "possibl": [4, 5, 6, 8, 12, 13, 14, 16, 19, 20, 21, 23, 26, 28, 29, 30, 31, 32, 33, 35, 38, 39, 41, 42, 43, 45, 46, 47, 48, 50, 51, 55, 57, 58, 59], "possibli": [7, 47], "post": [1, 4, 6, 7, 8, 12, 17, 19, 47, 49, 52, 59], "postprocess": 48, "potenti": [11, 15, 16, 22, 23, 26, 34, 35, 44, 47, 51, 52], "powder": 47, "power": [8, 14, 21, 28, 33, 41, 46, 47, 48, 51], "pplicat": 45, "pr": 55, "practic": [0, 1, 6, 9, 12, 14, 16, 21, 23, 33, 35, 43, 48, 51, 52, 55, 58, 59], "practition": 51, "prairielearn": [1, 12, 17, 19, 59], "pre": [1, 10, 12, 19, 27, 31, 41, 43, 47, 51, 52, 53, 55], "precipit": 52, "precis": [11, 40, 51, 52, 55], "precision_lr": 39, "precision_recall_curv": 39, "precision_scor": 39, "precision_svc": 39, "precisionrecallcurvedisplai": 39, "precisionrecalldisplai": 39, "pred": [39, 40, 46, 49, 50], "pred_df": [12, 19, 31, 46], "pred_dict": [12, 19, 31], "pred_g": 46, "pred_lin_reg": 46, "pred_train": 40, "pred_x": 46, "prediciton": 50, "predict": [2, 11, 14, 15, 16, 21, 22, 23, 24, 26, 28, 29, 30, 33, 34, 35, 38, 39, 40, 43, 44, 45, 47, 49, 51, 52, 53, 55, 57, 58], "predict_expect": 50, "predict_for_usr": 46, "predict_proba": [29, 30, 39, 41, 42, 48, 54], "predict_survival_funct": 50, "predicted_categori": [39, 52], "predicted_n_rent": 49, "predicted_quiz2": [13, 20, 32], "predicted_sal": 49, "predicted_target": [12, 19, 31], "predictor": [13, 20, 32, 55], "prefer": [12, 19, 31, 41, 44, 46], "prefer_skip_nested_valid": 28, "prefix": 8, "pregnant": 30, "preliminari": [16, 23, 35, 43], "prepar": [16, 23, 35, 43, 48], "prepend": 10, "preprocess": [1, 11, 14, 15, 18, 21, 22, 26, 27, 28, 33, 34, 37, 38, 39, 41, 42, 43, 45, 46, 48, 50, 57, 58], "preprocess_featur": 49, "preprocessing_fin": 50, "preprocessing_notenur": 50, "preprocessor": [28, 36, 38, 39, 40, 41, 42, 49, 50, 51, 53, 58], "preprocessor1": 43, "preprocessor2": 43, "preprocessor3": 43, "prereq": 52, "prerequisit": [2, 50, 59], "preschool": [39, 41, 42], "presenc": [17, 24, 36, 42, 50], "present": [7, 14, 21, 27, 29, 30, 33, 39, 46, 47, 48, 49, 50, 51, 52, 55, 57], "preserv": [39, 44], "pressure3pm": 49, "pressure9am": 49, "pretend": [13, 14, 21, 32, 33, 49], "pretrain": [47, 48, 53], "pretti": [13, 18, 20, 28, 32, 36, 37, 39, 41, 44, 47, 49, 50], "prevent": [38, 47, 50, 59], "previou": [12, 13, 19, 20, 26, 32, 40, 41, 44, 45, 49, 50, 51, 55], "previous": [46, 48, 49], "price": [8, 16, 18, 20, 23, 26, 28, 35, 37, 40, 42, 43, 50, 51, 57], "primari": [8, 15, 22, 29, 30, 34], "primarili": [12, 13, 19, 20, 32, 42, 48, 52], "prime": [12, 19, 31], "princ": 47, "princess": 47, "principl": [9, 11, 13, 32, 55], "print": [7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 57], "print_top": 47, "prior": [44, 49, 55], "priorit": [43, 55], "privaci": [0, 11, 44, 52], "privat": [7, 39, 41, 42], "privileg": 6, "prize": [17, 24, 36], "pro": [44, 48, 51], "prob": [18, 37, 41], "proba": 48, "probabilist": [2, 47], "probabl": [12, 15, 16, 19, 22, 23, 28, 29, 30, 31, 34, 35, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 55], "problem": [1, 4, 6, 11, 12, 17, 18, 19, 24, 26, 28, 30, 31, 36, 37, 39, 40, 41, 42, 44, 45, 47, 48, 50, 51, 54, 55, 57, 59], "problemat": [39, 42, 50], "probosci": [12, 19, 31, 48], "proce": [27, 59], "procedur": 41, "proceed": [14, 33], "process": [2, 5, 7, 11, 13, 15, 16, 17, 20, 22, 23, 24, 26, 27, 32, 34, 35, 36, 38, 43, 44, 45, 48, 51, 52, 53, 57], "procfil": 52, "prod": [17, 24, 36, 38], "produc": [2, 7, 20, 28, 30, 40, 42, 45, 50, 51, 55, 57], "product": [5, 30, 38, 46, 47, 51, 53], "prof": [39, 41, 42], "profession": [46, 52], "profil": 40, "profile_df": 46, "profilereport": 40, "profit": 51, "program": [0, 4, 9, 10, 12, 19, 31, 47, 59], "programm": 47, "progress": 44, "project": [10, 16, 23, 35, 41, 43, 48, 51, 52, 55, 59], "promin": 47, "promis": [12, 19, 26, 31, 47, 49, 52], "promot": 50, "prompt": [10, 12, 59], "pron": [47, 53], "prone": 38, "proper": [48, 56], "properli": [7, 12, 19, 50, 51], "properti": [13, 20, 32, 40, 42, 43], "prophet": 49, "propn": [47, 53], "proport": [11, 13, 14, 17, 18, 20, 21, 24, 32, 33, 36, 37, 39, 40, 41, 42, 51], "proportional_hazard_test": 50, "prostitut": 47, "protocol": 52, "prototyp": [52, 55], "prove": 39, "provid": [0, 5, 7, 10, 11, 13, 14, 17, 18, 20, 21, 24, 27, 32, 33, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 51, 55, 59], "provinc": [17, 24, 36, 47], "provinci": 47, "proxi": [14, 21, 33], "proxim": [18, 37, 47, 59], "prune": 43, "psychiatr": 30, "psychologi": [17, 24, 36, 55], "pt": [18, 37, 38, 48], "public": [0, 4, 7, 47, 53], "publish": [0, 1, 18, 37, 47], "puck": 47, "pud": 40, "pull": [10, 18, 37, 47], "punct": [47, 53], "punctuat": [17, 24, 36, 47], "punish": 51, "punkt": 53, "punkt_tab": 53, "purchas": [12, 19, 27, 31, 46, 52], "pure": [13, 20, 32, 49], "purpos": [0, 13, 14, 16, 20, 21, 23, 29, 30, 32, 33, 35, 46, 47, 49, 52, 55, 56, 57, 59], "pursuit": 51, "push": [7, 42], "put": [7, 8, 10, 13, 14, 16, 17, 21, 23, 24, 27, 28, 29, 30, 32, 33, 35, 36, 43, 44, 45, 46, 52], "px": [43, 47], "py": [13, 17, 20, 23, 24, 27, 28, 32, 33, 35, 36, 38, 41, 42, 44, 45, 50, 52, 53, 54], "pybo": 38, "pydata": 43, "pyplot": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 55, 56, 57, 58], "pysurviv": 50, "python": [1, 3, 4, 11, 31, 38, 40, 46, 47, 48, 49, 50, 51, 52, 53, 59], "python3": [9, 17, 20, 24, 27, 28, 32, 33, 36, 38, 42, 50, 54], "pythonwarn": 40, "pytorch": [12, 19, 31, 48], "pyviz": 39, "q": 1, "qualit": 28, "qualiti": [39, 42, 44, 45, 51], "quantifi": 39, "quantil": 28, "quantit": 28, "quebecoi": 28, "queen": 47, "queen_consort": 47, "queri": [16, 23, 27, 35, 39, 41, 44, 46, 47, 49, 50, 59], "query_img": 27, "query_point": [15, 22, 34], "quest": 43, "question": [1, 6, 7, 59], "queuepredictor": 52, "quick": [4, 12, 19, 47, 52, 59], "quickli": [13, 15, 16, 20, 22, 23, 32, 34, 35, 38, 45, 50, 55, 59], "quickstart": 9, "quirk": [14, 21, 33], "quit": [6, 12, 13, 16, 20, 23, 27, 30, 31, 32, 35, 38, 39, 40, 42, 43, 45, 47, 48, 49, 50, 51, 53], "quiz": [1, 12, 16, 19, 47, 59], "quiz1": [13, 14, 17, 20, 21, 24, 32, 33, 36, 55], "quiz2": [14, 17, 21, 24, 33, 36, 55], "quizz": [13, 15, 17, 20, 32], "r": [11, 13, 17, 18, 20, 24, 29, 30, 32, 36, 37, 39, 49, 51], "r1": 41, "r2": [26, 40, 41, 55, 57], "r2_score": [40, 43], "r4": 41, "race": [17, 36, 39, 41, 42, 59], "radial": [15, 22, 34], "radiu": [43, 45], "rail": 48, "rain": 49, "rain_df": 49, "rain_df_modifi": 49, "rainfal": 49, "rainfall_lag1": 49, "rainfall_lag2": 49, "rainfall_lag3": 49, "raintodai": 49, "raintoday_miss": 49, "raintoday_no": 49, "raintoday_y": 49, "raintomorrow": 49, "rais": [6, 17, 19, 24, 28, 36, 39, 49, 50], "rand": [8, 41], "randint": 38, "randn": [18, 37, 43], "random": [6, 8, 11, 14, 15, 18, 21, 22, 27, 33, 34, 37, 39, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55], "random_forest_data": 41, "random_search": 38, "random_st": [12, 15, 16, 18, 19, 22, 23, 26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58], "randomforestclassifi": [42, 43, 49, 51], "randomforestclassifierrandomforestclassifi": 41, "randomforestregressor": [40, 41, 42, 43, 49, 50, 51, 52], "randomhorizontalflip": 48, "randomizedsearchcv": [15, 22, 34, 41, 42, 51], "randomizedsearchcvifittedrandomizedsearchcv": 38, "randomli": [14, 18, 21, 33, 37, 38, 39, 41, 50], "randomoversampl": 39, "randomresizedcrop": 48, "randomst": [43, 45], "randomundersampl": 39, "rang": [4, 8, 11, 14, 15, 16, 17, 18, 21, 22, 23, 24, 28, 33, 34, 35, 36, 37, 41, 44, 46, 47, 48, 49, 50, 51, 53], "rangeindex": [17, 24, 36, 43, 49, 50], "rank": [39, 43, 46, 47, 50], "rank_test_mape_scor": 40, "rank_test_neg_mean_squared_error": 40, "rank_test_scor": [38, 40], "ranking_": 43, "rare": [17, 36, 39, 40, 44, 47, 55], "rate": [12, 18, 19, 31, 37, 39, 41, 44, 50, 51, 55], "rated_item": 46, "rather": [12, 17, 19, 24, 28, 30, 31, 36, 38, 39, 40, 41, 42, 44, 47, 48, 59], "ratings_df": 46, "ratio": [39, 41, 47, 50], "ravel": [27, 29, 30, 39, 55], "raw": [8, 17, 24, 36, 39, 42, 43, 47, 48, 51, 54], "raw_model_output": [18, 37], "raw_scor": 42, "rbf": [1, 14, 16, 18, 21, 23, 33, 35, 37, 38, 41, 42, 43, 51, 52, 55, 57], "rcparam": [12, 13, 14, 19, 20, 21, 31, 32, 33, 39, 44, 45, 46, 48, 49, 50, 51, 56], "re": [4, 7, 8, 10, 12, 13, 14, 17, 19, 20, 21, 24, 29, 30, 31, 32, 33, 36, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 52, 55, 56], "reach": [1, 6, 44, 59], "read": [1, 4, 7, 12, 15, 16, 17, 19, 22, 23, 24, 27, 34, 35, 36, 39, 40, 41, 42, 47, 49, 51, 52], "read_csv": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58], "read_excel": 8, "read_html": 8, "read_img_dataset": 27, "read_json": 8, "readabl": [0, 8], "reader": 11, "readi": [7, 12, 14, 15, 16, 18, 21, 22, 23, 33, 34, 35, 37], "readlin": 48, "readm": 50, "readthedoc": 50, "real": [14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 28, 33, 34, 35, 36, 37, 39, 42, 44, 45, 46, 47, 48, 51, 53, 55], "realdonaldtrump": 53, "realism": 30, "realist": [16, 23, 35, 49, 52], "realiti": [14, 21, 33, 40, 50], "realiz": 51, "realli": [8, 14, 18, 21, 30, 33, 37, 38, 41, 43, 45, 46, 48, 49, 50, 52], "reanim": 30, "reason": [0, 2, 4, 8, 11, 14, 16, 21, 23, 30, 33, 35, 38, 39, 40, 42, 44, 46, 47, 49, 50, 51, 52, 55, 59], "rec": [40, 42, 51], "recal": [11, 13, 14, 15, 16, 17, 18, 21, 23, 24, 28, 32, 33, 34, 35, 36, 37, 40, 44, 49, 52, 55], "recall_lr": 39, "recall_scor": 39, "recall_svc": 39, "receiv": [6, 7, 17, 19, 24, 36, 45, 48, 49, 52], "recent": [8, 10, 12, 17, 19, 24, 28, 31, 36, 43, 46, 47, 49, 50], "recip": [14, 21, 33], "recogn": [11, 14, 21, 30, 33, 45, 49, 51, 59], "recognit": [12, 13, 15, 19, 31, 32, 34, 39, 47, 59], "recommend": [1, 2, 4, 8, 10, 11, 14, 15, 21, 27, 29, 30, 31, 33, 34, 38, 39, 44, 47, 48, 51, 52], "record": [13, 20, 32, 50], "rectangular": 44, "recurr": 49, "recurs": 11, "red": [13, 15, 20, 22, 32, 34, 39, 42, 43, 44, 49], "redbon": 38, "redefin": 50, "redistribut": 0, "reduc": [7, 8, 12, 15, 19, 22, 31, 34, 38, 39, 40, 41, 42, 43, 46, 47, 48, 54, 57, 59], "reduct": [2, 39, 41, 43, 44], "redund": [18, 37, 42], "ref": [39, 50], "refer": [8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 32, 33, 34, 35, 36, 37, 39, 42, 44, 46, 47, 48, 57, 59], "referenc": 59, "referenti": 47, "refin": [15, 22, 27, 34, 57], "refit": 40, "reflect": [15, 22, 34, 40, 42, 47, 57, 59], "reflection_period": [39, 52], "refus": 30, "reg": [13, 20, 32, 41], "reg_model": [13, 20, 32], "regard": 59, "regardless": 7, "regex": 47, "regim": 52, "region": [13, 20, 32, 39, 45, 49, 52, 54], "region_data": 49, "regist": [12, 19, 52, 59], "registered_nurs": 47, "regrad": [6, 19], "regress": [1, 2, 11, 12, 16, 17, 19, 23, 24, 26, 29, 30, 31, 35, 36, 42, 43, 46, 49, 50, 51, 52, 53, 54, 55, 57], "regression_df": [13, 20, 32], "regressor": [13, 16, 17, 20, 23, 24, 26, 28, 32, 35, 36, 40, 49], "regular": [15, 17, 18, 22, 24, 34, 36, 37, 41, 47, 49, 50, 51, 55], "regularli": 30, "regulatori": 42, "reinforc": [12, 19, 31, 44], "reject": 39, "rel": [18, 21, 28, 37, 42, 45, 47, 53, 54], "rel_char_len": 53, "relabel": 44, "relat": [2, 6, 10, 12, 18, 19, 30, 31, 37, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 53, 59], "relationship": [11, 39, 41, 42, 43, 47, 49, 51, 53, 55, 56, 57, 59], "relationship_husband": 42, "relationship_own": 42, "releas": [1, 7, 14, 15, 16, 17], "relev": [1, 4, 8, 11, 13, 15, 16, 20, 22, 23, 32, 34, 35, 38, 42, 49, 59], "reli": [14, 15, 21, 22, 27, 33, 34, 43, 45, 46, 49, 57], "reliabl": [12, 19, 21, 31, 44], "religi": 47, "remain": [5, 40, 43, 46, 49, 51], "remaind": 6, "rememb": [7, 15, 17, 19, 22, 24, 29, 30, 34, 36, 38, 39, 42, 43, 45, 48, 49, 50, 56, 57], "remind": 56, "remix": 0, "remov": [7, 16, 23, 27, 35, 39, 41, 42, 43, 47, 48, 50, 54], "renam": [12, 19, 31, 39, 42, 49, 52], "render": [4, 7, 12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 31, 35, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 51, 53], "rent": 49, "rental": [49, 52], "rentals_df": 49, "rentals_lag5": 49, "rentals_lag5_i": 49, "rentals_lag5_x": 49, "rentals_model": 49, "repair": [39, 41, 42], "repeat": [8, 43, 44, 45, 48, 52], "repeatedli": 6, "repetit": 30, "rephras": 51, "replac": [12, 16, 19, 23, 28, 29, 30, 31, 35, 39, 41, 42, 46, 50], "replace_tag": [29, 30], "replic": 52, "repo": [1, 39, 52], "report": [6, 13, 20, 32, 38, 40, 43, 49, 53], "repositori": [0, 1, 5, 10, 12, 18, 19, 27, 28, 37, 39, 52, 59], "repres": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 32, 33, 34, 35, 36, 37, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55], "represent": [12, 13, 16, 19, 20, 23, 26, 27, 28, 29, 30, 31, 32, 35, 38, 39, 40, 41, 42, 43, 44, 45, 47, 51, 52, 53, 55], "reproduc": [4, 14, 21, 33, 38, 41, 52, 59], "republ": 42, "request": [6, 19, 47, 59], "requir": [5, 7, 15, 16, 22, 23, 27, 28, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 55, 57, 59], "rerun": [12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 31, 35, 36, 38, 39, 40, 41, 42, 43, 48, 51, 53], "res_mean": [14, 21, 33], "resampl": 39, "research": [12, 14, 19, 21, 31, 33, 38, 46, 47, 52], "reserv": [49, 59], "reset": 28, "reset_index": [12, 19, 31], "reshap": [8, 18, 28, 37, 38, 48, 49], "reshape_transform": 28, "resid": [18, 37], "residu": 41, "resiz": [27, 48], "resnet": 48, "resolut": 47, "resolv": 59, "resort": [18, 37], "resourc": [1, 3, 5, 32, 41, 42, 47, 48, 52, 55], "respect": [18, 37, 38, 39, 41, 42], "respons": [4, 7, 13, 20, 30, 32, 44, 47, 51, 59], "rest": [18, 30, 37, 38, 48, 50, 52, 55], "restart": [7, 10], "restaur": [28, 46, 52], "restaurant_df": 28, "restaurant_nam": 28, "restrict": [0, 40, 41, 47], "resubmit": 19, "result": [1, 2, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 52, 53, 57, 59], "result_block": 50, "result_img": 48, "results_df": [14, 15, 18, 21, 22, 26, 27, 29, 30, 33, 34, 37, 57], "results_dict": [14, 15, 16, 21, 22, 23, 27, 33, 34, 35, 36, 38], "results_single_valid_df": [26, 57], "retail": [53, 55], "retail_df": 49, "retail_df_test": 49, "retail_df_train": 49, "retail_lag_5": 49, "retail_model": 49, "retail_test_5": 49, "retail_test_5_pr": 49, "retail_train_5": 49, "retail_train_5_d": 49, "retail_train_5_i": 49, "retail_train_5_x": 49, "retent": 50, "retrain": [38, 52], "return": [5, 8, 10, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57], "return_gener": [17, 24, 36], "return_predict": 52, "return_train_scor": [14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 49, 50, 53, 57], "reus": [39, 59], "revenu": 46, "revers": [17, 24, 36, 40], "review": [1, 4, 18, 37, 44, 51, 53, 55, 59], "review_pp": [29, 30], "revisit": [39, 55], "revok": 0, "reward": [12, 17, 19, 24, 31, 36, 44], "rf": [49, 50], "rf_imp_df": 42, "rfe_cv": 43, "rfe_pip": 43, "rfecv": 43, "rgb": [12, 19, 31], "rhode_island": 47, "rich": [42, 47, 50, 51, 55], "richard": [30, 51], "rico": 42, "rid": [10, 17, 24, 28, 36, 41, 42, 47, 50], "ridg": [42, 43, 46, 49, 50, 51, 52], "ridge__alpha": 40, "ridge_pr": 40, "ridge_tun": 40, "ridgecv": 43, "ridgecv_pip": 40, "ridgeridg": [40, 43], "rifl": 30, "right": [0, 1, 11, 12, 18, 19, 26, 28, 30, 31, 37, 38, 39, 40, 43, 44, 45, 46, 47, 51, 52, 55], "rightarrow": [13, 15, 18, 22, 32, 34, 37, 39, 40, 41, 44, 45, 46, 47, 51, 52, 55], "rindfleischetikettierungs\u00fcberwachungsaufgaben\u00fcbertragungsgesetz": 47, "ring": 30, "rip": 30, "rise": [43, 47], "risk": [1, 39, 43, 51, 57], "riti": [19, 20, 21, 22, 23, 24, 59], "river": [18, 37], "rl": [40, 42, 51], "rmse": [46, 55], "rng": [43, 45], "rnn": 49, "ro": 39, "roast": 44, "robot": [46, 47], "robust": [12, 14, 15, 16, 19, 21, 22, 23, 28, 31, 33, 34, 35, 38, 41, 45, 57], "robustscal": 28, "roc": [11, 52, 55], "roc_auc": 39, "roc_auc_scor": 39, "roc_curv": 39, "roc_lr": 39, "roc_svc": 39, "roccurvedisplai": 39, "rock": 30, "rodolfo": 38, "rodr\u00edguez": 47, "roger": [30, 43], "role": [18, 30, 37, 38, 42, 48], "roman": 46, "romanc": 46, "romant": 46, "ronald": [18, 37], "roof": 42, "roofmatl": [40, 42, 51], "roofmatl_clytil": [40, 42], "roofmatl_compshg": [40, 42], "roofmatl_membran": 40, "roofmatl_met": 40, "roofmatl_rol": 40, "roofmatl_tar": 40, "roofmatl_wdshak": 40, "roofmatl_wdshngl": [40, 42], "roofstyl": [40, 42, 51], "roofstyle_flat": 40, "roofstyle_g": 40, "roofstyle_gambrel": 40, "roofstyle_hip": 40, "roofstyle_mansard": 40, "roofstyle_sh": 40, "room": [12, 13, 18, 19, 20, 28, 31, 32, 37, 40, 43, 52, 53, 59], "rooms_per_household": [16, 23, 35, 36, 43, 58], "rooms_per_household_0": 43, "rooms_per_household_1": 43, "rooms_per_household_10": 43, "rooms_per_household_11": 43, "rooms_per_household_12": 43, "rooms_per_household_13": 43, "rooms_per_household_14": 43, "rooms_per_household_15": 43, "rooms_per_household_16": 43, "rooms_per_household_17": 43, "rooms_per_household_18": 43, "rooms_per_household_19": 43, "rooms_per_household_2": 43, "rooms_per_household_3": 43, "rooms_per_household_4": 43, "rooms_per_household_5": 43, "rooms_per_household_6": 43, "rooms_per_household_7": 43, "rooms_per_household_8": 43, "rooms_per_household_9": 43, "root": [10, 13, 15, 20, 22, 27, 32, 34, 46, 48, 55], "rose": 47, "rostin": [1, 59], "rotat": 49, "roth": [1, 59], "rough": 4, "roughli": [5, 14, 33, 47, 52, 55], "round": [8, 15, 16, 22, 23, 27, 34, 35, 38, 39, 41, 45, 48, 57], "rout": [5, 13, 20, 32, 49], "row": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 59], "rry": 47, "rsh": 38, "ru": [8, 39], "rubric": [18, 19, 37], "rule": [1, 8, 12, 13, 15, 18, 19, 20, 26, 29, 30, 31, 32, 34, 37, 39, 41, 47, 52, 55, 57], "run": [1, 4, 5, 7, 10, 12, 14, 15, 17, 19, 21, 24, 27, 30, 31, 33, 34, 36, 38, 39, 40, 42, 44, 45, 47, 48, 52, 53, 54, 56, 57], "runtimewarn": 38, "ruscorpora": 47, "rush": 43, "russel": 1, "rv": 38, "rv_continuous_frozen": 38, "rv_discrete_frozen": 38, "rvert_2": 47, "s1": [8, 47], "s19": [16, 23, 35], "s2": [8, 47], "s_lag": 49, "sa": 1, "sabr": 47, "sabrina": 1, "sadli": 47, "safe": [16, 23, 35], "safeti": 48, "sai": [8, 13, 15, 16, 17, 20, 22, 23, 24, 30, 32, 34, 35, 36, 39, 40, 41, 42, 47, 49, 51, 55], "said": [14, 16, 18, 21, 23, 33, 35, 37, 42, 45, 46, 47, 51], "sal": [40, 42, 51], "sale": [8, 26, 39, 40, 49, 51, 57], "salecondit": [40, 42, 51], "salecondition_abnorml": 40, "salecondition_adjland": 40, "salecondition_alloca": 40, "salecondition_famili": 40, "salecondition_norm": 40, "salecondition_parti": 40, "salepric": [40, 42, 51], "sales_data": 49, "salesforc": 53, "saleswoman": 47, "saletyp": [40, 42, 51], "saletype_cod": 40, "saletype_con": 40, "saletype_conld": 40, "saletype_conli": 40, "saletype_conlw": 40, "saletype_cwd": 40, "saletype_new": 40, "saletype_oth": 40, "saletype_wd": 40, "salt": [18, 37, 42], "sam": 46, "same": [6, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57], "samosa": 47, "sampl": [12, 13, 15, 16, 18, 20, 21, 22, 23, 27, 28, 32, 34, 35, 37, 38, 42, 45, 48, 49, 50, 51, 52, 56, 57], "sample_df": [39, 52], "sample_text": 53, "sampling_strategi": 39, "samuel": [12, 19, 31], "sand": 48, "sandbar": 48, "saniti": [13, 20, 32, 50], "sarafian": 30, "sarah": 1, "sat": 49, "satisfactori": 44, "satisfi": 44, "satur": 51, "saturdai": 49, "sauc": 28, "save": [7, 8, 17, 24, 30, 36, 38, 42, 47, 48, 49, 51, 53, 58], "saw": [16, 18, 23, 35, 37, 38, 39, 45, 55], "sb": 43, "scalabl": [12, 19, 31, 45], "scalar": 8, "scale": [14, 15, 17, 21, 22, 24, 26, 27, 33, 34, 36, 38, 39, 40, 41, 43, 45, 48, 50, 51, 52, 55, 57, 58], "scale_pos_weight": 41, "scaler": [16, 23, 28, 35, 42, 43], "scan": 55, "scari": 52, "scatter": [16, 23, 35, 40, 42, 43], "scatter_3d": 43, "scatterplot": [43, 52], "scc": 47, "scenario": [11, 14, 17, 21, 24, 33, 36, 41, 42, 43, 45, 49, 50, 52, 55], "scene": 30, "schafer": 52, "schedul": [50, 55, 59], "schmidt": 38, "school": [12, 19, 31, 39, 41, 42, 46], "schoolteach": 47, "scienc": [1, 2, 9, 10, 11, 17, 24, 36, 44, 49, 51, 55, 57], "scientif": [46, 47], "scientist": [1, 9, 45], "scikit": [9, 10, 11, 13, 15, 18, 20, 22, 28, 32, 34, 37, 38, 39, 41, 44, 45, 48, 49, 51, 53, 54], "scipi": [10, 38, 45, 47], "scm": 5, "scope": [12, 19, 47, 49], "score": [11, 12, 15, 16, 17, 19, 22, 23, 24, 26, 27, 28, 29, 30, 31, 34, 35, 36, 41, 42, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59], "score_func": 40, "score_gb_test": 51, "score_gb_train": 51, "score_lr_print_coeff": 49, "score_param": [17, 24, 36], "score_rf_test": 51, "score_rf_train": 51, "score_tim": [14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 28, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 49, 50, 53], "scorer": [17, 24, 36, 40], "scores_dict": [18, 29, 30, 37], "scores_imag": [18, 37], "scoring_method": 50, "scoring_metr": [41, 42, 53], "scotland": 47, "scott": 51, "scratch": [2, 48, 52], "screen": [7, 29, 30], "screennam": 53, "screenplai": 47, "screenporch": [40, 42, 51], "screenshot": 51, "script": [10, 30], "scroog": 53, "sdng": [40, 51], "se": [49, 50], "sea": 48, "seaborn": [42, 43, 44, 45, 46], "seacoast": 48, "search": [4, 5, 10, 40, 47, 55], "search_multi": 40, "seashor": 48, "season_autumn": 49, "season_fal": 49, "season_summ": 49, "season_wint": 49, "seat": [48, 59], "seattl": 53, "seawal": 48, "second": [4, 6, 13, 18, 19, 20, 30, 32, 37, 41, 42, 45, 48, 49, 51], "secondari": [12, 19, 31], "secpompeo": 53, "section": [1, 7, 10, 14, 20, 32, 33, 43, 59], "secur": [42, 52, 59], "see": [1, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 55, 56, 57, 59], "seed": [18, 27, 37, 38, 44, 45, 52], "seem": [13, 15, 16, 17, 18, 20, 22, 23, 24, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 49, 50, 53, 54, 57], "seemingli": 39, "seen": [8, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 30, 31, 33, 34, 35, 36, 37, 43, 45, 46, 50, 55, 57], "segment": [11, 39, 47, 48, 50, 52, 55], "segmentspher": 52, "select": [1, 5, 6, 10, 11, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 33, 34, 35, 36, 37, 38, 39, 40, 41, 48, 49, 50, 51, 52], "select_dtyp": 40, "select_knn": 43, "select_rf": 43, "select_svc": 43, "selectfrommodel": 43, "self": [12, 17, 19, 24, 28, 31, 36, 50, 59], "sell": [0, 8, 13, 20, 32, 51], "semant": [11, 44, 45, 47], "semest": [12, 19, 59], "semi": [1, 12, 47], "semicolon": 8, "semilogx": 40, "send": [4, 12, 19, 31], "senior": 50, "seniorcitizen": 50, "sens": [6, 14, 17, 18, 21, 24, 29, 30, 33, 36, 37, 39, 40, 42, 43, 44, 46, 47, 49, 50, 52, 54], "sensibl": [7, 52], "sensit": [14, 16, 21, 23, 33, 35, 38, 39, 40, 44, 50], "sent": [12, 19, 31, 47], "sent_token": 47, "sentenc": [47, 51], "sentiment": [13, 18, 29, 30, 32, 37, 47, 53], "sentimentintensityanalyz": 53, "sepal": [15, 22, 27, 34, 57], "separ": [13, 14, 16, 17, 18, 20, 21, 23, 24, 28, 32, 33, 35, 36, 37, 39, 43, 44, 46, 47, 49, 54, 55, 56, 57, 58], "septemb": 49, "sequel": 30, "sequenc": [14, 17, 21, 24, 33, 36, 48, 49], "sequenti": [13, 20, 32, 41, 49, 50, 55], "sequentialfeatureselector": 43, "ser": [23, 33, 35, 50, 53], "seri": [1, 2, 11, 14, 16, 17, 21, 23, 24, 33, 35, 36, 39, 43, 48, 50, 52, 53], "serial": 41, "seriou": [6, 39, 46, 47, 50, 52, 59], "serv": [5, 11, 13, 20, 30, 32, 42, 59], "server": 5, "servic": [28, 41, 42, 46, 50, 53], "session": [12, 13, 44, 55, 59], "set": [1, 7, 8, 9, 13, 15, 16, 17, 18, 20, 22, 23, 24, 27, 30, 31, 32, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 57, 58], "set_config": [38, 41], "set_index": [14, 15, 21, 22, 27, 33, 34, 38, 39, 40], "set_opt": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 45, 46, 56, 57, 58], "set_properti": [12, 19, 31], "set_se": 27, "set_titl": [15, 18, 22, 27, 34, 37, 39, 48, 57], "set_xlabel": [15, 18, 22, 27, 34, 37, 44, 57], "set_ylabel": [15, 18, 22, 27, 34, 37, 44, 57], "setup": [3, 7, 10, 12, 19, 56], "sev": [40, 42, 51], "sever": [10, 16, 18, 23, 30, 35, 37, 44, 45, 47, 48, 49, 54, 59], "sex": [39, 41, 42, 43], "sexual": 59, "sfu": 47, "shall": [0, 47], "shallow": [29, 30, 41], "shan": 47, "shap": 52, "shape": [13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57], "shape_df": [14, 21, 33], "shape_dict": [14, 21, 33], "share": [0, 28, 43, 52, 59], "sharealik": 1, "sharex": [16, 23, 35], "she": [12, 19, 30, 31, 46, 47, 53], "shed": [40, 42, 51], "sheet": [9, 52, 55], "shelf": [41, 47], "shell": [5, 9, 12, 19], "shelv": 53, "shift": 49, "shipyard": 28, "shit": 53, "shng": [40, 51], "shock": 30, "shoot": 30, "shop": 46, "short": [1, 10, 14, 33, 38, 41, 47, 59], "shorter": 50, "shorthand": [16, 23, 35], "shortli": 52, "shot": [30, 43], "should": [5, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 42, 43, 44, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59], "shouldn": [39, 41, 47, 57], "show": [4, 7, 10, 12, 14, 16, 17, 19, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 36, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57], "show_nearest_neighbor": 27, "show_plot": 50, "showcas": 47, "shown": [7, 10, 12, 13, 15, 19, 20, 22, 31, 32, 34, 39, 41, 44, 45, 49, 51], "shrink": [38, 43, 51], "shuffl": [14, 21, 27, 30, 33, 48, 49], "si": [12, 19, 31], "sibl": 43, "sick": [44, 53], "sid": 53, "side": [6, 48, 51], "sift": 46, "sigma": 48, "sign": [4, 29, 30, 40, 42, 48, 57, 59], "signal": [14, 21, 33, 47], "signific": [11, 16, 23, 28, 35, 48, 51], "significantli": [17, 24, 36, 39, 46], "sigoptsearchcv": 38, "silhouett": 45, "silhouettevisu": [44, 45], "sim": 42, "sim_word": 47, "simard": 42, "similar": [1, 10, 13, 14, 17, 18, 19, 20, 21, 24, 27, 32, 33, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 50, 51, 54], "similarity_": 47, "similarli": [42, 44, 50], "simon_fras": 47, "simp": 49, "simpl": [1, 13, 15, 16, 20, 22, 23, 32, 34, 35, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 55, 56], "simplefilt": [41, 42], "simpleimput": [16, 17, 18, 23, 24, 35, 36, 37, 38, 39, 40, 41, 42, 43, 49, 50, 51, 55, 58], "simpleimputersimpleimput": [16, 17, 23, 24, 28, 35, 36, 40, 41, 43, 51], "simpler": [18, 26, 37, 38, 52, 57], "simplest": [17, 24, 36], "simpli": [16, 23, 30, 35, 43, 44, 47], "simplic": [13, 17, 20, 24, 32, 36, 46], "simplist": [15, 22, 27, 30, 34, 42, 57], "simul": 43, "sin": 8, "sinc": [5, 12, 18, 19, 27, 30, 37, 40, 42, 43, 44, 46, 48, 49, 50, 51, 54, 55, 56], "singer_songwriter_bob_dylan": 47, "singl": [8, 15, 16, 18, 22, 23, 27, 34, 35, 37, 38, 39, 41, 42, 45, 49, 50, 55, 56, 57], "sit": [28, 30, 59], "sitarist_ravi_shankar": 47, "site": [5, 12, 17, 20, 24, 27, 28, 32, 33, 36, 38, 42, 50, 54, 59], "situat": [6, 12, 19, 30, 31, 39, 41, 44, 48, 50, 59], "six": [14, 33, 41, 49, 52], "size": [12, 13, 14, 15, 17, 19, 20, 21, 22, 24, 27, 31, 32, 33, 34, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57, 59], "skeleton": 51, "skeptic": 51, "skew": 40, "skill": [11, 41, 52], "skin": 53, "skip_check_arrai": 28, "skip_parameter_valid": 28, "skipna": 50, "sklearn": [1, 12, 14, 15, 18, 19, 21, 22, 26, 27, 29, 30, 31, 33, 34, 37, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], "sklearn_gb": 41, "sklearn_histgb": 41, "sktime": 49, "skyblu": 49, "skyscrap": 49, "sl": 47, "slice": 8, "slide": [1, 9, 16, 23, 25, 35, 48, 59], "slightli": [17, 18, 24, 27, 28, 36, 37, 39, 41, 50], "slipper": 51, "slope": [18, 37], "sloppi": [16, 23, 35], "slot": 59, "slow": [15, 22, 30, 34, 41, 43, 48], "slower": [30, 41, 44], "sm": [12, 17, 19, 24, 31, 36], "smac": 38, "small": [10, 14, 15, 17, 21, 22, 24, 27, 28, 33, 34, 36, 38, 40, 41, 42, 43, 44, 46, 48, 50, 55, 57], "small_citi": [15, 22, 34], "small_train_df": [15, 22, 34], "smallalpha_coeff": 40, "smaller": [15, 16, 17, 18, 22, 23, 24, 26, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 49, 50, 51, 57], "smallest": [18, 37, 40, 44, 45], "smart": [44, 51, 53], "smile": 53, "smooth": [15, 22, 34, 57], "smoothli": 10, "smote_pip": 39, "sms_df": [12, 19, 31], "sn": [42, 44, 45], "snake": [18, 37, 48], "snake_length": [18, 37], "snakes_df": [18, 37], "snbf": 41, "snippet": [7, 12, 19], "snow": [12, 19, 31, 48], "snp": 43, "so": [0, 1, 4, 5, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59], "soap": 30, "social": [44, 45, 46, 49], "societ": 11, "societi": [39, 47], "sofist": 57, "soft": [18, 28, 37, 41], "softmax": 55, "softwar": [1, 5, 10, 50], "solar": 46, "sold": [8, 40], "sole": [39, 45], "solid": 30, "solidifi": 55, "solut": [12, 14, 19, 20, 21, 31, 32, 33, 41, 44, 50, 51, 52, 55, 59], "solv": [4, 12, 13, 15, 19, 20, 21, 22, 31, 32, 34, 43, 47, 51, 52, 57, 59], "solver": 39, "some": [4, 6, 7, 8, 10, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 56, 57, 58, 59], "someon": [12, 13, 14, 19, 20, 21, 30, 31, 32, 33, 43, 50, 51], "someth": [4, 7, 10, 13, 17, 20, 24, 30, 32, 36, 39, 40, 41, 42, 44, 49, 50, 51, 52, 55, 59], "sometim": [6, 13, 14, 17, 18, 20, 21, 24, 30, 32, 33, 36, 37, 38, 41, 42, 47, 51, 52], "somewhat": [30, 40], "somewher": [12, 19, 31, 40], "song": [15, 16, 23, 34, 35, 46, 53], "song_titl": [15, 16, 23, 34, 35, 38], "soon": [12, 15, 16, 19, 22, 23, 30, 31, 34, 35, 49, 52], "sopha": [12, 19, 31], "sophist": [38, 42, 47], "sorri": 30, "sort": [1, 5, 13, 14, 16, 21, 23, 29, 30, 32, 33, 35, 42, 46, 47, 48, 49, 52], "sort_index": [8, 38, 40, 49], "sort_valu": [16, 17, 18, 23, 24, 26, 29, 30, 35, 36, 37, 38, 40, 41, 42, 43, 49, 50, 53], "sound": [30, 42, 43], "soundtrack": 47, "sourc": [10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 28, 31, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 46, 47, 48, 53, 56, 59], "south": [17, 36], "space": [15, 18, 20, 22, 34, 37, 38, 43, 44, 45, 47, 53, 59], "spaci": 43, "spacymoji": 53, "spam": [14, 21, 33, 39, 44], "spam_predict": [12, 19, 31], "span": [47, 49], "spanish": [16, 23, 35], "spars": [12, 15, 18, 19, 22, 28, 30, 34, 37, 41, 46, 47, 55], "sparse_output": [16, 17, 23, 24, 28, 35, 36, 39, 40, 41, 42, 49, 50, 51, 55], "spatial": [18, 37], "speak": [5, 30, 52], "spearmint": 38, "speci": [15, 22, 27, 34, 55, 57], "special": [11, 12, 17, 19, 24, 30, 31, 36, 46, 47, 48, 49, 50, 57], "specialti": [39, 41, 42], "specif": [8, 11, 13, 14, 20, 21, 28, 32, 33, 38, 39, 42, 44, 46, 47, 48, 49, 50, 51, 52, 55, 57], "specifi": [8, 13, 14, 17, 20, 21, 24, 27, 32, 33, 36, 38, 39, 44, 45, 48, 51, 52], "spectrogram": 43, "speech": [43, 47, 53], "speechi": [15, 16, 23, 34, 35, 38], "speed": [8, 13, 20, 29, 30, 32, 41, 48, 52], "spell": [12, 19, 31], "spend": [12, 16, 19, 23, 28, 30, 31, 35, 43, 51, 53, 59], "spent": [6, 16, 23, 35, 43], "spheric": [45, 55], "spici": 44, "spini": 48, "spit": 48, "split": [11, 13, 15, 17, 18, 20, 22, 24, 29, 30, 32, 34, 36, 37, 38, 40, 41, 43, 46, 47, 50, 52, 53, 55], "split0_test_r2": 40, "split0_test_scor": 38, "split0_train_neg_mean_squared_error": 40, "split0_train_scor": 38, "split1_test_r2": 40, "split1_test_scor": 38, "split1_train_neg_mean_squared_error": 40, "split1_train_scor": 38, "split2_test_r2": 40, "split2_test_scor": 38, "split2_train_neg_mean_squared_error": 40, "split2_train_scor": 38, "split3_test_r2": 40, "split3_test_scor": 38, "split3_train_neg_mean_squared_error": 40, "split3_train_scor": 38, "split4_test_scor": 38, "split4_train_neg_mean_squared_error": 40, "split4_train_scor": 38, "spoil": 30, "spoken": [17, 24, 36], "sport": [47, 48, 49], "spot": [39, 40, 52, 57], "spotifi": [15, 34, 46], "spotify_df": [15, 16, 23, 34, 35, 38], "spotlight": [5, 10], "spous": [39, 41, 42], "spread": [30, 45], "spring": 30, "spring_month": 49, "sqft": 42, "sqft_abov": [12, 13, 19, 26, 31, 32], "sqft_basement": [12, 13, 19, 26, 31, 32], "sqft_live": [12, 13, 19, 26, 31, 32], "sqft_living15": [12, 13, 19, 26, 31, 32], "sqft_lot": [12, 13, 19, 26, 31, 32], "sqft_lot15": [12, 13, 19, 26, 31, 32], "sqrt": [15, 22, 34, 40, 42, 46, 47], "squar": [8, 11, 13, 15, 18, 20, 22, 32, 34, 37, 42, 46, 50, 51, 53, 55], "squash": [18, 37, 48], "squeez": [8, 28, 50], "src": [21, 33, 39], "sse": 49, "ssw": 49, "st": [49, 53], "stabil": 10, "stabl": [14, 21, 28, 33, 39, 41, 57], "stack": [7, 11, 28, 52, 55], "stacking_model": 41, "stacking_model_tre": 41, "stackingclassifi": 41, "stackingregressor": 41, "staff": 6, "stai": [12, 19, 39, 50], "stakehold": [11, 51, 52], "stale": 44, "stand": [15, 22, 30, 34, 38, 47, 52], "standard": [4, 6, 14, 16, 21, 23, 33, 35, 38, 41, 42, 43, 47, 52], "standardscal": [17, 18, 24, 28, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51, 53, 55, 58], "standardscalerstandardscal": [16, 17, 23, 24, 28, 35, 36, 38, 39, 40, 41, 43, 48, 51, 53], "stanford": 47, "star": [15, 22, 34, 44, 46, 53], "start": [7, 8, 10, 13, 14, 15, 20, 21, 22, 27, 28, 30, 32, 33, 34, 39, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58], "startswith": 42, "starttim": 49, "stat": [38, 50], "state": [6, 8, 14, 21, 33, 39, 41, 42, 46, 47, 52, 53], "statement": [7, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 33, 34, 35, 36, 37, 38, 39, 40, 43, 48, 50, 51], "static": [12, 19, 52], "station": [30, 49], "statist": [1, 9, 11, 13, 18, 20, 32, 37, 42, 46, 47, 50], "statistician": [15, 22, 34], "statlib": [18, 37], "statsmodel": [49, 50], "statu": [39, 41, 42], "status_marri": 42, "status_nev": 42, "std": [14, 15, 16, 21, 22, 23, 26, 27, 28, 33, 34, 35, 39, 40, 48, 49, 53, 54], "std_cv_error": [14, 21, 33], "std_cv_score": [15, 22, 27, 34], "std_fit_tim": [38, 40], "std_score": [14, 16, 21, 23, 33, 35, 53], "std_score_tim": [38, 40], "std_test_neg_mean_squared_error": 40, "std_test_scor": [14, 21, 33, 38], "std_train_error": [14, 21, 33], "std_train_neg_mean_squared_error": 40, "std_train_scor": [14, 15, 21, 22, 27, 33, 34, 38], "stdki": 50, "steal": 30, "stem": 47, "step": [7, 12, 14, 15, 16, 17, 21, 22, 23, 24, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 55, 56, 57, 59], "stereotyp": 47, "steroid": 30, "stick": [13, 29, 30, 49], "still": [4, 10, 20, 30, 38, 39, 40, 41, 43, 44, 49, 50, 53, 57, 58], "stipul": 51, "stochast": [43, 44], "stock": [12, 19, 31, 49], "stomach": 30, "stop": [8, 26, 28, 30, 44, 47, 48, 50, 57], "stop_word": [28, 29, 30, 38, 39, 47, 52, 53], "stopword": 47, "storag": [15, 34], "store": [7, 8, 15, 16, 17, 22, 23, 24, 30, 34, 35, 36, 38, 39, 41, 42, 45, 46, 47, 48, 49, 50, 52, 53], "stori": [30, 40, 41, 53], "storylin": 47, "str": [27, 38, 42, 47, 49, 50, 53], "straight": [30, 50, 52], "straightforward": 42, "strain": 7, "strang": [42, 50], "strata": 50, "strategi": [13, 15, 16, 17, 20, 22, 23, 24, 28, 32, 34, 35, 36, 39, 40, 42, 44, 46, 49, 50, 51, 52, 55, 56], "stratif": 50, "stratifi": 50, "stratifiedkfold": [14, 21, 33, 39], "stream": 50, "streamingmovi": 50, "streamingmovies_no": 50, "streamingmovies_y": 50, "streamingtv": 50, "streamingtv_no": 50, "streamingtv_y": 50, "street": [40, 42, 51], "street_grvl": 40, "street_pav": 40, "strength": [47, 55], "stress": 44, "strftime": [49, 50], "string": [8, 10, 15, 22, 28, 34, 39, 40, 41, 42, 47, 49, 50, 57], "strip": [42, 48], "stroke": 30, "strong": [41, 50, 55], "stronger": 41, "strongli": 41, "struck": 30, "structur": [8, 44, 47, 48], "struggl": [44, 49], "stuart": [1, 41], "stuck": [4, 8], "student": [1, 4, 5, 6, 7, 11, 12, 13, 18, 19, 20, 31, 32, 37, 39, 40, 42, 43, 44, 45, 46, 48, 52, 53, 59], "studi": [12, 17, 19, 24, 31, 36, 43, 47, 50], "stuff": [15, 22, 27, 30, 34, 48, 50], "stump": [13, 14, 15, 20, 21, 22, 26, 32, 33, 34, 41, 56], "stun": 30, "stunningli": 30, "stupid": [30, 53], "style": [31, 40, 43, 44, 46, 47, 48, 52, 53], "sub": [29, 30, 38, 44, 47, 50, 52, 55], "subdirectori": [42, 52], "subgroup": 50, "subject": [0, 1, 50, 59], "sublicens": 0, "submiss": [3, 59], "submit": [1, 8, 16, 19, 52, 59], "subplot": [14, 15, 18, 21, 22, 27, 33, 34, 37, 39, 44, 48, 50, 51, 57], "subplot_kw": [14, 21, 27, 33], "subprocess": 40, "subscrib": 50, "subscript": [49, 50], "subset": [13, 14, 20, 21, 27, 32, 33, 38, 41, 48, 49, 54, 57], "substanti": 0, "substitut": 0, "subtl": 47, "subtleti": [14, 21, 33, 40], "subtract": [15, 19, 22, 34, 39, 42], "suburb": 53, "subword": 47, "succe": [30, 43, 59], "success": [5, 8, 10, 12, 19, 31, 39, 41, 46, 47, 48, 49, 52], "successfulli": [10, 12, 19, 31, 53], "suddenl": 30, "suddenli": 30, "sudo": 5, "suei": 38, "suffer": [30, 38], "suffici": [7, 47], "suggest": [0, 1, 13, 20, 29, 30, 32, 46, 50, 52], "suicid": 47, "suit": [23, 30, 46], "suitabl": [10, 11, 12, 19, 26, 31, 44, 46, 52, 55], "sultan": 47, "sum": [8, 15, 16, 17, 18, 22, 23, 24, 28, 34, 35, 36, 37, 41, 42, 44, 48, 53], "sum_": [15, 22, 34, 40, 44, 47, 48], "sum_i": [42, 47], "sum_prob_ex1_class_0": 41, "sum_prob_ex1_class_1": 41, "summar": [1, 12, 18, 19, 31, 37, 39, 40, 44, 47, 52], "summari": [0, 54, 55, 57], "summary_plot": 42, "summat": [41, 51], "summer": [30, 46, 49], "summer_month": 49, "sun": [47, 49], "sundai": 49, "sundial": 48, "sunshin": 49, "sunstrum": [1, 59], "super": [17, 24, 36, 55], "superfici": [15, 22, 34], "superior": 11, "supermarket": 53, "supervis": [11, 16, 17, 23, 24, 28, 35, 36, 38, 39, 40, 43, 45, 47, 49, 50, 55, 59], "suppli": 59, "support": [10, 13, 16, 20, 23, 27, 28, 32, 35, 39, 41, 42, 43, 45, 47, 51, 53, 54, 57, 59], "support_": [15, 22, 34, 43], "suppos": [12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 51, 55, 56], "suppress": 8, "suprem": 47, "supr\u00eam": 47, "sure": [4, 7, 8, 10, 13, 14, 15, 16, 17, 22, 24, 33, 34, 36, 39, 40, 41, 42, 45, 48, 49, 51, 52, 57, 59], "surfac": 20, "surgeri": 50, "surpris": [30, 42, 46], "surprisingli": [17, 18, 24, 36, 37], "surround": [4, 11, 30, 51], "survei": [28, 44], "surviv": [1, 2, 11, 51, 52], "survival_function_": 50, "suscept": [45, 52], "suspect": 38, "suspens": 30, "svc": [15, 16, 17, 18, 22, 23, 24, 27, 28, 34, 35, 36, 37, 38, 41, 42, 43, 48, 57, 58], "svc__c": 38, "svc__gamma": 38, "svc_pipe": 38, "svc_pred": 39, "svcsvc": [17, 24, 36, 38, 39], "svm": [1, 14, 16, 17, 21, 23, 24, 28, 33, 35, 36, 38, 41, 42, 43, 48, 49, 51, 52, 54, 55, 57, 58], "svm_estim": 39, "svr": [15, 22, 34, 36, 42, 51], "svr_c_pipe": 36, "svr_pipe": 36, "sw": 49, "swai": [12, 31], "swamp": [15, 22, 34], "swan": 48, "swcarpentri": 9, "sweep": 39, "sweet": [30, 53], "switch": [13, 42, 44, 49, 50, 51], "swng": [1, 59], "sy": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 55, 56, 57, 58], "sydnei": 49, "syllabu": [3, 7, 12, 13, 15, 16, 17, 19], "symbol": [20, 32], "symmetri": 43, "sync": 5, "synonym": 47, "synopsi": 47, "syntact": 47, "syntax": [4, 8, 12, 19, 31, 43, 50], "synthet": [43, 54], "system": [1, 2, 4, 5, 6, 10, 11, 12, 14, 15, 17, 19, 21, 27, 31, 33, 34, 36, 39, 42, 44, 49, 51, 52], "systemat": [13, 20, 32, 36, 38, 42, 47], "t": [1, 4, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57], "t2a": 59, "t2b": 59, "t2c": 59, "t2d": 59, "t2e": 59, "t2f": 59, "t2g": 59, "t2h": 59, "t2i": 59, "t2j": 59, "t2k": 59, "ta": [7, 12, 19, 31, 40, 42, 51, 52, 56, 57, 58], "tab": [12, 19], "tabbi": [12, 19, 31, 48], "tabl": [7, 28], "tabular": [8, 12, 19, 27, 31, 48, 49], "tackl": [14, 16, 21, 23, 33, 35, 39, 45, 57], "taco": 43, "tag": [4, 47, 53], "tail": [8, 49], "tailor": [11, 44, 51, 52], "take": [2, 4, 5, 6, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59], "taken": [49, 54, 59], "talk": [13, 14, 16, 18, 20, 21, 23, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 59], "tall": 47, "target": [14, 15, 16, 18, 21, 22, 23, 27, 28, 29, 30, 33, 34, 35, 37, 38, 39, 41, 42, 43, 46, 48, 49, 50, 51, 52, 55, 57, 58], "target_column": [41, 42, 50], "target_nam": 39, "target_names_toi": 39, "target_tag": 28, "tariff": 47, "task": [11, 16, 17, 18, 23, 24, 26, 27, 35, 36, 37, 38, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 55], "tast": [28, 44, 46], "tasti": 28, "taught": [17, 24, 36, 47, 59], "tax": 51, "tba": 1, "teach": [4, 12, 16, 19, 23, 31, 35, 47, 55], "team": [4, 8, 12, 19, 31, 41, 42, 47], "tech": [15, 34, 39, 42], "technic": [30, 51, 52, 59], "techniqu": [1, 11, 12, 15, 22, 30, 34, 38, 43, 46, 48, 50, 52, 54, 55], "technolog": 0, "technologi": 47, "techsupport": 50, "techsupport_no": 50, "techsupport_y": 50, "ted": 44, "tediou": 45, "telco": 50, "telecom": 50, "telephon": 47, "tell": [14, 15, 16, 18, 21, 23, 30, 33, 34, 35, 37, 39, 42, 43, 46, 47, 49, 50, 51, 52, 57], "temp3pm": 49, "temp9am": 49, "temperatur": [13, 20, 32], "templat": 52, "tempo": [15, 16, 23, 34, 35, 38], "tempor": [50, 55], "tend": [14, 15, 18, 21, 22, 33, 34, 37, 41, 43, 46, 49, 50, 59], "tendenc": [14, 21, 33], "tensor": [27, 48], "tensorflow": [10, 42, 48], "tent": 12, "tenur": [50, 51, 55], "tenure_lm": 50, "tenure_predict": 50, "term": [0, 2, 13, 15, 17, 18, 20, 22, 24, 32, 34, 36, 37, 39, 42, 43, 46, 47, 50, 51, 52, 55], "termin": [5, 10, 13, 32, 44, 52], "terminologi": [14, 33, 39, 55, 56], "terrac": 48, "terribl": [30, 40, 46], "terribli": 30, "territori": 59, "tesoro": 38, "test": [1, 7, 8, 10, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 45, 50, 51, 52, 54, 55, 57, 59], "test_accuraci": 39, "test_average_precis": 39, "test_df": [12, 16, 18, 19, 23, 29, 30, 31, 35, 36, 37, 39, 40, 41, 42, 43, 49, 50, 51, 52, 53, 58], "test_df_churn": 50, "test_df_nan": [39, 41, 42], "test_df_sort": 49, "test_df_surv": 50, "test_exampl": 41, "test_f1": 39, "test_format": [15, 22, 34], "test_g50k": 41, "test_idx": 27, "test_imag": [12, 19, 31, 48], "test_l50k": 41, "test_mape_scor": 40, "test_nam": 50, "test_neg_mean_squared_error": 40, "test_neg_root_mean_square_error": 40, "test_point": [15, 22, 34, 54], "test_precis": 39, "test_r2": 40, "test_recal": 39, "test_roc_auc": 39, "test_scor": [14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 49, 50, 53, 57], "test_shap_valu": 42, "test_siz": [12, 15, 16, 18, 19, 22, 23, 26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 48, 49, 51, 52, 53, 54, 57, 58], "test_sklearn": 40, "test_statist": 50, "test_x": 50, "testabl": 19, "text": [1, 7, 11, 12, 13, 18, 19, 20, 23, 29, 30, 31, 32, 37, 38, 39, 40, 41, 42, 43, 46, 48, 51, 52, 55], "text_feat": 38, "text_featur": 53, "text_pip": 28, "text_pp": 47, "text_transform": 28, "textbook": [3, 9, 51], "textrm": [14, 21, 33], "textual": 11, "textur": 43, "tf": [17, 24, 36], "tfidfvector": [18, 29, 30, 37], "th": [12, 18, 19, 37, 46], "thai": 28, "than": [6, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 54, 56, 57, 59], "thank": [12, 19, 30, 31, 47, 57], "thankfulli": 49, "theater": 30, "thei": [1, 7, 8, 13, 14, 15, 18, 19, 20, 21, 22, 28, 30, 32, 33, 34, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 59], "theirs": 47, "them": [1, 2, 4, 7, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 59], "theme": 47, "themselv": [30, 44, 45, 47], "theoret": [16, 23, 35, 39, 41, 55], "theori": 42, "thepopbreak": 53, "therefor": [19, 30, 57], "thermostat": [13, 20, 32], "thi": [0, 1, 2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 18, 20, 21, 22, 27, 29, 30, 32, 33, 34, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 59], "thick": [28, 30, 44], "thicker": 30, "thin": 30, "thing": [1, 5, 7, 8, 12, 13, 14, 15, 19, 20, 21, 22, 29, 30, 32, 33, 34, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 57], "think": [4, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 28, 30, 31, 32, 33, 34, 36, 37, 39, 40, 42, 43, 44, 46, 48, 49, 50, 51, 52, 55, 56, 57], "third": 45, "thk": [12, 19, 31], "thorough": 10, "thoroughli": 55, "those": [5, 8, 10, 11, 12, 16, 19, 23, 35, 40, 41, 42, 46, 47, 50, 51, 52, 59], "though": [14, 17, 18, 20, 21, 24, 28, 30, 33, 36, 37, 44, 45, 46, 52, 53], "thought": [4, 15, 22, 30, 34, 42, 50, 55], "thousand": [18, 37, 45, 46], "thrasher": 47, "threahold": 43, "threaten": 53, "three": [8, 13, 16, 18, 23, 27, 32, 35, 37, 39, 41, 42, 43, 44, 45, 47, 48, 49, 54, 55, 59], "thresh": 8, "threshold": [13, 18, 20, 32, 37, 41, 43, 45, 47, 50], "thresholds_lr": 39, "thresholds_svc": 39, "through": [1, 7, 10, 12, 13, 19, 20, 30, 32, 39, 40, 43, 45, 46, 47, 48, 51, 59], "throughout": [14, 21, 30, 33, 51], "throught": [19, 59], "throw": [17, 24, 36, 48, 50, 51, 55], "thu": [1, 6, 12, 38, 49, 50, 59], "thumb": [13, 20, 32, 53], "thursdai": [12, 59], "ti": [17, 24, 36], "tianyu": [1, 59], "tick": 49, "tick_label": 42, "tick_param": 44, "tiffin": 47, "tiger": [12, 19, 31, 48], "tight": [15, 22, 27, 34, 45, 57], "tight_layout": [48, 51], "tightrop": [15, 22, 27, 34, 57], "tile": 42, "till": [15, 22, 34, 47, 50], "timber": 47, "time": [1, 2, 4, 8, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 59], "time_diff": 49, "time_signatur": [15, 16, 23, 34, 35, 38], "timedelta": 49, "timeit": [8, 54], "timelin": 51, "timeseri": [48, 49], "timeseriessplit": [49, 50, 55], "timestamp": 49, "timezon": [1, 50], "tinder": 46, "tini": [7, 14, 21, 33, 39, 45], "tip": 47, "tire": 53, "titan": 46, "titi": [12, 19, 31], "titl": [7, 14, 15, 18, 21, 22, 26, 27, 30, 33, 34, 37, 40, 43, 45, 48, 49, 50, 51, 57], "tldr": [12, 19], "tmp": 28, "tn": 39, "to_datetim": [26, 49], "to_html": [12, 13, 14, 19, 21, 31, 32, 33], "to_notebook_ifram": 40, "to_numpi": [15, 22, 34, 46, 49], "to_str": [12, 19, 31, 48], "toarrai": [17, 24, 29, 30, 36, 42, 49], "tobago": [41, 42], "todai": [13, 20, 32, 46, 48, 49, 50, 52, 55], "todens": [42, 43], "togeth": [5, 8, 12, 13, 15, 16, 17, 19, 20, 22, 23, 24, 28, 32, 34, 35, 36, 44, 47, 57], "toi": [8, 14, 15, 21, 22, 33, 34, 43, 44, 45, 46, 49, 55], "toilet": [48, 53], "token": [7, 19, 53, 59], "token_pattern": [17, 24, 36], "tol": [39, 43, 51], "told": [5, 59], "tolist": [12, 13, 14, 17, 18, 19, 20, 21, 24, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 46, 49, 50, 53], "tom": 30, "tomasbeuzen": 8, "tomorrow": [13, 16, 17, 20, 32, 49, 50, 55], "ton": [30, 38], "tone": 53, "too": [6, 7, 14, 15, 17, 21, 22, 23, 24, 27, 30, 33, 34, 36, 38, 40, 41, 42, 47, 49, 50, 51, 52, 57, 59], "took": [30, 49], "tool": [1, 7, 8, 10, 11, 17, 18, 24, 29, 30, 36, 37, 39, 40, 42, 45, 46, 48, 49, 50, 52, 55, 59], "toolbox": [15, 22, 34, 41, 47], "toolkit": 47, "top": [13, 17, 20, 24, 29, 30, 32, 36, 38, 39, 45, 49, 51, 52], "topi": 47, "topic": [1, 2, 8, 11, 13, 20, 32, 39, 40, 44, 46, 48, 52, 55, 59], "topic2vec": 47, "topics_per_chunk": 47, "topn": [12, 19, 31, 48], "torch": [27, 48], "torchvis": [12, 19, 27, 31, 48], "toronto": [47, 51, 53], "tort": 0, "total": [1, 8, 13, 16, 17, 20, 23, 24, 32, 35, 36, 39, 40, 41, 42, 43, 47, 49, 50, 51], "total_bedroom": [16, 23, 35, 36, 43, 58], "total_bilirubin": [12, 19, 31], "total_protien": [12, 19, 31], "total_room": [16, 23, 35, 36, 43, 58], "total_second": 49, "totalbsmtsf": [40, 42, 51], "totalcharg": 50, "totem": 48, "totensor": [27, 48], "toti": [0, 1, 47, 59], "totrmsabvgrd": [40, 42, 51], "touch": 52, "toward": [18, 29, 30, 37, 42, 47, 59], "towardsdatasci": [48, 50], "town": 53, "townsvil": 49, "toy_clust": 47, "toy_clust_df": 44, "toy_df": [17, 24, 36, 47], "toy_lda_data": 47, "toy_movie_feat": 46, "toy_rat": 46, "toy_spam": [17, 24, 36], "toy_x": 47, "tp": 39, "tpot": 38, "tpr": 39, "tpr_lr": 39, "tpr_svc": 39, "tr_score": [26, 57], "traceback": [4, 8, 17, 24, 28, 36, 50], "track": [1, 17, 24, 36, 52, 59], "trade": [11, 18, 37, 39, 43, 44, 55], "tradeoff": [15, 16, 18, 22, 23, 26, 34, 35, 37, 40, 43, 44, 48], "tradit": [12, 19, 31, 46, 48, 50, 59], "tradition": 59, "trail": 8, "train": [7, 15, 16, 22, 23, 26, 27, 28, 29, 30, 34, 35, 38, 40, 41, 42, 43, 44, 46, 47, 50, 53, 54, 55, 56, 57, 58], "train_accuraci": 39, "train_dataload": 48, "train_df": [12, 16, 18, 19, 23, 29, 30, 31, 35, 36, 37, 39, 40, 41, 42, 43, 49, 50, 51, 52, 53, 58], "train_df_churn": 50, "train_df_nan": [39, 41, 42], "train_df_ord": 49, "train_df_sort": 49, "train_df_surv": 50, "train_df_surv_not_churn": 50, "train_dir": 27, "train_f1": 39, "train_flatten": 48, "train_for_usr": 46, "train_load": 48, "train_mape_scor": 40, "train_mat": 46, "train_mat_imp": 46, "train_neg_mean_squared_error": 40, "train_neg_root_mean_square_error": 40, "train_precis": 39, "train_r2": 40, "train_recal": 39, "train_scor": [14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 49, 50, 53, 57], "train_shap_valu": 42, "train_sklearn": 40, "train_test_split": [12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58], "train_x": 46, "transact": [13, 20, 32, 39, 49, 51], "transfer": [50, 52], "transfer_learning_tutori": 48, "transform": [0, 15, 22, 27, 28, 29, 30, 34, 38, 39, 41, 42, 45, 47, 48, 49, 50, 52, 53, 55, 57, 58], "transformed_exampl": 41, "transformed_oh": [16, 23, 35], "transformedtargetregressor": [40, 43, 51, 55], "transformedtargetregressortransformedtargetregressor": 40, "translat": [1, 9, 12, 19, 31], "transpar": [39, 55], "transpos": [27, 43, 48], "trasform": [16, 23, 35], "trash": 56, "traumat": 59, "treat": [8, 16, 17, 23, 24, 33, 35, 36, 39, 40, 46, 49, 50, 51, 53, 55], "treati": 59, "treatment": [17, 24, 36], "tree": [1, 2, 14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 29, 30, 33, 34, 35, 36, 37, 38, 40, 43, 45, 48, 49, 50, 52, 54, 55, 56, 58], "tree1": 41, "tree2": 41, "tree3": 41, "tree_numeric_transform": 42, "treeexplain": 42, "trend": [11, 50, 55], "tri": [20, 30, 41, 42, 51, 54], "trial": [38, 50], "triangl": [15, 22, 34, 44], "trick": [5, 40], "tricki": [17, 24, 36, 38, 42, 46], "trigger": [15, 22, 34], "trigram": 47, "trivial": 45, "troubl": [10, 30], "true": [8, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 57], "truli": [40, 47], "truncat": 45, "truncate_mod": 45, "truncation_mod": 45, "trust": [12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 31, 35, 36, 38, 39, 40, 41, 42, 43, 46, 48, 51, 53], "trustworthi": 45, "truth": [41, 43, 44, 45, 46, 49], "try": [1, 4, 5, 8, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 55, 56, 57, 59], "tsa": 49, "tscv": 49, "tslearn": 49, "tsunami": [12, 31], "ttr": 40, "ttr_pipe": 40, "tue": [1, 12, 13, 49, 59], "tuesdai": [1, 12, 19, 43, 49, 59], "tuggeranong": 49, "tumor": 55, "tune": [14, 21, 26, 33, 38, 41, 45, 46, 48, 51, 52], "turn": [4, 14, 21, 27, 30, 33, 47, 48, 50, 58, 59], "tusker": 48, "tutori": [1, 4, 5, 9, 10, 12, 19, 46, 48, 52, 55, 59], "tweak": [15, 22, 27, 34, 57], "tweet": [47, 53], "tweetat": 53, "twice": [8, 14, 17, 18, 24, 33, 36, 37], "twinx": 51, "twist": [30, 47], "twitter": 47, "twitter_allowed_char": 53, "two": [4, 6, 7, 8, 9, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 28, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 58, 59], "two_citi": [15, 22, 34], "two_song": [16, 23, 35], "two_songs_subset": [16, 23, 35], "tx": [18, 37, 53], "tx_i": 51, "txt": [12, 19, 31, 48, 52], "typ": [40, 42, 51], "type": [4, 8, 10, 11, 13, 15, 16, 17, 20, 23, 24, 28, 32, 34, 35, 36, 38, 41, 43, 45, 46, 47, 48, 52, 55, 57, 58], "typeerror": 50, "typic": [2, 7, 12, 13, 15, 16, 18, 19, 20, 22, 23, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 44, 46, 49, 51, 52], "u": [4, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 56, 57, 58], "u6": [13, 20, 32], "u_1": [15, 22, 34], "u_2": [15, 22, 34], "u_i": [15, 22, 34], "u_n": [15, 22, 34], "ubc": [0, 4, 5, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 56, 57, 58, 59], "ubc_img": 48, "ubc_okanagan": 47, "ubco": 47, "ubyssei": 47, "ucsb": 9, "ud036": 9, "udac": 9, "ufunc": 40, "ufv": 47, "uint8": 27, "ultim": [4, 14, 21, 33, 51], "ultralyt": 48, "uluru": 49, "umbrella": 46, "un": [40, 50], "unabl": [12, 16, 17, 19, 23, 24, 26, 27, 28, 30, 31, 35, 36, 38, 39, 40, 41, 42, 43, 45, 48, 50, 51, 53, 59], "unambigu": 47, "unassign": [44, 45], "unassum": 30, "unbias": 39, "unced": 59, "uncertain": [18, 37], "uncertainti": [18, 37, 39, 51, 52], "unchang": 42, "uncia": [12, 19, 31, 48], "uncomfort": 46, "uncorrel": 42, "undead": 30, "under": [0, 1, 7, 13, 14, 21, 28, 30, 32, 33, 40, 47, 48, 50, 52], "under_sampl": 39, "underestim": 50, "underfit": [15, 18, 22, 26, 27, 34, 37, 38, 48, 57], "underli": [2, 42, 43, 44], "underneath": 7, "underpredict": 40, "underr": 30, "undersample_pip": 39, "understand": [0, 1, 4, 7, 11, 12, 13, 14, 15, 17, 18, 19, 22, 24, 26, 27, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 56, 59], "understood": 39, "unemploi": 50, "unexpect": [17, 18, 24, 36, 37, 38, 47], "unexplain": 40, "unf": [40, 42, 51], "unfinish": 40, "unfortun": [6, 38, 42, 44, 45], "unfunni": 30, "uniform": [38, 39, 45], "unimport": [38, 42], "uninstal": 10, "unintent": 30, "uninterpret": 42, "unintuit": 8, "union": 8, "uniqu": [16, 17, 23, 24, 35, 36, 39, 40, 41, 42, 46, 47, 49, 50], "unit": [18, 28, 30, 37, 39, 40, 41, 42, 47, 48, 50, 53], "unitless": 40, "univers": [1, 9, 47], "university_year": [17, 24, 36, 55], "unix": [5, 49], "unknown": [6, 47, 55], "unlabel": [12, 14, 19, 21, 31, 33, 45], "unless": [7, 19, 59], "unlik": [8, 12, 14, 15, 17, 19, 21, 22, 24, 33, 34, 36, 40, 42, 44, 45], "unlimit": 49, "unlucki": [14, 21, 33], "unmarri": [41, 42], "unnam": [12, 19, 31], "uno": 28, "unoffici": 59, "unpredict": 30, "unqualifi": 39, "unreason": [6, 19, 40], "unrecogniz": [12, 19], "unreli": [14, 21, 33], "unrespond": [12, 19], "unscal": [16, 23, 35], "unseen": [13, 32, 43, 44, 48, 52, 57], "unsqueez": 48, "unstructur": 47, "unsupervis": [12, 19, 31, 46, 47, 48, 52, 59], "unsur": [7, 51], "until": [4, 13, 14, 20, 21, 32, 33, 38, 43, 44, 45, 47, 50, 51, 52], "unus": 57, "unusu": 28, "unwieldi": [13, 16, 20, 23, 32, 35], "unzip": [42, 53], "uoft": 47, "up": [7, 8, 13, 16, 17, 18, 20, 23, 24, 26, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 55, 56, 59], "uparrow": 45, "upcom": 44, "updat": [10, 15, 16, 17, 22, 23, 24, 27, 34, 35, 36, 41, 44, 57], "update_cent": 44, "update_plot": [15, 22, 27, 34, 57], "update_z": 44, "upei": 47, "upgrad": 47, "upload": 7, "upon": [0, 13, 14, 17, 20, 21, 24, 32, 33, 36, 39, 41, 42, 43, 44, 45, 47], "upper": [39, 50], "upperbound_pric": 28, "uppercas": 53, "upto": 49, "ur": [12, 19, 31], "urgent": [17, 24, 36, 47], "url": [4, 14, 21, 33, 39, 50, 52], "us": [0, 1, 2, 4, 5, 10, 11, 18, 26, 28, 29, 30, 37, 38, 42, 45, 46, 49, 50, 52, 53, 55, 57, 58], "usa": [8, 14, 15, 18, 21, 22, 33, 34, 37, 47], "usabl": 52, "usag": [16, 17, 23, 24, 35, 36, 39, 40, 43, 47, 49, 50], "usec_": 50, "useless": [38, 42, 43], "user": [10, 12, 16, 17, 19, 20, 23, 24, 27, 31, 32, 33, 35, 36, 38, 41, 42, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55], "user_id": 46, "user_inverse_mapp": 46, "user_kei": 46, "user_mapp": 46, "user_nam": 46, "usernam": 53, "userwarn": [17, 20, 24, 27, 32, 33, 36, 41, 42], "usf": [17, 24, 36], "using_copy_on_writ": [28, 50], "using_cow": 50, "usual": [1, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 59], "utc": [49, 50], "utcnow": 50, "util": [5, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 48, 50, 51, 55, 56, 57, 58], "utilities_allpub": 40, "utilities_nosewa": 40, "utility_mat": 46, "uvic": 47, "v": [1, 3, 7, 17, 18, 24, 26, 27, 36, 37, 45, 47, 49, 50, 51, 55], "v1": [12, 19, 31, 39], "v10": 39, "v11": 39, "v12": 39, "v13": 39, "v14": 39, "v15": 39, "v16": 39, "v17": 39, "v18": 39, "v19": 39, "v2": [12, 19, 31, 39], "v20": 39, "v21": 39, "v22": 39, "v23": 39, "v24": 39, "v25": 39, "v26": 39, "v27": 39, "v28": 39, "v3": 39, "v4": 39, "v5": 39, "v6": 39, "v7": 39, "v8": 39, "v9": 39, "v_1": [15, 22, 34], "v_2": [15, 22, 34], "v_i": [15, 22, 34], "v_n": [15, 22, 34], "vacat": [18, 37], "vaccin": [51, 53], "vada_pav": 47, "vader": 53, "vader_lexicon": 53, "vader_senti": 53, "vain": 38, "val": [46, 50], "valenc": [15, 16, 23, 34, 35, 38, 53], "valid": [1, 15, 17, 20, 22, 24, 27, 28, 29, 30, 32, 34, 36, 40, 41, 42, 43, 44, 46, 48, 50, 51, 52, 53, 55, 58], "valid_dataload": 48, "valid_dir": 27, "valid_flatten": 48, "valid_load": 48, "valid_mat": 46, "valid_sample_df": 41, "valid_sample_i": 41, "valid_sample_x": 41, "valid_scor": [26, 57], "valid_x": 46, "validate_data": 28, "validate_separ": 28, "valu": [7, 8, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], "valuabl": [11, 43, 45, 59], "value_count": [13, 17, 20, 24, 26, 28, 30, 32, 36, 39, 41, 42, 49, 50, 52, 53], "value_throttl": [15, 22, 27, 34, 57], "valueerror": [8, 16, 17, 23, 24, 28, 35, 36, 50], "values_format": 39, "vampir": 30, "vancouv": [47, 51], "vancouver_canuck": 47, "vanilla": [18, 37], "var": [23, 33, 35, 42, 53], "var_": 42, "varada": [0, 1, 20], "vari": [11, 13, 20, 32, 38, 41, 45, 50, 57], "variabl": [7, 8, 13, 16, 17, 18, 20, 23, 24, 26, 32, 35, 36, 37, 38, 40, 42, 43, 49, 50, 51, 57], "varianc": [40, 42, 45, 49, 57], "variant": [42, 45], "variat": [14, 18, 21, 33, 37, 39, 40, 43], "varieti": [12, 19, 31, 41, 47], "variou": [11, 12, 15, 19, 22, 27, 31, 34, 40, 42, 48, 49, 50, 51, 52, 55, 57], "vault": [14, 21, 33], "ve": [7, 8, 12, 14, 15, 19, 21, 22, 26, 27, 31, 33, 34, 39, 40, 42, 46, 47, 48, 49, 51, 52, 54], "vec": [17, 24, 29, 30, 36, 47, 48], "vec1": 47, "vec1_i": 47, "vec2": 47, "vec2_i": 47, "vec8": [17, 24, 36], "vec8_binari": [17, 24, 36], "vec_binari": [17, 24, 36], "vecom": 38, "vector": [13, 18, 20, 23, 27, 32, 37, 39, 46, 48, 51, 57], "verb": [47, 53], "verbos": [12, 19, 31, 39, 41, 42, 51], "veri": [2, 4, 5, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 57, 59], "versa": [40, 57], "version": [1, 4, 5, 7, 8, 10, 12, 18, 20, 23, 28, 30, 33, 35, 37, 38, 40, 42, 45, 47, 49, 50, 53, 54], "versu": 9, "vert": 42, "vertic": [13, 20, 32, 39, 49], "vgg": 48, "vgg16": [27, 48], "vgg16_weight": 48, "via": [4, 7, 10, 12, 19, 39, 43, 59], "vibe": 28, "vice": [40, 57], "victim": 30, "video": [1, 7, 8, 9, 10, 26, 46, 48, 50, 51, 52, 57, 59], "vietnames": [16, 23, 35], "view": [6, 7, 10, 12, 13, 19, 26, 31, 32, 42, 45, 48, 49, 50, 51], "viewpoint": 46, "vif": 42, "vikski": 47, "violat": [16, 17, 23, 24, 35, 36, 50, 52, 59], "virginia": 48, "viridi": 38, "vision": [1, 52, 54], "visit": [8, 59], "visual": [1, 11, 13, 14, 15, 17, 18, 20, 21, 22, 24, 26, 29, 30, 32, 33, 34, 36, 37, 39, 40, 41, 42, 44, 45, 48, 49, 50, 53, 55, 58], "visualize_coeffici": [29, 30], "viu": 47, "vivid": 30, "viz": 51, "voc": [39, 41, 42], "vocab": [29, 30, 47], "vocabulari": [17, 18, 24, 36, 37, 47], "vocabulary_": [17, 24, 36], "voic": [12, 19, 31], "volcano": [12, 31], "volum": 52, "vote": [15, 16, 22, 23, 34, 35, 41, 54], "voting_ndt": 41, "votingclassifi": 41, "votingclassifierinot": 41, "votingregressor": 41, "vulner": 30, "vyfj": [31, 32, 36, 37, 38, 39, 40, 41], "w": [10, 17, 18, 24, 36, 37, 40, 44, 47, 49, 51, 52], "w_0": [18, 37], "w_1": [18, 37], "w_1x_1": [18, 37], "w_2x_2": [18, 37], "w_3x_3": [18, 37], "w_4x_4": [18, 37], "w_d": [18, 37], "w_dx_d": [18, 37], "w_j": [18, 29, 30, 37], "wa": [4, 5, 10, 14, 16, 17, 18, 19, 20, 21, 23, 27, 28, 29, 30, 32, 33, 35, 37, 39, 41, 42, 46, 47, 48, 50, 51, 53, 54, 56, 57, 59], "wa_fn": 50, "wai": [0, 2, 6, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 57, 59], "wait": [4, 12, 15, 17, 19, 20, 22, 24, 31, 32, 34, 36, 50, 52, 59], "waitlist": [13, 59], "walk": [15, 22, 27, 34, 39, 52, 57], "walker": [12, 19, 31, 48], "wallabi": 48, "wang": [1, 59], "want": [4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 27, 28, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 58, 59], "war": 46, "ward": 45, "warm": [16, 23, 35], "warm_start": [39, 51], "warn": [6, 12, 15, 17, 19, 21, 22, 24, 27, 33, 34, 36, 40, 41, 42, 50, 54], "warranti": 0, "washington": 53, "washroom": 59, "wasn": [28, 30, 47], "wast": [4, 17, 24, 30, 36, 51], "watch": [1, 10, 12, 15, 18, 19, 30, 34, 37, 46, 47, 55], "watchfil": 27, "water": 51, "waterfal": 42, "waterfront": [12, 13, 19, 26, 31, 32], "wavelet": 43, "waxwork": 30, "wb": 52, "wd": [40, 42, 51], "we": [1, 4, 5, 6, 7, 10, 12, 13, 15, 19, 20, 22, 27, 28, 29, 30, 31, 32, 34, 45, 47, 48, 49, 53, 54, 55, 56, 57, 58, 59], "weak": [30, 55], "weather": [13, 20, 32, 49, 52], "weatherau": 49, "web": [5, 12, 19, 47, 55], "web_api": 52, "web_appl": 52, "weblog": 47, "websit": [4, 10], "wed": 49, "wednesdai": [49, 59], "week": [1, 6, 14, 15, 16, 17, 19, 22, 23, 24, 33, 34, 35, 36, 39, 40, 41, 42, 46, 47, 49, 51, 59], "weekdai": 49, "weekend": [8, 30, 49, 51], "weekli": [12, 53], "weight": [15, 19, 22, 27, 34, 41, 43, 46, 47, 48, 59], "weighted_averag": 39, "weinberg": 42, "weird": 40, "welcom": [56, 59], "well": [4, 5, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 55, 59], "wellyanto": [1, 59], "welsh": [12, 19, 31, 48], "went": [40, 53], "were": [0, 6, 12, 18, 19, 28, 36, 37, 39, 40, 47, 48, 49, 50, 51, 59], "weren": 47, "what": [7, 8, 9, 13, 15, 20, 22, 26, 27, 28, 29, 30, 32, 34, 38, 45, 48, 49, 53, 54, 55, 56, 57, 58, 59], "whatev": 43, "whatsoev": 30, "when": [4, 6, 7, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 56, 58, 59], "wher": 53, "where": [0, 1, 7, 10, 13, 14, 15, 18, 20, 21, 22, 23, 27, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 51, 52, 55, 57], "wherea": [2, 13, 18, 20, 28, 32, 37, 38, 40, 42, 45, 51], "whether": [0, 4, 7, 8, 13, 14, 16, 17, 18, 20, 21, 23, 24, 28, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 45, 47, 49, 50, 52, 53, 56, 59], "which": [4, 6, 8, 10, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "whichev": 41, "while": [14, 18, 20, 21, 23, 30, 32, 33, 37, 38, 39, 41, 42, 44, 46, 47, 50, 53], "white": [30, 39, 41, 42, 45, 47], "whitespac": [47, 50], "who": [4, 5, 6, 12, 19, 30, 31, 39, 42, 44, 45, 47, 49, 50, 51, 52, 53, 55, 59], "whole": [14, 21, 30, 33, 38, 40, 42, 46, 52], "whom": [0, 47, 53], "whose": 4, "why": [8, 14, 15, 20, 22, 26, 28, 30, 33, 34, 39, 40, 41, 44, 45, 47, 49, 50, 55, 56, 57, 58], "wid": [39, 52], "wide": [10, 18, 37, 38, 41, 43, 46, 48, 51], "wider": [15, 22, 27, 34, 57], "widespread": 47, "widget": [15, 22, 27, 34, 39, 44, 45, 57], "width": [13, 14, 15, 20, 21, 22, 27, 32, 33, 34, 39, 47, 56, 57], "wife": [12, 30, 31, 39, 41, 42], "wiki": [47, 51], "wiki_df": 47, "wiki_dict": 47, "wikipedia": [47, 48, 51], "wikipedia2vec": 47, "wild": [12, 14, 19, 21, 27, 31, 33, 48], "willing": 39, "win": [15, 17, 22, 24, 29, 30, 34, 36, 41, 42, 43, 46, 54], "wind": [13, 20, 32], "winddir3pm": 49, "winddir3pm_miss": 49, "winddir3pm_ss": 49, "winddir3pm_ssw": 49, "winddir3pm_sw": 49, "winddir3pm_w": 49, "winddir3pm_wnw": 49, "winddir3pm_wsw": 49, "winddir9am": 49, "windgustdir": 49, "windgustspe": 49, "window": 50, "windsor": 53, "windspeed3pm": 49, "windspeed9am": 49, "wine_1": 8, "winter": 49, "winter_month": 49, "wire": 46, "wisdom": 41, "wish": [12, 13, 19, 20, 30, 31, 32, 44, 51, 59], "within": [13, 16, 18, 20, 23, 27, 30, 32, 35, 37, 41, 43, 44, 45, 50, 52, 55], "without": [0, 7, 12, 13, 19, 20, 31, 32, 39, 41, 42, 43, 46, 48, 49, 50, 51, 52, 59], "wnw": 49, "wolf": 30, "wolv": 45, "woman": [30, 47], "wombat": 48, "won": [5, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 32, 33, 34, 36, 37, 43, 46, 47, 48, 49, 50, 52, 53], "wonder": [12, 14, 19, 30, 31, 33], "wooddecksf": [40, 42, 51], "word": [11, 12, 18, 19, 26, 28, 29, 30, 31, 37, 38, 39, 43, 44, 45, 46, 48, 49, 50, 51, 55, 59], "word1": 47, "word2": 47, "word2vec": [11, 47, 48], "word3": 47, "word_coeff_df": [29, 30], "word_pair": 47, "word_token": [47, 53], "wordnet": 47, "wordnetlemmat": 47, "words_in_ex": [29, 30], "work": [0, 4, 5, 7, 8, 10, 12, 15, 16, 17, 18, 19, 22, 23, 24, 28, 30, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 55, 59], "workclass": [39, 41, 42], "workclass_feder": [41, 42], "workclass_loc": [41, 42], "workclass_miss": 42, "workclass_nev": [41, 42], "workclass_priv": [41, 42], "workclass_self": 42, "workclass_st": 42, "workclass_without": 42, "workflow": [13, 20, 32, 52, 59], "worksheet": 52, "world": [15, 16, 17, 18, 21, 22, 23, 24, 30, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 55], "worm": 48, "worri": [12, 19, 31, 44, 45, 46], "wors": [13, 20, 32, 38, 40, 41, 50, 56], "worst": [30, 39, 43, 44], "worth": [13, 15, 20, 22, 32, 34, 39, 40], "worthi": [18, 37], "would": [4, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 57, 58, 59], "wouldn": [17, 24, 36, 38, 47, 50], "wound": 30, "wow": 42, "wrangl": 28, "wrap": [17, 24, 36], "wrapper": [28, 43], "write": [4, 7, 11, 12, 19, 31, 38, 42, 43, 44, 47, 51, 52, 53, 57, 59], "writer": 30, "written": [7, 17, 24, 30, 36, 42, 49, 51], "wrong": [10, 14, 18, 21, 28, 30, 33, 37, 40, 43, 44, 50, 51], "wrote": [47, 49], "wsw": 49, "wtf": 52, "www": [9, 18, 37], "x": [4, 8, 10, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 33, 34, 35, 36, 37, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57], "x0": 43, "x0_male": 39, "x1": [43, 46], "x1x2": 43, "x2": [43, 45, 46], "x27": [16, 17, 23, 24, 28, 30, 35, 36, 38, 39, 40, 41, 43, 48, 51, 53], "x_": [18, 29, 30, 37], "x_1": [18, 37, 43, 44], "x_1x_2": 43, "x_2": [18, 37, 43, 44], "x_anim_train": 27, "x_anim_valid": 27, "x_binari": [13, 20, 32], "x_citi": [15, 22, 34], "x_count": [17, 24, 36], "x_d": [18, 37], "x_femal": 39, "x_hour": 49, "x_hour_week": 49, "x_hour_week_onehot": 49, "x_hour_week_onehot_poli": 49, "x_hour_week_onehot_poly_lag": 49, "x_i": [18, 37, 46], "x_imp_ohe_train": [16, 23, 35], "x_init": 44, "x_int": [17, 24, 36], "x_label": [13, 14, 15, 20, 21, 22, 32, 33, 34, 56], "x_lag_featur": 49, "x_lag_features_imp": 49, "x_male": 39, "x_mask": [17, 24, 36], "x_multi": 54, "x_n": 43, "x_orig": 45, "x_re": 39, "x_small_citi": [15, 22, 34], "x_spotifi": [15, 34, 38], "x_subset": [13, 14, 20, 21, 32, 33], "x_test": [12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 48, 49, 50, 51, 53, 54, 57, 58], "x_test_big": 38, "x_test_cat": 28, "x_test_cat_oh": 28, "x_test_enc": [42, 49, 50, 51], "x_test_happi": [39, 52], "x_test_imp": [16, 23, 35], "x_test_multi": 54, "x_test_num": 28, "x_test_num_imp": 28, "x_test_num_imp_sc": 28, "x_test_pr": 49, "x_test_predict": [16, 23, 35], "x_test_scal": [16, 23, 35], "x_test_transform": [16, 23, 35], "x_toi": [15, 16, 17, 22, 23, 24, 34, 35, 36, 49], "x_toy_oh": [16, 23, 35], "x_toy_ord": [16, 17, 23, 24, 35, 36], "x_tr": [26, 57], "x_train": [12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 48, 49, 50, 51, 53, 54, 57, 58], "x_train_big": 39, "x_train_cat": 28, "x_train_cat_oh": 28, "x_train_enc": [39, 40, 42, 49, 50, 51], "x_train_happi": [39, 52], "x_train_hous": 43, "x_train_imp": [16, 23, 35], "x_train_imp_sc": [16, 23, 35], "x_train_multi": 54, "x_train_num": 28, "x_train_num_imp": 28, "x_train_num_imp_sc": 28, "x_train_oversampl": 39, "x_train_perm": 42, "x_train_pp": 36, "x_train_predict": [16, 23, 35], "x_train_scal": [16, 23, 35, 43], "x_train_subsampl": 39, "x_train_tini": 38, "x_train_transform": [16, 23, 35], "x_train_usr": 46, "x_transform": [17, 24, 36], "x_valid": [26, 27, 39, 46, 57], "x_vari": 45, "x_xor": 43, "xanni": 38, "xavier": [43, 46], "xcode": 5, "xgbclassifi": [41, 42], "xgbclassifierxgbclassifi": 41, "xgboost": 42, "xgbregressor": [12, 19, 31, 41], "xlabel": [8, 13, 14, 15, 18, 20, 21, 22, 27, 32, 33, 34, 37, 38, 39, 40, 42, 45, 48, 49, 50, 51, 54, 56], "xlim": 50, "xor": [18, 37, 43], "xp": 28, "xt": [17, 24, 36], "xtick": [14, 21, 27, 33, 39, 49], "xticklabel": 38, "xticks_rot": 39, "xwm\u0259\u03b8kw\u0259y": 59, "xx": [43, 44], "y": [8, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57], "y_": 46, "y_citi": [15, 22, 34], "y_femal": 39, "y_hat": [18, 37, 41], "y_i": [40, 41, 43, 46], "y_init": 44, "y_label": [13, 14, 15, 20, 21, 22, 32, 33, 34, 56], "y_male": 39, "y_mat": 46, "y_multi": 54, "y_numer": 28, "y_pred": [39, 49], "y_pred_lower_threshold": 39, "y_pred_toi": 39, "y_pred_train": 49, "y_re": 39, "y_small_citi": [15, 22, 34], "y_spotifi": 38, "y_test": [12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 48, 49, 50, 51, 53, 54, 57, 58], "y_test_big": 38, "y_test_happi": [39, 52], "y_test_multi": 54, "y_test_num": [41, 42], "y_toi": [15, 22, 34, 49], "y_tr": [26, 57], "y_train": [12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 48, 49, 50, 51, 53, 54, 57, 58], "y_train_big": 39, "y_train_happi": [39, 52], "y_train_hous": 43, "y_train_multi": 54, "y_train_num": [41, 42], "y_train_ord": 49, "y_train_oversampl": 39, "y_train_subsampl": 39, "y_train_tini": 38, "y_train_usr": 46, "y_true": 51, "y_true_toi": 39, "y_valid": [26, 27, 39, 46, 48, 57], "y_vari": 45, "y_xor": 43, "yale": 47, "yan": [1, 59], "yann": 42, "ycxmx": 50, "ye": [4, 12, 13, 16, 17, 19, 20, 23, 24, 28, 31, 32, 35, 36, 42, 44, 45, 46, 48, 49, 51, 52, 53, 55], "year": [12, 13, 19, 20, 32, 46, 47, 48, 49, 50], "yearbuilt": [40, 42, 51], "yearremodadd": [40, 42, 51], "yellow": 38, "yellowbrick": [44, 45], "yesterdai": 49, "yet": [1, 10, 11, 18, 28, 30, 37, 42, 46, 49, 50, 57], "yifei": [1, 59], "ylabel": [8, 13, 14, 15, 18, 20, 21, 22, 26, 27, 32, 33, 34, 37, 38, 39, 40, 45, 48, 49, 50, 51, 54, 56, 57], "ylim": [50, 51], "yml": 10, "yolo": 48, "yolo8": 48, "yolo_input": 48, "yolo_result": 48, "yolo_test": 48, "yolov8n": 48, "york": [49, 53], "you": [0, 1, 4, 5, 6, 7, 8, 10, 26, 27, 42, 47, 53, 54, 55, 56, 57, 58, 59], "young": 30, "your": [0, 1, 2, 4, 6, 7, 8, 10, 14, 15, 16, 17, 18, 21, 22, 23, 24, 28, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59], "your_miniconda_path": 53, "your_nam": 10, "yourself": [4, 11, 17, 24, 36, 39, 46, 47, 51, 59], "yourselv": 47, "youtub": [1, 12, 19, 46, 47, 51, 59], "yr_built": [12, 13, 19, 26, 31, 32], "yr_renov": [12, 13, 19, 26, 31, 32], "yrpxn": 50, "yrsold": [40, 42, 51], "ytick": [14, 21, 27, 33, 39], "yticklabel": 38, "yy": [43, 49], "yyyi": 49, "z": [8, 18, 27, 37, 43, 44, 45, 46, 48, 50], "z_i": 48, "z_j": 48, "z_km": 44, "z_train": [27, 48], "z_valid": [27, 48], "zachari": 50, "zarei": [1, 59], "zefeng": [1, 59], "zeng": [1, 59], "zero": [8, 14, 17, 21, 24, 33, 36, 38, 46, 47, 51], "zero_divis": 39, "zhiyanov": [1, 59], "zip": [15, 18, 22, 27, 34, 37, 46, 53, 57], "zipcod": [12, 13, 19, 26, 31, 32, 57], "zombi": 30, "zone": [30, 49], "zoo": 30, "zoom": 7, "zorro": 30, "zu": 30, "zucco": 30, "\u0259m": 59, "\u03bc": 54}, "titles": ["LICENSE", "UBC CPSC 330: Applied Machine Learning (2024W2)", "CPSC 330 vs. CPSC 340", "CPSC 330 Documents", "How to ask for help", "What are git and GitHub?", "CPSC 330 grading policies", "Homework info &amp; submission guidelines", "CPSC 330 Python notes", "Reference material", "Setting up coding environment", "Course Learning Objectives", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "&lt;no title&gt;", "Lecture 3: ML Fundamentals Class Demo", "Lecture 4: Class demo", "Lecture 5 and 6: Class demo", "Lectures 7: Class demo", "Lectures 7: Class demo", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 12: Ensembles", "Lecture 13: Feature importances and model transparency", "Lecture 14: Feature engineering and feature selection", "Lecture 15: K-Means Clustering", "Lecture 16: More Clustering", "Lecture 17: Recommender Systems", "Lecture 18: Introduction to natural language processing", "Lecture 19: Multi-class classification and introduction to computer vision", "Lecture 20: Time series", "Lecture 21: Survival analysis", "Lecture 22: Communication", "Lecture 24: Deployment and conclusion", "Appendix A: Demo of feature engineering for text data", "Appendix B: Multi-class, meta-strategies", "Final exam preparation: guiding questions", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Syllabus"], "titleterms": {"": [12, 14, 15, 16, 17, 19, 22, 23, 24, 28, 31, 33, 34, 35, 36, 39, 40, 42, 49, 51], "0": 41, "1": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 50, 51, 55, 56, 57, 58], "10": 40, "12": 41, "13": 42, "14": 43, "15": [44, 51, 52], "16": 45, "17": 46, "18": 47, "19": 48, "2": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 50, 51, 55, 56, 57, 58], "20": [49, 51, 52], "2024w2": 1, "21": 50, "22": 51, "24": 52, "3": [12, 13, 14, 16, 19, 20, 21, 23, 26, 31, 32, 33, 35, 43, 44, 45, 50, 56, 57, 58], "330": [1, 2, 3, 6, 8, 12, 19, 52], "340": [2, 12, 19, 52], "4": [13, 14, 15, 20, 21, 22, 27, 32, 33, 34, 51, 56, 57, 58], "5": [8, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 28, 32, 33, 34, 35, 36, 39, 42, 43, 44, 47, 48, 50, 51, 57, 58], "6": [17, 24, 28, 36, 57], "7": [18, 29, 30, 37], "8": 38, "9": 39, "A": [4, 39, 45, 49, 53], "No": 8, "Not": 55, "One": [16, 23, 35, 49, 54], "The": [1, 14, 18, 21, 33, 37, 38, 41, 43, 44], "__": 38, "about": [8, 12, 19, 43, 46, 51], "academ": 59, "access": [7, 18, 37, 59], "accommod": 59, "acknowledg": 59, "activ": [12, 19, 26, 39, 42, 43, 44, 47, 51], "actual": [17, 36], "ad": 8, "addit": [7, 42], "address": 39, "advantag": 38, "advic": 43, "ai": 59, "aka": 51, "algorithm": [13, 15, 20, 22, 32, 34, 43, 44], "all": [12, 13, 16, 18, 19, 31, 32, 35, 37, 39, 44, 45, 46, 51], "alpha": [18, 37, 40], "alreadi": 52, "altern": [13, 16, 20, 23, 28, 32, 35], "an": [41, 51, 53], "analogi": [15, 34], "analysi": [26, 28, 49, 50, 52, 55, 57], "angl": 51, "announc": [12, 13, 14, 15, 16, 17, 18, 22, 24, 32, 34, 36, 37, 41], "answer": 50, "ap": 39, "api": [16, 23, 35, 52], "app": 52, "appendix": [53, 54], "appli": [1, 8, 16, 17, 23, 24, 35, 36, 40, 51], "applic": 44, "applymap": 8, "approach": [46, 49, 50, 51, 52, 54], "approxim": [14, 21, 33], "ar": [5, 12, 13, 16, 18, 19, 23, 31, 32, 35, 37, 39, 44, 45, 46], "area": 39, "argument": [14, 15, 21, 22, 33, 34], "around": 51, "arrai": 8, "articl": 9, "asap": 51, "ask": 4, "assess": 26, "assign": [7, 59], "associ": [18, 37], "assum": 50, "attent": [13, 15, 20, 22, 32, 34], "attribut": [42, 51], "auc": 39, "autom": 38, "averag": [39, 41, 46], "avoid": [14, 21, 33], "b": [44, 54], "backward": 43, "bad": 38, "bag": [17, 24, 36, 53], "balanc": 39, "base": [15, 34, 41, 43, 46, 49], "baselin": [13, 16, 20, 23, 26, 32, 35, 39, 41, 42, 46, 57], "basic": 47, "befor": [12, 16, 19, 23, 35], "best": 43, "better": [14, 21, 33, 38, 39, 43, 51], "between": [13, 15, 22, 32, 34, 52, 56], "beyond": [42, 46], "bia": [14, 21, 33, 38], "big": [13, 14, 16, 20, 21, 23, 32, 33, 35], "binari": 39, "book": 1, "boost": [41, 51], "bootstrap": 41, "bottom": 51, "boundari": [13, 15, 18, 20, 22, 27, 32, 34, 37, 56], "bow": [17, 24, 36], "box": 48, "break": [8, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 32, 33, 34, 35, 36, 43, 47, 48, 50, 51, 52], "broadcast": 8, "browser": [12, 19], "build": [12, 13, 19, 20, 26, 29, 30, 31, 32, 40, 46, 52], "c": [15, 22, 34, 38], "calcul": [18, 37], "california": [18, 36, 37, 58], "can": [8, 14, 16, 21, 23, 33, 35, 41, 42, 43, 44], "canada": [13, 32, 56], "care": [46, 51], "carri": [16, 23, 35, 43], "case": [17, 18, 24, 36, 37, 45], "catboost": 41, "categor": [16, 17, 23, 24, 28, 35, 36, 42, 49], "categori": [17, 24, 36], "censor": 50, "centr": 59, "certain": [17, 36], "cfa": 59, "chang": 39, "charact": [12, 19, 31], "characterist": 39, "cheatsheet": 8, "checklist": [12, 19], "choos": [15, 22, 34, 44], "chunk": 51, "churn": 50, "cite": 7, "citi": [18, 37], "claim": 51, "class": [12, 19, 26, 27, 28, 29, 30, 38, 39, 40, 41, 42, 46, 48, 54, 59], "class_attend": [17, 24, 36], "class_weight": 39, "classif": [13, 20, 27, 32, 39, 48, 52, 55], "classifi": [13, 18, 20, 28, 29, 30, 32, 37, 41, 53], "clearli": 43, "cluster": [44, 45, 55], "co": [1, 59], "code": [10, 59], "coeffici": [18, 29, 30, 37, 42], "color": [56, 57, 58], "column": [8, 16, 17, 23, 24, 35, 36, 49], "columntransform": [17, 24, 36, 58], "com": 15, "combin": 41, "come": [14, 15, 21, 22, 33, 34], "command": 5, "comment": [13, 20, 32, 38, 39, 40, 44, 45, 46], "common": [16, 23, 35, 44], "commonli": 47, "commun": [12, 19, 51, 55], "compact": [16, 23, 35], "companion": 9, "complet": 46, "complex": [14, 21, 33], "complic": 49, "compon": [18, 37], "comprehens": 58, "comput": [12, 19, 48, 55], "con": [15, 22, 34, 45, 55], "concept": [26, 51], "concern": 6, "concess": 59, "conclus": 52, "conda": 10, "conduct": 59, "confid": [18, 37, 51], "confus": [39, 51], "consid": 50, "construct": 41, "content": 46, "context": 47, "continu": [13, 20, 32], "conveni": [17, 24, 36], "corpu": 52, "correct": 44, "correl": 42, "countri": [13, 32, 56], "countvector": [17, 24, 36], "cours": [1, 9, 11, 12, 19, 31, 52, 59], "cover": [46, 50, 52], "cox": 50, "cpsc": [1, 2, 3, 6, 8, 12, 19], "creat": [7, 13, 14, 17, 20, 21, 24, 32, 33, 36, 46, 52], "credit": 10, "cross": [14, 16, 21, 23, 26, 33, 35, 39, 43, 49, 57], "cross_val_scor": [14, 21, 33], "cross_valid": [14, 21, 33, 40], "csv": 8, "curs": [15, 22, 34], "curv": [39, 50], "custom": [44, 50], "cv": 38, "dai": 49, "data": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 51, 52, 53, 57], "datafram": [8, 17, 24, 36], "dataset": [7, 13, 16, 18, 20, 23, 29, 30, 32, 35, 36, 37, 38, 39, 40, 48, 49, 51, 58], "date": [1, 49], "datetim": 49, "dbscan": 45, "deal": [17, 24, 36, 39], "debug": 10, "decis": [13, 15, 18, 20, 22, 26, 27, 32, 34, 37, 42, 51, 57], "decisiontreeclassifi": [13, 20, 32, 41], "decreas": 39, "deep": [48, 49], "defin": 43, "definit": [12, 19, 31], "deliver": [1, 12, 19], "demo": [26, 27, 28, 29, 30, 43, 49, 52, 53], "demonstr": 39, "dendrogram": 45, "depend": 43, "deploi": 52, "deploy": [14, 21, 33, 52, 55], "descript": 59, "desktop": 5, "detail": [21, 39, 40, 45], "detect": 48, "df": 8, "did": [14, 16, 17, 21, 23, 24, 33, 35, 36, 39, 40, 46, 50, 51, 52], "differ": [16, 23, 35, 38, 39, 40, 42, 52, 55], "dimens": [15, 22, 34], "dimension": [15, 22, 34], "directori": 52, "discuss": [26, 28, 38, 39, 46, 47, 51, 52], "diseas": [12, 19, 31], "distanc": [15, 22, 34, 44], "distribut": 38, "do": [16, 17, 23, 28, 35, 36, 38, 39, 41, 42, 43, 51, 52], "document": [3, 8, 44], "doe": [13, 18, 20, 21, 32, 37, 45, 51], "domain": 43, "drop": 8, "due": 1, "dummi": [27, 28, 53], "dummyclassifi": [13, 20, 32, 41, 49, 50], "dummyregressor": [13, 16, 20, 23, 32, 35, 40], "eda": [16, 23, 35, 39, 40, 52, 57], "effect": [41, 51], "elbow": 44, "element": 8, "elimin": 43, "embed": 47, "encod": [16, 17, 23, 24, 35, 36, 43, 49], "engin": [43, 49, 53, 55], "ensembl": [41, 55], "enter": 28, "environ": [10, 52], "equal": 51, "error": [14, 21, 33, 38, 39, 40, 46], "estim": [16, 23, 35, 41], "ethic": 55, "euclidean": [15, 22, 34], "eva": [12, 14, 19, 31, 33], "evalu": [39, 45, 46, 50, 55], "evalut": 39, "event": 50, "everyon": 50, "exactli": [18, 37], "exam": [55, 59], "examin": [17, 24, 29, 30, 36, 40, 51, 55], "exampl": [12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 47, 50, 51, 53], "exercis": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 46, 48, 50, 56], "exhaust": 38, "experi": 51, "explain": [42, 51], "explan": [42, 51], "explor": [15, 22, 34, 44], "exploratori": [26, 28, 49, 57], "extract": [17, 24, 36, 49], "extractor": 48, "f1": 39, "failur": 45, "fair": 39, "fancier": 38, "farewel": 52, "faster": 8, "fastest": 8, "featur": [12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 28, 31, 32, 34, 35, 36, 37, 40, 42, 43, 46, 48, 49, 51, 53, 55], "feature_importances_": 42, "few": [39, 45, 51], "fictiti": [12, 19, 31], "figur": 7, "filter": [8, 46], "final": [13, 20, 32, 38, 44, 45, 46, 49, 55, 57, 59], "find": [15, 22, 34, 43], "first": [12, 16, 19, 23, 35], "fit": [13, 16, 20, 23, 32, 35, 41], "flatten": 48, "follow": [12, 13, 14, 19, 21, 26, 31, 32, 33, 44, 45, 46], "font": [56, 57, 58], "forecast": 49, "forest": [41, 42, 51], "format": [7, 8, 12, 19], "formul": 46, "forward": 43, "from": [8, 51, 53], "full": 52, "function": [8, 18, 37, 40], "fundament": [14, 15, 21, 22, 26, 33, 34, 41, 55], "further": [49, 53], "futur": 49, "fuyi": 15, "gamma": [15, 22, 34], "garbag": 43, "gb": 51, "gener": [4, 6, 14, 15, 18, 21, 22, 33, 34, 37, 41, 43], "geometr": [15, 22, 34], "get": 42, "git": [5, 10], "github": 5, "given": [12, 13, 19, 20, 31, 32], "global": 46, "goal": [14, 21, 33], "golden": [14, 16, 17, 21, 23, 24, 33, 35, 36], "good": [39, 51], "grade": [4, 6, 13, 19, 20, 32, 59], "gradescop": 7, "gradient": [41, 51], "grid": [38, 51], "gridsearchcv": [38, 40, 51], "group": [26, 39, 44], "guid": 55, "guidelin": [4, 6, 7], "ha": [12, 19, 31], "halv": 38, "handl": 39, "have": [41, 42, 51], "hazard": 50, "heatmap": 38, "help": [4, 43], "here": [14, 21, 33], "hierarch": 45, "home": 45, "homework": [7, 12, 19], "hot": [16, 23, 35, 43, 49], "hous": [12, 13, 16, 18, 19, 23, 31, 32, 35, 36, 37, 58], "how": [4, 7, 13, 14, 15, 16, 18, 20, 21, 22, 23, 28, 32, 33, 34, 35, 37, 41, 42, 43, 45, 51], "http": 15, "hyper": 38, "hyperparamet": [13, 15, 17, 18, 20, 22, 24, 26, 32, 34, 36, 37, 38, 40, 41, 44, 55, 57], "i": [12, 14, 16, 17, 19, 21, 23, 24, 31, 33, 35, 36, 38, 39, 41, 42, 43, 44, 46, 47, 51, 52, 53], "iclick": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 50, 59], "idea": [15, 22, 34, 39, 41, 43, 51], "identifi": [17, 24, 36, 42], "imag": [12, 19, 27, 31, 48], "imagenet": 48, "imbal": [39, 40, 41, 42], "import": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57], "improv": 53, "imput": [16, 23, 35, 46], "incorpor": [17, 24, 28, 36], "increas": 39, "index": 8, "inertia": 44, "info": 7, "inform": [42, 49], "initi": [44, 52], "inject": 41, "input": [12, 19, 31, 44], "instal": [5, 10], "instruct": [0, 7], "instructor": 1, "interact": 43, "intercept": [18, 37], "interest": 51, "interim": [39, 42, 43, 49], "interpret": [18, 29, 30, 37, 42, 52], "intra": 44, "intro": 46, "introduct": [8, 12, 19, 31, 42, 43, 44, 45, 47, 48, 51, 55], "intuit": [18, 37], "involv": [49, 51], "issu": 51, "join": 15, "jupyt": [12, 19], "jupyterlab": 10, "k": [15, 16, 22, 23, 34, 35, 44, 45, 46], "kaplan": 50, "kei": [42, 51, 52], "kernel": [15, 22, 34], "kind": 41, "kneighborsclassifi": [15, 22, 27, 34], "knn": [27, 28], "label": [12, 19, 31, 44, 51], "lag": 49, "land": 59, "languag": 47, "larg": 38, "late": 7, "latitud": [13, 32, 56], "lda": 47, "learn": [1, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "least": [18, 37], "lectur": [1, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 59], "let": [15, 16, 17, 22, 23, 24, 28, 34, 35, 36, 39, 40, 42, 51], "licens": [0, 1], "lightgbm": 41, "limit": [6, 18, 37, 45], "line": 5, "linear": [18, 29, 30, 37, 40, 42], "link": 1, "list": 9, "liver": [12, 19, 31], "ll": [14, 21, 33], "lo": [14, 16, 17, 18, 21, 22, 23, 24, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 48, 49, 52], "load": 52, "local": 52, "localhost": 52, "logist": [18, 37, 39, 48], "logisticregress": [39, 49, 50, 51], "longitud": [13, 32, 56], "look": [39, 44], "loop": 8, "loss": 51, "lower": 38, "mac": 5, "machin": [1, 12, 13, 14, 15, 19, 20, 21, 22, 26, 31, 32, 33, 34, 39, 44, 52], "maco": 10, "macro": 39, "magnitud": [18, 37], "mai": 43, "main": [18, 37, 46, 51], "make": [8, 18, 37, 51], "make_column_transform": [17, 24, 36], "make_pipelin": [16, 23, 35], "mani": [17, 36, 38], "manual": 38, "mape": 40, "materi": [0, 1, 9], "matplotlib": 8, "matric": [17, 24, 36], "matrix": [39, 46], "matter": 21, "max_depth": [13, 20, 32], "mean": [40, 44, 45, 47, 51], "measur": 43, "media": 47, "meet": [12, 19, 31, 59], "meier": 50, "messag": [12, 19, 31, 45], "meta": 54, "method": [8, 28, 38, 43, 44], "metric": [39, 40, 55], "midterm": [44, 59], "might": 50, "min": [8, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 32, 33, 34, 35, 36, 39, 42, 43, 44, 47, 48, 50, 51, 52], "minor": 39, "misc": [1, 9], "miscellan": 46, "mislead": 51, "ml": [12, 14, 15, 19, 21, 22, 26, 31, 33, 34, 39, 42, 51, 55], "model": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 47, 48, 50, 52, 53, 55, 57], "model_select": 38, "moment": 52, "month": 49, "more": [13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 32, 34, 35, 36, 37, 39, 40, 43, 45, 49], "most": [18, 29, 30, 37], "motiv": [14, 15, 16, 18, 21, 22, 23, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 51], "movi": 46, "mse": 40, "much": 38, "multi": [39, 48, 54], "multiclass": 55, "multipl": [15, 17, 22, 24, 34, 36, 40], "multipli": 8, "n_estim": 41, "n_iter": 38, "n_job": 38, "n_neighbor": [15, 22, 34], "name": [14, 21, 33, 40, 46], "natur": 47, "nearest": [15, 16, 22, 23, 34, 35, 44, 46], "need": [16, 23, 35, 38], "neg": [29, 30, 39], "neighbour": [15, 16, 22, 23, 34, 35, 46], "nest": 8, "netflix": 41, "network": 48, "neural": 48, "new": [51, 52], "next": [12, 19, 52], "nlp": [47, 55], "nn": [15, 22, 34], "non": [15, 17, 22, 24, 34, 36, 42], "notat": 8, "note": [8, 14, 33, 49, 57], "notebook": [12, 19], "now": 50, "number": [41, 44, 49], "numer": [42, 43], "numpi": 8, "object": [11, 13, 20, 32, 41, 47, 48, 49, 50, 51, 52], "observ": 39, "occasion": [16, 23, 35], "off": [14, 15, 21, 22, 33, 34, 41], "oh": [16, 17, 23, 24, 35, 36], "ok": [16, 17, 23, 24, 35, 36], "onc": 39, "one": [17, 24, 36, 43], "onehotencod": [17, 24, 36], "onli": [17, 24, 36, 50], "onlin": [1, 9], "oper": 39, "optim": [26, 38, 55], "option": [10, 15, 16, 22, 23, 34, 35, 38, 39, 41, 43, 50, 52], "ordin": [1, 16, 17, 23, 24, 28, 35, 36, 42, 59], "other": [8, 15, 22, 34, 40, 43, 44, 47, 49, 50, 51], "our": [7, 14, 16, 21, 23, 33, 35, 51, 52, 53], "out": [16, 23, 35, 43, 48, 51, 52], "outcom": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46], "outlin": [56, 57, 58], "output": 44, "over": [8, 15, 18, 22, 34, 37, 39], "overfit": [14, 21, 33, 38], "oversampl": 39, "overview": [15, 22, 34, 39], "ovo": 54, "ovr": 54, "packag": [10, 49], "panda": 8, "pandas_profil": 40, "paper": [39, 41], "paradigm": [16, 23, 35], "paramet": [13, 18, 20, 32, 37, 38, 39, 55], "parametr": [15, 22, 34], "pars": 49, "part": 55, "pass": 38, "patient": [12, 19, 31], "perfect": 44, "perhap": 51, "permutation_import": 42, "persona": [12, 19, 31], "piazza": 4, "pick": [14, 21, 33, 38], "pictur": [13, 14, 16, 20, 21, 23, 32, 33, 35], "piec": 51, "pipelin": [16, 23, 28, 35, 47], "plan": 45, "playground": [15, 22, 27, 34, 57], "plot": [8, 42, 44, 50], "point": [15, 22, 34, 39, 42, 44, 49], "polici": 6, "poll": 44, "ponder": [29, 30], "popular": [12, 19, 31], "posit": [29, 30, 39], "posix": 49, "possibl": [17, 24, 36, 40, 44, 53], "post": 9, "pr": 39, "practic": [15, 20, 32, 34], "pre": 48, "precis": 39, "predict": [12, 13, 17, 18, 19, 20, 31, 32, 36, 37, 41, 42, 46, 48, 50, 54, 56], "predict_proba": [18, 37, 51], "predictor": 52, "prefer": 51, "prepar": [7, 55], "preprocess": [16, 17, 23, 24, 35, 36, 40, 47, 49, 51, 52, 55], "prerequisit": [12, 19], "preval": [12, 19, 31], "price": [12, 13, 19, 31, 32], "principl": 51, "prize": 41, "pro": [15, 22, 34, 45, 55], "probabl": [18, 37, 38], "problem": [13, 14, 15, 16, 20, 21, 22, 23, 32, 33, 34, 35, 38, 43, 46, 49, 52, 53], "procedur": 39, "process": 47, "product": [12, 19, 31], "profil": 46, "program": [13, 20, 32], "project": 53, "properli": 28, "proport": 50, "python": [8, 9, 10, 12, 19], "q": 4, "qualiti": 43, "queri": [8, 15, 22, 34], "question": [4, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58], "quick": [15, 34], "quiz": [13, 20, 32], "quiz2": [13, 20, 32], "quot": 43, "r": 40, "random": [38, 41, 42, 51], "random_st": [14, 21, 33], "randomforestclassifi": [41, 50], "randomizedsearchcv": [38, 40], "rang": 38, "rate": 46, "raw": [18, 37], "rbf": [15, 22, 27, 34], "re": 51, "read": [8, 13, 20, 32, 38, 48], "reader": 51, "real": [13, 32, 52, 56], "realist": [17, 24, 36], "reason": 6, "recal": 39, "recap": [13, 15, 20, 32, 34, 45, 50, 51, 56, 58], "receiv": 39, "recip": 52, "recommend": [12, 16, 19, 23, 35, 46, 55], "record": 59, "recurs": 43, "red": [56, 57, 58], "refer": [1, 9, 50], "reflect": [13, 14, 20, 21, 32, 33, 44, 45], "registr": [12, 19, 59], "regress": [13, 15, 18, 20, 22, 32, 34, 37, 39, 40, 41, 48], "regressor": [15, 22, 34], "relat": [4, 13, 15, 20, 22, 32, 34, 51], "relev": [9, 39, 41, 43], "remark": 49, "rememb": 44, "remind": [13, 32, 46], "remov": 8, "renam": 8, "render": 52, "report": [7, 39], "repositori": 7, "represent": [17, 24, 36, 48], "request": 52, "requir": [12, 19, 52], "rescu": [14, 21, 33], "resourc": [9, 12, 19, 38, 39, 43, 44, 45, 46], "rest": 54, "result": [38, 51], "retail": 49, "reus": 51, "review": [29, 30, 52], "revis": 26, "rf": 51, "rfe": 43, "ridg": [18, 37, 40], "ridgecv": 40, "right": 50, "rmse": 40, "roc": 39, "root": 40, "row": 8, "rule": [14, 16, 17, 21, 23, 24, 33, 35, 36], "run": [16, 23, 35, 51], "same": 8, "sampl": [39, 41, 44], "sauc": 44, "save": [12, 19, 31, 52], "scale": [12, 16, 18, 19, 23, 28, 31, 35, 37, 42], "schedul": 1, "scheme": 59, "scikit": [14, 16, 17, 21, 23, 24, 33, 35, 36, 40], "score": [13, 14, 18, 20, 21, 32, 33, 37, 38, 39, 40, 43, 44, 53], "search": [15, 22, 34, 38, 43, 51], "season": 49, "segment": 44, "select": [12, 13, 19, 31, 32, 43, 44, 45, 46, 55], "send": 52, "separ": [40, 42, 51], "seri": [8, 49, 55], "server": 52, "servic": 52, "set": [5, 10, 12, 14, 19, 21, 26, 33, 38, 39, 52], "set_config": [17, 24, 36], "shap": 42, "shape": [8, 45], "shaplei": 42, "short": 9, "should": [41, 46, 51], "show": [42, 51], "sigmoid": [18, 37, 48], "sign": [18, 37], "silhouett": 44, "similar": [15, 22, 34], "simpl": [14, 21, 33, 53], "simplefeatur": 42, "simpleimput": 28, "singl": [14, 21, 26, 33], "size": 8, "sklearn": [13, 16, 17, 20, 23, 24, 28, 32, 35, 36, 38, 39, 41, 42], "slowest": 8, "small": 51, "smote": 39, "social": 47, "softmax": 48, "softwar": [0, 48, 49], "solv": 38, "some": [13, 20, 32, 38, 39, 41, 43, 52], "sort": 8, "sort_valu": 8, "sourc": 7, "space": 49, "spaci": [47, 53], "spaghetti": 44, "spam": [12, 17, 19, 24, 31, 36], "spars": [17, 24, 36], "specif": [4, 43], "split": [14, 16, 21, 23, 26, 28, 33, 35, 39, 49, 57], "spotifi": [16, 23, 35, 38], "squar": 40, "stack": 41, "standardscal": [16, 23, 35], "statement": [12, 13, 19, 31, 32, 44, 45, 46], "statist": 52, "step": [13, 20, 26, 32, 47, 58], "strategi": [41, 54], "stratifi": 39, "strength": [18, 37, 41], "structur": 52, "studi": 55, "style": [12, 19], "submiss": 7, "submit": 7, "success": 38, "summari": [8, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], "supervis": [12, 13, 14, 15, 19, 20, 21, 22, 26, 31, 32, 33, 34, 44, 46, 52], "support": [15, 22, 34], "surviv": [50, 55], "svc": 39, "svm": [15, 18, 22, 27, 34, 37], "syllabu": [1, 59], "syntax": [16, 17, 23, 24, 35, 36, 38], "synthet": 39, "system": [46, 55], "ta": [1, 59], "tabular": [13, 15, 20, 22, 32, 34, 52], "tackl": 40, "take": 45, "takeawai": 52, "target": [12, 13, 17, 19, 20, 24, 31, 32, 36, 40, 44], "task": 47, "teach": [1, 59], "team": [1, 59], "techniqu": [16, 23, 35, 39], "templat": 7, "tempor": 49, "tent": 1, "terminologi": [13, 20, 32, 48], "test": [5, 14, 21, 26, 33, 38, 49], "test_df": [14, 21, 33], "test_siz": [14, 21, 33], "text": [17, 24, 28, 36, 47, 53], "than": [17, 24, 36, 38, 43, 51], "thei": 41, "them": 8, "thi": [8, 12, 16, 17, 19, 23, 24, 26, 28, 31, 35, 36, 42, 51, 52], "thing": [16, 23, 35, 51], "threshold": 39, "time": [6, 12, 19, 31, 49, 50, 55], "tip": 55, "todai": [14, 16, 17, 21, 23, 24, 33, 35, 36, 39, 40, 51], "toi": [13, 17, 20, 24, 32, 36, 39, 47], "token": 47, "tool": 47, "topic": 47, "trade": [14, 15, 21, 22, 33, 34, 41], "tradeoff": [14, 21, 33, 39, 41], "tradit": [13, 20, 32, 49], "train": [12, 13, 14, 17, 18, 19, 20, 21, 24, 31, 32, 33, 36, 37, 39, 48, 49, 51, 52], "train_df": [14, 21, 33], "train_siz": [14, 21, 33], "transfer": 48, "transform": [16, 17, 23, 24, 35, 36, 40, 43, 51], "transpar": [42, 52], "tree": [13, 20, 26, 32, 41, 42, 51, 57], "trend": 49, "true": [12, 19, 31, 44, 45, 46], "try": [16, 23, 28, 35, 40, 51, 52], "tune": [40, 44, 57], "tutori": [22, 56, 57, 58], "two": [17, 24, 36], "type": [12, 14, 19, 21, 31, 33, 39, 40, 42, 44, 49, 50, 51], "typic": [14, 21, 26, 33, 47], "u": 51, "ubc": 1, "ubuntu": 5, "under": 39, "underfit": [14, 21, 33], "undersampl": 39, "understand": 52, "unequ": 49, "unknown": [17, 24, 36], "unlabel": 44, "unseen": [12, 14, 19, 21, 31, 33], "unsupervis": [13, 20, 32, 44], "up": [5, 10, 12, 14, 15, 19, 21, 22, 33, 34, 51, 52], "updat": 7, "url": 8, "us": [7, 8, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 27, 31, 32, 33, 34, 35, 36, 39, 40, 41, 43, 44, 47, 48, 51, 54, 56, 59], "usa": [13, 32, 56], "user": [5, 46], "usual": 43, "util": 46, "v": [2, 12, 13, 14, 15, 19, 20, 21, 22, 32, 33, 34, 39, 42, 44, 48, 52, 54], "valid": [14, 16, 21, 23, 26, 33, 35, 38, 39, 49, 57], "varianc": [14, 21, 33], "vector": [8, 15, 22, 34, 47], "video": [12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 31, 32, 33, 34, 35, 37, 39, 40, 41, 44, 45, 47], "view": [15, 17, 22, 24, 34, 36], "violat": [14, 21, 33], "virtual": 10, "vision": [48, 55], "visual": [9, 38, 51], "vocabulari": [29, 30], "wai": [38, 43, 51], "waitlist": [12, 19], "want": [17, 24, 36, 42, 50], "warn": [13, 20, 32, 43], "watch": 51, "we": [8, 14, 16, 17, 18, 21, 23, 24, 26, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 50, 51, 52], "weak": 41, "web": 52, "websit": [12, 19], "weight": [18, 37, 39], "what": [5, 10, 12, 14, 16, 17, 18, 19, 21, 23, 24, 31, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 50, 51, 52], "when": [8, 16, 23, 35, 38, 51], "where": [17, 24, 36, 50], "whether": [12, 19, 31], "which": [12, 13, 19, 31, 32, 39, 41, 44, 45, 46], "why": [10, 12, 17, 19, 21, 24, 31, 36, 38, 42, 43, 46, 48, 51], "window": [5, 10], "wise": 8, "without": 44, "word": [17, 24, 36, 47, 53], "work": [13, 20, 32, 41, 45, 51], "workflow": [12, 14, 21, 31, 33, 39], "would": [14, 21, 28, 33, 52], "wrapper": 54, "write": [13, 20, 32], "x": [12, 13, 19, 20, 31, 32, 40, 42, 51], "xgboost": 41, "y": [12, 13, 19, 20, 31, 32, 40, 42, 51], "ye": 50, "yield": 38, "you": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52], "your": [5, 12, 13, 19, 20, 26, 32, 51]}})